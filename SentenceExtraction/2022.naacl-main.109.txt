
Jiaxin Yuand Deqing Yangand Shuyu Tian
School of Data Science, Fudan University, Shanghai 200433, China{jiaxinyu20,yangdeqing}@fudan.edu.cnsytian21@m.fudan.edu.cn
Abstract
Compared with traditional sentence-level re-
lation extraction, document-level relation ex-
traction is a more challenging task where an
entity in a document may be mentioned mul-
tiple times and associated with multiple rela-
tions. However, most methods of document-
level relation extraction do not distinguish be-
tween mention-level features and entity-level
features, and just apply simple pooling opera-
tion for aggregating mention-level features into
entity-level features. As a result, the distinct
semantics between the different mentions of an
entity are overlooked. To address this problem,
we propose RSMAN in this paper which per-
forms selective attentions over different entity
mentions with respect to candidate relations. In
this manner, the flexible and relation-specific
representations of entities are obtained which
indeed benefit relation classification. Our exten-
sive experiments upon two benchmark datasets
show that our RSMAN can bring significant
improvements for some backbone models to
achieve state-of-the-art performance, especially
when an entity have multiple mentions in the
document.
1 Introduction
Relation extraction (RE) is one important task of in-
formation extraction, aiming to detect the relations
among entities in plain texts. Recently, many schol-
ars have paid more attention to document-level RE
(Sahu et al., 2019; Yao et al., 2019) which aims
to identify the relations of all entity pairs in a doc-
ument, since it is more in demand than sentence-
level RE in various real scenarios. In general, one
document contains multiple entities and an entity
may have multiple mentions across different sen-
tences. Furthermore, one entity may be involved by
multiple valid relations and different relations areFigure 1: A t-SNE visualization example from DocRED.
Points of the same color and marker are different men-
tions’ embeddings of an entity, which are encoded by
BERT (Devlin et al., 2019).
expressed by different mentions of the same entity.
As a result, document-level RE is more challenging
than sentence-level RE.
A key step of existing document-level RE meth-
ods is to aggregate the information of different
mentions of an entity (mention-level features) to
obtain the entity’s representation (entity-level fea-
ture) at first, since relation classification is gener-
ally achieved on entity level. To this end, previous
RE models simply apply average pooling (Ye et al.,
2020; Xu et al., 2021), max pooling (Li et al., 2021),
or logsumexp pooling (Zhou et al., 2021; Zhang
et al., 2021). Finally, a fixed representation is ob-
tained for the given entity, which is then fed into
the classifier for relation classification.
However, different mentions of an entity in a
document may hold distinct semantics. A simple
pooling operation of generating a fixed entity repre-
sentation may confound the semantics of different
mentions, and thus degrades the performance of
relation classification when the entity is involved
by multiple valid relations. We call such situation
asmulti-mention problem in this paper. In Fig. 1,
we display the t-SNE (Van der Maaten and Hin-
ton, 2008) visualization of a toy example’s mention
embedding space to validate this problem. As the1523
figure shows, different mentions’ embeddings of
an entity (marked by the same color) in a document
are scattered over the whole embedding space, in-
dicating that different mentions of an entity are not
semantically adjacent. We further illustrate it by
the toy example in Fig. 2, the first mention Samuel
Herbert Cohen of the person entity is more impor-
tant for the classifier to identify the relation country
of citizenship between him and Australian . But for
extracting the relation place of birth , the second
mention Heshould be considered more. It implies
that different mentions should play different roles
when extracting the different relations involving
the same entity. In other words, different mentions
function differently in different relation recogni-
tions.
Inspired by this intuition, we propose a novel
Relation- Specific Mention Attention Network
(RSMAN ) to improve the model performance of
document-level RE. In RSMAN, each relation’s
essential semantics is first encoded into a prototype
representation. Then, the relevance weight (atten-
tion) between the prototype of a specific candidate
relation and each mention’s representation of the
given entity is calculated. Based on these atten-
tions, we get an attentive (weighted) sum of all
mentions’ representations as the entity’s synthetic
representation. In this manner, RSMAN enables
the model to attend to the information of multiple
mentions from different representation space when
representing an entity, indicating that the entity’s
representation is flexible and relation-specific with
respect to different candidate relations.
Our contributions in this paper can be summa-
rized as follows:
1. To the best of our knowledge, this is the first
to consider different mentions’ significance with
respect to candidate relations on representing anentity to achieve document-level RE.
2. We propose a novel RSMAN which can be used
as a plug-in of a backbone RE model, to learn a
relation-specific representation for a given entity
which enhances the model’s performance further.
3. Our empirical results show that RSMAN can
significantly promote some backbone models to
achieve state-of-the-art (SOTA) RE performance,
especially when an entity have multiple mentions
in the document.
The rest of this paper is organized as follows.
In Section 2, we briefly introduce some works re-
lated to our work. Then we introduce the proposed
method in Section 3 and the experiment results in
Section 4. At last, we conclude our work in Section
5.
2 Related Work
Prior efforts on document-level RE mainly focused
on representation learning and reasoning mecha-
nism. Yao et al. (2019) employed four different
sentence-level representation models to achieve
document-level RE, including CNN, LSTM, BiL-
STM, and Context-Aware. For more powerful rep-
resentations, later work introduced pre-trained lan-
guage models into their neural architectures (Ye
et al., 2020; Zhou et al., 2021; Xu et al., 2021).
In particular, Ye et al. (2020) added a novel men-
tion reference prediction task during pre-training
and presented CorefBERT to capture the coref-
erential relations in contexts. Zhou et al. (2021)
proposed ATLOP to learn an adjustable threshold
and thus enhanced the entity pair’s representation
with localized context pooling. Xu et al. (2021)
defined various mention dependencies in a docu-
ment and proposed SSAN to model entity structure
for document-level RE. In addition, other work
built various kinds of document graphs to model
reasoning mechanism explicitly (Nan et al., 2020;
Zeng et al., 2020; Wang et al., 2020). For example,
Nan et al. (2020) induced the latent document-level
graph and performed multi-hop reasoning on the
induced latent structure. Wang et al. (2020) con-
structed a global heterogeneous graph and used a
stacked R-GCN (Schlichtkrull et al., 2018) to en-
code the document information. Zeng et al. (2020)
proposed GAIN to leverage both mention-level
graph and entity-level graph to infer relations be-
tween entities. However they all ignore the multi-
mention problem described in Sec. 1.1524
3 Methodology
At first, we formalize the task of document-level
RE addressed in this paper as follows.
Suppose a document Dmentions Pentities, de-
noted as E={e}, and the i-th entity ehasQ
mentions in D, denoted as {m}, the task of
document-level RE is to extract a set of relational
triples {(e, r, e)|e, e∈ E, r∈ R} where Ris
a pre-defined relation set.
3.1 Backbone RE Model
Suppose for each mention of e, its representation
mis obtained by a model-specific method. Most
of existing backbone models apply a certain pool-
ing operation for all ms to obtain e’s represen-
tation e, such as the following average pooling,
e=1
Q/summationdisplaym. (1)
As we claimed in Section 1, eis a fixed represen-
tation which ignores that different mentions of e
play distinct roles when identifying the different
relations involving e.
Finally, given the subject entity’s eand the ob-
ject entity’s representation e, a bilinear classifier
is often used to calculate the probability of relation
rinvolving these two entities as follows
P(r|e, e) =σ(eWe+b) (2)where W∈Randb∈Rare trainable model
parameters specific to r, and σis Sigmoid activa-
tion.
3.2 Attentive Operations in RSMAN
Our proposed RSMAN incorporates attentive
mention-level features to generate flexible entity
representations with respect to different candidate
relations, and thus enhances the backbone model’s
performance. RSMAN’s framework is shown in
Fig. 3, which acts as a plug-in of the backbone
model.
For each candidate relation r, its prototype repre-
sentation pis first obtained through random initial-
ization and is trainable during the training process.
Then, we leverage pto calculate the semantic rel-
evance between rand each mention mas follows,
s=g(p,m) (3)
where gis a certain function to compute the similar-
ity between two embeddings, which can be a simple
dot-product or multi-layer perceptron (MLP) fed
with the concatenation of two embeddings. Then,
we feed all ss ofeinto a softmax function to get
final attention weight
α=exp(s)
/summationtextexp(s). (4)
Since there is a necessity to consider all the men-
tion information of the entity, we use a weighted1525sum of all mention representations to obtain the
relation-specific entity representation instead of us-
ing only one specific mention representation. We
gete’s representation specific to ras
e=/summationdisplayαm. (5)
Different to the fixed representation computed by
Eq. 1, such eis a flexible embedding adaptive to
different candidate relation r.
At last, we use this relation-specific entity repre-
sentation to achieve relation classification by modi-
fying Eq. 2 as
P(r|e, e) =σ(eWe+b). (6)
4 Experiments
In this section, we introduce our experiments to
justify our RSMAN, and provide insight into the
experiment results.
4.1 Datasets and Evaluation Metrics
We conducted our experiments on two representa-
tive document-level RE datasets: DocRED (Yao
et al., 2019) and DWIE (Zaporojets et al., 2021),
which are introduced in detail in Appendix A. We
adopted F1 and Ign F1 as our evaluation metrics
as (Yao et al., 2019), where Ign F1 is computed by
excluding the common relation facts shared by the
training, development (dev.) and test sets.
4.2 Experimental Settings
We use dot-product as the similarity scoring func-
tion for its computational efficiency, and before
it we add a fully connected layer to project the
mention representations into the same embedding
space with the prototype representations. All the
additional parameters we introduce for RSMAN
including the prototype representations is much
fewer than the parameters of either the original
bilinear classifier or the backbone model itself.
We took some stat-of-the-art models mentioned
in Sec. 2 as the baselines, i.e., CNN (Zeng
et al., 2014), LSTM/BiLSTM (Cai et al., 2016),
Context-Aware (Sorokin and Gurevych, 2017),
CorefBERT (Ye et al., 2020), GAIN (Zeng et al.,
2020), SSAN (Xu et al., 2021) and ATLOP (Zhou
et al., 2021). We chose CorefBERT and SSAN as
the backbone models in our framework due to their
good performance and strong pluggability for our
RSMAN. We did not consider GAIN and ATLOP
as the backbone because they both leverage extra
information besides entity representations. More
setting details are shown in Appendix B.
4.3 Results and Analyses
All the following results of our method were re-
ported as the average scores of three runs. From
the results on DWIE shown in Table 1 we find
that plugged with RSMAN, both CorefBERT and
SSAN have significant improvements. Specifically,
our RSMAN relatively improves CorefBERT’s F1
by 1.9% (dev. set) and 1.4% (test set), and rela-
tively improves SSAN’s F1 by 1.84% dev F1 (dev.
set) and 2.25% (test set), respectively. The con-
sistent improvements verify the effectiveness of
leveraging attentive mention-level features to learn
relation-specific entity representations. What’s
more, the positive effects on different backbone
models show good generalization performance of
our RSMAN. Overall, SSAN+RSMAN achieves
63.42% Ign F1 and 70.95% F1 on the test set, out-
performing all the baselines apparently.
For simplicity, we only display the results on
DocRED of CorefBERT and SSAN plugged with1526
RSMAN in Table 2. It shows that RSMAN also
brings relative improvements of 1.39% Ign F1 and
1.00% F1 on the test set for CorefBERT, along with
relative improvements of 1.71% Ign F1 and 1.51%
F1 for SSAN. It is worth noting that the perfor-
mance improvements on DocRED are relatively
less significant than that on DWIE. Through our
statistics, we found that the average number of men-
tions per entity in DocRED is only 1.34, while it is
1.98 in DWIE. Besides, only 18.49% of entities in
DocRED have multiple mentions, much less than
33.59% in DWIE. It implies that our RSMAN is
more effective on the entities with multiple men-
tions, which are more common and challenging in
many real scenarios of document-level RE.
4.4 Effect Analysis for Mention Number
To confirm our conjecture mentioned before, we
investigated the effect of mention number through
further experiments. We first reconstructed the re-
lation instances in DocRED’s dev. set and obtained
three different subsets: the first one contains all
instances (All), another one contains either subject
or object argument having more than one mention
(M1), and the rest one contains either subject or
object argument having more than two mentions
(M2). We don’t consider M3 or higher becausethey have very few instances limited by the dataset.
Then, we evaluated CorefBERT and SSAN with or
without RSMAN upon the three subsets.
From Fig. 4, we find that the F1s of all compared
methods increase from All to M2. It indicates that
multiple mentions can provide more information
for the models to capture the entity semantics, re-
sulting in more precise RE results. Furthermore,
the performance gains of plugging RSMAN into
the two backbone models also increase as the men-
tion number per entity increases. It shows that our
RSMAN can bring more significant performance
boosts for the backbone model when the entities
of the relation instances have more mentions in a
document. These results justify that RSMAN has
more potential for extracting relations based on the
entities with more mentions.
4.5 Case Study
To explore how RSMAN attends to different men-
tions’ information of an entity, we collected all
relations’ normalized attentions for an entity’s men-
tions in RSMAN. Fig. 5 is the heatmap of atten-
tions for a specific entity, from which we observe
that the distribution of relation attentions varies
greatly among different mentions. Besides, accord-
ing to the high attention of a given relation, we can
capture which mention of the entity well expresses
this relation’s semantics. This map also confirms
the implication of Fig. 1 that different mentions of
an entity contain distinct semantics. Therefore, the
attentive aggregation of all mention-level features
in RSMAN is more appropriate for enhanced RE
than the common pooling operations.
5 Conclusion
In this paper, we focus on the multi-mention prob-
lem in document-level RE and propose RSMAN
to address it. Our experiment results demonstrate
RSMAN’s effectiveness especially on the scenario
of multi-mention situation. In the future, we plan to
adapt RSMAN to more document-level RE models.
Acknowledgements
This paper was supported by Shanghai Sci-
ence and Technology Innovation Action Plan
No.21511100401, and AECC Sichuan Gas Turbine
Establishment (No.GJCZ-2019-0070), Mianyang
Sichuan, China. We sincerely thank all reviewers
for their valuable comments to improve our work.1527References1528
A Datasets
DocRED is a large-scale human-annotated dataset
for document-level RE. DWIE is a dataset for
document-level multi-task information extraction
which combines four main sub-tasks and in our
work we only used the dataset for document-level
relation extraction. We preprocessed DWIE dataset
and adopted the same dataset partition as (Ru et al.,
2021). More statistical information is detailed in
Table 3.
Statistics DWIE DocRED
# Train 602 3053
# Dev 98 1000
# Test 99 1000
# Relations 65 96
# Relation facts 19493 56354
Avg.# mentions per Ent. 1.98 1.34
Hyper-parameter DWIE DocRED
Batch size 4 8
Learning rate 3e-5 5e-5
Epoch 40 60
Gradient clipping 1 1
Warmup ratio 0.1 0.1
B Implementation Details
In this appendix, we introduce more details of our
experimental settings. We implemented our RS-
MAN with PyTorch and trained it with an NVIDIA
GeForce RTX 3090 GPU. In addition, we adopted
AdamW (Loshchilov and Hutter, 2018) as our opti-
mizer and used learning rate linear schedule with
warming up based on Huggingface’s Transformers
(Wolf et al., 2019). The hyper-parameter settingsof our experiments on the two datasets are listed
in Table 4, which were decided through our tuning
studies.1529