
Yan Song
University of Science and Technology of China
clksong@gmail.com
Abstract
Composing Ci (also widely known as Song
Ci), a special type of classical Chinese po-
etry, requires to follow particular format once
their tune patterns are given. To automatically
generate a well-formed Ci, text generation
systems should strictly take into account pre-
deﬁned rigid formats (e.g., length and rhyme).
Yet, most existing approaches regard Ci gener-
ation as a conventional sequence-to-sequence
task and use autoregressive models, while it is
challenging for such models to properly han-
dle the constraints (according to tune patterns)
of Ci during the generation process. Moreover,
consider that with the format prepared, Ci gen-
eration can be operated by an efﬁcient syn-
chronous process, where autoregressive mod-
els are limited in doing so since they fol-
low the character-by-character generation pro-
tocol. Therefore, in this paper, we propose to
compose Ci through a non-autoregressive ap-
proach, which not only ensure that the gener-
ation process accommodates tune patterns by
controlling the rhythm and essential meaning
of each sentence, but also allow the model
to perform synchronous generation. In addi-
tion, we further improve our approach by ap-
plying reinforcement learning to the genera-
tion process with the rigid constraints of Ci as
well as the diversity in content serving as re-
wards, so as to further maintain the format and
content requirement. Experiments on a col-
lected Ci dataset conﬁrm that our proposed ap-
proach outperforms strong baselines and previ-
ous studies in terms of both automatic evalua-
tion metrics and human judgements.
1 Introduction
Ci is a special type of Chinese poetry and different
from general poems, where their shape (including
lengths and tunes) is determined by tune patterns
(i.e.,词牌, also known as brand names) deﬁningFigure 1: The ﬁrst half of an example Ci following the
tune pattern “ 念奴娇”(Charm of a Singer ), where all
essential words in this Ci are highlighted in blue. Trans-
lations for each clause are provided for reference.
the particular syllable and rhythm schemes that a Ci
should stick to.Over the past one thousand years,
composing Ci has long been an interesting game
and continued to present days for Chinese people to
demonstrate one’s literary and artistic accomplish-
ments. Given that Ci composition is challenging,
to perform this task with artiﬁcial intelligence is
meaningful since it is a good test for controlled nat-
ural language generation under speciﬁc constraints
(i.e., the length and rhyme of Ci should follow the
constraints given by the tune pattern).7219
Recently, text generation models based on deep
neural networks (e.g., LSTM (Hochreiter and
Schmidhuber, 1997) and Transformer (Vaswani
et al., 2017)) have been widely used for poem
and Ci generation (Wang et al., 2016a; Yang et al.,
2018a; Yi et al., 2018; Yeh et al., 2019; Li et al.,
2020; Wu et al., 2021) and demonstrated their va-
lidity in doing so. Among previous studies, most
mainly follow the conventional text generation
paradigm which performs an autoregressive gen-
eration process by generating a poem or Ci in a
character-by-character manner. However, since Ci
is usually longer than classical poem, these au-
toregressive models face the challenge of losing
semantic coherence in-between the beginning and
end of a Ci when it is too long and thus might
lead to inferior results because a high-quality Ci
always requires good coherence in the topic. To
illustrate, Figure 1 shows a well-known Ci with
the tune pattern “ 念奴娇” (Charm of a Singer ),
where every sentence in this Ci are correlated to
each other and stick to the main topic. Therefore,
Ci shows the following two characteristics which
are required to be addressed carefully during its
generation process: (1) once the tune pattern is
given, the rigid format of the Ci (i.e., the length
and rhyme) is determined; (2) different parts in a Ci
should show high relevance in semantics (e.g., stickto a particular topic). These characteristics suggest
that non-autoregressive models (whose effective-
ness for text generation has already been demon-
strated in machine translation (Gu et al., 2018),
image captioning (Lee et al., 2018), and summa-
rization (Qi et al., 2021)) have their potential to
be appropriate choices for this task. Moreover,
another advantage of non-autoregressive models
is that they are able to generate different parts of
a Ci synchronously, which is more efﬁcient com-
pared with autoregressive ones. Still, although non-
autoregressive models show aforementioned superi-
ority, there are further improvements needed for Ci
composition, such as guiding the model to generate
clauses strictly following the length and rhyme re-
quirements of the tune pattern and providing more
diversiﬁed generation results, which are normally
hard to be controlled through conventional super-
vised/unsupervised functions. Consider that rein-
forcement learning (RL) is able to guide the pa-
rameter optimization process of a model through
object-oriented rewards and it has been demon-
strated to be effective in many natural language
generation tasks such as dialogue generation (Li
et al., 2016), paraphrase generation (Li et al., 2017),
and image captioning (Qin and Song, 2022), it is
expected to be also effective in helping the non-
autoregressive models to generate Ci that better7220follows the constraints of the tune pattern.
In this paper, we propose, CG, a non-
autoregressive model for Ci generation with a
given tune pattern, where we employ a key word
guided generation process to ﬁrstly generate essen-
tial (ESS) words (e.g., the ones highlighted in blue
in Figure 1) that convey the important meaning for
each part (e.g., sentence) and then generate the ﬁnal
full Ci. To further enhance the non-autoregressive
model, we apply RL to Ci composition so as to
accommodate the formats and rhyming constraints,
which are generally hard to learn by the conven-
tional supervised or unsupervised learning methods
since it is not easy to design normal loss functions
for them. In evaluation, we test our approach on
a collected Song Ci dataset, where our approach
outperforms strong baselines and previous studies
on both automatic and human evaluation metrics.
2 The Proposed Approach
Figure 2 illustrates the overall architecture of our
CGfor Ci composition with the given tune
patternZ, where the format (denoted as X=
x,···,x,···,xwithxpresenting the format
of thet-th character and Tthe number of char-
acters) of Ci is obtained based on the tune pat-
ternZand then used to generate the intermedi-
ateESS words (denoted as /hatwideK), and the candidate
Ci (denoted as /hatwideV=/hatwidev,···,/hatwidev,···,/hatwidev), then the
generated ESS words and the candidate Ci are
then combined to obtain the ﬁnal Ci (denoted as
/hatwideY=/hatwidey,···,/hatwidey,···,/hatwidey). Therefore, the process
of the proposed non-autoregressive approach for
Ci composition is formally expressed by
/hatwideY=C(/hatwideV,/hatwideK) (1)
with

/hatwideV=f(X,/hatwideK)
/hatwideK=f(X)
X=F(Z)(2)
whereCrefers to the combination of candidate Ci
andESSwords,fdenotes a general text generation
process with the given input, Fextracts the format
of the Ci based on the given tune pattern. In the
following text, we ﬁrst illustrate the process to ob-
tain the format representation from the tune pattern,
then present the non-autoregressive model for guid-
ing word driven Ci generation, and ﬁnally how we
use RL enhancement to compose high-quality Ci.2.1 Format Representations
One characteristic of Ci is that its format is de-
termined by the tune pattern. To represent the
format information, we refer to a previous studie
(Li et al., 2020) and use the combination of four
types of symbols to represent the format x=
(r,p,s,g), wherer,p,s, andgdenote
therhyme (RHY), intra-position (INP), clause-
index (CLI), and global-position (GLO) symbols,
respectively. Table 1 presents the values of differ-
ent symbols for the ﬁrst three clauses (i.e., “ 大江东
去，浪淘尽，千古风流人物。”) in the example
in Table 1 for better illustration, and we elaborates
the details of these symbols in the following texts.
Rhyme symbols Rhyme symbols are designed
to illustrate whether the associated characters are
required to follow the rhyme of the tune pattern.
Speciﬁcally, the rhyme symbol rforxhas three
choices, namely, P(punctuation), R(rhyme), and
O(other cases): r=Pifxshould be a punc-
tuation;r=Rifxshould follow the rhyme, in
which casexis a punctuation (for Ci, the char-
acter that directly precedes the punctuation has to
follow the rhyme); r=Ootherwise.
Intra-position symbols Intra-position symbols
pare used to represent the distance of xto the
nearest following punctuation. That is, we deﬁne
this symbol by measuring how far the next punc-
tuation (denoted as x) is to thex(wheret≤t),
and set its value to ptob. Therefore,balways
denotes the punctuation, which enables our model
to correctly recognize the boundary of clauses.
Clause-index symbols Local-position symbols
are used to represent each character that the index
of a clause it belongs to. Therefore, s=cif the
t-th character is in the j-th clause in a Ci.
Global-position symbols Global-position sym-
bolsgare designed to represent the global posi-
tional information for each character xand they
are demonstrated to be powerful in many previous
studies for text generation (Radford et al., 2019;
Deng et al., 2020; Lewis et al., 2020; Raffel et al.,
2020). In our approach, the global-position symbol
gfor thet-th character is t, i.e.,g=t.
Once all symbol values are obtained for x,
we map them to their corresponding embeddings,
namely, rhyme embedding e, intra-position em-
bedding e, clause-index embedding e, and
global-position embedding e, where we follow the7221
positional embedding mechanism in Transformer
(Vaswani et al., 2017) to compute our GLO em-
beddings. Afterwards, we directly concatenate ( ⊕)
the four types of embeddings and obtain the format
embedding efor thet-th character by
e=e⊕e⊕e⊕e (3)
To summarize, since the four types of symbols re-
ﬂect the characteristics of Ci from different aspects,
the combination of them (i.e., the format represen-
tation e) contains informative features and con-
straints given by the tune pattern and thus could be
used to enhance a model for Ci composition.
2.2 Ci Composition with Essential Words
Although non-autoregressive models with afore-
mentioned format representations are able to lever-
age the format constraints in composing Ci, it is
still hard for them to automatically maintain se-
mantic consistency. Consider that the overall emo-
tional tone and topic of a Ci are generally carried
by its essential words, we propose to enhance non-
autoregressive models through a guided generation
process with ESS words. Speciﬁcally, the model
ﬁrstly generates the ESSwords with the given tune
pattern (i.e., the format representations) and then
uses the generated ESSwords to guide the rest gen-
eration process. Therefore, our model is able to
learn the potential relation between the format and
the overall emotion tone carried by the ESSwords
and leverage them for the later Ci composition.
ForESSwords generation, our model applies an
encoder (denoted as f) to the format representa-
tionE=e,···,eand obtain a sequence of
hidden vectors H=h,···,h,···,hby
H=f(E) (4)
It is worth noting that ftakes the matrix E
and computes the matrix Hthrough a single for-ward pass, which differs from conventional auto-
regressive approach that generates a single vector
step by step. Then the hidden vector his then
fed into a fully connected layer with the softmax
classiﬁer to predict the ESS character/hatwidekfor the
inputx:
/hatwidek=softmax (W·h+b) (5)
where Wandbare the trainable matrix and bias
vector in the fully connected layer, respectively.
With ESS words, for Ci generation, we ﬁrstly
map all generated ESScharacters /hatwidekto their embed-
dingseand then add the format representation e
to the resulting embeddings through
h=e+e (6)
Afterwards, similar to the generation process of
ESS words, we use another encoder (which is de-
noted asfand computes the output matrix via
a process similar to f) to process the obtained
H=h,···,h,···,hand obtain the hidden
vectors H=h,···,h,···,hvia
H=f(H) (7)
where his fed into a fully connected layer with
thesoftmax classiﬁer to predict the character /hatwidev
for eachxin the candidate Ci:
/hatwidev=softmax (W·h+b) (8)
where Wandbare the trainable matrix and
bias vector. Finally, to take the advantage of the
generated ESS words, we combine the ESS words
and the candidate Ci based on the following rule:
/hatwidey=/braceleftBigg
/hatwidevif/hatwidek=[N]
/hatwidekotherwise(9)
so as to obtain the ﬁnal resulted Ci, /hatwideY.
Different from the conventional autoregressive7222text generation approaches, for both ESSword and
Ci generation, our model generates all characters
synchronously, which allows our model to efﬁ-
ciently leverage context information in a one-time
encoding and decoding process in Ci composition.
In the training process, we compare the gener-
ated ESS words and the ﬁnal resulted Ci with the
ground truthand compute the loss LandLfor
them, respectively, which are further used to update
the model parameters through backpropagation.
2.3 Enhancement with RL
Although using the non-autoregressive model con-
ditioning on format and rhyme is able to generate
more satisfying Ci than models without such re-
striction (e.g., systems designed for poetry genera-
tion), there are still gaps between the performance
of automatically generated Ci and those composed
by poets. To address this problem, we propose to
incorporate reinforcement learning (RL) into our
non-autoregressive model so as to further improve
the quality of Ci composition. In doing so, we re-
gard the entire generation process as a two-state
reward maximization task. Therefore, in training
each instance, the agent (i.e. the model) starts from
the initial state S, which is the input format, then
selects an action (i.e. generated Ci /hatwideY) according to
thepolicy (i.e.π(S,/hatwideY) =p(/hatwideY;θ)withθdenot-
ing all model parameters), and receives a reward
rand arrives at the terminal state. Speciﬁcally, the
total reward is a linear combination of the format ,
rhyme , and diversity scores via
r=λr+λr+λr+λr (10)
whereλ(i∈{1,2,3,4})are hyper-parameters;
ris the score for format, which is the number of
correctly segmented sentences/clauses in /hatwideY;ris
the score for rhyme which is the number of pre-
dicted characters that correctly follow the rhyme
requirement of the given tune pattern; randr
are the scores for uni-gram and bi-gram diversi-
ties, respectively, which are the number of unique
uni-grams and bi-grams in the generated Ci.
To solve the reward maximization problem,
we follow the REINFORCE algorithm (Williams,
1992) with loss and corresponding gradient
L(θ) =−E(r) =−/summationdisplayp(/hatwideY;θ)·r(/hatwideY)(11)
and
∇L(θ) =−/summationdisplayp(/hatwideY;θ)r(/hatwideY)∇logp(/hatwideY;θ)
=−E[∇logp(/hatwideY;θ)r(/hatwideY)]
(12)
respectively. The gradient is estimated by a single
Monte-Carlo sampling /hatwideY={/hatwidey,...,/hatwidey}through
∇L(θ)≈−∇logp(/hatwideY;θ)r(/hatwideY) (13)
However, the estimation of gradient is of high vari-
ance. Therefore, we follow Rennie et al. (2017)
and introduce a baseline function that is indepen-
dent with the action /hatwideY. Therefore, the reﬁned loss
and gradient estimations are formalized as
L(θ) =−E(r(/hatwideY)−r(/hatwideY)) (14)
and
∇L(θ)≈−∇logp(/hatwideY;θ)(r(/hatwideY)−r(/hatwideY))
(15)
respectively, where /hatwideYdenotes the generated Ci
selected using top-ksampling.
As a result, the overall training loss is formal-
ized as a linear combination of all losses from the
aforementioned steps, including L,L,L:
L=αL+βL+γL (16)
whereα,β, andγare hyper-parameters to control
the effect of L,L, andL, respectively.
3 Experiment Settings
3.1 Dataset
To evaluate the performance of our approach, we
run experiments with Song Ci dataset, where there
is no ofﬁcial train/dev/test split for this dataset,
so that we randomly split the data into training,
development, and test sets, with the statistics re-
ported in Table 2. Since no ESSword annotations
are provided in the original dataset, we automati-
cally annotate ESS words and regard them as the
ground truth in training our model. In doing so,7223ModelsDiversity Format RhymeSpeed
MA-U MI-U MA-B MI-B MA MI MA MI
SongNet (Li et al., 2020) 72.34 2.18 97.05 34.09 99.84 99.81 62.97 62.84 0.40
CG 37.08 0.06 92.59 2.60 99.77 99.75 44.65 43.15 43.03
CG+ESS 56.12 0.22 95.60 9.76 99.88 99.87 54.61 53.87 42.94
CG+ESS+ RL 74.36 3.13 98.73 51.45 99.92 99.89 63.47 63.16 38.49
we randomly sample 1,000 Ci from the dataset and
invite two annotators to manually mark ESSwords
that convey important meaning in each Ci. Next,
we use the annotated Ci as training data to train
a BERT-based(Devlin et al., 2019) ESS word
annotator (which is similar to a named entity an-
notator) following the sequence labeling paradigm.
Then, we apply the trained annotator to the entire
dataset and obtain the “ground truth” ESS words.
The statistics of the auto-annotated ESS words in
the train/dev/test sets are also reported in Table 2.
3.2 Implementation Details
Since the quality of text representation plays an im-
portant role in many natural language processing
tasks (Han et al., 2018; Radford et al., 2019; Tian
et al., 2020; Lewis et al., 2020; Diao et al., 2020;
Raffel et al., 2020), we use the well-performed
Transformer (Vaswani et al., 2017) architecture for
both ESS word and Ci generation.Speciﬁcally,
for both Transformer encoders (i.e., fandf),
we use 6 layers of multi-head attentions, with 12
heads and the dimension of the hidden vectors set
to 768. For the λin RL rewards, we treat the re-
wards from format, rhyme, and diversity equally
withλ=λ=λ=λ= 0.25in Eq. (10)).
Besides, we use k= 32 for the top-ksampling
to compute the reﬁned loss (i.e., see Eq. (11)).
We train all models including the one with RL for
30 epochs over all training data. For evaluation,
we follow previous studies (Li et al., 2020) andevaluate model performance from diversity, format,
and rhyme using Macro-F1 (MA) and Micro-F1
(MF), where the diversity is evaluated based on the
distinctness of uni-grams (U) and bi-grams (B).
4 Results and Analysis
4.1 Overall Results
Table 3 reports the experimental results of our ap-
proach with different settings: CGis the model
that uses only fand treats the candidate Ci as the
ﬁnal one. CG+ESS uses the ESS words to
guide the Ci generation process, and CG+ESS
+ RL is our full model which leverages both ESS
words and RL. The results of our experiment us-
ing SongNet (Li et al., 2020) is also reported for
comparison. We also present the inference speed
(i.e., the number of generated Ci per second) of all
models. Overall, there are several observations.
First, compared with CGthat directly gener-
ates Ci, the model enhanced by ESS word guided
generation (i.e., CG+ESS) achieves higher
performance with respect to all evaluation metrics.
This observation indicates that, CG+ESS is
able to learn from the ESSwords that carry impor-
tant semantic or topic information, and thus allows
the model to generate a Ci with more coherent and
meaningful expression. On the contrary, CG
does not beneﬁt from the ESSwords so that it leads
to inferior performance in all evaluation metrics.
Second, comparing CG+ESS and our full
model CG+ESS + RL, it is observed that the
full model with RL further improves the perfor-
mance of CG+ESS on all evaluation metrics,
which demonstrates the effectiveness of RL in Ci
composition. A possible explanation can be elab-
orated as follows. With the modeling of format,
rhyme, and diversity rewards through RL, the full7224ModelsDiversity Format Rhyme
MA-U MI-U MA-B MI-B MA MI MA MI
CG+ESS+ RL 74.36 3.13 98.73 51.45 99.92 99.89 63.47 63.16
– Format (r) 73.05 2.31 97.77 45.05 99.77 99.73 62.51 62.43
– Rhyme (r) 73.91 2.20 97.86 45.49 99.82 99.80 62.13 62.40
– Uni-gram diversity ( r)71.71 2.14 97.65 42.26 99.85 99.81 62.44 62.19
– Bi-gram diversity ( r) 71.73 2.16 97.43 41.50 99.79 99.76 62.48 62.90
model is able to learn to force the generation pro-
cess to satisfy the restrictions (e.g., format and
rhyme constraints) of the given tune pattern and
thus achieves higher performance than CiGen +
ESSthat does not target to such restrictions.
Third, our full model CG+ESS + RL out-
performs SongNet (Li et al., 2020) (which uses an
autoregressive approach for Ci generation) with
respect to all evaluation metrics. This observa-
tion not only demonstrates the effectiveness of our
proposed approach, but also indicates that non-
autoregressive models are also plausible solutions
for composing Ci and format-speciﬁc text genres.
In addition, beneﬁting from the nature of non-
autoregressive approach (i.e., the model is able
to generate all characters at the same time), our
models are able to generate Ci around 100 times
faster than SongNet, where the simplest CGis
the fastest one that is able to generate around 43
Ci in each second. This comparison demonstrates
the superior efﬁciency of applying synchronous
procedure to Ci composition and shows its great
potential to be applied to real applications that in
similar scenario and require high generation speed.
4.2 Effect of Different Rewards
In our full model with RL (i.e., “ CG+ESS
+ RL”), we compute the ﬁnal reward rfor RL by
averaging the rewards from format (i.e., r), rhyme(i.e.,r), uni-gram diversity (i.e., r), and bi-gram
diversity (i.e., r) (see Eq. (10)). To further in-
vestigate the effect of the designed rewards, we
perform ablation study where one of the four types
of reward is ablated. Table 4 reports the experimen-
tal results, where the best and the worst result for
each evaluation metric are highlighted in boldface
and underlines, respectively. There are several ob-
servations. First, overall, the ablation of any one
of the reward types hurts model performance on
all metrics, which demonstrates that all types of
rewards contribute to the quality of Ci composition.
Second, the ablation of a particular type of reward
would strongly hurt the model performance on its
corresponding metric. For example, the worst per-
formance on rhyme evaluation metrics is achieved
when rhyme reward (i.e., r) is ablated. So that
each reward does conﬁrm its value in helping gener-
ate better Ci from different aspects. To summarize,
our observations demonstrate the effectiveness of
the full model with RL to learn from all types of
reward and thus to generate Ci satisfying different
types of evaluation metrics.
4.3 Human Evaluation
Following previous studies (Li et al., 2018; He
et al., 2012; Zhang and Lapata, 2014; Wang et al.,
2016b; Yu et al., 2017), we further conduct human
evaluation on those Ci generated from different
models (i.e. CG,CG+ESS, and CG+
ESS + RL), where four different metrics (namely,
consistency ,ﬂuency ,meaning , and poeticness ) are
considered. To explain, consistency evaluates the
theme consistence; ﬂuency measures the grammati-
cal correctness; meaning stands for the meaningful-
ness of the content; and poeticness exams whether
the Ci follows the attributes of poetry. We randomly
sample 50 Ci from the test set and invite ﬁve human
evaluators who are familiar with Chinese poetry to
score each Ci based on the aforementioned four7225Ci Translation
Tune Pattern 捣练子 Daolianzi Theme
Reference斜月下，北风前。
万杵千砧捣欲穿。
不为捣衣勤不睡，
破除今夜夜如年。Under the falling moon, (a lady) faces the north wind. With
thousands of times the pestle hit the clothes (to make the
clothes ﬂatten), the plank is about to be broken. (The lady)
is awake not for ﬂatting the clothes. Not just tonight, every
night is like a year to her (by deadly missing her husband).
CG南岳顶，日落西。
四面青峰入层云。
细水流，猿猴啼。
满林惊鸟振天去。On the top of the south mountain, (I) see the west sunset. The
green peaks from all sides enter the layers of clouds. The
creek is ﬂowing; the monkeys are chirping. All the frightened
birds in the woods are ﬂying into the sky.
CG+ESS春风起，雨还晴。
一树青梅入眼帘。
莫道春踪无寻处。
落红飞絮总含情。The spring breeze is blowing, the rainy days are clearing.
The green plums on the tree comes into view. Please do not
say there is nowhere to look for signs of spring. The falling
ﬂowers and catkins always deliver silent affection.
CG+ESS
+ RL山脚下，溪水边。
满园飞花梦留年。
独依阑干不能寐。
一帘疏影欲成仙。(I am standing) at the foot of a mountain, by the stream. (I)
see the ﬂying ﬂowers in the entire garden which reminds me
of the passing years. (I) rely on the railing alone and cannot
fall asleep. Seeing a sparse scene of shadows, I feel like I
am about to become a fairy.
metrics, where the score is one of {1,2,3}with
1forpoor ,2formedium , and 3forgood . The
evaluation is conducted in a blind review manner,
where evaluators are provided with the Ci gener-
ated from different models but they cannot locate
which model generates the given Ci. We report
the scores for all evaluation metrics as well as the
overall average score ( A.) in Table 5. Similar to
the observations from Table 3, in Table 5, CG
+ESS with essential word guided generation pro-
cess achieves better performance than CGand
CG+ESS+ RL further improves CG+ESS
with the help of RL. To conclude, human evalua-
tion not only reveals the capability of the proposed
CG, but also further conﬁrms the effectiveness
ofESSwords and RL for Ci composition.
4.4 Case Study
To qualitatively investigate different models, espe-
cially the effect of ESSwords and RL, we conduct
a case study with an example input tune pattern
“捣练子” (Daolianzi Theme ). Figure 3 illustrates
a reference Ci and the generated ones from three
different models (i.e., CG,CG+ESS, and
CG+ESS+ RL) given the tune pattern, wherethe rhyme characters required by the tune pattern
are underlined in the reference and the generated
Ci; the ESS words in the reference (automatically
labeled) and in the Ci generated by CG+ESS
andCG+ESS + RL are highlighted in blue
color. It is observed that CGgenerates an in-
ferior output that is irregular in terms of rhythm
where the underlined rhyming characters (i.e., “ 西”,
“云”, “去”) of the generated clauses do not follow
the same vowels. When ESS words are used,
CG+ESSis able to beneﬁt from the ESSwords
and thus generates most of the ESS words at the
expected positions. However, we notice that the
Ci generated by CG+ESS is still not perfect:
the underlined rhyming character “ 晴” and “情” in
the ﬁrst and fourth clause are homophones, which
is normally avoided in poem and Ci composition
but using characters with different pronunciation
while sharing the same rhyme. When RL is applied,
compared with CG+ESS,CG+ESS+ RL7226is able to generate more coherence and consistent
content, having better artistic conception and diver-
siﬁed in generating rhyming characters as well as
theESS words, with their positions matching the
ones in the reference. generate high-quality Ci.
5 Related Work
Chinese Ci generation is generally considered as
one type of Chinese archaic style text generation
tasks. In addition to Ci generation, such tasks also
include couplet and classical poetry generation,
where they have different concerns regarding to
particular restrictions. Speciﬁcally, couplet gener-
ation (Jiang and Zhou, 2008; Zhang et al., 2018;
Fan et al., 2019; Gao et al., 2021; Song, 2022) is
a strictly conditioned text generation task where
the generated text (subsequent clause) has to cor-
respond to the input text (antecedent clause) in
almost all aspects, such as rhyme, length, syntactic
and semantic correspondence, etc. Classical poetry
generation (Zhang and Lapata, 2014; Zhang et al.,
2017; Li et al., 2018; Yang et al., 2018b, 2019;
Chen et al., 2019; Deng et al., 2020) normally fo-
cuses on unconditioned text generation with limited
format constraints, where there are typically two
poem types, i.e., ﬁve-character and seven-character
quatrain. Different from the two tasks, Ci gener-
ation is more ﬂexible than couplet but less than
poem, in terms of using tune patterns for restric-
tion. To the best of our knowledge, there are 871
different types of tune patterns with each having
its own format requirements. In performing Ci
generation, studies are much less than that for cou-
plet and poem generation, recent ones (Wang et al.,
2016a; Li et al., 2020; Luo et al., 2021) leverage
deep learning based models and achieve outstand-
ing performance, where most of them regard the
task as a conventional sequence-to-sequence task
and use autoregressive approaches. To further im-
prove the task, there are studies applying enhanced
modules such as attentions (Wang et al., 2016a)
and pre-training language models (Li et al., 2020).
Compared to previous studies based on deep neu-
ral networks, this work takes the advantage of the
properties of Ci (i.e., the format is determined once
the tune pattern is given and different parts of Ci
should stick to a particular topic) and provides an
alternative solution for Ci generation through a non-
autoregressive method, which allows our model to
generate Ci efﬁciently. Particularly, the generation
process guided by essential words and RL withcarefully designed rewards further facilitate the ex-
plicit accommodation of the rigid constraints for
Ci, leading to better results in all evaluations.
6 Conclusion
In this paper, we propose a non-autoregressive
model named CGfor Ci composition, which
is further enhanced by an essential word guided
generation process and RL. Speciﬁcally, our model
ﬁrstly generates the ESSwords that convey impor-
tant meaning or topic of Ci and then use these ESS
words to complement the generation of the entire
Ci. In addition, we design a set of RL rewards
based on format, rhyme, and diversity (including
uni-grams and bi-grams based measures) to en-
hance the model by further accommodating the
constraints from the tune pattern, for the purpose
of solving the problem that normal loss functions
for conventional supervised/unsupervised methods
cannot be applied to such constraints. Experimental
results and analyses on a Song Ci dataset conﬁrm
the validity of our proposed model, with its eval-
uation outperforms strong baselines and previous
studies with respect to different evaluation metrics.
Moreover, owing to the non-autoregressive char-
acteristic, the inference speed of our model also
shows its great superiority over the autoregressive
ones. Therefore, the effectiveness and efﬁciency in-
dicates that our model design has its potential to be
implemented to similar text generation scenarios.
References722772287229