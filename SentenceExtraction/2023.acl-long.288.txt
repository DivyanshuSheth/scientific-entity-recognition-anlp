
Zhaowei Wang, Quyet V . Do, Hongming Zhang, Jiayao Zhang,
Weiqi Wang, Tianqing Fang, Yangqiu Song, Ginny Y. Wong, & Simon SeeDepartment of Computer Science and Engineering, HKUSTTencent AI Lab, Bellevue, USAUniversity of PennsylvaniaNVIDIA AI Technology Center (NV AITC), NVIDIA, Santa Clara, USA
{zwanggy,yqsong}@cse.ust.hk, {gwong,ssee}@nvidia.com
Abstract
Detecting commonsense causal relations (cau-
sation) between events has long been an es-
sential yet challenging task. Given that events
are complicated, an event may have different
causes under various contexts. Thus, exploit-
ing context plays an essential role in detecting
causal relations. Meanwhile, previous works
about commonsense causation only consider
two events and ignore their context, simplifying
the task formulation. This paper proposes a new
task to detect commonsense causation between
two events in an event sequence (i.e., context),
called contextualized commonsense causal rea-
soning. We also design a zero-shot frame-
work: COLA (Contextualized C ommonsense
Causa lity Re asoner) to solve the task from the
causal inference perspective. This framework
obtains rich incidental supervision from tem-
porality and balances covariates from multiple
timestamps to remove confounding effects. Our
extensive experiments show that COLAcan
detect commonsense causality more accurately
than baselines.
1 Introduction
Commonsense Causal Reasoning (CCR) aims at
identifying plausible causes and effects of events
in natural language that are typically reasonable by
an average person (Zhang et al., 2022c). To solve
the task, existing efforts devoted by the community
mainly rely on language models wholeheartedly
with supervised learning approaches (Stali ¯unait ˙e
et al., 2021; Sap et al., 2019; Tamborrino et al.,
2020; He et al., 2020; Raffel et al., 2020). Those
ingenious engineering works have brought signifi-
cant progress in recent years. However, recent stud-
ies (Kavumba et al., 2019; Han and Wang, 2021)
found that pure engineering designs are inadequate
to seize commonsense causation, as language mod-Figure 1: An illustration of leveraging context to con-
duct commonsense causal reasoning. Both causes could
be plausible under different contexts, while only the
frequent one (i.e., Cause 1 ) is plausible without context.
els tend to reach higher scores by exploiting super-
ficial artifacts in data.
Recently, Zhang et al. (2022c) first studied grasp-
ing commonsense causation from the causal infer-
ence perspective, by drawing analogies between ob-
servational studies (Cochran and Chambers, 1965;
Rosenbaum, 2002) and natural languages (Zhang
and Zhang, 2021). The proposed framework ROCK
achieves good potential for the zero-shot CCR task
(e.g., COPA by Gordon et al. (2012)). However,
Zhang et al. (2022c) only focuses on the common-
sense causation between a pair of events without
specifying context. Given that events are com-
plex (Chen et al., 2021), an event may have differ-
ent causes under different contexts (Mostafazadeh
et al., 2020). Thus, it is necessary to utilize con-
text when detecting commonsense causation, such
as other events related to given ones. Missing a
clear and specific context simplifies commonsense
causal knowledge and hinders models from detect-
ing commonsense causal relations more accurately.
For example, as shown in Figure 1, the frequent
cause of “Emma made a steak in the kitchen.” is
“Emma felt hungry.” However, the cause also could5253be “Emma was doing her job” if “Emma is a chef
at a steakhouse.” Without the context of Emma’s
job, models cannot distinguish those two causes
and may return to the frequent one.
To involve context when detecting commonsense
causation, we propose a new task to detect causes
between two events in an event sequence, called
Contextualized Commonsense Causal Reasoning
(Contextualized CCR). In this task, models are
asked to detect commonsense causal relations be-
tween two given events enclosed in an event se-
quence. Other events in the event sequence can
provide a clear and specific definition of the cur-
rent context, helping models to capture common-
sense causation more accurately. In fact, we find
that contextualized CCR is a non-trivial task. Di-
rectly applying the framework ROCK (Zhang et al.,
2022c) cannot achieve competitive performance on
the contextualized CCR since it cannot integrate
context information.
We propose the framework COLA , which in-
corporates contextual information from an event
sequence, to solve the Contextualized CCR. Our
framework adopts the potential-outcomes frame-
work (Rubin, 1974; Rosenbaum, 2002; Rubin,
2005) to estimate the causal estimand ∆defined as
a type of “ average treatment effect ” (ATE), which
measures the change in the likelihood of E’s oc-
currence when intervening E(denoted by ¬E) as
∆ =P(E≺E)−P(¬E≺E), (1)
where P(·)can be estimated with a pre-trained
language model, such as a masked language
model (Devlin et al., 2018). The magnitude of
average treatment effect informs the strength of
E’s effect on E, and its sign indicates the direc-
tion of the effect. For instance, ∆≈1means
Ebecomes more prone to occur due to the oc-
currences of E. In an ideal world (e.g., Eand
Eon any study unit occur completely randomly),
a plugging-in estimator in Equation (1) suffices
for detecting commonsense causation. Neverthe-
less, spurious correlations introduced by pervasive
confounding co-occurrences need to be eliminated
for an unbiased estimation of the causal estimand.
This can be done by balancing events that precede
E, orcovariates . To incorporate context, we de-
sign a mechanism to sample diversified covariates
from multiple timestamps and use temporal propen-
sity(Zhang et al., 2022c) for balancing.
We annotated commonsense causal relations be-
tween two events (~1.3k examples) within eventsequences from ROCStories (Mostafazadeh et al.,
2016) to benchmark our proposed contextualized
CCR task. We conduct extensive experiments with
multiple pre-trained language models, showing that
COLA can detect cause-and-effect relations more
accurately than competitive baselines by a large
margin. Our experiments also show that temporal-
ity is essential in our framework but not sufficient
to detect commonsense causation without covari-
ates being appropriately balanced.
2 Background and Related Works
Understanding events and relations between them
have long been a challenging NLP task (Chen
et al., 2021). The community has dedicated many
works to studying various event-centric tasks, in-
cluding event relation reasoning (Ning et al., 2018;
Zhou et al., 2021; Wang et al., 2020), event extrac-
tion (Huang et al., 2018; Lai et al., 2020; Zhang
et al., 2022b; Lin et al., 2023), event-centric KG
construction (Zhang et al., 2020b, 2022a), and
many others (Chambers and Jurafsky, 2008; Chen
et al., 2020; Jin et al., 2022; Wang et al., 2022b).
Among them, there are a few lines of work that are
most related to our work:
Commonsense Causal Reasoning Since our
work is about Contextualized CCR, we first dis-
cuss related works about commonsense causal rea-
soning. Existing commonsense causal reasoning
approaches are typically categorized under the gen-
eral topic of commonsense reasoning (Rashkin
et al., 2018; Sap et al., 2020). Most previous
works depend on language models. Remarkable
progress in CCR mainly comes from dataset aug-
mentation, training procedure design, and external
knowledge (Stali ¯unait ˙e et al., 2021; Sap et al., 2019;
Shwartz et al., 2020; Tamborrino et al., 2020; Iter
et al., 2020). Studies (Kavumba et al., 2019; Han
and Wang, 2021) show that language models ex-
ploit superficial artifacts to achieve suspicious high
performance.
Causal event detection (Mirza and Tonelli, 2014;
Mirza et al., 2014) forms another line of work per-
tinent to CCR. The task aims to detect causal re-
lations in documents, where various methods are
proposed (Chang and Choi, 2005; Do et al., 2011;
Ning et al., 2019). However, those works consider
verbal (e.g., “attack”) or nominal predicates (e.g.,
“explosion”) as events, oversimplifying the rela-
tion detection task. In this paper, we study events
expressed in free text, facing a more challenging5254setup but being closer to real applications.
Narrative-related Tasks Since Contextualized
CCR is primarily about chains of events, our work
is inspired by earlier research that deals with nar-
ratives and scripts (Chambers and Jurafsky, 2008;
Granroth-Wilding and Clark, 2016; Mostafazadeh
et al., 2016; Bhagavatula et al., 2019; Zhang et al.,
2020a). In contrast, our work aims to identify
causal relations in a chain of events.
Methodologies of Causal Inference Zhang and
Zhang (2021) provided the first study to solve the
CCR task from the causal inference perspective.
The human population studies have scrutinized
extensively the causal inference, which identifies
causal relations from ubiquitous associations, in-
cluding biomedical research, agriculture, epidemi-
ology, and economics (Fisher, 1958; Imbens and
Rubin, 2015; Giannarakis et al., 2022; Rosenbaum,
2002; Cochran and Chambers, 1965), where re-
searchers usually use the potential-outcomes frame-
work (Splawa-Neyman et al., 1990; Rubin, 1974;
Holland, 1986), graphical and structural equation
models (Robins, 1986; Pearl, 1995; Heckman,
2005), and Granger causality (Granger, 1969).
Recent studies have drawn causal inferences on
textual data with the help of powerful pre-trained
language models (Kang et al., 2017; Keith et al.,
2020; Feder et al., 2022). Concurrently, causal in-
ference can improve the robustness and fairness of
NLP models (Feder et al., 2022) or boost perfor-
mance on downstream tasks (Ghosal et al., 2021;
Zheng et al., 2022; Alabdulkarim et al., 2021; Wang
et al., 2022a).
3 Problem Formulation
Notation We use sans−serif fonts to represent
an event, such as Ein Figure 2, where the sub-
script imeans the i-th event in a sequence. Si-
multaneously, uppercase serif letters denote indi-
cators of whether the corresponding event occurs:
E=1{Eoccurs}, and a lowercase serif letter
means the realizations of this indicator: e=
1{Eoccurs to the j-th study unit }. We introduce
the point process to more clearly describe the order
ofa pair of events: E(t)witht∈ {0,1}(e.g., past
versus present), so that E(0)andE(1)means
thatEhappens before E. We also use E≺Eto
indicate that Eoccurs before Efor simplicity. We
writeP(E≺E) =P(E(0), E(1)).Task Description We articulate the Contextual-
ized CCR as a tweaked form of the binary classi-
fication problem. Specifically, we provide models
with an event sequence of nevents: E,E, . . . , E.
Models need to find the top- kevents in this se-
quence that more plausibly have commonsense
causal relations with the last event E, where kin-
dicates the number of positive labels in the ground
truth. Then, models need to predict the common-
sense causal relation between each event pair ( E,
E) as a positive/negative one. The strength of
causal relations between EandEcan be ex-
pressed with average treatment effect as:
∆=P(E≺E)−P(¬E≺E).(2)
4 Theoretical Mechanism of COLA
As discussed in Section 1, we articulate the Con-
textualized CCR problem as the estimation of the
causal estimand ∆, which we model as the change
of temporal likelihood with contexts controlled . We
adopt the potential-outcomes framework to design
COLA to eliminate potential confounding effects
due to co-occurrences of events when estimating
the causal estimand from data. In this section, we
first clarify all essential concepts in the theoretical
mechanism of COLA one by one, including study
unit,intervention ,covariate , and propensity , by
drawing analogies between the underlying causal
mechanisms in natural languages with that in hu-
man population research. We then describe the
implementation of each component in Section 5.
4.1 The Analogy and Study Unit
Motivated by Zhang et al. (2022c), we draw the
analogy between human subjects and semantic
meanings through the following process: assuming
that every human subject kept a textbook recording
each event (s)he has experienced, we can then treat
each textbook (in natural language) as a study unit
and infer the temporal relationships between events
from it. In this analogy, we clearly understand the
study unit in semantic meanings.
Then, we can formulate contextualized CCR
with concepts from the potential-outcome frame-
work. Given two events EandEfrom an event
sequence E,E, . . . , E, where we assume that
Erepresents the event that the j-th study unit
experienced at the timestamp iwhen Eis sup-
posed to occur. Then for each unit j, we can define
the treatment assignment as E=1{E=E},
realizations of covariates as x= (x)for5255
x=1{X≺E}, and two potential-outcomes
as /braceleftigg
r=1{E≺E},
r=1{E≺E}.(3)
When the j-th unit receives the treatment assign-
ment E, the hypothetical scenario is denoted by
E, which describes what if the assign-
ment were flipped. Clearly, we can only observe
either rorr, but not both of them. We can
rewrite the causal estimand ∆in Equation (2) ex-
actly as an average treatment effect by averaging
over the unit index:
∆=E[r−r]
≡P(E≺E)−P(¬E≺E).(4)
The above formulation naturally embodies the tem-
poral nature of covariates (Rubin, 2005), which,
by definition, are pretreatments that precede treat-
ments.
4.2 Intervention Beyond Negation
In human population studies, the generally ac-
cepted stable unit treatment value assumption (Ru-
bin, 1980) ensures only one type of non-treatment
(usually negation) for each study unit. As events
are complicated, we would interpret intervention
(manipulation) of semantic meanings in a broader
sense. Take E“Emma felt hungry” from Figure 2
as an example. While “Emma didn’t feel hungry”
is the most direct intervention, it is nonetheless too
restrictive: Emma may have felt happy; maybe Al-
ice is the one who felt hungry, instead of Emma.
Consequently, interventions in our framework are
interpreted much broader as any event that could
result in a plausible counterfactual of the outcome.
We use Ato represent all possible interventions of
an event E.4.3 Balancing Covariates and Comparable
Study Units
We have discussed that the plugging-in estimator
in Equation (1) suffers from biases due to potential
confounders. One mitigation strategy is properly
balancing the covariates (Rubin, 2005), namely
events that occur before E, which ensures that
covariates of untreated study units are compara-
ble to those of treated ones. Consider the vaccine
trial as an example; one needs to ensure that the
health conditions (covariates) in the control group
(not administered vaccines) are comparable to the
treated group (administered vaccines). As such, we
rewrite the causal estimand ∆in Equation (2) as
expectations conditional on the covariates xamong
comparable study units:
E[P(E≺E|x)−P(¬E≺E|x)],(5)
provided that the treatment assignment is strongly
ignorable with respect to potential outcomes (i.e.,
randr) according to the strong ignorability
assumption.
The strong ignorability assumption is essential
in causal inference. Simply, it means that given a
set of covariates, the treatment assignment among
study units can be viewed as “random” (or “ig-
norable”) with respect to potential outcomes (see,
e.g., Rosenbaum (2002); Rubin (2005) for textbook
treatments and Zhang et al. (2022c) for more dis-
cussions on this assumption in CCR).
4.4 Matching Temporal Propensities
Directly estimating Equation (5) may face the issue
of data sparsity since we may sample multiple co-
variates, and combinations of their values grow ex-
ponentially. There are various methods to mitigate
this issue in balancing covariates, including assign-
ment modeling, outcome modeling, and doubly-5256robust estimations (Rubin, 2005), among which
we base our method on propensity score matching.
It is a simple and effective method that is widely
used in observational studies (Rosenbaum and Ru-
bin, 1983), which matches the propensity scores of
study units to balance covariates. The propensity
score is defined as p(x) =P(E(1) = 1 |x(0)),
which represents the probability of Etaking place
conditioning on covariates x. Since it is unclear
how to pack an unordered set of covariates (events)
into a sequential input, Zhang et al. (2022c) pro-
posed to use a relaxed notion of temporal propen-
sity vector, defined as the vector of probabilities of
Ehappening conditional on each covariate x∈x:
q(x) =q(x;E) = (P(E(1) = 1 |x(0))).
(6)
Hence, we can rewrite the conditional expectation
in Equation (5) in the form of matching temporal
propensity vectors for some fixed threshold ϵ, given
below:
/braceleftiggˆ∆=f(E,E)−/summationtextf(A,E),
A:=
,
(7)
where f(E,E)is an estimate for P(E≺E)
produced by a language model.
5 The COLA Framework
After establishing the theoretical mechanism for
our framework COLA , we describe the implemen-
tation of each component of COLA in this sec-
tion. Generally, since events are in free-text form
in our task, pre-trained language models play a
central role in our framework. Given that LMs
are pre-trained on an enormous amount of textual
data (Gao et al., 2020; Raffel et al., 2020), it is
sensible to suppose that those LMs would emulate
the responses of an average reasonable person.
Specifically, our framework COLA takes two
events EandEfrom a sequence E,E, . . . , E
as input. As shown in Figure 2, our framework
COLA contains four steps: (1) a multistamp covari-
ate sampler samples a set Xof covariates. (2) an
intervention generator generates a set Aof inter-
ventions. (3) A score estimator builds temporal
propensity vectors and selects a matched subset
Aout ofA, by estimating the temporality with a
temporal predictor. (4) Eventually, the same score
estimator computes ˆ∆according to Equation (7).
Multistamp Covariate Sampler Our multi-
stamp covariate sampler is based on GPT-J(6b) (Wang and Komatsuzaki, 2021). For an in-
put event E, we add “Before that,” at the end
to build “ EBefore that,” as the prompt template.
For the i-th event in a sequence, we first sam-
ple a covariate set X, which contains events be-
foreE. To diversify covariates, we also sample
events before E,E, . . . , Eseparately, forming
X,X, . . . ,X. Those events are also before E
and can serve as covariates due to the transitivity
of the temporal relation. We evenly merge covari-
ates before each timestamp to construct the final
covariate set:
X=∪X. (8)
Union vs. Intersection While the aforemen-
tioned method takes the union of events sampled
according to the left-side context of E, another in-
tuitive approach is to take the intersection of events
sampled according to multiple timestamps in the
right-side context. In this way, we can collect co-
variates that happen before all of E,E, . . . , E,
that is, X=∩X. We discuss the experimental
results of these two methods in Section 7.3 and
found taking union works better, which will be the
default in the remaining sections.
Intervention Generator This component gen-
erates a set Aof interventions as discussed in
Section 4.2. There are a variety of related
works about generating interventions (counter-
factuals) of an event (Gardner et al., 2020; Qin
et al., 2019; Ribeiro et al., 2020) and we choose
PolyJuice (Wu et al., 2021) in our framework
owing to its non-task-specific training objective.
PolyJuice generates interventions by masking
some phrases individually and filling in masks
with a fine-tuned GPT2. Then, we apply the se-
mantic role labeling (SRL) tool provided by Al-
lenNLP (Gardner et al., 2018) to extract the verb V
and two arguments ARG0 andARG1 as phrases to be
manipulated (see Appendix A.2 for more details).
Temporal Predictor We prompt a masked lan-
guage model to estimate the temporal relation
scores between two given events EandE. The
prompt template “ E<MASK> E” predicts scores
f(E,E)andf(E,E)for the output tokens
before andafter . Similarly, we can obtain a
reversed estimation by inputting “ E<MASK> E.”
Final temporal score faverages scores from5257both directions: f(E,E) =(f(E,E) +
f(E,E))
Our temporal predictor needs to be fine-tuned on
a temporal relation corpus. Directly applying a pre-
trained LM encounter the problem of low coverage,
where the tokens before andafter cannot be
found in the top- kprompted tokens (even k= 30 ).
Thus, we fine-tuned masked language models to
predict the masked connectives in a prompt learn-
ing setting. Intuitively, temporal relations exist be-
tween each pair of adjacent events in a chronologi-
cally ordered event sequence. Assuming an event
sequence contains two adjacent events E,E,
we then can create an example Ebefore E
and an symmetric example Eafter E. We
also construct negative samples by replacing Eor
Ewith a randomly sampled event from other
sequences. Those negative examples can teach
models when no temporal relation exists. While
we mask before orafter in a positive exam-
ple for models to predict, a special token [none]
should be prompted for negative examples. Then,
the cross-entropy loss is used to optimize the tem-
poral predictor. We call this fine-tuning process
temporal fine-tuning . More details about the tem-
poral relation dataset and fine-tuning process are
shown in Appendix A.1.
Score Estimator With the temporal predictor, we
can estimate P(X≺A)for all covariates X∈ X
and interventions A∈ A :P(X(0), A(1)) =
P(X≺A) = f(X,A). We also need to esti-
mateP(X(0)) to compute conditional probabilities
P(A(1) = 1 |X(0)) in temporal propensity vectors
q(x;A). As all covariates Xare events preceding
Esampled by GPT-J, there is an implicit condi-
tioning on E. Thus, we can approximately get
P(X(0))≈f(X,E)(see Appendix B for more
details). Then, temporal propensity vectors are
computed as
q(x;A) =/parenleftbiggP(X(0), A(1))
P(X(0))/parenrightbigg. (9)
Finally, the score estimator computes ˆ∆in Equa-
tion (7). We also test normalization methods in
Appendix E and observe that some of those nor-
malization methods can benefit our framework.
6 Experiment
We conduct extensive experiments and compare
COLA with a wide selection of baselines.6.1 Dataset
Since our work is the first attempt to study Contex-
tualized CCR, we carried out human annotation on
Amazon Mechanical Turk. We randomly sampled
event sequences from ROCStories (Mostafazadeh
et al., 2016), where each sequence contains five
chronologically ordered events. Workers are asked
to annotate whether an event causes the last event
in a sequence. There are two qualification tests to
choose workers to maintain rigorous quality con-
trol. See more details in Appendix D.
Eventually, we collected a dataset containing
1,360 event pairs, called Choice of Plausible Event
in Sequence (COPES ). We equally divide them into
a validation set and a testing set.
6.2 Evaluation Metric
We calculate accuracy, F1-score, and Macro F1-
score between predicted labels and ground truth
labels, to automatically evaluate all models on our
dataset. Notice that our task definition provides the
number of positive events in a sequence, so that
recall, precision, and F1-score are the same.
6.3 Baseline Methods
We compare our framework to three baselines:
CLM Perplexity An intuitive solution to the con-
textualized CCR task would be computing perplex-
ity scores for each pair of events with a causal
language model (CLM). An event pair ( E,E)
within a sequence E, E, . . . , E(nis sequence
length) is converted into full-text input with the
prompt template: “If E, E, . . . , E,Ebecause
E”. The causal language models we tested are
GPT2, GPT2-medium/large/XL (Radford et al.,
2019), and GPT-J (Wang and Komatsuzaki, 2021).
Cloze Prompt Score This baseline proposed
by Tamborrino et al. (2020) concatenates two
events ( E,E) into full-text input. Then, it
masks and tries to recover each token with a
masked language model. It averages log-likelihood
over every token as the final score of two events.
The prompt used is the same as CLM Per-
plexity . Multiple masked language models are
tested: BERT-base/large (Devlin et al., 2018),
RoBERTa-base/large (Liu et al., 2019), DeBERTa-
base/large (He et al., 2020).
ROCK This baseline is a causal inference frame-
work (Zhang et al., 2022c) that draws analogies
between human subjects and natural language. We5258
test different language models for the temporal
predictor: BERT-base/large, RoBERTa-base/large,
and DeBERTa-base/large.
7 Main Evaluation
We provide results in Table 1 for baselines and
COLA with the temporal predictor based on differ-
ent language models. In general, COLA can detect
commonsense causal relations more accurately, out-
performing all baseline models by a large margin.
Our framework COLA based on DeBERTa-large
and DeBERTa-base (also BERT-large) achieves the
best performance on the validation and testing set,
respectively. Also, changing language models of
the temporal predictor in COLA only involves a
small fluctuation in performance, showing that our
framework is robust to underlying language mod-
els.
Another observation is that CLM Perplexity
and ClozePromptScore can achieve performance
higher than the random result. This manifests that
pre-trained language models with commonly used
pre-training objectives can capture commonsense
causal relations to some extent.7.1 Ablation Study
In this section, we conduct four ablation exper-
iments to demonstrate that our causal inference-
motivated framework can mitigate spurious corre-
lations between events and boost performance.
Temporal Propensity Matching The first three
ablation experiments prove the effectiveness of tem-
poral propensity matching. Here, we separately
remove three modules in our framework: (i) We
drop the multistamp covariate sampler and sam-
ple covariates only based on the last timestamp
(⋄w/o Multi Step). This experiment verifies the
benefit of utilizing context to detect commonsense
causality. (ii) We remove all interventions ( ⋄w/o
Inter) and use temporal precedence as causation:
ˆ∆=P(E≺E), equivalent to ϵ= 0 in Equa-
tion (7). (iii) Covariates are removed ( ⋄w/o Cov)
so that interventions are not adjusted. This unad-
justed score keeps all sampled interventions, equiv-
alent to ϵ= 1in Equation (7).
From the results in Table 2, we observe that bal-
anced estimand ˆ∆achieve better performances,
showing that multiple timestamp sampling, treat-5259
ment effect, and balancing covariates play essential
roles in detecting commonsense causation accu-
rately. Removing any of the three modules will
result in sheer drops in all metrics. These experi-
ments imply that temporal relation is vital in Con-
textualized CCR, but it is still insufficient due to
spurious correlations. Thus, we need to measure
average treatment effect with balancing covariates.
Temporal Predictor We also ablate the temporal
predictor ( ⋄w/o Temp) to verify the effectiveness
oftemporal fine-tuning (in Section 5). Here, we
use pre-trained language models and increase kto
30 to mitigate the problem of low coverage.
As shown in Table 2, a directly pre-trained lan-
guage model without fine-tuning cannot perform
well. We conclude that pre-trained language mod-
els do not have sufficient “temporal awareness” and
temporal fine-tuning is necessary for our frame-
work.
7.2 Rules-of-thumb for Choosing ϵ:
The hyperparameter ϵcontrols the number of inter-
ventions when balancing covariates in Equation (7).
In Figure 3, we can observe that a recommended
range for ϵisϵ∈[0,0.1]. We also list the optimal ϵ
in Appendix A.3. From Table 6, ϵshould be fairly
small within [0.001, 0.015]. Though the best so-
lution relies on how to implement the components
inCOLA and data distribution, our analysis can
provide a good starting point. We also study the ef-
fect of changing another important hyperparameter:
covariate set size N=|X|, in Appendix C.
7.3 Union and Intersection
Our framework COLA samples covariates from
multiple timestamps and take union on them to
get the final covariate set. We also introduce an-
other method to sample covariates preceding all
timestamps after and including E(“intersection”)
in Section 5. Here, we conduct experiments to
discuss the differences between these two meth-
ods. For the “intersection” method, we also use5260
GPT-J to sample covariates with “There are tem-
porally ordered events [ E, E, . . . , E]. Before
all events,” being the prompt template.
As shown in Table 3, the “union” method gets
better performance since it can diversify covariate
sets. It samples covariates conditioned on each
event before Eseparately. Meantime, each co-
variate of the “intersection” method is only condi-
tioned on the same context E, E, . . . , E. We
compute the self-BLEU (Zhu et al., 2018) to eval-
uate the diversity of the generated covariates. The
self-BLEU of the “intersection” method is 66.40%
while that of the “union” method is 41.34%, quanti-
tatively showing that our method can diversify the
covariate set.
7.4 Comparison with ChatGPT
Large language models have shown strong per-
formance on extensive NLP tasks (Radford et al.,
2019; Ouyang et al., 2022). Thus, we compare
our framework with ChatGPT, the latest large lan-
guage model trained using Reinforcement Learning
from Human Feedback (RLHF). To adopt ChatGPT
to our task, we design the prompt template: “Given
a story as a chain of events E, E, . . . , E, which
kevent(s) in the first n−1events more plausibly
cause the last event?” where kis the number of
positive events in the ground truth. We randomly
sample 120 examples within 30 event sequences
from our dataset COPES and manually read pre-
dicted labels from ChatGPT’s answers. We also
test ChatGPT without providing the number k, i.e.,
removing kfrom the prompt.
The experimental result in the selected 120 ex-
amples is shown in Table 4. From the table, we
can find that providing ChatGPT with the number
kdoes not lead to too much change in all met-
rics. (More discussion about this in Appendix F)
Also, our framework COLA achieves better zero-
shot performance than ChatGPT with much fewer
parameters.8 Conclusion
In this paper, we design a new task to consider the
context when detecting commonsense causal rela-
tions. We also crowd-sourced a dataset with strict
quality control to benchmark the task. Our COLA
framework is motivated by the principles of causal
inference and attempts to leverage context infor-
mation. The extensive evaluation demonstrates the
effectiveness of COLA for detecting commonsense
causal relations.
9 Acknowledgement
The authors of this paper were supported by
the NSFC Fund (U20B2053) from the NSFC of
China, the RIF (R6020-19 and R6021-20) and
the GRF (16211520 and 16205322) from RGC
of Hong Kong, the MHKJFS (MHP/001/19) from
ITC of Hong Kong and the National Key R&D
Program of China (2019YFE0198200) with spe-
cial thanks to HKMAAC and CUSBLT. This pa-
per was also supported by the Tencent Rhino-
bird Focused Research Program. We also thank
the support from NVIDIA AI Technology Cen-
ter (NV AITC) and the UGC Research Match-
ing Grants (RMGS20EG01-D, RMGS20CR11,
RMGS20CR12, RMGS20EG19, RMGS20EG21,
RMGS23CR05, RMGS23EG08).5261Limitations
OurCOLA framework is mainly based on pre-
trained language models, such as GPT-J and
PolyJuice . We only utilize the simplest prompt
to sample covariates and interventions. Further
efforts such as prompt engineering are expected
to boost the performance of COLA further. Also,
pre-trained language models can be biased by im-
plicit events and reporting biases in their training
data. Such biases lead the framework to omit some
critical covariates and interventions, hindering our
framework from achieving more accurate detection
of commonsense causal relations. How to account
for this problem of language model remains to be
studied. Last but not least, the temporal propensity
used in our framework is only an approximation of
the exact propensity (Zhang et al., 2022c) since it is
unclear how to pack an unordered set of covariates
into a sequential input for language models. Further
studies are needed to design the exact propensity
and improve performance.
Ethics Statement
This work presents COPES , a free and open dataset
for the research community to study the contex-
tualized CCR problem. Examples in COPES are
collected from ROCStories (Mostafazadeh et al.,
2016), a free and open dataset about anonymized
chains of events. Each chain logically follows ev-
eryday topics and does not involve privacy prob-
lems about any specific entities (e.g., a person or
company). We carried out human annotation on
Amazon Mechanical Turk. Annotators are fairly
paid 1.2 USD for each HIT, which fulfills the mini-
mum wage requirement.References5262526352645265
A Implementation Details
In this appendix, we introduce the implementation
details of every component in our framework COLA .
We conduct all experiments on 8 NVIDIA A100
GPUs. Since our COLA and baselines are zero-shot,
we test each model once and report the results.
Parameter Number We list parameter numbers
of all pre-trained langauge models here. BERT-
base/large, RoBERTa-base/large, and DeBERTa-
base/large have 110M, 340M, 125M, 355M, 100M,
and 350M parameters, respectively. GPT, GPT-
medium/large/XL, and GPT-6b contain 117M,
345M, 774M, 1.5B, and 6B parameters, respec-
tively.
A.1 Temporal Predictor
We fine-tune temporal predictors based on BERT-
base/large, RoBERTa-base/large, and DeBERTa-
base/large for ten epochs. The learning rate is 1e-5,
and the batch size is 256. We sampled 800k exam-
ples (event pairs) from ROCStories (Mostafazadeh
et al., 2016) to build a temporal relation dataset.
The ROCStories dataset contains about 100k tem-
porally ordered event sequences. The proportion of
training, validation, and testing splits of our sam-
pled event pairs are 98:1:1. We show the accuracy
of each fine-tuned temporal predictor on the valida-
tion and testing splits in Table 5.
A.2 Intervention and Covariate
For each event pair, we sample 50 covariates using
GPT-J with a maximum length of generated events
of 15 and a temperature of 0.9. We also sample 50
interventions using PolyJuice with a maximum
length of generated events of 40 and a temperature
of 1.0.
PolyJuice provided various control codes to
manipulate events in various manners. The full
list of control codes is negation ,lexical ,
resemantic ,quantifier ,insert ,
restructure ,shuffle , and delete . We
only use resemantic ,negation ,lexical ,
quantifier ,insert ,delete to generate in-
terventions since restructure andshuffle
do not generate counterfactual events.
A.3 Temporal Propensity Threshold ϵ
In this section, we list the best temporal propensity
threshold ϵfor our framework COLA with the tem-
poral predictor based on different language models
in Table 6.
B Probability Approximation
Our approximation of the probability of a covari-
ateP(X(0)) in Section 5 is a consequence of the
efficiency trade-off. Notice that even though a co-
variate Xis an event preceding Esampled by GPT-
J, it can occur before other events. Strictly, we
must enumerate all possible events E, compute
P(X≺E), and marginalize out E. Here, we as-
sumeP(E(1)|X(0))≈1to compute P(X(0)) ef-
ficiently. We approximately have:
P(X≺E) =P(X(0), E(1))
=P(X(0))P(E(1)|X(0))
≈P(X(0))(10)
C Number of Covariates
We show that balancing covariates are essential
in our framework COLA . Meanwhile, the number5266of covariates also has an impact on performance.
Here we test different covariate set size N=|X|
spanning from 10 to 40, shown in Figure 4 with
various ϵvalues.
We observe that gradually increasing the covari-
ate set size Ncan enhance the performance of our
framework when the ϵis within [0.001, 0.01] as
we recommend in Section 7.2. On the other hand,
adding more covariates may introduce more noise
if we test with a larger ϵ. For example, when ϵ
equals 0.02 and 0.025, increasing covariates only
brings about fluctuations in accuracy.
D Dataset Annotation
Since our work is the first attempt to study Con-
textualized CCR, we carried out human annota-
tion on Amazon Mechanical Turk to construct a
new dataset. In this appendix, we discuss the an-
notation process of the dataset COPES in our pa-
per. We randomly sampled event sequences from
ROCStories (Mostafazadeh et al., 2016), where
each sequence contains five chronologically or-
dered events. Workers are provided with event
sequences and are asked to annotate whether an
event causes the last event in a sequence. Each
human intelligence task (HIT) includes ten poten-
tial (cause ,effect ) event pairs (with corresponding
event sequences), and each pair is labeled by seven
workers. We take the majority vote among seven
votes as the final result for each pair.
We conduct two qualification tests to choose
workers to maintain rigorous quality control. First,
we invited annotators who meet the following con-
ditions to take our qualification examinations: 1)
an approval rate of at least 95% and 2) at least
a thousand approved HITs. In the second round,
a qualification question set including both effort-
less and tricky examples is collected by experts,
namely the authors of this paper, who have a clear
understanding of Contextualized CCR. The experts
annotate 160 event pairs sampled from ROCSto-
ries. An annotator needs to answer a HIT involving
ten questions from the qualification set, and the
answers are compared with the experts’ answers.
An annotator should correctly answer 8 out of 10
questions to pass the second round test. While 307
annotators participated in the second round quali-
fication test, only 29 (9.45%) were selected as our
main round annotators.
Eventually, we collected the dataset containing
human-annotated labels for 1,360 pairs from 340
event sequences ( 1360 = 340 ×4), called Choice
of Plausible Event in Sequence (COPES ). The IAA
score is 61.13% calculated using pairwise agree-
ment proportion, and Fleiss’s κ(Fleiss, 1971) is
0.52. We equally divide them into a validation set
and a testing set (e.g., each contains 680 examples).
We also provide a screenshot of our annotation
platform in Figure 5.
D.1 Dataset Statistics
Here we provide the breakdown of numbers of
causal relations kin all 340 event sequences in Ta-
ble 7. Also, 476 event pairs are positive (with
causal relation), and 884 are negative (without
causal relation).
E Normalization
In this section, we enumerate some methods to
normalize estimand ˆ∆and temporal propensity
vectors in Equation (7).
Direct Matching ( D):Instead of condition
probability in Equation (9), we can directly use the
vectors of temporal relation scores (f(A,X))
as propensity vectors.
Score Simplification ( S):We fine-tune tempo-
ral predictors to prompt before ,after , and
[none] , which might be difficult for smaller
Masked LMs, like BERT-base. When constructing
propensity vectors, we simplify the task to consider
onlybefore ,after by normalizing scores:
f(X,A) =
Propensity Covariate Normalization ( Q):We
also try to normalize temporal relation scores on
the covariate set Xbefore building propensity
vectors: P(X) =f(X,E)//summationtextf(X,E)and
P(X, A) =f(X,A)//summationtextf(X,A).
Co-occurrence Normalization ( C):The fine-
tuned temporal predictor may sometimes still faces5267
the problem of low coverage, causing estimates
f(E,E)andf(A,E)inaccurate in Equation (7).
We set them to (f(E,E) +f(E,E))/2and
(f(A,E) +f(E,A))/2, respectively.
Estimand Normalization ( E):In this method,
estimates f(E,E)andf(A,E)in estimand ˆ∆
in Equation (7) are normalized by f(E,E) +
f(E,E)andf(A,E) +f(E,A), respectively.
We also conduct comprehensive analyses about
removing these normalizations. The results are
shown in Tables 8 to 10. We present drops in every
metric when removing each normalization method.
Some normalization methods cannot improve per-
formance, and we delete those rows from tables.
We observe that some of these normalization meth-
ods, such as Estimand Normalization ( E), can
benefit our framework on Contextualized CCR.
F ChatGPT
In this section, we show and discuss the result of
ChatGPT on COPES . Given the insignificant dif-
ferences in performance between the prompts with
and without the number kin Section 7.4, we fo-
cus on the answers of the prompt with k. We show
three examples, respectively corresponding to three
cases:
1.ChatGPT’s answer is correct (with a good ex-
planation)
2.ChatGPT’s answer is different from the
ground truth answer, but the correctness is
debatable with the explanation from ChatGPT
3. ChatGPT’s answer is incorrect.
Example 1. Which event mainly/directly causes
the last event?
Example 2. Which event mainly/directly causes
the last event?5268
Example 3. Which event mainly/directly causes
the last event?
In most cases, ChatGPT clearly explains its choices.
For example, in the Example 1 , it points out the
positive emotion “... food was great. ” as the un-
derlying fact that causes the last event “... going to
try to go next year. ” (i.e., decision ). Similarly in
theExample 2 , even though ChatGPT’s answer is
different from the ground truth answer, ChatGPT
mentions two key points “... The second event ...
sets up the possibility of ... ” (i.e., potential ) and
“.. the forth event ... establishes that the coupon is
being used ... ” (i.e., action ) that together causes
the last event (i.e., effect ). The reasoning paradigm
implicit in its explanation, e.g emotion →decision
andpotential + action →effect in the abovemen-
tioned two examples, implies the inherent reason-
ing capability of ChatGPT. Nonetheless, there arecases where ChatGPT fails to give a persuasive an-
swer. However, as a foundation model instead of a
task model, ChatGPT’s performance is fair enough.5269ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
In the Section Limitations, we discuss the limitations of our work.
/squareA2. Did you discuss any potential risks of your work?
In the Section Ethics Statement, we discuss the ethical considerations, including privacy problems.
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
Abstract and Section 1
/squareA4. Have you used AI writing assistants when working on this paper?
Left blank.
B/squareDid you use or create scientiﬁc artifacts?
We annotate new datasets based on a previous dataset (Section 6, Appendix B, and Appendix D) and a
new model (Section 4 and Section 5).
/squareB1. Did you cite the creators of artifacts you used?
We cite the previous dataset a few times in Section 6, Appendix B, Appendix D.
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
The artifacts we use is open sourced without a license.
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
Not applicable. No intended use is stated for the existing artifact(s) in our paper.
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
The artifact we use is already anonymized.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
The Section Ethics Statement.
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
Section 6, Appendix B, and Appendix D.
C/squareDid you run computational experiments?
Sections 6 and 7.
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
Section 6 and Appendix B.5270/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
Appendix B.
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
Appendix B.
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
Section 6 and Appendix B.
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
Section 6 and Appendix D.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
Appendix D
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
Section 6, Section Ethics Statement, and Appendix D.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
Section 6 and Appendix D.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
Not applicable. For anonymity.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
Not applicable. For anonymity.5271