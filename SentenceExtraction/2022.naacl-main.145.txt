
Si-An Chen, Jie-Jyun Liu, Tsung-Han Yang, Hsuan-Tien Lin, and Chih-Jen LinNational Taiwan University
{d09922007,htlin,cjlin}@csie.ntu.edu.twASUS Intelligent Cloud Services
{eleven1_liu,henry1_yang}@asus.com
Abstract
The power and the potential of deep learning
models attract many researchers to design ad-
vanced and sophisticated architectures. Never-
theless, the progress is sometimes unreal due to
various possible reasons. In this work, through
an astonishing example we argue that more ef-
forts should be paid to ensure the progress in
developing a new deep learning method. For a
highly inﬂuential multi-label text classiﬁcation
method XML-CNN, we show that the supe-
rior performance claimed in the original paper
was mainly due to some unbelievable coinci-
dences. We re-examine XML-CNN and make
a re-implementation which reveals some con-
tradictory ﬁndings to the claims in the original
paper. Our study suggests suitable baselines
for multi-label text classiﬁcation tasks and con-
ﬁrms that the progress on a new architecture
cannot be conﬁdently justiﬁed without a cau-
tious investigation.
1 Introduction
Deep learning has been a popular research topic in
NLP due to its superior performance. The intrin-
sic structure of deep learning allows researchers
to enhance the model performance by introducing
more complex network architectures. Neverthe-
less, the increasing complexity brings difﬁculties
to ensure the true architectural progress. For exam-
ple, Adhikari et al. (2019) have shown that LSTM
architectures with appropriate regularization are ei-
ther competitive or superior to more recent models.
As another example, Liu et al. (2021) report that
the lack of hyperparameter tuning in an inﬂuential
work (Mullenbach et al., 2018) makes the progress
of subsequent network developments questionable.
Complex architectures are more difﬁcult to train,
involve more hyperparameters, and are riskier to
unintentional implementation. Because new archi-
tectures are usually modiﬁed from previous ones, a
questionable work may make the research progress
unclear. Therefore, re-examining or reproducinginﬂuential architectures are now considered impor-
tant in the community.
In this work, we re-examine XML-CNN (Liu
et al., 2017), an inﬂuential work in extreme multi-
label text classiﬁcation (XMTC), as a case study
to demonstrate the demands of inspecting exist-
ing architectures. XML-CNN has been viewed as
an essential baseline in subsequent works (Peng
et al., 2018; Prabhu et al., 2018; You et al., 2019;
Chang et al., 2020; Adhikari et al., 2019) with more
than hundreds of citations. XML-CNN roots from
Kim-CNN (Kim, 2014), a classical architecture
for multi-class text classiﬁcation. The authors of
XML-CNN proposed several modiﬁcations from
Kim-CNN to accommodate the XMTC task and
empirically claim that all modiﬁcations bring sig-
niﬁcant improvements.
Despite XML-CNN’s popularity, we identiﬁed
two serious implementation issues that make the
original claims uncertain. First, the authors intro-
duced dynamic max-pooling into XML-CNN, but
the implementation is actually far from the intended
formulation. Second, a bug in the experiment code
caused the dimensions of convolution operations
accidentally swapped. The two issues coinciden-
tally make XML-CNN competitive, leading the
authors to illusively claim superiority over Kim-
CNN and usefulness of dynamic max-pooling in
the original paper (Liu et al., 2017).
Our contribution can be summarized as follows.
•We point out, analyze, and correct the issues in
the authors’ XML-CNN implementation. Our
implementation is made public to help the com-
munity build future works on top of the correct
implementation
•We re-examine the claims about XML-CNN. Our
results demonstrate that the progress from Kim-
CNN to XML-CNN may not be as signiﬁcant as
claimed in Liu et al. (2017), and again conﬁrm
that careful attention is needed on ensuring true
architectural progress.1987•Our investigation suggests that instead of XML-
CNN, Kim-CNN or a simpler variant of XML-
CNN should be considered as a baseline in
XMTC tasks.
The paper is organized as follows: in Section 2,
we introduce Kim-CNN, XML-CNN, and their dif-
ferences. We conduct an investigation on XML-
CNN in Section 3. The investigation includes in-
spection of the authors’ code and our analysis on
why it coincidentally works. We then conduct a fair
and thorough comparison between Kim-CNN and
XML-CNN in Section 4. Finally, we conclude
this work in Section 5. Supplementary materi-
als and programs used for experiments are avail-
able at https://www.csie.ntu.edu.tw/
~cjlin/papers/xmlcnn/ .
2 XML-CNN: CNN for Multi-Label Text
Classiﬁcation
For multi-label text classiﬁcation, each instance
is ann-word document that is associated with a
subset ofLpossible categories. The relationship
between the document and the categories can be
modeled by a convolutional neural network (CNN),
as pioneered for multi-class text classiﬁcation by
Kim-CNN (Kim, 2014). The architecture was later
extended to XML-CNN (Liu et al., 2017) for multi-
label text classiﬁcation. Here we introduce the
two architectures along with a focus on the key
modiﬁcations.
2.1 CNN for Text Classiﬁcation
Kim-CNN (Kim, 2014) is the ﬁrst work that applies
convolutional neural networks in text classiﬁcation.
The architecture is illustrated in Fig. 1a. Kim-CNN
preprocesses a document by ﬁrst encoding the i-th
word to ak-dimensional embedding vector x∈
R(Pennington et al., 2014). We denote an n-word
document by x, where x= [x,...,x]∈
Rrepresents a sub-sequence from the i-th
to thej-th word in the document.
A convolutional operation applies a ﬁlter w∈
Rto a sub-sequence of mwords to produce a
new feature:
c=f(w·x+b), (1)
wherefis an activation function such as ReLU,
b∈Ris a bias term and the “ ·” operator means
the sum after component-wise products between
two matrices. The ﬁlter is applied to all m-word
sub-sequences in the document to form a featuremapc= [c,...,c]∈R. Suppose
Kim-CNN uses tﬁlters and let c,...,cbe
the corresponding feature maps. A max-pooling
layer is then applied to summarize the features as
z=/bracketleftbig
max(c),..., max(c)/bracketrightbig
∈R. Lastly, a
dropout layer and a fully-connected layer is used
to predict a score vector
s=˜W(z⊙r) +˜b∈R, (2)
where⊙is the element-wise multiplication opera-
tor,˜W∈R,˜b∈Rare learnable parameters
and eachrofr∈Ris a dropout random variable
that follows a Bernoulli distribution.
Kim-CNN was originally proposed for multi-
class classiﬁcation based on the cross-entropy loss
−/summationdisplayylogp,wherep=e
/summationtexte(3)
is the estimated probability of the i-th class,sis
thei-th element of sthat denotes the score of the
i-thclass, and y∈ {0,1}denotes the ground
truth of the instance. If the i-th label is associ-
ated with the document, then y= 1; otherwise,
y= 0. By the construction of pin Eq. (3),/summationtextp
is forced to be 1, which is natural for multi-class
classiﬁcation. For multi-label classiﬁcation, how-
ever, it is not clear whether requiring all p’s to sum
to one would be too restrictive, given that there
can be multiple y’s withy= 1. Nevertheless,
the loss has been considered for some multi-label
works (Gong et al., 2014; Ghosh et al., 2015).
2.2 From CNN to XML-CNN
XML-CNN is a pioneering work that extends Kim-
CNN from multi-class text classiﬁcation to XMTC.
The architecture of XML-CNN is illustrated in
Fig. 1b. It extends Kim-CNN with three modi-
ﬁcations:
•using a label-wise binary cross-entropy loss in-
stead of the cross-entropy loss in Eq. (3),
•adding an additional linear hidden layer with
dropout,
•introducing dynamic max-pooling (Chen et al.,
2015) to extract multiple features from each
CNN ﬁlter.
For the ﬁrst modiﬁcation, the authors noticed the
issue of the cross-entropy loss discussed in Sec-
tion 2.1. They then allow the model to ﬂexibly1988
predict multiple positive labels by taking the inde-
pendent binary cross-entropy loss instead:
−/summationdisplay[ylog(σ(s)) + (1−y) log(1−σ(s))],
(4)
whereσ(s) =is the sigmoid function.
For the second modiﬁcation, the additional linear
layer may help to reduce the number of parame-
ters, allowing the model to be stored in common
GPU devices when Lis extremely large. Let hbe
the number of elements in the added hidden layer.
XML-CNN reduces the number of parameters after
the CNN layer from t×Lin the original Kim-CNN
to
t×h+h×L (5)
whenhis sufﬁciently small.
For the third modiﬁcation, the authors applied
dynamic max-pooling (Chen et al., 2015) in XML-
CNN to capture multiple features from different
parts of the document. In contrast to the traditional
max-pooling, which calculates the maximum along
the whole sequence, dynamic max-pooling divides
the sequence into multiple pools and then collects
the maximum values within each pool to get some
ﬁne-grained features. Given a ﬁlter map c∈R,
the formulation with dpools is:
D(c)=/bracketleftBig
max{c},..., max{c}/bracketrightBig
∈R.
(6)
The output becomes
z=/bracketleftBig
D(c),...,D (c)/bracketrightBig
∈R
instead of/bracketleftbig
max(c),..., max(c)/bracketrightbig
∈Rin
Kim-CNN.2.3 Claims about XML-CNN
Liu et al. (2017) compared their proposed XML-
CNN with Kim-CNN by reporting P@K on six
datasets,as shown in Table 1. P@K calculates
for each document the percentage of correct predic-
tions (i.e., precision) among the top Kpredicted la-
bels and reports the average over all test documents.
Table 1 clearly indicates signiﬁcant improvements
from Kim-CNN to XML-CNN on all datasets. To
examine the impact of each new component in
XML-CNN, the authors further conducted ablation
studies to make the following claims.
•Eq.(4)is more suitable than Eq. (3)for multi-
label classiﬁcation problems.
•The additional linear layer improves both the
performance and the scalability.
• Dynamic max-pooling further improves the per-
formance signiﬁcantly.
The impressive progress of XML-CNN makes it a
standard benchmark for XMTC (e.g., Peng et al.,
2018; Prabhu et al., 2018; You et al., 2019; Chang
et al., 2020; Adhikari et al., 2019). However, we
will show in this study that the progress may not
be as signiﬁcant as the authors claimed. While the
ﬁrst modiﬁcation is included in our evaluation in
Section 4.2, our focus is on the other two modiﬁca-
tions, which correspond to the differences between
XML-CNN and Kim-CNN-Eq. (4), the multi-label
version equipped with the binary cross-entropy loss
in Eq. (4). Subsequently, Kim-CNN-Eq. (4)will be
shorthanded Kim-CNN for simplicity.1989
3 Investigation into XML-CNN
In this section, we point out a signiﬁcant gap be-
tween the formulations in the XML-CNN paper
and the authors’ implementations. We ﬁrst repro-
duce the results in Liu et al. (2017) to ensure what
the authors have done. We then conﬁrm the re-
ported superiority of XML-CNN over Kim-CNN
is actually due to some coincidences.
3.1 The Challenges of Reproducing Liu et al.
(2017)
The authors have released their implementation of
XML-CNN on GitHub.They wrote the code in
Lasagne (Dieleman et al., 2015), an outdated deep
learning framework. To facilitate a thorough com-
parison, we implement a PyTorch-based program
that is as close to the released Lasagne code as pos-
sible. Though their implementation is available, to
our surprise, reproducing XML-CNN results on the
same datasets is more challenging than expected.
We leave details of solving various challenges in
Appendix A. In particular, we ﬁnd that some data
sets used in Liu et al. (2017) are no longer available,
so similar ones are considered; see data statistics
in Table 2.
We choose EUR-Lex for checking the repro-
ducibility due to the following reasons.
•The dataset is publicly available and from Tabel 2
it has the same statistics as in Liu et al. (2017).
•The improvement of XML-CNN is signiﬁcant as
shown in Table 1.
• The size is relatively small but adequate.
The results of the authors and our implementations
are respectively shown in the second and the third
rows in Table 3. The difference between the two
implementation is even smaller than the difference
between XML-CNN’s paper numbers to its public
implementation. This justiﬁes that our results are
close enough for reproducing the numbers. We con-
clude that the author’s result on EUR-Lex can be
reproduced, though many issues must be addressed
in the entire process.
3.2 Problematic Gap Between
Implementations and Formulations
Though we can reproduce the results reported in
Liu et al. (2017), in checking their programs, we
surprisingly found some signiﬁcant gaps between
the implementation and the formulations in their
paper. The ﬁrst one is that their implementation of
the convolutional operation is completely different
from Eq. (1). We illustrate the two CNNs in Fig. 2.
In the authors’ implementation, the convolution
operation sweeps along the embeddings rather than
the words, as shown in Fig. 2b. That is, it seems
the authors did not implement what they intended
to do.
Another problem is about the dynamic max-1990
Implementation Framework P@1 P@3 P@5
Results reported in Liu et al. (2017) 76.38 62.81 51.41
Public code by Liu et al. (2017)’s authors Lasagne 74.28 58.98 48.16
Our code mimicking the above PyTorch 75.50 60.47 49.38
pooling. The authors set the default pool size to 2
and stride to 1in their public implementation:
[max{c},max{c},...max{c}],(7)
which differs from Eq. (6)in that overlapped pools
are used. Further, given that the aim of max-
pooling is to extract information from each pool,
a size-two pool is unusually small. We do not
know why the authors implemented dynamic max-
pooling in this form, but we will show that this odd
implementation, together with the wrong convolu-
tion mentioned earlier, surprisingly works well.
To compare with these unusual settings, we gen-
erate another implementation of XML-CNN by
following Eq. (1)and Eq. (6). The details of our
implementation can be found in Appendix B. Ac-
cording to Liu et al. (2017), this version should be
what its authors intend to have. Table 4 shows the
results on EUR-Lex by various ways to implement
Kim-CNN and XML-CNN. Other settings (e.g., hy-
perparameters) are kept to be the same as those in
the authors’ implementation; see also Section 3.1
and supplementary materials.From Table 4, we
have the following observations.
•For each category (Kim-CNN or XML-CNN),
the last row indicates the setting described in the
original papers. If the CNN input is changed to
the wrong one, the results of both Kim-CNN and
XML-CNN become dramatically worse (rows
1 and 5). On the other hand, if the implemen-
tation of dynamic max-pooling follows Eq. (7)
rather than Eq. (6), the result of XML-CNN also
signiﬁcantly deteriorates (row 4).•However, if both inappropriate settings for CNN
and dynamic max-pooling are applied, the result-
ing procedure corresponds to the actual imple-
mentation by Liu et al. and works surprisingly
well (row 3). In contrast, without the help of
Eq.(7), Kim-CNN by the inappropriate CNN
implementation performs poorly. In such a situa-
tion, Kim-CNN’s scores are quite similar to the
results of Kim-CNN reported in Liu et al. (2017),
as shown in Table 1. So we presume that in Liu
et al. (2017), Kim-CNN was implemented with
the inappropriate CNN setting.
In sum, the implementation seems not what Liu
et al. intended to do in their paper. Thus, their con-
clusions based on the unintentional implementa-
tions may be questionable. In particular, in Table 4
Kim-CNN is competitive if an implementation fol-
lowing its original paper (Kim, 2014) is considered.
For better distinction in subsequent discussions,
we name the two XML-CNN implementations re-
spectively corresponding to Liu et al.’s paper and
public code as follows.
•XML-CNN-paper : XML-CNN following
Eq. (1) and Eq. (6).
•XML-CNN-impl : XML-CNN using CNNs
sweeping along embeddings and Eq. (7).
3.3 The Two Implementations of XML-CNN:
Analysis
We try to explain why XML-CNN-impl can achieve
competitive results. For the analysis, we ﬁrst ar-
gue that conceptually, the unusual dynamic max-
pooling Eq. (7)is similar to not doing pooling. The
reason is because the small pool size = 2implies
that at least half of celements are retained. Then
we design an experiment to compare the combina-1991MethodCNN sweeping
directionDynamic
Max-poolingP@1 P@3 P@5 Note
Kim-CNN embeddings N/A 45.38 34.02 27.72 Actual implementation of Liu
et al. (2017)
Kim-CNN words N/A 75.83 61.08 50.19 Procedure described in Kim
(2014)
XML-CNN embeddings Eq. (7) 75.96 60.56 49.23 XML-CNN-impl: actual imple-
mentation of Liu et al. (2017)
XML-CNN words Eq. (7) 58.09 45.19 37.06
XML-CNN embeddings Eq. (6) 63.03 48.31 39.32
XML-CNN words Eq. (6) 75.73 61.82 50.82 XML-CNN-paper: procedure de-
scribed in Liu et al. (2017)
tions of the following settings.
•CNN sweeping direction: embeddings or words
•Pooling implementation: standard max-pooing
or no pooling
Table 5 shows the P@1 scores on predicting the
test set of EUR-Lex. We have the following obser-
vations.
•Results of the (embeddings, no pooling) setting
are similar to those of the (embeddings, Eq. (7))
setting in Table 4. This conﬁrms our earlier ar-
gument that Eq. (7) is close to no pooling.
•If CNN sweeps along the words, the standard
max-pooling is signiﬁcantly better than no pool-
ing. A possible explanation is that when CNN
sweeps along the words, some sub-sequence of
words are shown to be more important than oth-
ers. Then the standard max-pooling is helpful
to identify them. This situation is similar to that
in image classiﬁcation, where max-pooling is ef-
fective to extract “sharp” features (Springenberg
et al., 2015).
•If CNN sweeps along the embeddings, an oppo-
site situation occurs. No pooling is much better
than standard max-pooling. Because all the em-
beddings can be considered equally useful, the
resulting features after convolutional operation
have similar importance. For such “smooth” fea-
tures, it is known in image classiﬁcation that aver-
age pooling or no pooling are recommend (Sprin-
genberg et al., 2015). In other words, standard
max-pooling can extract little information in
such a case and may lead to worse performance.
In Section 3.4, we will present results to furthermax{c}No pooling
words 74.67 53.61
embeddings 58.14 76.48
support the above analysis.
3.4 The Two Implementations of XML-CNN:
Performance Comparison
Table 6 shows a comprehensive comparison be-
tween XML-CNN-impl and XML-CNN-paper on
more datasets. In contrast to Table 4 where we fol-
low the hyperparameters used in Liu et al. (2017),
we tune the hyperparameters for both methods
in Table 6.We observe that XML-CNN-paper
outperforms XML-CNN-impl on EUR-Lex and
Wiki10-31K. Following the discussion in Sec-
tion 3.3, the reason may be that XML-CNN-impl
lacks the ability to learn position-agnostic features
when documents are long. Note that for EUR-Lex
and Wiki10-31K, the documents are truncated to
500 words because of the long document length.
On the other hand, XML-CNN-impl works com-
petitively on AmazonCat-13K and Amazon-670K.
Though the documents are also truncated to 500
words when needed, the average document lengths
of these two sets are less than 250.
In sum, XML-CNN-paper should be preferable1992because of the more reasonable architecture and
better performance on long documents. Moreover,
XML-CNN can deal with variable sentence lengths,
while XML-CNN-impl cannot because the network
architecture depends on the sentence length. We
consider XML-CNN-paper as the setting for XML-
CNN in subsequent experiments.
4 The True Performance of XML-CNN
After showing the gap between the implementation
and the formulation in Liu et al. (2017), the true
performance of XML-CNN should be re-examined.
In this section, we conduct a comprehensive abla-
tion study for XML-CNN to investigate the claims
in the original paper. We then investigate more
deeply on dynamic max-pooling to determine its
usefulness for XMTC tasks. The results bring us
a similarly competitive but simpler baseline for
XMTC tasks.
4.1 Experimental Setup
We consider a random 80/20 split of the training
data to generate a training subset and a validation
subset for hyperparameter selection. We follow
Liu et al. (2017) to truncate the documents to 500
words, represent each word as a 300-dimensional
GloVe word embedding (Pennington et al., 2014)
and pad the sequences in each batch when needed.
The word embeddings are considered as trainable
parameters during training. We have carefully con-
ducted hyperparameter selection. The procedure
and other details are in Appendix C.
We follow Liu et al. (2017) to train the mod-
els with 50 epochs on the whole training set after
hyperparameter tuning and then evaluate the test
set. We evaluate each method on three datasets:
EUR-Lex, Wiki10-31K, and AmazonCat-13K. In
Section 4.2, we conduct the ablation study by in-
cluding one larger dataset: Amazon-670K. All of
them are in English. The datasets are obtained from
the repository of You et al. (2019) and we follow
Liu et al. (2017) to reduce the vocabulary set.
4.2 Ablation Studies of XML-CNN
To understand how each component introduced in
Liu et al. (2017) really works, we conduct an abla-
tion study as what the authors have done. Speciﬁ-
cally, the effects of using Eq. (4)as the loss, adding
a linear hidden layer, and introducing dynamic max-
pooling are checked. By the results shown in Ta-ble 7, we can re-examine what the authors have
claimed in Liu et al. (2017). To begin, from the
ﬁrst and the second rows, the loss function Eq. (4)
indeed improves the scores 2%-6%on each dataset.
The results validate the claim that Eq. (4)is more
suitable for multi-label tasks than Eq. (3).
Next, while adding a hidden layer is claimed
to be beneﬁcial in Liu et al. (2017), our results
show that the hidden layer is slightly harmful on
EUR-Lex and Wiki10-31K when the standard max-
pooling is applied; see rows 2 and 4 in Table 7. It
works when dynamic max-pooling is employed, but
the improvements are not signiﬁcant. The authors
also claimed that the hidden layer could reduce the
number of parameters; see Eq. (5). This claim is
true whenhis relatively small compared with the
number of convolutional features. However, we
noticed that larger h’s such as 512and1,024are
always preferable after hyperparameter tuning. In
these cases, the number of parameters may not be
reduced.
Lastly, we discuss the effect of dynamic max-
pooling. In the situation of not adding a hid-
den layer, dynamic max-pooling slightly improves
upon the standard max-pooling on most but not all
datasets. If a hidden layer is included in the archi-
tecture, dynamic max-pooling also gives moderate
improvements. However, dynamic max-pooling
may require more network parameters due to mul-
tiple pools. To check its usefulness, we investigate
more in Section 4.3.
4.3 Further Investigation on Dynamic
Max-Pooling
We conduct two experiments to understand whether
dynamic max-pooling always beneﬁts XML-CNN.
The ﬁrst experiment is a comparison between dif-
ferent numbers of pools. The second experiment
compares dynamic max-pooling with standard max-
pooling by using a similar total number of parame-
ters.The experiment results and more discussions
are in Appendix D.1 and Appendix D.2. The inves-
tigations tell us:
•Using too many pools may deteriorate the per-
formance.
•Under similar total numbers of parameters, stan-
dard max pooling is more preferable than dy-
namic max-pooling.1993method EUR-Lex Wiki10-31K
P@1 P@3 P@5 P@1 P@3 P@5
XML-CNN-impl 77.39 62.32 51.28 83.98 70.03 60.18
XML-CNN-paper 78.94 65.77 54.15 84.70 71.80 61.03
AmazonCat-13K Amazon-670K
P@1 P@3 P@5 P@1 P@3 P@5
XML-CNN-impl 94.73 80.29 64.97 38.02 34.13 31.20
XML-CNN-paper 94.78 80.03 64.52 35.69 31.89 29.08
4.4 What We May Claim about XML-CNN
We conclude our ﬁndings in this section as follows:
•Eq.(4)is indeed more suitable for multi-label
tasks than Eq. (3).
•For the hidden layer, there is a minor tradeoff
between the number of parameters and the per-
formance. A negative way to interpret this is that
introducing the hidden layer does not always
improve the performance. However, a positive
interpretation is that with a slight performance
loss, a hidden layer can effective reduce the num-
ber of parameters when the output size of the
pooling operation is large.
•Dynamic max-pooling is not as beneﬁcial as in-
creasing the number of convolutional ﬁlters.
After our careful re-investigation, our suggestion
to future studies of XMTC is that instead of using
XML-CNN as a baseline, the following simpler
settings can be considered.
•If there is no memory concern, Kim-CNN is suit-
able for its similar performance to XML-CNN.
•Otherwise, a simpliﬁed version of XML-CNN
without dynamic max-pooling, namely Kim-CNN with an additional hidden layer, is sufﬁ-
ciently strong and space-efﬁcient as the baseline.
5 Conclusion
This work aims to highlight the importance of val-
idating existing works. From the investigation of
XML-CNN, we learned that there are many pitfalls
when developing new architectures. We correct
the issues in the authors’ implementation, care-
fully re-examine the claims about XML-CNN and
recommend suitable baselines for future studies.
Though not proposing a new method, we hope this
work encourages the community to reproduce and
re-examine inﬂuential works. This may help the
community build future works on top of correct
materials.
6 Acknowledgement
This work is partially supported by ASUS Intel-
ligence Cloud Services and the Ministry of Sci-
ence and Technology of Taiwan via the grants
MOST 110-2628-E-002-013. We also thank the
National Center for High-performance Computing
(NCHC) of National Applied Research Laborato-1994ries (NARLabs) in Taiwan for providing computa-
tional resources.
References1995A The Challenges of Reproducing Liu
et al. (2017)
A.1 Dataset
The authors evaluated XML-CNN on six datasets
from the Extreme Multi-Label Repository.Unfor-
tunately, some of the datasets have been changed
on the repository to different number of data/labels
(with a similar name). Furthermore, for some
of them, the repository does not provide the raw-
text documents, making it hard to preprocess the
documents to the embedding needed for XML-
CNN. Fortunately, we ﬁnd the repository of Atten-
tionXML.(You et al., 2019) where two datasets
(EUR-Lex and Amazon-670K) of raw text match
the statistics of the datasets in the XML-CNN work.
We then choose the smaller EUR-Lex as the ﬁrst
attempt to reproduce XML-CNN faithfully.
A.2 Evaluation
The released code includes only the training but not
the validation/evaluation procedure. In the original
paper (Liu et al., 2017), it is mentioned that 25%
of training data is reserved as the validation set
for hyperparameter selection. However, the details
such as how to generate the validation set, which
metric was considered in validation, and whether
they re-trained the model with the whole training
set are not speciﬁed in the paper. Therefore, we
cannot exactly replicate the results in Table 1. We
ran the released code and observed that with only
75% of training data, the results are always worse
than ones reported in Liu et al. (2017). Thus, we
presume that in Liu et al. (2017), the authors re-
ported the results of models trained on the whole
training set by using the selected hyperparameters.
A.3 Lasagne vs PyTorch
As mentioned in Sec 3.1, we implement a PyTorch-
based program that is as close to the released
Lasagne code as possible. We ﬁx the common
hyperparameters such as the number of ﬁlters and
the dropout rate as ones provided in the authors’
implementation. Then we train the whole train-
ing set and follow their setting to report the test
scores at the 50-th epoch. The results of their and
our implementations are respectively shown in thesecond and the third rows in Table 8. The minor dif-
ferences between the scores are possible because
ensuring everything to be the same from the be-
ginning to the end is tremendously difﬁcult. For
example, optimizers implemented in Lasagne and
PyTorch are not entirely the same. What we have
conﬁrmed is that for the network part, under the
same input, the two implementations generate ex-
actly the same output and loss values. Therefore,
we conclude that our implementation can be used
together with theirs in checking the reproducibility.
However, both are still worse than the results of
Liu et al. (2017) in the ﬁrst row of Table 8. This
fact encouraged us to investigate more on the data
processing step done in Liu et al. (2017).
A.4 Vocabulary Set
In Liu et al. (2017), the authors compared XML-
CNN with some linear-based algorithms, which
use bag-of-word (BOW) features to deal with doc-
ument inputs. The BOW features usually only con-
sider vocabularies with higher frequency to reduce
the dimensionality. To fairly compare XML-CNN
with linear models, the authors removed vocab-
ularies which are not used in the BOW features.
While the Extreme Multi-Label Repository pro-
vides BOW features of EUR-Lex and we assume
that they were used in Liu et al. (2017), the vo-
cabulary set of the BOW features is not accessible
now. Fortunately, we obtained from the repository
owner the vocabulary set used in generating their
BOW features. The results of XML-CNN with the
reduced vocabulary set are shown in the fourth and
the ﬁfth rows in Table 8. By using the reduced
vocabulary set, the results of both Lasagne and Py-
Torch implementations are improved to be closer
to the ones in Table 1. As a result, we conclude that
the authors’ result on EUR-Lex can be reproduced,
though many issues must be addressed in the entire
process.
B Implementation Details of Section 3.2
To implement Eq. (6), we follow Adhikari et al.
(2019) to use AdaptiveMaxPool1dand consider
4 pools, i.e., d= 4. Notice that Eq. (6)does not
handle the situation where the sequence length is
not divisible by d. Adaptive max-pooling solve the
problem by allowing some overlapping between1996Implementation Framework V ocabulary set P@1 P@3 P@5
Results reported in Liu et al. (2017) 76.38 62.81 51.41
Public code by Liu et al. (2017)’s authors Lasagne All 72.08 56.32 46.20
Our code mimicking the above PyTorch All 74.05 59.61 48.24
Public code by Liu et al. (2017)’s authors Lasagne Reduced 74.28 58.98 48.16
Our code mimicking the above PyTorch Reduced 75.50 60.47 49.38
pools. Therefore, it generates exactly doutputs
from documents with varying lengths.
C Details of Experimental Setup
From the hyperparameter ranges listed in Table 9,
we apply Optuna (Akiba et al., 2019) to select the
best hyperparameters from 48random trials. In
the validation procedure, we optimize P@1 for
EUR-Lex, AmazonCat-13K, and Amazon-670K,
and P@3 for Wiki10-31K. We do not optimize P@1
for Wiki10-31K because there is a dominant class
that is associated with about 80% of data. Each trial
is stopped if the validation metric does not improve
for 10 epochs or when it reaches 50 epochs.
In the original papers of Kim-CNN and XML-
CNN, both described the use of ﬁlters with different
window sizes in the convolutional layer. In Kim
(2014) and Liu et al. (2017), ﬁlter sizes 3,4,5and
2,4,8are respectively used. However, as shown in
Table 10, using multiple ﬁlter sizes does not have
a signiﬁcant beneﬁt compared with using a ﬁxed
ﬁlter size 8. Furthermore, among single ﬁlter-size
settings, the ﬁlter size 8is generally competitive,
so we use it in our ensuing investigation.
The experiments are conducted on Azure with
an Nvidia Tesla V100 GPU, taking <1, <1, 6, 20
GPU hours for one trial on EUR-Lex, Wiki10-31K,
AmazonCat-13K, and Amazon-670K respectively.
D Further Investigation on Dynamic
MaxPoolingD.1 Effect of the Number of Pools
In dynamic max-pooling, a crucial hyperparameter
is the number of pools d. Nevertheless, in the pub-
lic code of the XML-CNN work (Liu et al., 2017),
due to the unusual setting in Eq. (7),dis not a ﬁxed
number but depends on the document length. Con-
sequently, discussion about the number of pools is
lacking in the original work.
In Table 11, we conduct a comparison by us-
ingd∈{1,2,8,32,64}. On all datasets, d= 2
andd= 8have the best performance. Increasing
the number of pools to more than 8not only leads
to worse results on some problems, but also costs
more memory and training time. Our results indi-
cate that while the goal of dynamic max-pooling is
to extract multiple features from each CNN ﬁlter,
using too many pools may deteriorate the perfor-
mance instead.
D.2 Investigation on Dynamic Max-Pooling by
Fixing the Number of Parameters
As discussed in Sec 4.2, we noticed that the num-
ber of parameters in XML-CNN increases along
with the number of pools in dynamic max-pooling.
Assume the number of ﬁlters is tand the number
of pools isd. In XML-CNN, the total number of
ﬁlters after the pooling layer is t×d, while Kim-
CNN still only has tﬁlters. It is unclear whether the
improvement of dynamic max-pooling is caused
by the richer information from multiple pools or
simply the larger number of parameters. We in-
vestigate this issue by comparing XML-CNN with
different numbers of pools but ensuring the similar
number of parameters. From Table 12, we observe
that XML-CNN with 1 pool (i.e., without dynamic
max-pooling) outperforms XML-CNN with 2or
8pools. The result reveals that the architectural
modiﬁcation of dynamic max-pooling may not be
that useful.
Though increasing the number of ﬁlter also in-
troduced more parameters in CNN, the number is
negligible compared to the number of parameters in1997
# pools EUR-Lex Wiki10-31K AmazonCat-13K
P@1 P@3 P@5 P@1 P@3 P@5 P@1 P@3 P@5
d= 1 76.40 62.78 51.88 80.89 67.89 58.17 94.73 79.64 63.95
d= 2 77.98 65.11 53.90 82.68 69.40 59.43 94.55 79.72 64.16
d= 8 76.79 63.28 52.10 84.19 71.55 61.14 94.79 80.04 64.49
d= 32 66.57 52.51 42.56 82.94 69.20 59.20 94.46 79.45 63.78
d= 64 68.28 54.14 44.19 83.01 69.91 59.13 94.29 79.00 63.27
the output layer, where the output size Lis usually
extremely large.
E NDCG results
This section shows NDCG@K results reported by
Liu et al. (2017) and in our experiments. Table 13
shows NDCG@K results reported by Liu et al.
(2017). Table 14 shows NDCG@K results cor-
responding to Table 4. Table 15 shows NDCG@K
results of our ablation study (Table 7). The obser-
vations from NDCG@K results are similar to those
from P@K results.1998# of ﬁlters # of pools EUR-Lex Wiki10-31K AmazonCat-13K
P@1 P@3 P@5 P@1 P@3 P@5 P@1 P@3 P@5
256 1 76.66 63.70 52.64 83.07 69.35 58.89 94.52 79.66 64.23
128 2 77.36 62.93 51.79 83.62 68.92 58.35 94.34 79.51 64.14
1024 1 78.37 65.65 54.42 83.42 70.66 60.50 94.90 80.29 64.79
128 8 75.91 62.12 51.33 84.11 69.94 59.22 94.30 79.50 64.13
RCV1 Amazon-670K
N@1 N@3 N@5 N@1 N@3 N@5
Kim-CNN-Eq.(3) 93.54 88.2 87.26 15.19 14.6 14.12
XML-CNN 96.88 92.63 92.22 35.39 33.74 32.64
EUR-Lex Wiki-30K
N@1 N@3 N@5 N@1 N@3 N@5
Kim-CNN-Eq.(3) 42.84 36.95 33.83 78.93 60.52 51.96
XML-CNN 76.38 66.28 60.32 84.06 76.35 68.94
Amazon-12K Wiki-500K
N@1 N@3 N@5 N@1 N@3 N@5
Kim-CNN-Eq.(3) 90.31 83.87 81.21 23.38 15.45 13.64
XML-CNN 95.06 89.48 87.06 59.85 48.67 46.12
MethodCNN sweeping
directionDynamic
Max-poolingN@1 N@3 N@5 Note
Kim-CNN embeddings N/A 45.38 36.72 33.04 Actual implementation of Liu
et al. (2017)
Kim-CNN words N/A 75.83 64.75 58.93 Procedure described in Kim
(2014)
XML-CNN embeddings Eq. (7) 75.96 64.31 58.20 XML-CNN-impl: actual imple-
mentation of Liu et al. (2017)
XML-CNN words Eq. (7) 58.09 48.30 43.81
XML-CNN embeddings Eq. (6) 63.03 51.92 46.88
XML-CNN words Eq. (6) 75.73 65.31 59.54 XML-CNN-paper: procedure de-
scribed in Liu et al. (2017)19992000