
Raquel G. Alhama
Tilburg University,
Warandelaan 2, 5037AB Tilburg,
the Netherlands
rgalhama@uvt.nl
Abstract
Word identiﬁcation from continuous input is
typically viewed as a segmentation task. Ex-
periments with human adults suggest that fa-
miliarity with syntactic structures in their na-
tive language also inﬂuences word identiﬁca-
tion in artiﬁcial languages; however, the re-
lation between syntactic processing and word
identiﬁcation is yet unclear. This work takes
one step forward by exploring a radically
different approach of word identiﬁcation, in
which segmentation of a continuous input is
viewed as a process isomorphic to unsuper-
vised constituency parsing. Besides formal-
izing the approach, this study reports simu-
lations of human experiments with DIORA
(Drozdov et al., 2019), a neural unsupervised
constituency parser. Results show that this
model can reproduce human behavior in word
identiﬁcation experiments, suggesting that this
is a viable approach to study word identiﬁca-
tion and its relation to syntactic processing.
1 Introduction
When exposed to speech in an unknown language,
humans are faced with the task of ﬁnding out what
are the basic combinatorial units of the language,
such as phonemes, syllables, words and phrases.
Since speech is continuous, humans need to rely on
implicit cues –such as statistical information– to
ﬁnd out the building blocks of the language. One
approach that studies which statistical cues can be
used by humans in this task is Artiﬁcial Grammar
Learning (AGL). Experiments in AGL are char-
acterized by the use of artiﬁcial languages with
carefully controlled statistical properties. To in-
vestigate word identiﬁcation with this paradigm,
participants in a typical AGL experiment are ﬁrst
exposed to a speech-like sample of the artiﬁcial
language (usually recorded with synthetic voice).
Then, they participate in a test that has been de-
signed to show whether participants identiﬁed the
words in the artiﬁcial language.To formalize theories of how humans identify
words in AGL tasks, a range of computational mod-
els have been proposed over the last two decades.
These models have explained a wide arrange of
phenomena, using a variety of algorithms such as
Bayesian inference (Frank et al., 2010), normative
statistics (Swingley, 2005), cognitively inspired
processes implementing recognition or memoriza-
tion (Alhama and Zuidema, 2017; Perruchet and
Vinter, 1998), and neural networks (French et al.,
2011; Endress and Johnson, 2021).
There is, however, one phenomenon that has
not been addressed in the computational literature
in AGL: the fact that participant’s knowledge of
their native language inﬂuences performance in
this type of AGL experiments. In particular, results
seem to be inﬂuenced by co-occurrence statistics
of sublexical units (Onnis et al., 2005; Siegelman
et al., 2018; Elazar et al., 2022), and interestingly,
also by the presence of left- or right-branching
syntactic structures in the native language, which
predict the statistics that subjects use to identify
words (Onnis and Thiessen, 2013).
One likely reason why this has not been the fo-
cus of prior models of word identiﬁcation in AGL
is that we are in need a computational framework
that can represent this information on the ﬁrst place.
While sensitivity to co-occurrences of sublexical
patterns could potentially be accounted for with
at least some of the existing models (in particular
the neural network approaches, which should show
similar output to input with similar representations),
the inﬂuence of prior syntactic knowledge cannot
be readily explained with the existing approaches,
as none of these models incorporate syntactic pro-
cessing.
Thus, a preliminary step before modelling the
inﬂuence of prior knowledge is to develop a mod-
elling framework that can relate word identiﬁcation
in AGL to syntactic processing in the ﬁrst place.4103This work aims to ﬁll this gap by presenting a radi-
cally different account of word identiﬁcation that is
isomorphic to syntactic processing: namely, word
segmentation as unsupervised constituency pars-
ing.
This paper is structured as follows. Section 2
reviews the experimental record that this work fo-
cuses on. The approach of modelling word seg-
mentation as unsupervised constituency parsing is
formalized in section 3. Next, section 4 reports
an empirical study using DIORA (Drozdov et al.,
2019), an unsupervised neural inside-outside con-
stituency parser. The results, reported in section
5, show that this approach can be effectively used
to model human word identiﬁcation in AGL exper-
iments with human adults. Finally, implications
of this new perspective on word identiﬁcation are
discussed in section 6, and directions for future
studies are proposed in section 7.
2 Experimental Record
A long tradition of AGL experiments have used ar-
tiﬁcial languages to discover how humans identify
words from a continuous speech-like stream. Stud-
ies show that humans can segment words based
on statistics over syllables, such as frequency of
co-occurence (Aslin et al., 1998), transitional prob-
abilities (Saffran et al., 1996a,b; Perruchet and
Desaulty, 2008) predictive dependencies between
non-adjacent syllables (Peña et al., 2002; Endress
and Bonatti, 2007; Frost and Monaghan, 2016), or
phonotactic patterns (Onnis et al., 2005).
Here, the focus is on the two experiments re-
ported in Perruchet and Desaulty (2008) (P&D on-
wards). These experiments showed that humans
have the ability to keep track of both forward and
backward transitional probabilities (as explained
next) and use them for identifying words. It is
precisely this ability that is susceptible of being in-
ﬂuenced by prior syntactic knowledge (Onnis and
Thiessen, 2013), motivating the choice to focus on
these experiments as a starting point.
In Experiment 1, the authors used an artiﬁ-
cial language consisting of 9 bi-syllabic ‘words’,
formed with combinations of 12 different syllables.
There were two conditions in the experiment: for-
ward andbackward . In the forward condition, the
ﬁrst syllable of each word uniquely predicted thesecond syllable (e.g. if AandBwere syllables
andABwas word, then Awas only followed by
B). In other words, the forward TP ( TP)within
words was consistently 1, while it was much lower
between words:
TP(AB) =p(BjA) =(
1ifAB 2 fwords g
0:11otherwise
The backward condition follows exactly the
same design, except that it is the second syllable in
the word which uniquely predicts the ﬁrst:
TP(AB) =p(AjB) =(
1ifAB 2 fwords g
0:11otherwise
The participants were familiarized with a sample
of synthesized speech of this language, consisting
of a random concatenation of 115 repetitions of
each word. With this design, the co-occurrence
frequency of syllables within a word was 3 times
larger than for syllables spanning word boundaries.
The total duration of the recorded stream was 8
minutes, and there were no pauses or any other
acoustic indication that separated the words. Thus,
the only two cues that participants could use to
identify words were the TPs between syllables and
the co-occurrence frequency of syllables (as it was
3 times higher for syllables within words than for
syllables spanning word boundaries).
Condition Words
Forward AX, BX, CX,
DY , EY , FY ,
GZ, HZ, IZ
Backward XA, XB, XC,
YD, YE, YF,
ZG, ZH, ZI
After listening to this stream of artiﬁcial words,
the participants were presented with a 2-Alternative
Forced Choice (2AFC) test. Each trial in the test
consisted of a choice between a word of the lan-
guage, and a ‘partword’, i.e. a sequence of two
syllables that spanned across word boundaries. For
instance, in the forward condition, a test trial could
involve the word CX and the partword XD (see4104Table 1). Participants were instructed to choose the
item that seemed more like a word of the artiﬁcial
language. In both conditions, participants chose
words more frequently than partwords (with a slight
advantage for the backward condition). This ﬁnd-
ing suggests that words can be identiﬁed based on
statistical properties such as syllable co-occurrence
frequency and TPs, in either directions.
To disentangle the contribution of each cue, in
a second experiment, the authors designed an ar-
tiﬁcial language in which the frequency of words
and partwords in the familiarization stream was
controlled. Thus, the only way to identify words
was to keep track of TPs. Results of Experiment
2 showed that participants were statistically above
chance in both conditions, with a slight advantage
for the forward condition (although the difference
between directions did not reach signiﬁcance). The
authors concluded that human adults can track TPs
in both directions, and use them to identify words
in a continuous stream.
3 Formalization of the Approach
The approach presented this paper is to model the
task of word identiﬁcation from a continuous input
using the same process for discovering syntactic
constituents. A number of adaptations and consid-
erations are required, as described next.
3.1 Word Segmentation as Unsupervised
Constituency Parsing
Constituency parsing is the task of identifying
which word spans form constituents, and how are
those constituents are hierarchically combined into
larger constituents to form the correct syntactic
tree. The nodes that occupy the lowest positions
in the tree (considering that the root is the high-
est node) correspond to the ‘tightest’ constituents,
i.e. those that span over words that form cohesive
phrases that can be further combined (Onnis and
Thiessen, 2013). As an example, given the sen-
tence the singer yelled , a constituency parser needs
to decide whether a grouping like ((the, singer),
yelled) is more likely than (the, (singer, yelled)) . A
successful parser would conclude that (the, singer)
forms a cohesive constituent (concretely, a noun
phrase), while (singer, yelled) does not.
More generally, given a sentence S=ABC
where A,BandCare basic units (in this case,
words), the parser needs to decide whether to group
together ABorBCto form a higher-order unit (aconstituent). Likewise, a segmentation algorithm
presented with a stream S=ABC , where A,B
andCare basic units (e.g. syllables or phonemes),
also needs to decide whether the most cohesive
higher-order unit (in this case, a word) is ABor
BC. Thus, with this simile, word segmentation
can be cast in terms of a process that is isomorphic
to (unsupervised) constituency parsing.
3.2 Input
Participants in the experiments by P&D were ex-
posed to a speech stream formed with a randomized
concatenation of the bisyllabic words in the artiﬁ-
cial language. Similarly, to train a parsing model,
a stream of ‘syllables’ (which is coded simply us-
ing the same symbols as P&D, i.e. A-D, X-Z) is
generated with the same procedure described in the
original paper. Thus, these symbols are the basic
units (or vocabulary) for the parser.
As in most AGL experiments, the stimuli in
P&D consisted of one single stream, which was
not separated into different sentences. However,
the training data used for parsing typically consists
of a large number of sentences, likely much shorter
than the stimuli in AGL experiments. Moreover,
the adults participating in the experiment are pre-
sumably not deriving one single parse during the 8
minute exposure to the artiﬁcial language, as this
input greatly exceeds the average sentence length
of natural language. More likely, humans sepa-
rately processed subsequences of the stimuli, as
would be expected given limited attention span and
short term memory. This intuition is captured in
some models of segmentation in AGL, which oper-
ate over subsequences of random length (Perruchet
and Vinter, 1998), or an all possible subsequences
up to a predeﬁned maximum length (Alhama and
Zuidema, 2017).
Similarly, the approach proposed here is to di-
vide the stream into subsequences (‘sentences’),
the length of which is determined with a stochastic
procedure. Unlike previous models, this approach
samples the length of the subsequences from a
Poisson distribution, with parameters derived from
spoken natural language: the mean and standard
deviation of the distribution were computed from
the monolingual French corpus in OpenSubtitles4105(Lison and Tiedemann, 2016). The corpus con-
sisted of over 100 million sentences, and the mean
sentence length was 5.93 (with standard deviation
of 4.55). A constraint is set such that the mini-
mum sentence length is 4, and the maximum is 10.
This prevents too much fragmentation of the input
and keeps the distribution centered around the peak.
Figure 1 shows the distribution of the subsequences
derived from the stimuli.
It must be noted that, by breaking the stream
into subsequences, boundaries are introduced in an
otherwise continuous stream, and it is therefore im-
perative that these are not consistently aligned with
word boundaries, as otherwise this would provide
additional information to the model (which was not
available to participants in the experiments). By
using a stochastic procedure, the boundaries are
not consistently set either within or between words,
and thus no artiﬁcial cue is introduced.
3.3 Evaluation
In the experiments reported in P&D, participants
responded to a 2AFC test that paired words with
partwords, i.e. sequences of syllables that spanned
word boundaries. A preference for words at group
level was taken as indication of having successfully
identiﬁed the words of the artiﬁcial language.
From a modelling perspective, what is required
to implement the 2AFC choices is some ‘score’
that conditions the choice for for words vs. part-
words. Previous models of segmentation derivedscores based on internal counts of the model, i.e.
the amount of times that a sequence was encoun-
tered (Frank et al., 2010) or memorized (Perruchet
and Vinter, 1998; Alhama and Zuidema, 2017); or
alternatively, based on the reconstruction error of
these items in an autoencoder (French et al., 2011).
In this work, a different approach is required,
since scores need to be derived from the predicted
parse trees. The proposal presented here is to as-
sign a score to each test item (word or partword)
based on to what extent the parser identiﬁes this
syllable sequence as a cohesive constituent. Given
that all the tested items are bisyllabic, the most
straightforward approach is to quantify cohesive-
ness as the number of times a word or partword
has been placed at the lowest level of the trees pre-
dicted from the familiarization stimuli (or, in other
words, the amount of times that the syllables in a
word or partword are siblings; see table 2 for an
example). This computation can easily be extended
to longer items by considering additional higher
nodes in the tree.
Score
Tree Words Partwords
[[A[XE]][Y B]]AX: 0 EY: 0 XE: 1 YB: 1
[[[AX][EY]]B]AX: 1 EY: 1 XE: 0 YB: 0
[[AX][E[Y B]]] AX: 1 EY: 0 XE: 0 YB: 1
Then, for each item pair in the test, the item
that has the largest score is chosen (or randomly
determined in the unlikely case of a tie). Finally,
as in the original experiments, the accuracy is the
mean number of choices for words over the total
number of test items.
4 Simulations
This section presents simulations with Deep Inside-
Outside Recursive Autoencoder (DIORA, Drozdov
et al., 2019), an unsupervised neural constituency
parser. DIORA is an autoencoder network, trained
with a ﬁll-in-the-blank objective: it encodes all the
words in a sentence except one in a single vector,
and then decodes from this vector, predicting all
the words (including the removed one). The en-
coder uses a chart to build a constituency tree, with
each cell consisting of a weighted average all the
possible subtrees covering the represented span.4106These subtrees are encoded as independent vectors
with their corresponding score, both of which are
computed recursively using a composition function.
In a recent empirical comparison, DIORA exhib-
ited some of the best results in unsupervised con-
stituency parsing for English, and outperformed all
the competing models in most of the experiments
in Japanese (Li et al., 2020).
To reproduce the original experiments in P&D,
I trained DIORA with the input data generated ac-
cording to the procedure described in 3.2. DIORA
can be used with different composition functions:
a multilayer feed-forward network (MLP), a ver-
sion of the MLP that shares the inside and out-
side parameters (MP ), and a TreeLSTM (Tai
et al., 2015). The model can be optimized with ei-
ther Max-Margin or Cross-Entropy loss (Softmax).
Simulations are reported with all these variants,
with the rest of hyperparameters ﬁxed to the de-
fault values, except: batch size=20, hidden layer
size= 16, maximum epochs=50).
I trained 30 individual models for each conﬁgu-
ration and experimental condition. This is roughly
the larger number of participants in the experimen-
tal conditions in P&D (n=31), and the models only
differed in their initial state. At the end of train-
ing, the models were presented with the stimuli
one more time, to produce the ﬁnal parse trees that
would be used for evaluation. The evaluation met-
ric described in 3.3 was computed for each model,
and —as in the original paper— the mean perfor-
mance of the 30 models is submitted to a one-sided
Student’s t-test to ﬁnd whether the performance is
signiﬁcantly above chance level.
5 Results
5.1 Experiment 1
The ﬁrst experiment reported in Perruchet and De-
saulty (2008) used an artiﬁcial language in which
words could be identiﬁed based on the TPs between
syllables (either in the forward or the backward
direction, depending on the condition). Table 3 re-
ports the mean performance (i.e. mean number ofcorrect choices in the 2AFC test), and the statistical
signiﬁcance when comparing against chance level.
Comp. Loss Cnd. Acc. (SE)
TreeLSTM margin fw 0.77(0.02)***
bw 0.76(0.03)***
softmax fw 0.78(0.03)***
bw 0.78(0.03)***
MLP margin fw 0.77(0.03)***
bw 0.75(0.03)***
softmax fw 0.74(0.03)***
bw 0.65(0.03)***
MLP margin fw 0.75(0.03)***
bw 0.74(0.03)***
softmax fw 0.77(0.02)***
bw 0.76(0.02)***
Humans fw 0.60(0.51)
bw 0.67(0.56)**
As can be seen, all the model variants are suc-
cessful in distinguishing words from partwords.
The mean accuracies of all the models are statis-
tically above chance, and do not differ greatly in
terms of model choices (with TreeLSTM-softmax
having the best performance). Thus, word iden-
tiﬁcation in this condition can be achieved with
DIORA, slightly outperforming humans.
5.2 Experiment 2
The second experiment used an artiﬁcial language
with controlled frequency, such that words and part-
words would not differ on this regard. The results
of simulations with this stimuli are reported in table
4. The pattern of results is notably different from
Experiment 1: only the model with Tree-LSTM
combined with Max-Margin reconstruction loss is
successful in this task (with the exception of MLP-
shared for the backward condition). Thus, this
variant of DIORA, which was also successful in
identifying words in Experiment 1, successfully
reproduces the observed behavior of human adults,
and is capable of identifying words in continuous
input based solely on the transitional probabilities
between syllables, regardless of whether these are
more reliable in the forward or the backward direc-
tion.4107Comp. Loss Cnd. Acc. (SE)
TreeLSTM margin fw 0.60(0.04)*
bw 0.58(0.03)*
softmax fw 0.55(0.04)
bw 0.53(0.03)
MLP margin fw 0.50(0.04)
bw 0.52(0.04)
softmax fw 0.52(0.04)
bw 0.55(0.04)
MLP margin fw 0.55(0.04)
bw 0.58(0.05)
softmax fw 0.51(0.04)
bw 0.58(0.04)*
Humans fw 0.66(0.43)***
bw 0.61(0.51)*
However, the fact that the accuracy dropped for
the other model variants is intriguing. Since the
evaluated performance is the mean over 30 simula-
tions, there could be at least two reasons behind the
tendency to perform at chance. One would be that
most of these simulations do perform individually
at chance, and are simply not well suited for distin-
guishing between words and partwords based on
TPs. Alternatively, the mean may be around chance
due to a similar number of well-performing and fail-
ing models, as would be the case if the initial state
was highly inﬂuential on the ﬁnal performance of
the individual models. The greater variance found
in this experiment (compared to experiment 1) sug-
gests that this may be the case. To ﬁnd out more,
the distribution of scores is graphically reported in
Figure 2.
As can be seen, the distributions are much tighter
for Experiment 1, and the spread of the scores in Ex-
periment 2 cover almost the entire range of scores,
suggesting that, as suspected, the initial state is
highly inﬂuential on performance.
5.3 Subjective Frequencies
The experimental design in P&D involves the use
of a 2AFC test to discover whether the words in the
speech sample have been discovered. However, the
extent to which 2AFC tests reﬂect the discovery of
words has been put into question before (Alhamaet al., 2015; Kidd et al., 2020). In particular, suc-
cess in 2AFC can happen even when words are not
that clearly distinguished from partwords. Thus, to
gain further insight on the status of words, Fig. 3
shows the amount of times that the best-performing
DIORA model (TreeLSTM-margin) –which was
successful in the 2AFC test– recognized each test
item as a constituent. This quantity is known as the
‘subjective’ frequencies of the model (Alhama and
Zuidema, 2016).
As can be seen, the frequencies for words in
Experiment 1 are much higher than those of part-
words. A Student’s t-test conﬁrms that counts for
words are statistically different from partwords
(backward: [t(30) = 14 :54; p= 1:19e], for-
ward: [t(30) = 13 :40; p= 1:52e]). However,
in Experiment 2, the difference between words and
partwords is less obvious, and a few partwords
are identiﬁed more often than some of the words.
The slight superiority of words was enough for
this model to be successful in the 2AFC test. A
Student’s t-test over counts of words vs. part-
words does not yield evidence of signiﬁcant dif-
ferences (backward: [t(30) = 1 :62; p= 0:10],
forward: [t(30) = 1 :96; p= 0:05]). Together, these
results suggest that the 2AFC test reveals only a
slight superiority of words over partwords.
6 Discussion
From a computational perspective, word identiﬁca-
tion from continuous (artiﬁcial) input has always
been portrayed as a segmentation task, concerned
with breaking the continuous stream into combi-
natorial pieces. This work explores a completely
different perspective, in which the identiﬁcation of
words is carried out with a syntactic constituency
parser, which groups the syllables hierarchically
into tree structures.
The results for experiments 1 and 2 show that
a model like DIORA (with TreeLSTM and Max-
Margin loss) can successfully reproduce human
behavior in the experiments. From a mechanistic
perspective, a tentative conclusion is that, when
exposed to speech-like input in an unknown lan-
guage, human adults group syllables that follow
statistically coherent patterns, and this grouping
is hierarchical –akin to the hierarchical structures
attributed to syntax.
How, then, does the process of identifying words
relate to ﬁnding the syntactic relations between the
identiﬁed words? Given the hierarchical nature of4108
the process, a possibility is that one single process
builds a bottom-up hierarchy of units, grouping sub-
word sequences into words and combining those
into syntactic constituents. This is consistent with
some usage-based theories of language (Kay and
Fillmore, 1999; Goldberg, 2006, p.5), which deem
all levels of grammatical analyses as homologous.
This interpretation would explain the results in On-
nis and Thiessen (2013), which show that humans
identify words consistent with TPs in the forward
or backward direction, depending on grammatical
patterns in the native language (in particular, the
tendency for head-directionality).
Although DIORA reproduced, to a great extent,
the pattern of results reported in P&D, there are
some differences. To begin with, DIORA is better
than humans in identifying words when those aremore frequent than partwords. This is evidenced
by the performance in Experiment 1, as well as
by the distribution of frequency counts reported in
section 5.3. On the other hand, only one of the
variants of DIORA identiﬁed words in Experiment
2, when frequency information was removed. As
shown above, there is large variance in the perfor-
mance of the models, depending on their initial
state. This is again consistent with the results ob-
served in Onnis and Thiessen (2013): in the ab-
sence of frequency information, humans seem to
rely on prior knowledge to guide the discovery of
words. Nevertheless, to conﬁrm whether the cur-
rent results speak to the observed behavior in Onnis
and Thiessen (2013), simulations using the same
stimuli are required. Thus, a prediction from this
work is that pre-training the parser with Korean or4109
English could set a bias in the model to discover
words based on either TPor TP. The fact
that DIORA was successful in both English and
Japanese (a language that, like Korean, has a ten-
dency for left-branching syntactic structures) bodes
well for such experiment (Li et al., 2020).
Finally, it must be noted that, to fully understand
the role of TPs in word identiﬁcation –specially in
the absence of frequency cues– it would be useful
to have experimental procedures with stricter tests,
as the analyses of subjective frequencies revealed
thatsuccess in the 2AFC can be achieved with only
a slight difference between words and partwords.
7 Conclusion
This paper proposes a novel approach for word
identiﬁcation from continuous speech-like input:
word segmentation as unsupervised parsing. Us-
ing this framework with DIORA revealed that word
identiﬁcation in AGL can be explained from the per-
spective of unsupervised constituency parsing, sug-gesting this framework can be effectively used to
bridge the gap between models of word identiﬁca-
tion and syntactic syntactic processing. This work
paves the way for addressing unanswered questions
on the inﬂuence of syntactic knowledge in subse-
quent learning; in particular, an immediate next
step for future work is to pre-train DIORA with
head-ﬁrst and head-last languages to ﬁnd whether
the model can be biased towards tracking forward
or backward TPs.
The implications of this study are not limited to
Cognitive Modelling: the use of techniques from
Natural Language Processing to investigate human
learning can also be fruitful for this ﬁeld. In par-
ticular, one ﬁnding is that, unlike humans, DIORA
discovers constituents best when those are identi-
ﬁable by the frequency of co-occurrence of the re-
lated units –rather than by transitional probabilities–
. Although this model was not designed to mimic
human learning, incorporating the inductive biases
of humans (i.e. a tendency for tracking forward or4110backward dependencies depending on the degree
of left- or right-branchness of the language) may
be a fruitful avenue to pursue, as humans are, after
all, the best-performing syntactic parsers.
Acknowledgements
I am grateful to Phong Le, Jelle (Willem) Zuidema
and Afra Alishahi for their helpful comments on a
previous version of this article. I also thank Phong
for insightful discussions.
References41114112