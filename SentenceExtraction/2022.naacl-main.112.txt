
Lixing Zhu, Zheng Fang, Gabriele Pergola, Rob Procter, Yulan HeDepartment of Computer Science, University of Warwick, UKThe Alan Turing Institute, UK
{lixing.zhu,z.fang.4,gabriele.pergola.1
rob.procter,yulan.he}@warwick.ac.uk
Abstract
Building models to detect vaccine attitudes on
social media is challenging because of the com-
posite, often intricate aspects involved, and the
limited availability of annotated data. Existing
approaches have relied heavily on supervised
training that requires abundant annotations and
pre-defined aspect categories. Instead, with the
aim of leveraging the large amount of unan-
notated data now available on vaccination, we
propose a novel semi-supervised approach for
vaccine attitude detection, called VAD. A
variational autoencoding architecture based on
language models is employed to learn from
unlabelled data the topical information of the
domain. Then, the model is fine-tuned with a
few manually annotated examples of user atti-
tudes. We validate the effectiveness of VAD
on our annotated data and also on an existing
vaccination corpus annotated with opinions on
vaccines. Our results show that VADis
able to learn disentangled stance and aspect
topics, and outperforms existing aspect-based
sentiment analysis models on both stance de-
tection and tweet clustering. Our source code
and dataset are available at http://github.
com/somethingx1202/VADet .
1 Introduction
The aim of vaccine attitude detection in social me-
dia is to extract people’s opinions towards vaccines
by analysing their online posts. This is closely re-
lated to aspect-based sentiment analysis in which
both aspects and related sentiments need to be
identified. Previous research has been largely fo-
cused on product reviews and relied on aspect-
level sentiment annotations to train models (Barnes
et al., 2021), where aspect-opinions are extracted
as triples (Peng et al., 2020), polarized targets (Ma
et al., 2018) or sentiment spans (He et al., 2019).
However, for the task of vaccine attitude detec-
tion on Twitter, such a volume of annotated data is
barely available (Kunneman et al., 2020; Paul et al.,Figure 1: Top: Expressions of aspects entangled with
expressions of opinions. Bottom: Vaccine attitudes can
be expressed towards a wide range of aspects/topics
relating to vaccination, making it difficult to pre-define
a set of aspect labels as opposed to corpora typically
used for aspect-based sentiment analysis.
2021). This scarcity of data is compounded by the
diversity of attitudes, making it difficult for models
to identify all aspects discussed in posts (Morante
et al., 2020).
As representative examples, consider the two
tweets about personal experiences for vaccination
at the top of Figure 1. The two tweets, despite ad-
dressing a common aspect (vaccine side-effects),
express opposite stances towards vaccines. How-
ever, the aspect and the stances are so fused to-
gether that the whole of the tweets need to be con-
sidered to derive the proper labels, making it diffi-
cult to disentangle them using existing methodolo-
gies. Additionally, in the case of vaccines attitude
analysis, there is a wide variety of possible aspects
discussed in posts, as shown in the bottom of Fig-
ure 1, where one tweet ironically addressed vaccine
side-effects and the second one expressed instead
specific political concerns. This is different from
traditional aspect-based sentiment analysis on prod-
uct reviews where only a small number of aspects
need to be pre-defined.
The recently developed framework for integrat-
ing Variational Auto-Encoder (V AE) (Kingma and1566Welling, 2014) and Independent Component Anal-
ysis (ICA) (Khemakhem et al., 2020) sheds light
on this problem. V AE is an unsupervised method
that can be used to glean information that must be
retained from the vaccine-related corpus. Mean-
while, a handful of annotations would induce the
separation of independent factors following the
ICA requirement for prior knowledge and induc-
tive biases (Hyvarinen et al., 2019; Locatello et al.,
2020a,b). To this end, we could disentangle the
latent factors that are either specific to the aspect or
to the stance, and improve the quality of the latent
semantics learned from unannotated data.
We frame the problem of vaccine attitude de-
tection as a joint aspect span detection and stance
classification task, assuming that a tweet, which
is limited to 280 characters, would usually only
discuss one aspect. In particular, we extend a pre-
trained language model (LM) by adding a topic
layer, which aims to model the topical theme dis-
cussed in a tweet. In the absence of annotated data,
the topic layer is trained to reconstruct the input
message built on V AE. Given the annotated data,
where each tweet is annotated with an aspect span
and a stance label, the learned topic can be disen-
tangled into a stance topic and an aspect topic. The
stance topic is used to predict the stance label of the
given tweet, while the aspect topic is used to pre-
dict the start and the ending positions of the aspect
span. By doing so, we can effectively leverage both
unannotated and annotated data for model training.
To evaluate the effectiveness of our proposed
model for vaccine attitude detection on Twitter, we
have collected over 1.9 million tweets relating to
COVID vaccines between February and April 2021.
We have further annotated 2,800 tweets with both
aspect spans and stance labels. In addition, we
have also used an existing Vaccination Corpusin
which 294 documents related to the online vacci-
nation debate have been annotated with opinions
towards vaccination. Our experimental results on
both datasets show that the proposed model outper-
forms existing opinion triple extraction model and
BERT QA model on both aspect span extraction
and stance classification. Moreover, the learned
latent aspect topics allow the clustering of user atti-
tudes towards vaccines, facilitating easier discovery
of positive and negative attitudes in social media.
The contribution of this work can be summarised
as follows:•We have proposed a novel semi-supervised
approach for joint latent stance/aspect repre-
sentation learning and aspect span detection;
•The developed disentangled representation
learning facilitates better attitude detection
and clustering;
•We have constructed an annotated dataset for
vaccine attitude detection.
2 Related Work
Our work is related to three lines of research:
aspect-based sentiment analysis, disentangled rep-
resentation learning, and vaccine attitude detection.
Aspect-Based Sentiment Analysis (ABSA)
aims to identify the aspect terms and their polari-
ties from text. Much work has been focusing on
this task. The techniques used include Conditional
Random Fields (CRFs) (Marcheggiani et al., 2014),
Bidirectional Long Short-Term Memory networks
(BiLSTMs) (Baziotis et al., 2017), Convolutional
Neural Networks (CNNs) (Zhang et al., 2015b), At-
tention Networks (Yang et al., 2016; Pergola et al.,
2021b), DenseLSTMs (Wu et al., 2018), NestedL-
STMs (Moniz and Krueger, 2017), Graph Neural
Networks (Zhang et al., 2019) and their combina-
tions (Wang et al., 2018; Zhu et al., 2021; Wan
et al., 2020), to name a few.
Zhang et al. (2015a) framed this task as text span
detection, where they used text spans to denote as-
pects. The same annotation scheme was employed
in (Li et al., 2018b), where intra-word attentions
were designed to enrich the representations of as-
pects and predict their polarities. Li et al. (2018c)
formalized the task as a sequence labeling problem
under a unified tagging scheme. Their follow-up
work (Li et al., 2019) explored BERT for end-to-
end ABSA. Peng et al. (2020) modified this task
by introducing opinion terms to shape the polarity.
A similar modification was made in (Zhao et al.,
2020) to extract aspect-opinion pairs. Position-
aware tagging was introduced to entrench the offset
between the aspect span and opinion term (Xu et al.,
2020). More recently, instead of using pipeline ap-
proaches or sequence tagging, Barnes et al. (2021)
adapted syntactic dependency parsing to perform
aspect and opinion expression extraction, and po-
larity classification, thus formalizing the task as
structured sentiment analysis.1567Disentangled representation learning Deep
generative models learn the hidden semantics of
text, of which many attempt to capture the inde-
pendent latent factor to steer the generation of text
in the context of NLP (Hu et al., 2017; Li et al.,
2018a; Pergola et al., 2019; John et al., 2019; Li
et al., 2020). The majority of the aforementioned
work employs V AE (Kingma et al., 2014) to learn
controllable factors, leading to the abundance of
V AE-based models in disentangled representation
learning (Higgins et al., 2017; Burgess et al., 2018;
Chen et al., 2018). However, previous studies
show that unsupervised learning of disentangle-
ment by optimising the marginal likelihood in a
generative model is impossible (Locatello et al.,
2019). While it is also the case that non-linear ICA
is unable to uncover the true independent factors,
Khemakhem et al. (2020) established a connection
between those two strands of work, which is of par-
ticular interest to us since the proposed framework
learns to approximate the true factorial prior given
few examples, recovering a disentangled latent vari-
able distribution on top of additionally observed
variables. In this paper, stance labels and aspect
spans are additionally observed on a handful of
data, which could be used as inductive biases that
make disentanglement possible.
Vaccine attitude detection Very little literature
exists on attitude detection for vaccination. In con-
trast, there is growing interest in Covid-19 corpus
construction (Shuja et al., 2021). Of particular in-
terest to us, Banda et al. (2021) built an on-going
tweet dataset that traces the development of Covid-
19 by 3 keywords: “coronavirus”, “2019nCoV”
and “corona virus”. Hussain et al. (2021) uti-
lized hydrated tweets from the aforementioned cor-
pus to analyze the sentiment towards vaccination.
They used lexicon-based methods (i.e., V ADER
and TextBlob) and pre-trained BERT to classify
the sentiment in order to gain insights into the
temporal sentiment trends. A similar approach
has been proposed in (Hu et al., 2021). Lyu et al.
(2021) employed a topic model to discover vaccine-
related themes in twitter discussions and performed
sentiment classification using lexicon-based meth-
ods. However, none of the work above constructed
datasets about vaccine attitudes, nor did they train
models to detect attitudes. Morante et al. (2020)
built the Vaccination Corpus (VC) with events, at-
tributions and opinions annotated in the form of
text spans, which is the only dataset available to usto perform attitude detection.
3 Methodology
The goal of our work is to detect the stance ex-
pressed in a tweet (i.e., ‘ pro-vaccination ’, ‘anti-
vaccination ’, or ‘ neutral ’), identify a text span that
indicates the concerning aspect of vaccination, and
cluster tweets into groups that share similar aspects.
To this end, we propose a novel latent representa-
tion learning model that jointly learns a stance clas-
sifier and disentangles the latent variables capturing
stance and aspect respectively. Our proposed Vac-
cine Attitude Detection ( VAD) model is firstly
trained on a large amount of unannotated Twitter
data to learn latent topics via masked Language
Model (LM) learning. It is then fine-tuned on a
small amount of Twitter data annotated with stance
labels and aspect text spans for simultaneously
stance classification and aspect span start/end po-
sition detection. The rationale is that the inductive
bias imposed by the annotations would encourage
the disentanglement of latent stance topics and as-
pect topics. In what follows, we will present our
proposed VADmodel, first under the masked
LM learning and later extended to the supervised
setting for learning disentangled stance and aspect
topics.
VADin the masked LM learning We insert a
topic layer into a pre-trained language model such
as ALBERT, as shown in Figure 2, allowing the
network to leverage pre-trained information while
fine-tuned on an in-domain corpus. We assume that
there is a continuous latent variable zinvolved in
the language model to reconstruct the original text
from the masked tokens. We retain the weights of
a language model and learn the latent representa-1568
tion during the fine-tuning. More concretely, the
topic layer partitions a language model into lower
layers and higher layers denoted as ψandθ, respec-
tively. The lower layers constitute the Encoder that
parameterizes the variational posterior distribution
denoted as q(z|ψ(w)), while the higher layers re-
construct the input tokens, which is referred to as
the Decoder.
The objective of V AE is to minimize the KL-
divergence between the variational posterior dis-
tribution and the approximated posterior. This
is equivalent to maximizing the Evidence Lower
BOund (ELBO) expressed as:
where q(z|ψ(w)) is the encoder and
p(w|z, ψ(w))is the decoder. Here,
w= [w, w], since the special classifi-
cation embedding wis automatically prepended
to the input sequence (Devlin et al., 2019), w
denotes the reconstructed input.
Following (Kingma and Welling, 2014), we
choose a standard Gaussian distribution as the prior,
denoted as p(z), and the diagonal Gaussian distri-
bution z∼ N (µ(ψ(w)), σ(ψ(w)))as the vari-
ational distribution. The decoder computes the
probability of the original token given the latent
variable sampled from the Encoder. We use the
Memory Scheme (Li et al., 2020) to concatenate
zandψ(w), making the latent representation com-patible for higher layers of the language model.
Then the latent presentation zis passed to θto
reconstruct the original text.
VADwith disentanglement of aspect and
stance One of the training objectives of vaccine
attitude detection is to detect the text span that
indicates the aspect and to predict the associated
stance label. Existing approaches rely on structured
annotations to indicate the boundary and depen-
dency between aspect span and opinion words (Xu
et al., 2020; Barnes et al., 2021), or use a two-stage
pipeline to detect the aspect span and the associ-
ated opinion separately (Peng et al., 2020). The
problem is that the opinion expressed in a tweet
and the aspect span often overlap. To mitigate this
issue, we instead separate the stance and aspect
from their representations in the latent semantic
space, that is, disentangling latent topics learned by
VADinto latent stance topics and latent aspect
topics. A recent study in disentangled representa-
tion learning (Locatello et al., 2019) shows that un-
supervised learning of disentangled representations
is theoretically impossible from i.i.d. observations
without inductive biases, such as grouping informa-
tion (Bouchacourt et al., 2018) or access to labels
(Locatello et al., 2020b; Träuble et al., 2021). As
such, we extend our model to a supervised setting
in which disentanglement of the latent vectors can
be trained on annotated data.
Figure 3 outlines the overall structure of VAD1569in the supervised setting. On the right hand side,
we show VADlearned from the annotated aspect
text span [w:w]under masked LM learning. The
latent variable zencodes the hidden semantics of
the aspect expression. We posit that the aspect span
is generated from a latent representation with a
standard Gaussian distribution being its prior. The
ELBO for reconstructing the aspect text span is:
where wdenotes the reconstructed aspect span.
Ideally, the latent variable zdoes not encode any
stance information and only captures the aspect
mentioned in the sentence. Therefore, the zfor the
language model on the right hand side is detached
and the reconstruction loss for [CLS] is set free.
On the left hand side of Figure 3, we train
VADon the whole sentence. The input to
VADis formalized as: ‘ [CLS] text’. Instead
of mapping an input to a single latent variable z,
as in masked LM learning of VAD, the input
is now mapped to a latent variable decomposing
into two components, [z, z], one for the stance
and another for the aspect. We use a conditionally
factorized Gaussian prior over the latent variable
z∼p(z|w), which enables the separation of
zandzsince the diagonal Gaussian is factorized
and the conditioning variable wis observed.
We establish an association between zandz
by specifying p(z|w)to be the encoder net-
work of q(z|w), since we want the latent se-
mantics of aspect span to encourage the disentan-
glement of attitude in the latent space. In other
words, the prior of zis configured as the approx-
imate posterior of zto enforce the association
between the disentangled aspect in sentence and
thede facto aspect. As a result, the ELBO for the
original text is written as
where wdenotes the reconstructed input text,
z|w∼ N (µ(ψ(w)), σ(ψ(w))). The KL-
divergence allows for some variability since there
might be some semantic drift from the original se-
mantics when the aspect span is placed in a longer
sequence.
The annotation of the stance label provides an
additional input. To exploit this inductive bias, weenforce the constraint that zparticipates in the
generation of [CLS] , which follows an approx-
imate posterior q(z|ψ(w )). We place the
standard Gaussian as the prior over z∼ N (0,I)
and obtain the ELBO
Since the variational family in Eq. 1 are Gaussian
distributions with diagonal covariance, the joint
space of [z, z]factorizes as q(z, z|ψ(w)) =
q(z|ψ(w))q(z|ψ(w))(Nalisnick et al., 2016).
Assuming zto be solely dependent on ψ(w),
we obtain the ELBO for the entire input sequence:
Note that the expectation term can be decomposed
into the expectation term in Eq. 3 and Eq. 4 accord-
ing to the decoder structure. For the full derivation,
please refer to Appendix A.
Finally, we perform stance classification and
classification for the starting and ending position
over the aspect span of a tweet. We use negative
log-likelihood loss for both the stance label and
aspect span:
where MLP is a fully-connected feed-forward net-
work with tanh activation, yis the predicted stance
label, yandyare the starting and ending position
of the aspect span. The overall training objective
in the supervised setting is:
L=L+L− L− L
4 Experiments
We present below the experimental setup and eval-
uation results.
4.1 Experimental Setup
Datasets We evaluate our proposed VADand
compare it against baselines on two vaccine attitude
datasets.
V AD is our constructed Vaccine Attitude Dataset.
Following (Hussain et al., 2021), we crawl tweets
using the Twitter streaming API with 60pre-
defined keywordsrelating to COVID-19 vaccines1570
(e.g., Pfizer ,AstraZeneca , and Moderna ). Our final
dataset comprises 1.9million English tweets col-
lected between February 7th and April 3rd, 2021.
We randomly sample a subset of tweets for anno-
tation. Upon an initial inspection, we found that
over97% of tweets mentioned only one aspect. As
such, we annotate each tweet with a stance label
and a text span characterizing the aspect. In total,
2,800 tweets have been annotated in which 2,000
are used for training and the remaining 800 are
used for testing. The statistics of the dataset is
listed in Table 1. The stance labels are imbalanced.
On the other hand, the average opinion length is
longer than the average aspect length, and is close
to the average tweet length. For the purpose of
evaluation on tweet clustering and latent topic dis-
entanglement, we further annotate tweets with a
categorical label indicating the aspect category. In-
spired by (Morante et al., 2020), we identify 24
aspect categoriesand each tweet is annotated with
one of these categories. It is worth mentioning that
aspect category labels are not used for training.
VC(Morante et al., 2020) is a vaccination corpus
consisting of 294 Internet documents about online
vaccine debate annotated with events, 210 of which
are annotated with opinions (in the form of text
spans) towards vaccines. The stance label is con-
sidered to be the stance for the whole sentence.
Those sentences with conflicting stance labels are
regarded as neutral. We split the dataset into a ra-
tio of 2:1 for training and testing. This eventually
left us with 1,162 sentences for training and 531
sentences for testing.Baselines We compare the experimental results
with the following baselines:
BertQA (Li et al., 2018c): a pre-trained language
model well-suited for span detection. With BertQA,
attitude detection is performed by first classifying
stance labels then predicting the answer queried
by the stance label. The text span is configured as
the ground-truth answer. We rely on its Hugging-
Face(Wolf et al., 2020) implementation. We em-
ploy ALBERT (Lan et al., 2020) as the backbone
language model for both BertQA and VAD.
ASTE (Peng et al., 2020): a pipeline approach
consisting of aspect extraction (Li et al., 2018c)
and sentiment labelling (Li et al., 2018b).
Evaluation Metrics For stance classification, we
use accuracy and Macro-averaged F1 score. For
aspect span detection, we follow Rajpurkar et al.
(2016) in adopting exact match (EM) accuracy of
the starting-ending position and Macro-averaged
F1 score of the overlap between the prediction and
ground truth aspect span. For tweet clustering, we
follow Xie et al. (2016) and Zhang et al. (2021)
and use the Normalized Mutual Information (NMI)
metric to measure how the clustered group aligns
with ground-truth categories. In addition, we also
report the clustering accuracy.
4.2 Experimental Results
In all our experiments, VADis firstly pre-trained
in an unsupervised way on our collected 1.9 million
tweets before fine-tuned on the annotated training
set from the V AD or VC corpora.
Stance Classification and Aspect Span Detection
In Table 2, we report the performance on attitude
detection. In stance classification, our model out-
performs both baselines with more significant im-
provements on ASTE. On aspect span extraction,
VADyields even more noticeable improvements,
with a 2.3%increase in F1 over BertQA on V AD,
and2.7%on VC. These results indicate that the
successful prediction relies on the hidden represen-
tation learned in the unsupervised training. The
disentanglement of stance and aspect may have
also contributed to the improvement.
Clustering To assess whether the learned latent
aspect topics would allow meaningful categoriza-
tion of documents into attitude clusters, we perform1571
clustering using the disentangled representations
that encode aspects, i.e., z. Deep Embedding
Clustering (DEC) (Xie et al., 2016) is employed as
the backend. For comparison, we also run DEC on
the aspect representations of documents returned
by BertQA. For each document, its aspect represen-
tation is obtained by averageing over the fine-tuned
ALBERT representations of the constituent words
in its aspect span. To assess the quality of clus-
ters, we need the annotated aspect categories for
documents in the test set. In V AD, we use the an-
notated aspect labels as the ground-truth categories
whereas in VC we use the annotated event types.
Results are presented in the lower part of Table 2.
We found a prominent increase in NMI score over
the baselines. Using the learned latent aspect top-
ics as features, DEC ( VAD) outperforms DEC
(BertQA) by 4.6%and1.9%in accuracy on V AD
and VC, respectively. We also notice that using
K-means as the clustering approach directly on the
BERT-encoded tweet representations gives worse
results compared to DEC. A similar trend is ob-
served on the NMI metric. The improvements are
shown visually in Figure 4 where the clustered
groups produced by VADare more identifiable.
In the absence of categorical labels, the perspective
expressed by each group can be inferred from the
constituent tweets. For example, the tweet ‘@user
Georgian nurse dies of allergic reaction after re-
ceiving AstraZeneca Covid19 vaccine’ lies in the
centroid of the red group, which relates to safety
concerns.
Cluster Semantic Coherence Evaluation The
semantic coherence is the extent to which tweets
within a cluster belong to each other, which is em-
ployed as an evaluation metric for cluster quality
evaluation in an unsupervised way. Recent work
of Bilal et al. (2021) found that Text Generation
Metrics (TGMs) align well with human judgement
in evaluating clusters in the context of microblog
posts. TGM by definition measures the similarity
between the ground-truth and the generated text.
The rationale is that a high TGM score means sen-
tence pairs are semantically similar. Here, two
metrics are used: BERTScore , which calculates the
similarity of two sentences as a sum of cosine simi-
larities between their tokens’ embeddings (Zhang
et al., 2020), and BLEURT , a pre-trained adjudica-
tor that fine-tunes BERT on an external dataset of
human ratings (Sellam et al., 2020). As in (Bilal
et al., 2021), we adopt the Exhaustive Approach
that for a cluster C, its coherence score is the aver-
age TGM score of every possible tweet pair in the
cluster:
f(C) =1
N/summationdisplayTGM(tweet,tweet).
Figure 5 shows the BERTScore and the BLEURT
score of V ADand baselines on two datasets. The
V ADshows consistent improvements across the
datasets. This indicates that tweets clustered us-
ing the latent aspect topics generated by V AD
are semantically more similar, thus validating the
assumption that disentangled representations are
more effective in bringing together tweets of a sim-
ilar gist.
Conditional Perplexity Few metrics have been
proposed to evaluate the quality of disentangled rep-
resentations (Pergola et al., 2021a). Therefore, we1572
adopt the language model perplexity conditioned
onzto evaluate the extent to which the disentan-
gled representation improves language generation
on held-out data. Perplexity is widely used in the
literature of text style transfer (John et al., 2019;
Yi et al., 2020), where the probability of the gen-
erated language is calculated conditioned on the
controlled latent code. A lower perplexity score
indicates better language generation performance.
Following John et al. (2019), we compute an esti-
mated aspect vector ˆzof a cluster kin the train-
ing set as
ˆz=/summationtextztweets in cluster k,
where zis the learned aspect vector of the i-th
tweet in the k-th cluster. For the stance vector z,
we sample one value per tweet. The stance vec-
tor is concatenated with the aspect vector ˆzto
calculate the probability of generating the held-out
data, i.e., the testing set. For the baseline mod-
els, we choose β-V AE (Higgins et al., 2017) and
SCHOLAR (Card et al., 2018). We train β-V AE
on the same data with βset to different values.
SCHOLAR is trained on tweet content and stance
labels. For both the baselines we use ELBO on the
held-out data as an upper bound on perplexity.
Figure 6 plots the perplexity score achieved by
all the methods. Our model achieves the lowest
perplexity score on both datasets. It managed
to decrease the perplexity value by roughly 200
compared to the baseline models. SCHOLAR out-
performs β-V AE under three settings of βvalue.
We speculate that this might be due to the in-
corporation of the class labels in the training of
SCHOLAR. Nevertheless, V ADproduces con-
genial sentences in aspect groups, with latent codes
tweaked to proxy centroids, showing that the dis-
entangled representation does capture the desiredfactor.
Ablations We conduct ablation studies to inves-
tigate the effect of semi-supervised learning that
uses the variational latent representation learning
approach and aspect-stance disentanglement on the
latent semantics. We study their effects on stance
classification and aspect span detection. The results
are reported in Table 3.
We can observe that on V AD without disentan-
gled learning or unsupervised pre-training results in
the degradation of the stance classification perfor-
mance. However, on VC, we see a slight increase in
classification accuracy without disentangled learn-
ing. We attribute this to the vagueness of the stance
which might cause the model to disentangle more
than it should be. On the aspect span detection task,
we observe consistent performance drop across all
metrics and on both datasets. In particular, with-
out the pre-training module, the performance drops
more significantly. These results indicate that semi-
supervised learning is highly effective with V AE,
and the disentanglement of stance and aspect serves
as a useful component, which leads to noticeable1573improvements.
5 Conclusions
In this work, we presented a semi-supervised model
to detect user attitudes and distinguish aspects of
interest about vaccines on social media. We em-
ployed a Variational Auto-Encoder to encode the
main topical information into the language model
by unsupervised training on a massive, unannotated
dataset. The model is then further trained under
a semi-supervised setting that leverages annotated
stance labels and aspect spans to induce the disen-
tanglement between stances and aspects in a latent
semantic space. We empirically showed the bene-
fits of such an approach for attitude detection and
aspect clustering over two vaccine corpora. Ab-
lation studies show that disentangled learning and
unsupervised pre-training are important to effective
vaccine attitude detection. Further investigations
on the quality of the disentangled representations
verify the effectiveness of the disentangled factors.
While our current work mainly focuses on short
text of social media data where a sentence is as-
sumed to discuss a single aspect, it would be inter-
esting to extend our model to deal with longer text
such as online debates in which multiple arguments
or aspects may appear in a single sentence.
Acknowledgements
This work was funded by the the UK Engineering
and Physical Sciences Research Council (grant no.
EP/T017112/1, EP/V048597/1). LZ is supported
by a Chancellor’s International Scholarship at the
University of Warwick. YH is supported by a Tur-
ing AI Fellowship funded by the UK Research and
Innovation (grant no. EP/V020579/1).
References1574157515761577A Derivation of the Decomposed ELBO
Unsupervised training is based on maximizing the
Evidence Lower Bound (ELBO):
E[logp(w|z, z, ψ(w))]
−KL[q(z, z|ψ(w))||p(z, z)],
where zis partitioned into zandz. Like standard
V AE (Kingma and Welling, 2014), the variational
distribution is a multivariate Gaussian with a diag-
onal covariance:
q(z, z|ψ(w)) =N(z, z|µ, σI),
where µ= [µ, µ]andσ= [σ, σ]. Since the
coveriance matrix is diagonal, zandzare uncor-
related. Therefore, the joint probability is decom-
posed into:
q(z, z|ψ(w)) =q(z|ψ(w))q(z|ψ(w)),
where q(z|ψ(w)) = N(z|µ, σ),ϕare the
variational parameters. The prior of [z, z]∼
N(z, z|0, I)can also be decomposed into the
product of p(z)andp(z), then the KL term be-
comes:
As for the decoder p(w|z, z, ψ(w)), the recon-
struction of each masked token and w are
independent from each other, i.e., they are not pre-
dicted in an autoregressive way. Therefore, the
joint probability is decomposed into:
p(w|z, z, ψ(w))
=p(w|z, z, ψ(w))p(w|z, z, ψ(w))
We customize the decoder network to make w
solely dependent on z, and obtain
EE[logp(w|z, ψ(w)) +
logp(w|z, ψ(w))]
Here, we omit ψ(w)for notational simplicity.
Given the supervision of annotated aspect spans,
the prior of zis constrained by q(z|ψ(w))
(a.k.a., the encoder of w), this will change the
KL term into:
and finally the ELBO is expressed as
E[logp(w|z, ψ(w))]
+E[logp(w|z, ψ(w))]
−KL[q(z|ψ(w))||p(z)]
−KL[q(z|ψ(w))||q(z|ψ(w))].B Data Collection and Preprocessing
We are qualified Twitter Academic Research API
users. We obtained the ethical approval for our
proposed research from the university’s ethics com-
mittee before the start of our work. We col-
lected tweets between February 7th and April 3rd,
2022 using 60 vaccine-related keywords. The
exhaustive list is: ‘covid-19 vax’ ,‘covid-19 vac-
cine’ ,‘covid-19 vaccines’ ,‘covid-19 vaccination’ ,
‘covid-19 vaccinations’ ,‘covid-19 jab’ ,‘covid-19
jabs’ ,‘covid19 vax’ ,‘covid19 vaccine’ ,‘covid19
vaccines’ ,‘covid19 vaccination’ ,‘covid19 vac-
cinations’ ,‘covid19 jab’ ,‘covid19 jabs’ ,‘covid
vax’,‘covid vaccine’ ,‘covid vaccines’ ,‘covid
vaccination’ ,‘covid vaccinations’ ,‘covid jab’ ,
‘covid jabs’ ,‘coronavirus vax’ ,‘coronavirus vac-
cine’ ,‘coronavirus vaccines’ ,‘coronavirus vacci-
nation’ ,‘coronavirus vaccinations’ ,‘coronavirus
jab’,‘coronavirus jabs’ ,‘Pfizer vaccine’ ,‘BioN-
Tech vaccine’ ,‘Oxford vaccine’ ,‘AstraZeneca
vaccine’ ,‘Moderna vaccine’ ,‘Sputnik vaccine’ ,
‘Sinovac vaccine’ ,‘Sinopharm vaccine’ ,‘Pfizer
jab’,‘BioNTech jab’ ,‘Oxford jab’ ,‘AstraZeneca
jab’,‘Moderna jab’ ,‘Sputnik jab’ ,‘Sinovac jab’ ,
‘Sinopharm jab’ ,‘Pfizer vax’ ,‘BioNTech vax’ ,‘Ox-
ford vax’ ,‘AstraZeneca vax’ ,‘Moderna vax’ ,‘Sput-
nik vax’ ,‘Sinovac vax’ ,‘Sinopharm vax’ ,‘Pfizer
vaccinate’ ,‘BioNTech vaccinate’ ,‘Oxford vacci-
nate’ ,‘AstraZeneca vaccinate’ ,‘Moderna vacci-
nate’ ,‘Sputnik vaccinate’ ,‘Sinovac vaccinate’ ,
‘Sinopharm vaccinate’ .
Only tweets in English were collected. Retweets
were discarded. For pre-processing, hyperlinks,
usernames and irregular symbols were removed.
Emojis and emoticons were converted to their lit-
eral meanings using an emoticon dictionary.
CHyper-parameters and Training Details
The dimensions of z,zandzare768,768and
32, respectively. For each tweet, the number of
samples from ϵ∼ N (0,I)is1. We modified
the LM-fine-tuning scriptfrom the HuggingFace
library to implement V ADin the masked LM
learning. We use default settings for the training1578script (i.e., Trainer in the HuggingFace library),
except for the batch size which is set to 128. The
data pre-processor for the masked language model
is the data collator for language modeling, which
provides the function of randomly masking the to-
kens. The tokenizer for the data collator is the
ready-to-use ALBERT tokenizer. For the pre-
trained language model (i.e., ALBERT) employed
in this model, we inherit the default setting from
theAlbertConfig class. We train V ADfor5
epochs on the un-annotated corpus.
In the supervised training of V AD, we use a
batch size of 64. The learning rate is initialized
to2e−5with a linear warm-up schedule. We
employ 5-fold training in which the training set is
split into 5subsets, of which 4 are used for training
and the rest is for validation at the end of each
epoch, and the final prediction is an ensemble of 5
independently-saved models. We train each model
for 5 epochs, which takes roughly 2hours on a
node of single Nvidia RTX 2080 GPU.
D Annotation Guidelines
We invited two annotators who are PhD students
and proficient in English to label each tweet with
a stance label and an aspect span. Each annotator
was instructed to answer four questions in a row.
The four questions are:
• What is the stance towards vaccination?
•What is the Aspect Span? (i.e., Events or
targets, it can be nouns, noun phrase, clause
or sentence with verbal predicates).
•What is the opinion term/span? It should be
opinion expressions, comprising both explicit
and implicit expressions of stance.
•What is the Aspect category? It should be one
of the pre-defined aspect categories (shown in
Table A1).
The annotators have the choice to skip some of the
questions if they find it difficult to answer. Tak-
ing the tweet ‘ Very grateful to those at Oxford.I’ve got my first #Covid19 vaccine. ’ as an exam-
ple, the annotators are expected to answer with:
‘Pro-vaccine ’, ‘I’ve got my first #Covid19 vaccine ’,
‘Very grateful to those at Oxford. I’ve got my first
#Covid19 vaccine ’, ‘2’. If an annotator chooses to
skip a tweet at any step of the process, this tweet
will be recorded as skipped and the annotator will
not be assigned with similar tweets.
We first had a trial run where each annotator
was asked to annotate the same set of tweets. Any
disagreement was recorded and discussed to refine
our annotation guideline in order to achieve consis-
tency between the annotators.
E Predefined Aspect Categories
Table A1 shows our pre-defined aspect categories,
partly inspired by (Morante et al., 2020). These
categories are only used in the evaluation of tweet
clustering results, not for training.1579Label Definition
1AstraZeneca: How health organisations/institution, communities, groups, individuals and
other entities position themselves towards vaccines
2 AstraZeneca: Explaining personal experiences with any aspect of vaccines
3AstraZeneca: The achievement that vaccines have brought (vaccines save lives, protect the
community, protect future generations)
4 AstraZeneca: The (adverse) side effects of vaccines: illnesses, symptoms, deaths
5 AstraZeneca: The immunity level provided by vaccines
6AstraZeneca: The economic effect of vaccination (less illnesses, less expenses for family
and society)
7 AstraZeneca: Discussing the personal freedom to choose in relation to vaccines
8AstraZeneca: Discussing the relation between vaccines and religion, conspiracy or moral
attitudes
9Pfizer or Moderna: How health organisations/institution, communities, groups, individuals
and other entities position themselves towards vaccines
10 Pfizer or Moderna: Explaining personal experiences with any aspect of vaccines
11Pfizer or Moderna: The achievement that vaccines have brought (vaccines save lives,
protect the community, protect future generations)
12 Pfizer or Moderna: The (adverse) side effects of vaccines: illnesses, symptoms, deaths
13 Pfizer or Moderna: The immunity level provided by vaccines
14Pfizer or Moderna: The economic effect of vaccination (less illnesses, less expenses for
family and society)
15 Pfizer or Moderna: Discussing the personal freedom to choose in relation to vaccines
16Pfizer or Moderna: Discussing the relation between vaccines and religion, conspiracy or
moral attitudes
17Other Brands or not mentioned: How health organisations/institution, communities,
groups, individuals and other entities position themselves towards vaccines
18Other Brands or not mentioned: Explaining personal experiences with any aspect of
vaccines
19Other Brands or not mentioned: The achievement that vaccines have brought (vaccines
save lives, protect the community, protect future generations)
20Other Brands or not mentioned: The (adverse) side effects of vaccines: illnesses,
symptoms, deaths
21 Other Brands or not mentioned: The immunity level provided by vaccines
22Other Brands or not mentioned: The economic effect of vaccination (less illnesses, less
expenses for family and society)
23Other Brands or not mentioned: Discussing the personal freedom to choose in relation
to vaccines
24Other Brands or not mentioned: Discussing the relation between vaccines and religion,
conspiracy or moral attitudes1580