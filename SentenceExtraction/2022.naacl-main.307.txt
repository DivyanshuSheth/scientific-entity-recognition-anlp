
Yanan Wu, Keqing He, Yuanmeng Yan, Qixiang Gao, Zhiyuan Zeng,
Fujia Zheng, Lulu Zhao, Huixing Jiang, Wei Wu, Weiran XuBeijing University of Posts and Telecommunications, Beijing, ChinaMeituan Group, Beijing, China
{yanan.wu,yanyuanmeng,gqx,zengzhiyuan,fujia_zheng,
zhaoll,xuweiran}@bupt.edu.cn
{hekeqing,jianghuixing,wuwei30}@meituan.com
Abstract
Detecting Out-of-Domain (OOD) or unknown
intents from user queries is essential in a task-
oriented dialog system. A key challenge of
OOD detection is the overconfidence of neural
models. In this paper, we comprehensively ana-
lyze overconfidence and classify it into two per-
spectives: over-confident OOD and in-domain
(IND). Then according to intrinsic reasons, we
respectively propose a novel reassigned con-
trastive learning (RCL) to discriminate IND
intents for over-confident OOD and an adaptive
class-dependent local threshold mechanism to
separate similar IND and OOD intents for over-
confident IND. Experiments and analyses show
the effectiveness of our proposed method for
both aspects of overconfidence issues.
1 Introduction
Out-of-domain (OOD) detection is a key compo-
nent of the task-oriented dialogue system(Gnewuch
et al., 2017; Akasaki and Kaji, 2017; Shum et al.,
2018; Tulshan and Dhage, 2019). It aims to de-
cide whether a user query falls outside the range
of predefined supported intents and avoid perform-
ing wrong operations (Lin and Xu, 2019; Xu et al.,
2020; Zeng et al., 2021a). Due to the complexity
of annotating OOD intents, most work focus on
unsupervised OOD detection where there is no la-
beled OOD data but only labeled in-domain (IND)
data (Xu et al., 2020). No prior knowledge about
OOD intents makes it challenging to identify these
unknown samples in the dialog system.
Existing unsupervised OOD detection methods
mostly follow the same framework: firstly learn
intent representations via labeled in-domain (IND)
data then employ detecting algorithms, such as
Maximum Softmax Probability (MSP) (HendrycksFigure 1: Examples of two kinds of overconfidence.
Figure 2: Number of error cases comparing over-
confident IND and OOD. Global threshold denotes the
best overall performance.
and Gimpel, 2017), Local Outlier Factor (LOF)
(Lin and Xu, 2019), Gaussian Discriminant Analy-
sis (GDA) (Xu et al., 2020) to compute the similar-
ity of features between OOD samples and IND sam-
ples. For example, Hendrycks and Gimpel (2017)
simply uses a fixed threshold on the IND classifier’s
probability estimate and predicts a query as OOD
only if its max logit is below the threshold. Lin and
Xu (2019) employs an unsupervised density-based
novelty detection algorithm, local outlier factor
(LOF) to detect OOD intents. Further, Zeng et al.
(2021a) proposes a supervised contrastive learning
objective to learn discriminative intent features.
However, these methods ignore the key chal-
lenge of OOD detection, over-confidence. Guo
et al. (2017); Liang et al. (2017, 2018) have the-
oretically proved that deep neural networks with
the softmax classifier are prone to produce highly4165over-confident posterior distributions even for such
abnormal OOD samples. In this paper, we de-
fine the over-confidence issue from two aspects.
(1) IND →OOD: Given an in-domain test sam-
ple, the pre-trained IND classifier predicts a lower
confidence score than a fixed thresholdand in-
correctly regards it as an OOD intent, which we
name as over-confident OOD . We argue it’s be-
cause IND classes have high semantic similarity
then scatter and lower the max confidence score.
For example, in Figure 1, the IND test query “can
you call me a different name” is wrongly detected
as OOD intent because its ground-truth IND label
change_user_name is similar to the other IND cat-
egories what_is_your_name andchange_ai_name .
Thus the query gets comparable probability scores
among the three IND classes, resulting in a lower
max probability score than the threshold. (2) OOD
→IND: Given an OOD test sample, the same clas-
sifier instead predicts a higher confidence score
than the threshold and wrongly regards it as an
IND, which we name as over-confident IND . The
reason is the spurious correlation between OOD
and IND intents, such as similar syntactic structure,
entities, etc. For example, the OOD query “please
clean the car windows” is classified into the IND
category smart_home because plausibly similar ex-
amples like “please lock the doors” also exist in this
category. The spurious correlation is frequent since
humans define OOD without a clear and standard
principle. Existing models (Lee et al., 2018; Ren
et al., 2019; Zheng et al., 2020; Xu et al., 2020)
mainly focus on the latter aspect over-confident
IND, but we find the former over-confident OOD
also makes a side effect on OOD detection. As
Figure 2 shows, as the threshold rises, the number
of negative OOD samples also increases which de-
notes the over-confident OOD issue gets worse but
the over-confident IND issue gets better. We need
to consider both two aspects of overconfidence.
In this paper, we propose a novel reassigned
contrastive learning (RCL) to discriminate intent
representations between semantically similar IND
categories and an adaptive class-dependent local
threshold mechanism to separate similar IND and
OOD intents. Specifically, for over-confident OOD,
we first construct hard contrastive pairs among eas-
ily misclassified IND types using a pre-trained in-
tent classifier. Then we train a new model to learndiscriminative intent representations for similar
IND categories via supervised contrastive learning
(Khosla et al., 2020; Gunel et al., 2020). We aim
to sample hard contrastive batches where anchors
and positives have the same class label but different
classifier outputs (hard positives), and anchors and
negatives have the same classifier output but differ-
ent class labels (hard negatives). For over-confident
IND, we propose an adaptive class-dependent lo-
cal threshold mechanism to separate similar IND
and OOD intents. Traditional detection methods
like MSP, GDA, Energy (Liu et al., 2020) use a
global threshold to identify the confidence score
of a test query, ignoring the difference between
each IND class with OOD samples. We aim to
adjust the class-dependent local threshold so that
semantically correlated OOD and IND classes have
a higher threshold to mitigate the model’s overcon-
fidence to IND.
Our contributions are three-fold: (1) We perform
a comprehensive study on the overconfidence issue
of OOD detection and analyze two-aspect reasons.
(2) We propose a novel reassigned contrastive learn-
ing (RCL) to discriminate IND intents for over-
confident OOD and an adaptive class-dependent
local threshold mechanism to separate similar IND
and OOD intents for over-confident IND. (3) Ex-
periments and detailed analyses demonstrate the
effectiveness of our proposed method for both as-
pects of overconfidence issues.
2 Related Work
OOD Detection Unsupervised models use only
IND data for OOD detection following the
threshold-based protocol, including modeling the
probability density (Pidhorskyi et al., 2018), re-
construction (Golan and El-Yaniv, 2018), using
classifier ensembles (Vyas et al., 2018; Shu et al.,
2017), Bayesian models (Malinin and Gales, 2018),
likelihood ratios (Ren et al., 2019). Note that all
these methods require a dev set of labeled OOD
intents to tune a fixed global threshold hyperpa-
rameter. We propose a more robust and efficient
local threshold mechanism both to improve OOD
performance and reduce the need for a large dev set
of labeled OOD data. Another type of OOD detec-
tion model aims to utilize a set of OOD data in the
training phase, including N+1 classifier (Fei and
Liu, 2016; Zhan et al., 2021), entropy regulariza-
tion (Zheng et al., 2020), adversarial augmentation
(Zeng et al., 2021c).4166
Contrastive Learning Recent contrastive learning
methods (Chen et al., 2020; He et al., 2020) have
proven effective to learn unsupervised representa-
tions for downstream tasks. Winkens et al. (2020);
Zeng et al. (2021b) combine cross-entropy loss
on labeled IND data and instance-wise contrastive
learning (CL) loss on unlabeled data (including
unlabeled IND and OOD intents). They require a
large amount of unlabeled corpus and can’t explic-
itly distinguish different intent types. Further, Zeng
et al. (2021a) uses supervised contrastive learning
(SCL) (Khosla et al., 2020) to learn discriminative
intent representations only using labeled IND data.
Compared to CL, SCL regards all the IND intents
from the same class as positive pairs and samples
from different classes as negative pairs. However,
we find intents within similar categories are still
easily misclassified (see Section E). Thus, we pro-
pose a simple but strong reassigned contrastive
learning (RCL) framework to give more penalty
on these easily-confused IND classes to explicitly
distinguish them. RCL aims to learn discriminative
intent representations for OOD detection. Zhuang
et al. (2019); Wang and Liu (2021) mines nega-
tives close to the anchor sample as hard negatives
by computing representation cosine similarity, but
RCL uses the model’s wrong predictions as super-
vised positives and negatives. Our method is more
accurate because estimating representation similar-
ity may be biased and we can construct both hard
positives and negatives.
3 Methodology
Figure 3 shows the overall architecture of our pro-
posed RCL and class-dependent local thresholdwhere RCL discriminates easily-confused IND in-
tents and local threshold separates similar IND and
OOD intents. We follow a two-stage framework:
first train an in-domain intent classifier in the train-
ing stage, then extract the intent feature of a test
sample and employ the detection methods in the
test stage.
3.1 Reassigned Contrastive Learning
Traditional models (Hendrycks and Gimpel, 2017)
use cross-entropy (CE) loss to train an IND intent
classifier which does not explicitly distinguish the
margins between IND categories. Later, Lin and
Xu (2019) and Zeng et al. (2021a) respectively
propose a large margin cosine loss (LMCL) and a
supervised contrastive learning (SCL) loss to mini-
mize intra-class variance and maximize inter-class
distance. However, we find IND intents within
similar categories are still easily misclassified (see
Section E). Therefore, we aim to give more penalty
on these easily-confused IND classes to learn dis-
criminative intent representations.
We first review the original contrastive learning
(CL) and supervised contrastive learning (SCL)
then introduce our RCL framework. Given an
IND sample xand its intent label y, we adopt
a BiLSTM (Hochreiter and Schmidhuber, 1997) or
BERT (Devlin et al., 2019) encoder to get the intent
representation z. Following Chen et al. (2020);
Zeng et al. (2021b), we formulate CL loss for a
positive pair of examples (i, j)as:
ℓ=−logexp (sim ( z, z)/τ)/summationtext⊮exp (sim ( z, z)/τ)
(1)
where ⊮∈ {0,1}is an indicator function4167evaluating to 1 if k̸=i.τdenotes a tempera-
ture parameter. The final loss is computed across
all positive pairs, both (i, j)and(j, i)in a mini-
batch of Nexamples. CL regards two augmentedviews of a sample as positive pairs and views of
different samples as negative pairs. Further, SCL
extends the positive set by adding views of differ-
ent samples from the same IND intent class and
vice versa. However, these methods ignore easily-
confused relations between semantically similar
IND classes and can’t separate them in the latent
space. Therefore, we add more penalty to these
easily-confused IND classes to learn discriminative
intent representations. Specifically, our proposed
reassigned contrastive learning (RCL) framework
includes three stages.
IND classifier training First, we train an initial in-
tent classification model Mon the labeled IND
dataset {(x, y)}using CE, and save its predic-
tions{ˆy}on the training IND datapoints. We
will use these outputs to train a more discriminated
model.
Confused-label pair contrasting Here we aim to
separate easily misclassified IND types. Thus we
use the Moutputs to obtain confused label pairs
of the training data. For example, if class A and
B have misclassified error cases, we use all the A
and B’s samples to construct contrastive batches.
Then we perform SCL on these batches to train
a new intent model Mfrom scratch. The intu-
ition is that we treat samples that have the same
class label but different classifier outputs as hard
positives, and samples that have the same classifier
output but different class labels as hard negatives.
We display an example as Figure 4. Essentially,
we restrict the new model to focus on misclassi-
fied intent classes by adding hard positives and
negatives, further to learn discriminative intent rep-
resentations. Different from existing hard CL work
(Zhuang et al., 2019; Wang and Liu, 2021) which
only consider close negatives as hard negatives us-
ing representation similarity, RCL uses the model’s
wrong predictions as supervised positives and neg-
atives. Our method is more accurate because esti-
mating representation similarity may be biased and
we can construct both hard positives and negatives.
We also perform SCL on other clean IND types.
In the experiments, we iteratively repeat the two
processes for 5 epochs.
Global contrasting Apart from the confused label
pairs, we also employ SCL on all the IND samples
to avoid knowledge forgetting. Following Zeng
et al. (2021a), we regard views of different samples
from the same IND intent class as positives and
views of different samples from the different IND
intent class as negatives. Finally, we use CE to
fine-tune the model M. In the experiments, we set
the training epoch of SCL and CE to 10 and 20.
3.2 Adaptive Class-Dependent Local
Threshold
Previous detection methods usually use a global
threshold to identify the confidence score of a test
query, ignoring the difference between individual
IND classes with OOD samples. For example, if a
test OOD query is similar to an IND type, it may
obtain a high confidence score on this IND category
and be wrongly regarded as IND. Therefore, we
aim to set adaptive class-dependent local thresholds
to avoid over-confident IND.
Previous methods using global threshold (Xu
et al., 2020; Zeng et al., 2021a) first compute the
max confidence scores of all the OOD and IND
intents on the dev set, like max probability score,
then adjust the threshold to maximize OOD F1 on
the dev set. Notice it’s a general and standard set-
ting where a few labeled OOD data exists in the
dev set for hyperparameter tuning for the OOD de-
tection task.For the local threshold, we input all
OOD and IND queries to the pre-trained classifier
and then get the confidence scores belonging to
each IND type. Here we can use existing detection4168
methods to get confidence scores, such as MSP,
GDA, Energy, etc. Taking MSP as an example, we
get probability scores of all the intents. Then we
group all the OOD samples into the correspond-
ing IND type according to the max probability. So
in each group, we have both OOD and IND in-
tents and learn the class-dependent threshold by
maximizing OOD F1 on each group. If no OOD
sample is grouped into an IND type, we simply
select the global threshold as the local threshold for
this IND type. For inference, we select the local
threshold of corresponding IND category where
the test query gets the max probability score and
predict it as OOD if the score is below the local
threshold, Otherwise IND. Note that tuning local
threshold doesn’t increase too much computation
cost but only multiple judgments and no extra cost
in the inference. Local threshold achieves the best
performance on CLINC and Snips even only using
20 OOD intents and is robust to different datasets
and different number of OOD intents.
4 Experiments
4.1 Datasets
We perform experiments on three public bench-
mark OOD datasets, including CLINC-Full,
CLINC-Small (Larson et al., 2019) and Snips
(Coucke et al., 2018). We show the detailed statis-
tic of these datasets in Table 1. Snips is a personal
voice assistant dataset which contains 7 types of
user intents across different domains. We randomly
sample two classes among all classes in Snips, re-
garding them as OOD classes and the rest as IND
classes. CLINC-Full and CLINC-Small both con-
tain 150 IND intents across 10 domains. CLINC-
Full has 100 training samples for each IND type,
while CLINC-Small contains 50. We follow the
standard dataset split Larson et al. (2019) and use
the collected OOD test queries for evaluation. Note
that all the datasets we used have a fixed set of
labeled OOD data but we don’t use it for training.We notice some work (Zhang et al., 2021) use a
different split in CLINC-Full dataset where they
sample 25%, 50%, 75% of all IND classes as IND,
the other IND classes as OOD. The simulated split
makes OOD data similar to IND data which class
clusters are more compact thus get higher metrics.
In this paper, we mainly follow the standard dataset
split unless otherwise stated. For fair comparison,
we also perform the same dataset split 25%, 50%,
75% in Table 3 and Table 10.
4.2 Metrics
We report both OOD metrics: Recall and F1-score
(F1) and in-domain metrics: F1-score (F1). Since,
we aims to improve the performance of detecting
out-of-domain intents from user queries, OOD Re-
call and F1 are the main evaluation metrics in this
paper.
4.3 Baselines
In training stage, we compare RCL with CE and
SCL. In detection stage, we compare local thresh-
old with global threshold. To verify the generaliza-
tion of our proposed models, we use three OOD de-
tection algorithms MSP (Maximum Softmax Proba-
bility)(Hendrycks and Gimpel, 2017), GDA (Gaus-
sian Discriminant Analysis)(Xu et al., 2020) and
Energy(Ouyang et al., 2021). Besides, we com-
pare our models with the following state-of-the-art
baselines, OpenMax(Bendale and Boult, 2016a),
DeepUnk(Lin and Xu, 2019), Energy(Ouyang et al.,
2021), SCL(Zeng et al., 2021a) and ADB(Zhang
et al., 2021). We provide a more comprehensive
comparison and implementation details of these
models in the Appendix.
4.4 Implementation Details
To conduct a fair comparison, we follow a simi-
lar evaluation setting as (Zeng et al., 2021a) and
(Zhang et al., 2021). We use the public pre-trained
GloVe embeddings (Pennington et al., 2014) and
BERT-uncased (Devlin et al., 2019) (with 12-layer
transformer, implemented in PyTorch) to embed
tokens. We set the learning rate to 1e-03 for LSTM
and 2e-05 for BERT. To speed up the traning proce-
dure and achieve better performance, we freeze all
but the last transformer layer parameters of BERT.
We use Adam optimizer (Kingma and Ba, 2014)
to train our model and set the dropout rate to 0.5.
We use the best F1 scores on the development set
to calculate the MSP, GDA and Energy thresholds
adaptively. Each result of the experiments is tested4169
for 10 times under the same setting and reports the
average value. In the training stage, for our model,
we conduct 5 epochs of confused-label pair con-
trasting on designative batches of IND data, and
then 10 epochs of global contrasting on randomly
sampled IND data. Finally, we used CE to finetune
the previous model with the epoch to 20. For the
baselines in Table 2, we set the training epoch to
20 for CE and 15 for SCL. For fair comparison,
we adopt the same data augmentation method as
(Zeng et al., 2021a). Specifically, we apply adver-
sarial attack to generate pseudo positive samples
to increase the diversity of views for contrastive
learning. The training time for CE is about 1.6
minutes using Glove+LSTM, and 12 minutes using
BERT. The training stage of our model lasts about
2 minutes using Glove+LSTM, and 15 minutes
using BERT on single Tesla T4 GPU (16 GB of
memory) in CLINC-Full dataset which has 15,000
training samples. And the test stage of our model
lasts about 1 second using Glove+LSTM, and 3
seconds using BERT. We have similar training time
with SCL. And the test time of RCL is the same as
that of CE and SCL.
4.5 Main Results
Table 2 displays our experimental results on
datasets of CLINC-full and Snips with three dif-
ferent OOD detection algorithms: MSP, GDA and
Energy. We show similar results on CLINC-Smalldataset in the Appendix Table 7. From Table 2, we
can make the following observations.
Our method achieves the best results un-
der all detection algorithms. Using RCL+Local
threshold significantly outperforms all the base-
lines under different OOD detection algorithms.
Specifically, our method achieves 10.44%, 5.84%,
4.20% improvements over SCL+Global threshold
on OOD F1 under three OOD detection algorithms
on CLINC-full dataset and 7.30%, 7.64% and
7.49% on Snips dataset. We also observe that F1
score of IND classification with our approaches
can keep comparable or slightly outperform the
baselines, showing that RCL and class-dependent
local threshold effectively improve OOD detection
without harming the performance of IND classifi-
cation. We show similar results on CLINC-Small
dataset in the Appendix Table 7.
RCL consistently outperforms CE and SCL.
On CLINC-Full, RCL achieves 4.73%, 4.57% and
4.18% improvements over SCL on OOD F1 under
three OOD detection settings and 4.77%, 4.97%
and 4.69% on Snips dataset, respectively. It demon-
strates that RCL can stably discriminate the rep-
resentation space by separating easily-confused
classes and thus improve the performance of OOD
detection. We also find compared with local thresh-
old, RCL improved more significantly on global
threshold. We argue this is due to the local thresh-
old has alleviated part of overconfidence problem.
Local threshold consistently outperforms
global threshold. We find the local threshold con-
sistently wins the global one with a significant mar-
gin, especially in MSP. We argue MSP suffers from
more serious over-confident IND issue than GDA
and energy. This reveals that the local threshold can
alleviate the over-confident IND issue by assigning
an adaptive threshold for each IND class.
Comparing with previous baselines. To make a4170
fair comparison with previous baselines, we follow
the same setting as Zhang et al. (2021). Specifically,
we use the BERT as the backbone of the model,
and sample 25%, 50%, 75% or 100% (Full) classes
of the CLINC-Full dataset as the IND classes,
the other as OOD. From Table 3 and 10 (in the
Apendix), we can observe that our approach out-
performs previous baselines on F1 scores of both
OOD detection and IND classification. We achieve
4.56%, 3.51%, 4.03%, and 5.51% performance
gain on OOD F1 for the 25%, 50%, 75% and Full
settings.
5 Analysis
5.1 Analysis of IND Representations
To analyse how our RCL method affects the repre-
sentation space and improves the performance of
OOD detection, we perform a statistical analysis of
the intra-class variance within each class as well as
the inter-class distance between multiple classes.
RCL leads to smaller intra-class variance. To
calculate the intra-class variance, we first compute
the class center by averaging all samples representa-
tion corresponding to same class, then we calculate
the variance of all samples to corresponding class
center as the corresponding intra-class variance. In
Table 4, we show the intra-class variance statistics
among all classes with different training strategies:
CE, SCL and our proposed RCL. We can find that
all of the minimum, median, mean and maximum
values of our approach are lower than CE and SCL,
demonstrating that the RCL makes the representa-
tions within a single class tighter.
RCL leads to larger inter-class distance. We
calculate the inter-class distance by averaging the
euclidean distance from the center class to its K
nearest classes. For each class, we take the class
center by averaging all representations that belong
to this class. Figure 5 show that our RCL approach
consistently obtains larger inter-class distance com-
pared to CE and SCL. This phenomena shows that
our approach improves the OOD detection perfor-
mance by separating among classes while main-
taining intra-class high cohesion. It effectively im-
proves the uniformity of the representation space.
5.2 Analysis of Confusing IND Categories
To further verify the effect of RCL on easily-
confused classes, we select 4 label pairs that are
easily confused by the baseline model ( change user
name v.s.change ai name ,what is your name v.s.
user name ,change speed v.s.play music , and re-
wards balance v.s.redeem rewards ). In addition,
we also select one label pair that is semantically un-
related ( change user name v.s.payday ). For each
class pair, we compare the inter-class of models
that are trained with CE, SCL and our RCL.
We can observe from the group that training
with RCL greatly increases the inter-class distance
between confusable classes in Table 5. Take the
first class pair as an example, our RCL achieves
57% gain of inter-class distance over the SCL base-
line, while the SCL only achieves 9% gain based
on CE. On the other hand, when comparing be-
tween the group 1 and 2, we can conclude that our
method works better on pushing away confusable
class pairs, while for semantically unrelated ones,
the effect is not obvious (+ 57% v.s. + 2.6%).
5.3 Effect of Local Threshold
As we discussed above, setting a general global
threshold for OOD detection is a straightforward4171
idea and the common practice in reality. How-
ever, it can not be applied to the situation where
the variance of each IND class is various. If the
global threshold is not suitable for some specific
IND classes, the probability of true OOD samples
may exceed the global threshold, resulting in over-
confident IND samples.
To show the effect of class-dependent local
threshold, we randomly select 20 IND classes, and
give the mean softmax probability of the IND sam-
ples of each class as well as the OOD samples
that have the same class with maximum softmax
probability (i.e., these samples may be misclas-
sified to this IND class or correctly identified as
OOD, depending on the threshold). Then, we give
the global threshold and the class-dependent local
threshold for each IND class. For simplicity, we
only show the mean value but variance. Note that
the threshold between IND and OOD means most
of the judgments are correct, but not necessarily all
of them. We show half of results in Figure 6 and
the rest in the Appendix(Figure 10).
For IND classes (1) - (4), the averaged maxi-
mum softmax probabilities of OOD samples are all
beyond the threshold, indicating that a large pro-
portion of the OOD samples are over-confident and
will be classified to the corresponding IND class.
However, with our class-dependent local threshold,
the threshold is greater than the global threshold
and can distinguish the IND and OOD samples
more precisely.
For IND classes (5) - (6), the global threshold
is lucky to distinguish the IND and OOD samples.
However, we find these classes only make up a
small proportion of all IND classes (about 20%
since only 2 classes among 10 belong to this case).
For IND classes (7) - (10), we find even the av-
eraged maximum softmax probability of IND sam-
ples is below the global threshold. It means that
these IND classes can be easily confused with other
semantically related IND classes, and thus degrades
their maximum softmax probabilities, resulting in
over-confident OOD samples. In contrast, our lo-
cal threshold can automatically select the proper
threshold, adaptively degrading the threshold cor-
respondingly so that the threshold can exactly sep-
arate the IND and OOD samples.
5.4 Effect of Development Set Size
Figure 7 shows the effect of development set size.
Using a small amount of OOD samples in devel-
opment set to get a more suitable threshold is in-
evitable in OOD detection task. To show the ef-
fect of development set size, we randomly choose
development data with a certain proportion from
CLINC-Full OOD labeled development set and use
the original test set for evaluation. We use the
LSTM+Energy and LSTM+GDA settings.
Compare local and global thresholds. We
find that the local threshold consistently outper-
forms global threshold with a significant margin,
regardless of the OOD detection methods and train-
ing strategies we applied. Specifically, the per-
formance drops are -4.5%(-2.8%), -10.5%(-4.4%)
and -22.8%(-13.4%) over global(local) thresholds
with three training strategies, respectively. Besides,
we also find that the CE+Global collapses in per-
formance when there are only 20 samples in dev
set, while CE+Local is much better. We specu-
late that this phenomenon occurs because the OOD
samples in the CLINC-Full dataset are diverse and
the global threshold tends to overfit the data. It
confirms that our proposed local threshold method
can alleviate the reliance on development size by4172
assigning a specific threshold for each class.
Compare RCL with other training strategies.
We find that the RCL consistently outperforms SCL
and CE. Specifically, under CE, SCL and RCL, the
performance drops are -22.8%, -10.5% and -4.5%,
respectively. Besides, with the decrease of develop-
ment data size, the corresponding difference gradu-
ally increases. It demonstrates that RCL can effec-
tively relieve the dependence on development size
by separating easily misclassified classes.
We also observe that in the range of 40-100, the
performance of RCL hardly degrades. To be more
specific, when only 40 OOD labeled data provided,
the OOD F1 score of RCL+Local threshold model
is still 74.58(-0.74%). And even when only 20
OOD labeled data are available(about 0.13% train-
ing data), our proposed model still outperforms
the best baseline(SCL+Global threshold) with 100
OOD labeled data by 1.35%. This reveals that our
model is more robust and less dependent on de-
velopment set size. And the result of our model
is significantly improved under four datasets fur-
ther proves that our proposed methods have strong
robustness and generalization capability.
5.5 Analysis of Error Types
In order to explore the effect of our method on
different error types. We divide all the error sam-
ples into three categories: confusion between
IND(IND<->IND), over-confident OOD (IND<-
>OOD) and over-confident IND (OOD<->IND).
Figure 8(a) indicates that RCL can achieve con-
sistently improvements in all the three error types.
Figure 8(b) indicates that local threshold outper-
forms global threshold both in error of IND<->IND
and OOD->IND. While greatly reducing OOD-
>IND errors, local threshold inevitably increases
IND->OOD errors (explained by Figure 2). We
hypothesize this is due to the high semantic sim-
ilarity between IND classes and labeling noise in
dataset, which can be mitigated by RCL(see Table
6). We will leave more possible solutions for future
work. Combined with Table 6, compared to global
threshold, our local threshold can obtain smaller
overall errors. In general, local threshold is better
for the overall performance.
Table 6 displays the comparison between RCL
and local threshold. We find our RCL and lo-
cal threshold both outperform MSP baseline and
RCL+local threshold achieves the best perfor-
mance. Comparing RCL and local threshold, RCL
targets at IND->OOD errors (from 156 to 122) for
over-confident OOD, while local threshold helps
reduce OOD->IND errors (from 576 to 378) for
over-confident IND. Besides, they both help reduce
overall IND&OOD errors. On the other hand, the
performance improvement on OOD detection al-
ways helps IND classification.
6 Conclusion
In this paper, we focus on the overconfidence issue
of unsupervised OOD detection. We find the rea-
sons for overconfidence arise from two aspects: (1)
IND classes have high semantic similarity. (2) IND
and OOD intents have spurious correlations. Ac-
cording to the two reasons, we respectively propose
a novel reassigned contrastive learning (RCL) to
discriminate IND intents for over-confident OOD
and an adaptive class-dependent local threshold
mechanism to separate similar IND and OOD in-
tents for over-confident IND. We perform extensive
experiments and comprehensive analyses to demon-
strate the effectiveness of our approach. We hope
to provide new guidance for future work.
Acknowledgements
We thank all anonymous reviewers for their helpful
comments and suggestions. This work was par-
tially supported by National Key R&D Program of
China No. 2019YFF0303300 and Subject II No.
2019YFF0303302, DOCOMO Beijing Communi-
cations Laboratories Co., Ltd, MoE-CMCC "Artifi-
cal Intelligence" Project No. MCM20190701.4173References4174
A Comparison of CL, SCL and RCL
Contrastive learning (CL) methods (Chen et al.,
2020; He et al., 2020) have been proven effective to
learn unsupervised representations for downstream
tasks. Winkens et al. (2020); Zeng et al. (2021b)
propose to apply contrastive learning (CL) to OOD
detection task. They first perform CL on unlabeled
data (including unlabeled IND and OOD intents) to
learn OOD representations, then use cross-entropy
loss on labeled IND data to learn an IND intent
classifier. But the unlabeled data is not always
available. More importantly, CL can only inde-
pendently learn the OOD and IND representations
(because the CL loss is built in an instance-wise
way), but not explicitly distinguish different in-
tent types in a class-wise way. Further, Zeng et al.
(2021a) uses supervised contrastive learning (SCL)
(Khosla et al., 2020) to learn discriminative intent
representations only using labeled IND data. Com-
pared to CL, SCL regards all the IND intents from
the same class as positive pairs and samples from
different classes as negative pairs. SCL aims to
learn tight intent representations for each intent
type and tries to distinguish different intent types.
However, we find intents within similar categories4175
are still easily misclassified (see Section E). Intu-
itively, these easily-confused IND classes can be
regarded as hard examples (Zhuang et al., 2019) for
existing CL-based methods. Inspired by the idea,
we propose a simple but strong reassigned con-
trastive learning (RCL) framework to give more
penalty on these easily-confused IND classes to ex-
plicitly distinguish them. The main difference is the
confused-label pair contrasting process (we provide
an example to show how to construct hard positives
and negatives in Figure 4) and please see details
in the Confused-label pair contrasting section(line
241-267). Generally, RCL aims to learn discrim-
inative intent representations for OOD detection,
especially for these easily-confused intent classes.
Compared to Zhuang et al. (2019); Wang and Liu
(2021), these work only mines negatives close to
the anchor sample as hard negatives by computing
representation cosine similarity, but RCL uses the
model’s wrong predictions as supervised positives
and negatives. Our method is more accurate be-
cause estimating representation similarity may be
biased and we can construct both hard positives
and negatives. Note that RCL only increases the
training cost for a little but requires no extra infer-
ence budget and uses the same model size as SCL.
Please see the following section for details.
B Comparison of time complexity and
space complexity
We discuss the time and space complexity of RCL
and Local threshold in Table 8 and Table 9. In terms
of time complexity, we set the epoch of SCL and
RCL to 15. The training time for RCL is about 15
minutes using BERT in CLINC-Full dataset which
has 15,000 training samples. RCL have similar
training time with SCL. And the test stage of global
threshold lasts about 3 seconds using BERT. The
local threshold has almost the same test time as the
global threshold, while the performance can even
be increased by 9%. From the perspective of space
complexity, RCL and SCL utilize the same encoder
structure. The size of the model parameters of RCL
is equal to that of SCL. Besides, the global thresh-
old and the local threshold are only the differences
of the algorithm, and there are no extra parameters.
C Algorithm
We show the training procedure of RCL in Algo-
rithm 1. E,EandEare the training epochs of
confused-label pair contrasting, global contrasting
and cross-entropy classification processes, respec-
tively. In practice, we set E,EandEto 5, 10
and 20, respectively. nis the number of training
samples. First, we construct a set of confused la-4176Algorithm 1 : Reassigned Contrastive Learning
Input: training dataset D={(x, y)}, Batch size N, training epoch E,EandE, initial intent
classification model’s predictions D={(x,ˆy)}
Output: a new intent classification modelconstruct confused label pairs set P={(y,ˆy)|y∈D,ˆy∈D, y̸= ˆy}and clean labels set
S={y|y/∈P}forepoch = 1 to Edo ▷Confused-label pair contrasting sample confused mini-batch ˆB={{(x, yorˆy))|(y,ˆy)∈P}}fromD sample clean mini-batch B={(x, y)|y∈S}fromD iteratively compute supervised contrastive loss on ˆBorBend forforepoch = 1toEdo ▷Global contrasting random sample batches B={(x, y)}fromD compute supervised contrastive lossend forforepoch = 1toEdo random sample batches B={(x, y)}fromD compute cross-entropy lossend for
bel pairs by combining the ground truth labels y
and predicted labels ˆyof the training data. Taking
Figure 4 as an example, (A, B)is one of confusing
label pairs in P.mis the number of confusing
label pairs. And the remaining labels that never
confused with other labels, called clean labels, are
collected in the set S.kis the number of clean
labels. Then, we sample confused mini-batch ˆB
following Prestrainedly. Note that a mini-batch
ˆBwill only contain the samples with ground truth
yorˆy. We also sample clean mini-batch Bfol-
lowing Srestrainedly. Different from the confused
mini-batch, a clean mini-batch Bcan contain any
sample whose label belongs to S. We will compute
the supervised contrastive loss iteratively, on con-
fused mini-batch or clean mini-batch. Apart from
confused-label pair contrasting, we also employ
global contrasting by randomly sampling batches
on all IND samples to avoid knowledge forgetting.
Finally, we compute cross-entropy loss to fine-tune
the model.
D Baselines
We compare many types of unsupervised OOD
detection models. For feature extractor, we use
LSTM(Long Short Term Memory)(Hochreiter and
Schmidhuber, 1997) or BERT(Bidirectional En-
coder Representations from Transformers)(Devlin
et al., 2019). For training objection, we com-
pare RCL with CE and SCL. For detection algo-rithms, to verify the generalization of our proposed
models, we use MSP(Maximum Softmax Probabil-
ity)(Hendrycks and Gimpel, 2017), GDA(Gaussian
Discriminant Analysis)(Xu et al., 2020) and En-
ergy(Ouyang et al., 2021). Besides, we compare
our models with the following state-of-the-art base-
lines, OpenMax(Bendale and Boult, 2016a), Deep-
Unk(Lin and Xu, 2019), Energy(Ouyang et al.,
2021), SCL(Zeng et al., 2021a), ADB(Zhang et al.,
2021). We supplement the relevant baseline details
as follows:
MSP (Maximum Softmax Probability)(Hendrycks
and Gimpel, 2017) applies a threshold on the max-
imum softmax probability. We use the best F1
scores on the validation set to calculate the thresh-
old adaptively.
GDA (Gaussian Discriminant Analysis)(Xu et al.,
2020) is a generative distance-based classifier for
out-of-domain detection with Euclidean space. It
estimates the class-conditional distribution on fea-
ture spaces of DNNs via Gaussian discriminant
analysis to avoid over-confidence problems and use
Mahalanobis distance to measure the confidence
score of whether a test sample belongs to OOD.
Energy (Ouyang et al., 2021) maps a sample xto a
single scalar called the energy . We use the thresh-
old on the energy score to consider whether a test
query belongs to OOD.
OpenMax (Bendale and Boult, 2016b) is an open
set detection method in computer vision, we adapt4177
it for OOD. We firstly use the CE loss to train a
classifier on in-domain intents, then fit a Weibull
distribution to the classifier’s output logits.
DeepUnk (Lin and Xu, 2019) learns the deep in-
tent features with the margin loss and detects the
unknown intent with local outlier factor.
SCL (Zeng et al., 2021a) uses a supervised con-
trastive learning objective to learn discriminative
intent features. We conduct many experiments and
from multiple perspectives prove that our method
can consistently outperform SCL.
ADB (Zhang et al., 2021) learns adaptive decision
boundary using a loss function to balance both the
empirical risk and the open space risk. It is still a
time-consuming process. Compare with ADB, our
method can achieve the best performance.
E IND Confusion Matrix
To demonstrate how our proposed RCL approach
improves the performance by decreasing the num-
ber of error cases, we show the confusion matrix
among 10 IND classes as well as the unseen OOD
class. Specially, we pick 10 easily-confused classes
by the baseline model as the IND classes, and show
the confusion matrices of CE, SCL and RCL in Fig-
ure 9. From the figure, we can make the following
observations.
On the one hand, we find the confusion of easily-
confused IND classes is significantly mitigated.
Take the beginning four IND classes change user
name (a),user name (b),change ai name (c) and
what is your name (d) as an example, when train-
ing with CE, there are totally 34 misclassified sam-
ples. However, after applying our RCL approach,
the number misclassified samples decreases to 11,
which is a 68% reduction. It indicates that the con-
fusion among those semantically close IND classes
is effectively alleviated by our RCL training strat-
egy.
On the other hand, we focus on the confusion
between the unseen OOD and the IND classes. The
last row of the confusion matrix indicates the over-
confident IND (truly OOD sample, but predicted as
IND), while the last column of the confusion matrix
indicates the over-confident OOD (truly IND sam-
ple, but predicted as OOD). We can find that our
RCL model reduces the number of over-confident
IND samples by 69.6% and 70.0% compared to
the CE and SCL models, respectively. Meanwhile,
our RCL model also reduces the number of over-
confident OOD samples by 60.0% and 47.4% com-
pared to the CE and SCL models, respectively. This
phenomena proves that our RCL model improves
the OOD detection performance through solving
the over-confident IND and OOD issues.
F Effect of Local Threshold
Figure 10 shows the result of the additional 10
IND classes. Limited by the degree of semantic
similarity between OOD and IND, there may be
no OOD samples on some classes. In this case, we
will set the local threshold to be the same as the
global threshold, as IND class (3).
For IND classes (1), (6), (7) and (8), both the4178global threshold and local threshold are between
the mean softmax probability of the IND samples
and OOD samples. Analyze with specific exam-
ples, we find that the probability of OOD samples
in (6) is more concentrated on small probability val-
ues, while (7) and (8) have greater variance. Com-
pared with the global threshold, the local threshold
can better alleviate the over-confident problem by
choosing a more appropriate threshold boundary.
For IND classes (2), (4) and (5), the mean maxi-
mum softmax probabilities of OOD samples are all
beyond the global threshold. For category (2), the
local threshold falls exactly between IND and OOD
while global does not. For (4) and (5), although
both the local threshold and the global threshold
are below OOD, it is clear that the local threshold
is more reasonable.
For IND classes (9) and (10), both the averaged
max softmax probability of IND and OOD are
lower than the global threshold, which means that
a large portion of IND samples will be misclas-
sified as OOD. On the contrary, our local thresh-
old method can adaptively select more appropriate
thresholds, which largely eliminates the problem
of overconfident OOD.4179