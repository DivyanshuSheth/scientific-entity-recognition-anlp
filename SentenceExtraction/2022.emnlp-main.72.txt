
Changqun Li, Linlin Wang, Xin Lin, Gerard de Melo, Liang HeEast China Normal UniversityHasso Plattner Institute / University of Potsdam
Abstract
Succinctly summarizing dialogue is a task of
growing interest, but inherent challenges, such
as insufficient training data and low informa-
tion density impede our ability to train abstrac-
tive models. In this work, we propose a novel
curriculum-based prompt learning method with
self-training to address these problems. Specif-
ically, prompts are learned using a curriculum
learning strategy that gradually increases the
degree of prompt perturbation, thereby improv-
ing the dialogue understanding and modeling
capabilities of our model. Unlabeled dialogue
is incorporated by means of self-training so
as to reduce the dependency on labeled data.
We further investigate topic-aware prompts to
better plan for the generation of summaries. Ex-
periments confirm that our model substantially
outperforms strong baselines and achieves new
state-of-the-art results on the AMI and ICSI
datasets. Human evaluations also show the su-
periority of our model with regard to the sum-
mary generation quality.
1 Introduction
As billions of people engage in instant messag-
ing and other forms of interaction, there is no-
table interest in techniques to process and dis-
till recorded dialogues into concise and natural
summaries (Gurevych and Strube, 2004; Murray
et al., 2006). The inherent challenges of the di-
alogue make abstractive dialogue summarization
particularly difficult. First, the available labeled
data is substantially smaller than news summa-
rization data, e.g., 137 meetings in AMI (Mc-
Cowan et al., 2005) vs. 312K articles in CNN/Daily
Mail (Hermann et al., 2015). Second, everyday di-
alogue involves a dynamic information exchange
flow (Sacks et al., 1978) such that salient informa-
tion is often scattered across multiple utterances by
different interlocutors (Li and Choi, 2020).Figure 1: A dialogue and its summary, consisting of
three sentences s,s,s. For illustration purposes, we
show relevant content snippets C,C,Cin the dia-
logue that these correspond to, and have also underlined
salient information that appears in the summary.
Recently, there is a growing trend of using Pre-
trained Language Models (PLMs) for dialogue
summarization (Gliwa et al., 2019; Fabbri et al.,
2021). However, these models tend to require abun-
dant labeled dialogue, which is difficult to pro-
cure for low-resource domains and downstream
tasks. To reduce the dependency on labeled dia-
logue resources, Chen and Yang (2021) explore a
self-training method (He et al., 2020; Xie et al.,
2020) to include unlabeled data, but the model fails
to consider that abundant in-domain unlabeled di-
alogue remains hard to procure in low-resource
settings. In recent years, prompt learning (Li and
Liang, 2021; Lester et al., 2021) has become a
promising alternative to full model fine-tuning that
significantly reduces the amount of parameters to
be tuned in few-shot settings. In our pilot experi-
ments, however, prompt learning did not work as
expected for dialogue summarization. This is be-
cause general prompt learning assigns universal
prompt tokens to all inputs in a given task. In con-
trast, dialogue is a dynamic form of interaction1096among multiple participants. We conjecture that
this tasks needs to be addressed using prompt learn-
ing with a high level of semantic understanding.
Considering a typical example in Figure 1, the
dialogue includes discussion of three different mat-
ters, which we marked as content snippets C,C,
andC, respectively. The summary consists of
salient information summarizing each snippet C
with one sentence s. Moreover, the content of
sstems from a single utterance, while the con-
tent of sandsis scattered across multiple utter-
ances. Additionally, sis more abstract, so it is
necessary to understand interaction relationships
between utterances to succinctly summarize the C
snippet. This phenomenon suggests that a single
prompt may be insufficient to model the dialogue
adequately.
Considering the inherent challenges of dialogue
and the advantage of prompt learning in few-
shot settings, in this work, we propose a novel
curriculum-based prompt learning method with
self-training. The proposed prompts are learned
using a curriculum learning strategy that gradually
increases the degree of prompt perturbation to ob-
tain a high level of semantic understanding, specif-
ically including soft prompts, perturbed prompts,
and interpolated prompts. We further incorporate
unlabeled dialogue via self-training (Zoph et al.,
2020; He et al., 2020) to optimize the prompts and
reduce the reliance on labeled dialogue. Addition-
ally, we investigate topic-aware prompting to better
plan for the generation of dialogue summaries. Ex-
tensive experiments on diverse benchmark datasets
evince the effectiveness of our model for dialogue
summarization. To sum up, our contributions are:
•Our curriculum-based prompt learning strat-
egy gradually increases the degree of prompt
perturbation to improve the understanding
ability of the proposed model on dialogue.
•We further utilize unlabeled dialogue by self-
training to alleviate the problem of insuffi-
cient training data and investigate topic-aware
prompts to better plan for the generation.
•We extensively evaluate our model on three
dialogue summarization datasets and obtain
new state-of-the-art results on AMI and ICSI.
2 Related Work
2.1 Dialogue Summarization
Dialogue summarization has received increasing
attention recently. Current studies typically applyconventional Transformer-based summarization ar-
chitectures, e.g., BART (Lewis et al., 2020), di-
rectly to dialogue scenarios (Gliwa et al., 2019;
Fabbri et al., 2021), whereas these models are pre-
trained with well-written texts such as news articles
that are notably different from dialogue in a number
of respects. To achieve better results, subsequent
research incorporates diverse distinctive traits of
dialogue to boost the performance, including di-
alogue acts (Goo and Chen, 2018), topic-related
multi-modal information (Li et al., 2019), domain
terminologies (Koay et al., 2020), commonsense
knowledge (Feng et al., 2021a), and dialogue dis-
course (Feng et al., 2021b). Another line of work
solves the challenge of very long sequences in in-
put dialogues with a hierarchical architecture (Zhu
et al., 2020) and the Longformer model (Fabbri
et al., 2021). However, most existing summariza-
tion approaches perform poorly when the annotated
dialogues are limited (Chen and Yang, 2021). In
this work, we explore a novel strategy that enables
the model to utilize abundant relevant signals from
unlabeled data, thereby reducing the dependency
on labeled dialogue in low-resource settings.
2.2 Prompt Learning and Self-Training
A recent trend in Natural Language Processing
(NLP) has been to explore prompt learning as a
lightweight alternative to fine-tuning. Prompt learn-
ing keeps the parameters of PLMs frozen and opti-
mizes only a small portion pertaining to prompts.
This allows few-shot or nearly zero-shot learning
for pre-trained models on new tasks with scarce
or entirely unlabeled data and it has been demon-
strated to be very effective over fine-tuning in
a number of tasks. For example, Li and Liang
(2021) propose “Prefix-Tuning”, which only tunes
“soft tokens” (prefix) activation prepended to all
Transformer layers, and keeps the PLM param-
eters frozen. Prompt tuning (Lester et al., 2021)
prepends a sequence of prompt tokens to the source
text, and only the embeddings of these tokens are
optimized. Gu et al. (2022) propose a pretrained
prompt tuning framework to boost the performance
of existing models in few-shot learning. However,
dialogue summarization requires models to under-
stand interactions between multiple utterances to
generate succinct summaries, suggesting that exist-
ing prompt learning techniques may be insufficient
to extract adequate information imparted across
multiple turns of the dialogue.1097Self-training is a simple and effective pseudo-
label semi-supervised learning method (Lee et al.,
2013; Chen et al., 2021; Chen and Yang, 2021)
that often iteratively performs the process of creat-
ing pseudo-labels on unlabeled data with a teacher
model, and subsequently applying the combined
labeled data to train a student model. Bringing
in large amounts of unlabeled data can lead to
better-performing models, particularly when la-
beled data is scarce. Inspired by these develop-
ments in prompt-learning and self-training, in this
work, we propose a new curriculum-based prompt
learning with self-training optimization for better
abstractive dialogue summarization.
3 Task Formulation
Given a dialogue Xconsisting of Dutterances
from multiple speakers, abstractive dialogue sum-
marization aims to compress the input dialogue X
into a concise summary Y, typically maximizing
the conditional probability P(Y|X;θ, ϕ)overN
instances, where θhere represents prompt-related
parameters and ϕdenotes the remaining parameters
of the backbone model, such as BART.
4 Approach
To address the task of abstractive dialogue summa-
rization, we propose an encoder–decoder architec-
ture with heterogeneous prompts, which gradually
increases the degree of prompt perturbation via
a curriculum learning strategy, and conducts the
optimization using a self-training technique.
4.1 Model Overview
An overview of our model is given in Figure 2,
where the backbone encoder–decoder architecture
is an extension of the prominent BART model
(Lewis et al., 2020). As depicted, heterogeneous
prompts, including curriculum prompts (left) and
topic-aware prompts (middle) are incorporated to
boost the performance of our model on dialogue
summarization. Self-training optimization (right)
is further proposed to exploit abundant relevant
information from unlabeled dialogue, aiming to al-
leviate the problem of insufficient training data. In
the following, we explain these steps in detail.
4.2 Heterogeneous Prompt Construction
We design two types of prompts, including: (1)
curriculum learning based prompts, on which we
increase the degree of perturbation so as to improvethe generalization ability and obtain better results,
and (2) topic-aware prompts, which enable plan-
ning the generation of dialogue summarization.
4.2.1 Curriculum Learning based Prompts
Motivated by the cognitive progress of humans
when gradually acquiring knowledge from easy
to hard, we propose a curriculum learning ap-
proach (Bengio et al., 2009) to augment prompt
learning by increasing the degree of prompt pertur-
bation gradually. Specifically, we introduce three
types of prompts, namely soft prompts, perturbed
prompts, and interpolated prompts. Soft prompts
serve to learn essential features for the dialogue un-
derstanding and modeling, and perturbed prompts
aim to improve the generalization of soft prompts
via additive perturbations. Interpolated prompts are
relevant mixtures of soft prompts with perturbed
prompts, which boost the understanding of the in-
herently rich interactions between utterances.
Soft Prompts Inspired by Lester et al. (2021),
we prepend a soft prompt Pto the input of our en-
coder. Here, P={p, p, ..., p}is a sequence of
trainable token vectors parametrized by θ, where
θ∈R,ρis the length of the soft prompt, and
dis the hidden state dimensionality. During train-
ing, we update the parameters of the soft prompt
while freezing all PLMs parameters.
Perturbed Prompts In empirical investigations
of dialogue summarization, we observe a common
phenomenon that particularly long prompts with
more than 200 trainable parameters tend to overfit
the training data and become less generalizable.
To improve the generalization ability of prompts,
we introduce two simple operations for prompt
perturbations: (1) random swapping, which breaks
the original relations by randomly swapping two
tokens in a prompt, such that the perturbed prompt
may become P={p, p, ..., p, ..., p}(where ρ
denotes the length of the perturbed prompt), and
(2) cutoff, which consists of both span and token-
level cutoff operations, aiming to induce a more
severely perturbed prompt. To explain this process,
we define two preset coefficients αandαthat
indicate the ratio between the length/number of
removed spans/tokens to that of the prompt. For
span-level cutoff, we set the length of a span as
l=α×ρ, and randomly sample the starting
index sfor this span from the index range from 0
toρ−l. Subsequently, the vectors with respect
to the prompt tokens from the s-th to (s+l−1)-1098
th positions are all masked, i.e., turned into zero
vectors. As for token-level cutoff, the number of
masked tokens is set to be α×ρ, and the indexes
of masked tokens are randomly sampled as well.
Interpolated Prompts Inspired by the recent suc-
cess of Mixup (Zhang et al., 2018) and MixText
(Chen et al., 2020), we explore interpolation tech-
niques to mix the above two types of prompts,
seeking to understand the interaction relationships
in multiparty dialogue with interpolated prompts.
Given a soft prompt Pand its corresponding per-
turbed prompt P, the Mixup algorithm creates a
novel virtual prompt by linear interpolation:
˜P=λ P+ (1−λ)P, (1)
where λis a scalar mixing ratio that is sampled
from a Beta distribution Beta( α, α)for every batch
to perform the interpolation, and αis the hyperpa-
rameter to control the distribution of λ. Different
from Mixup, we do not need to mix the correspond-
ing labels in the same way. We believe that by
mixing the two types of prompts, more attention
can be given to understanding and modeling inher-
ently rich interactive relations between utterances.
4.2.2 Topic-aware Prompts for Planning
Decoding with Learned Prompts Unlike regu-
lar prose documents, dialogue consists of multiple
utterances from two or more participants forming
a dynamic information exchange flow (Sacks et al.,
1978). The topics being discussed can vary during
the progression of a conversation. This trait makes
it difficult to summarize dialogue.Given the structure of dialogue, we investigate
how to better control the summary generation pro-
cess with topic planning. Specifically, we introduce
topic-aware prompts P, which are constructed by
prepending topic-related features from different
dialogue segments. As shown in Figure 2, we
first leverage DialoGPT (Feng et al., 2021b), an
unsupervised dialogue annotator, to capture topic-
related information by dividing the dialogue into
Ctopically coherent segments. Therefore, we have
P={P, P, . . . , P, . . . , P}with parameters
θto be updated, where c∈ {1, . . . , C}, each
topic-aware prompt P={p, p, ..., p}corre-
sponds to a topic segment, and ρrefers to the
length. We thus combine each Pwith the corre-
sponding topic segment by calculating the average
value of every dimension in P, and adding this
average value to the token embeddings in the cor-
responding segment. We believe that by prompting
based on different topic segments, these combined
prompts are able to capture crucial features for dif-
ferent topics in the dialogue. Further, we concate-
nate these prompts Pto the decoder inputs. Thus,
topic-aware prompts are able to aid in planning for
the generation process of dialogue summarization,
thereby improving the quality of summaries.
4.3 Prompt Optimization with Self-Training
To further improve the ability to learn from lim-
ited labeled dialogues, we combine the proposed
prompt learning with self-training (Zoph et al.,
2020; He et al., 2020) to harness unlabeled dialogue
data. Our prompt optimization with self-training1099Algorithm 1: Self-Training Optimization
approach is specified in Algorithm 1.
Self-training refers to the process of creating
pseudo-labels on unlabeled data with a teacher
model, and then applying the combined data to
train a student model. Nevertheless, conventional
self-training approaches have some shortcomings.
On one hand, self-training needs a sizeable amount
of in-domain unlabeled data, whereas, for low-
resource tasks, abundant in-domain unlabeled data
is often not available. On the other hand, a draw-
back of previous work (Chen and Yang, 2021) is
that it relies on a pre-defined constant threshold and
ignores a considerable amount of other unlabeled
dialogue, especially for samples that have a greater
learning difficulty, which may fail to get selected
throughout the entire training process.
To address the first problem, we leverage data
augmentation (Wu et al., 2021b) to synthesize un-
labeled data and reduce the impact of the data
domain. For SAMSum, we first randomly select
two dialogues from the dataset without considering
the labels, and subsequently concatenate them by
adding a special token <SEP> in between, obtaining
ample synthetic data as unlabeled resources. For
the AMI and ICSI datasets, we leverage DialoGPT
to divide the dialogue into topically coherent seg-ments for all training instances, and subsequently
randomly sample three topic segments from all seg-
ments as synthetic data. To improve the quality
of all synthetic data, we further utilize advanced
techniques, e.g., masking words, to process all syn-
thetic data, obtaining the final forms of abundant
unlabeled data. To resolve the second problem,
we further replace the constant threshold with a dy-
namic thresholding mechanism explained in further
detail in the following.
Dynamic Thresholding To perform dynamic
thresholding, we first cluster the entire unlabeled
data with the K-means algorithm, such that differ-
ent clusters represent dialogue samples with differ-
ent learning difficulties. We then use the teacher
model to generate pseudo-summaries for every in-
stance in a cluster c, and calculate the correspond-
ing BERTScore, which is later used for compari-
son with the threshold to determine which dialogue
samples to add. The proposed dynamic threshold-
ing mechanism can thus dynamically adjust our
threshold for every cluster based on the number of
instances in the corresponding cluster.
4.4 Training Objective
We formulate the training objective as follows with
respect to the model parameters /hatwideθ:
/hatwideθ= argmax/summationdisplaylogp/parenleftbig
Y|X;θ, θ, ϕ/parenrightbig
,
(5)
where θ={θ;θ;θ}refers to the parame-
ters of curriculum-based prompts, and θ,θ,θ
represent the soft, perturbed, interpolated prompt
parameters, respectively. In addition, θstands
for topic-aware prompts parameters, and ϕdenotes
the remaining parameters of the backbone model.
Note that /hatwideθconsists of various types of parame-
ters, while prompt learning keeps the parameters
of PLMs frozen and optimizes only θandθ.
5 Evaluation
5.1 Experimental Setup
Datasets We conduct our experiments on three
commonly-used benchmark datasets, AMI (Mc-
Cowan et al., 2005), ICSI (Janin et al., 2003), and
SAMSum (Gliwa et al., 2019), comprising English
language dialogues from both meeting and daily
life chat domains. Detailed statistics are given in
Table 1. Additionally, we further study the effec-
tiveness of our model in few-shot scenarios, which1100Description AMI ICSI SAMSum
Source Domain Meeting Meeting Daily Chat
Number of dialogues 137 59 16,369
Train/Dev./Test 97/20/20 43/10/6 14,732/818/819
Avg. participants 4.0 6.2 2.38
Avg. turns 296.74 398.63 11.08
Avg. dialogue length 5,490.98 11,000.60 83.68
Avg. summary length 286.81 521.53 20.31
Unlabeled data 291 129 29,464
are constructed by randomly sampling 10, 100, or
1,000 dialogue instances from the original training
set of SAMSum.
Automatic Metrics We use standard evaluation
metrics that include ROUGE-1, ROUGE-2, and
ROUGE-L (Lin, 2004)to assess the quality of
generated summaries, which consider the overlap-
ping uni-grams, bi-grams, and the longest common
subsequences, respectively.
Human Metrics Apart from automatic metrics,
we conduct human evaluations to assess the quality
of generated summaries. Specifically, we randomly
sample 150 dialogues from SAMSum, all dialogues
from AMI and ICSI, and ask three experts to grade
the quality of generated summaries using three cri-
teria: (1) Fluency measures how well the generated
summaries are readable. (2) Informativeness eval-
uates how well the generated summaries capture
more salient information. (3) Relevance evaluates
how well the generated summaries reflect the input
dialogues. We set the range of rating from 1.0 to
5.0 (higher scores indicating a better quality).Baselines and Experimental Settings A variety
of representative models are chosen as competitive
baselines for our experiments, ranging from early
ranking-based models such as TextRank (Mihalcea
and Tarau, 2004) to mainstream Transformer-based
approaches (e.g., BART). Further comparison
details are provided in Section 5.2.
All implementations are built on the top of the
Transformers(Wolf et al., 2020) library. During
training, we leverage a linear learning rate sched-
uler and AdamW optimization (Loshchilov and
Hutter, 2019). The two coefficients αandαin
perturbed prompts are selected from {0.03, 0.07,
0.1} and {0.01, 0.03, 0.05}, respectively. We set
different learning rates for three types of prompts
in curriculum-based prompt learning by decreas-
ing the rates as the learning process progresses.
Specifically, when using the soft, perturbed, and
interpolated prompts, we set the learning rates as
7×10,5×10, and 4×10, respectively.
In addition, we set the maximum iteration times as
5, and the batch size to be 16 for SAMSum and 1
for AMI and ICSI. In the decoding phase, we set1101the beam size to be 4, and assign length normaliza-
tion to be 0.8 for SAMSum and 0.5 for AMI/ICSI,
respectively.
5.2 Main Results
Table 2 provides a comparison of our model with
previous approaches on AMI and ICSI. We ob-
serve that our model achieves new state-of-the-art
results on these two benchmark datasets. For in-
stance, compared with the previous baseline model
LED (Beltagy et al., 2020), our model ob-
tains relative gains of 7.4% on ROUGE-1, 4.6%
on ROUGE-2, and 9.6% on ROUGE-L on the
ICSI dataset. Furthermore, our model signifi-
cantly outperforms the conventional BART
with fine-tuning (Lewis et al., 2020) on both AMI
and ICSI, demonstrating the effectiveness of our
prompt learning in dialogue summarization.
Results of the comparison on SAMSum are re-
ported in Table 3. Our model also achieves strong
results on this dataset, suggesting the generaliza-
tion ability of our model across diverse domains.
Instead of relying heavily on additional coreference
resolution or named entity tagging tools, our model
obtains relative improvements of 1.2% on ROUGE-
1 and 1.2% on ROUGE-2 compared with the pre-
vious state-of-the-art model DiaSumm+Coref (Liu
and Chen, 2021).
Few-shot settings To further study the effective-
ness of our model in few-shot scenarios, we set
different few-shot settings based on SAMSum. Ta-
ble 4 shows that our model achieves the best results
on different sample settings, especially when there
are fewer than 100 samples.Human Evaluation Table 5 shows the mean hu-
man ratings of different models on AMI, ICSI and
SAMSum. The summaries generated by our model
prove preferable across all considered metrics, fur-
ther confirming the effectiveness of our approach.
6 Quantitative Analysis
6.1 Ablation Study
To better quantify the contributions of different
components in our model, we conduct ablation
studies with three types of simplified architectures
as follows. The first type removes the all curricu-
lum prompts, and the second drops topic-aware
prompts. The third variant is to use our model with-
out self-training. Table 6 provides the results of the
corresponding ablations on the dev. set of ICSI. We
observe that all of the aforementioned components
of our model make noticeable contributions. For
example, the removal of curriculum prompts causes
a relative performance drop of 3.0% on ROUGE-
1, confirming the validity of our curriculum-based
prompt learning strategy. When self-training is
removed, this causes a relative performance drop
of 2.6% on ROUGE-1, which shows the effective-
ness of self-training with our augmented pseudo-
dialogue data.
6.2 Impact of Curriculum Prompts
Curriculum Prompt Ablation In Table 7, we
deeply investigate the effect of our curriculum-
based prompt learning, where we adopt the same
hyperparameters for all experiments. We observe
that the model performance degrades with the re-
moval of each curriculum stage, indicating that
curriculum-based prompt learning with three stages
in our model accounts for more importance.
Comparison with Prompt Variants We further
compare the proposed prompt learning strategy
with other prompt variants in Table 8. Here, we use
the same backbone models for all variants. From
this table, we observe that substantial gains are
made when going from prompt tuning to our model.
For example, our approach outperforms full-model
fine-tuning with a relative increase of 7.4% in terms
of ROUGE-1 on the ICSI dataset.
6.3 Parameter Sensitivity of Self-training
Iteration We further study the effects of iterative
training in our model, adopting the same hyperpa-
rameters for all the iterations. As shown in Figure 3,
ROUGE scores keep improving at first, achieve the1102
ModelsAMI ICSI SAMSum
Flu. Info. Rel. Flu. Info. Rel. Flu. Info. Rel.
BART 4.21 4.00 4.34 4.12 3.84 4.23 4.46 4.19 4.62
Prompt-tuning 4.02 3.86 4.17 3.84 3.56 3.99 4.33 3.89 4.41
Ours 4.37 4.02 4.64 4.25 3.94 4.47 4.53 4.21 4.76
best performance at iteration 4, and then start to
converge. This indicates the effectiveness of iter-
ative training by continually updating the teacher
model to generate better pseudo-summaries.
Dynamic Thresholding Figure 4 compares the
performance of our dynamic thresholding with the
conventional constant threshold for self-training.
We observe that our dynamic thresholding mecha-
nism significantly outperforms the fixed thresholds
on all metrics. During self-training, hard-to-learn
dialogue samples can gradually contribute to the
training when we dynamically adjust the thresh-
old. This not only ensures the quality of pseudo-
summaries, but also improves the data utilization.
6.4 Case Study
Table 9 presents a sample summary generated by
different models for the SAMSum dataset. As the
example shows, the summaries generated by our
model generally appear more informative and rele-
vant to the given dialogue, consistent with the re-1103
sults of the human evaluation. Furthermore, we ob-
serve that the prompt-tuning model summarizes im-
portant information in a single utterance. However,
the form of the dialogue determines that salient
information is often scattered across multiple ut-
terances, which results in the generated summaries
being unable to summarize the entire dialogue. The
summary generated by our curriculum prompting
covers all salient contents, thanks to the interpo-
lated prompts effectively integrating the contents
captured by another two prompts. The summaries
generated by our model appear more informative,
presumably because combined with self-training to
optimize prompts, the model further acquires capa-
bilities for dialogue understanding and modeling.
7 Conclusion
In this work, we propose a novel curriculum-based
prompt learning method with self-training that im-
proves the dialogue understanding and modeling
capabilities and reduces the dependency on labeled
dialogue. We further explore topic-aware prompt-
ing to aid in planning for the summary generation.
Experiments on diverse datasets with several differ-
ent settings confirm the effectiveness of our model
on abstractive dialogue summarization.
Limitations
Currently, we use a curriculum learning strategy
to gradually increase the degree of three types of
prompts to accomplish common dialogue summa-rization tasks. This may be less effective in more
complex scenarios. Moreover, additional tech-
niques may be needed for other complex tasks that
require specific domain knowledge, complex in-
tents, and fine-grained features. Since our current
design provides the model with shared prompts,
this approach may fail in future scenarios that
require instance-aware prompts for personalized
dialogue summary generation. In addition, self-
training often requires a large amount of data as
well as extra computation efforts with many iter-
ations. Our model may not work well if there ex-
ists insufficient labeled data to train an initial base
model that misclassifies a certain amount of unla-
beled data. In this case, the mislabeled examples
may greatly affect the results in subsequent itera-
tions.
Acknowledgements
This work was supported by the National In-
novation 2030 Major S&T Project of China
(No. 2020AAA0104200 & 2020AAA0104205),
National Natural Science Foundation of China
(No. 62006077), Shanghai Sailing Program
(No. 20YF1411800), the Science and Tech-
nology Commission of Shanghai Municipality
(No. 21511100100), and Qingpu Scientific Re-
search Project (No. 2021-6).1104References11051106