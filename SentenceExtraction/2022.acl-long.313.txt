
Jian Liu, Yufeng Chen, Jinan Xu
Beijing Jiaotong University, School of Computer and Information Technology, China
{jianliu, chenyf, jaxu}@bjtu.edu.cn
Abstract
Event detection (ED) is a critical subtask of
event extraction that seeks to identify event
triggers of certain types in texts. Despite sig-
niﬁcant advances in ED, existing methods typ-
ically follow a “one model ﬁts all types” ap-
proach, which sees no differences between
event types and often results in a quite skewed
performance. Finding the causes of skewed
performance is crucial for the robustness of
an ED model, but to date there has been lit-
tle exploration of this problem. This research
examines the issue in depth and presents a
new concept termed trigger salience attribu-
tion, which can explicitly quantify the un-
derlying patterns of events. On this founda-
tion, we develop a new training mechanism
for ED, which can distinguish between trigger-
dependent and context-dependent types and
achieve promising performance on two bench-
marks. Finally, by highlighting many dis-
tinct characteristics of trigger-dependent and
context-dependent types, our work may pro-
mote more research into this problem.
1 Introduction
Event detection (ED) is the ﬁrst and a crucial step
of event extraction, which aims to identify events of
certain types in plain texts (Ahn, 2006; Nguyen and
Grishman, 2015; Mitamura et al., 2017). Previous
methods to ED typically adopt a “one model ﬁts
all types” approach, seeing no difference between
event types and using a single model to address
them all (Ji and Grishman, 2008; Li et al., 2013;
Chen et al., 2015; Lin et al., 2020). However, such
approaches produce quite skewed performance on
different types. Tasking the ACE benchmark as
an example, we note the state-of-the-art ED model
(Wadden et al., 2019) can strike 90% in F1 for the
type , yet only 50% for the type - , and it is more surprising that the training
set of is eight times smaller than that of - . Finding the causes underlyingFigure 1: Two typical event instances of and - (taken from the ACE 2005 bench-
mark), where the trigger words are colored.
the skewed performance is crucial to the robustness
of an ED model; however, this problem is still
understudied in current research.
In this study we take a fresh look at above prob-
lem and for the ﬁrst time attribute the skewed per-
formance to the contextual patterns of events . Let
consider the two typical instances of
and - shown in Figure 1. Intu-
itively, they demonstrate distinct patterns: the- event is more trigger-dependent , and the
trigger word (i.e., “divorced”) is very indicative
of the event’s occurrence; by contrast, the - event is more context-dependent — the
event semantic is primarily expressed by contexts
rather than the trigger “become”, which is a merely
light verb. We hypothesize an ED model performs
poorly on context-dependent types because cap-
turing context semantics is challenging (Lu et al.,
2019; Liu et al., 2020b). With the above intuitions,
two questions rise: (i) Can we estimate an event’s
pattern quantitatively? (ii)) How to robustify an
ED model by characterizing such patterns?
To address the ﬁrst question, we introduce a
brandy new concept called trigger saliency attribu-
tion, which can explicitly quantify an event’s con-
textual pattern. Figure 2 illustrates the key idea: to
determine how much an event is trigger-dependent
or context-dependent, we measure the trigger’s con-
tribution to expressing overall the event semantic.
Speciﬁcally, we ﬁrst assign each sentence a global
event label that represents the overall event seman-
tic. Then, inspired by the feature attribution method4573(Simonyan et al., 2014; Sundararajan et al., 2017),
we regard each word as a feature and compute its
contribution (i.e., saliency value) for predicting
the global event label. Finally, by examining the
ground-truth trigger’s saliency value, we can tell
how much an event depends on triggers or con-
texts: a higher value, for example, indicates that
the trigger contributes more to the event, implying
the event is more trigger-dependent.
To answer the second question, we develop a
new training mechanism based on trigger saliency
attribution, which uses saliency as evidence to en-
hance learning. Our method is simple and straight-
forward — instead of using a single model to detect
all event types, we group event types with similar
patterns together (assessed by trigger saliency attri-
bution) and develop separate models for each group.
This strategy enables different models to capture
distinct patterns — for example, the model for
context-dependent type can focus on mining con-
textual information for learning. To further boost
learning, we also propose two saliency-exploration
strategy to augment the above framework, which
can explicitly integrate saliency information into
learning and produce improved performance par-
ticularly for context-dependent types ( x6.2).
To verify the effectiveness of our approach, we
have conducted extensive experiments on two ED
benchmarks (i.e., ACE 2005 (LDC, 2005) and
MA VEN (Wang et al., 2020)). According to the
results: (i) Our trigger saliency attribution method
can capture the underlying pattern and well explain
the skewed performance, obtaining Spearman’s cor-
relation coefﬁcients of 0.72 and 0.61 with per-type
F1 on ACE 2005 and MA VEN respectively; (ii)
Our new training regime based on saliency demon-
strates improved results on the two benchmarks.
On ACE 2005, for example, it produces a 2% ab-
solute gain in F1 over methods training different
event types jointly. Finally, in ablation studies, we
compare and highlight many signiﬁcant characteris-
tics (e.g., linguistic and lexical patterns) of trigger-
dependent and context-dependent event types; our
work may inspire future research into their patterns.
To summarize, our contributions are three-fold:
•We analyze the origins of an ED model’s
skewed performance and propose a new no-
tion termed trigger saliency attribution, which
can assess the underlying pattern of events.
Our ﬁndings, as a seminal study, raises the
possibility that the traditional “one model ﬁts
all types” paradigm may need to be changed.
•We present a new ED training mechanism
based on trigger saliency attribution that
achieves promising results on two bench-
marks, especially when dealing with context-
dependent event types.
•We highlight several diverse patterns of
trigger-dependent and context-dependent
event types, and our ﬁndings may stimulate
future research into their differences.
2 Background and Related Work
Event Detection. ED is a critical subtask of
event extraction that seeks to locate event instances
in text, which has received a lot of attention from
researchers. Traditional methods for ED typically
use ﬁne-grained features (Ahn, 2006; Ji and Grish-
man, 2008; Liao and Grishman, 2010; Hong et al.,
2011; Li et al., 2013), whereas newer methods rely
on neural networks (Chen et al., 2015; Nguyen and
Grishman, 2015; Feng et al., 2016; Nguyen and
Nguyen, 2019; Liu et al., 2018a, 2019a,b), which
have investigated the use of syntactic information
(Liu et al., 2018b; Lai et al., 2020), document-level
cues (Wadden et al., 2019; Lin et al., 2020; Du and
Cardie, 2020; Liu et al., 2020b; Lai et al., 2021;
Pouran Ben Veyseh et al., 2021; Li et al., 2021;
Chen et al., 2021; Liu et al., 2021), and external
supervision signals (Tong et al., 2020; Liu et al.,
2020a) to boost learning. However, most methods
recognize no distinction between event types and
train a single model to identify all event types, re-
sulting in rather skewed performance on different
event types. Two seminal works (Lu et al., 2019;4574Liu et al., 2020b) have observed the comparatively
poor performance on context-dependent texts and
offered a better context-exploration strategy to im-
prove training. Nonetheless, they are in a position
to improve performance rather than investigate the
root causes. Our approach, on the other hand, takes
a fresh look at the issue and aims to deﬁne the
underlying patterns of events for learning.
Feature Attribution. The goal of feature attri-
bution (FA) is to assess how important an input
feature for model prediction, which has sparked a
lot of interest in interpreting model decisions (Si-
monyan et al., 2014; Sundararajan et al., 2017).
Formally, suppose we have an input vector x= (x,
x, ...,x)2Rand a functionF:R![0, 1] rep-
resenting a model. The attribution value of x, with
respect to the output F(x), is deﬁned as a vector
A(x)= (a,a, ...,a)2R, whereameasures
the contribution of xtoF(x). The existing FA
methods are classiﬁed as gradient-based methods,
which consider the gradient of the output to the in-
put as the attribution value (Simonyan et al., 2014;
Springenberg et al., 2015), and reference-based
methods, which consider the difference between
the model’s output and some “reference" output,
in terms of the difference between the input and
some “reference" input, as the attribution value
(Ribeiro et al., 2016; Sundararajan et al., 2017).
FA have been used to interpret model predictions
in applications including image classiﬁcation (Si-
monyan et al., 2014), machine translation (Ding
et al., 2017), text classiﬁcation (Chen et al., 2018),
and others (Bastings and Filippova, 2020). To the
best of our knowledge, this is the ﬁrst work intro-
ducing FA to ED for quantifying the underlying
event patterns.
Integrated Gradient. Integrated Gradient (Sun-
dararajan et al., 2017) is a speciﬁc (reference-
based) FA method that views the feature attribution
value as the accumulated gradient along the line be-
tween the model’s input xand a reference input x,
which denotes the lack of a feature. Particularly,
the attribution value of x(i.e., theidimension
ofx) with respect to an output F(x) is deﬁned as:
whereindicates the gradient of F(x)tox.
In our approach, we prefer Integrated Gradient toAlgorithm 1: Trigger Saliency Attribution
other FA methods due to its computing efﬁciency
and effectiveness in addressing a wide range of
text based tasks (Sundararajan et al., 2017; Liu and
Avci, 2019; Bastings and Filippova, 2020).
3 Trigger Saliency Attribution
Algorithm 1 provides an overview of our trigger
saliency attribution method, which consists of three
major steps: (i) sentence-level event classiﬁcation,
(ii) word-level saliency estimation, and (iii) type-
level saliency estimation. Let s= [w,w,,
w] be a sentence of Nwords, and the ED task
corresponds to predicting an event label sequence
Y= [y,y,,y], wherey2T [f Ogindi-
cates the event label of w,Tis a set containing
all pre-deﬁned event types, and O is a “null type”
denoting no-trigger words.
Sentence-Level Event Classiﬁcation. We start
by givingsa sentence-level event label G, which
represents the overall event semantic. Let the label
beG=[g;g;:::;g]2R, whereg2f0;1g
indicates whether a trigger of the ievent type is
contained by s(g=1) or not (g=0). Following that,
we construct a sentence-level event classiﬁer and
aim to learn a mapping from stoG. Particularly,
we devise a BERT based sentence classiﬁer (Devlin
et al., 2019) and adopt a multi-label binary cross-
entropy loss for optimization:
whereXis the input embedding of sin BERT,o
2Rindicates the logits vector computed by the
classier, andodenotes theielement ofo.
Word-Level Saliency Estimation. Based on the
sentence-level classiﬁer, we next use Integrated
Gradient (Sundararajan et al., 2017) to calculate
the contribution (i.e., saliency value) of each word4575
to the prediction. We utilize the loss function as
the desired model (Wallace et al., 2019), and calcu-
late the saliency of w, more accurately, its BERT
representation x2X, regarding the loss by:
whereXis a sequence of all-zero vectors (serving
as a reference input), and xdenotes theielement
inX. We then normalize as a scalar value
with a sentence-wise normalization:
=e=Xe(4)
wherekkdenotes the Lnorm. In actuality, we
may not be concerned with a word’s saliency to the
general event semantic G, but rather with a speciﬁc
event typeT2T. To this end, we replace Gwith
the one-hot representation of Tin Equation (3) for
evaluation. Finally, we represent the word-level
saliency ofwwith respect to the event type Tby
, and we suppose = 0 if the sentence
does not describe any event of type T.
Type-Level Saliency Estimation. Based on the
word-level saliency, we measure the type-level trig-
ger saliency value (regarding an event type T) as:
SL(T) =PP
#of training examplesof type T(5)
where (s;Y)ranges over each training instance;
fwjy=Tgis a set containing all of the trig-
gers of type Tins. The type-level saliency valeSL(T)indicates how trigger-dependent or context-
dependent an event type Tis, and it has been shown
to correlate strongly with the per-type model per-
formance (x6.1).
4 Saliency Enhanced ED
Based on trigger saliency attribution, we devise a
new training paradigm for ED, which can distin-
guish event types with similar patterns for learning
and achieves promising results. The overview is
shown in Figure 3, and the technical details follow.
Event Type Division. Based on type-level
saliency estimation, we divide all event types into
a trigger-dependent set T =fTjSL(T)
gand a context-dependent set T =
fTjSL(T)< g. The threshold is empirically
determined as the median of all per-type trigger
saliency values, implying that the event types are
evenly divided into two sets.
Saliency-Enriched Event Detector. Following
that, we create separate ED models for T
andT . Each model is implemented using
the BERT architecture (Devlin et al., 2019), and
given a sentence s, it performs a word-by-word
classiﬁcation over BERT’s output to generate a
label sequence: ~Y= (~y,~y,,~y), with ~y
being the predicted event label for w. Based on
the different characteristics of trigger-dependent
and context-dependent types, we devise different
saliency-exploration methods to boost learning.
(i) Word Saliency Embeddings. Given that
trigger-dependent types often have indicative trig-4576gers, we build a mechanism called word saliency
embeddings (WSEs) in the model for T to
capture such regularities. Speciﬁcally, we ﬁrst
quantify each word’s saliency valueas 0 or 1 based
on, i.e., the threshold we used previously for dis-
tinguishing event types, and then use a separate
embedding vector to distinguish 0 and 1, similar
to word embeddings. Such embeddings are incor-
porated into the modelto capture a regularity that
words with high saliency values are more likely to
be triggers. Note WSEs are also incorporated in
the model for theT , which on the other hand
seeks to learn the opposite regularity that words
with high saliency values may not be triggers.
(ii) Saliency as Context Evidence. In the event
detector forT , we also devise a regime for
interpreting salient information as context evidence
for reasoning. Consider the previous example S2.
Our method identiﬁes the context words “US minis-
ter” as the most salient words (with saliency values
larger than) expressing the overall event semantic.
Here we regard salient contexts as supplementary
evidence and concatenate them with the sentence
for learning, as shown in the bottom of Figure 3.
Compared with WSEs, this method can additional
capture the lexical semantics of the salient words,
which has been shown to considerably aid in the
recognition of context-dependent event types ( x7).
Model Ensemble. In the testing stage, we com-
bine the results of two models to make a ﬁnal pre-
diction. If ambiguous cases occur, i.e., the two ED
models predict different event types for the same
word, we use the type with a higher probability as
the result. We use cross-entropy loss for optimiza-
tion. For example, the model for T is trained
by minimizing the following loss:
L= XXlogP(yjw)
(6)
where (s;Y)refers to each training instance; ( w,
y) ranges over each pair of word and its ground-
truth event label; P(yjw)denotes the conditional
probability that the model predicts yforw. We
use Adam (Kingma and Ba, 2015) with default
hyper-parameters for parameter update.
5 Experimental Setups
Datasets. We conduct experiments on ACE 2005
(LDC, 2005) and MA VEN (Wang et al., 2020).
ACE 2005 deﬁnes 33 event types and contains 599
documents. We adopt a common split for evalu-
ation following previous works (Li et al., 2013;
Wadden et al., 2019). MA VEN is a newly released
corpus deﬁning 168 more ﬁne-grained event types
(Wang et al., 2020). Because the MA VEN test
set is not publicly available and our study is con-
cerned with per-type performance, we instead use
the MA VEN development set for assessment and
divide the original MA VEN training set as 9:1 for
training and validating. Table 1 displays the com-
prehensive data statistics for the two datasets.
Evaluation Metrics. We adopt the following
metrics to evaluate our model: (i) Spearman’s rank
correlation coefﬁcient, which can determine the sta-
tistical dependency between two ranked variable se-
quences. The metric is deﬁned as = 1 ,
wheredis the difference between the ipair of
ranked variables, and nis the sequence length. We
use it to measure how well our trigger saliency
attribution results correlate with per-type model
performance. (ii) Precision (P), Recall (R) and (Mi-
cro) F1, which are widely used to assess the overall
performance of an ED model. (iii) Macro F1, the
arithmetic mean of class-wise F1-scores, which
will be low for models that only perform well on
common types but badly on rare types.
Implementations. In our trigger saliency attribu-
tion method, the sentence-level classiﬁer is built on
theBERT-base . The batch size is set to 20, and
the learning rate is set to 1e-5. After 5 epochs, it
achieves 74.8% in F1 on the ACE 2005 develop-
ment set, matching the state-of-the-art performance
(Liu et al., 2019c). As for the two ED models, we
consider BERT-base architectures. The batch
size is set to 20, chosen from [1, 5, 10, 20, 30]. The4577
learning rate is set to 1e-5, chosen from a range
from 1e-3 to 1e-6. The dimension of word saliency
embeddings is empirically set to 100. To allow
for further investigation, we have made our code
publicly available at https://github.com/
jianliu-ml/SaliencyED .
6 Experimental Results
6.1 Results of Correlation Measurement
Table 2 shows the Spearman’s rank correlation be-
tween per-type F1 and four criteria: 1) the number
of training instances (regarding an event type); 2)
trigger variance, deﬁned as the ratio of the num-
ber of unique event triggers to the total number of
event triggers (regarding an event type); 3) trigger
attention value, which corresponds to the ground-
truth trigger’s attention value in the BERT model;
4) trigger saliency attribution (our method). We use
a state-of-the-art ED model (Wadden et al., 2019)
and perform a 5-run average on the development
set to obtain the per-type F1 score.
According to the results, our trigger saliency at-
tribution approach correlates the best with model
performance, yielding a score as high as 0.72 and
0.61 in Spearman’s correlation. This suggests
that our method can well explain the skewed perfor-
mance. Our other ﬁndings are interesting: (i) Sur-
prisingly, the number of training examples shows
a negligible correlation ( = 0.06 and 0.09) with
per-type F1. This implies that simply collecting
more training data may not be an effective way to
improve an ED model. (ii) The trigger variance
metric demonstrates a moderate association ( =
0.25 and 0,26), indicating that the diversity of event
triggers is a factor inﬂuencing model performance.
(iii) The trigger attention value also shows a poor
association, which may be another proof that atten-
tion is not explainable (Jain and Wallace, 2019).
Lastly, Figure 4 visualizes correlations between
per-type F1 and the number of training instances
and our trigger saliency attribution method. In addi-
tion to noting that our method adequately explains
the per-type F1-score, we ﬁnd that = 0.25 may be
a good threshold for distinguishing between trigger-
dependent and context-dependent event types.
6.2 Results of Saliency Enhanced ED
To test the efﬁcacy of our saliency enhanced ED
model: 1) For ACE 2005, we compare our model
with (i) DYGIE++ (Wadden et al., 2019), which
uses a graph view to learn context features; (ii) Trig-
gerQA (Du and Cardie, 2020), which uses a ques-
tion answering formulation for the task; (iii) OneIE
(Lin et al., 2020), which adopts cross-sentence fea-
tures for the task. Because pre-processing has a sig-
niﬁcant impact on the results (Orr et al., 2018), to
ensure a fair comparison, we only consider models
using the same pre-processing steps as in (Wad-
den et al., 2019). 2) For MA VEN, we use the
BERT+CRF proposed in the original work (Wang
et al., 2020) for comparison. As a baseline, we also
construct a model called BERTEns, which ensem-
bles two BERT models similar to ours but does not
differentiate event types. We refer to our approach
that merely separates event types for learning (with-
out saliency-exploration strategies) as SaliencyED
(SL), and our full approach as SaliencyED (Full).
Table 3 displays performances of different models.
The results have conﬁrmed our approach’s effec-
tiveness. Particularly: (i) our full model achieves
the best Micro F1 score (75.8% and 67.1%) on4578
ACE 2005 and MA VEN without the use of sophis-
ticated architectures or external resources, as DY-
GIE++ and OneIE do. (ii) Impressively, with the
identical architectures, our full model SaliencyED
(Full) outperforms BERTEns by 2.8% and 1.7% in
F1 on the two datasets, respectively; SaliencyED
(SL), which only differentiates event types for train-
ing, outperforms BERTEns by 1.6% in F1. This
emphasizes the signiﬁcance of identifying event
patterns for ED. (iii) Our method gives the best
Macro F1 on two datasets, indicating that it per-
forms well on both common and rare event types.
Table 4 shows the performance breakdown
for trigger-dependent (TD) and context-dependent
(CD) types. According to the results, different mod-
els consistently produce good performance on TD
types but low performance on CD types, implying
that the patterns found by our trigger saliency at-
tribution method are reasonable. When comparing
SaliencyED (SL) and SaliencyED (Full), we see
that the saliency-exploring method is more effec-
tive on CD types (+2.3% in F1) than on TD types
(+0.3% in F1). This makes sense because detect-
ing context-dependent events relies signiﬁcantly
on context reasoning, and our method can just use
important contexts as evidence to improve learning.
7 Discussion
Ablation Study. We undertake an ablation study
in Table 5 to investigate different model com-
ponents, using the more challenging context-
dependent (CD) types as an example. In the vari-
ant models, +WSE and +Evidence denote sup-
plementing SaliencyED (SL) with word saliency
embeddings and context evidence, respectively.
+MaskAtt is an approach for calculating atten-
tion that masks the word itself, which can drive
the model to focus more on contexts for learning;
+Gold Argument is an oracle method that uses gold
event arguments as evidence for learning. Based
on the results, +Evidence outperforms +WSE and
+MaskAtt, indicating its efﬁcacy. Interestingly,
+MaskAtt also boosts performance, implying that
the contexts of CD events do carry important infor-
mation for asserting the event. Finally, the superior
performance of +Gold Arguments implies that ﬁnd-
ing indicative evidence (e.g., event arguments) is
the key factor boosting learning on CD types.
Impact of Event Type Division. We use our
event type division method as a baseline and com-
pare it to three other event type division strategies:
1) at random; 2) based on the amount of training in-
stances; 3) based on development set performance.
According to the results, the ﬁrst two strategies de-
crease performance by 1.27% and 1.41% in Micro
F1 on ACE, and 1.53% and 1.40% on MA VEN,
which suggests that an inappropriate separation
of event types impairs learning. The third strat-
egy based on development performance improves
learning (+0.8%/+1.1% on ACE/MA VEN), but it4579
is still inferior to our approach. An explanation is
that the ﬁnal model performance is the product of a
combination of factors, and thus categorizing event
types based on development set performance may
not assure that event types with similar patterns are
grouped together, resulting in inferior results.
Distinctions in TD/CD Types. We use ACE
2005 as a case to highlight the distinct characteris-
tics between TD and CD types. Figure 5 (Left) de-
picts the top k accuracy (hit@k) in the case where
the most salient word in a sentence appears to be
an event trigger; Figure 5 (Right) depicts the per-
formance drop in an adversarial attack in which
the gold event triggers are masked for sentence-
level event type classiﬁcation. The CD and TD
types exhibit opposing behaviors: TD types display
excellent H@k accuracy but a signiﬁcant perfor-
mance loss in adversarial attack, whereas CD types
exhibit the opposite tendency. This implies that
the CD and TD types respectively rely on triggers
and contexts. Figure 6 shows a comparison of the
number of event arguments for TD and CD types.
Clearly, CD types have a larger number of event
arguments than TD types. This is also another in-
dication that CD types rely on contexts — they
require more arguments to convey an event.
Linguistic/Lexical Insights. Table 6 give typi-
cal TD and CD types on ACE 2005 (Please refer
to Appendixes for the full set). Intuitively, the
TD types appear to be ﬁner-grained and concrete,
whereas the CD types appear to be coarser-grained
and abstract. For example, we may further sub-
divide a CD type _ into ﬁner-
grained ones like and . We pro-
vide linguistic/lexical insights by comparing the hi-
erarchy levels of TD/CD types on WordNet (Miller,
1992). Accordingly, triggers of TD types are at
the lower level of WordNet, with an average of 5.6
hypernyms; yet CD type triggers are at a higher
level of WordNet, with 2.3 hypernyms. This ﬁnd-
ing supports our intuition that TD types are more
concrete whereas CD types are more abstract.
Case Visualization. Figure 7 depicts the
saliency map of several cases. Accordingly, event
triggers of TD types do usually have large saliency
values. For example, case 2) is the instance of with the lowest trigger saliency value,
which is still as high as 0.34. In contrast, event
triggers of CD types typically have low saliency
values. For example, case 4) and 6) show random
instances of - and ,
where the trigger saliency values are only 0:01.
8 Conclusion
In this study, we analyze the origins of an ED
model’s skewed performance and introduce a new
notion called trigger saliency attribution to quan-
tify the pattern of events. We devise a new train-
ing paradigm for ED that can distinguish between
trigger-dependent and context-dependent types for4580learning, yielding promising results on two bench-
marks. We also examine the differences between
the two types extensively, and our work may pro-
mote future research on this problem. In the future,
we would apply our method to other tasks (e.g., re-
lation extraction) where contextual patterns matter.
Acknowledgments
This work is supported by the National Natu-
ral Science Foundation of China (No.62106016).
This work is also supported by Fundamental Re-
search Funds for the Central Universities (No.
2021RC234), the National Key R&D Program of
China (2019YFB1405200), and the Open Projects
Program of National Laboratory of Pattern Recog-
nition.
References458145824583A The Full Event Types and Their Saliency Values
We provide the full set of event types in ACE (LDC, 2005) and MA VEN (Wang et al., 2020) and their
saliency values evaluated by our method.45844585