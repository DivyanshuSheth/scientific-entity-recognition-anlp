
Ruixiang Cui, Daniel Hershcovich, Anders Søgaard
University of Copenhagen
{rc, dh, soegaard}@di.ku.dk
Abstract
Logical approaches to representing language
have developed and evaluated computational
models of quantiﬁer words since the 19th
century, but today’s NLU models still strug-
gle to capture their semantics. We rely on
Generalized Quantiﬁer Theory for language-
independent representations of the semantics
of quantiﬁer words, to quantify their contribu-
tion to the errors of NLU models. We ﬁnd
that quantiﬁers are pervasive in NLU bench-
marks, and their occurrence at test time is as-
sociated with performance drops. Multilingual
models also exhibit unsatisfying quantiﬁer rea-
soning abilities, but not necessarily worse for
non-English languages. To facilitate directly-
targeted probing, we present an adversarial
generalized quantiﬁer NLI task (GQNLI) and
show that pre-trained language models have a
clear lack of robustness in generalized quanti-
ﬁer reasoning.
1 Introduction
Quantiﬁer words—such as each ormost ormore
than three —have been extensively studied, both in
logic and in linguistics (Westerståhl, 1989; Peters
and Westerståhl, 2006), going all the way back
to Frege (1879). In this paper, we examine the
extent to which they present a challenge to modern
NLU systems. Our analysis is motivated by three
observations:
Quantiﬁer words are abstract Unlike nouns,
verbs and adjectives, quantiﬁer words do not have
referents out in the world. Rather, quantiﬁer
words specify relationships between sets of entities,
events and properties. To provide intuitions about
the semantics of quantiﬁer words, and to be able to
refer to quantiﬁers in a language-independent way,
we rely on the notion of generalized quantiﬁers
(Mostowski, 1957), as described in §2.
Quantiﬁer words vary across languages
Quantiﬁer word inventories differ across languages.
Table 1: Examples of quantiﬁers (marked in bold texts)
in NLP tasks, with RoBERTa’s prediction for QA and
XLM-R’s prediction for NLI after ﬁne-tuning.
Often what is considered rough translation equiva-
lents also differ in syntax, ﬁne-grained semantics
or pragmatics. Stateva et al. (2019) show, e.g.,
that perceptions of the numerical bounds of ex-
istential quantiﬁers differ across speakers of En-
glish, French, Slovenian, and German. Other pa-
pers showing discrepancies between quantiﬁer sys-
tems include comparisons of Salish to English
(Matthewson, 2001), Adyghe to English (Niko-
laeva, 2012), or of Dutch, Hebrew and Bengali
(Gil, 1982). The cross-linguistic differences in how
generalized quantiﬁers are expressed motivates a
cross-lingual error analysis, since quantiﬁers may
contribute more to error when processing some
languages rather than others.
Quantiﬁer words are important Quantiﬁer
words are extremely important for tasks that require
inference, including natural language inference,
question answering, fact-checking, etc. Datasets
have, for example, been developed for numerical
reasoning in English (Dua et al., 2019). Several
researchers have identiﬁed quantiﬁer words as im-
portant sources of errors for natural language pro-
cessing systems (Joshi et al., 2020); see Table 1
for examples of such errors. Unfortunately, most4875
efforts have concentrated on subsets of quantiﬁer
words and on English.
Contributions We analyze how quantiﬁers are
represented in NLU benchmarks, and how their oc-
currence at test time contributes to errors by neural
language models (LMs). We derive a linguistically
motivated 11-way categorization set for general-
ized quantiﬁers and look into their distribution in
three steps: (a) monolingual NLI; (b) cross-lingual
NLI; (c) cross-lingual question answering. We also
propose GQNLI, an adversarial generalized quan-
tiﬁer NLI challenge dataset. Our work shows that
(i) generalized quantiﬁers are pervasive and cause
overall performance drops in NLU benchmarks;
(ii) the contribution of quantiﬁer words to system
error varies across languages; and (iii) generalized
quantiﬁers are particularly difﬁcult for LMs in in-
teraction with negation and subsumption.
2 Background
Generalized quantiﬁers (GQs) are developed upon
ﬁrst-order predicate logic, denoting relations be-
tween sets (Mostowski, 1957). Given a universe
E, a quantiﬁer Qwould be treated as a map-
pingQfrom the Cartesian product of powersets
P(E)×P(E)to the set { false,true } or, as a binary
relation on subsets of E(Dvo ˇrák and Hol ˇcapek,
2015). GQs are generalizations of the ∀,∃quanti-
ﬁers from ﬁrst-order predicate logic (Mostowski,
1957; Lindström, 1966; Montague, 1973; Bach
et al., 1995; Keenan and Paperno, 2012). A general-
ized quantiﬁer is, abstractly, a relation between sets.
Generalized quantiﬁer theory, while developed by
logicians, is used by formal linguists to analyze themeaning of quantiﬁer words in combination with
referential expressions (Barwise and Cooper, 1981;
Higginbotham and May, 1981).
Most human languages contain ways of ex-
pressing generalized quantiﬁers, and their seman-
tics exhibit striking similarities across languages
(Matthewson, 2004; Fintel and Matthewson, 2008;
Steinert-Threlkeld, 2019). At the same time, gen-
eralized quantiﬁers can be instantiated very differ-
ently across languages due to pragmatic considera-
tions (Grice, 1989) or cognitive economy and cost-
beneﬁt optimisation in the exchange of information
(Levinson et al., 2000; Steinert-Threlkeld, 2021;
Uegaki, 2022). Quantiﬁer words also exhibit syn-
tactic differences, e.g., with some languages having
specialized words to express quantity, while others
rely on metaphorical usage of common nouns (Kat-
sos et al., 2012). In English, most is a determiner,
but Spanish and French express the same concept
through common nouns, la mayoría andla ma-
jorité . The relative stability of the core semantics
of quantiﬁers makes a cross-linguistic comparison
possible, but the syntactic and pragmatic variation
associated with the expression of generalized quan-
tiﬁers poses a challenge for multilingual NLU. We
consult quantiﬁer taxonomy studies (Keenan and
Westerståhl, 1997; Peters and Westerståhl, 2006;
Szymanik and Thorne, 2015; Szymanik, 2016) and
derive a categorization set for quantiﬁer analysis
in NLU benchmarks. In Table 2, we list the 11-
way quantiﬁer categorization set and their logical
denotation based on set theory.
While other foci of formal linguistics have at-
tracted the attention of NLP researchers—including
coreference (Ogrodniczuk et al., 2019, 2020), nega-4876
tion (Hossain et al., 2020; Hartmann et al., 2021),
and consistency (Li et al., 2019; Ribeiro et al.,
2019; Asai and Hajishirzi, 2020; Geva et al.,
2022)—there has been little work on generalized
quantiﬁers as a source of error in NLU, let alone
in multilingual NLU. It remains an open problem
whether LMs represent the semantics of quantiﬁers
words adequately, or if they provide a basis for
resolving scopal ambiguities.
3 NLU Benchmarks
We conduct an error analysis focusing on the role of
generalized quantiﬁers in two NLU tasks, Natural
Language Inference (NLI) and Question Answer-
ing (QA), which generally require understanding
of quantiﬁers. For each type of task, both mono-
lingual and cross-lingual evaluation are conducted.
We focus on generalized quantiﬁers in the hypothe-
sesin NLI examples—and on generalized quanti-
ﬁers in the question ﬁelds in question answering.
To this end, we identify quantiﬁers by the lemma
and the universal dependency relation (Nivre et al.,
2020) of a quantiﬁer after preprocessing the sen-
tences using Stanza (Qi et al., 2020). Take the
sentence “The Yiddish culture has survived for
more than a thousand years.”, we annotate it as
“The/ detYiddish/ amod culture/ nsubj have/ auxsur-
vive/ root for/case more/ advmod than/ ﬁxed a/det
thousand/ nummod year/ obl./punct ”. By match-
ing the regex pattern of the quantiﬁer “more
than k”, in this case “((more|great)\/advmod
than\/(ﬁxed|case)|at\/case least\/nmod) .+\/num-
mod .+\/(nsubj|obj|obl)” , we approximate the sur-
face form of the type “more than k”.Through match-
ing quantiﬁer patterns, we are able to ﬁnd entries in
which quantiﬁers are instantiated. See Appendix A
for the list of regex patterns we write to identify
GQs. In Table 3 and Table 6, we present the statis-
tics of the quantiﬁer distributions in NLI and QA
tasks, respectively. As can be seen, quantiﬁers are
indeed widespread in NLU tasks, accounting for
roughly 10% in NLI tasks and 5% in QA tasks. We
will further discuss the statistics and experiments
in the following section.
4 Quantiﬁers in English NLI
Benchmarks
NLI is commonly framed as a three-way classiﬁ-
cation task with labels entailment ,contradiction
andneutral (Bowman et al., 2015a). While SOTA
models exhibit low error rates on NLI benchmarks,
it is unclear when they succeed or fail in their un-
derlying reasoning. We are interested in whether
generalized quantifers challenge modern NLI mod-
els. In our error analysis, we initially focus on three
English NLI datasets, MultiNLI (MNLI; Williams
et al., 2018), SNLI (Bowman et al., 2015a) and
ANLI (Nie et al., 2020) as testbeds.
Table 3 presents statistics of quantiﬁer distri-
bution in these datasets, where we observe that,4877
across, about 10% of all hypotheses contain quan-
tiﬁer words, indicating the pervasiveness of quan-
tiﬁcation. We also plot the frequency of quantiﬁers
in NLI in Figure 1 and ﬁnd the quantiﬁer word
distribution follows Zipf’s law (Zipf, 1949). Note
the top three most common quantiﬁers account for
more than 90% of all.
Experiments and Results In order to investigate
whether NLU systems can solve quantiﬁers in NLI,
we experiment with two pretrained LMs: BERT
(Devlin et al., 2019) and RoBERTa(Liu et al.,
2019). We use the codebase by Nie et al. (2020).
The training data combines SNLI, MNLI, FEVER-
NLI (Nie et al., 2019) and ANLI.
In Table 4, we report the test set performance
on SNLI and ANLI, and the dev set performance
on MLNI matched andmismatched sections. We
can observe that SOTA models suffer from per-
formance drops across almost all quantiﬁcation
phenomena in every task. When it comes to perfor-
mance over all quantiﬁers, the improvement from
RoBERTa to BERT (2.2%) is less prominent than
that over full datasets (2.9%), suggesting RoBERTa
is particularly challenged.
Taking a closer look at error by category, propor-
tional quantiﬁers seem harder to solve than Aris-
totelian/counting quantiﬁers. Except for k%, all
proportional quantiﬁers— p/k,most , and few—are
about 10% lower than the ﬁve counting quanti-
ﬁers (except less than k ) with BERT; and about 5%
lower with RoBERTa. RoBERTa is not generallysuperior to BERT; e.g., for k%, BERT outperforms
it by 22%. We show a pairwise analysis of how
GQs affect performance when they appear in both
the premises and hypotheses in the Appendix B.
Generally, our results attest to the difﬁculty of re-
solving GQs in NLI benchmarks.
5 Quantiﬁers in Cross-lingual NLU
Benchmarks
Quantiﬁers are acquired in similar orders across lan-
guages (Katsos et al., 2016), although languages
express quantiﬁers in different ways. For exam-
ple, there are eight different universal quantiﬁers
with different level of distributivity in Malagasy
(Matthewson, 2008). This poses challenges to train-
ing multilingual LMs and transfer learning. We are
interested in whether quantiﬁers are universally and
evenly challenging for all languages.
Quantiﬁers in Cross-lingual NLI We choose
XNLI (Conneau et al., 2018), a manual transla-
tion of the development and test set of MNLI into
15 languages, for this multilingual error analysis.
We should clarify that for XNLI, the authors anno-
tate entailment labels for the English data only and
apply them to the other languages. We do not as-
sume label changes due to translation in this study,
but it is worth investigate in the future. We choose
ﬁve languages belonging to different language fam-
ilies, namely Arabic, Chinese, German, Spanish
and Vietnamese as targets. The last column in Ta-
ble 3 shows the numbers of quantiﬁers in XNLI.
The distribution rate is 10%. Note that the universal
quantiﬁer is the most common quantiﬁer in XNLI.4878
We ﬁne-tune mBERT(Devlin et al., 2019) and
XLM(Lample and Conneau, 2019) on the MNLI
training set and evaluate them on XNLI. We report
the results in Table 5. We ﬁnd that performance
varies across languages. For Chinese and Viet-
namese, we see signiﬁcant drops in performance
for examples with GQs, whereas for Arabic and
German, we see improvements. The results per
quantiﬁer are more homogeneous, however.
Similar to our results for English, we can see
that the lowest accuracies in XNLI are with pro-
portional quantiﬁers, such as most andfew. But
the gap in non-English languages is wider for these
two categories, especially for Chinese, the differ-
ence reaches 30%. Other hard quantiﬁers include
all,> k,< k, and each other .Quantiﬁers in Cross-lingual QA Cross-lingual
question answering (XQA) is another important
NLU task that evaluates the cross-lingual transfer-
ability of LMs. We evaluate the effect of quantiﬁers
on system errors across two XQA datasets, namely
XQuAD (Artetxe et al., 2020) and MLQA (Lewis
et al., 2020). As demonstrated in Figure 1, quan-
tiﬁer word distributions in XQA tasks also follow
Zipf’s law, as in NLI tasks, but kis more frequent
(perhaps because of a traditional emphasis on nu-
merical reasoning), and we see less variance across
languages. This is probably because question an-
swering is targeting quantiﬁcation less directly. To
evaluate cross-lingual QA performance on GQs,
we ﬁne-tune mBERT and XLM-R(Conneau et al.,
2020) using Hu et al. (2020)’s architecture. We
present results for mBERT in Table 7; for XLM-R
results, please refer to Appendix D.
Just as with XNLI, LMs suffer from performance
drops across all languages for almost all GQ phe-
nomena with signiﬁcant, cross-lingual variation.
The most distinguished is that Exact Match (EM)
suffers from a greater deterioration than F1 scores
for all languages. For example, the weighted EM
difference for mBERT on MLQA is 2.9% while
the weighted F1 is 1%. As one example in Table 1,
we observe that the plausible answers selected by
models, while being incorrect, result in a sharper
decrease of EMs comparing to F1s. Questions con-
taining GQs also tend to have less verbal answers
comparing to those without GQs, and therefore
require higher precision.
Regarding cross-lingual comparisons, Chinese
and Arabic are the two languages that do not have4879
lower performance over GQs compared to the per-
formance over the complete dataset. Despite the
overall trends, subtle differences from XNLI per-
formance still exist. For example, XLM-R is worse
than mBERT on quantiﬁer reasoning on XQuAD
Chinese, especially at proportional quantiﬁers, but
this is not the case on MLQA Chinese.
6 GQNLI
We have seen how quantiﬁers present challenges
to NLI and QA models. Using an approach similar
to ANLI (Nie et al., 2020) and DynaBench (Kiela
et al., 2021), we use model difﬁculty (RoBERTa’s)
as a heuristic to select hard examples for a chal-
lenge dataset that can hopefully be used to evaluate
any future progress on this. We propose GQNLI, a
generalized quantiﬁer NLI challenge dataset, con-
sisting of 30 premises and 300 hypotheses. The av-
erage sentence lengths of hypothesis and premises
are 15.97 and 7.35, respectively. Both numbers
are comparable to those of MNLI, but lower than
ANLI’s (Williams et al., 2020). It should be noted
that GQNLI is designed for evaluating future mod-
els; obviously not for benchmarking RoBERTa.
Dataset Creation Firstly, we manually create
100 premise-hypothesis pairs, in which various
types of GQs appear. For each premise and hy-
pothesis, the number of GQs varies from one to
three. To choose the premises, we randomly sam-
pled 100 premises with GQs from SNLI and ANLI
test sets, respectively, and selected 10 premises in
total, that we consider are semantically adequate
for adding GQs and making simple hypotheses.
To construct the hypotheses, we rely on
RoBERTa ﬁne-tuned on MNLI and manually select
examples about which the model is unsure or incor-
rect. To focus on GQs, we keep the challenge ex-
amples otherwise simple (Ribeiro et al., 2020), and
avoid lexical variations in the hypotheses. Hard
examples were found to be characterized by (i)
mixing generalized quantiﬁers with other logicaloperators, such as subsumption or negation, and
(ii) combining multiple different generalized quan-
tiﬁers. We discuss these observations in Section
7.
Two of the authors annotated the examples.
The inter-annotator agreement (Fleiss’ kappa) was
0.895, substantially higher than ANLI’s (0.672–
0.740). It is worth noting that the level of semantic
or pragmatic interpretation difference of GQs is
reﬂected in the measurement.
We augmented the examples by substituting
non-quantiﬁer words (e.g., replacing “dogs” with
“cats”) while keeping the labels, to exclude the ef-
fect of speciﬁc lexical items. The resulting labels
are uniformly distributed. Table 8 presents GQNLI
statistics. Since the dataset is curated to probe the
ability to reason with quantiﬁers, the distribution of
generalized quantiﬁers does not follow Zipf’s law;
see §4. A list of GQNLI examples per category is
shown in Appendix E.
Experiments and Results We evaluate seven
types of models on GQNLI, ﬁne-tuned with dif-
ferent combinations of NLI datasets. As data cre-
ation only relied on RoBERTa and MNLI, nothing
prevents that models with different architectures
and training data will perform well. They do not,
however. The results are shown in Table 8.
We see that all models have great difﬁculty with
GQNLI. With more training data, models improve,
but the best performance is 48%, less than 15 points
above chance level. In general, the counting quanti-
ﬁers, especially the existential and universal quan-
tiﬁers, are easier than proportional quantiﬁers. Par-
ticularly, most models struggle with less than k and
between . This is in some contrast with the NLU
tasks studied above, where these quantiﬁers were
among the easiest.
We also observe unstable GQ reasoning ability
in simple word substitution cases. For instance, it
happens for DeBERTa ﬁne-tuned with M, F, Ling,
DocNLI that it predicted correctly the contradiction4880
relation between “There are six children standing
on top of a yellow mountain. Two thirds wear red
tops and one third wear green.” and “Between
80% and 90% children do not wear red tops.”, but
incorrectly when “red” is substituted with “beige”
and “green” with “cyan”. We are yet to study what
kind of cues lead to the instability. Our experiments
suggest a lack of testing proportionality reasoning
and robustness in existing benchmarks.
7 Discussion
Negation The interaction between negation
words and quantiﬁers increases semantic complex-
ity (Partee, 1970; Horn, 2010). We investigate
whether this holds for NLI tasks, using negation
cue detection to ﬁnd all cases where a negation
word and a quantiﬁer appear in the hypotheses.
We break down the performances on negation
of the seven models in Appendix F. As indicated,
LMs overall have polarized results for negation
cases comparing to the entire dataset. We can see
a majority of the models even predicted opposite
labels for some GQ categories, with 0% accuracy.
BART is no longer the second best model, replaced
by RoBERTa. The improvement by training with
more data is overall consistent for reasoning over
GQs with negation.
For a cross-lingual investigation of the interac-
tion of GQs and negation, we ﬁnd that in XNLI,
the number of cases combining both phenomena is
insufﬁcient: we identiﬁed four such cases, involv-
ing only the quantiﬁers “all” and “more than.” ForEnglish, mBERT predicted two cases successfully.
For Chinese, German, Vietnamese and Arabic, one
is correct. For Spanish, all are wrongly predicted.
It is evident that NLU models suffer from rea-
soning difﬁculties in certain cases when negation
interacts with GQs, especially in cross-lingual eval-
uation. In future work, we are interested in expand-
ing GQNLI to more instances and more languages
to facilitate qualitative investigations.
Subsumption In generalized term subsumption
languages (TSLs; Yen, 1991; Ali and Shapiro,
1993), a term asubsumes another term bif and
only if the extension of ais a superset of the ex-
tension of b. Rather than surface number compar-
ison, subsumption reasoning requires knowledge
of the relations between supersets and subsets. For
example, to decide whether “There are six dogs.
Three brown dogs, a black dog and a white dog run
along the green grass” entails “One dog sits”, LMs
should be aware that “six dogs” is a superset of the
extension of the “brown dogs”, “black dog” and
“white dog”. Another example in GQNLI is to infer
whether “There are twelve singers on a stage, less
than half from Argentina and one from Cape Verde”
entails “Several singers do not come from Chile”.
We annotate 63 cases out of the ﬁrst 100 in
GQNLI requiring subsumption reasoning. We
show the statistics and results regarding subsump-
tion in Appendix G. It can be seen that more train-
ing data leads to higher accuracies. Especially,
DeBERTa ﬁne-tuned with DocNLI, which uniﬁes4881the two classes “neutral” and “contradict” into a
new class “not entail”, has a signiﬁcant improve-
ment on subsumption cases with neutral label. The
training bias give an advantage to the model on
the subsumption subset, half cases of which are
labelled neutral. But such bias has a negative ef-
fect on non-subsumption cases; the accuracy drops
by 20.2% comparing to the model without train-
ing with DocNLI. It is worth investigating whether
DocNLI is truly helping subsumption reasoning in
future work. Subsumption is a key concept in the
study of knowledge representation (Woods, 1991),
but is neglected in current NLP research. The fact
that LMs struggle to perform subsumption reason-
ing asserts the necessity to explicit tackle the prob-
lem.
8 Related Work
We examine the sensitivity of NLU models to gen-
eralized quantiﬁers. These models are designed
to induce correlations from large volumes of data,
not to reason symbolically with logical quantiﬁers.
Such models have, nevertheless, been probed for
logical knowledge.
Mul and Zuidema (2019), for example, show
neural networks encode fragments of ﬁrst-order
logic and exhibit zero-shot generalization ability.
Evans et al. (2018) present a neural architecture
that improves performance on propositional logi-
cal inference. Bowman et al. (2015b) also suggest
neural networks learn semantic representations for
logical inference in natural languages. However,
on the same task, Veldhoen and Zuidema (2017)
ﬁnd neural networks fail to do so on a more strin-
gent test. Geiger et al. (2019) also show that neural
networks fail to exhibit robust logical inference.
Srivastava et al. (2018) use semantic parsers to en-
code quantiﬁers and improve zero-shot learning in
classiﬁcation tasks. Haruta et al. (2020) present a
system that computes logical inference over GQs
and see improvements on two specialized datasets,
FraCaS (Cooper et al., 1994) and MED (Yanaka
et al., 2019). None of these papers explicitly dis-
cussed generalized quantiﬁers, and all were limited
to studying the ability of neural networks to capture
the logical semantics of English.
Many studies have instead focused on LMs’ abil-
ity to capture negation (Gururangan et al., 2018;
Naik et al., 2018; Hossain et al., 2020; Ettinger,
2020; Hartmann et al., 2021) or coreference (Ye
et al., 2020; Varkel and Globerson, 2020; Abdouet al., 2020). Others have focused on LMs’ abil-
ity to reason with numbers (Johnson et al., 2020).
DROP (Dua et al., 2019), for example, is a question
answering dataset designed speciﬁcally to probe
LMs’ ability to count, add and subtract for answer-
ing factoid questions. Models have also been tai-
lored for numerical reasoning (Geva et al., 2020;
Zhang et al., 2020). Cobbe et al. (2021) proposes
to use a veriﬁcation task during pretraining of LMs
to improve their ability to solve math word prob-
lems. Others have studied monotonicity inference
(Hu et al., 2019; Yanaka et al., 2019, 2020), and
Fang and Lou (2021) recently focused on the two
quantiﬁer words partandwhole in an error analysis
for named entity recognition.
Many NLU benchmarks contain quantiﬁer
words, but their inﬂuence on performance has not
been studied systematically. One exception to this
is that generalized quantiﬁers have been used to
generate adversarial examples in the context of nu-
merical reasoning (Naik et al., 2018; Nie et al.,
2020). TaxiNLI (Joshi et al., 2020), which cate-
gorizes 15 types of reasoning abilities, is a dataset
drawn from MNLI. In their taxonomy, the Quanti-
ﬁer category only refers to universal and existen-
tial quantiﬁers, notto generalized quantiﬁers, and
ditto for Kim et al. (2019). All of the above fo-
cused on English, but in an extension to TaxiNLI,
K et al. (2021) incorporated quantiﬁers into the
Logic class and found a large cross-lingual transfer
gap on LMs.
9 Conclusion
Quantiﬁers lie in the intersection of logic, linguis-
tics and NLP research. It is essential for NLU
systems to learn quantiﬁer reasoning. We exam-
ined generalized quantiﬁers in multilingual NLU
tasks with regards to their expressiveness and logi-
cal reasoning requirement. Our survey and experi-
ments indicate quantiﬁers are neglected to a degree
and cause signiﬁcant performance drops for neural
LMs. To better understand LMs’ reasoning abili-
ties, we release GQNLI, a novel generalized quanti-
ﬁer NLI challenge dataset. With the pervasiveness
of generalized quantiﬁers, we stress that more ef-
forts are necessary to investigate: (1) when and
why models systematically fail when quantiﬁers
interact with other operators; (2) how to improve
cross-lingual transferability of quantiﬁers; (3) how
we can exploit the theoretical results about gener-
alized quantiﬁers from logic and linguistic studies,4882so as to improve the logical inference ability of
neural LMs.
Acknowledgements
We would like to thank Miryam de Lhoneux, Con-
stanza Fierro, Desmond Elliott and the anonymous
reviewers for their valuable feedback.
References48834884488548864887
Appendices
A Regular Expressions for Generalized Quantiﬁers
Table 9 lists the regex we use to parse generalized quntiﬁers in sentences augmented with universal
dependency tags. The approach does not ﬁnd all the generalized quantiﬁers exhuastively but rather
approximates the common distributions.
B Pairwise Observation
While the analysis in Section 4 is based on quantiﬁers in hypotheses, next we consider the interaction of
quantiﬁers in hypotheses and quantiﬁers in premises. To this end, we calculate the difference between
overall performance and performance for premise-hypothesis pairs of GQs. In Figure 2, we visualize the
results as heatmaps (see Table 10 for exact numbers of occurences and accuracies). Surprisingly, whenever
quantiﬁers appear in both the premise and the hypothesis, LMs largely fail to predict the entailment.
Percentage quantiﬁers, supposed to be semantically more complex than counting quantiﬁers, are not de
facto harder in NLI. We studied all 27 cases of percentage quantiﬁers in the English NLI datasets, and
found that in most cases, percentage quantiﬁers occurrences are identical across premises and hypotheses,
i.e., triggering little or no inference. The other two proportional quantiﬁers, most andfew, are hard for4888
LMs to resolve, e.g., in some quantiﬁer pairs, models yield 0% accuracy. Although each other is supposed
to be hardest to resolve due to the complex semantics of reciprocals (Szymanik and Thorne, 2015), it is
not reﬂected in NLI tasks as such. The reason is similar to percentage quantiﬁers, while annotators intend
to alter counting quantiﬁers when writing hypotheses, reciprocality is seldomly considered a linguistic
ability that needs testing for NLU systems. And the annotation for Ramsey quantiﬁer is simply a knockoff,
making reciprocal relation identiﬁcation unwarranted through shallow correlations.
C Fine-grained NLI Analysis
D XQA Result: mBERT and XLM-R
Table 11 compares the results of mBERT and XLM-R on two XQA tasks, XQuAD and MLQA.
E GQNLI Examples
Table 12 list one example per category in GQNLI.
F GQNLI Negation Cases
We present the results of seven models’ performance on cases with negation cues in GQNLI in Table 13.
G GQNLI Subsumption Cases
See Table 14 for models ’performance on cases requiring subsumption reasoning in GQNLI. We also
break down subsumption results by entailment labels into two categories: neutral and non-neutral.4889H GQNLI Experiment Details
We reused the ﬁne-tuned BERT and RobERTa in Section 4. The other ﬁne-tuned LMs are from Hugging
Face. We list the models and thier links in Table 15.4890489148924893