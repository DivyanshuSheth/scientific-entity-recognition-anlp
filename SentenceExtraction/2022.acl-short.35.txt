
Suvodip Dey, Ramamohan Kummara, Maunendra Sankar Desarkar
Indian Institute of Technology Hyderabad, India
Abstract
Dialogue State Tracking (DST) is primarily
evaluated using Joint Goal Accuracy (JGA) de-
fined as the fraction of turns where the ground-
truth dialogue state exactly matches the predic-
tion. Generally in DST, the dialogue state or
belief state for a given turn contains all the in-
tents shown by the user till that turn. Due to
this cumulative nature of the belief state, it is
difficult to get a correct prediction once a mis-
prediction has occurred. Thus, although being
a useful metric, it can be harsh at times and un-
derestimate the true potential of a DST model.
Moreover, an improvement in JGA can some-
times decrease the performance of turn-level or
non-cumulative belief state prediction due to
inconsistency in annotations. So, using JGA as
the only metric for model selection may not be
ideal for all scenarios. In this work, we discuss
various evaluation metrics used for DST along
with their shortcomings. To address the exist-
ing issues, we propose a new evaluation metric
named Flexible GoalAccuracy ( FGA ). FGA is
a generalized version of JGA. But unlike JGA,
it tries to give penalized rewards to mispredic-
tions that are locally correct i.e. the root cause
of the error is an earlier turn. By doing so, FGA
considers the performance of both cumulative
and turn-level prediction flexibly and provides
a better insight than the existing metrics. We
also show that FGA is a better discriminator of
DST model performance.
1 Introduction
Dialogue State Tracking (DST) is at the core of
task-oriented dialogue systems. It is responsible
for keeping track of the key information exchanged
during a conversation. With the growing popularity
of task-based conversational agents, it is essential
to review the evaluation of DST to appropriately
measure the progress in this evolving area.
The task of DST is to predict the user intent
through dialogue states (Henderson et al., 2014).
Fig. 1 shows an example DST task from Multi-WOZ (Budzianowski et al., 2018) dataset. Let U
andSbe the user and system utterances respec-
tively at turn t. Then a typical conversation can
be expressed as D={U,(S, U), ...(S, U)}.
The commonly used ground-truth dialogue state
for DST is the belief state. Belief state Bfor turn
tis defined as the set of (domain, slot, slot-value)
triplets that have been extracted till turn t, thereby
it is cumulative in nature. The objective of DST is
to predict Bgiven the dialogue history till turn t.
The primary metric for evaluating DST is Joint
Goal Accuracy (JGA). It compares the predicted
dialogue states to the ground truth Bat each dia-
logue turn t(Henderson et al., 2014). As the belief
state is cumulative, it is very unlikely for a model
to get back a correct prediction after a mispredic-
tion. This is why it can provide an underestimated
performance in certain cases. Besides, JGA com-
pletely ignores the performance of turn-specific
local predictions. Let Tbe the turn-level belief
state that contains all the intents or (domain, slot,
slot-value) triplets expressed by the user only at
turnt. Ideally, a model with higher JGA should
also perform equally well to predict T. But, we ob-
serve that improving JGA can sometimes degrade
the performance of predicting Tmainly due to the
presence of annotation inconsistencies in the avail-
able datasets. For example, in Fig. 1, the presence
of(hotel, area, centre) and absence of (attraction,
name, all saints church) in ground-truth Band
Bshows such inconsistencies. So, the general-
ization of the model may get compromised if the
model selection is done only using JGA. Anno-
tation inconsistencies and errors are common in
real-world datasets. Hence, to provide a fair esti-
mate, it requires not only track the performance of
the cumulative belief state but also turn-level belief
state as well.
In this work, we address these issues of JGA by
proposing a novel evaluation metric for DST called
Flexible GoalAccuracy ( FGA ). The central idea of318FGA is to partially penalize a misprediction which
is locally correct i.e. the source of the mispredic-
tion is some earlier turn. The main contributions of
our work are as follows:
•Detailed analysis of the existing DST metrics.
•Proposal of Flexible Goal Accuracy (FGA)
than can keep track of both joint and turn-
level performances simultaneously.
•Justification of FGA along with performance
comparison on the MultiWOZ dataset.
2 Discussion on existing DST metrics
2.1 Joint goal accuracy
Joint accuracy or joint goal accuracy (JGA) checks
whether the set of predicted belief states exactly
matches the ground truth for a given user turn (Hen-
derson et al., 2014; Wu et al., 2019). Let Band
Bbe the set of ground-truth and predicted belief
states at turn t. Then the prediction of turn tis
considered to be correct if and only if Bexactly
matches B. Fig. 1 shows an illustration of the pre-
dicted belief state where the predictions of Bare
generated using SOM-DST (Kim et al., 2020). In
the example, there are 2 out of 6 correct predictions
ofBthat result in a JGA score of 33.33% for the
whole conversation.
Although joint goal accuracy is a convenient met-
ric to evaluate DST, it has certain limitations. The
main source of the issue is the cumulative nature of
ground-truth B. As a result, once a misprediction
has occurred, it is difficult to get back a correct
prediction in subsequent turns. For example, in
Fig. 1, the prediction goes wrong in Turn 2which
affects all the later predictions. So, it is very likely
to get a JGA of zero if the model somehow mispre-
dicts the first turn. Therefore, JGA can undermine
the true potential of a DST model and provide an
underestimated performance.
In addition, JGA does not take into account turn-
level performances. For instance, in Fig. 1, Turn 3
and5are locally correct but JGA will mark them 0
sinceBandBhas not matched exactly. Normally,
it is expected that increasing the exact matches will
also reflect in turn-level matches. But we observed
that sometimes increasing exact matches can de-
crease turn-level matches mainly due to annotation
inconsistencies. So, one should be careful while
using only joint accuracy for model selection. Be-
sides, the available DST datasets (like MultiWOZ)
contain a lot of annotation errors (Zang et al., 2020).
For example in turn 4, the model has predicted the
intent (attraction, name, all saints church) . Al-
though the prediction looks rational, the triplet is
absent in the ground-truth. So, if a mismatch occurs
due to an annotation error, it is highly probable that
all the subsequent turns will be marked incorrect
leading to an underestimated performance.
Hence, using joint goal accuracy for evaluating
DST works fine if there are no annotation errors
and the sole purpose is to improve the prediction of
cumulative belief state. Otherwise, there is a need
to include turn-level performance in order to obtain
a fair evaluation of a DST model.3192.2 Slot Accuracy
Slot accuracy (SA) is a relaxed version of JGA that
compares each predicted (domain, slot, slot-value)
triplet to its ground-truth label individually (Wu
et al., 2019). Let Sbe the set of unique domain-
slot pairs in the dataset. Let BandBbe the set
of ground-truth and predicted belief states respec-
tively. Then slot accuracy at turn tis defined as
SA=|S| − |X| − |Y|+|P∩Q|
|S|, (1)
where X= (B\B),Y= (B\B),Pis the set
of unique domain-slot pairs from X, andQis the
set of unique domain-slot pairs from Y. Basically,
in Equation 1, |X|and|Y|represent the number
of false negatives and false positives respectively.
Note that if the value of a ground-truth domain-slot
pair is wrongly predicted then this misprediction
will be counted twice (once in both XandY). The
term|P∩Q|in the above equation helps to rectify
this overcounting. In MultiWOZ, the value of |S|
is 30. For Turn 2 in our running example, since
|B\B|= 2and|B\B|= 0, slot accuracy is
equal toi.e. 93.33%. Slot accuracy for
the entire conversation in Fig. 1 is 94.44%.
The value of slot accuracy can be very mislead-
ing. For instance, even if the prediction of Turn 2 is
wrong in Fig. 1, we get a slot accuracy of 93.33%
which is extremely high. Basically, slot accuracy
overestimates the DST performance. Let us exhibit
this fact by considering the case where we predict
nothing for all turns i.e. B=∅,∀t. Then, slot
accuracy simplifies to. It is natural that
|B|<<|S|because a conversation will typically
have only a small number of domain-slot pairs live
at any time. As a result, slot accuracy remains on
the higher side ( ≈81% for MultiWOZ 2.1) even if
we predict nothing. For datasets with a larger num-
ber of domain/slots, since |S|is large, slot accuracy
will be close to 1 for almost all scenarios. Thus,
slot accuracy is a poor metric to evaluate DST.
2.3 Average Goal accuracy
Average goal accuracy (AGA) is a relatively newer
metric proposed to evaluate the SGD dataset (Ras-
togi et al., 2020). Here, the slots that have a non-
empty assignment in the ground-truth dialogue
state are only considered during evaluation. Let
N⊆Bbe the set of ground-truth triplets having
non-empty slot-values. Then AGA is computed aswhere Bis the predicted belief state forturnt. The turns having N=∅are ignored during
the computation of AGA. In Fig. 1, AGA for turn
2 is 4/6, and 76.19% for the entire conversation.
This metric has mainly two limitations. Firstly,
AGA is only recall-oriented and thereby does not
consider the false positives. Ignoring the false pos-
itives makes this metric insensitive to extraneous
triplets in the predicted belief state. However, this
issue can be easily addressed by redefining AGA
as. But there still exists a second major
problem with AGA. Note that even if a turn is com-
pletely wrong, AGA for that turn can still be higher
because of the correct predictions in the previous
turns. For example, even if turn 2 and 4 are incor-
rect, we get an AGA of 4/6 and 5/7 respectively
which clearly indicates an overestimation.
3 Flexible Goal Accuracy
From the previous discussion, it is evident that
despite a few limitations, joint goal accuracy is su-
perior to the other two metrics. This is why with
the objective to obtain a better evaluation metric
for DST, we address the shortcomings of JGA by
proposing a new metric called Flexible goal accu-
racy (FGA). The description of FGA is presented
in the next part of this section, whereas its working
is described as a pseudo-code in Algo. 1.
For a given a turn t, an error in belief state predic-
tion (i.e. B̸=B) can occur in two ways: 1) the
source of the error is turn titself i.e. the turn-level
prediction is wrong, 2) the turn-level prediction of
turntis correct but the source of the error is some
earlier turn t≺t. FGA works differently from
JGA only for type 2 errors. Unlike JGA, FGA does
not penalize type 2 errors completely. It assigns
a penalized score based on the distance between
the error turn ( t) and the current turn ( t) and the
penalty is inversely proportional to this distance
(t−t). The main idea is to forget the mistakes
with time in order to attain a fair judgment of a
DST model offline.
We decide the correctness of a turn-level match
using the logic shown in line 10 of Algo. 1. A turn
t >0is locally correct if ( T⊆BandT⊆B)
where T=B\BandT=B\B. In
other words, a turn-level or local match indicates
that all the intents shown by the user in a particular
turn have been correctly detected without any false
positives. Just comparing TandTto check a
turn-level or local match can be erroneous because
it will not credit the model for error corrections.320Algorithm 1: FGA for single conversation
Input: B=list of groun-truth belief states,
B= list of predicted belief states,
N= #turns
Output: Flexible goal accuracyT={0,1, . . . , N −1},t← −∞ , f = 0fort∈Tdo w←1 ifB̸=Bthen ift= 0then
/*Type 1 error */ w←0,t←t else T←B\B T←B\B ifT̸⊆BorT̸⊆Bthen
/*Type 1 error */ w←0,t←t else
/*Type 2 error */ x←(t−t) w←1−exp(−λx) f←f+wreturn f/N
For the penalty function, we use the CDF of expo-
nential distribution (shown in Line 14 of Algo. 1)
parameterized by λwhere λ≥0. Clearly, the strict-
ness of FGA is inversely proportional to λ. Note
thatλ= 0will reduce FGA to JGA (strict metric)
whereas λ→ ∞ will report only the accuracy on
turn-level matches (relaxed metric). Finding the
appropriate λfor a specific DST task should be
done carefully in order to match the desired evalu-
ation criteria. However, we can take a theoretical
stand and approximate the hyper-parameter value
asλ=−ln(1−p)/twhere tis the number of
turns that it will take to forget a mistake by factor
pwhere (0≤p <1). For example, if t=6 and
p=0.95, then λ=0.499. So, the strictness of FGA
is directly proportional to tand inversely propor-
tional to p. If the dataset is clean, one can alterna-
tively find the best λthrough a human evaluation,
although it would require additional human effort.
Hence, we can flexibly set the strictness criteria of
FGA through the hyper-parameter λaccording to
our requirement.
In our running example (Fig. 1), the FGA score
for each turn with λ= 0.5is {1, 1, 0, 0.39, 0, 0.39}
which results in a FGA score of 46.33% for theentire conversation. We can observe two things
from these numbers. Firstly, it is not overestimat-
ing in comparison to SA and AGA. Secondly, it
gives a better estimate than JGA in keeping track of
both exact and turn-level matches simultaneously.
Hence, FGA can provide a relatively balanced esti-
mate than the existing metrics even in the presence
of annotation errors and inconsistencies.
4 Result and Analysis
In this section, we report the performance of FGA
along with the other metrics on four different DST
models: TRADE (Wu et al., 2019), Hi-DST (Dey
and Desarkar, 2021), SOM-DST (Kim et al., 2020),
and Trippy (Heck et al., 2020). We use the Mul-
tiWOZ 2.1 dataset (Eric et al., 2020) as most of
the recent progress in DST are showcased on this
dataset. The results are reported in Table 1. Since
the MultiWOZ dataset covers many domains (ho-
tel, restaurant, taxi, train, attraction) where each
domain may have different levels of tolerance (in-
tuitively train, taxi booking may be strict whereas
information seeking about attraction, restaurant do-
mains may be lenient), an overall common/single
strictness setting for the entire dataset may be diffi-
cult to reach at. Hence, we reported the FGA score
for multiple values of hyper-parameter λrather
than showing the result for a single value. For the
same reason, we did not try to find the best λfor
evaluating the MultiWOZ dataset.
From Table 1, we can observe that Trippy has
the best JGA. Currently, most of the state-of-the-art
DST performances are shown using Trippy. How-
ever, we can notice that Trippy does not have the
same performance gain for turn-level matches. It
has lesser turn-level matches than SOM-DST and
Hi-DST. This behavior of Trippy can be a side-
effect of boosting the JGA using its intricate featur-
ization. In contrast, Hi-DST optimizes explicitly
for turn-level non-cumulative belief states, thereby
achieving better turn-level accuracy at the expense
of JGA. Among the four models, SOM-DST per-
forms well for both objectives because of their so-
phisticated selective overwrite mechanism. Now,
by comparing the numbers of Table 1, we can infer
that FGA does a better job in providing a fair esti-
mate while considering both exact and turn-level
matches. Moreover, we can also notice that FGA
acts as a better discriminator of DST models in
comparison to the existing metrics.
Human Evaluation: We conducted a human321
evaluation involving 11 evaluators on 100 randomly
picked conversations from the MultiWOZ 2.1 test
data. For each turn in a conversation, we pro-
vided the system and user utterances along with the
ground-truth and predicted belief states. The pre-
dictions were generated using SOM-DST. For each
conversation, the evaluators were asked to report
their satisfaction ( 1) or dissatisfaction ( 0) with the
performance of the model in keeping track of user
intent throughout the conversation. Pearson corre-
lation coefficient of JGA and FGA (with λ= 0.5)
with human ratings came out to be 0.33 and 0.37
respectively. This shows that FGA is slightly better
correlated than JGA with human evaluation.
5 Conclusion
In this work, we analyzed the limitations of exist-
ing DST metrics. We argued that joint accuracy
can underestimate the power of a DST algorithm,
whereas slot and average goal accuracy can overes-
timate it. We addressed the issues of joint accuracy
by introducing Flexible goal accuracy (FGA) which
tries to give partial credit to mispredictions that are
locally correct. We justified that FGA provides a
relatively balanced estimation of DST performance
along with better discrimination property. In con-
clusion, FGA is a practical and insightful metric
that can be useful to evaluate future DST models.
References322A Appendix
A.1 MultiWOZ Dataset
MultiWOZ (Budzianowski et al., 2018) is a popular
DST corpus that contains both single and multi-
domain conversations. For this work, we used
MultiWOZ 2.1 (Eric et al., 2020) which is an up-
dated version of the original MultiWOZ 2.0 dataset.
In addition to the original dataset, MultiWOZ 2.1
contains fixes to some noisy annotations. Table 2
shows few elementary statistics of the dataset.
A.2 Result generation procedure
We generated results for four DST models - Trade
(Wu et al., 2019), Hi-DST (Dey and Desarkar,
2021), SOM-DST (Kim et al., 2020), and Trippy
(Heck et al., 2020). We used their official code
to train them on MutiWOZ 2.1 dataset. All four
models generate an inference file that contains the
predicted belief states for the test set. We used these
inference files to compute the values of different
metrics shown in Table 1. As we trained all the
models from scratch, the results may not be exactly
the same as those reported in the original paper.
A.3 Human evaluation format
For each randomly picked conversation for human
evaluation, we prepared a file that logged the utter-
ances, ground-truth, and predicted belief state for
each turn. Additionally, we indicated whether the
ground truth exactly matched the predicted belief
state to speed up the evaluation process. A sample
file format is shown in Fig. 2.323324