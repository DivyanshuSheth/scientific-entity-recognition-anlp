
Shiquan Yang, Rui Zhang, Sarah Erfani, and Jey Han LauThe University of Melbourne,www.ruizhang.info{shiquan@student., sarah.erfani@, laujh@}unimelb.edu.au,rayteam@yeah.net
Abstract
We study the interpretability issue of task-
oriented dialogue systems in this paper. Pre-
viously, most neural-based task-oriented dia-
logue systems employ an implicit reasoning
strategy that makes the model predictions un-
interpretable to humans. To obtain a trans-
parent reasoning process, we introduce neuro-
symbolic to perform explicit reasoning that
justifies model decisions by reasoning chains.
Since deriving reasoning chains requires multi-
hop reasoning for task-oriented dialogues, ex-
isting neuro-symbolic approaches would in-
duce error propagation due to the one-phase
design. To overcome this, we propose a two-
phase approach that consists of a hypothesis
generator and a reasoner. We first obtain mul-
tiple hypotheses, i.e., potential operations to
perform the desired task, through the hypothe-
sis generator. Each hypothesis is then verified
by the reasoner, and the valid one is selected
to conduct the final prediction. The whole sys-
tem is trained by exploiting raw textual dia-
logues without using any reasoning chain an-
notations. Experimental studies on two public
benchmark datasets demonstrate that the pro-
posed approach not only achieves better results,
but also introduces an interpretable decision
process. Code and data: https://github.
com/shiquanyang/NS-Dial .
1 Introduction
Neural task-oriented dialogue systems have en-
joyed a rapid progress recently (Peng et al., 2020;
Hosseini-Asl et al., 2020; Wu et al., 2020), achiev-
ing strong empirical results on various benchmark
datasets such as SMD (Eric et al., 2017) and Multi-
WOZ (Budzianowski et al., 2018). However, most
existing approaches suffer from the lack of explain-
ability due to the black-box nature of neural net-
works (Doshi-Velez and Kim, 2017; Lipton, 2018;
Bommasani et al., 2021), which may hurt the trust-
worthiness between the users and the system. ForFigure 1: An example dialogue that incorporates exter-
nal KB. The context entity (i.e., Leichhardt ) and answer
entity (i.e., Cityroom ) are marked as Red and Yellow,
respectively. The triple containing the context entity and
answer entity is not directly stored in KB and should
be derived by a reasoning chain formed by multiple KB
triplets.
instance, in Figure 1, a user is asking for a ho-
tel recommendation at a given location. The sys-
tem performs reasoning on a knowledge base (KB)
and incorporates the correct entity in the response.
However, when the system fails to provide the cor-
rect entities, it would be difficult for humans to
trace back the issues and debug the errors due to
its intrinsic implicit reasoning nature. As a result,
such system cannot be sufficiently trusted to be
deployed in real-world products.
To achieve trustworthy dialogue reasoning, we
aim to develop an interpretable KB reasoning as
it’s crucial for not only providing useful informa-
tion (e.g., locations in Figure 1) to users, but also
essential for communicating options and selecting
target entities. Without interpretability, it’s difficult
for users to readily trust the reasoning process and
the returned entities.
To tackle this challenge, we present a novel
Neuro- Symbolic Dialogue framework ( NS-Dial )
which combines representation capacities of neural
networks and explicit reasoning nature of symbolic
approaches (e.g., rule-based expert systems). Ex-
isting neuro-symbolic approaches (Vedantam et al.,49182019; Chen et al., 2020) mostly employ a one-
phase procedure where a tree-structured program
composed of pre-defined human interpretable neu-
ral modules (e.g., attention and classification mod-
ules in Neural Module Networks (Andreas et al.,
2016)) is generated to execute to obtain the final
predictions. However, since the KB reasoning task
involves a reasoning process spanning over multi-
ple triplets in a diverse and large-scale KB, only
generating and following a single program (i.e., a
reasoning chain formed by KB triplets) is prone to
error propagation where a mistake in one step could
lead to a failure of the subsequent reasoning pro-
cess and may result in sub-optimal performances.
To address this, we propose a two-phase pro-
cedure to alleviate the effects of error propaga-
tion by first generating and then verifying multiple
hypotheses . Here, a hypothesis is in the form of a
triplet containing an entity mentioned in dialogue
context and an entity within KB, and their corre-
sponding relation. The valid (i.e., correct) hypoth-
esis is the one that contains the entity mentioned
in the ground-truth response. Once we obtain mul-
tiple hypothesis candidates during the generation
phase, we employ a reasoning engine for verifying
those hypotheses. For instance in Figure 1, given
the user query “ Can you recommend me a hotel
located in Leichhardt? ”, in order to find the valid
hypothesis, the hypothesis generator obtains multi-
ple candidates e.g.,
and . The rea-
soning engine will then construct proof trees to
verify them, e.g., for the first hypothesis , it can be verified with the fol-
lowing reasoning chain in the KB: → → . The whole frame-
work is trained end-to-end using raw dialogues and
thus does not require additional intermediate labels
for either the hypothesis generation or verification
modules.
To summarize, our contributions are as follows:
•We introduce a novel neuro-symbolic frame-
work for interpretable KB reasoning in task-
oriented dialogue systems.
•We propose a two-phase “generating-and-
verifying” approach which generates multiple
hypotheses and verifies them via reasoning
chains to mitigate the error-propagation issue.
•We conduct extensive experimental studies ontwo benchmark datasets to verify the effec-
tiveness of our proposed model. By analyzing
the generated hypotheses and the verifications,
we demonstrate our model’s interpretability.
2 Related Work
Task-Oriented Dialogue Traditionally, task-
oriented dialogue systems are built via pipeline-
based approaches where task-specific modules are
designed separately and connected to generate sys-
tem responses (Chen et al., 2016; Zhong et al.,
2018; Wu et al., 2019a; Chen et al., 2019a; Huang
et al., 2020). In another spectrum, many works
have started to shift towards end-to-end approaches
to reduce human efforts (Bordes et al., 2017; Lei
et al., 2018; Madotto et al., 2018; Moon et al., 2019;
Jung et al., 2020). Lei et al. (2018) propose a two-
stage sequence-to-sequence model to incorporate
dialogue state tracking and response generation
jointly in a single sequence-to-sequence architec-
ture. Zhang et al. (2020) propose a domain-aware
multi-decoder network (DAMD) to combine be-
lief state tracking, action prediction and response
generation in a single neural architecture. Most
recently, the success of large-scale pre-trained lan-
guage models (e.g., BERT, GPT-2) (Devlin et al.,
2018; Radford et al., 2019) has spurred a lot of re-
cent dialogue studies starting to explore large-scale
pre-trained language model for dialogues (Wolf
et al., 2019; Zhang et al., 2019). In task-oriented di-
alogue, Budzianowski and Vuli ´c (2019) use GPT-2
to fine-tune on MultiWOZ dataset for dialogue re-
sponse generation. Peng et al. (2020) and Hosseini-
Asl et al. (2020) employed a single unified GPT-2
model jointly trained for belief state prediction, sys-
tem action and response generation in a multi-task
fashion. However, most existing approaches cannot
explain why the model makes a specific decision
in a human understandable way. We aim to ad-
dress this limitation and introduce interpretability
for dialogue reasoning in this study.
Neuro-Symbolic Reasoning Neuro-Symbolic
reasoning has attracted a lot of research attentions
recently due to its advantage of exploiting the rep-
resentational power of neural networks and the
compositionality of symbolic reasoning for more
robust and interpretable models (Andreas et al.,
2016; Hu et al., 2017; Hudson and Manning, 2018;
Vedantam et al., 2019; Chen et al., 2019b; Vedan-
tam et al., 2019; van Krieken et al., 2022). The
main difference between neuro-symbolic vs. pure4919neural networks lies in how the former combines
basic rules or modules to model complex func-
tions. Rocktäschel and Riedel (2017) propose a
neuro-symbolic model that can jointly learn sub-
symbolic representations and interpretable rules
from data via standard back-propagation. In visual
QA, Andreas et al. (2016) propose neural module
networks to compose a chain of differentiable mod-
ules wherein each module implements an operator
from a latent program. Yi et al. (2018) propose
to discover symbolic program trace from the in-
put question and then execute the program on the
structured representation of the image for visual
question answering. However, these approaches
cannot be easily adapted to task-oriented dialogues
due to the error propagation issue caused by multi-
hop reasoning on large-scale KBs. Thus, we aim
to bridge this gap by developing a neuro-symbolic
approach for improving task-oriented dialogues.
3 Preliminary
In this work, we focus on the problem of task-
oriented dialogue response generation with KBs.
Formally, given the dialogue history Xand knowl-
edge base B, our goal is to generate the system
responses Yword-by-word. The probability of the
generated responses can be written as:
where yis the t-th token in the response Y. The
overall architecture is shown in Figure 2. We start
by introducing the standard modules in our system
and then explain the two novel modules afterward.
3.1 Dialogue Encoding
We employ pre-trained language model BERT (De-
vlin et al., 2019) as the backbone to obtain the
distributed representations for each token in the di-
alogue history. Specifically, we add a [CLS]token
at the start of the dialogue history to represent the
overall semantics of the dialogue. The hidden states
H= (h, h, ..., h) for all the input tokens
X= ([CLS], x, ..., x) are computed using:
where Mis the number of tokens in the dialogue
history, ϕis the embedding layer of BERT.3.2 Response Generation
To generate the system response, we first uti-
lize a linear layer to project HtoH=
(h, h, ..., h) that are in the same space of
the decoder. We initialize the decoder with h.
During decoding timestep t, the model utilizes the
hidden state h to attend Hto obtain an at-
tentive representation hvia standard attention
mechanism. We then concatenate h andh
to form a context vector Cand project it into the
vocabulary space V:
where Uis a learnable linear layer, P is the
vocabulary distribution for generating the token y.
Next, we aim to estimate the KB distribution
P, i.e., the probability distribution of entities in
the KB, in an interpretable way and fuse P
andPfor generating the final output tokens. We
follow See et al. (2017) and employ a soft-switch
mechanism to fuse P andPto generate
output token y. Specifically, the generation proba-
bility p∈[0,1] is computed from the attentive
representation hand the hidden state h:
where σis sigmoid function, Uis a linear layer.
The output token yis generated by greedy sam-
pling from the probability distribution P(w):
We next describe how to obtain the KB distribu-
tionPin details using the two novel modules
we proposed, i.e., hypothesis generator and hierar-
chical reasoning engine.
4 Neuro-Symbolic Reasoning For
Task-Oriented Dialogue
To compute the KB distribution P, we present
two novel modules: hypothesis generator (HG)
and hierarchical reasoning engine (HRE). We take
the context vector C(Equation 3) as the input of
HG module and generate K hypotheses H, each of
which are then fed into the HRE module to gen-
erate the logical reasoning chains and their belief
scores. The estimated belief scores are then served
asP, giving us a distribution over the entities
in the KB. Next, we describe how each component
works in detail and explain how they interact with
each other for generating P.4920
4.1 Hypothesis Generator
Let a hypothesis be a 3-tuple of the form
“[H, R, T ]”, where HandTare the head and tail en-
tities, and Ris the relation between entities. In this
paper, we are interested in three types of hypothe-
ses including the H-Hypothesis, T-Hypothesis, and
R-Hypothesis. The H-Hypothesis is the structure
where the tail entity Tand relation Rare inferred
from the context and the head entity His unknown
(which needs to be answered using the KB), and
it takes the form “ [▷, R, T ]”. In a similar vein, the
T-Hypothesis and R-Hypothesis have unknown tail
entity Tand relation R, respectively. The goal of
the Hypothesis Generator module is to generate
hypotheses in this triple format which will later be
verified by the Hierarchical Reasoning Engine.
Intuitively, a hypothesis can be determined by
its content and structure. The structure indicates
the template form of the hypothesis while the con-
tent fills up the template. For instance, the H-
Hypothesis has its template form of “ [▷, R, T ]” and
the content that needs to be realised includes can-
didate entities (i.e., “ ▷”), and query states (i.e., the
tail “T” and relation entities “ R”). To this end,
we employ a divide-and-conquer strategy to jointly
learn three sub-components: structure prediction,
query states prediction, and candidates prediction.
Next, we describe each sub-component in details.
Structure Prediction (SP) The goal of the struc-
ture prediction module is to determine the structure
of the hypothesis (i.e., H/T/R-Hypothesis) based
on the context. For example in Figure 1, one might
expect an H-Hypothesis at timestep 0. Specifically,
SP uses a shared-private architecture to predict the
hypothesis type. It first takes the context vector C
(Equation 3) as input and utilizes a shared transfor-
mation layer between all the three sub-components
to learn task-agnostic feature h :
where WandWare learnable parameters (shared
by the structure prediction, query states predic-
tion and candidate prediction components) and
LeakyReLU is the activation function.
The shared layer can be parameterised with com-
plicated neural architectures. However, to keep our
model simple, we use linear layers which we found
to perform well in our experiments. SP next uses
a private layer on top of the shared layer to learn
task-specific features for structure prediction:
where WandWare learnable parameters. For
ease of presentation, we define the private feature
transformation function as:
where ⋆denotes any of the three sub-components.
To obtain the predicted hypothesis structure, a
straightforward approach is to apply softmax on
h . However, this will break the differentia-
bility of the overall architecture since we perform
sampling on the outcome and pass it to the neural
networks. To avoid this, we utilize the Gumbel-
Softmax trick (Jang et al., 2017) over h to
get the sampled structure type:
where Iis a one-hot vector and the index of one
element can be viewed as the predicted structure.
In this paper, we define 0 as H-Hypothesis, 1 as
T-Hypothesis and 2 as R-Hypothesis.
Query States Prediction (QSP) Query states
are the tokens in hypothesis that need to be in-
ferred from the dialogue history. For example, one
might want to infer relation R=Located_in and tail4921T=Leichhardt based on the history in Figure 1.
Therefore, the goal of the query states prediction
is to estimate the state information (e.g., TandR
in H-Hypothesis) of hypothesis. Specifically, QSP
takes the shared feature h as the input and next
applies the private feature transformation function
followed by Gumbel-Softmax to obtain the state
tokens of hypothesis using:
where nis the number of tokens (entities and rela-
tions) in the KB, k∈{0,1}, IandIare two
one-hot vectors where their corresponding tokens
in KB serve as the state tokens of the hypothesis.
Candidates Prediction (CP) To generate the fi-
nal hypotheses, we need multiple candidates to
instantiate the structure of the hypothesis except
the state tokens, e.g., Cityroom orGonville_Hotel
as candidate head entities Hin Figure 1. To this
end, we utilize an embedding layer ϕto convert
all the tokens in the KB to vector representations.
We then compute a probability distribution over all
the KB tokens using:
where Kis the i-th token in KB, ϕis the em-
bedding layer of CP, Pis the probability of the
i-th token to be candidate, ⊙denotes inner-product.
We use sigmoid instead of softmax as we find that
softmax distribution is too “sharp” making the prob-
ability between different tokens are hard to differen-
tiate for sampling multiple reasonable candidates.
Hypothesis Synthesizing The final hypotheses
Hare composed by combining the outputs of the
three sub-components as follows: (i) We generate
the hypothesis template according to the predicted
structure type. For example, if SP predicts a struc-
ture type 0 which denotes H-Hypothesis, the model
will form a template of “ [▷, R, T ]”; (ii) We next in-
stantiate the state tokens in the hypothesis sequen-
tially by using the outputs of QSP module. For ex-
ample, if the output tokens of QSP are “ Located_in ”
(k=0) and “ Leichhardt ” (k=1), the hypothesis will
become [▷,Located_in ,Leichhardt ]; (iii) Finally,
we instantiate the candidate (i.e., ▷) with the top-
K(K=5 in our best-performing version) entities
selected from P. If the top-2 highest probability
tokens are Cityroom andGonville_Hotel , the model
will instantiate two hypotheses , .4.2 Hierarchical Reasoning Engine
With the hypotheses generated by HG module, we
next aim to verify them via logical reasoning chains.
Inspired by Neural Theorem Provers (Rocktäschel
and Riedel, 2017), we develop chain-like logical
reasoning with following format:
where αis a weight indicating the belief of the
model on the target hypothesis [H, R, T ], and the
right part of the arrow is the reasoning chain used
to prove that hypothesis, and RandZare rela-
tions and entities from the KB. The goal is to find
the proof chain and the confidence αfor a given
hypothesis. To this end, we introduce a neural-
network based hierarchical reasoning engine (HRE)
that learns to conduct chain-like logical reasoning.
At a high level, HRE recursively generates multiple
levels of sub-hypotheses using neural networks that
form a tree structure as shown in Figure 2. Next,
we describe how this module works in details.
The module takes the output hypotheses from
the HG module as input. Each hypothesis serves
as one target hypothesis. To generate the reason-
ing chain in Equation 14, the module first finds
sub-hypotheses of the same format as the target
in the hypothesis space. The sub-hypotheses can
be viewed as the intermediate reasoning results to
prove the target. One straightforward approach is
to use neural networks to predict all the tokens in
the sub-hypotheses (2 heads, 2 tails and 2 relations).
However, this can lead to extremely large search
space of triples and is inefficient. Intuitively, sub-
hypotheses inherit from the target hypothesis and
sub-hypotheses themselves are connected by bridge
entities. For example, can be ver-
ified by two sub-hypotheses
and ,Uber andUSA are inher-
ited from the target and Seattle is the bridge en-
tity between sub-hypotheses. Motivated by this,
we propose to reduce the triple search complexity
by constraining the sub-hypotheses. Specifically,
given target [H, R, T ], we generate sub-hypotheses
of the format [H, R, Z],[Z, R, T], where Zis the
bridge entity, RandRare relations to be pre-
dicted. Therefore, the goal of the neural networks
has been reduced to predict three tokens (2 relations
and 1 bridge entity). Formally, HRE predicts the
vector representation of bridge entity as follows:4922
where [h, h, h]are the concatenation of the
representations of tokens in target hypothesis, h
is the vector representation of bridge entity Z. The
prediction of handhuses the same architec-
ture in Equation 16 and the difference is that they
use different linear layers for the feature transfor-
mation. Note that hdenotes a KB token in the
embedding space. We can decode the token by
finding the nearest KB token to hin vector space.
More details on the token decoding can be found
in Appendix A. Upon obtaining h, h, h, the
module generates the two sub-hypotheses in vector
representations. Next, the module iteratively takes
each of the generated sub-hypothesis as input and
extend the proof process by generating next-level
sub-hypotheses in a depth-first manner until the
maximum depth Dhas been reached.
Belief Score To model confidence in different
reasoning chains, we further measure the semantic
similarities between each triple of the leaf node and
triples in the KB, and compute the belief score α
of the m-th hypothesis H:
where Leafis the representation (concatenation
ofH, R, T ) of the i-th leaf node in the proof tree
(DFS manner), KBis the representation of the
j-th triple in KB, U=[0,..., u-1],V=[0,..., v-1] where
uandvare the number of leaf nodes and KB triples
correspondingly, dis the distance metric. In gen-
eral, any distance function can be applied and we
adopt Euclidean distance in our implementation
since we found that it worked well in our experi-
ments. All the triples in the leaf nodes form the
reasoning chain for the input hypothesis as in Equa-
tion 14. The hypotheses Hcoupled with the belief
αform our KB distribution P. More details
can be found in Appendix B. Intuitively, the belief
score can be viewed as the likelihood of the hypoth-
esis contains the correct entity. If the hypothesis
is valid (i.e., contains the correct answer entity), it
should have a high likelihood and thus encourage
to generate more proper reasoning chains based on
the triples stored in the KB.
Training We apply two loss functions to train
the whole architecture end-to-end. The first loss
function Lis for the final output. We use a cross-
entropy loss over the ground-truth token and the
generated token from the final distribution P(w).
The second loss Lis for the candidates predic-
tion (CP) module in the hypotheses generator. We
apply binary cross-entropy loss over the output dis-
tribution for each KB token (Equation 13) and their
corresponding labels. The labels for each KB token
are computed as follows:
where Kis the i-th token in the KB and yis the
ground-truth output at timestep t. The final loss L
is calculated by:
L=γ∗ L+γ∗ L (19)
where γandγare hyper-parameters and we set
them to 1 in our experiments.
5 Experiments
5.1 Datasets
To evaluate the effectiveness and demonstrate the
interpretability of our proposed approach, we con-
duct experiments on two public benchmark datasets
for task-oriented dialogue in this paper, SMD (Eric
et al., 2017) and MultiWOZ 2.1 (Budzianowski
et al., 2018). We use the partitions created by
Eric et al. (2017); Madotto et al. (2018) and Qin
et al. (2020) for SMD and MultiWOZ, respectively.
Statistics of the datasets are presented in Table 1.
In the Appendix E, we present several additional
results on a large-scale synthetic dataset to demon-
strate our model’s multi-hop reasoning capability
under complex KB reasoning scenarios.
5.2 Baselines
We compare our model with the following state-of-
the-art baselines on KB reasoning in task-oriented
dialogues: (1) Mem2Seq (Madotto et al., 2018):
employs memory networks to store the KB and
combine pointer mechanism to either generate to-
kens from vocabulary or copy from memory; (2)
GLMP (Wu et al., 2019b): uses a global-to-local
pointer mechanism to query the KB during de-
coding; (3) DF-Net (Qin et al., 2020): employs4923
shared-private architecture to capture both domain-
specific and domain-general knowledge to improve
the model transferability; (4) GraphDialog (Yang
et al., 2020): incorporates graph structural informa-
tion obtained from sentence dependency parsing
results for improving KB reasoning accuracy and
response generation quality. Detailed experimental
settings are included in Appendix C.
5.3 Main Results
Following prior work (Eric et al., 2017; Madotto
et al., 2018; Wu et al., 2019b), we adopt the BLEU
andEntity F1 metrics to evaluate the performance
of our framework. The results on the two datasets
are shown in Table 2. As we can see, our frame-
work consistently outperforms all the previous
state-of-the-art baselines on all datasets across both
metrics. Specifically, on MultiWOZ dataset, our
model achieves more than 2% absolute improve-
ment in Entity F1 and 1.2% improvement in BLEU
over baselines. The improvement in Entity F1 indi-
cates that our model enhances KB reasoning, while
the increase in BLEU suggests that the quality of
the generated responses has been improved. The
same trend has also been observed on SMD dataset.
This indicates the effectiveness of our proposed
framework for task-oriented dialogue generation.
5.4 Model Interpretability
To demonstrate our framworks’s interpretability,
we investigate the inner workings of our frame-
work. As shown in Figure 3, given the dialogue
history “ Can you recommend me a restaurant near
Palm_Beach? ”, the generated response is “ There is
a Golden_House. ”. During the 3rd timestep, our
model has successfully predicted an appropriateH-Hypothesis with Located_in andPalm_Beach
as its state tokens. Our model further instantiates
five concrete hypotheses and computes their be-
lief scores leveraging the reasoning engine, respec-
tively. As we can see from the table, our model
successfully generates five reasonable hypotheses
and scores them correctly (with highest score for
the oracle KB entity Golden_House ). The proof
process for the highest score hypothesis is shown
in Figure 3. The verification procedure generated
by the HRE module has a depth of 3 and the rea-
soning chaining used to verify the target hypothe-
sis is: → → → . This indicates that our framework has
successfully utilized the KB information to support
the reasoning process explicitly to reach a correct
conclusion. More examples and error analyses can
be found in the Appendix (Appendix E.4 and F).
5.5 Ablation Study
We ablate each component in our framework to
study their effectiveness on both datasets. The re-
sults are shown in Table 3. Specifically, 1) w/o
HRE denotes that we simply use the probability
in candidates prediction (CP) module (Equation
13) as the KB distribution without using the scores
from the reasoning engine. 2) w/o BERT denotes
that we use standard GRU as encoder instead of
BERT. 3) w/o Soft-switch denotes that we sim-
ply sum the KB distribution and vocabulary distri-
bution without using a soft gate. As we can see
from the table, all the individual components have
notably contributed to the overall performance of4924
our framework. Specifically, when removing HRE
module, the performance has decreased substan-
tially (more than 5% absolute drop), which con-
firms that the effectiveness of the proposed hierar-
chical reasoner module.
5.6 Generalization Capability
We further investigate the generalization ability of
our model under unseen settings. In the original
dataset released by prior works, the entity overlap
ratio between the train and test split is 78% and15.3% for MultiWOZ 2.1 and SMD, respectively.
To simulate unseen scenario, we construct a new
dataset split that reduces the entity overlap ratio to
30% for MultiWOZ 2.1 and 2% for SMD between
the train and test split, which is a more challenging
setting for all the models. More details of the con-
struction process can be found in Appendix D. We
re-run all the baselines with their released codes
and our model on the new data split and report the
results in Table 4. As we can see, the performance
drops significantly for all systems on both datasets.
However, our model degrades less compared to
other systems, showing that it has better generali-
sation capability under unseen scenarios. This also
verifies that neuro-symbolic approach has the ad-
vantage of better generalisation ability which has
also been confirmed by many other studies (An-
dreas et al., 2016; Rocktäschel and Riedel, 2017;
Minervini et al., 2020).
5.7 Human Evaluation
Following prior work (Qin et al., 2020), we also
conduct human evaluations for our framework and
baselines from three aspects: Correctness ,Fluency ,
andHumanlikeness . Details about the scoring cri-
terions can be found in Appendix H. We randomly
select 300 different dialogue samples from the test
set and ask human annotators to judge the quality
of the responses and score them according to the
three metrics ranging from 1 to 5. We train the
annotators by showing them examples to help them4925
understand the criteria and employ Fleiss’ kappa
(Fleiss, 1971) to measure the agreement across dif-
ferent annotators. The results are shown in Table 5.
As we can see, our model outperforms all baselines
across all the three metrics, consistent with our
previous observations using automatic evaluations.
6 Conclusion
In this paper, we propose an explicit and inter-
pretable Neuro-Symbolic KB reasoning framework
for task-oriented dialogue generation. The hypoth-
esis generator employs a divide-and-conquer strat-
egy to learn to generate hypotheses, and the rea-
soner employs a recursive strategy to learn to gen-
erate verification for the hypotheses. We evaluate
our proposed framework on two public benchmark
datasets including SMD and MultiWOZ 2.1. Ex-
tensive experimental results demonstrate the effec-
tiveness of our proposed framework, as well being
more interpretable.
7 Ethical Considerations
For the human evaluation in this paper, we recruit
several annotators on Amazon Mechanical Turk
from English-speaking countries. We pay the an-
notators USD$0.15 for each annotation task. Each
task can be finished on average in 1 minute, which
amounts to $9.0 per hour that is above the US fed-
eral minimum wage ($7.25). To ensure the quality
of the human evaluation results, we perform quality
control in a few ways. First, the annotators will be
shown our scoring standards (Appendix H) before
their tasks, and are asked to follow them. If the task
is not done properly, either as determined by expert
judgements (we recruit 3 native English speakers
to validate the results of the Turkers’ annotations)
or there are obvious patterns such as constantly giv-
ing the same score for all tasks, we remove their
annotations. We also compute agreement score to
check for the consistency among the annotators.References492649274928A Details on Token Decoding in HRE
Given the vector representations of the generated
sub-hypotheses in hierarchical reasoning engine
module, we utilize the similarity-based approach
to decode the symbolic representations of those
sub-hypotheses. Specifically, given a generated
sub-hypotheses [h, h, h], where h,hand
hare the vector representations for the head entity,
relation and tail entity correspondingly. To decode
the symbolic representations for the head, relation
and tail entities, we use:
arg min∥ϕ(K)−h∥. (20)
arg min∥ϕ(K)−h∥. (21)
arg min∥ϕ(K)−h∥. (22)
where i,jandkare the indices for the head en-
tity, relation and tail entity in the vocabulary, K,
K,Kdenotes the i-th,j-th,k-th token of the
KB,ϕ(K)denotes the embedding of the i-th to-
ken. Through this, we can decode the generated
sub-hypotheses and obtain their explicit symbolic
representations.
B Details on KB Distribution Calculation
We extract the KB distribution Pat timestep
tfrom the generated hypotheses and their corre-
sponding belief scores as follows. For instance,
if the generated hypothesis [H, R, T ]is an H-
Hypothesis with a belief score α, we extract the
candidate token of the H-Hypothesis which is H
and then pair Hwith the belief score α, where α
is viewed as the probability of the token Hto be
selected as the output at timestep t. We conduct
this for all the generated hypotheses and their cor-
responding belief scores from the HG and HRE
modules. Finally, all the candidate tokens paired
with their belief scores form the Pat timestep t.
C Experimental Settings
The dimensionality of the embedding and the de-
coder RNN hidden units are 128 and embeddings
are randomly initialized. The dropout ratio is se-
lected from [0.1, 0.5]. We use Adam (Kingma and
Ba, 2014) optimizer to optimize the parameters in
our model and the learning rate is selected from
[1e,1e]. For the encoder, we fine-tune the
BERT-base-uncased model from HuggingFace’slibrary with an the embedding size of 768 with 12
layers and 12 heads. The maximum depth Dof
the HRE module is selected from [1,5], the maxi-
mum number of candidates Kin CP module is se-
lected from [1,10], and the temperature of Gumbel-
Softmax is 0.1. All hyper-parameters are selected
according to the validation set, and we repeat all the
experiments 5 times with different random seeds
and report the average results.
D Details on Unseen Setting
We construct new dataset splits both on SMD and
MultiWOZ 2.1 to simulate unseen scenarios for
testing the generalization ability of all the models.
Specifically, we construct the new dataset split as
follows: We first extract all the KB entities that
appeared in the dialogue responses and accumu-
late the percentage of samples for each KB entity.
Second, we rank all the entities according to their
percentage of samples in a decreasing order. Next,
we split the KB entity set into train entities and
test entities by accumulating the total percentages
of samples. Finally, we iterate each sample in the
dataset and assign it to train or test split by check-
ing whether the entity in the response belong to
the train entities or test entities. In this way, we
obtain a new dataset split for both SMD and Multi-
WOZ 2.1, which has an entity overlap ratio of 2%
and 30%, respectively, between train and test split
(overlap ratio in the original SMD and MultiWOZ
2.1 are 15.3% and 78%, respectively).
The dataset statistics for the unseen splits are
shown in Table 6 and Table 7:
Dataset Train Dev Test
SMD 1850 311 870
MultiWOZ 2.1 1472 252 3734929E Additional Experiments
We find that KB reasoning for most existing task-
oriented dialogue datasets are quite simple, for the
most part only requiring that only one or two hop
reasoning over the KB in order to answer the user’s
request successfully. To further test our model and
baseline models’ multi-hop reasoning capability
under complex reasoning scenarios, we develop a
large-scale multi-domain synthetic dataset consist-
ing dialogues requiring multi-hop reasoning over
KBs. This is similar in spirit to bAbI dataset, and
we hope that this dataset will continue to be used
with other dialogue benchmarks in future studies.
We will release this dataset upon publication. Next,
we describe how we construct the dataset in details
and show the experimental results performed on it.
E.1 Dataset Construction
As is shown in Figure 4, each sample in the dataset
consists of several rounds of dialogues. We gener-
ate the questions and answers of the dialogues by
randomly sample template utterances with place-
holders (e.g., @movie ,@director ,@location ) indi-
cating the types of KB entities to be instantiated to
form the complete utterances. To simulate a natural
conversation between user and system under differ-
ent scenarios (i.e., restaurant booking, hotel reser-
vation, movie booking), we designed 18 different
types of question-answer templates. For example,
movie to director denotes that the user requests the
director given the movie name, location to theatre
denotes the user requires theatre information given
the location. For each conversation, we randomly
select several different types of question-answer
templates sequentially to form the skeleton of the
whole dialogue. To ensure the coherent of the di-
alogue flow, we provide the guided next types for
each question-answer template. For instance, if the
current sampled question-answer type is location to
restaurant , the guided next types will be randomly
sampled from restaurant to price ,restaurant to
cuisine etc. Thus, we can ensure the generated dia-
logue turns more coherent in terms of semantics to
simulate a real conversation as much as possible.
For each conversation, we generate 3 or 4 rounds
of dialogues following the existing work such as
SMD andMultiWOZ 2.1 . At each round of the
dialogue, we randomly select a question-answer
template and instantiate the placeholders in the
template with the corresponding types of KB enti-
ties. If there are multiple entities in the KB satisfythe types indicated by the placeholders, we ran-
domly sample one to implement the template. In
this way, we can increase the diversity of the gen-
erated data. For instance, if the question template
isIs there any restaurant located in @district? , the
possible sets of entities in the KB for the place-
holder @district might include multiple location
entities in the KB such as vermont ,blackburn etc.
We randomly sample one of them to replace the
placeholder and generate a final sentence. If we
sample vermont , the implemented sentence will be
Is there any restaurant located in the vermont? .
To make the generated dialogue utterances more
natural as human conversations, we further ran-
domly replace the KB entities in the sentence with
pronouns such as it,they etc, provided that the en-
tities have been mentioned in previous dialogue
turns. Thus, it requires the model to overcome the
co-reference resolution to arrive at the correct an-
swer which increases the difficulty. For example,
Who is the director of the movie mission impossi-
ble? will be rephrased as Who is the director of
it?if the movie name mission impossible has been
mentioned in the dialogue history.
For movie domain, we employ the KB used in
the well-known WikiMovie dataset. For hotel and
restaurant domain, we use the KB provided in the
MultiWOZ 2.1 dataset. For each employed KB,
we further extend it by adding information such as
hierarchies of locations to enrich the KB in order
to make it suitable for testing multi-hop reasoning
capability. For example, if the KB contains a hotel
entity love lodge , we add different levels of loca-
tion information to support multi-hop KB reason-
ing. For instance, we add location information such
aslove_lodge next_to lincoln_park ,lincoln_park
is_within waverley_district ,waverley_district lo-
cated_in grattan_county . Thus, if the user asked
about the hotel located in grattan_county , it re-
quires the model to conduct multi-hop reasoning
over the KB to know that love_lodge is located in
grattan_county . Through this, we make our syn-
thetic dataset suitable for multi-hop reasoning tasks
over KB under task-oriented dialogue scenarios.
The location information we utilized in the syn-
thetic dataset are obtained from the Wikipedia and
the official website of famous cities around the
world.4930
E.2 Dataset Statistics
The detailed statistics of the synthetic dataset are
shown in Table 8 and Table 9:
Domain Train Dev Test
Movie 7219 1645 1667
Hotel 7115 1631 1639
Restaurant 7131 1672 1684
Total 21465 4948 4990
E.3 Experimental Results
Evaluation Metrics. We use the same metrics as
onSMD andMultiWOZ 2.1 dataset includes BLEU
andEntity F1 for performance evaluation.
Results. The results on the three domains are
shown in Table 10, 11, 12. For each domain, we
evaluate the model performance on different sub-
sets of the test data, i.e., 1-hop, 2-hop and >=3-
hop. Specifically, we group the test data into three
different subsets according to the KB reasoning
length for obtaining the ground-truth entity. For in-
stance, 2-hop denotes that the KB entity mentioned
in the response needs 2-hop reasoning over the
KB. As we can see from the tables, our proposed
model consistently outperforms all the baselines
by a large margin across all the domains and KB
reasoning lengths. We also observe that all the
models’ performance decrease monotonously as
the KB reasoning path length increases, suggesting
that KB reasoning with longer range is challengingfor all the tested models. However, our frame-
work has less performance degradation compared
to all the baselines, and the performance gap be-
tween our framework and the baselines has become
larger when the length of KB reasoning increases,
which demonstrates that our framework has better
generalization ability especially under longer KB
reasoning paths compared to those baselines.
E.4 Example Outputs
We show the generated hypotheses and the proof
trees in our framework as shown in Table 13 and
Figure 5. As we can see, our model can success-
fully obtain the correct entities from the KB. More-
over, our framework can formulate sensible hy-
potheses and generate reasonable proof procedures
which can help us gain some insights about the
inner workings of our model.
F Error Analysis
We conduct error analysis on both SMD andMulti-
WOZ 2.1 to provide insights in our framework for
future improvements. We randomly sample 100 di-
alogues from each test set and analysis both the gen-
erated responses and the inner procedures. The er-
rors have four major categories: 1) structure errors,
2) query states errors, 3) candidates errors, 4) belief
score errors. For example, given dialogue history
“Where is a nearby parking_garage? ”, the gener-
ated response is “ 5671_barringer_street is 1_mile
away. ” and the ground-truth is “ The nearest one
is palo_alto_garage, it’s just 1_mile away. ”. The
generated hypotheses by HG module at timestep
0 are “[ 5671_barringer_street ,distance ,1_mile ],
[whole_foods ,distance ,1_mile ], [home ,distance ,
1_mile ], [valero ,distance ,1_mile ], [pizza_chicago ,
distance ,1_mile ]”. The predicted structure type
is a H-Hypothesis with a relation “ distance ” and
tail entity “ 1_mile ”. However, a reasonable
hypothesis should be an H-Hypothesis such as
“[palo_alto_garage ,poi_type ,parking_garage ]”
with “ poi_type ” (place of interest) and “ park-
ing_garage ” as relation and tail. This illustrates
the challenge of the task, and we plan to further
improve our framework include SP, QSP, CP and
HRE in future work.
F.1 Structure Prediction Errors
Given the dialogue history “ Find me a nearby
shopping mall. ”, the generated response is “ mid-
town_shopping_center is 3_miles away. ” and4931Movie Hotel Restaurant
Train Dev Test Train Dev Test Train Dev Test
Hop=1 27238 5985 5998 14321 3472 3482 14386 2107 2117
Hop=2 6401 1472 1507 3351 594 614 4527 564 609
Hop>=3 5359 1508 1530 3328 514 524 4545 562 593
Total 38998 8965 9035 21000 4580 4620 23458 3233 3319
Movie Domain
1-Hop 2-Hop Hop>=3 All
BLEU F1 BLEU F1 BLEU F1 BLEU F1
Mem2Seq 25.6 68.9 21.8 60.8 19.5 49.2 23.9 62.0
GLMP 30.1 77.2 28.7 72.9 27.1 61.5 28.3 73.2
GraphDialog 29.2 76.6 25.6 69.1 24.7 60.6 27.2 71.6
DF-Net 30.6 77.4 29.5 71.6 28.9 62.1 30.3 73.5
Ours (Full model) 33.2 82.6 31.3 80.4 30.7 74.9 32.7 80.6
Hotel Domain
1-Hop 2-Hop Hop>=3 All
BLEU F1 BLEU F1 BLEU F1 BLEU F1
Mem2Seq 14.4 79.8 13.1 71.2 11.4 68.6 13.2 75.4
GLMP 21.3 85.5 19.8 79.4 18.9 76.2 21.0 82.9
GraphDialog 20.6 83.8 19.1 78.8 18.8 75.9 19.3 81.0
DF-Net 22.1 86.7 19.9 80.2 19.5 76.8 21.5 83.2
Ours (Full model) 23.3 92.4 21.3 89.6 20.7 87.8 22.1 91.6
Restaurant Domain
1-Hop 2-Hop Hop>=3 All
BLEU F1 BLEU F1 BLEU F1 BLEU F1
Mem2Seq 19.0 79.8 17.3 69.4 12.4 66.3 17.0 73.7
GLMP 22.0 90.4 19.1 83.7 18.4 80.4 20.9 86.1
GraphDialog 23.2 89.9 21.2 82.1 20.6 79.8 21.4 85.0
DF-Net 24.5 91.5 23.0 84.2 21.1 81.0 23.3 87.3
Ours (Full model) 26.8 96.7 24.4 93.1 22.7 92.2 25.1 94.24932
the ground-truth response is “ The closest shop-
ping_center is midtown_shopping_center 3_miles
away. ”. The generated hypotheses by HG mod-
ule at decoding timestep 0 are “ , , , , ”. As we can see, the
predicted structure type is an T-Hypothesis with an
head entity “ home ” and relation “ address ”. How-
ever, a reasonable structure type should be an H-
Hypothesis such as “ ” which the model has mispredicted
to a T-Hypothesis.
F.2 Query States Prediction Errors
Given the dialogue history “ What time is dinner
tonight? ”, the generated response is “ Dinner is at
11pm. ” and the ground-truth response is “ Your din-
ner is 5pm tonight. ”. The generated hypotheses
in HG module for decoding timestep 3 are “ , , , , ”. As we can see, the SP and
QSP modules have successfully predicted a sen-
sible T-Hypothesis with “ dinner ” as head entity.
However, the predicted relation “ traffic_info ” is not
reasonable according to context where an expected
relation would be relations such as “time”.F.3 Candidates Prediction Errors
Given the dialogue history “ What time is my doc-
tor_appointment? ”, the generated response is “ Your
doctor_appointment is on Thursday. ” and the
ground-truth response is “ Your doctor_appointment
is scheduled for Friday at 11am. ”. The generated
hypotheses by HG for decoding timestep 4 are
“ , , , ,”. As we can see, our framework has correctly
predicted a T-Hypothesis and state tokens. How-
ever, the predicted top-5 candidate tokens don’t in-
clude the ground-truth date which is Friday , which
might affect the final response generation.
F.4 Belief Score Prediction Errors
Given the dialogue history “ Where is home? ”, the
generated response is “ Home is at 819_alma_st. ”
and the ground-truth is “ Home is where is your
heart, at 56_cadwell_street. ” The generated hy-
potheses for decoding timestep 3 are “ , , , , ”. As we can see, our framework
has predicted a sensible T-Hypothesis with “ home ”
as head entity and “ address ” as relation. Also,
the CP module has predicted top-5 candidate tail4933entities which include the ground-truth 56_cad-
well_street . But the HRE module ranked “ ” highest with a score of 0.78
while the ground-truth one “ ” is only ranked the second highest with
a score of 0.41, which indicates that there is still
room for improvements for the HRE module. We
are interested in continually improving our frame-
work include all the modules in future work.
G Discussions
G.1 Why not use search-based techniques for
generating reasoning chains?
This is an alternative approach to our learning-
based method. However, search-based approach
cannot be jointly learnt end-to-end with other mod-
ules in our framework, and thus may face error
propagation and credit assignment issues like in the
traditional pipeline-based task-oriented dialogue
approaches. In this work, we want to explore the
possibility of learning end-to-end the logical rea-
soning chain directly from the dialogues. Also,
the time complexity of search-based approach is
approximately O(n), where nis the average de-
gree of nodes in the external knowledge base, kis
the number of reasoning hops. In other words, the
time complexity tends to have polynomial growth
(when k >1); and it’s worse when the reasoning
complexity ( k) increases (exponential). In contrast,
when the number of KB nodes increases it only im-
pacts the size of the input embedding layer in our
framework (Equation 15), and the efficiency can
be further improved by leveraging modern acceler-
ating hardware such as GPU (which search-based
approaches cannot).
G.2 Why sample with Gumbel-Softmax
instead of directly applying argmax in
Hypothesis Generator and Hierarchical
Reasoning Engine modules?
Argmax function is non-differentiable which hin-
ders our aim of end-to-end differentiability of the
whole system. We tried utilizing REINFORCE
(reward is obtained by comparing predicted en-
tities with ground-truth entities) to mitigate this
issue. However, we find that the results of using
argmax+REINFORCE is worse than using Gumbel-
Softmax. By checking the sampled tokens from
Gumbel-Softmax, we find that it can generate rea-
sonable tokens (Figure 3 in the main paper, state
tokens etc.), since we have set the temperature pa-rameter of Gumbel-Softmax to 0.1 which is a close
approximation to argmax.
G.3 Why not expand the KB using KB
completion methods and then use
semantic parsing to query KB?
In this work, we are interested in developing an end-
to-end trainable framework with explainable KB
reasoning. Semantic parsing is one possible alterna-
tive. However, when adapting to our own dataset, it
requires further annotations for fine-tuning which
is costly and time-consuming, and might be not
feasible for large-scale datasets. Also, it might in-
duce the error propagation issue since the different
modules (KB completion, semantic parsing, dia-
logue encoding and response generation etc.) are
not jointly learnt.
G.4 KB scale.
The average nodes of KB for each sample in the
training data is 63.5 for SMD and 57.6 for Multi-
WOZ . The average number of relations is 5.5 for
SMD and 9.4 for MultiWOZ .
H Human Evaluation Details
TheFluency of the predicated responses is evalu-
ated according to the following standards:
•5: The predicted responses contain no gram-
mar errors or repetitions at all.
•4: Only one grammar error or repetition ap-
peared in the generated responses.
•3: One grammar error one repetition, or two
grammar errors, or two repetitions are ob-
served in the responses.
•2: One grammar error two repetitions, or one
repetition two grammar errors, or three gram-
mar errors, or three repetitions appeared in the
generated responses.
•1: More than three inappropriate language
usages with regard to grammar errors or repe-
titions are observed in the responses.
TheCorrectness is measured as follows:
• 5: Provide the correct entities.
• 4: Minor mistakes in the provided entities.
•3: Noticeable errors in the provided entities
but acceptable.4934• 2: Poor in the provided entities.
• 1: Wrong in the provided entities.
TheHumanlikeness is measured as:
•5: 100% sure that the sentences are generated
by a human, not by system.
•4: 80% chance that the sentences are gener-
ated by a human.
•3: Cannot tell whether the sentences is gener-
ated by a human or system, 50% for human
and 50% for system.
•2: 20% chance that the sentences are gener-
ated by a human.
•1: Totally impossible that the sentences are
generated by a human.4935