
Mario Giulianelli
Institute for Logic, Language and Computation
University of Amsterdam
m.giulianelli@uva.nl
Abstract
This position paper proposes a conceptual
framework for the design of Natural Language
Generation (NLG) systems that follow efficient
and effective production strategies in order to
achieve complex communicative goals. In this
general framework, efficiency is characterised
as the parsimonious regulation of production
and comprehension costs while effectiveness is
measured with respect to task-oriented and con-
textually grounded communicative goals. We
provide concrete suggestions for the estimation
of goals, costs, and utility via modern statisti-
cal methods, demonstrating applications of our
framework to the classic pragmatic task of visu-
ally grounded referential games and to abstrac-
tive text summarisation, two popular generation
tasks with real-world applications. In sum, we
advocate for the development of NLG systems
that learn to make pragmatic production de-
cisions from experience, by reasoning about
goals, costs, and utility in a human-like way.
1 Introduction
Novelists choose the right words to keep readers
engaged and enthused, good journalists can con-
vey facts clearly and convincingly, while poets
may want to surprise the reader. Teachers adapt
their explanations to the level of their students,
and the language of parents changes with the pro-
ficiency of their children, with the same objects
described first using simplified funny expressions
(‘moo moo’ ) and then more informative and dis-
criminative names ( ‘cow’ ,‘calf’ ). Using language
to communicate successfully requires effort. On
the side of the language producer, it is first of all ef-
fortful to come up with words that truthfully corre-
spond to one’s communicative intent. Then, words
must be actually produced, e.g. said out loud or
typed on a keyboard. At the same time, the pro-
ducer has to take into consideration whether the
comprehender—for whom, too, linguistic commu-
nication is costly—will be able to infer the originalintent. Comprehenders make efforts to pay atten-
tion to the utterance they are being addressed with,
to interpret it, and to infer their interlocutor’s com-
municative intent. Fortunately, these efforts are
often not in vain. They allow people to exchange
knowledge, ideas, plans, and to achieve goals.
This paper introduces a conceptual framework
for Natural Language Generation (NLG) in vari-
ably complex communicative scenarios, which re-
lies on three main notions: communicative goals ,
production and comprehension costs , and utility .
We define these notions formally and then, in two
case studies, we provide suggestions for their op-
erationalisation in classic NLG tasks. In sum, we
model humans as decision makers striving for effi-
cient and effective communication, and argue that
human-like linguistic behaviour emerges as a result
of reasoning about goals, costs, and utility. Learn-
ing to navigate the complex decision space defined
by these notions is still an open problem: we dis-
cuss possible promising directions.
2 Doing Things with Words
Communication always comes with a goal: speak-
ers use words to change the state of the world. In
this section, we give a characterisation of commu-
nicative goals, discuss the types of effort (or costs)
necessary to achieve goals, and describe the re-
wards associated with successful communication.
2.1 Communicative Goal
What do speakers do with words? The communica-
tive goal (or communicative intent ) of a speaker
can be formulated as a function of the current state
of the world w∈W:
G:W→W, w ∝⇕⊣√∫⊔≀→w(1)
where wis the intended future state of the world.
Speaker sand audience aare included in was
they can be both conceptualised, and there is ev-
idence that they are processed (Brown-Schmidt7978et al., 2015), as parts of the state of the world. For
communication to be successful, the audience must
be able to reconstruct the original communicative
goal: their decoded transformation of the world,
D:W→W, must be such that D(w)≈G(w).
Communicative goals shape and constrain a
speaker’s production choices: different utterance
types typically correspond to different goals. The
communicative goal of a referring utterance ( “The
black and white cat” ), for example, is a state of
the world where the audience is able to identify an
entity in context. The transformation Drequired
to achieve wis a change of attention by the
audience. Statements ( “The Sun is a star” ) are
typically used when the purpose of an interaction is
pure information transmission—e.g., when giving
a scientific talk. In this case, the communicative
goal is a state of the world in which the audience
holds new beliefs, the ones intended by the speaker.
Dis a transformation of the belief state of the
audience, and the communicative goal is achieved
when D(w)≈G(w)=w. All utterance types—
e.g., questions, directives, and performatives—can
be seen as strategies to achieve communicative
goals. The same utterance type, and even the same
utterance, can fulfil different goals: a blatantly
false statement ( “It never rains in Amsterdam” )
can be used for comedic effect rather than for
conveying facts. For simplicity, in the rest of this
paper, we describe utterances as having a single
communicative goal. Often, however, different
goals are associated with the same utterance at
the same time: a teacher can use a question ( “Are
you sure this is the right answer?” ) to inform
their student that their answer is incorrect, while
showing a positive attitude towards them—thereby
striving for both epistemic and social utility. Our
framework naturally generalises over such cases;
when multiple communicative goals are involved,
states of the world can be designed accordingly.
2.2 Production Costs
Given the current and the intended future state
of the world, wandw∗=G(w), a speaker en-
codes the communicative goal G(w)into a mental
representation of the intended state of the world:E(G(w))=e. To use a slightly different vocabu-
lary, this is the speaker’s conception of the intended
environment state. The speaker then realises eas
an utterance rwhich is presented to the audience:
R(e) =r. Two types of cost are associated with
the encoding and realisation processes. Because
the encoding process is inevitably lossy—mental
representations are compressed representations of
the real state of the world—the speaker makes an
effort to reduce information loss; we refer to this as
theencoding cost C. The cost associated with ex-
ecuting a bit of behaviour rmeant to be perceived
by the audience (e.g., speaking, writing, or typing)
is the realisation cost C. Both costs affect the
decision making process of speakers. In addition,
the speaker is influenced by the expected compre-
hension costs of the audience.
2.3 Comprehension Costs
The speaker’s communicative goal G(w)is not
observable by comprehenders. Given a state of the
world wand the speaker’s behaviour r, compre-
henders process rinto a reconstruction of the orig-
inal mental representation, P(r) =e≈e, from
which they decode the speaker’s communicative
goal: D(e)=w≈G(w). Two types of cost are
associated with the comprehension of an utterance.
Speaker and comprehender are different individu-
als and therefore have different ways of encoding
communicative goals into messages (Connell and
Lynott, 2014). In the absence of a perfect model of
the speaker’s encoding mechanism, reconstructing
eis a lossy and effortful process; we denote the
corresponding cost as processing cost ,C. The
second cost results from interpreting ein context—
i.e., decoding from ethe state of the world intended
by the speaker. In other words, this is the effort
required to ground the message in the environment.
We refer to it as the decoding cost C. It is impor-
tant to note that although processing and decoding
costs are on the side of comprehenders, speakers
estimate them and take them into account when
making production decisions.
2.4 Utility
In what ways is the decision making process
of speakers affected by these costs? Speakers
are thought to be driven by efficiency concerns
(Zipf, 1949; Jaeger and Tily, 2011): they strive
to minimise the collaborative effort required
to achieve their communicative goals (Clark
and Wilkes-Gibbs, 1986; Clark and Schaefer,79791989). We thus take the speaker’s utility Uto be
inversely proportional to the joint production and
comprehension costs required for goal achieve-
ment ( D≈G). Production costs can be reduced
directly by the speaker, by putting less cognitive
and physical effort in encoding and realisation.
Comprehension costs, instead, need to be first
estimated via a mental model of the audience’s
comprehension system (including their concep-
tual knowledge, perceptual capacity, language
proficiency, etc.). The ability to form such mental
models is often referred to as Theory of Mind
(Premack and Woodruff, 1978) and it is deemed
a fundamental social-cognitive skill for language
acquisition and language use (Tomasello, 2005).
Speaker’s utility is not only defined in terms of
costs; speakers profit from getting things done with
their words. Thus Uis directly proportional to
the positive cognitive, physical, and social effects
that derive from achieving the intended state of the
world w. Because, in practice, interlocutors often
approach but do not reach wexactly, Ucan be
defined as a function of D(w)andG(w)that
quantifies the difference in positive effects between
true and intended states of the world.
3 Case Study 1: Reference Games
In this section, we demonstrate how to use our
framework to conceptualise a communication sce-
nario that corresponds to a classic NLG task, refer-
ring expression generation (Reiter and Dale, 1997;
Krahmer and van Deemter, 2012). We will also
provide concrete examples of how to model the
costs and utility described in Section 2.
In a reference game, the goal is for participants
to produce descriptions that allow comprehenders
to identify the correct referent out of a set of can-
didates. These games have been extensively used
in psycholinguistics to study human strategies for
effective reference (Krauss and Weinheimer, 1964;
Brennan and Clark, 1996; Hawkins et al., 2020).
For our case study, we use a visually grounded
reference game with two participants, a speaker s
and a listener a. The speaker produces referring
utterances rsuch as “a boy cutting a cake” and the
listener needs to identify the target image iamong
a set of similar images V, the visual context (see,
e.g., Shore et al., 2018; Haber et al., 2019). The
initial state of the world is one where the speaker is
aware of the target referent while the listener has no
information about it. We can express such a stateof the world as w= (V, p, p), i.e. in terms of the
speaker and listener’s probability distributions p
andpover candidate images Vbefore anything is
uttered ( r=ϵ, the empty string):
p(I|V) :p(I=i|V) = 1 (2)
p(I|V, ϵ) :p(I=i|V, ϵ) =1
|V|∀i∈V(3)
Note that pis never observable by a, and for this
scenario to be realistic, pshould also not be ob-
servable by s. The communicative goal Gis a
transformation of wintow, a state of the world in
which aidentifies ias the target referent:
G(w) = (V, p, p)with (4)
p(I=i|V, r) = 1 (5)
How can the costs associated with reaching this
state of the world using utterance rbe estimated?
A computer vision model may be used to encode
the communicative goal w= (V, p, p)into a
mental representation. This model receives as
input the visual context Vand information about
the target image pand yields a mental (abstract)
representation e=E(w). If this is, e.g., a model
that produces image segmentations, the encoding
effort Ccan be quantified as the uncertainty
of the model over its segmentation decisions, as
the number of output image segments, or, if the
segments form a scene graph, as a measure of the
graph complexity. The encoding emay then be
fed to an NLG model Rwhich realises it into an
utterance r=R(e). The realisation cost Ccan
be computed as the utterance length, the depth of
the syntactic tree corresponding to the utterance,
or as a function of the distribution of vocabulary
ranks for the sampled utterance tokens.
Next, ris received by the listener, who processes
it into a reconstruction of the original mental repre-
sentation: e=P(r). This can be achieved using
a neural language model, the processing cost C
being calculated as the model’s cumulative sur-
prisal (the sum of the per-word information con-
tent). From ethe listener decodes a state of the
world w. The decoding system may be one that
measures the similarity of eto candidate image
embeddings and outputs a probability distribution
overV. The decoding cost Ccan be estimated as
the entropy reduction with respect to the prior prob-
ability p(I|V)(the information gain), or as the7980increase in the target image’s probability. Commu-
nication is successful if p(I=i|V, r) = 1 (see
Eq. 5); in practice the condition is often relaxed to:
i= arg maxp(I=i|V, r) (6)
In a simplified reference game where pis observ-
able by s, the speaker’s positive utility Ucan be
simply modelled as logp(i|V, r)−logp(i|V).
In a more realistic scenario, either the speaker
entertains a mental model of pand uses it to
compute utility, or the listener must in turn execute
a bit of behaviour to communicate the state of
p, for example by selecting an image through a
simple decision rule (e.g., arg max p).Ucan
then be modelled as a binary reward based on the
listener’s behaviour: 1 for a correct guess, 0 for an
incorrect one. Recall that Uis not only a function
of positive cognitive effects. It is also inversely
proportional to the costs C, C, C,andC.
4 Case Study 2: Text Summarisation
With our second case study, we demonstrate the
generality of our framework by applying it to text
summarisation, a widely studied NLG (and NLU)
task with a large range of practical applications.
When people summarise a text, they produce a con-
cise and meaning-preserving version of that text
with the goal of conveying to the audience the text’s
most important ideas. In NLP, texts have been
typically summarised either via extraction of their
most significant sentences (Luhn, 1958; Edmund-
son, 1969) or by the generation of fewer, new sen-
tences (DeJong, 1982; Banko et al., 2000). Here,
we look at the second case, often referred to as
abstractive summarisation , where a summariser s
produces an utterance rmade up of one or multiple
sentences to succinctly report the main content of a
texttto an audience a. The initial state of the world
is one where the summariser knows the content of
twhile the audience has no information about it.
Summaries can have multiple communicative
goals—sometimes simultaneously—roughly corre-
sponding to practical goals of NLP summarisation
systems. For example, the communicative goal G
of a summary can be a transformation of the state
of the world into one in which aknows the general
topic of tand is interested in reading t. This setup
roughly corresponds to headline generation, a clas-
sic abstractive summarisation task. If the practical
goal of the summary, instead, is to make the audi-
ence aware of the main facts reported in a text, thecommunicative goal Gis a transformation of the
state of the world into one in which those facts are
part of a’s knowledge. This is the goal, for example,
of summaries of financial, legal, or medical reports.
We now look at this second case, providing
examples of how to model communicative goals,
costs, and utility. A hierarchical language model
with explicit attention over multiple sentences can
be used to encode the document into a mental rep-
resentation e. The encoding cost Ccan be quanti-
fied as the entropy of the attention distribution—the
rationale being that it is harder to condense the in-
formation in a document in which each sentence
contains salient details. The encoding emay then
be fed to a generation model Rwhich realises it
into an utterance r=R(e)(one or multiple sen-
tences). The realisation cost Ccan be computed
as the utterance length or as a function of the pre-
dicted tokens’ probabilities. The summary ris
received by the audience, for example via a neural
language model pretrained on summaries, which
processes it into a reconstruction of the original
mental representation: e=P(r). The processing
costCcan be calculated as the model’s cumu-
lative surprisal. From e, the audience decodes a
new state of the world, one where it can hopefully
answer factual questions about the target document
correctly. The decoding system can be a question
answering model (which can be as simple as a
table-lookup and as complex as a response gener-
ation model) and the decoding cost Ccan be es-
timated as the system’s reduction in uncertainty in
answering a set of questions designed to probe un-
derstanding of the main content of the document—
formulated, e.g., as key-value queries or using nat-
ural language. The speaker’s utility Ucan be mod-
elled as the accuracy of the audience in answering
questions about the content of the document.
5 Pragmatic Production Strategies
Language producers are thought to balance their
own production costs and their audience’s compre-
hension costs in a way that minimises joint collabo-
rative effort (Clark and Wilkes-Gibbs, 1986; Clark
and Schaefer, 1989) while attempting to gain util-
ity from successful communication. Nevertheless,
most modern NLG systems, whose aim is arguably
to reproduce the communicative behaviour of hu-
man language users, do not take into consideration
the costs and utility for which humans are con-
stantly optimising. As a major example, GPT-37981(Brown et al., 2020), one of the best foundation
models currently available for NLG, conflates all
costs into a single next-word probability value. To
generate words from this model, typically, next-
word probabilities are passed to a decoding algo-
rithm such as beam search or nucleus sampling
(Reddy, 1977; Holtzman et al., 2019). This algo-
rithm can be seen as a way to search through the
space of possible utterances by following a sim-
ple utility-maximising decision rule, with higher
probability utterances having higher utility. Future
work should investigate decision making rules that
take into account production and comprehension
costs more explicitly, connecting them to the goal
of the linguistic interaction. The Rational Speech
Act model (RSA; Frank and Goodman, 2012) is a
compelling solution: it was shown to optimise the
trade-off between expected utility and communica-
tive effort and it is related to Rate-Distortion theory
(Shannon, 1948), the branch of information the-
ory that studies the effect of limited transmission
resources on communicative success (Zaslavsky
et al., 2021). Its application to simple reference
games has indeed demonstrated that richer deci-
sion making routines, grounded in listeners’ ac-
tions and beliefs, result in human-like pragmatic
behaviour (Sumers et al., 2021). Bounded rational-
ity (Simon, 1990), which models optimal decision
making under constrained cognitive resources, is a
strong alternative to RSA theory but there is so far
only limited evidence that it can be used to charac-
terise language production choices (Franke et al.,
2010). A third, more practically oriented solution,
are utility-based decoding algorithms—e.g., mini-
mum Bayes risk (Goel and Byrne, 2000) decoding—
which have been successfully used to weigh in util-
ities and costs when selecting utterances for NLG
tasks (Kumar and Byrne, 2002, 2004).
Modelling and artificially reproducing human
communicative behaviour requires advanced deci-
sion making algorithms that are able to learn from
experience efficient and effective strategies for
weighing costs and utility. The learned strategies
should apply both to individual utterances and to
sequences of utterances: this will allow successful
multi-turn planning of communicative subgoals
and strategies. Reinforcement learning (RL) can
naturally interact with notions of cost and utility
(these can be used as learning signal for RL
models, or they can be inferred by RL models
from observations of human behaviour) and it hasbeen used in combination with RSA and bounded
rationality; it thus appears to be a promising
avenue for the strategy learning problem.
Independent of the choice of language model—
which is an important open question—we believe
that our conceptual framework can account for a
variety of human behavioural patterns of commu-
nication as described in pragmatics, the field of
linguistics which studies the aspects of language
use that involve reasoning about context, goals and
beliefs. Let us take as an emblematic example
Grice’s four maxims of conversation (Grice, 1975).
The maxim of quantity , which states that speakers
should make their contribution as informative as
required for the current purposes of the exchange,
can be understood as the optimisation of realisation
and processing costs, CandC, while ensuring
that the distance from the communicative goal is
reduced. The maxim of quality , which is about
making truthful contributions, can be thought of
as the result of minimising decoding cost Cand
maximising the probability of achieving the com-
municative goal. The maxim of relation , stating
that speakers should provide information that is
relevant to the exchange, can be seen as a way to
ensure that production and comprehension costs
are always balanced by gains in positive utility. Fi-
nally, the maxim of manner states that speakers
should avoid obscurity of expression, ambiguity,
and strive for brief and orderly contributions. This
can be easily understood as the optimisation of re-
alisation and processing cost, CandC, given
fixed encoding and decoding costs CandC.
6 Conclusion
We have presented a conceptual framework for
natural language generation that relies on three
central notions: communicative goals, production
and comprehension costs, and utility optimisation.
We have defined these notions formally and
demonstrated their application to two realistic
communication scenarios, providing examples
for the modelling of goals, costs, and utility
with modern method of statistical learning. We
have further argued for our framework’s ability
to account for a variety of pragmatic patterns
of communicative behaviour, highlighting the
importance of the development of new complex
decision making algorithms that learn to reproduce
human-like production strategies from experience.7982Limitations
Some of the notions upon which our framework re-
lies are not new; they are the results of decades of
research in linguistics, cognitive science, and psy-
chology, as acknowledged in the paper. We want
to highlight this here in fairness, yet we believe
that there is value in bringing ideas together from
a pool of interdisciplinary studies and organising
them into a structured framework. Moreover, al-
though our proposal is designed to model language
production in varying communicative scenarios,
we presented only two case studies. We plan to
demonstrate the generality of our framework with
further case studies accompanied by computational
experiments, which are absent in this paper.
Acknowledgements
I would like to thank Raquel Fernández, Arabella
Sinclair, and the members of the Dialogue Mod-
elling Group of the University of Amsterdam for
our insightful discussions, as well as the anony-
mous EMNLP 2022 reviewers for their useful com-
ments. This project has received funding from
the European Research Council (ERC) under the
European Union’s Horizon 2020 research and inno-
vation programme (grant agreement No. 819455).
References79837984