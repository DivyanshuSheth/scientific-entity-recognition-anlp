112111121211213112141121511216112171121811219112201122111222112231122411225112261122711228112291123011231112321123311234ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
After the acknowledgement, before the reference.
/squareA2. Did you discuss any potential risks of your work?
To our best knowledge, our work is an empirical study based on previous work and there is no
potential risks of our work.
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
In abstract and Section 1.
/squareA4. Have you used AI writing assistants when working on this paper?
We use ChatGPT to polish our paper, mainly on abstract and limitation part.
B/squareDid you use or create scientiﬁc artifacts?
In Section 4.1, Appendix B.1 and Appendix B.2
/squareB1. Did you cite the creators of artifacts you used?
In Section 4.1 and Appendix B.1
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
In Appendix B.2
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
In Appendix B.2
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
To our best knowledge, no such problems in three datasets we use.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
In Appendix B.1
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
In Appendix B.2
C/squareDid you run computational experiments?
In Section 4.2, Section 4.3 and Appendix B.4
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
In Section 4.3 and Appendix B.411235/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
In Appendix B.4
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
In Section 4.2 and Appendix B.4
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
In Appendix B.4
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
Left blank.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
No response.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
No response.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
No response.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
No response.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
No response.11236