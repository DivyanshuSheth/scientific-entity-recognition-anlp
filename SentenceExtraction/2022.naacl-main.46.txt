
Bashar Alhafni, Nizar Habash, Houda Bouamor
Computational Approaches to Modeling Language Lab
New York University Abu DhabiCarnegie Mellon University in Qatar
{alhafni,nizar.habash}@nyu.edu ,hbouamor@qatar.cmu.edu
Abstract
In this paper, we define the task of gen-
der rewriting in contexts involving two users
(I and/or You) – first and second grammatical
persons with independent grammatical gender
preferences. We focus on Arabic, a gender-
marking morphologically rich language. We
develop a multi-step system that combines the
positive aspects of both rule-based and neu-
ral rewriting models. Our results successfully
demonstrate the viability of this approach on
a recently created corpus for Arabic gender
rewriting, achieving 88.42 MFon a blind
test set. Our proposed system improves over
previous work on the first-person-only version
of this task, by 3.05 absolute increase in M
F. We demonstrate a use case of our gender
rewriting system by using it to post-edit the
output of a commercial MT system to provide
personalized outputs based on the users’ gram-
matical gender preferences. We make our code,
data, and pretrained models publicly available.
1 Introduction
Gender bias is a fundamental problem in natural
language processing (NLP) and it has been re-
ceiving an increasing attention across a variety
of core tasks such as machine translation (MT),
co-reference resolution, and dialogue systems. Re-
search has shown that NLP systems have the ability
to embed and amplify gender bias (Sun et al., 2019),
which not only degrades users’ experiences but
also creates representational harm (Blodgett et al.,
2020). The embedded bias within NLP systems
is usually attributed to training models on biased
data that reflects the social inequalities of the world
we live in. However, even the most balanced of
models can still exhibit and amplify bias if they are
designed to produce a single text output without
taking their users’ gender preferences into consider-
ation. Therefore, to provide the correct user-awareoutput, NLP systems should be designed to pro-
duce outputs that are as gender-specific as the users
information they have access to. Users information
could be either embedded as part of the input or
provided externally by the users themselves. In
cases where this information is unavailable to the
system, generating all gender-specific forms or a
gender-neutral form is more appropriate.
Producing user-aware outputs becomes more
challenging for systems targeting multi-user con-
texts (first and second persons, with indepen-
dent grammatical gender preferences), particularly
when dealing with gender-marking morphologi-
cally rich languages. In this paper, we define the
task of gender rewriting in contexts involving two
users (I and/or You) – first and second grammatical
persons with independent grammatical gender pref-
erences and we focus on Arabic, a gender-marking
morphologically rich language. The main contribu-
tions of our work are as follows:
1.We introduce a multi-step gender rewriting
system that combines the positive aspects of
rule-based and neural models.
2. We demonstrate our approach’s effectiveness
by establishing a strong benchmark on a
publicly available multi-user Arabic gender
rewriting corpus.
3.We show that our best system yields state-of-
the-art results on the first-person-only version
of this task, beating previous work.
4.We demonstrate a use case of our system by
post-editing the output of an MT system to
match users’ grammatical gender preferences.
This paper is organized as follows. We first dis-
cuss related work (§2) as well as relevant Arabic
linguistic facts (§3). We then define the gender
rewriting task in §4 and describe the data we use
and the gender rewriting model we build in §5 and
§6. Lastly, we present our experimental setup (§7)
and results (§8) and conclude in §9.6182 Background and Related Work
Substantial research has targeted the problem of
gender bias in various NLP tasks such as MT (Ra-
binovich et al., 2017; Vanmassenhove et al., 2018;
Stafanovi ˇcs et al., 2020; Savoldi et al., 2021), di-
alogue systems (Cercas Curry et al., 2020; Dinan
et al., 2020; Liu et al., 2020a,b; Sheng et al., 2021),
language modeling (Lu et al., 2018; Bordia and
Bowman, 2019; Sheng et al., 2019; Vig et al.,
2020; Nadeem et al., 2021), co-reference resolu-
tion (Rudinger et al., 2018; Zhao et al., 2018a), and
named entity recognition (Mehrabi et al., 2019).
While the majority of research has focused on
tackling gender bias in English by debiasing word
embeddings (Bolukbasi et al., 2016; Zhao et al.,
2018b; Gonen and Goldberg, 2019; Manzini et al.,
2019; Zhao et al., 2020) or by training systems
on gender-balanced corpora built using counter-
factual data augmentation techniques (Lu et al.,
2018; Hall Maudslay et al., 2019; Zmigrod et al.,
2019), our work falls under text rewriting through
the controlled generation of gender alternatives for
morphologically rich languages.
Within text rewriting, Vanmassenhove et al.
(2021) and Sun et al. (2021) recently presented
rule-based and neural rewriting models to generate
gender-neutral sentences in English. For morpho-
logically rich languages and specifically Arabic,
Habash et al. (2019) introduced the Arabic Par-
allel Gender Corpus v1.0 ( APGC v1.0) of first-
person-singular constructions and designed a two-
step gender identification and reinflection system
to generate masculine and feminine grammatical
gender alternatives. Alhafni et al. (2020) used
APGC v1.0 to create a joint gender identification
and reinflection model. They treated the problem as
a user-aware grammatical error correction task and
showed improvements over Habash et al. (2019)’s
results. Both efforts modeled gender reinflection
using character-level Seq2Seq models. More re-
cently, Alhafni et al. (2022) extended APGC v1.0
toAPGC v2.0 by including contexts involving first
and second grammatical persons covering singular,
dual, and plural constructions; and adding six times
more sentences.
In our work, we use APGC v2.0 to build a multi-
step gender rewriting system to generate gender
alternatives in multi-user contexts. We also show
improvements over both Habash et al. (2019)’s and
Alhafni et al. (2020)’s results on APGC v1.0.3 Arabic Linguistic Facts
We highlight two of the many challenges that face
Modern Standard Arabic (MSA) NLP systems deal-
ing with gender expressions.
Morphological Richness and Complexity Ara-
bic has a rich and complex morphological system
that inflects for many morphological features (gen-
der, number, person, case, state, aspect, mood,
voice), in addition to several attachable clitics
(prepositions, particles, pronouns) (Habash, 2010).
Arabic nouns, adjectives, and verbs inflect for gen-
der: masculine ( M) and feminine ( F), and for num-
ber: singular ( S), dual ( D) and plural ( P).
Changing the grammatical gender of Arabic
words involves either changing the form of the
base word , changing the pronominal enclitics that
are attached to the base word , or a combination
of both. A base word in Arabic refers to the stem
along with its attachable affixes (prefixes, suffixes,
circumfixes). Changing the base word gender re-
quires either a suffix change, a pattern change, or
a lexical change as shown in Table 1(a-c). Arabic
also has clitics that attach to the stem after affixes.
A clitic is a morpheme that has the syntactic char-
acteristics of a word but shows evidence of being
phonologically bound to another word. In this re-
spect, a clitic is distinctly different from an affix,
which is phonologically and syntactically part of
the word. Proclitics are clitics that precede the
word (like a prefix), whereas enclitics are clitics
that follow the word (like a suffix). Pronominal en-
clitics are pronouns that cliticize to previous words
(Table 1(d)). It is worth noting that multiple af-
fixes and clitics can appear in a single word in
Arabic and changing the grammatical gender of
such words requires changing the genders of both
the base word and its clitics (Table 1(f-g)).
Orthographic Ambiguity Arabic uses diacritics
to specify short vowels. However, these optional
diacritics are usually omitted in Arabic orthogra-
phy, leaving readers to infer the meaning of certain
words based on the context (Habash, 2010). This
increases the degree of word ambiguity as gender-
specific words could only differ in terms of dia-
critics. For instance, the verblςbtcan be
diacritized aslaςibta‘you [masc.] played’
or aslaςibti‘you [fem.] played’.619
4 The Gender Rewriting Task
We define the task of gender rewriting as generat-
ing alternatives of a given Arabic sentence to match
different target user gender contexts (e.g., female
speaker with a male listener, a male speaker with
a male listener, etc.). This requires changing the
grammatical gender (masculine or feminine) of cer-
tain words referring to the users (speaker/1person
and listener/2person). Previous work done by
Habash et al. (2019) and Alhafni et al. (2020) refer
to this task as gender reinflection, but we believe
that gender rewriting is a more appropriate term
given that it goes beyond reinflection.
Notation We will use four elementary symbols
to facilitate the discussion of this task: 1M, 1F, 2M
and 2F. The digit part of the symbol refers to the
grammatical persons (1or 2) and the letter part
refers to the grammatical genders (masculine or
feminine). Additionally, we will use B to refer to
invariant/ambiguous gender.
We define the sentence-level gender using the
following four labels: 1M/2F, 1F/2M, 1M/2F, and
1F/2F. These four labels indicate the grammatical
persons and genders of the user contexts we are
modeling.
We define the word-level gender based on the
genders of the word’s base form and its attach-
able pronominal enclitics (§3) using the notation:
base form gender + enclitic gender . This results in25 word-level gender labels (e.g., B+1F, 1F+2M).
We use B to refer to gender invariant/ambiguous
words. Examples of the word-level gender labels
are shown in Table 2.
Task Definition Given an Arabic sentence and a
sentence-level target gender, the goal is to rewrite
the input sentence to match the target users’ gender
preferences.
Some of the models we explore only use
sentence-level gender labels; while other models
use word-level gender labels to identify which in-
put words need to be rewritten to match the target
users’ gender preferences.
5 Data
For our experiments, we use the publicly available
Arabic Parallel Gender Corpus ( APGC ) – a parallel
corpus of Arabic sentences with gender annotations
and gender rewritten alternatives of sentences se-
lected from OpenSubtitles 2018 (Lison and Tiede-
mann, 2016). The corpus comes in two versions:
APGC v1.0 and APGC v2.0. APGC v1.0 was
introduced by Habash et al. (2019) and it con-
tains 12,238 first-person-singular Arabic parallel
gender-annotated sentences. Alhafni et al. (2022)
expanded APGC v1.0 by including contexts involv-
ing first and second grammatical persons covering
singular, dual, and plural constructions to create
v2.0, which contains 80,326 gender-annotated par-
allel sentences (596,799 words). Both versions of
APGC include the original English parallels of the
Arabic sentences.620
In all of our experiments, we use an extended
version of APGC v2.0 to train and test our systems.
We also report results on the test set of APGC v1.0
to compare with previous work.
Annotations Each sentence in APGC v2.0 has
word-level gender labels where each word is la-
beled as B, 1F, 2F, 1M, or 2M. All sentences con-
taining gender-specific words referring to human
participants have parallels representing their op-
posite gender forms. For the sentences without
any gender-specific words, their parallels are trivial
copies. Out of the 80,326 sentences in APGC v2.0,
46% (36,980) do not contain any gendered words,
whereas sentences with gendered references consti-
tute 54% (43,346). In terms of the word-level statis-
tics, 9.7% (58,066) are gender-specific, whereas
90.3% (538,733) are marked as B.
Moreover, APGC v2.0 is organized into five par-
allel corpora that are fully aligned (1-to-1) at the
word level: Input, Target 1M/2M, Target 1F/2M,
Target 1M/2F, and Target 1F/2F. All five corpora
are balanced in terms of gender, i.e., the number of
words marked as 1F and 1M is the same; and the
number of words marked as 2F and 2M is the same.
The Input corpus contains sentences with all pos-
sible word types (B, 1F, 2F, 1M, 2M). The Target
1M/2M corpus contains sentences that consist of B,
1M, 2M words; the Target 1F/2M corpus contains
sentences that consist of B, 1F, 2M words; the Tar-
get 1M/2F corpus contains sentences that consist of
B, 1M, 2F words; and the Target 1F/2F corpus con-
tains sentences that consist of B, 1F, 2F words. The
four target corpora are intended to model the targetusers’ gender preferences for a particular input.
Splits We use Alhafni et al. (2022)’s splits:
57,603 sentences (427,523 words) for training
(T ), 6,647 sentences (49,257 words) for de-
velopment ( D), and 16,076 sentences (120,019
words) for testing (T).
Preprocessing the Word-Level Annotations
Since gender information could be expressed at dif-
ferent parts of Arabic words (§3), we automatically
extend the APGC v2.0 word-level annotations to
mark the genders of both the base words and their
pronominal enclitics.
Our preprocessing pipeline considers the labeled
gendered words across the five parallel forms of
each sentence in APGC v2.0. If the word ends with
a gender marking pronominal enclitic, we label the
gender of the enclitic based on predefined rules
as 1F, 1M, 2F, or 2M. If the gendered word does
not end with a gender-marking enclitic, then we
label the enclitic as B. Once the enclitic is labeled,
we compare the base form of the word across its
parallel forms. If the base form is the same, we
label it as B. Otherwise, we assign the base form the
same label that is provided as part of APGC v2.0.
All gender ambiguous words will be labeled as B.
Table 2 presents some examples from APGC v2.0
with the extended word-level gender annotations.
The extended word-level statistics are presented
in Appendix B. We make the extended word-level
gender annotations publicly available as a new re-
lease of APGC (APGC v2.1).6216 The Multi-step Model Approach
Most of the recent work on gender rewriting rely
on using Seq2Seq models (Habash et al., 2019; Al-
hafni et al., 2020; Sun et al., 2021; Jain et al., 2021;
Vanmassenhove et al., 2021). However, the lack
of large gender-annotated parallel datasets presents
a challenge when training Seq2Seq models, and
especially when dealing with morphologically rich
languages. This issue is highlighted by Alhafni
et al. (2020), who report that most of the errors
(68%) produced by their character-level Seq2Seq
model are due to not making any changes to gender-
specific words in the input sentences. Given the
complexity of the gender rewriting task in Arabic
and the relatively small training data size, we model
the gender rewriting task using a multi-step system
the combines the positive aspects of rule-based
and neural models. Our system consists of three
components: Gender identification ,Out-of-context
word gender rewriting , and In-context ranking and
selection .
6.1 Gender Identification (GID)
We first identify the word-level gender label (base
word + pronominal enclitic) for each word in the
input sentence. We build a word-level classifier
by leveraging a Transformer-based pretrained lan-
guage model. There are many Arabic monolingual
BERT models available such as AraBERT (An-
toun et al., 2020), ARBERT (Abdul-Mageed et al.,
2021), and QARIB (Abdelali et al., 2021). How-
ever, we chose to use CAMeLBERT MSA (Inoue
et al., 2021) as it was pretrained on the largest MSA
dataset to date. Following the work of Devlin et al.
(2019), we fine-tune CAMeLBERT MSA using
Hugging Face’s transformers (Wolf et al., 2020) by
adding a fully-connected linear layer with a soft-
max on top of its architecture. During fine-tuning,
we use the representation of the first sub-token as
an input to the linear layer.
6.2 Out-of-context Word Gender Rewriting
Given the desired sentence-level target gender as an
input and the identified gender label for each word
in the input sentence, we decide if a word-level
gender rewrite is needed based on the compati-
bility between the provided sentence-level target
gender and the predicted word-level gender labels.
We implement three word-level gender alternative
generation models: Corpus-based Rewriter ,Mor-
phological Rewriter , and Neural Rewriter .
Corpus-based Rewriter (CorpusR) We build a
simple word-level lookup rewriting model by ex-
ploiting the fully aligned words in APGC v2.1.
We implement this model as a bigram maximum
likelihood estimator: given an input word with its
bigram surrounding context ( w,w), a gender al-
ternative target word ( y), and a desired word-level
target gender ( g), the CorpusR model is built by
computing P(y|w, w, g)over the training ex-
amples. During inference, we generate all possible
gender alternatives for the given input word ( w). If
the bigram context ( w,w) was not observed in
the training data, we backoff to a unigram context.
If the input word was not observed during training,
we pass it to the output as it is.
Morphological Rewriter (MorphR) For the
morphological rewriter, we use the morphological
analyzer and generator provided by CAMeL Tools
(Obeid et al., 2020). We extend the Standard Arabic
Morphological Analyzer database (SAMA) (Graff
et al., 2009) used by the morphological generator to
produce controlled gender alternatives. We make
our extensions to the database publicly available.622Given an input word and a desired word-level target
gender, the morphological generator has the ability
to produce gender alternatives by either rewriting
the base word, its pronominal enclitics, or both. If
an input word does not get recognized by the mor-
phological analyzer and generator, we pass it to the
output as it is. It is worth noting that this rewriting
model does not require any training data.
Neural Rewriter (NeuralR) Inspired by work
done on out-of-context morphological reinfec-
tion (Kann and Schütze, 2016; Cotterell et al.,
2018), we design a character-level encoder-decoder
model with attention. Given an input word and
word-level target gender, the encoder-decoder
model would generate gender alternatives of the
input word. For the encoder, we use a two-layer
bidrectional GRU (Cho et al., 2014) and for the
decoder we use a two-layer GRU with additive at-
tention (Bahdanau et al., 2015). Furthermore, we
employ side constraints (Sennrich et al., 2016) to
control for the generation of gender alternatives.
That is, we add the word-level target gender as a
special token (e.g., <1F+B>) to the beginning of
the input word and we feed that entire sequence
to the model (i.e., <1F+B>). The intuition
here is that the attentional encoder-decoder model
would be able to learn to pay attention to the side
constraints to generate the desired gender alterna-
tive of the input word. During inference, we use
beam search to generate the top 3-best hypotheses.
6.3 In-Context Ranking and Selection
Since the three word-level gender alternative gener-
ation models we implement are out-of-context and
given Arabic’s morphological richness, we expect
to get multiple output words when generating a sin-
gle gender alternative for a particular input word.
This leads to producing multiple candidate gender
alternative output sentences. To select the best can-
didate output sentence, we rank all candidates in
full sentential context based on their pseudo-log-
likelihood (PLL) scores (Salazar et al., 2020). We
first use Hugging Face’s transformers to fine-tune
the CAMeLBERT MSA model on the Input corpus
ofAPGC v2.1 by using a masked language mod-
eling (Devlin et al., 2019) objective. This helps in
mitigating the domain shift (Gretton et al., 2006)
issue between CAMeLBERT’s pretraining data and
APGC v2.1. We then compute the PLL score for
each sentence using the fine-tuned CAMeLBERT
MSA model by masking the sentence tokens oneby one.We will refer to the in-context ranking
and selection as simply selection throughout the
paper.
Figure 1 presents an overview of our gender
rewriting model. We describe the training settings
and the model’s hyperparameters in Appendix A.
7 Experimental Setup
7.1 Evaluation Metrics
We follow Alhafni et al. (2020) by treating the gen-
der rewriting problem as a user-aware grammatical
error correction task and use the MaxMatch (M)
scorer (Dahlmeier and Ng, 2012) as our evaluation
metric. The Mscorer computes the precision (P),
recall (R), and Fby maximally matching phrase-
level edits made by a system to gold-standard ed-
its. The gold edits are computed by the Mscorer
based on provided gold references. Moreover and
to be consistent with previous work, we also report
BLEU (Papineni et al., 2002) scores which are ob-
tained using SacreBLEU (Post, 2018). We report
the gender rewriting results in a normalized space
for Alif, Ya, and Ta-Marbuta (Habash, 2010).
7.2 Baselines
Do Nothing Our first baseline trivially passes
the input sentences to the output as they are. This
baseline highlights the level of similarity between
the inputs and the outputs.
Joint Baseline Model Our second baseline uses
a variant of the sentence-level linguistically en-
hanced joint gender identification and rewriting
model introduced by Alhafni et al. (2020). The
main difference between this model and the one in-
troduced by Alhafni et al. (2020) is that we model
four multi-user target genders, whereas they only
modeled two single-user target genders (1M, 1F).
We implement this joint baseline model using a
character-level GRU encoder-decoder with addi-
tive attention, where the learned input character-
level representations are enriched with word-level
morphological features obtained from the extended
morphological analyzer that is part of CAMeL
Tools. The representation of the input sentence-
level target gender (1M/2M, 1F/2M, 1M/2F, 1F/2F)
is learned as part of the model and used during
decoding when generating gender alternatives. We
refer to this baseline as Joint+Morph .623Extended Joint Baseline Models Our third and
fourth baseline models reduce the complexity of
theJoint+Morph model by not learning a repre-
sentation for the input sentence-level target gen-
der as part of the model. Instead, we provide the
sentence-level target gender information as side
constraints. We add the target gender as a special
token to the beginning of the input sentence (e.g.,
<1M/2F>Input Sentence) when we feed it to the
model. Moreover, we explore the effectiveness of
enriching the input character representations with
word-level morphological features. To do so, we
omit the morphological features from the first joint
variant, and we use them in the second. We refer
to these models as Joint+Side Constraints and
Joint+Morph+Side Constraints , respectively.
7.3 Our Multi-step Models
We explore five variants of the gender rewriting
multi-step model described in §6. All five variants
use the same gender identification ( GID ) and in-
context selection models, but they differ in their out-
of-context word-level gender rewriting generation
setup. The first three variants use one word-level
gender rewriting model each – CorpusR ,Mor-
phR, orNeuralR . The fourth multi-step model
uses MorphR as a backoff if the input words that
need to be rewritten are not observed by the Cor-
pusR model during training ( CorpusR»MorphR ).
The fifth system uses all three word-level gender
alternative generation models in a backoff cascade:
CorpusR»MorphR»NeuralR .
7.4 Data Augmentation
Given the relatively small size of APGC v2.1 and
motivated by recent work on using data augmenta-
tion to improve grammatical error correction (Wan
et al., 2020; Stahlberg and Kumar, 2021), we inves-
tigate adding additional training examples through
data augmentation. We randomly selected 800K
sentences from the English-Arabic portion of the
OpenSubtitles 2018 dataset, which was used to
build APGC . We ensured that all extracted pairs
include either first or second (or both) person pro-
nouns on the English side: I, me, my, mine, myself,
andyou, your, yours, yourself . To generate gen-
der alternatives of the selected Arabic sentences,
we pass each sentence four times through our best
gender rewriting system to generate all four user
gender contexts (1M/2M, 1F/2M, 1M/2F, 1F/2F).
We add the 800K selected Arabic sentences and
their 1M/2M, 1F/2M, 1M/2F, 1F/2F generated gen-der alternatives to the Input, Target 1M/2M, Target
1F/2M, Target 1M/2F, and Target 1F/2F corpora
of the training split of APGC v2.1, respectively.
At the end, we end up with 857,603 Arabic par-
allel sentences (6,209,958 words). We make the
synthetically generated data publicly available.
8 Results
Table 3 presents the Dset results. Joint+Side
Constraints andJoint+Morph+Side Constraints
significantly improve over the Joint+Morph base-
line with up to 13.87 increase in F. The best
performing system overall is our multi-step model
using all rewrite components – Table 3(i), hence-
forth, Our Best Model . It improves over all the
joint models in every compared metric, includ-
ing a 22.84 increase in Fwhen compared to the
Joint+Morph baseline. Our Best Model ’s biggest
advantages seem to come from combining the three
word-level out-of-context gender alternative gen-
eration models in a cascaded setup to deal with
OOV words during the generation. Comparing (i)
with (e,f,g) in Table 3, we observe improvements
ranging from 3.91 to 6.02 F.
We used Our Best Model to conduct the data aug-
mentation experiments as discussed in §7.4. The
full set of augmentation experiment results are pre-
sented in Appendix C. The best augmented model’s
results, which benefits from augmentation in the
GID andNeuralR components, are also presented
in Table 3(j). However, its increase of 0.19 points
in Fis not statistically significant with McNe-
mar’s (McNemar, 1947) test at p > 0.05.
The results of our best models on the Tsets
ofAPGC v2.1 and APGC v1.0 are presented
in Table 4. The results on APGC v2.1 T
show consistent conclusions with the Dresults.
Our best augmented model improves over its non-
augmented variant in every compared metric, in-
cluding a 0.25 absolute increase in Fthat is statis-
tically significant with McNemar’s test at p < 0.05.
ForAPGC v1.0, we do not report results with aug-
mentation for fair comparison to previous results.
In both Tsets, we establish new SOTAs.
Error Analysis We conducted an error analysis
over the output of our best augmented system on
APGC v2.1 D. In total, there were 1,475 (5.5%
out of 26,588) sentences with errors across the four
target corpora. Table 5 presents a summary of the
error types our best augmented gender rewriting
model makes.624P R FBLEU
(a)Do Nothing 100.0 0.0 0.0 89.36
(b)Joint +Morph 64.76 67.40 65.27 93.31
(c)Joint +Side Constraints 77.10 77.71 77.22 95.60
(d)Joint +Morph +Side Constraints 78.97 79.84 79.14 96.17
(e)GID +CorpusR +Selection 88.22 71.22 84.20 96.54
(f)GID +MorphR +Selection 84.48 75.29 82.47 96.96
(g)GID +NeuralR +Selection 84.62 73.32 82.09 96.75
(h)GID +CorpusR »MorphR +Selection 88.59 85.84 88.02 97.96
(i)GID +CorpusR »MorphR »NeuralR +Selection 88.46 86.74 88.11 98.04
(j)GID+CorpusR »MorphR »NeuralR+Selection 88.67 86.84 88.30 98.05
P R FBLEU
APGC Joint +Morph +Side Constraints 79.27 80.44 79.50 96.19
v2.1 GID +CorpusR »MorphR »NeuralR +Selection 88.70 86.13 88.17 97.98
Test GID+CorpusR »MorphR »NeuralR+Selection 88.86 86.69 88.42 98.05
APGC Habash et al. (2019) 77.74 52.06 70.76 98.28
v1.0 Alhafni et al. (2020) 78.98 60.32 74.38 98.49
Test GID +CorpusR »MorphR »NeuralR +Selection 78.57 73.17 77.43 98.92
1M/2M 1F/2M 1M/2F 1F/2F
GID 150 56% 194 70% 325 68% 324 72%
Rewrite 69 26% 50 18% 82 17% 66 15%
Select 49 18% 35 13% 73 15% 58 13%
Total 268 279 480 448
Target 1M/2M 1F/2M 1M/2F 1F/2F
Google Translate 13.59 13.15 11.38 10.96
Best System 13.71 13.64 13.30 13.23
The majority of errors (67.3%) were caused
byGID which achieves a word-level accuracy of
98.9% on D. The gender-rewriting errors con-
stituted 18.1% and selection errors 14.6%. Con-
sidering different target corpora, we observe that
every time an F target is added, the number of er-
rors increases. The 1M/2M target outputs has the
lowest number of errors (268 or 18%), while the
1M/2F targets outputs has the highest number of
errors (480 or 33%).Use Case: Post-Editing MT Output We demon-
strate next how our proposed gender rewriting
model could be used to personalize the output of
user-unaware MT systems through post-editing.
We use the English to Arabic Google Translate
output sentences that are part of APGC v2.1. We
evaluate Google Translate’s output against all four
target corpora (1M/2M, 1F/2M, 1M/2F, 1F/2F) sep-
arately. To re-target Google Translate’s Arabic out-
put for the four user gender contexts we model, we
pass each Arabic sentence four times through our
best augmented system (Table 3(j)). We present
the evaluation in terms of BLEU in Table 6 over
APGC v2.1 T. All the results are reported in
an orthographically normalized space for Alif, Ya,
and Ta-Marbuta.
Again, we observe that every time an M partic-
ipant is switched to F, the BLEU scores drop for
Google Translate’s output. This is consistent to
what have been reported by Alhafni et al. (2022)
and highlights the bias the machine translation
output has towards masculine grammatical gen-
der preferences. The post-edited outputs gener-
ated by our best augmented system improves over
Google Translate’s across the four target user con-
texts, achieving the highest increase in 2.27 BLEU
points for 1F/2F.6259 Conclusion and Future Work
We defined the task of gender rewriting in contexts
involving two users (I and/or You), and developed
a multi-step system that combines the positive as-
pects of both rule-based and neural rewriting mod-
els. Our best models establish the benchmark for
this newly defined task and the SOTA for a previ-
ously defined first person version of it. We further
demonstrated a use case of our gender rewriting
system by post-editing the output of a commercial
MT system to provide personalized outputs based
on the users’ grammatical gender preferences.
In future work, we plan to explore the use of
other pretrained models, and to work on the prob-
lem of gender rewriting in other languages and
dialectal varieties.
Ethical Considerations
Gender Rewriting Our underlying intention of
developing a gender rewriting model for Arabic
is to increase the inclusiveness of NLP applica-
tions that deal with gender-marking morphologi-
cally rich languages. Our work aims at empowering
and allowing users to interact with NLP technol-
ogy in a way that is consistent with their social
identities. We acknowledge that by limiting the
choice of gender expressions to the grammatical
gender choices in Arabic, we exclude other alter-
natives such as non-binary gender or no-gender
expressions. However, we are not aware of any
sociolinguistics published research that discusses
such alternatives for Arabic. We stress on the im-
portance of adapting Arabic NLP models to new
gender alternative forms as they emerge as part
of the language usage. We further recognize the
limitations of the gender identification component
we use as part of our multi-step gender rewriting
model as it relies on a language model that was
pretrained on a large monolingual Arabic corpus,
which could possibly contain biased text. We re-
alize the potential risks of our proposed gender
rewriting model if it is intentionally maliciously
misused to produce gender alternatives that do not
match the target users’ gender preferences.
Data We use the publicly available Arabic Paral-
lel Gender Corpus ( APGC ).It is subject to its cre-
ators’ own Copy Rights and User Agreement and
we strictly adhere to its intended usage. It is worthnoting that APGC does not contain any hetero-
centric assumptions as part of its annotations (e.g.,
the word‘my husband’ is labeled as gender-
ambiguous (B)). Moreover, all proper names are
labeled as B, even when they have strong gender-
specific association (Alhafni et al., 2022). The
Arabic data we use for our data augmentation ex-
periments was randomly sampled from OpenSub-
titles 2018 (Lison and Tiedemann, 2016), which
is publicly available.OpenSubtitles is distributed
under a Creative Commons license.
Acknowledgements
We thank Alberto Chierici, Christian Khairallah,
Go Inoue, and Ossama Obeid for the helpful dis-
cussions. We acknowledge the support of the High
Performance Computing Center at New York Uni-
versity Abu Dhabi. Finally, we wish to thank the
anonymous reviewers at NAACL 2022 for their
feedback.
References626627628629A Detailed Experimental Setup
Gender Identification We fine-tune CAMeL-
BERT MSA on a single GPU for 10 epochs with
a learning rate of 5e-5, batch size of 32, a seed
of 12345, and a maximum sequence length of 128.
For the augmentation experiments, we use the same
hyperparamters but we run the fine-tuning for 3
epochs. At the end of the fine-tuning, we pick
the best checkpoint based on the performance on
theDset. Our gender identification model has
108,506,901 parameters.
In-Context Ranking and Selection We fine-
tune CAMeLBERT MSA on a single GPU for 3
epochs with a learning of 5e-5, batch size of 32,
and a seed of 88. The fine-tuned CAMeLBERT
MSA model has 109,112,880 parameters.
Neural Rewriter (NeuralR) For the character-
level encoder-decoder neural rewriter model we use
a character embedding size of 128, a hidden size
of 256, a dropout probability of 0.2 on the outputs
of each GRU layer, and gradient clipping with a
maximum norm of 1. We train for 50 epochs on a
single GPU with early stopping after 6 epochs if
the loss does not decrease on the Dset. We use
the Adam (Kingma and Ba, 2014) optimizer with
an initial learning rate of 5e-4, decaying by a factor
of 0.5 if the loss on the Dset does not decrease
after 2 epochs. We train with greedy decoding
and a batch size of 32. We also apply scheduled
sampling (teacher forcing) (Bengio et al., 2015)
with a constant sampling probability (0.3) during
training. During inference, we use beam search
with a beam width of 10 to produce the top 3-best
hypotheses. Our NeuralR model has 3,287,110
parameters.
Joint Models The training settings and the hy-
perparameters of the joint models are identical to
the ones we use in our NeuralR model.
The crucial difference between the
Joint+Morph model and its extended variants
(Joint+Side Constraints andJoint+Morph+Side
Constraints ) is that the rewriting in the
Joint+Morph model is conditioned on the
sentence-level target gender. The representation
of the sentence-level target gender in the baseline
model is learned as an embedding of size 10 during
training and only used in the decoder.
Our Joint+Morph model has 3,481,178 pa-
rameters; the Joint+Side Constraints model has3,293,258 parameters; and the Joint+Morph+Side
Constraints model has 3,480,926 parameters.
Training Time TheCorpusR model was trained
on a single CPU and it took ≈2 minutes to be
trained. All our neural models were trained on a
single GPU. Fine-tuning CAMeLBERT MSA on
the gender identification task took ≈1 hour; fine-
tuning CAMeLBERT MSA on the MLM objective
took≈1 hour. Training the NeuralR model with
different settings took ≈12 hours in total. All the
baseline joint models took ≈29 hours to be trained.
It is worth noting that all the results presented
in this work are reported over a single run and
the hyperparameters of our neural models were
manually tuned based on the performance on the
Dset.
B Arabic Parallel Gender Corpus v2.1:
Extended Word-Level Annotations630P R F BLEU
(a)GID +CorpusR»MorphR »NeuralR +Selection 88.19 86.66 87.88 98.04
(b)GID+CorpusR »MorphR »NeuralR +Selection 88.63 86.91 88.28 98.05
(c)GID +CorpusR »MorphR »NeuralR+Selection 88.50 86.64 88.12 98.04
(d)GID+CorpusR»MorphR »NeuralR +Selection 88.41 86.89 88.10 98.06
(e)GID+CorpusR »MorphR »NeuralR+Selection 88.67 86.84 88.30 98.05
(f)GID+CorpusR»MorphR »NeuralR+Selection 88.39 86.87 88.08 98.05
C Augmentation Experiments
When it comes to the data augmentation experi-
ments, we took the best performing system (Table
3(i)) and explored training its different components
on the augmented training data. Evaluation results
on the Dset of APGC v2.1 using data augmen-
tation are presented in Table 8. Starting off with
training the CorpusR model on the augmented
data (Table 8(a)), we notice a decrease in perfor-
mance by 0.23 Fcompared to Our Best Model
(Table 3(i)). This is attributed to the noisy cov-
erage increase in the CorpusR model and can be
observed by the decrease in precision (88.19) and
recall (86.66). When we train the GID and the Neu-
ralR models on the augmented data (Table 8(b-c)),
we get an increase in Freaching 88.28 and 88.12,
respectively. However, using both the augmented
GID andCorpusR models (Table 8(d)) decreases
the performance slightly as it achieves 88.10 in
F. The best performing system was the one that
uses both the augmented GID andNeuralR models
(Table 8(e)) as it improves over its non-augmented
variant reaching 88.30 (0.19 increase) in F. Com-
bining the three augmented GID ,CorpusR , and
NeuralR models (Table 8(f)) achieves 88.08 in
F.631