
Chuhan WuFangzhao WuTao QiYongfeng HuangDepartment of Electronic Engineering, Tsinghua University, Beijing 100084, ChinaMicrosoft Research Asia, Beijing 100080, China
{wuchuhan15, wufangzhao, taoqi.qt }@gmail.com
yfhuang@tsinghua.edu.cn
Abstract
Effectively finetuning pretrained language mod-
els (PLMs) is critical for their success in down-
stream tasks. However, PLMs may have risks
in overfitting the pretraining tasks and data,
which usually have gap with the target down-
stream tasks. Such gap may be difficult for
existing PLM finetuning methods to overcome
and lead to suboptimal performance. In this
paper, we propose a very simple yet effective
method named NoisyTune to help better fine-
tune PLMs on downstream tasks by adding
some noise to the parameters of PLMs before
finetuning. More specifically, we propose a
matrix-wise perturbing method which adds dif-
ferent uniform noises to different parameter
matrices based on their standard deviations. In
this way, the varied characteristics of different
types of parameters in PLMs can be consid-
ered. Extensive experiments on both GLUE
English benchmark and XTREME multilingual
benchmark show NoisyTune can consistently
empower the finetuning of different PLMs on
different downstream tasks.
1 Introduction
In recent years, pretrained language models
(PLMs) have achieved huge success in NLP (Qiu
et al., 2020). Many PLMs such as BERT (De-
vlin et al., 2019), RoBERTa (Liu et al., 2019)
and UniLM (Dong et al., 2019) which are pre-
trained from large-scale unlabeled corpus in a self-
supervised way, have significantly improve vari-
ous downstream tasks such as reading comprehen-
sion (Xu et al., 2019), machine translation (Brown
et al., 2020), text classification (Bao et al., 2020),
dialog (Wu et al., 2020) and recommendation (Wu
et al., 2021) by finetuning on these tasks.
How to effectively finetune PLMs to better em-
power downstream tasks is an important research
problem (Zheng et al., 2021). Many existing NLP
methods usually directly finetune PLMs with theFigure 1: Schematic comparisons between standard
PLM finetuning and our NoisyTune .
labeled data in downstream tasks (Sun et al., 2019).
Only a few works explore more effective and ro-
bust PLM finetuning methods (Chen et al., 2020;
Lee et al., 2020; Aghajanyan et al., 2021; Zhang
et al., 2021; Xu et al., 2021). For example, Chen
et al. (2020) proposed RecAdam that adds a penalty
item to minimize the Ldistance between the fine-
tuned models and the pretrained models, where
the penalty intensity is time-variant during fine-
tuning. Lee et al. (2020) proposed Mixout which
randomly replaces part of the parameters in the
finetuned model with their original weights in the
PLMs. These PLM finetuning methods mainly
focus on preventing PLMs from overfitting the lim-
ited labeled data in downstream tasks. Besides the
overfitting of downstream task data, a rarely stud-
ied problem is that the PLMs usually overfit the
pretraining tasks and data (Qi et al., 2020), which
may have significant gap with the downstream task
and data. It is not easy for existing PLM finetun-
ing methods to overcome such gap (Roberts et al.,
2020), which may lead to suboptimal performance
especially when labeled data in downstream tasks
is insufficient.
In order to handle this problem, in this paper
we propose a very simple yet effective method
named NoisyTune , which can help better finetune
PLMs for downstream tasks. Different from the680standard finetuning paradigm (Fig. 1 (a)) which
directly finetunes PLMs on the downstream task
data, the key idea of NoisyTune is to add a small
amount of noise to perturb PLMs parameters before
finetuning (Fig. 1 (b)). It can help prevent PLMs
from overfitting the tasks and data in the pretrain-
ing stage, and reduce the gap between pretraining
and downstream tasks. Since PLMs have different
types of parameters which usually own different
characteristics, in NoisyTune we use a matrix-wise
perturbing method that adds uniform noise with
different intensities to different parameter matri-
ces according to their standard deviations for bet-
ter adaptation. We conduct extensive experiments
on two widely used NLP benchmarks, namely,
GLUE (Wang et al., 2018) for English language
understanding and XTREME (Hu et al., 2020) for
multilingual language understanding. The results
show NoisyTune can empower the finetuning of dif-
ferent PLMs on many different downstream NLP
tasks to consistently achieve better performance. In
addition, the results show NoisyTune can be eas-
ily combined with many existing PLM finetuning
methods and further improve their performance.
2 NoisyTune
The goal of NoisyTune is for more effective finetun-
ing of PLMs on downstream tasks. The motivation
ofNoisyTune is that PLMs are well pretrained on
some unlabeled corpus with some self-supervision
tasks, and they may overfit these pretraining data
and tasks (Qi et al., 2020), which usually have gap
with the downstream task and data. It may be diffi-
cult for PLMs to effectively adapt to downstream
tasks especially when labeled data in these tasks
are limited, which is usually the case. Motivated by
the dueling bandits mechanism (Yue and Joachims,
2009) that adds randomness to the model for explo-
ration, as shown in Fig. 1, we propose to add some
noise to the parameters of PLMs before finetuning
them on downstream tasks to do some “exploration”
in parameter space and reduce the risk of overfitting
the pretraining tasks and data.
PLMs usually have different kinds of parameter
matrices, such as query, key, value, and feedfor-
ward network matrices (Devlin et al., 2019). Differ-
ent parameter matrices in the PLMs usually have
different characteristics and scales. For example,
some researchers found that the self-attention pa-
rameters and the feed-forward network parame-
ters in Transformers have very different properties,such as rank and density (Wang et al., 2020). Thus,
adding unified noise to all parameter matrices in
PLMs may not be optimal for keeping their good
model utility. To handle this challenge, we propose
a matrix-wise perturbing method that adds noise
with different intensities to different parameter ma-
trices according to their variances. Denote the pa-
rameter matrices (or scalars/vectors) in a PLM as
[W,W, ...,W], where Nis the number of pa-
rameter matrix types. Denote the perturbed version
of the parameter matrix Was˜W, which is com-
puted as follows:
˜W=W+U(−λ
2,λ
2)∗std(W),(1)
where stdstands for standard deviation. The func-
tionU(a, b)represents uniform distribution noise
ranged from atob, and λis a hyperparameter
that controls the relative noise intensity.We can
see that in NoisyTune parameters in PLMs with
higher variance will be added with stronger noise.
In addition, in some PLMs there are some con-
stant matrices, such as token type embeddings in
RoBERTa (Liu et al., 2019). They will not be per-
turbed because their standard deviation is 0. It
can ensure that these constant matrices will not be
accidentally activated by additional noise.
NoisyTune is a simple and general plug-and-play
technique that can be applied to the finetuning of
any PLM on any task, simply by inserting the fol-
lowing PyTorch-style code before finetuning: −
* *
3 Experiments
3.1 Datasets and Experimental Settings
We conduct extensive experiments on two widely
used benchmarks for PLM evaluation. The first one
is GLUE (Wang et al., 2018), which is a benchmark
for English language understanding that contains
different tasks like natural language inference, sen-
timent analysis and sentence similarity evaluation.
The second one is XTREME (Hu et al., 2020),
which is a benchmark for multilingual language
understanding. It covers 40 languages and contains681four groups of tasks, including sentence classifica-
tion, structured prediction, sentence retrieval and
question answering. More details of these bench-
marks can refer to their original papers and official
websites. Since the test labels of GLUE are not
released, following (Bao et al., 2020) we report re-
sults on the dev set of GLUE. The XTREME results
are evaluated on the test set. The hyperparameter
λis 0.15 on GLUE and is 0.1 on XTREME. The
searching range of hyperparameters in our work
are listed in Table 1.
Following (Zheng et al., 2021), in sentence re-
trieval tasks we first train the models on the XNLI
dataset, and then use the average of token repre-
sentations produced by the hidden layer that yields
the best performance. In order not to harm the
alignment of token embeddings across different
languages, we do not add noise to the token em-
beddings in multilingual PLMs. We repeat exper-
iments 5 times with different random seeds and
report the average scores.
3.2 Performance Evaluation
On the GLUE benchmark, we compare the perfor-
mance of directly finetuning the base version of
BERT (Devlin et al., 2019), XLNET (Yang et al.,
2019), RoBERTa (Liu et al., 2019) and ELEC-
TRA (Clark et al., 2020) with that of finetuning
them after applying NoisyTune . On the XTREME
benchmark, we compare the performance of di-
rectly finetuning both base and large versions of
XLM-R (Conneau et al., 2020) with that of their
variants obtained by applying NoisyTune . The
results on these two benchmarks are shown in
Tables 2 and 3, respectively. On the XTREME
datasets, we report two types of results. The first
one is zero-shot crosslingual transfer from English
to other languages, and the second one is learning
models on both English and translated data.
According to these results, NoisyTune can consis-
tently improve the performance of different PLMs
on different tasks in both English and multilingual
settings. In addition, the performance improvementbrought by NoisyTune is usually larger on relatively
small datasets (e.g., RTE, CoLA and WNLI). These
results indicate that when labeled data in down-
stream tasks is insufficient, it is quite difficult to
effectively finetune PLMs starting from the origi-
nal parameters which usually overfit the pretraining
tasks and data. The experimental results validate
thatNoisyTune can properly perturb PLMs with a
little noise to explore different parameter spaces
and reduce the overfitting problem, making PLMs
easier to be adapted to downstream tasks.
3.3 Which Noise to Use and How?
In this section we study which kind of noise is
more suitable for NoisyTune . In addition, we ex-
plore whether our proposed matrix-wise perturb-
ing method is better than using a unified global
noise for all model parameters in PLMs. We com-
pare five methods, including (1) NoisyTune without
any noise; (2) NoisyTune with a global Gaussian
noise; (3) NoisyTune with a global uniform noise;
(4)NoisyTune with matrix-wise Gaussian noise; (5)
NoisyTune with matrix-wise uniform noise. The re-
sults on GLUE are shown in Fig. 2, and the results
on XTREME show similar patterns. We find that
adding global noise with the same distribution to
all the PLM parameters will harm the model perfor-
mance. This is because different parameter matri-
ces in PLMs have very different distributions and
characteristics (Wang et al., 2020). Simply adding
a unified global noise to all the parameter matrices
is not optimal. The results show that matrix-wise
noise is a much better choice, since the different
characteristics of different parameter matrices can
be taken into consideration. In addition, we find an
interesting phenomenon that adding uniform noise
is better than Gaussian noise. This may be because
Gaussian noise has wider ranges and some extreme
values may affect the model performance. Thus,
we use matrix-wise uniform noise in NoisyTune .
3.4 Combination with Existing PLM
Finetuning Methods
From Fig. 1, it is very clear that NoisyTune is in-
dependent of the specific PLM finetuning method,
since it is applied at the stage before finetuning
PLM on the task-specific data. Thus, it is very
easy to combine NoisyTune with any kind of ex-
isting PLM finetuning method. In this section, we
explore whether NoisyTune has the potential to em-
power the existing PLM finetuning techniques to
achieve better performance. Here we select two682
well-known PLM finetuning for experiments, i.e.,
RecAdam (Chen et al., 2020) and Mixout (Lee
et al., 2020). The experimental results are summa-
rized in Fig. 3. We find that combining NoisyTune
with existing PLM finetuning techniques can fur-
ther improve their performance. This is because
NoisyTune aims to address the overfitting of pre-
training signals while these methods aim to prevent
overfitting in downstream tasks. Thus, NoisyTune
and these PLM finetuning methods are complemen-
tary, and they can be empowered by NoisyTune to
achieve better performance.
3.5 Empirical Analysis of NoisyTune
Next, we empirically analyze why NoisyTune can
help PLM finetuning. We compare the accuracy
of BERT with and without NoisyTune finetuned
with different percentage of samples on the MRPC
dataset.The results are shown in Fig. 4. We
findNoisyTune can consistently improve PLMs un-
der different amounts of data, especially when less
training data is used. This is because the perturbed
PLMs may have lower risks of overfitting the pre-
training tasks and have better generalization abil-
ities, which is especially beneficial for finetuning
PLMs on downstream task with limited data.
To further study the impact of NoisyTune on
PLM finetuning, we show the relative changes of
the L-norms of different kinds of parameters in
the BERT model during finetuning on the MRPC
dataset in Fig. 5.Since the noise we added to
PLMs in NoisyTune is zero-mean uniform noise,
the absolute parameter L-norm will not change
too much. However, we can see that the relative
change of L-norms becomes smaller when Noisy-
Tune is applied, which indicates that the PLMs can
find the (sub)optimal parameters for downstream683
tasks more easily. This result validates directly fine-
tuning PLMs may need more updates to adapt to
downstream tasks, which is due to the overfitting of
pretraining tasks, and NoisyTune can provide a sim-
ple way to alleviate this problem and help finetune
PLMs on downstream tasks more effectively.
3.6 Hyperparameter Analysis
We study the influence of the most important hy-
perparameter in NoisyTune , i.e.,λ, which controls
the relative noise intensity. The average GLUE
scores w.r.t. different λvalues are shown in Fig. 6.
We find that when λis too small or too large, the
performance is not optimal. This is because when
λis too small, it is difficult for PLMs to do param-
eter space exploration and overcome the overfitting
problem. While when λis too large, the useful pre-
trained knowledge in PLMs may be overwhelmed
by random noise. Values between 0.1 and 0.15 are
more suitable for NoisyTune on the GLUE datasets.
4 Conclusion
In this paper, we propose a very simple but effective
method named NoisyTune , which can help better
finetune PLMs on downstream tasks by adding a
little noise to them before finetuning. In NoisyTune ,
we propose a matrix-wise perturbing method that
adds noise with different intensities to different
kinds of parameter matrices in PLMs according
to their variances. NoisyTune is a very general
method, and is PLM model agnostic, downstream
task agnostic, and finetuning method agnostic. Ex-
tensive experiments on both monolingual GLUE
benchmark and multilingual XTREME benchmark
demonstrate NoisyTune can consistently empower
the finetuning of different PLMs on various down-
stream tasks to achieve better performance.
Acknowledgments
This work was supported by the National Natural
Science Foundation of China under Grant num-
bers U1936216, U1936208, and 61862002, and
the research initiation project of Zhejiang Lab (No.
2020LC0PI01).684References685