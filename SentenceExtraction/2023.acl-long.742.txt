
Xiangqing Shen, Siwei Wu, and Rui Xia
School of Computer Science and Engineering,
Nanjing University of Science and Technology, China
{xiangqing.shen, wusiwei, rxia}@njust.edu.cn
Abstract
A is a large-scale commonsense knowl-
edge graph (CSKG) containing everyday if-
then knowledge triplets, i.e., { head event , rela-
tion, tail event }. The one-hop annotation man-
ner made A a set of independent bipar-
tite graphs, which ignored the numerous links
between events in different bipartite graphs and
consequently caused shortages in knowledge
coverage and multi-hop paths. In this work,
we aim to construct Dense- A with high
knowledge coverage and massive multi-hop
paths. The events in A are normalized to
a consistent pattern at first. We then propose a
CSKG completion method called Rel-CSKGC
to predict the relation given the head event and
thetail event of a triplet, and train a CSKG
completion model based on existing triplets
inA . We finally utilize the model to
complete the missing links in A and ac-
cordingly construct Dense- A . Both au-
tomatic and human evaluation on an annotated
subgraph of A demonstrate the advan-
tage of Rel-CSKGC over strong baselines. We
further conduct extensive evaluations on Dense-
A in terms of statistics, human evalua-
tion, and simple downstream tasks, all prov-
ing Dense- A ’s advantages in Knowledge
Coverage and Multi-hop Paths. Both the source
code of Rel-CSKGC and Dense- A are
publicly available on https://github.com/
NUSTM/Dense-ATOMIC .
1 Introduction
A is a large-scale human-annotated com-
monsense knowledge graph focusing on the infer-
ential knowledge in social life (Sap et al., 2019).
It consists of nine if-then relation types describ-
ing the causes, effects, agent, stative, and theme
of an event. The research on A has drawn
more and more attention in recent years. An in-
creasing number of downstream tasks, includingcommonsense reasoning (Yu et al., 2022), sto-
rytelling (Brahman and Chaturvedi, 2020), ques-
tion answering (Heo et al., 2022), dialog genera-
tion (Wu et al., 2022), etc., have improved their
performances by acquiring and utilizing the com-
monsense knowledge from A .
Currently, A was constructed under one-
hop annotations. It began with 24,000 pre-defined
base events and nine relation types. For each base
event and each relation, the annotators were asked
to write a possible tail event based on one-hop rea-
soning. As shown in Figure 1, given the base event
“X asks Y to marry” , the annotated tail events can be
“loving” under the relation of “xAttr” ,“smiles” un-
der the relation of “xEffect” , and “says yes” under
the relation of “oEffect” .
In such a one-hop annotation manner, each base
event and its related annotated tail events shape
a bipartite graph containing only B-to-Alinks,
whereBdenotes the Base event and Adenotes the
Annotated tail event. Thereby, the whole graph of
A can be viewed as a set of B-to-Abipartite
graphs, while the B-to-B,A-to-BandA-to-Alinks
between different bipartite graphs were almost ig-
nored. In Figure 1, the dashed lines illustrate such
missing links in A , e.g., an annotated tail
event “in front of Y” and a base event “X asks Y to
marry” in two different bipartite graphs miss a link
of the “xIntent” relation.
This leads to two shortcomings of A .
Firstly, with only B-to-Alinks, A contains
very few multi-hop paths, since an annotated tail
event cannot become the head event of a triplet.
Secondly, missing B-to-B,A-to-BandA-to-A
links cause unsatisfactory knowledge coverage, de-
spite its high-quality human-annotated common-
sense knowledge. Both shortcomings limit the po-
tential of A in practical applications. Intu-
itively, an ideal CSKG requires high knowledge
coverage to meet the needs of various tasks, and
massive multi-hop paths to understand the evolu-13292
tion between different events.
In this work, we aim to construct a densely-
connected A . The key is to complete dif-
ferent types of missing links, leading to denser
A with high knowledge coverage and mas-
sive multi-hop paths. We achieve this goal through
three main steps: Normalizing Tail Events, Train-
ing a Relation Prediction Model and Constructing
Dense-A .
Firstly, most of the annotated tail events in
A have different patterns to the base events,
so we normalize annotated tail events in A to
a consistent pattern ( “Subject + Verb + Object” ), to
facilitate subsequent CSKG completion. Specific
relations are also grouped to mitigate ambiguity.
Secondly, we train a relation prediction model
based on a set of existing triplets in A to
infer the missing links on the whole graph, i.e.,
CSKG completion upon A . To the best of
our knowledge, most of the existing studies for
CSKG completion utilized the translation based
methods, which formalized the CSKG completion
as a tail event ranking task given the head event
and the relation. A graph convolutional network
(GCN) was mostly employed to encode the graph
embeddings of events, but its performance is unsat-
isfactory since the sparsity of A limits the
information propagation on the GCN (Malaviya
et al., 2020). In contrast, in this work, we propose a
method called Rel-CSKGC, which regards CSKGcompletion as a relation prediction problem given
thehead event and the tail event , and accordingly
train a CSKG completion model based on A .
Finally, based on the CSKG completion model,
we construct Dense- A by inferring the miss-
ing links on A . Figure 1 illustrates the main
differences between A and Dense- A .
We conduct extensive evaluations towards the
Rel-CSKGC method and the constructed Dense-
A , respectively.
First, we compare Rel-CSKGC with several
newly proposed relation prediction methods and
translation based methods. Both automatic evalua-
tion on an annotated subgraph and human evalua-
tion on 500 sampled triplets show the advantage of
Rel-CSKGC for completion on A .
Next, we evaluate Dense- A from the per-
spectives of knowledge coverage and multi-hop
paths respectively. Extensive experiments are con-
ducted in terms of statistics, human evaluation, and
simple downstream tasks. The results demonstrate
that Dense-ATOMIC surpasses ATOMIC in terms
of triplet counts by an order of magnitude, and
multi-hop paths by more than two orders of magni-
tude, respectively, while at the same time maintain-
ing its quality.
2 Approach
Figure 2 illustrates the procedure of constructing
Dense- A , consisting of three main steps:13293
Normalizing Tail Events, Training a Relation Pre-
diction Model, and Constructing Dense-A .
2.1 Normalizing Tail Events
A contains only B-to-Atriplets. A CSKG
completion model trained with B-to-Atriplets is
inapplicable to predict B-to-B,A-to-A, andA-to-
Blinks, since base events (usually sentences) and
annotated tail events (usually phrases or words)
have different patterns. This results in a shortage
of knowledge coverage and multi-hop paths during
the completion.
To this end, we propose Normalizing Tail Events
to convert annotated tail events to the same pattern
as the base events, including subject removal, third
person singular form conjugation, subject recovery,
and relation grouping.
Subject Removal For a few annotated tail events
being complete sentences, we perform depen-
dency tree parsing and part-of-speech tagging with
CoreNLP (Manning et al., 2014) and remove sub-
jects based on the two kinds of structure patterns,
which makes the nodes in the graph become a uni-
form pattern and benefits the subject recovery pro-
cess. For example, given a tail event “He smiles”,
we first remove the subject “He” and convert it to
a universal expression “Y smiles” in the subject
recovery process.Third Person Singular Form Conjugation In
our preliminary experiments, a CSKG completion
model tends to correlate phrases starting with “to”
with relations such as “xWant” ,“xIntent” , so we
leverage WordNet (Miller, 1995) to acquire the
verb root and add the suffix (-s, -es, etc.) according
to English grammar.
Subject Recovery We add subjects to processed
annotated tail events based on different relations.
Relation Grouping Both “xWant” and“xEffect”
describe the possible subsequent events, distin-
guished by “to” representing subject will. After
third person singular form conjugation, the two
relations may lead to ambiguity. We perform re-
lation grouping for all these relations to mitigate
ambiguity. “xEffect” and“xWant” form “xAfter”
describing what will happen to X .“oEffect” and
“oWant” form “oAfter” describing what will hap-
pen to Y .“xAttr” and“xReact” form “xPersona”
describing how X feels or is described . It should
be noted that the relation grouping process leads
to a non-serious problem, i.e., the grouped relation
cannot distinguish between subjective and objec-
tive semantics. However, it mitigates A ’s
sparsity issue and improves the performance of the
relation prediction model.
Due to the page limitation, the pseudo-code of
normalizing tail events is present in Appendix A.13294It is worth noting that our normalization method
resembles a prior work (Fang et al., 2021b,a). Their
purpose is to align A with other CSKGs,
while we focus on event alignment in A by
eliminating differences among different events.
2.2 Training a Relation Prediction Model
2.2.1 Limitation of Traditional Methods
Traditional methods for the completion of A
proposed to score all candidate tail events given
thehead event and the relation. The GCN for en-
coding graph embeddings of events induced two
shortcomings: 1) it is difficult for a GCN to propa-
gate information due to the sparse graph structure
ofA (Malaviya et al., 2020); 2) it cannot
sufficiently utilize semantic information of events.
2.2.2 Our Rel-CSKGC Method
To address these issues, we propose Rel-CSKGC,
as illustrated in Figure 3. Specifically, A is
first decomposed into independent triplets, and then
Rel-CSKGC predicts the relation given the head
event and the tail event of a triplet. Rel-CSKGC uti-
lizes no graph structure information thus avoiding
the problem caused by the sparsity. Additionally,
encoding both the head event and the tail event
with the pretrained language model successfully
takes advantage of semantic information.
Problem Formulation Given a CSKG G=
(N, V), where Nis the set of nodes and Vis the
set of edges, we consider a single training instance
as a triplet v= (h, r, t )with the head event h,
relation type rand the tail event t. Here, r∈V
andh, t∈N. The objective of Rel-CSKGC is to
predict the most reasonable rgiven handt.Main Structure We utilize RoBERTa (Liu et al.,
2019) to acquire contextual representations of free-
form texts describing events. The input is the con-
catenation of handt. We acquire the embedding
matrix of handtby:
[H;T] =RoBERTa ([h;t]) (1)
where H∈RandT∈R.|N|is the
number of tokens of the event, and Dis the dimen-
sionality of representation. We apply max pooling
onHandTto acquire sentence embeddings e
ande. The objective function can be defined with
trainable weights W∈RandW∈R:
o=sigmoid (We)+softmax (W(e, e))(2)
where Kis the number of relations and ethe
embedding of <s>-token used as a indicator for
whether handtare related.
Negative Sampling Rel-CSKGC requires nega-
tive samples to predict unlinkable links. We con-
sider the following two strategies to construct neg-
ative samples: 1) Random negative sampling. For
a gold triplet, we randomly select an event from
normalized A as the new tail event to re-
place the original tail event ; 2)Persona negative
sampling. Triplets under relations of “xPersona”
and“oPersona” follow the pattern of “Subject +
is + Adjective” and account for a large part in
A . Models tend to always predict “xPersona”
or“oPersona” when the given tail event follows
the pattern of “Subject + is + Adjective” . To allevi-
ate this problem, we specifically construct negative
samples by replacing the tail event of triplets under
relations of “xPersona” and“oPersona” with a
randomly-chosen event containing “is”.
2.3 Constructing Dense-A
Based on Rel-CSKGC, we train a relation predic-
tion model with existing triplets in A and
then use the model to complete missing links in
A . We adopt threshold-based link prediction
to decide whether two events are related and pro-
pose an intra-and-inter cluster completion strategy
to reduce the cost of completing entire A .
Threshold-based Link Prediction Threshold-
based link prediction (TLP) is a heuristic strategy
to decide whether a relation is acceptable accord-
ing to the probability predicted by Rel-CSKGC.
Different thresholds are specifically tuned for dif-
ferent relations. The model predicts the relation13295only if the final probability is above the correspond-
ing threshold. TLP is used in all our models as the
last step for the link acceptance decision.
Intra-and-inter Cluster Completion Strategy
Since it’s computationally expensive to iterate over
all pairs of head andtail event s during the infer-
ence, we design an intra-and-inter cluster comple-
tion strategy to trade off between the completion
scale and the time complexity. In Figure 1, we con-
sider each base event and its annotated tail events
as acluster .Intra-cluster completion infers miss-
ing links inside a cluster. Intuitively, annotated tail
events in one cluster, written based on the same
base event, are highly related and may contain
more missing links. Inter-cluster completion in-
fers missing links between different clusters. An-
notated tail events in different clusters are written
independently based on different base events, thus
links between different clusters are under-explored.
Due to the limited computing resource and time,
we temporarily provide the results of 100 sampled
clusters in this paper. Increasing the sampling size
can further improve the scale of Dense- A ,
but that will also linearly increases the computa-
tional cost. We will release versions with larger
sampling sizes later.
3Evaluation of Our Rel-CSKGC Method
In this section, we compare Rel-CSKGC with re-
lation prediction and translation based methods by
experimenting on a newly annotated subgraph and
human evaluation.
3.1 Training and Test Set Construction
Training Set with Negative Sampling Follow-
ing Sap et al. (2019)’s split of A , we ran-
domly sample negative triplets from the training
split with negative sampling strategies introduced
in Section 2.2. We combine sampled negative
triplets and the training split to construct the train-
ing set for Rel-CSKGC. The statistic of the training
set is illustrated in Table 1.Test Set with Annotated Subgraph To test
the performance of Rel-CSKGC, we construct a
ground-truth subgraph by randomly sampling three
clusters from the test split and annotating all pairs
ofhead event s and tail event s with the most rea-
sonable relation. The statistic of the annotated
ground-truth subgraph is shown in Table 2.
Relation Total Intra Inter
xAfter 243 186 57
xNeed 66 64 2
xIntent 72 51 21
xPersona 291 226 65
oAfter 262 174 88
oPersona 114 70 44
NoLink 4234 2303 1931
3.2 Compared Methods
We select 4 baselines comprising two different
types of CSKG completion methods and use the
specific evaluation protocol for each of them.
3.2.1 Relation Prediction Methods
Baselines We adapt CE-random (Li et al., 2016),
a method augmenting CSKGs by scoring novel tu-
ples, to predict the missing relation. We also com-
pare KG-BERT (Yao et al., 2019), which probes
the performance of relation prediction methods on
knowledge graphs. Note that we replace BERT (De-
vlin et al., 2019) with RoBERTa (Liu et al., 2019)
in KG-BERT for fair comparison.
Evaluation Protocal Ranking metrics (HITS and
Mean Reciprocal Rank) designed for translation
based methods are not applicable to relation pre-
diction methods. By valuing precision more than
recall on CSKG completion, we utilize precision
for the evaluation of relation prediction methods.
3.2.2 Translation Based Methods
Baselines SynLink (Malaviya et al., 2020) pro-
posed to densify the CSKG with synthetic links
for better graph representation. InductiveE (Wang
et al., 2021) introduced indutive learning on the
CSKG by enhancing the unseen event representa-
tions with neighboring structure information.
Evaluation Protocal To handle the evaluation
mismatch between Rel-CSKGC and translation13296based methods, we designed a transformation strat-
egy. Specifically, we randomly sample 500 triplets
from Malaviya et al. (2020)’s test split. For Syn-
Link and InductivE, a threshold is set for hit@1
score, and a tail event is accepted only when the
score is above the threshold. We tune the threshold
to ensure the number of triplets inferred by Rel-
CSKGC, SynLink, and InductivE close on these
500 triplets. We then calculate the proportion of
meaningful triplets for different methods manu-
ally.
3.3 Main Results
Relation Prediction Methods In Table 3, we
compare Rel-CSKGC with different relation pre-
diction methods, and Rel-CSKGC achieves consis-
tent improvement on the test set of the annotated
subgraph. Paired t-Test result proves that the im-
provement of Rel-CSKGC is significant. From
Table 3, we can observe that the precision of intra-
cluster completion is significantly higher than that
of inter-cluster completion for all methods. This
demonstrates that tail events annotated based on
the same base event are highly related to each other
and easier for models to predict relations, while the
prediction for inter-cluster events is more challeng-
ing.
Method Total Intra Inter
CE-random 0.45 0.53 0.29
KG-BERT 0.60 0.67 0.43
Rel-CSKGC 0.68 0.78 0.51
- w/o random 0.36 0.45 0.22
- w/o persona 0.58 0.66 0.44
Rel-CSKGC 0.80 0.91 0.62
Translation Based Methods After carefully tun-
ing the threshold based on the strategy in Sec-
tion 3.2.2, Rel-CSKGC, SynLink, and InductivE
predict 174, 133, and 132 triplets on 500 randomly
sampled triplets. In Table 4, Rel-CSKGC outper-
forms SynLink and InductivE by a large margin on
proportion and the number of meaningful triplets.
3.4 Human Evaluation
Motivation Upon observing predictions of Rel-
CSKGC, we note that some triplets could be reason-
able, while the annotated subgraph doesn’t cover
them. For example, given a head event “X ac-
cepts Y’s apology” and a tail event “X is generous”,
the annotated ground-truth relation is “xPersona”,
while Rel-CSKGC could predict another reason-
able relation “xIntent”. Consequently, we perform
the human evaluation to check whether a predicted
triplet is actually meaningful.
Result We can find from the last row of Table 3
that Rel-CSKGC achieves an even higher precision
of 0.80, suggesting that Rel-CSKGC can predict
reasonable triplets neglected during the subgraph
annotation. The high precision by human evalua-
tion also guarantees the quality of predicted triplets.
3.5 Ablation Study
To validate the effectiveness of negative sampling,
we report experimental results without negative
sampling in Table 3. The performance of Rel-
CSKGC drops dramatically without any negative
sampling strategies, validating the effectiveness of
negative sampling.
By experimenting Rel-CSKGC with different
scales of random negative samples in Figure 4, we
find that the precision of Rel-CSKGC increases
using both automatic and human evaluation as more
negative samples are used for training.132974 Evaluation of the Constructed
Dense-A
4.1 Knowledge Coverage and Quality
In this subsection, we aim to answer the follow-
ing question: Does Dense- A yield higher
knowledge coverage while ensuring the quality?
To this end, we statistically and manually com-
pare Dense- A with A from the fol-
lowing three perspectives.
Dense- A yields higher knowledge cov-
erage In Table 5, we present the comparison
between A and Dense- A . Dense-
A contains 3x more one-hop paths than
A , contributing a significantly higher knowl-
edge coverage. It’s worth noting that different tail
events in A could become the same after nor-
malizing tail events, so Dense- A contains
slightly fewer events than A .
Triplets in Dense- A have relatively high
precision In Table 3, Rel-CSKGC achieves a pre-
cision of 0.80 by human evaluation. Moreover,
from comparison results with translation based
methods in Table 4, Rel-CSKGC outperforms two
state-of-the-art methods by more than 7 percentage
points. The high performance of Rel-CSKGC en-
sures the quality of predicted triplets to a certain
extent.
Dense- A benefits the performance of
COMET To empirically demonstrate the knowl-
edge coverage and quality of Dense- A , we
evaluate Dense- A withCOMET (Bosselut
et al., 2019). The relation distribution of Dense-
A is long-tailed. We randomly sample
262,678 triplets from predicted triplets and recover
the grouped relations to their original relations by
following the relation distribution of the Sap et al.
(2019)’s training split. Apart from the evaluation
of perplexity, we design a strategy to evaluate the
diversity score of generated tail event s. For each
relation, we randomly sample 10 head events from
the test set. For each test sample consisting of a
head event and a relation, 10 candidates are gen-
erated using beam search. For each candidate, wePPL↓DS↑
COMET 11.14 9.16
COMET 11.11 10.77
COMET COMET
to study hard to study harder
study hard to study more
to study more to get a good grade
to study to take a test
to get a good grade to do well in school
to take a test to do well in class
to do well in school to apply for a job
to get a good job to pass the class
to apply for a job to get a prize
to apply for a good job to go to school
manually give a score of 0, 1, or 2, representing
“unreasonable”, “plausible”, and “reasonable”, re-
spectively. We then merge candidates of similar
semantics into a group and calculate the group av-
erage score. The diversity score of 10 candidates is
the sum of the group scores. Intuitively, the lower
perplexity and the higher diversity score indicate
the higher knowledge quality and the higher knowl-
edge coverage of Dense- A , andCOMET
outperforms COMET on both metrics in Table 6. In
Table 7, we can find that tail events generated by
COMETare more semantically different.
4.2 Multi-hop Paths in Dense-A
The aim of this subsection is to answer the ques-
tion: Can multi-hop paths in Dense- A better
present the commonsense knowledge?
Accordingly, we evaluate multi-hop paths based
on the human evaluation and performing a newly
designed Commonsense Reasoning experiment, re-
spectively:
Sampling Method 2-hop 3-hop 4-hop
Random 0.69 0.62 0.50
Heuristic Rule 0.84 0.77 0.7413298
Human evaluation confirms the correctness of
multi-hop paths in Dense- A In Table 5,
we have already shown that Dense- A con-
tains orders of magnitude more two-hop and three-
hop paths than A . Now, to further validate
the correctness of multi-hop paths, we perform the
human evaluation on sampled paths to calculate
the proportion of reasonable paths. Note that it’s
a common phenomenon (both KGs and CSKGs)
thatA→BandB→Care reasonable, while A
→B→Cis irrational. For example, { Beethoven ,
owner ,piano } and { piano ,color ,black } are two
reasonable triplets, but “ Beethoven ” and “ black ”
are not related. Consequently, we additionally de-
sign a simple heuristic sampling rule: a multi-hop
path A→. . .→Cis chosen only when A and C
are also linked in Dense- A . By comparing
with random sampling in Table 8, we can find that
heuristic rule sampling consistently outperforms
random sampling: the longer the multi-hop paths,
the more significant the improvement. Multi-hop
paths randomly sampled from Dense- A with
two different methods are illustrated in Table 9.
Dense- A has the potential of providing
contextual information for Commonsense Rea-
soning In order to further validate the effective-
ness of multi-hop paths in Dense- A , we uti-
lize BART (Lewis et al., 2020) to perform gen-
erative Commonsense Reasoning with or without
multi-hop paths. Specifically, with the heuristic
rule above, we randomly sample 5000 four-hop
paths from Dense- A as the training sam-
ples. For test samples, we manually select 500
reasonable paths from Dense- A . BART is
trained to generate the subsequent event in two
different settings: 1) given only the first node of
the path; 2) given the first four nodes of the path.From Table 10, we can find that BART trained with
multi-hop paths achieves better performance in that
multi-hop paths could provide more contextual in-
formation useful for Commonsense Reasoning.
Bleu-1 Bleu-2 ROUGE-L
One-hop 48.57 14.24 35.58
Multi-hop 48.63 14.93 36.90
5 Related Work
ConceptNet (Speer et al., 2017) is a large-
scale CSKG merging various knowledge bases.
ASER (Zhang et al., 2020b) contains the selectional
preference knowledge extracted from more than
11 billion-token unstructured textual data. Tran-
sOMCS (Zhang et al., 2020a) utilizes linguistic
graphs to convert ASER into the same representa-
tion as ConceptNet. DISCOS (Fang et al., 2021b)
aggregates the neighboring information to distill
the commonsense knowledge in ASER.
Recent years have seen crowdsourced CSKGs
aiming to provide high-quality commonsense
knowledge triplets. Sap et al. (2019) released
A consisting of if-then knowledge triplets
mainly about daily events. Hwang et al. (2021) aug-
mented A with event-centered and physical-
entity triplets. GLUCOSE (Mostafazadeh et al.,
2020) grounds the implicit commonsense knowl-
edge about everyday situations in a narrative con-
text for richer inferential content.
Dense- A unleashes the power of A
for high knowledge coverage and multi-hop paths.
Prior CSKG completion methods performed bi-
nary classification by scoring BiLSTM-encoded tu-
ples (Li et al., 2016; Saito et al., 2018; Jastrz˛ ebski13299et al., 2018). Following translation based meth-
ods for the knowledge graph completion (Dettmers
et al., 2018; Shang et al., 2019; Meilicke et al.,
2019; Qu et al., 2021; Zhang et al., 2021; Lovelace
et al., 2021), Malaviya et al. (2020) additionally
densified the CSKG based on BERT similarity and
achieve promising results. Wang et al. (2021) and
Ju et al. (2022) designed heuristic rules to add more
edges for nodes with fewer neighbors. Moghimifar
et al. (2021) presented a neural-symbolic reasoner
to learn logic rules during the training, making the
CSKG completion process interpretable.
Rel-CSKGC differs from them in that we utilize
pretrained language models to predict the relation
given the head event and the tail event . Similar
relation prediction methods targeting at the knowl-
edge graph completion have been proposed (Socher
et al., 2013; Yao et al., 2019; Cao et al., 2020). To
our best knowledge, we are the first to explore the
relation prediction method on CSKG completion.
6 Conclusion
In this paper, we construct Dense- A for
high knowledge coverage and massive multi-hop
paths and accordingly propose a CSKG comple-
tion method called Rel-CSKGC to train a relation
prediction model and infer the missing links in
A . Both automatic and human evaluation
show the advantage of Rel-CSKGC over strong
baselines. The statistics prove that Dense- A
has significantly more triplets and multi-hop paths,
providing potential for high-quality downstream ap-
plications and multi-hop reasoning based on com-
monsense knowledge.
Limitations
Our approach for constructing Dense- A still
has two limitations: 1) to keep Dense- A
simple, we only consider the most reasonable rela-
tion in this paper, while the relation between two
events can be complex and diversified. We will
release versions of Dense- A with diversified
relations later; 2) due to page limitation, we only
evaluate Dense- A on simple commonsense
reasoning tasks, and we will further validate the
multi-hop reasoning capacity of Dense- A
on more complex downstream tasks in the future.
Ethics Statement
We would like to thank the Allen Institute for AI
for their valuable work on A . The Ais licensed under a license of CC BY , which al-
lows remixing, transforming, and building upon the
material for any purpose. We will also make our
Dense- A publicly available later. Mehrabi
et al. (2021) have found representational harms in
common sense resources. We acknowledge that the
generated commonsense from our models might
contain biases. All of the datasets and models are
in English, which benefits English speakers more.
We have employed 3 postgraduates experienced
in natural language processing for annotation and
human evaluation. We pay postgraduates around
$8 per hour, well above the local average wage,
and engage in constructive discussions if they have
concerns about the process.
Acknowledgments
This work was supported by the Natural Science
Foundation of China (No. 62076133), and the Nat-
ural Science Foundation of Jiangsu Province for
Distinguished Young Scholars (No. BK20200018).
References133001330113302A Algorithm for Normalizing Tail Events
Algorithm 1 presents the pseudo-code of Normal-
izing Tail Events in Section 2.1.
Algorithm 1 Normalizing Tail Events
Input: A set of annotations Aand relations R
Output: A set of sentences in present tense
FARemove annotations with underscores or none,
and get a series of filtered annotations FAforeachfa∈FA,r∈Rdo Obtain the dependency tree depand POS
tagging result posoffa Findsubnode with POS prpand edge subj
connected directly to it ifPosition of subis at the start of fathen Remove subinfa end if Find node verb with POS vbinfa ifr∈[xIntent, xWant, xNeed, oWant ]
AND the first word of faistothen Remove the first tooffa end if Transform node verb infato its root form Append suf∈[−s,−es,−ies, ... ]toverb
based on English grammar ifr∈[xAttr, xReact ]then Insert PersonX is to the start of fa else if risoReact then Insert PersonY is to the start of fa else if r∈[oWant, oEffect ]then Insert PersonY to the start of fa else Insert PersonX to the start of fa end ifend forReturn FA
B Implementation Details
Rel-CSKGC We use RoBERTa-large containing
335M parameters as the base model. We use a
maximum sequence length of 100 and batch size of
128. The Adam optimizer is used for optimization
with a learning rate of 2e-5 for RoBERTa-large and
a learning rate of 1e-4 for MLP layers. The warmup
proportion is set to 0.1. We train Rel-CSKGC with
1 NVIDIA RTX 3090 Graphical Card for 5 epochs,
and it takes 20 hours to finish the training.COMET To train COMET, we use the im-
plentations provided here.We use the learning
rate of 1.625e-5 and the default values for other
parameters.
Generative Commonsense Reasoning BART-
base is employed as the base model, which contains
140M parameters. We use a batch size of 128 and
use the default values for other parameters.13303ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
In Limitations section.
/squareA2. Did you discuss any potential risks of your work?
Not applicable. Left blank.
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
In Abstract section and section 1, respectively.
/squareA4. Have you used AI writing assistants when working on this paper?
Left blank.
B/squareDid you use or create scientiﬁc artifacts?
In section 2, Appendix B.
/squareB1. Did you cite the creators of artifacts you used?
In section 2.1, Appendix B.
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
In Ethics Statement section.
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
In Ethics Statement section.
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
We use publically available datasets, and the authors of the dataset have made the corresponding
declaration.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
The documentation of the artifacts will be released after the reviewing process.
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
In Section 3 and 4.
C/squareDid you run computational experiments?
In Section 3 and 4.
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
In Appendix B.13304/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
In Appendix B.
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
In Section 3.
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
In Appendix B.
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
In Section 3 and 4.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
We perform simple human annotation and evaluation, there is no need of providing the full text.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
In Ethics Statement.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
Not applicable. Left blank.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
Not applicable. Left blank.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
In Ethics Statement.13305