
Jacob Bremerman Xiang Ren Jonathan May
University of Southern California
Information Sciences Institute
{jbrem,xiangren,jonmay}@usc.edu
Abstract
Current Machine Translation (MT) models still
struggle with more challenging input, such as
noisy data and tail-end words and phrases. Sev-
eral works have addressed this robustness issue
by identifying specific categories of noise and
variation then tuning models to perform bet-
ter on them. An important yet under-studied
category involves minor variations in nuance
(non-typos) that preserve meaning w.r.t. the
target language. We introduce and formal-
ize this category as Natural Asemantic Vari-
ation (NA V) and investigate it in the context
of MT robustness. We find that existing MT
models fail when presented with NA V data,
but we demonstrate strategies to improve per-
formance on NA V by fine-tuning them with
human-generated variations. We also show that
NA V robustness can be transferred across lan-
guages and find that synthetic perturbations can
achieve some but not all of the benefits of or-
ganic NA V data.
1 Introduction
While current Machine Translation (MT) models
often perform decently in regular conditions, ro-
bustness to slight modifications on input remains a
challenge. Several works have investigated the dev-
astating effects that minor noise can cause in MT
(Belinkov and Bisk, 2018; Khayrallah and Koehn,
2018). Addressing this is critical as robustness
to naturally occurring variation is important in de-
ployed systems.
Some classes of perturbations to which humans
exhibit robustness but studies have shown MT
models struggle with include speling errors or
rtypos, CaSinG (Niu et al., 2020), v15sua11y-
51m1ll4r ch4r4ct3r5 (Eger et al., 2019), and syn-
onym replacement substitution (Wang et al., 2018).
However, we focus on a less-known class we call
Natural Asemantic Variation (NA V).
Table 1:
Whereas aforementioned classes tend towards
perturbations that generate agrammatical, nonstan-
dard, or unnatural sentences, NA V perturbations
represent the extra-semantic linguistic properties of
a language that allow for subtle changes in nuance
while expressing the same core meaning. Specifi-
cally, a NA V perturbation is a kind of paraphrase
in a source language that would not affect its trans-
lation in a given target language. Studying NA V
is an important endeavor in MT robustness since
it covers a less-contrived source of variation com-
pared to existing MT robustness studies. As this
topic is under-studied, it has also not been well-
defined. We offer an example of NA V perturbations
in Japanese in Table 1 and will provide further def-
initions and examples throughout the paper to help
solidify the reader’s understanding.
From Table 1, we see how slight modifications of
a sentence in one language can convey specific nu-
anced differences in that language, without warrant-
ing a change to its translation in another language.
A common challenge in MT has to do with the fact
that there are almost always several correct answers,
and we can imagine translationally-equivalent map-
pings between large sets of similar sentences in
different languages. Often we must resort to im-
perfect training and evaluating using subsets of
these imagined sets due to normal data limitations.
However, leveraging the STAPLE dataset (Mayhew3517et al., 2020), we have a unique opportunity to inves-
tigate NA V phenomena more directly with access
to several (often hundreds) of high-quality NA V
perturbations. These perturbations allow us to test
for NA V robustness, evaluating model behavior on
challenging NA V test sentences.
In this paper, we contribute a formal defini-
tion for a linguistically-rich class of perturbations
(NA V) and provide examples which help ground
the concept (§2.1). We also contribute an evalua-
tion setup to measure NA V robustness in the form
of a repurposed test set from STAPLE and simple
metrics to evaluate quality and consistency of MT
models (§2.2). This formalization and metrics al-
low us to investigate specific research questions
regarding NA V , as summarized below.
We evaluate existing MT models for NA V robust-
ness and characterize the observed errors related
to underspecification resolution and rarer expres-
sions (§4.1). We show improvements in BLEU and
our NA V-robustness metrics by exposing the model
to NA V data and comparing various sub-selection
and fine-tuning strategies (§4.2). We even find that
these improvements can be transferred across lan-
guages, improving NA V robustness in languages
that have not seen any NA V data (§4.3). We also de-
sign and perform synthetic perturbations, as these
may provide a cheaper, more scalable way to im-
prove NA V robustness without human annotations.
We do achieve improvements though organic data
is still more useful than synthetic (§4.4). Finally,
we analyze our NA V-robust models in other evalua-
tion settings with data that is out-of-domain and/or
showing different classes of noise to investigate the
side-effects of our methods (§4.5).
2 NA V Robustness
In robustness of NLP, it is difficult to determine im-
provements without considering both what types of
input models are meant to be robust toand what ro-
bustness looks like . In this section, we will first dis-
cuss NA V with a formal definition and explanatory
examples. Then we will define NA V robustness in
terms of desired behaviors and present metrics as
proxies for measuring NA V robustness.
2.1 NA V Perturbations
To formally define natural asemantic variation ,
we consider a corpus Cin two languages X,Y
that contain cpaired clusters of translationally-
equivalent natural and grammatical sentences:
C={(X, Y)} ∀i∈ {1, ..., c};
X={x, ..., x};Y={y, ..., y};
∀j∈ {1, ..., n},∀k∈ {1, ..., m}, x⇔y,
where ⇔represents translational equivalence ,
meaning the two sentences xandy, which are
in clusters XandY, respectively, can be reason-
ably translated to each other. For example, all the
Japanese examples in Table 1 are translationally
equivalent with she returned the book to me in
English. Another valid ycould be she gave the
book back to me . All x∈Xcan then be consid-
ered NA Vperturbations of each other. A NA V
perturbation must be considered in context of the
language pair. xandxmay be NA Vperturba-
tions of each other but not NA Vperturbations.
In this work, we further limit the corpus to be:
∀i|X|>1,|Y|= 1,
meaning only one reference translation is provided.
This choice is due to data limitations as we only
have access to semantically-equivalent variations
on the source side. (if |X|= 1as well, then Chas
the form of most standard MT datasets).
To ground these definitions, Figure 1 offers spe-
cific examples to distinguish NA V perturbations3518from non-NA V perturbations. The modifications in
examples 1 and 2 are either nonstandard or have
too large of an impact on semantics such that their
translations are different. Example 3 shows a sim-
ple example of a NA V perturbation while example
4 demonstrates the language dependence of NA V
by using the same perturbation from 3, highlight-
ing the complexity of this problem. For a different
target language, the two sentences would no longer
exist in the same X.
2.2 NA V Robustness
In order to evaluate models for their robustness
to NA V perturbations, we consider two desiderata,
quality andconsistency , which we evaluate sepa-
rately. There are often several high-quality answer
options in MT, so two models could both produce
high-quality translations but differ greatly in their
consistency (how similar their hypotheses among
minimally-altered, translationally-equivalent in-
puts are). For our purposes, we posit that a more
NA V-robust MT model should not only have in-
creased or maintained translation quality but also
consistency in output when given different NA V
perturbations as input. Consistency in output would
help ensure overall system robustness if we imagine
the MT system being part of a larger NLP pipeline.
In this work, for translation quality, we use
BLEU (Papineni et al., 2002) with SacreBLEU
(Post, 2018). For translation consistency we define
a metric, CONSIST, which rewards a translation
model ffor exhibiting less variation in its out-
putsˆY=f(X)among NA V-perturbed inputs
X. Specifically, for a pair (X,ˆY), CONSIST
is calculated as follows:
CONSIST≜1
|X|/summationdisplay|ˆy|
j,
where ˆY≜{ˆy:∃x∈X∧θ(x) = ˆy},|ˆy|≜
|{x:x∈X∧θ(x) = ˆy}|, and we order ˆYas
[ˆy, ...,ˆy], sorted descending by |ˆy|. Intuitively,
|ˆy|is the number of x∈Xfor which θ(x)
outputs hypothesis ˆy. We then average this score
across all translation cluster-pairs in the corpus:
CONSIST≜1
c/summationdisplayCONSIST.We drop the superscript when unambiguous. This
metric may break down in long-output tasks but
works well for our domain of short, simple sen-
tences. Essentially, this metric works by punish-
ing the model more and more for novel translation
outputs on translationally-equivalent inputs. An
explanatory example calculation is available in Ap-
pendix §A.1. We also discuss an alternative consis-
tency metric with trade-offs in Appendix §A.2.
3 Analysis Setup
In this work, we seek to provide answers to several
analysis questions related to NA V perturbations
and MT models’ robustness to them. Using our
quality and consistency metrics we investigate the
following:
•Are existing MT models robust to NA V? if not,
what types of errors are the models making?
•How can NA V perturbation data be used to
improve an MT model’s NA V robustness?
•Can a model’s improved NA V robustness in
one language pair be transferred to another
language pair?
•How do synthetic perturbations compare to
organic NA V data w.r.t. NA V robustness?
•What behavior changes does a ‘NA V-
robustified’ MT model exhibit in other MT
contexts such as out of domain data or on
other types of robustness tests?
3.1 Baseline Models
We work with two main classes of baseline models:
mono-pair (can translate one specific language to
one specific other language, e.g. ja-en) and multi-
pair translation models (can translate between sev-
eral languages, e.g. {hu,ja,pt}-{hu,ja,pt}). All
models are transformer models (Vaswani et al.,
2017) using the fairseq toolkit (Ott et al., 2019).
Our principal models are multi-pair since many of
our analysis questions relate to language transfer,
but we also perform preliminary experiments with
mono-pair models for completeness.
We pre-train mono-pair models with the Tatoeba
corpus for {hu,ja,pt}-en. This corpus is fairly close
to the STAPLE domain and allows for reasonable
baseline models. We obtain subwords and tokenize
using SentencePiece (Kudo and Richardson, 2018).3519
Hyperparameters are the default settings for the
transformer architecture in fairseq.
For multi-pair model experiments, we use
the M2M-100 model (Fan et al., 2021), which
is trained on CC-Matrix (Schwenk et al.,
2021) and CC-Aligned (El-Kishky et al.,
2020). This model comes with a predeter-
mined vocabulary and tokenizer. It uses the
transformer_wmt_en_de_big architecture
in fairseq with 24 encoder and 24 decoder layers.
The checkpoints available online are used as
initialization for further fine-tuning using different
NA V data, as described next..
3.2 NA V Data
This research is made possible largely by the
unique dataset publicly released by Duolingo for
the STAPLE shared task (Mayhew et al., 2020).
For each English sentence, several (average 300)
accepted translations of that sentence in one of five
languages were sourced from Duolingo users and
further annotated with frequency scores based on
how often they used that specific translation. We
use the enumerated valid translations as source-side
NA V perturbations translating to the same target
English sentence. A diagram representing the data
can be seen in Figure 2. Table 1 includes a real ex-
ample from the training split for Japanese-English.
For NA V fine-tuning (§4.1), we use different
subsets of the STAPLE training corpus in three
language pairs {hu,ja,pt}-en. For each “many-to-
one” pair, we either use allof the many NA V per-
turbations or subselect. When subselecting, we
consider three strategies. Since we also have fre-
quency scores for each perturbation, we could se-
lect a number of the most frequent perturbations,
least frequent perturbations, or uniformly samplelang train dev test
hu 250k/4k 28k/500 34k/500
ja 860k/2.5k 170k/500 170k/500
pt 530k/4k 60k/500 68k/500
ko -/- -/- 150k/500
vi -/- -/- 28k/500
for a random subset. In our paper, a subset is de-
fined by a number and a strategy, so “10-random”
means 10 random NA V perturbations were chosen
for each example.
For NA V robustness evaluation, we use the full
(all NA V perturbations included) many-to-1 pairs
of the STAPLE test split. On top of the {hu,ja,pt}-
en sets, we hold out {ko,vi}-en test sets to evaluate
0-shot language transfer using multi-pair models
(§4.2). Data statistics are shown in Table 2.
3.3 Synthetic Data Augmentation
Obtaining NA V perturbations is expensive, requir-
ing human annotation by bilingual language ex-
perts to generate natural variations that don’t affect
translation equivalence. We consider applying syn-
thetic perturbations to some of the STAPLE data
to compare potential NA V robustness gains with a
cheaper, more scalable strategy.
With the organic, human-generated variations in
the STAPLE data, we create a synthetic dataset by
taking the 1-most frequent source sentence from
each translation pair and perturbing it synthetically
9 times for a total of 10 variations (while the 10
copies of the target sentence are left unchanged).
For our roman script languages {hu,pt}-en, we
use known noising techniques of random casing
changes and character substitutions, insertions and
deletions as in Niu et al. (2020). These perturba-
tions are not NA V perturbations, but they represent
a common and easy way to add noisy data.
We also add synthetic NA V perturbations for the
ja-en split. Roman script noising strategies are not
perfectly translatable to ja-en. Also, ja-en arguably
has the easiest rule-based modifications that can be
programmed to automatically generate NA V pertur-
bations. By no means are these methods exhaustive,
but a combination of simple insertions of emphasis-
related particles, substitutions of pronouns based
on gender identity, and dropping unnecessary pro-
nouns serve as a basic technique for synthetic NA V
noising. Rules were implemented after scanning3520training data and observing patterns of NA V pertur-
bation.
3.4 Additional Evaluations
We use other existing MT datasets to evaluate our
models in contexts such as performance on out-of-
domain (OOD) data (§B.1) and robustness-transfer
to other types of noisy input (§B.2). We use test
splits from Tatoeba, OPUS-100 (Zhang et al., 2020)
and MTNT (Michel and Neubig, 2018).
We also create additional evaluation sets from
the STAPLE data to analyze in-domain model be-
havior. In addition to the ‘all perturbations’ test
sets, we also filter out ‘1-most’ and ‘1-least’ test
sets. These provide a more standard MT eval-
uation framework that relies on BLEU to mea-
sure in-domain translation performance on com-
mon (‘1-most’) and robustness to uncommon, NA V-
perturbed (‘1-least’) sentence pairs.
4 Experiments and Results
For our experiments and results section, we will
progress chronologically as we address each of our
analysis questions as defined in Section 3.
4.1 Existing MT NA V Behavior
Before we perform comprehensive experiments to
analyze NA V robustness, we investigate how ex-
isting MT models perform on NA V perturbations.
This way we can establish 1) if this even is a prob-
lem in MT and 2) if so, what types of errors are we
aiming to address? We simply take our baseline
models (§3.1) and search for error patterns pro-
duced from example inputs in the STAPLE dataset.
One pattern of errors involves an inability to
properly resolve cases of under-specification. For
example, the M2M-100 model properly handles “
それはトマトの種類です。”, outputting “This
is a type of tomato.” However, a NA V-perturbed
input, “トマトの種類です。” causes the model
to output ‘Species of tomatoes.’ since this sentence
drops the subject, common in Japanese.
Another pattern of errors involves an inability
to handle less common synonyms or paraphrases
for the same target word(s). ‘Please’ is the main
way to express politeness in a request in English
but other languages have multiple common ways to
express this. The M2M-model properly translates
the Portuguese sentence “por favor , não a desperteagora.” as “Please don’t wake her up now.” but
mistakenly translates “por obséquio , não a desperte
agora.” as “For obsession, don’t wake her up now.”.
In just a small sample of examples, we find sev-
eral instances of these types of errors, confirming
our intuition that existing MT models cannot han-
dle NA V perturbations completely. We are also able
to see that these types of mistakes will be captured
by our BLEU and CONSIST metrics, motivating
our quantitative experiments. More information on
this error analysis is available in Appendix §A.6.
4.2 Improving NA V Robustness with NA V
Data
For our first experiments, we fine-tune our mono-
pair transformer models pre-trained on Tatoeba us-
ing strategies for subselecting STAPLE data dis-
cussed in Section 3.2 and evaluate using metrics
from Section 2.2. After initially experimenting
with several combinations of number of perturba-
tions per set pair and selection strategy,we report
on 4 conditions, representative of common “real-
world” MT scenarios:
baseline: off-the-shelf MT model, no fine-
tuning (§3.1)
+ 1-most: simple domain adaptation using paral-
lel text in target domain (one “typical” translation
per sentence).
+ 10-random: preferred “NA V robustness” data
condition, having a small yet diverse set of NA V
perturbations per translation pair
+ all: “throw in all the data” approach
Our results from these experiments are shown in
Figure 3. The main purpose of these preliminary
experiments is to provide evidence that NA V ro-
bustness improvement is possible on smaller scale
models. We test various configurations to justify
design choices for our future, more comprehensive
experiments with large multi-pair models. We find
that the ‘+ 10-random’ condition results in the best
trade-off of BLEU and CONSIST.
We repeat these experiments using a large multi-
pair model. We find similar patterns in the results,
confirming “10-random” as a decent strategy for
improving NA V robustness. Here, the baseline is
the M2M-100 model and models are fine-tuned3521
and evaluated on only the same language pair.As
the patterns are similar, results are plotted in the
Appendix A.5.
4.3 Transfering NA V Robustness across
Languages
With a large multi-pair model, we can consider
zero-shot language-transfer of NA V robustness.
First, we take the M2M-100 baseline models and
fine-tune them on one of the STAPLE fine-tuning
language-pairs. We then evaluate on our held-out
language test sets (unseen pairs during fine-tuning,
{ko,vi}-en). Our results are shown in Figure 4.
From previous experiments, we see sufficient evi-
dence that “ + 10 random ” is appropriate for NA V
robustifying, so we mainly report on this setting.
Results suggest zero-shot transfer of NA V ro-
bustness is possible, with 10-random NA V pertur-
bations per pair showing larger robustness improve-
ment than simply fine-tuning on 1-most. We also
observe language differences. ko-en BLEU im-
proves more from ja-en fine-tuning while vi-en
improves more from hu-en.
Finally, we perform multilingual fine-tuning ex-
periments in which we combine all three training
sets together {hu,ja,pt}-en with the ‘+ 10 random’
strategy and evaluate on all 5 test sets. We compare
the multilingual fine-tuning results to the previous
best results (according to BLEU) from our mono-
lingual fine-tuning experiments. Results are shown
in Figure 5. We see that using all 3 test sets for
NA V fine-tuning is consistently a better option over
any given single set.
4.4 Approaching NA V Robustness with
Synthetic Data Augmentation
We repeat experiments from the previous section
using our synthetic fine-tuning sets (Section 3.3)
and compare to the organic 10-random sets. We
also combine all the synthetic sets {hu,ja,pt}-en for
multilingual fine-tuning and evaluate on our NA V
robustness evaluation sets. Results are shown in
Figure 6.
Our synthetic fine-tuning sets do improve robust-
ness compared to a baseline model, but they are
far from achieving the same improvements as the
organically generated data. We also see how our
NA V-oriented synthetic data (ja-en) more closely3522
approximates organic NA V data gains compared to
our non-NA V synthetic data ({hu,pt}-en).
We also test synthetic fine-tuning performance in
zero-shot language transfer. Results are shown in
Figure 7. We continue to see that synthetic data is
not able to provide the same NA V robustness gains
as organically-generated data. However, in zero-
shot language transfer, multilingual synthetic data
more closely approaches organic-data performance
than it can with in-language fine-tuning. This sug-
gests in-language organic NA V data is most useful
even if some NA V robustness can be improved with
transfer.
4.5 Additional Evaluations
Results from the previous sections suggest that
NA V robustness can be effectively learned (even
in zero-shot scenarios) by exposing models to a
variety of several NA V perturbations per transla-
tion example. However, these findings raise new
questions about what specifically the models arelearning, how transferable that learning is and how
else the model’s behavior changes.
We perform several analysis experiments in
which we take our best models from previous ex-
periments, which we designate as our ‘NA V-robust’
models and evaluate them compared to baseline
MT models in other evaluation settings. These
new test settings include OOD data (§B.1), other
classes of noise (§B.2) and more frequent (less
NA V-relevant) in-domain data (§B.3).
The overall takeaway from these experiments
is that our NA V-robust models sacrifice some per-
formance in non-NA V-relevant settings. This is
not uncommon in general NLP fine-tuning, as of-
ten models fine-tuned for a new task, domain, etc.
often underperforms in the original setting (Thomp-
son et al., 2019; He et al., 2021).
These experiments serve primarily to confirm
that there are limitations and drawbacks to im-
proving NA V robustness with our current proposed
methods. We include specifics in the Appendix to
distill the main work for novel contributions. These
results suggest avenues for future work to avoid
these trade-offs for robustness, which remains a
problem in the wider NLP community.
One set of results we communicate here is per-
formance on in-domain ‘1-most’ and ‘1-least’ test
data. These test settings are useful because they
allow us to directly compare models on similar text
examples that differ in frequency of use, thus distin-
guishing between ‘normal’ sentences and heavily-
NA V-perturbed sentences. The latter evaluation
serves as another proxy for robustness.
In most of our NA V experiments from earlier
sections, ‘+ 10 random’ consistently performs bet-
ter than ‘+ 1 most’. This is reflected in the ‘1-least’
evaluation as well. However, in the ‘1-most’ evalu-
ation, ‘+ 1 most’ outperforms ‘+ 10 random’. What
this shows is that evaluating on frequent, non-noisy
data may select for models that actually perform
worse on data of the same domain but with less
frequent NA V forms. These results can be seen
for ja-en in Figure 8 and full results (which mirror
those shown here) are shown in §B.3.
5 Discussion
Overall our work raises several questions about
NA V phenomena and how to address them in MT.
We are able to provide some answers to a few
research questions and open pathways for future
work. NA V describes a subtle yet substantial mark3523
of language that stands as an appropriate target for
current NLP research.
Addressing NA V in a systematic way is an in-
credible challenge due to the vastness of possible
variation. The STAPLE dataset provides a suitable
way to begin investigating solutions to NA V-related
problems in MT. We are able to show how NA V
robustness can be improved using STAPLE data
and how those improvements can transfer across
languages. There seems to be language dependence
whereby robustness learned in one language can
have varying effects depending on the language
transferred to.
We find that NA V-robust models can perform
worse in non-NA V settings, which does not differ
from several other findings in robustness work in
which a more robust model may not perform bet-
ter on original, non-noised input. We also address
scaling issues by synthetically generating NA V and
non-NA V examples. The synthetic NA V examples
seem to help more than the non-NA V examples, butnone of them are able to obtain the same improve-
ments as human-created NA V data.
The major results from all of our experiments are
displayed in Table 3 for side-by-side comparison.
6 Related Work
Paraphrasing Paraphrasing has been shown to
be beneficial in MT contexts. Hu et al. (2019)
have done work in releasing and using paraphrase
data. Khayrallah et al. (2020) use generated para-
phrases as data augmentation for MT. One thing
that differentiates our work is the formal definition
of NA V . It can be difficult to clarify what is or is not
a paraphrase, and this work attempts to formalize a
specific kind of paraphrase.
MT Robustness Several works investigate ro-
bustness in MT by considering different classes of
perturbations and developing strategies to improve
performance at test time. Niu et al. (2020) per-
form misspelling- and casing-related perturbations
on MT test input and evaluate different models on
their robustness to these. Salesky et al. (2021) ad-
dress several classes of perturbations by replacing
a standard unicode-based encoder with a visual
encoder, which demonstrates higher robustness to
perturbations associated with visual appearance of
language, such as 1337speak. Zhang et al. (2020)
generate additional clean and noisy data using back-
translation and different datasets to improve perfor-
mance on noisy text. We add to this line of work
by addressing a specific kind of robustness (NA V).
Data Augmentation There has also been sub-
stantial work in using synthetic data to improve
MT more generally. Sennrich et al. (2016) use
back translation to augment MT datasets, which
improves performance. Wang et al. (2018) augment
data by reusing sentences with synonyms replaced.
Karpukhin et al. (2019) and Berard et al. (2019)
improve robustness by adding synthetic noise. Our
work is unique in our attempts to augment data
using developed rules based on asemantic under-
specification in language.
7 Conclusion
We present the reader with an under-studied subject
in MT and contribute more formalized definitions3524and simple evaluation metrics for the phenomenon
of natural asemantic variation. We also perform
experiments, showing how NA V perturbations can
be used during fine-tuning to improve robustness
of MT models, even when evaluating on a differ-
ent language-pair. Several questions remain to be
explored to further formalize NA V , investigate its
role in NLP modeling and improve techniques to
increase nuanced understanding.
8 Limitations
Several of the limitations of this work are discussed
throughout the paper and in the Appendix. To sum-
marize, the metrics used to evaluate NA V robust-
ness may not work as well in other domains such
as data with longer sentences. However, the intro-
duced formalism of NA V is relevant to any domain.
A limitation to mention about the formalism is
that it likely does not perfectly distinguish NA V and
non-NA V sentences. Just as translators can argue
about translation decisions, there are arguments for
why or why not certain sentences should be con-
sidered ‘translationally-equivalent’. ‘Asemantic’ is
also a term that has gray areas. Nonetheless, the
formalism allows us to establish metrics and a foun-
dation for analysis for this very real phenomenon.
Our methods are also limited since they rely on
access to unique high-quality data. We address this
with language-transfer and synthetic perturbations,
but we are unable to obtain the same benefits as
human-generated in-language data.
Other limitations include language coverage. We
work with 6 languages, which offers more support
for generalization than only one language pair but
still could raise some doubts about applicability to
all languages.
There are also equipment limitations to consider.
Most of our experiments use the M2M-100 model
as a baseline, which required our experiments to
be run on RTX 6000 GPUs. We do run some of
the experiments on smaller baseline models which
fit on older RTX 2800 machines and see similar
results.
Acknowledgments
This material is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Agreement No. HR00112290056.
Xiang Ren’s research is supported in part by
the Office of the Director of National Intelli-
gence (ODNI), Intelligence Advanced ResearchProjects Activity (IARPA), via Contract No. 2019-
19051600007 and NSF IIS 2048211.
References352535263527A Appendix
A.1 CONSIST Metric Example
Say, as an example, we have 1000 NA V perturba-
tions of the same source sentence. The model will
then have 1000 output sentences, many of which
will (hopefully) be the same. We can then create
groups of identical translation outputs and rank
them by size from largest to smallest. In our exam-
ple, the model outputs 3 different translations, one
750 times, one 200 times, and one 50 times. We
define CONSIST as:
CONSIST =1
n/summationdisplay|G|
i
where iis the rank of the group, nis the number
of total input-output example pairs and |G|is the
ratio of the size of the ith largest group to n. In
our example, CONSIST =(++).
In this way, models are rewarded for producing a
small number of groups with large sizes, suggesting
higher consistency.
A.2 Pair-Wise BLEU
The CONSIST metric we propose has several
strengths. It ensures very fine-grained similarity,
which would benefit NLP systems in which MT
is part of a larger pipeline. In such a case, tiny
variations could cause large down-stream errors.
CONSIST is also quick to compute since it does
not require comparing each hypothesis with each
other one separately. However, we concede that
CONSIST may not be best in all settings, especially
for domains with longer sentences.
To address this weakness, we also calculate
a pairwise-BLEU-based score in which we com-
pute average sentence BLEU between all pairs of
hypotheses for a prompt and average across all
prompts. Specifically, for a pair (X,ˆY):
PWB≜1
n/summationdisplay/summationdisplaysBLEU (ˆy,ˆy),
n=(|X|)(|X| −1)
2
Thus a model’s final PWB score is:
PWB≜1
|C|/summationdisplayPWB.CONSIST PWB
m2m 54.7 58.3
+ 1 most 47.3 53
+ 10 random 72.3 73.2
+ all 77.6 78.3
This metric is like Minimum Bayes Risk (Freitag
et al., 2022) and like that metric, takes significantly
longer than CONSIST to compute. It mitigates
some of the negatives of CONSIST since it works
for long sentences and allows for less-strict similar-
ity evaluation.
We observe the same consistency patterns from
our models using this pairwise score as the patterns
drawn from CONSIST shown in Table 4.
The similarity in consistency scores between
these two metrics motivates our usage for the
quicker of the two, CONSIST.
A.3 Synthetic Perturbation
A.3.1 Latin Script Perturbations (hu, pt)
For the Latin-script perturbations, each word (de-
termined by white space) has a uniform random-
chance of one of the following perturbations:
• No change
• Casing e.g. ‘apple’ →‘Apple’
• Insertion e.g. ‘apple’ →‘appqle’
• Deletion e.g. ‘apple’ →‘aple’
• Subsitution e.g. ‘apple’ →‘apqle’
A.3.2 Japanese Script NA V Perturbation
For the Japanese-script perturbations, we use rules
(which also have uniform chance of being imple-
mented after certain conditions are met). These
rules attempt to create true NA V perturbations,
compared to the more-contrived Latin-script per-
turbations. Rules include:
•Sentence-Ending Emphasis Particles e.g. ‘’
→‘よ’
• Copula removal e.g. ‘ です ’→‘’
• Pronoun substitution e.g. ‘ 私’→‘俺’3528A.4 Full Mono-Pair Results
Table 5 shows our full results from the mono-pair
model experiments. In addition to CONSIST and
BLEU, we also obtain a MATCH score, based on
average percentage the output sentence matches the
reference and NUM, the average number of differ-
ent translations generated per set of semantically-
equivalent NA V perturbations.
A.5 Multi-pair Model Results
Results from multi-pair experiments in Section 4.2
in Figure 9.
A.6 Quantitative Error
Getting clear quantitative descriptions for the fre-
quency of specific types of errors seen in baseline
models is difficult, but we provide some more infor-
mation about the analysis. We find the types of er-
rors mentioned (issues with dropped pronouns, un-
common synonyms, gender ambiguity, etc.) fairly
frequently. Skimming through several prompts, we
see these types of erroneous output many times.
For example, in a prompt with 92 NA V pertur-
bations in Japanese, 52 of the outputs from the
baseline model were incorrect. With a reference
“It is a kind of tomato”, erroneous outputs include
“Type of tomatoes” “It is like tomatoes” “Some-
thing about tomatoes” and “One sort of tomato”;
correct outputs include “It is a variety of tomato”
“This is a type of tomato” and “It is a tomato
species”. Some of these errors are language spe-
cific, since NA V is very dependent on the two lan-
guages involved, but as several languages sharehu-en Quality Consistency
cond # BLEU MAT. CONS. NUM
base 0 28.2 11.1 43.1 21.3
most1 37.4 22.3 44.8 20.5
2 42.3 26.7 51.3 16.5
10 45.4 29.6 58.0 12.4
rand1 46.3 29.8 56.3 12.9
2 46.9 32.0 58.3 11.9
10 46.6 32.3 62.9 10.0
least1 47.2 30.6 56.4 13.0
2 48.1 31.4 58.8 11.3
10 46.9 31.2 62.8 9.9
all all 43.3 26.4 64.4 8.4
ja-en Quality Consistency
cond # BLEU MAT. CONS. NUM
base 0 29.0 14.5 39.5 46.8
most1 45.7 27.3 48.9 29.4
2 45.6 28.5 49.6 28.1
10 50.5 33.6 60.5 16.2
rand1 47.9 30.8 54.3 21.6
2 51.0 33.2 57.3 18.1
10 50.0 33.0 60.3 15.2
least1 49.4 31.7 55.1 21.2
2 48.8 32.2 56.8 18.6
10 50.1 33.1 61.7 13.9
all all 40.8 22.6 66.4 9.1
pt-en Quality Consistency
cond # BLEU MAT. CONS. NUM
base 0 38.4 12.0 35.3 34.3
most1 42.0 14.1 34.2 34.0
2 43.4 16.2 37.5 29.8
10 52.8 26.1 53.3 16.9
rand1 52.4 26.3 51.6 18.5
2 54.8 26.3 55.8 15.7
10 56.9 29.0 59.2 13.0
least1 53.8 27.9 52.8 18.2
2 55.7 29.4 55.3 15.3
10 56.5 30.0 59.3 12.8
all all 53.0 26.9 63.0 10.03529properties, relevant errors can be seen across lan-
guages (e.g. pronoun drop in Japanese, Korean and
Portuguese)
B Additional Evaluations
B.1 Out-of-Domain Performance of
NA V-robust Models
To further investigate behavior of NA V-robust mod-
els, we run experiments to see the effect on perfor-
mance in OOD tasks. For {hu,ja,pt}-en we use a
held-out test split of the Tatoeba corpus. Our re-
sults are shown in Figure 10. For {ko,vi}-en we use
the official OPUS-100 test set with results shown
in Figure 11.
From these experiments, we see that generally
NA V-robustification slightly worsens OOD perfor-
mance. While these results appear negative, they
are not too surprising considering common trends
in fine-tuning and robustification (He et al., 2021).
Often, fine-tuning can cause some forgetting and
models with higher robustness perform worse when
evaluated on original, un-noisy input. Correctingthis widespread behavior is beyond the scope of
this work.
While it’s clear that improving NA V robustness
has shown a decrease in ‘regular’ MT BLEU, there
are many differences between our NA V evaluation
settings and our experiment settings in this section.
For example, these experiments are not just 1) out
of domain, they also 2) no longer have a robustness
component to them because we aren’t evaluating
the models on several perturbations (NA V or oth-
erwise) of input sentences. The decrease in BLEU
may be due to either or both of these properties,
which our next subsections attempt to disentangle.
B.2 NA V-robust Models on Other Types of
Noise
Our next set of experiments in this section looks
at measuring NA V-robustness transfer. By this we
seek to answer the question does a model fine-tuned
deliberately for NAV robustness exhibit robustness
to non-NAV-related noise? For this, we use an exist-
ing MT test set designed to include noisy input text
to challenge models’ robustness, MTNT (Machine
Translation of Noisy Text) (Michel and Neubig,
2018).
We simply evaluate our baseline and select NA V-
tuned models on the ja-en test split of MTNT. Our
results are shown in Figure 12. We see that our
baseline performs better than our NA V-tuned mod-
els, suggesting zero-shot transfer of robustness may
not be possible in this way. The NA V perturbations
which our models were trained to be robust to do
not overlap with many of the types of noise in
MTNT, which resembles less-standard ‘internet-
speech’.3530Again, we have another problem with this evalu-
ation in that the models are not only tested against
new classes of perturbations but also in a new do-
main. One way of testing performance on new
classes of perturbation but staying in-domain is to
use our synthetic augmentation scripts to create a
synthetic robustness test set.
We use the same scripts but apply them to the test
splits of {hu,ja,pt} STAPLE. In this way, we can
probe transferability of NA V robustness by evaluat-
ing our NA V-robust models on these synthetic test
sets. We also evaluate the models fine-tuned on
synthetic data for comparison. Results are shown
in Figure 13.
In general, the synthetic-tuned models perform
better on these synthetic test evaluations. However,
the organic NA V-tuned models do exhibit some im-
proved robustness compared to a baseline model.
The NA V perturbations these models are fine-tuned
on rarely overlap with the types of synthetic per-
turbations performed on the new {hu,pt}-en sets,
explaining the only slight transferability. Organic
NA V perturbations help more on our synthetic ja-
en test set, likely because the ja-en test set attempts
to synthetically create NA V perturbations, thus im-
itating the organic fine-tuning data more closely.
B.3 In-Domain MT
One possible source of confusion in our NA V ro-
bustness evaluation could be the fact that it is ab-
normal to have hundreds of test examples with the
same reference translation. Perhaps BLEU is not as
reliable in such conditions. To account for this, wecalculate BLEU on in-domain data by using our ‘1-
most’ and ‘1-least’ STAPLE test sets. This returns
the task to single-pair examples while focusing on
common and uncommon examples, respectively.
The results for ‘1-most’ are shown in Figures 14
and 15. In our NA V experiments from Section 4,
the “10 random” models outperform the “1 most”
models, but here we see the opposite. This is not
surprising as the ‘1-most’ fine-tuning is most sim-
ilar to this ‘1-most’ evaluation. Also, this evalua-
tion no longer contains a robustness aspect as each
example pair uses a commonly-occurring source
sentence.
This raises the concern that it could be, in fact,
that 10-random has higher BLEU on our robust-
ness experiments because of the property of having
hundreds of variations for each example. To disen-
tangle this possible explanation, we also evaluate
our models on a “1-least” STAPLE set. We source
theleast common source sentence for each exam-
ple. This helps ensure the test inputs will exhibit3531more difficult NA V perturbations, thus serving as
a better NA V-robustness test set without the added
property of having several variations from each
translation pair. The results are shown in Figures
16 and 17.
Our results now reflect those from our robustness
experiments with “10-random” fine-tuning consis-
tently performing better than “1-most”. This sug-
gests that the models showing highest NA V robust-
ness by our evaluations also show higher robustness
in a more standard MT evaluation on NA V-noisy
data.3532