
Xiaolin Zheng, Mengling Hu, Weiming Liu, Chaochao Chen, and Xinting Liao
Zhejiang University, China
{xlzheng,humengling,21831010,zjuccc,xintingliao}@zju.edu.cn
Abstract
Short text clustering is challenging since it
takes imbalanced and noisy data as inputs. Ex-
isting approaches cannot solve this problem
well, since (1) they are prone to obtain de-
generate solutions especially on heavy imbal-
anced datasets, and (2) they are vulnerable to
noises. To tackle the above issues, we propose
a Robust Short Text Clustering ( RSTC ) model
to improve robustness against imbalanced and
noisy data. RSTC includes two modules, i.e.,
pseudo-label generation module androbust
representation learning module . The former
generates pseudo-labels to provide supervision
for the later, which contributes to more robust
representations and correctly separated clus-
ters. To provide robustness against the imbal-
ance in data, we propose self-adaptive optimal
transport in the pseudo-label generation mod-
ule. To improve robustness against the noise in
data, we further introduce both class-wise and
instance-wise contrastive learning in the robust
representation learning module. Our empirical
studies on eight short text clustering datasets
demonstrate that RSTC significantly outper-
forms the state-of-the-art models. The code is
available at: https://github.com/hmllmh/RSTC.
1 Introduction
Text clustering, one of the most fundamental tasks
in text mining, aims to group text instances into
clusters in an unsupervised manner. It has been
proven to be beneficial in many applications, such
as, recommendation system (Liu et al., 2021,
2022a,b), opinion mining (Stieglitz et al., 2018),
stance detection (Li et al., 2022), etc. With the
advent of digital era, more and more people enjoy
sharing and discovering various of contents on the
web, where short text is an import form of informa-
tion carrier. Therefore, it is helpful to utilize short
text clustering for mining valuable insights on the
web.However, short text clustering is not a trivial
task. On the one hand, short text has many cate-
gories and the category distributions are diversify-
ing, where the heavy imbalanced data is common.
The heavy imbalanced data is prone to lead to de-
generate solutions where the tail clusters (i.e., the
clusters with a small proportion of instances) disap-
pear. Specifically, the recent deep joint clustering
methods for short text clustering, (Hadifar et al.,
2019) and (Zhang et al., 2021), adopt the clustering
objective proposed in (Xie et al., 2016), which may
obtain a trivial solution where all the text instances
fall into the same cluster (Yang et al., 2017; Ji et al.,
2019). (Zhang et al., 2021) introduces instance-
wise contrastive learning to train discriminative
representations, which avoids the trivial solution
to some extent. However, (Zhang et al., 2021) still
tends to generate degenerate solutions, especially
on the heavy imbalanced datasets.
On the other hand, short text is typically charac-
terized by noises, which may lead to meaningless
or vague representations and thus hurt clustering
accuracy and stability. Existing short text cluster-
ing methods cope with the noise problem in three
ways, i.e., (1) text preprocessing, (2) outliers post-
processing, and (3) model robustness. Specifically,
earlier methods (Xu et al., 2017; Hadifar et al.,
2019) apply preprocessing procedures on the text
(HaCohen-Kerner et al., 2020) for reducing the neg-
ative impact of noises. The recent method (Rakib
et al., 2020) proposes to postprocess outliers by
repeatedly reassigning outliers to clusters for en-
hancing the clustering performance. However, both
preprocessing and postprocessing methods do not
provide model robustness against the noise in data.
The more recently short text clustering method
SCCL (Zhang et al., 2021) proposes to utilize the
instance-wise contrastive learning to support clus-
tering, which is useful for dealing with the noises
in the perspective of model robustness. However,
the learned representations of SCCL lack discrim-10493inability due to the lack of supervision information,
causing insufficiently robust representations.
In summary, there are two main challenges, i.e.,
CH1 : How to provide model robustness to the
imbalance in data, and avoid the clustering degen-
eracy? CH2 : How to improve model robustness
against the noise in data, and enhance the clustering
performance?
To address the aforementioned issues, in this pa-
per, we propose RSTC , an end-to-end model for
short text clustering. In order to improve model
robustness to the imbalance in data (solving CH1 )
and the noise in data (solving CH2 ), we utilize
two modules in RSTC , i.e., pseudo-label gener-
ation module androbust representation learning
module . The pseudo-label generation module gen-
erates pseudo-labels for the original texts. The
robust representation learning module uses the gen-
erated pseudo-labels as supervision to facilitate
intra-cluster compactness and inter-cluster sepa-
rability, thus attaining more robust representations
and more correctly separated clusters. The better
cluster predictions in turn can be conductive to
generate more reliable pseudo-labels. The itera-
tive training process forms a virtuous circle, that is,
the learned representations and cluster predictions
will constantly boost each other, as more reliable
pseudo-labels are discovered during iterations.
The key idea to solve CH1 is to enforce a con-
straint on pseudo-labels, i.e., the distribution of
the generated pseudo-labels should match the esti-
mated class distribution. The estimated class dis-
tribution is dynamically updated and expected to
get closer to the ground truth progressively. Mean-
while, the estimated class distribution are encour-
aged to be a uniform distribution for avoiding clus-
tering degeneracy. We formalize the idea as a new
paradigm of optimal transport (Peyr√© et al., 2019)
and the optimization objective can be tractably
solved by the Sinkhorn-Knopp (Cuturi, 2013) style
algorithm, which needs only a few computational
overheads. For addressing CH2 , we further intro-
duce class-wise contrastive learning and instance-
wise contrastive learning in the robust representa-
tion learning module. The class-wise contrastive
learning aims to use the pseudo-labels as supervi-
sion for achieving smaller intra-cluster distance and
larger inter-cluster distance. While the instance-
wise contrastive learning tends to disperse the rep-
resentations of different instances apart for the sep-
aration of overlapped clusters. These two modulescooperate with each other to provide better short
text clustering performance.
We summarize our main contributions as follows:
(1) We propose an end-to-end model, i.e., RSTC ,
for short text clustering, the key idea is to discover
the pseudo-labels to provide supervision for robust
representation learning, hence enhancing the clus-
tering performance. (2) To our best knowledge, we
are the first to propose self-adaptive optimal trans-
port for discovering the pseudo-label information,
which provides robustness against the imbalance in
data. (3) We propose the combination of class-wise
contrastive learning and instance-wise contrastive
learning for robustness against the noise in data. (4)
We conduct extensive experiments on eight short
text clustering datasets and the results demonstrate
the superiority of RSTC .
2 Related Work
2.1 Short Text Clustering
Short text clustering is not trivial due to imbalanced
and noisy data. The existing short text clustering
methods can be divided into tree kinds: (1) tradi-
tional methods, (2) deep learning methods, and (3)
deep joint clustering methods. The traditional meth-
ods (Scott and Matwin, 1998; Salton and McGill,
1983) often obtain very sparse representations that
lack discriminations. The deep learning method
(Xu et al., 2017) leverages pre-trained word em-
beddings (Mikolov et al., 2013) and deep neural
network to enrich the representations. However,
the learned representations may not appropriate
for clustering. The deep joint clustering meth-
ods Hadifar et al. (2019); Zhang et al. (2021) inte-
grate clustering with deep representation learning
to learn the representations that are appropriate for
clustering. Moreover, Zhang et al. (2021) utilizes
the pre-trained SBERT (Reimers and Gurevych,
2019) and contrastive learning to learn discrimina-
tive representations, which is conductive to deal
with the noises. However, the adopted clustering
objectives are prone to obtain degenerate solutions
(Yang et al., 2017; Ji et al., 2019), especially on
heavy imbalance data.
Among the above methods, only Zhang et al.
(2021) provides model robustness to the noise in
data. However, its robustness is still insufficient
due to the lack of supervision information. Be-
sides, Zhang et al. (2021) cannot deal with various
imbalanced data due to the degeneracy problem.
As a contrast, in this work, we adopt pseudo-label10494technology to provide reliable supervision to learn
robust representations for coping with imbalanced
and noisy data.
2.2 Pseudo-labels for Unsupervised Learning
Pseudo-labels can be helpful to learn more dis-
criminative representations in unsupervised learn-
ing (Hu et al., 2021). Caron et al. (2018) shows
that k-means clustering can be utilized to generate
pseudo-labels for learning visual representations.
However, it does not have a unified, well-defined
objective to optimize (i.e., there are two objec-
tives: k-means loss minimization and cross-entropy
loss minimization), which means that it is difficult
to characterize its convergence properties. Asano
et al. (2020) proposes SeLa to optimize the same
objective (i.e., cross-entropy loss minimization)
for both pseudo-label generation and representa-
tion learning, which can guarantee its convergence.
Besides, SeLa transforms pseudo-label generation
problem into an optimal transport problem. Caron
et al. (2020) proposes SwA V which combines SeLa
with contrastive learning to learn visual represen-
tations in an online fashion. However, both SeLa
and SwA V add the constraint that the distribution
of generated pseudo-labels should match the uni-
form distribution, to avoid clustering degeneracy.
With the constraint, it is hard for them to cope
with imbalanced data. As a contrast, in this work,
we propose self-adaptive optimal transport to si-
multaneously estimate the real class distribution
and generate pseudo-labels. Our method enforce
the distribution of the generated pseudo-labels to
match the estimated class distribution, and thus can
avoid clustering degeneracy and adapt to various
imbalanced data.
3 Methodology
3.1 An Overview of RSTC
The goal of RSTC is to discover and utilize the
pseudo-labels to provide supervision for robust rep-
resentation learning. RSTC consists of pseudo-
label generation module androbust representa-
tion learning module , as illustrated in Fig.1. The
pseudo-label generation module aims to generate
reliable pseudo-labels for the robust representation
learning module. To achieve this aim, we first ob-
tain cluster predictions by the cluster assignment
step, then we excavate pseudo-label information
from the predictions by the self-adaptive optimal
transport (SAOT) step. The robust representationlearning module aims to use the generated pseudo-
labels as supervision to train robust representations.
To achieve this goal, we introduce class-wise and
instance-wise contrastive learning. In this way,
RSTC can provide robustness to imbalanced and
noisy data, thus enhancing the clustering perfor-
mance.
3.2 Pseudo-label Generation Module
We first introduce the pseudo-label generation mod-
ule. Although the deep joint clustering meth-
ods (Xie et al., 2016; Hadifar et al., 2019; Zhang
et al., 2021) are popular these days, their cluster-
ing performance is limited due to the following
reasons. Firstly, lacking supervision information
prevents the deep joint clustering methods from
learning more discriminative representations (Hu
et al., 2021). Secondly, they are prone to obtain
degenerate solutions (Yang et al., 2017; Ji et al.,
2019), especially on heavy imbalanced datasets.
Therefore, to provide reliable supervision informa-
tion for various imbalanced data, we propose SAOT
in the pseudo-label generation module to generate
pseudo-labels for the robust representation learning
module. The overview of pseudo-label generation
module is shown in Fig.1(a), which mainly has
two steps: Step 1: cluster assignment, and Step 2:
SAOT.
Step 1: cluster assignment. Cluster assignment
aims to obtain cluster predictions of the original
texts. Specifically, we adopt SBERT (Reimers and
Gurevych, 2019) as the encoding network Œ¶to en-
code the original text XasŒ¶(X) =E‚àà R
where Ndenotes batch size and Dis the dimen-
sion of the representations. We utilize the fully
connected layers as the clustering network Gto
predict the cluster assignment probability (predic-
tions), i.e., G(E) =P‚àà R, where Cis the
category number. The encoding network and the
clustering network are fixed in this module.
Step 2: SAOT. SAOT aims to exploit the clus-
ter predictions to discover reliable pseudo-label.
Asano et al. (2020) extends standard cross-entropy
minimization to an optimal transport (OT) prob-
lem to generate pseudo-labels for learning image
representations. This OT problem can be regarded
as seeking the solution of transporting the sample
distribution to the class distribution. However, the
class distribution is unknown. Although Asano
et al. (2020) sets it to a uniform distribution to
avoid degenerate solutions, the mismatched class10495
distribution will lead to unreliable pseudo-labels.
Therefore, it is essential to estimate real class dis-
tribution for addressing this issue. The recent re-
search (Wang et al., 2022) studies the class distri-
bution estimation, but it tends to cause clustering
degeneracy on heavy imbalanced data, which we
will further discuss in Appendix A. Hence, to dis-
cover reliable pseudo-labels on various imbalanced
data, we propose SAOT.
We will provide the details of SAOT below. We
expect to minimize the cross entropy loss to gener-
ate the pseudo-labels by solving a discrete OT prob-
lem. Specifically, we denote the pseudo-labels as
Q‚àà R. LetœÄ=Qbe the transport matrix
between samples and classes, M=‚àílogPbe
the cost matrix to move probability mass from sam-
ples to classes. The reason that we usebetween
œÄandQis the transport matrix should be a joint
probability (Cuturi, 2013), i.e., the sun of all values
in the œÄshould be 1, while the sum of each raw
inQis1. We have, Q= argmin‚ü®Q,‚àílogP‚ü©=
Nargmin‚ü®œÄ,M‚ü©. Thus, the OT problem is as fol-
lows:
min‚ü®œÄ,M‚ü©+œµH(œÄ)
s.t.œÄ1=a,œÄ1=b,œÄ‚â•0,(1)
where œµis a balance hyper parameter, H(œÄ) =
‚ü®œÄ,logœÄ‚àí1‚ü©is the entropy regularization (Cuturi,
2013), a=1is the sample distribution, and b
is an unknown class distribution. To avoid cluster-
ing degeneracy and obtain reliable transport matrix
with randomly initialized b, we introduce a penalty
function about bto the OT objective and update bduring the process of solving the transport matrix.
We formulate the SAOT optimization problem as:
min‚ü®œÄ,M‚ü©+œµH(œÄ) +œµ(Œ®(b))1
s.t.œÄ1=a,œÄ1=b,œÄ‚â•0,b1= 1,(2)
where œµandœµare balance hyper-parameters,
Œ®(b) =‚àílogb‚àílog(1‚àíb)is the penalty function
aboutb. The penalty function not only limits b(a
value of b) ranges from 0to1, but also avoids clus-
tering degeneracy by encouraging bto be a uniform
distribution. The encouragement is achieved by in-
creasing the punishment for bthat is close to 0or
1. Besides, the level of the encouragement can be
adjusted by œµ. Specifically, there are two critical
terms in Equation (2) for exploring b, i.e., (1) the
cost matrix Mand (2) the penalty function Œ®(b),
and we use œµto balance these two terms. For bal-
anced data, both MandŒ®(b)encourage bto be a
uniform distribution. For imbalanced data, Men-
courages the head clusters (i.e., the clusters with a
large proportion of instances) to have larger band
the tail clusters (i.e., the clusters with a small pro-
portion of instances) to have smaller b. When bof
a tail cluster approaches 0, this tail cluster tends to
disappear (clustering degeneracy). Whereas Œ®(b)
still encourages bto be a uniform distribution for
avoiding the degeneracy. With a decent trade-off
parameter œµ, SAOT can explore appropriate band
obtain reliable œÄfor various imbalanced data. We
provide the optimization details in Appendix B.
After obtaining œÄ, we can get pseudo-labels by10496argmax operation, i.e,
Q=Ô£±
Ô£≤
Ô£≥1,ifj= argmaxœÄ
0,otherwise .(3)
It should be noted that, for convenience, we let
œÄ=Qbefore. However, œÄis essentially a join
probability matrix and œÄcan be decimals, while
each row of Qis a one-hot vector.
Through the steps of cluster assignment and self-
adaptive optimal transport, we can generate reliable
pseudo-labels on various imbalanced data for the
robust representation learning module.
3.3 Robust Representation Learning module
We then introduce the robust representation learn-
ing module. To begin with, motivated by (Wenzel
et al., 2022), we propose to adopt instance augmen-
tations to improve the model robustness against
various noises. Furthermore, inspired by (Chen
et al., 2020), (Zhang et al., 2021) and (Dong et al.,
2022), we adopt both class-wise and instance-wise
contrastive learning to utilize the pseudo-labels and
the augmented instance pairs for robust representa-
tion learning, as shown in Fig.1(b). The class-wise
contrastive learning uses pseudo-labels as the su-
pervision to pull the representations from the same
cluster together and push away different clusters.
While the instance-wise contrastive learning dis-
perses different instances apart, which is supposed
to separate the overlapped clusters.
Next, we provide the details of the robust repre-
sentation learning module. We utilize contextual
augmenter (Kobayashi, 2018; Ma, 2019) to gener-
ate augmented pairs of the original texts as X
andX. Like the cluster assignment step in the
pseudo-labels generation module, we can obtain
the representations of augmented pairs Xand
XasE‚àà RandE‚àà R, re-
spectively. We can obtain the predictions of them
asP‚àà RandP‚àà R, respec-
tively. We use the fully connected layers as the
projecting network Gto map the representations
to the space where instance-wise contrastive loss
is applied, i.e., G(E) =Z‚àà Rand
G(E) =Z‚àà R, where Dis the
dimension of the projected representations. The
encoding network and the clustering network share
weights with the pseudo-label generation module.
The class-wise contrastive learning enforces con-
sistency between cluster predictions of positivepairs. Specifically, the two augmentations from
the same original text are regarded as a positive
pair and the contrastive task is defined on pairs
of augmented texts. Moreover, the pseudo-label
of an original text is considered as the target of
corresponding two augmented texts. We use the
augmented texts with the targets as supervised data
for cross-entropy minimization to achieve the con-
sistency. The class-wise contrastive loss is defined
as below:
L=1
N‚ü®Q,‚àílogP‚ü©+1
N‚ü®Q,‚àílogP‚ü©.
(4)
The instance-wise contrastive learning enforces
consistency between projected representations of
positive pairs while maximizing the distance be-
tween negative pairs. Specifically, for a batch, there
are2Naugmented texts, their projected represen-
tations are Z= [Z,Z], given a positive
pair with two texts which are augmented from the
same original text, the other 2(N‚àí1)augmented
texts are treated as negative samples. The loss for
a positive pair (i, j)is defined as:
l(i, j) =‚àílogexp( sim(Z,Z)/œÑ)/summationtext 1exp( sim(Z,Z)/œÑ),
(5)
where sim(u,v)denotes cosine similarity between
uandv,œÑdenotes the temperature parameter, and
1is an indicator. The instance-wise contrastive
loss is computed across all positive pairs in a batch,
including both (i, j)and(j, i). That is,
L=1
2N/summationdisplay(l(i,2i) +l(2i, i)). (6)
By combining the pseudo-supervised class-wise
contrastive learning and the instance-wise con-
trastive learning, we can obtain robust represen-
tations and correctly separated clusters.
3.3.1 Putting Together
The total loss of RSTC could be obtained by
combining the pseudo-supervised class-wise con-
trastive loss and the instance-wise contrastive loss.
That is, the loss of RSTC is given as:
L=L+ŒªL, (7)
where Œªis a hyper-parameter to balance the two
losses. By doing this, RSTC not only provides ro-
bustness to the imbalance in data, but also improve
robustness against the noise in data.10497The whole model with two modules forms a
closed loop and self evolution, which indicates that
the learned representations (more robust) and clus-
ter predictions (more accurate) elevate each other
progressively, as more reliable pseudo-labels are
discovered during the iterations. Specifically, we
firstly initialize the pseudo-labels Qby performing
k-means on text representations. Next, we train
the robust representation learning module by batch
with the supervision of pseudo-labels. Meanwhile,
we update Qthroughout the whole training pro-
cess in a logarithmic distribution, following (Asano
et al., 2020). Finally, we can obtain the cluster as-
signments by the column index of the largest entry
in each row of P. The training stops if the change
of cluster assignments between two consecutive
updates for Pis less than a threshold Œ¥or the max-
imum number of iterations is reached.
4 Experiment
In this section, we conduct experiments on sev-
eral real-world datasets to answer the following
questions: (1) RQ1 : How does our approach per-
form compared with the state-of-the-art short text
clustering methods? (2) RQ2 : How do the SAOT,
and the two contrastive losses contribute to the per-
formance improvement? (3) RQ3 : How does the
performance of RSTC vary with different values
of the hyper-parameters?
4.1 Datasets
We conduct extensive experiments on eight pop-
ularly used real-world datasets, i.e., AgNews ,
StackOverflow ,Biomedical ,SearchSnippets ,
GoogleNews-TS ,GoogleNews-T ,GoogleNews-
Sand Tweet . Among them, AgNews ,Stack-
Overflow andBiomedical are balanced datasets,
SearchSnippets is a light imbalanced dataset,
GoogleNews ,GoogleNews-T ,GoogleNews-S and
Tweet are heavy imbalanced datasets. Following
(Zhang et al., 2021), we take unpreprocessed data
as input to demonstrate that our model is robust to
noise, for a fair comparison. More details about the
datasets are shown in Appendix C.1.
4.2 Experiment Settings
We build our model with PyTorch (Paszke et al.,
2019) and train it using the Adam optimizer
(Kingma and Ba, 2015). We study the ef-
fect of hyper-parameters œµandœµon SAOT
by varying them in {0.05,0.1,0.2,0.5}and{0,0.001,0.01,0.1,1}, respectively. Besides, we
study the effect of the hyper-parameter Œªby vary-
ing it in {0,1,5,10,20,50,100}. The more details
are provided in Appendix C.2. Following previous
work (Xu et al., 2017; Hadifar et al., 2019; Rakib
et al., 2020; Zhang et al., 2021), we set the clus-
ter numbers to the ground-truth category numbers,
and we adopt Accuracy (ACC) and Normalized
Mutual Information (NMI) to evaluate different ap-
proaches. The specific definitions of the evaluation
methods are shown in Appendix C.3. For all the
experiments, we repeat five times and report the
average results.
4.3 Baselines
We compare our proposed approach with the fol-
lowing short text clustering methods. BOW (Scott
and Matwin, 1998) & TF-IDF (Salton and McGill,
1983) applies k-means on the TF-IDF representa-
tions and BOW representations respectively. STC-
LPI (Xu et al., 2017) first uses word2vec to train
word embeddings on the in-domain corpus, and
then uses a convolutional neural network to obtain
the text representations where k-means is applied
for clustering. Self-Train (Hadifar et al., 2019)
follows (Xie et al., 2016) uses an autoencoder to
get the representations, and finetunes the encod-
ing network with the same clustering objective.
The difference are that it uses the word embed-
dings provided by (Xu et al., 2017) with SIF (Arora
et al., 2017) to enhance the pretrained word embed-
dings, and obtains the final cluster assignments via
k-means. K-means_IC (Rakib et al., 2020) first
applies k-means on the TF-IDF representations and
then enhances clustering by the iterative classifi-
cation algorithm. SCCL (Zhang et al., 2021) is
the more recent short text clustering model which
utilizes SBERT (Reimers and Gurevych, 2019) as
the backbone and introduces instance-wise con-
trastive learning to support clustering. Besides,
SCCL uses the clustering objective proposed in
(Xie et al., 2016) for deep joint clustering and ob-
tains the final cluster assignments by k-means.
4.4 Clustering Performance (RQ1)
Results and discussion The comparison results
on eight datasets are shown in Table 1. SBERT(k-
means) denotes the pre-trained SBERT model with
k-means clustering, which is the initial state of our
RSTC .
From the results, we can find that: (1) Only
adopting traditional text representations ( BOW and10498
TF-IDF ) cannot obtain satisfying results due to the
data sparsity problem. (2) Deep learning methods
(STC-LPI andSelf-Train ) outperform traditional
ones, indicating that the application of pre-trained
word embeddings and deep neural network allevi-
ates the sparsity problem. (3) SCCL obtains bet-
ter results by introducing instance-wise contrastive
learning to cope with the noises problem. How-
ever, the clustering objective of SCCL is prone to
obtain degenerate solutions (Yang et al., 2017; Ji
et al., 2019). Besides, it is suboptimal for extra
application of k-means (Van Gansbeke et al., 2020).
The degeneracy gives the representation learning
wrong guidance, which degrades the final k-means
clustering performance. (4) RSTC outperforms all
baselines, which proves that the robust represen-
tation learning with pseudo-supervised class-wise
contrastive learning and instance-wise contrastive
learning can significantly improve the clustering
performance. To better show the clustering degen-
eracy problem, we visualize how the number of
predicted clusters are changing over iterations on
SCCL andRSTC in Appendix C.4. From the re-
sults, we verify that SCCL has relatively serious
clustering degeneracy problem while RSTC solves
it. The visualization results illustrate the validity
of our model.4.5 In-depth Analysis (RQ2 and RQ3)
Ablation (RQ2) To study how each component
ofRSTC contribute to the final performance, we
compare RSTC with its several variants, includ-
ingRSTC -OT, RSTC -C and RSTC -I.RSTC -
OT adopts both the pseudo-supervised class-wise
contrastive learning and instance-wise contrastive
learning, while the pseudo-labels are generated by
traditional OT with fixed random class distribu-
tion. RSTC -C only adopts the pseudo-supervised
class-wise contrastive learning, the pseudo-labels
are generated by SAOT. RSTC -I only adopts the
instance-wise contrastive learning while the clus-
tering results are obtained by k-means.
The comparison results are shown in Table 1.
From it, we can observe that they all cannot achieve
satisfactory results due to their limitations. Specif-
ically, (1) RSTC -OT will be guided by the mis-
matched distribution constraint to generate unre-
liable pseudo-labels. (2) RSTC -C is good at ag-
gregating instances, but it has difficulties to ad-
dress the situation when different categories are
overlapped with each other in the representation
space at the beginning of the learning progress,
which may lead to a false division. (3) RSTC -
I is good at dispersing different instances, but it
has limited ability to aggregate instances which10499
may lead to the unclear boundaries between clus-
ters. (4) RSTC achieves the best performance with
the combination of pseudo-supervised class-wise
contrastive learning and instance-wise contrastive
learning while the pseudo-labels are generated by
SAOT. Overall, the above ablation study demon-
strates that our proposed SAOT and robust repre-
sentation learning are effective in solving the short
text clustering problem.
Visualization To further show the functions and
the limitations of the pseudo-supervised class-wise
contrastive learning and the instance-wise con-
trastive learning, we visualize the representations
using t-SNE (Van der Maaten and Hinton, 2008)
forSBERT (initial state), RSTC -C,RSTC -I and
RSTC . The results on SearchSnippets are shown
in Fig.2(a)-(d). From it, we can see that: (1)
SBERT (initial state) has no boundaries between
classes, and the points from different clusters have
significant overlap. (2) Although RSTC -C groups
the representations to exact eight clusters, a large
proportion of points are clustered by mistake. (3)
RSTC -I disperses the overlapped categories to
some extent, but the points are not clustered. (4)
With the combination of RSTC -C and RSTC -I,
RSTC obtains best text representations with small
intra-cluster distance, large inter-cluster distance
while only a small amount of points are clustered
wrongly. The reasons for these phenomenons are
the same as previous results analyzed in Ablation .
Effect of hyper-parameter (RQ3) We now
study the effects of hyper-parameters on model
performance, including œµ,œµandŒª. We first
study the effects of œµandœµby varying them
in{0.05,0.1,0.2,0.5}and{0,0.001,0.01,0.1,1},
respectively. The results are reported in Fig. 3(a)
and Fig. 3(b). Fig. 3(a) shows that the accuracy are
not sensitive to œµ. Fig. 3(b) shows that choosing
the proper hyper-parameters for different imbal-
ance levels of datasets is important, especially on
the heavy imbalanced dataset GoogleNews-T . Em-
pirically, we choose œµ= 0.1on all datasets, œµ=
0.1on the balanced datasets, œµ= 0.01on the light
imbalanced datasets, and œµ= 0.001on the heavy
imbalanced datasets. Then we perform experiments
by varying Œªin{0,1,5,10,20,50,100}. The re-
sults on three datasets are shown in Fig. 4. From
them, we can see that the performance improves
when Œªincreases, then keeps a relatively stable
level after Œªreaches 1and finally decreases when
Œªbecomes too large. We can conclude that when
Œªis too small, the ability of instance-wise con-
trastive learning cannot be fully exploited. When
Œªis too large, the ability of class-wise contrastive
learning will be suppressed, which also reduces the
clustering performance. Empirically, we choose
Œª= 10 for all datasets.
5 Conclusion
In this paper, we propose a robust short text cluster-
ing ( RSTC ) model, which includes pseudo-label
generation module androbust representation learn-
ing module . The former generates pseudo-labels
as the supervision for the latter. We innovatively
propose SAOT in the pseudo-label generation mod-10500ule to provide robustness against the imbalance
in data. We further propose to combine class-
wise contrastive learning with instance-wise con-
trastive learning in the robust representation learn-
ing module to provide robustness against the noise
in data. Extensive experiments conducted on eight
real-world datasets demonstrate the superior per-
formance of our proposed RSTC .
6 Limitations
Like existing short text clustering methods, we as-
sume the real cluster number is known. In the
future, we would like to explore a short text clus-
tering method with an unknown number of clusters.
Moreover, the time complexity of self-adaptive op-
timal transport is O(n), we are going to seek a
new computation to reduce the complexity.
Acknowledgements
This work was supported in part by the Leading
Expert of ‚ÄúTen Thousands Talent Program‚Äù of Zhe-
jiang Province (No.2021R52001) and National Nat-
ural Science Foundation of China (No.72192823).
References1050110502
ADifferent Class Distribution Estimation
Methods
We have tried three class distribution estimation
methods, including: (1) M1(ours): The method pro-
posed in our paper with the penalty function Œ®(b=
‚àílog(b)‚àílog(1‚àíb)), andbcan be updated dur-
ing the process of solving the OT problem. (2)
M2: The method proposed in (Wang et al., 2022)
holds no assumption on b, andbcan be updated by
the model predicted results with moving-average
mechanism, that is, b=¬µÀÜb+ (1‚àí¬µ)Œ≥, where ¬µis
the moving-average parameter, ÀÜbis the last updated
bandŒ≥=/summationtext 1(j= arg max P). (3) M3:
This method replaces the penalty function in our
method with the common entropy regularization
Œ®(b) =KL(b‚à•ÀÜb), where ÀÜbis the last updated b,
and the current bcan be updated the same way our
method does. Note that, the parameters of M2are
following (Wang et al., 2022), the parameters of
M3are the same as M1(ours).
For comprehensive comparison, we conduct
the experiments on one imbalanced dataset
GoogleNews-T and one balanced dataset Stack-
Overflow with randomly initialized bfor visualiz-
ing how the accuracy and the number of predicted
clusters are changing over iterations. Moreover,
except the update of b, everything else about the
experiments is the same for three methods. The re-
sults are shown in Fig.5(a)-(d). From them, we can
find that: (1) For the imbalanced dataset, M1(ours)
achieves the best accuracy and converges to the real
category number, while other methods have clus-
tering degeneracy problem. (2) For the balanced
dataset, M2achieves best accuracy more quickly
while M1(ours) catches up in the end, and all meth-
ods obtain real category number. Although M3can
obtain good accuracy on the imbalanced dataset, it
has the worst accuracy on the balanced dataset. In
addition, although M2achieves good accuracy on
the balanced dataset, it has the worst accuracy on
the imbalanced dataset. Only M1(ours) achieves
fairly good performance on both datasets, which
indicates that our method are robust to various im-
balance levels of datasets. The experiments prove
the effectiveness of our class distribution estima-
tion method.
B SAOT
As mentioned in Section 3.2, the SAOT problem is
formulated as:
min‚ü®œÄ,M‚ü©+œµH(œÄ) +œµ(Œ®(b))1,
s.t.œÄ1=a,œÄ1=b,œÄ‚â•0,b1= 1.(8)
where œµandœµare balance hyper-parameters,
Œ®(b) =‚àílogb‚àílog(1‚àíb)is the penalty func-
tion about b. We adopt the Lagrangian multiplier
algorithm to optimize the problem:
min‚ü®œÄ,M‚ü©+œµH(œÄ) +œµ(Œ®(b))1
‚àíf(œÄ1‚àía)‚àíg(œÄ1‚àíb)‚àíh(b1‚àí1),
(9)
where f,g, and hare all Lagrangian multipliers.
Taking the differentiation of Equation (9) on the
variable œÄ, we can obtain:
œÄ= exp(f+g‚àíM
œµ)>0. (10)10503We first fix b, due to the fact that œÄ1=aand
œÄ1=b, we can get:
exp (f
œµ) =a/summationtextexp(), (11)
exp (g
œµ) =b/summationtextexp(). (12)
Then we fix fandg, and update bby:
min/bracketleftbig
œµ(Œ®(b))1+gb‚àíh(b1‚àí1)/bracketrightbig
.(13)
Taking the differentiation of Equation (13) on the
variable b, we can obtain:
(g‚àíh)b‚àí((g‚àíh) + 2œµ)b+œµ= 0.(14)
It is easy to get the discriminant of Equation (14)
‚àÜ= (g‚àíh)+ 4œµ>0,
b(h) =(g‚àíh+ 2œµ)¬±/radicalbig
‚àÜ
2(g‚àíh). (15)
Note that,
b(h) =((g‚àíh) + 2œµ) +/radicalbig
‚àÜ
2(g‚àíh)‚â•1.(16)
Thus, we choose the following b(h):
b(h) =((g‚àíh) + 2œµ)‚àí/radicalbig
‚àÜ
2(g‚àíh). (17)
Taking Equation (17) back to the original constraint
b1= 1, the formula is defined as below:
(b(h))1‚àí1 = 0 , (18)
where his the root of Equation (18), and we can
use Newton‚Äôs method to work out it. Specifically,
we first define that f(h) = (b(h))1‚àí1, then h
can be updated by:
h‚Üêh‚àíf(h)
f(h), (19)
where the iteration number is set to 10. Then we
can obtain bby Equation (17). In short, through
iteratively updating Equation (11), (12), (19), and
(17), we can obtain the transport matrix œÄon
Equation (10). We show the iteration optimization
scheme of SAOT in Algorithm 1.Algorithm 1 The optimization scheme of SAOT
Input: The cost distance matrix: M.
Output: The transport matrix: œÄ.
Procedure :Initialize fandgrandomly;Initialize brandomly and perform normaliza-
tion so that b1= 1;Initialize h= 1.fori= 1toTdo Update fin Equation (11); Update gin Equation (12); Update bin Equation (17) with the con-
straint b1= 1.end forCalculate œÄin Equation (10).
C Experiment
C.1 Datasets
We conduct extensive experiments on eight popu-
larly used real-world datasets. The details of each
dataset are as follows.
AgNews (Rakib et al., 2020) is a subset of AG‚Äôs
news corpus collected by (Zhang et al., 2015)
which consists of 8,000 news titles in 4 topic cate-
gories. StackOverflow (Xu et al., 2017) consists of
20,000 question titles associated with 20 different
tags, which is randomly selected from the chal-
lenge data published in Kaggle.com.Biomedical
(Xu et al., 2017) is composed of 20,000 paper titles
from 20 different topics and it is selected from the
challenge data published in BioASQ‚Äôs official web-
site.SearchSnippets (Phan et al., 2008) contains
12,340 snippets from 8 different classes, which is
selected from the results of web search transaction.
GoogleNews (Yin and Wang, 2016) consists of the
titles and snippets of 11,109 news articles about
152 events (Yin and Wang, 2014) which is divided
into three datasets: the full dataset is GoogleNews-
TS, while GoogleNews-T only contains titles and
GoogleNews-S only has snippets. Tweet (Yin and
Wang, 2016) consists of 2,472 tweets related to 89
queries and the original data is from the 2011 and
2012 microblog track at the Text REtrieval Confer-
ence. The detailed statistics of these datasets are
shown in Table 2.10504Dataset C N A R
AgNews 4 8,000 23 1
StackOverflow 20 20,000 8 1
Biomedical 20 20,000 13 1
SearchSnippets 8 12,340 18 7
GoogleNews-TS 152 11,109 28 143
GoogleNews-T 152 11,108 6 143
GoogleNews-S 152 11,108 22 143
Tweet 89 2,472 9 249
C.2 Experiment Settings
We choose distilbert-base-nli-stsb-mean-tokens
in Sentence Transformer library (Reimers and
Gurevych, 2019) to encode the text, and the maxi-
mum input length is set to 32. The learning rate is
set to 5√ó10for optimizing the encoding network,
and5√ó10for optimizing both the projecting
network and clustering network. The dimensions
of the text representations and the projected rep-
resentations are set to D= 768 andD= 128 ,
respectively. The batch size is set to N= 200 .
The temperature parameter is set to œÑ= 1. The
threshold Œ¥is set to 0.01. The datasets specific tun-
ing is avoided as much as possible. For BOW and
TF-IDF , we achieved the code with scikit-learn
(Pedregosa et al., 2011). For all the other baselines,
i.e.,STC-LPI,Self-Train,K-means _IC, and
SCCL(MIT-0 license), we used their released
code. Besides, we substitute the accuracy eval-
uation code of K-means _ICwith the evaluation
method described in our paper.
In addition, as STC-LPI andSelf-Train use the
word embeddings pre-trained with in-domain cor-
pus, and there are only three datasets‚Äô pre-trained
word embeddings provided, therefore we do not
report the results of other five datasets for them.
C.3 Evaluation Metrics
We report two widely used evaluation metrics of
text clustering, i.e., accuracy (ACC) and normal-
ized mutual information (NMI), following (Xu
et al., 2017; Hadifar et al., 2019; Zhang et al., 2021).
Accuracy is defined as:
ACC =/summationtext 1
N, (20)
where yandÀÜyare the ground truth label and
the predicted label for a given text xrespec-
tively, map()maps each predicted label to the
corresponding target label by Hungarian algo-
rithm(Papadimitriou and Steiglitz, 1998). Normal-
ized mutual information is defined as:
NMI (Y,ÀÜY) =I(Y,ÀÜY)/radicalÔ£¨ig
H(Y)H(ÀÜY),(21)
where YandÀÜYare the ground truth labels and
the predicted labels respectively, I()is the mutual
information, and H()is the entropy.
C.4 Visualization
To better show the clustering degeneracy problem,
we visualize how the number of predicted clus-
ters (we call it clusters later) are changing over
iterations on SCCL andRSTC . The results are
shown in Fig.6. From it, we verify that SCCL has
relatively serious clustering degeneracy problem
while RSTC solves it to some extent. Specifically,
theclusters ofSCCL is much less than the real
category number. Moreover, the degeneracy has
a negative effect on the final k-means clustering
performance because it makes the representations
getting worse. Whereas the clusters ofRSTC al-
most convergent to real category number, which
assures the high accuracy of RSTC . The visualiza-
tion results illustrate the validity of our model.
C.5 Computational Budget
The number of parameters in our model is 68M.
Our training for each dataset takes about 10-30
minutes, using a GeForce RTX 3090 GPU.10505ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
Section 6
/squareA2. Did you discuss any potential risks of your work?
Not applicable. Left blank.
/squareA3. Do the abstract and introduction summarize the paper‚Äôs main claims?
Abstract and Section 1
/squareA4. Have you used AI writing assistants when working on this paper?
Left blank.
B/squareDid you use or create scientiÔ¨Åc artifacts?
Left blank.
/squareB1. Did you cite the creators of artifacts you used?
Section 4.3, Appendix C.1 and Appendix C.2
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
Appendix C.2
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciÔ¨Åed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
We use the datasets the same way as existing work.
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiÔ¨Åes individual people or offensive content, and the steps
taken to protect / anonymize it?
The datasets we use only have the text instances and their category IDs.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
Appendix C.1
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiÔ¨Åcant, while on small test sets they may not be.
Appendix C.1
C/squareDid you run computational experiments?
Left blank.
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
Appendix C.510506/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
Section 4.2, Section 4.5, and Appendix C.2
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
Section 4.2 and Section 4.4
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
Appendix C.2
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
Left blank.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
No response.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants‚Äô demographic
(e.g., country of residence)?
No response.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you‚Äôre
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
No response.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
No response.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
No response.10507