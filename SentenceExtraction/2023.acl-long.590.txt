
Raphaël Bailly
SAMM, EA 4543, FP2M 2036 CNRS
Université Paris 1
rbailly@univ-paris1.frLaurent Leblond
Stellantis
laurent.leblond1@
stellantis.comKata Gábor
ERTIM, EA 2520
INALCO
kata.gabor@inalco.fr
Abstract
This paper presents an information-theoretical
model of syntactic generalization. We study
syntactic generalization from the perspective of
the capacity to disentangle semantic and struc-
tural information, emulating the human capac-
ity to assign a grammaticality judgment to se-
mantically nonsensical sentences. In order to
isolate the structure, we propose to represent
the probability distribution behind a corpus as
the product of the probability of a semantic con-
text and the probability of a structure, the latter
being independent of the former. We further
elaborate the notion of abstraction as a relax-
ation of the property of independence. It is
based on the measure of structural and contex-
tual information for a given representation. We
test abstraction as an optimization objective on
the task of inducing syntactic categories from
natural language data and show that it signif-
icantly outperforms alternative methods. Fur-
thermore, we find that when syntax-unaware
optimization objectives succeed in the task,
their success is mainly due to an implicit dis-
entanglement process rather than to the model
structure. On the other hand, syntactic cate-
gories can be deduced in a principled way from
the independence between structure and con-
text.
1 Introduction
In the context of both human learning and statistical
machine learning, what distinguishes generaliza-
tion from memorization is the process of deliber-
ately ignoring a part of the input information. In
machine learning, the generalization will be guided
towards some specific direction by the learning hy-
pothesis: the model structure and the choice of reg-
ularization impacts the nature of the information
loss. We can talk about syntactic generalization
from textual data when the information pertaining
to sentence structure tend to be preserved by the
model and the information pertaining to other as-
pects of the text tend to be ignored.Syntactic generalization is of great interest be-
cause the human capacity to assign an abstract
structure to utterances is a prerequisite to creatively
combine constituents and understand novel sen-
tences (Frege, 1892). Knowledge of syntax can
boost the robustness of NLP applications with re-
spect to unseen data, in particular when there is a
distribution shift (He et al., 2020; Wu et al., 2019).
In a broader perspective, understanding syntactic
generalization informs the discussion on the learn-
ability of syntax from unlabelled text without any
built-in grammatical knowledge or inductive bias
(Gold, 1967; Clark and Lappin, 2010; Bailly and
Gábor, 2020). Finally, studying syntactic gener-
alization in large language models (LLMs) sheds
light on whether and to what extent these models
emulate human functioning with respect to linguis-
tic competence.
The prevailing formalization of syntax is by
means of algebraic compositional rules operating
on a finite set of discrete categories (parts of
speech). Language models can acquire syntactic
knowledge when they are given specific super-
vision or bias (Dyer et al., 2016; Shen et al.,
2020; Sartran et al., 2022). Whether unsupervised
settings can lead to syntactic generalization and
under which conditions is still unknown. Current
LLMs use distributed representations that cannot
be unequivocally mapped to a set of categories,
let alone syntactically meaningful categories. The
question whether their representations encode
syntactic information and how to uncover it is
actively investigated today (Hu et al., 2020; Marvin
and Linzen, 2018). The majority of works in
the topic of syntactic generalization in language
models adopt an empirical approach, such as
probing or analysis of a model with a comparison
to actual or expected human performance on
linguistically motivated tasks. In contrast, we
present a theoretical approach to formalize syn-
tactic generalization in an information theoretical10576framework.
Statistical learning can be formulated as the min-
imization of KL-divergence - a measure of infor-
mation loss - subject to constraints. The constraints
on model expressivity ensure that generalization
takes place by eliminating the information result-
ing from sampling noise. We claim that the train-
ing objective of maximum likelihood estimation
by nature does not incentivize models to syntactic
generalization. In the case of syntactic generaliza-
tion, the information loss needs to be directed to
non-structural information, which is only remotely
related to the elimination of sampling noise.
First, a corpus is not randomly sampled from the
set of grammatical sentences. Word co-occurrences
in a corpus are indeed influenced by different fac-
tors such as semantics and pragmatics. The pro-
cess of abstracting away from these factors is ar-
guably different from the concept of generalization
in machine learning, as the acquisition of syntactic
knowledge always involves a shift of distribution
(Hupkes et al., 2022). Second, the target of gen-
eralization is the capacity to recognize the setof
grammatical sentences: well-formedness is inher-
ently a binary notion rather than a probabilistic one.
These considerations motivate our proposition to
decompose a corpus distribution as a factor of se-
mantic/pragmatic context and a factor of structure
representing well-formedness. In what follows,
we reinterpret syntactic generalization based on
the separation of structural and semantic informa-
tion, and we show that our approach outperforms
concurrent methods on unsupervised POS induc-
tion. We also define the notion of abstraction , an
optimization objective specifically conceived for
disentangling semantic information and syntactic
well-formedness.
1.1 Related work
Generative linguists agree on the nativist argument
that learners cannot converge on the same syntax
unless some of their linguistic knowledge is innate
(Baker, 1979; Chomsky, 1965, 1975), which makes
the complete unsupervised learning of syntax im-
possible. Therefore, theoretical linguistics demon-
strated little interest in machine learning and the
interaction between the two fields is limited (Lap-
pin and Shieber, 2007; Linzen and Baroni, 2021).With the recent advent of large language models
(Devlin et al., 2019; Peters et al., 2018; Radford
et al., 2019) it has become relevant to test their lin-
guistic competence (Linzen et al., 2016; Belinkov
and Glass, 2019; Baroni, 2019). Researchers in
NLP thus turned to linguistic theory to create prob-
ing tasks (Alain and Bengio, 2017; Giulianelli et al.,
2018) or test sets targeted at specific linguistic
knowledge (Linzen et al., 2016). Linguistic chal-
lenges like long-distance agreement (Linzen et al.,
2016), hierarchical syntax (Lin et al., 2019; Dyer
et al., 2016; Conneau et al., 2018; Hupkes et al.,
2018), parts of speech (Saphra and Lopez, 2018;
Kim and Smolensky, 2021), or morphology (Be-
linkov et al., 2017; Peters et al., 2018) have been
applied to probe the latest language models with
contrasting results. Recently, probing classifiers
have also been subjected to methodological criti-
cism. Models can succeed on some test tasks by
learning shallow heuristics (McCoy et al., 2019;
Poliak et al., 2018). It was also argued that the
presence of sufficient information to learn a given
task does not entail alone that models rely on it
Ravichander et al. (2021); Hewitt and Liang (2019);
Xu et al. (2020).
On rarer occasions, studies aimed to test the ca-
pacity of language models to predict grammatical-
ity judgments. Out of distribution testing system-
atically shows that the performance drops when
the test data contains natural or artificial exam-
ples which are deliberately different from the train-
ing examples (Lake and Baroni, 2017; Marvin and
Linzen, 2018; Chowdhury and Zamparelli, 2018;
van Schijndel et al., 2019; Maudslay and Cotterell,
2021).
Another branch of model analysis and interpre-
tation studies are concerned with the nature of the
generalization that takes place, with a particular
accent on the notion of compositionality (Loula
et al., 2018; Baroni, 2019; Valvoda et al., 2022).
Among others, Fodor and Lepore (2002) and Kottur
et al. (2017) claim that syntactic compositionality
(Chomsky, 1957, 1965) is a prerequisite to learn
to generalize to complex unseen input. In empir-
ical studies, Gulordava et al. (2018) and Lakretz
et al. (2019) report a lack of compositionality in
the models they analyse, despite their impressive
performance. In contrast, Bastings et al. (2018)
and Valvoda et al. (2022) find that some composi-
tional relations can be learned by neural sequence-
to-sequence models. Chaabouni et al. (2020) argue10577that there is no correlation between the composi-
tionality of an emergent language and its ability to
generalize.
The problem of conflation between semantic and
syntactic information in language models has been
identified (Maudslay and Cotterell, 2021) as a fac-
tor hindering syntactic generalization. A new line
of research is concerned with disentangling syn-
tactic and semantic information in representations
(Felhi et al., 2020; Huang et al., 2021) by adver-
sarial training or syntactic supervision. In order
to incite syntactic generalization in models, Shen
et al. (2020) and (Dyer et al., 2016) propose to in-
tegrate explicit syntactic information for language
modelling. Hu et al. (2020) show that there is a
trade-off between the general language modelling
objective and syntax-specific performance.
Some recent work relies on information theory to
improve our understanding of the syntactic knowl-
edge in LMs. Pimentel et al. (2020) reformulates
probing as approximating mutual information be-
tween a linguistic property and a contextual rep-
resentation. Subsequently, Pimentel and Cotterell
(2021) introduced Bayesian Mutual Information,
a definition that allows information gain through
processing. V oita and Titov (2020) use Minimum
Description Length to measure regularity in LM
representations with respect to the labels to be pre-
dicted in a linguistic probe. Our work builds on
the propositions formulated in Bailly and Gábor
(2020) who address the problem of the learnability
of grammar by separating syntactic and semantic
information in a corpus.
2 Syntactic Representation
2.1 Autonomy of Syntax
The concept of generalization we introduce is based
on the autonomy of syntax (Chomsky, 1957, 1982;
Adger, 2018) reinterpreted in terms of statistical
independence. In the process of linguistic gen-
eralization, learners need to abstract away from
semantic, pragmatic and idiosyncratic lexical in-
formation in the input they are exposed to. With a
string prediction task and likelihood maximization
as a training objective, models have no incentive to
abstract away from these features. One can expect
a statistical learner to ignore sampling noise, but
the above features are relevant to learn the distri-
bution behind a corpus. This insight motivates our
proposition of statistical abstraction , a training ob-
jective that focuses on certain aspects of the inputwhile deliberately ignoring others.
We want our learner to concentrate on the struc-
ture and ignore the factors we call context , i.e. all
the aspects that are unrelated to well-formedness.
We do so by creating two representations of the
input: one of them structured, the other having
structural information removed but co-occurrence
relations conserved.
Let us consider a small artificial example for
illustration. Our observation is a corpus with the
two sentences below:
cats eat mice
men build houses
A valid syntactic generalization would recognize
the sentence
cats build mice
as grammatical. In order to do so, we consider
p(cats eat mice )
as a factor of the probability of the co-occurrence
of its words in the same context :
p({cats, eat, mice })
and a factor of the probability of the words to ap-
pear in a given structure :
p(cats eat mice |{cats, eat, mice })
A syntactic representation with a desirable degree
of generalization would identify the distributional
classes {cats, men },{build, eat },{mice, houses }.
This set of distributional classes can be seen
as a function fthat associates a word (e.g cats)
with its class ( {cats, men} ). Our goal is to study
the properties of such a function so that it can be
considered as achieving syntactic generalization,
for instance:
p(cats eat mice |{cats, eat, mice })
can be deduced from
p(f(cats) f(eat) f(mice) |{f(cats), f(eat), f(mice) })
2.2 Properties of a Syntactic Partition
We define the probability distribution that predicts
the grammaticality of sequences, learned from ob-
servation. In order to do so, we first define a par-
tition of words into abstract categories. This map-
ping, together with the category sequences found
in the corpus, will allow us to induce the grammar.
Behind the corpus data there is a probability dis-
tribution p(ww. . . w). This distribution can be
written as a product of two factors. First, the un-
structured data, i.e. the probability of the elements10578of the vocabulary to occur in the same sequence
without considering their order. Second, the proba-
bility of these elements to be observed in a particu-
lar structure. The contextual information is related
to the former, and the structural information to the
latter.
Let us see a probabilistic interpretation. Let
Abe the vocabulary, one defines the set A=
A\εwhere εis the empty sequence. w=
w. . . w∈Aa sequence (of words) of length n
andp({w, . . . , w})the probability of observing
these elements in the same sequence, in any order.
A trivial decomposition of p(www)would be
p({w, w, w})p(www|{w, w, w})
However, we want structural information to be inde-
pendent of the context. The decomposition above
does not suppose the autonomy of structure. We
propose to transform the above distribution with
a mapping f, which will induce a partition over
the elements of the vocabulary. In what follows,
we examine which properties of this mapping will
ensure that the categories of the resulting parti-
tion do not contain contextual information, while
still preserving the information necessary to predict
grammaticality.
w=w. . . w∈A
|w|=length of w
f(w) =f(w). . . f(w)
f[w] ={w∈A|f(w) =f(w)}
forσ∈S,σ(w) =w. . . w
⟨ ⟨W⟩ ⟩=∪{σ(w)}
µ(w) =card({σ∈S|w=σ(w)})
LetAbe the vocabulary, one defines the set
A=A\εwhere εis the empty sequence.
Letf(w)denote the sequence of categories re-
sulting from the mapping of a word sequence, and
f[w]the set of sequences that map to f(w).W
denotes a set of sequences w. In the case of a
singleton we will denote ⟨ ⟨w⟩ ⟩=⟨ ⟨{w}⟩ ⟩. The con-
textual information will be modeled through the
probability p(⟨ ⟨w⟩ ⟩), where one can see the object
⟨ ⟨w⟩ ⟩as a bag of words, from which the information
of the structure (order) has been erased.
A syntactically relevant representation needs tomeet two criteria: it has to allow to recover the
structure, i.e. the ordering of the bag of words,
and it needs to be independent of contextual in-
formation. The first criterion is defined below as
factorization, the second as minimality.
Factorization. One will say that a mapping f
factorises a distribution pif the order of a bag-
of-words {w}drawn from pcan be entirely de-
duced from the knowledge of the corresponding
categories.
Definition 1. Letpbe a distribution over A, and
f:A∝⇕⊣√∫⊔≀→Bbe a mapping. The distribution pis
factorised byfif there exists a mapping λ(⟨ ⟨w⟩ ⟩)
such that ∀w∈A
p(w| ⟨ ⟨w⟩ ⟩) =λ(⟨ ⟨w⟩ ⟩)p(f[w]| ⟨ ⟨f[w]⟩ ⟩)
in that case, one has λ(⟨ ⟨w⟩ ⟩) =.
In the case where ffactorises p, one will say that
context and structure are independent conditionally
tof.
Independence. As the property of factorization
does not guarantee the complete independence of
structure and context (for instance the identity al-
ways factorises p), we need to limit the information
carried by fto its minimal value in order to reach
this independence. From f[w]one can deduce, at
the minimum, the length of w. The purpose of min-
imality is to ensure that knowing f[w]provides no
further information for finding w:
Definition 2. Letpbe a distribution over Aand
letf:A∝⇕⊣√∫⊔≀→Bbe a mapping. We will say that fis
(information)-minimal for pif
∀w∈A, p(w|f[w]) =p(w|A)
We will say that context and structure are
independent inpif there exists an information-
minimal factorization of p.
2.3 Induced grammar
From a probability distribution pand a mapping
f, it is possible to induce a syntax based on the
observed patterns: a sequence is structurally correct
if its pattern corresponds to an observed pattern.
Definition 3. Letpbe a distribution over Aand
letf:A∝⇕⊣√∫⊔≀→Bbe a mapping. One denotes the
syntax induced by pandfby
w∈ G(p, f)⇔p(f[w])>0
One has for instance G(p, id) = supp(p): this
representation is a memorization with no general-
ization.10579Minimal syntax. A syntax induced by minimal
factorization of pwill be called minimal syntax .
The set of all minimal syntaxes will be denoted
G(p).
It can be shown that the intersection of all mini-
mal syntaxes of pis a minimal syntax of p:
G(p) =∩G(p, f)∈G(p)
Hence, if the independence between context and
structure holds, there exists a canonical way to
define the set of well-structured sequences which
is different from the support of p.
Example 1. Let us consider the first example
above: let pbe the distribution defined by
p(cats eat mice ) =
p(men build houses ) =
then the mapping fdefined by
f(cats) =f(men) =b
f(eat) =f(build) =b
f(mice) =f(houses ) =b
is a minimal factorization of p. The minimal syntax
G(p)is the set
cats eat mice cats eat houses
cats build mice cats build houses
men eat mice men eat houses
men build mice men build houses
3 Geometry of Information
Using information theoretical tools, we transform
the criteria above into metrics and define an infor-
mation space which allows to track the amount of
contextual and structural information in a partition,
as well as the direction of generalization during a
training process.
The concept of minimal factorization provides
the formal definition of minimal syntax; however,
the conditions of factorization (Definition 1) and
minimality (Definition 2) are restrictive. In natu-
ral language corpora, a perfect independence be-
tween semantic context and grammaticality cannot
be expected. Syntax and semantics do interface in
natural language, semantic acceptability interacts
with grammaticality and depending on how one
deals with this interface, either the assumption of
perfect independence or the precise retrieval of the
distribution underlying the corpus may not be met.
This motivates our methodology for relaxing both
conditions in a way that gives an equivalent butquantifiable formulation for each criterion in terms
of information. We thus provide a method to mea-
sure the amount of structural information present
in a partition, hence relaxing the factorization crite-
rion. We also define contextual information , which
relaxes the minimality requirement.
3.1 Structural information
Let
H(p∥q) =−/summationdisplayp(w) log( q(w))
be the cross entropy of the distribution qwith re-
spect to the distribution p.
For a distribution poverA, we will consider
thedistance (in terms of cross-entropy) between p
and the class of factorised distributions.
Definition 4. Letpbe a distribution over Aand
letfbe a mapping. One denotes:
F={q|qis factorised by f}
and one defines the projection of pconditionally to
fby
p= arg minH(p∥q)
The structural information of fwith respect to p
is given by
i(p∥f) =H(p∥p)−H(p∥p)
where zis the null mapping.
The set Frepresents the set of distributions for
which the knowledge of fis sufficient to recover
the order of a sequence. The structural information
is minimal for z, and maximal for the identity (see
Appendix):
i(p∥z) = 0≤i(p∥f)≤i(p∥id)
The link between structural information and fac-
torization is given by:
Lemma 1. Letpbe a distribution over Aand let
f:A∝⇕⊣√∫⊔≀→Bbe a mapping. One has
i(p∥f)is maximal ⇔ffactorises p
3.2 Contextual information
An optimal syntactic representation is one that ful-
fills the independence requirement: the probability
of a sequence of categories does not provide in-
formation about which actual words are likely to10580appear in the sentence. The contextual informa-
tion will measure the amount of lexical or semantic
information that is present in a representation.
Let
H(p) =H(p∥p)
be the Shannon entropy. Let pbe a distribution
overAand let f:A∝⇕⊣√∫⊔≀→Bbe a mapping. One
will denote p◦fthe distribution on Binduced
byf. One has p◦f(f(w)) =p(f[w]).
Definition 5. The contextual information of fwith
respect to pis given by
i(p∥f) =H(p◦f)−H(p◦z)
where zis the null mapping.
From standard properties of Shannon entropy,
i(p∥f)is minimal for z, and maximal for the
identity (see Appendix):
i(p∥z) = 0≤i(p∥f)≤i(p∥id)
The maximum value of i(p∥f)is reached for
H(p◦f) =H(p).
The link between contextual information and
information-minimality is given by:
Lemma 2.
i(p∥f) = 0⇔fis minimal for p
3.3 Representation of a mapping in the
information space
Let us now consider how to represent geomtrically
the two types of information in a partition. For a
given distribution p, any mapping fwill be repre-
sented in Rby its coordinates
x=i(p∥f), y=i(p∥f)
Example 2. Let us consider the same distribu-
tion as in Example 1. Fig. 1 represents all pos-
sible mappings gby the point with coordinates
(i(p∥g), i(p∥g)).
Details are in the Appendix. One can check
that the minimal factorization is in (1,0), and the
second closest mapping to a minimal factorization
is{cats, mice, men, houses }{eat, build }.
4 Abstraction
Abstraction relaxes the definition of a minimal fac-
torization of pin terms of a solution to an optimiza-
tion problem. For a given probability distribution
pand a mapping f, the abstraction measures the
distance between fand the position of a minimal
factorization of pin the information space:
Definition 6. Letpbe a distribution over Aand
letf:A∝⇕⊣√∫⊔≀→Bbe a mapping. Let dbe a distance
onR. Let t= (i(p∥f), i(p∥f))andt=
(i(p∥id),0)). The abstraction (w.r.t. d) is defined
as
α(p∥f) =e
One has α(p∥f)≤1, with the maximum
value reached iff fis a minimal factorization of p.
For a mapping f, maximizing abstraction can be
considered as a relaxation of the property of being
a minimal factorization.
4.1 Minimal Syntax Identification
We prove here that abstraction can be used to iden-
tify the set of minimal syntaxes of pfrom a sample.
Consistency of the plug-in estimator of abstrac-
tion. In the case where the set of of possible se-
quences is infinite, it is not possible to ensure a
convergence rate of the abstraction (cf.(Antos and
Kontoyiannis, 2001)). Nevertheless, it is possible
to show the following consistency result:
Proposition 1. Letpbe a distribution over A, and
letdbe a distance on R. Let ˆpbe the empirical
distribution derived from an i.i.d. sample of size N
drawn from p.
The plug-in estimator for the abstraction
α(p||f)is consistent:
α(ˆp∥f)−→ α(p∥f)a.s.
As a consequence, when the vocabulary Ais
finite, abstraction can be used to isolate the set of
minimal factorizations of p.10581Corollary 1. Letpbe a distribution over A, with
|A|<∞. Letdbe a distance measure on R. Let
ˆpbe the empirical distribution derived from an
i.i.d. sample of size Ndrawn from p.
Then one has:
limP[G(p, f(ˆp))∈G(p)] = 1
where f(ˆp)maximizes abstraction for ˆp.
5 Experiments
We test abstraction as an optimization objective for
learning syntactic representations, when the repre-
sentation takes the form of a mapping into discrete
syntactic categories. The results are evaluated on
an unsupervised POS induction task. While our
understanding of a syntactic category may not per-
fectly overlap with actual parts of speech (the latter
being defined on the basis of a mixture of crite-
ria instead of pure syntax, and are usually more
coarse-grained than real distributional categories),
this task will allow a good comparison with con-
current models on a gold standard.
In NLP, part-of-speech categories are usually a
part of a probabilistic model; typically a parameter
which will be tuned during learning. For instance,
if the model is an HMM, its hidden states corre-
spond to POS categories. If the model is a PCFG,
categories will correspond to non-terminals. We
call this approach - when POS categories are de-
duced from a given model structure as a parameter
- the model-specific approach. In the experiments,
we compare the model-specific approach with our
hypothesis: that POS categories can be deduced
from the independence of structure and context.
We consider the task of unsupervised POS induc-
tion, and compare the accuracy of the abstraction
maximization criterion with model-specific cross-
entropy minimization.
The corpus we use comes from Wikipedia in
simplified English, contains 430k sentences, 8M
tokens, and was POS tagged by the Stanford POS
tagger (Toutanova et al., 2003). To create the target
partition, words (a vocabulary of 6044 elements)
were assigned to their most frequent POS. There
are 36 POS categories.
5.1 The target partition in the information
space
We created (Fig. 2) the information space for the
Wikipedia corpus with the coordinates indicating
structural and contextual information. We repre-
sented the target partition (36 categories, correct
mapping), and located randomly generated modifi-
cations of this partition obtained by changing 1) the
assignment of words to the target POS categories
(in red) and 2) the number of categories between
2 and 2000 (partitions with > 36 categories are in
yellow, partitions with < 36 categories in green)
by merging or splitting existing categories. First,
it can be observed that any random modification
of the target partition (whether it increases or de-
creases the information) comes at the expense of
the abstraction objective. This distinctive position
of the syntactic partition could not be visualized
in one dimension, suggesting the relevance of the
coordinates in the information space in identifying
it.
Second, with a strict constraint on the number
of categories, the representation of the noisy target
(in red) indicates a negative correlation between
contextual information and structural information:
a trade-off induced by the limitation of information
capacity. The choice of normalised ddistance
for abstraction is driven by the shape of random
partitions in the information space (in blue).
5.2 POS induction
We compare abstraction and likelihood maximiza-
tion as training objectives for unsupervised POS
induction. The most efficient POS induction meth-
ods at present are mainly – if not exclusively –10582based on models derived from HMM (Brown et al.,
1992; Merialdo, 1994; Lin et al., 2015; Stratos et al.,
2016; Tran et al., 2016; He et al., 2018). We ex-
periment with different variations of the model
by Brown et al. (1992), because the method is
purely distributional, involves discrete embeddings
and is still competitive (cf. (Stratos et al., 2016;
Christodoulopoulos et al., 2010)).
As we cannot perform a brute-force search for
the best possible partitions for our criteria, we re-
placed it by a local measure of the performance :
for every single word, provided that all other words
are correctly classified, we checked whether the
criterion would attribute the correct POS category.
Accuracy indicates the rate of correctly classified
words.
Tested models We will call plain model the gen-
eral form of a distribution pfactorised by a map-
pingf:
p(f[w])p(⟨ ⟨w⟩ ⟩ | ⟨ ⟨f[w]⟩ ⟩)µ(w)
µ(f(w))
We can add model-specific constraints:
(MK) : Markov constraint for
p(f[w]) =p(f(w))/productdisplayp(f(w)|f(w))
(CI): contextual independence constraint for
p(⟨ ⟨w⟩ ⟩ | ⟨ ⟨f[w]⟩ ⟩) =/productdisplayp(w|f(w))µ(f(w))
µ(w)
We will consider the normalised αabstraction
maximization objective, and the likelihood maxi-
mization objective (with a constraint on the number
of categories) for the plain model alone, with con-
textual independence (CI) constraint, with Markov
(MK) constraint, or with both constraints (MK) +
(CI) (Brown clustering criterion).
The results are shown in Figure 3. They indi-
cate that the abstraction criterion significantly out-
performs likelihood maximization for any model
considered. This reinforces our hypothesis that
syntactic categories emerge naturally from the cri-
terion of independence between structure and con-
text, without any assumption about the structure of
the model.
The second important finding concerns the phe-
nomenon we call implicit disentanglement . By
definition, if we estimate the parameters of a distri-
bution qwith likelihood maximization, we max-
imize structural information (i.e. the partition f
tends towards the right-most solutions in the infor-
mation space). However, contextual information
will still be present. Syntactic generalization may
occur when the encoding capacity of the model
is bounded (e.g. by limiting the number of cate-
gories), inducing a trade-off between structural and
contextual information.
A way to estimate the role of implicit disentangle-
ment is to consider the confusion matrix of cor-
rectly classified or misclassified words for abstrac-
tion maximization classifier (a) and a likelihood
maximization classifier (b), and decompose (b) into
a convex combination of (a) and an independent
classification process (c).
With the confusion matrix for Brown clustering
criterion:
M=/parenleftbiggb b
a0.202 0 .049
a0.212 0 .537/parenrightbigg
one obtains that a proportion F= 0.667of the
correct classification of (b)is imputable to (a), and
at most 33.3%of correct classification by (b)can
be considered as independent from implicit disen-
tanglement. This factor Fis known in literature as
certainty factor (see (Tan et al., 2002), Appendix
for details)
The accuracy of maximum likelihood with the
plain model (no constraint) is a good example of10583implicit disentanglement : it can only be the result
of the limitation on the number of categories. The
hatched part in Figure 3 represents the fraction of
correct classification due to implicit disentangle-
ment in max-likelihood classifiers.
These results indicate that the impact of model
structure in the ability to infer syntactic categories
(and, more broadly, in syntactic generalization ca-
pacity) is over-estimated: parameter tuning seems
far less efficient than the application of the princi-
ple of independence between context and structure.
6 Conclusion
As to our current knowledge, language models do
not have a convincing performance on modelling
grammaticality: despite their impressive results on
downstream tasks, they are not good at syntactic
generalization unless syntactic knowledge is some-
how injected in the system. Moreover, there is a
trade-off in large LMs between syntactic general-
ization and language modelling performance.
We suggest a measurable interpretation of syn-
tactic generalization and show results that align
with the observations reported by many authors:
training on a natural language corpus (e.g. using
language models) results in memorization of se-
mantics and entanglement with syntactic informa-
tion. This motivates our proposition of abstraction,
a new training objective for syntactic generaliza-
tion without supervision. We prove the statistical
consistency of abstraction in the task of grammar
identification. Empirical results on an unsupervised
POS induction task show that abstraction consider-
ably outperforms concurrent models trained with
a likelihood estimation objective, without making
any assumptions about the structure of the model.
7 Limitations
The contribution of this paper is mainly theoretical.
Like most of the POS identification algorithms, the
optimization of a criterion among the space of all
partitions requires the use of heuristics, and finding
the optimum is never guaranteed. Additional work
is required before a generalization model that is
efficient in practice can be obtained.
8 Acknowledgement
We would like to thank Guillaume Wisniewski and
the anonymous reviewers for their valuable com-
ments.References10584105851058610587Appendix – Proofs and complements
Letpbe a probability distribution, and fa mapping.
One will denote p◦fthe probability distribution
induced by f.
Remark 1. One has
⟨ ⟨σ(w)⟩ ⟩=⟨ ⟨w⟩ ⟩
⟨ ⟨f[σ(w])⟩ ⟩=⟨ ⟨f[w]⟩ ⟩
f(σ(w)) =σ(f(w))
p(f[w]) =p◦f(f(w))
p(⟨ ⟨f[w]⟩ ⟩) =p◦f(⟨ ⟨f(w)⟩ ⟩)
Remark 2. One has
p(⟨ ⟨w⟩ ⟩) =1
µ(w)/summationdisplayp(σ(w))
Remark 3. One has
p(⟨ ⟨f[w]⟩ ⟩) =1
µ(f(w))/summationdisplayp(f[σ(w)])
Proof. By Remark 2 applied to p◦fand Re-
mark 1.
Remark 4. One has
⟨ ⟨⟨ ⟨w⟩ ⟩⟩ ⟩=⟨ ⟨w⟩ ⟩
f[f[w]] =f[w]
⟨ ⟨σ(w)⟩ ⟩=⟨ ⟨w⟩ ⟩
⟨ ⟨f[σ(w)]⟩ ⟩=⟨ ⟨f[w]⟩ ⟩
Proof. The second equality comes from
f◦f◦f◦f=f◦f
Lemma 3. Letpbe a distribution over A, and
f:A∝⇕⊣√∫⊔≀→Bbe a mapping. One supposes that there
exists a mapping λ(⟨ ⟨w⟩ ⟩)such that ∀w∈A
p(w| ⟨ ⟨w⟩ ⟩) =λ(⟨ ⟨w⟩ ⟩)p(f[w]| ⟨ ⟨f[w]⟩ ⟩)
then one has λ(⟨ ⟨w⟩ ⟩) =.Proof. One has
/summationdisplayp(σ(w)| ⟨ ⟨σ(w)⟩ ⟩)
=/summationdisplayλ(⟨ ⟨σ(w⟩ ⟩))p(f[σ(w)]| ⟨ ⟨f[σ(w)]⟩ ⟩)
=λ(⟨ ⟨(w⟩ ⟩)
p(⟨ ⟨f[w]⟩ ⟩)/summationdisplayp(f[σ(w)])
=λ(⟨ ⟨(w⟩ ⟩)µ(f(w))
from Remark 1 and Remark 3. With the fact that
p(σ(w)) =p(⟨ ⟨w⟩ ⟩)p(σ(w)| ⟨ ⟨σ(w)⟩ ⟩)
one has
p(⟨ ⟨w⟩ ⟩) =p(⟨ ⟨w⟩ ⟩)
µ(w)/summationdisplayp(σ(w)| ⟨ ⟨σ(w)⟩ ⟩)
=p(⟨ ⟨w⟩ ⟩)λ(⟨ ⟨(w⟩ ⟩)µ(f(w))
µ(w)
hence the result.
Corollary 2. Letpbe a distribution and fbe a
mapping. Then ffactorises piff
p(w) =p(⟨ ⟨w⟩ ⟩(f[w]| ⟨ ⟨f[w]⟩ ⟩)µ(w)
µ(f(w))
Lemma 4. Letpbe a distribution and fa mapping.
Then one has
∀w∈A, p(w|f[w]) =p(w|A)⇔
∀w∈A, p(f[w]) =/braceleftbigg
p(A)or
0
Proof. Suppose the left hand side of the equiva-
lence, then, for any w∈A, either p(f[w]) = 0
or there exists w∈f[w]such that p(w)>0then
p(f[w]) =p(f[w]) =p(A).
On the other way, either p(w) = 0 (and the
equality holds) or p(w)>0implying p(f[w])>
0hence p(f[w]) = p(A)implying in turn
p(w|f[w]) =p(w|A).10588Computing Example 1. Letwbe the sentence
"cats eat rats" and let wbe the sentence "men
build houses". one has
⟨ ⟨w⟩ ⟩= {cats eat mice ,cats mice eat ,
. . . ,mice eat cats }
⟨ ⟨w⟩ ⟩= {men build houses ,
men houses build ,
. . . ,houses build men }
f(w) = bbb
f(w) = bbb
f[w] = {cats eat mice ,cats build mice ,
. . . ,men eat mice ,
men build mice }
⟨ ⟨f[w]⟩ ⟩={cats eat mice ,cats build mice ,
. . . ,build mice men ,
men houses eat }
One has
p(w) =
p(⟨ ⟨w⟩ ⟩)p(f[w]| ⟨ ⟨(f[w]⟩ ⟩)µ(w)
µ(f[w])=
1
2·1·1
1
hence ffactorises p. One has
p(w|f[w]) =
1=p(w|A)
hence fis information-minimal for p.
The Lemma 5 gives a formula for the projection
pofpconditionally to f.
Lemma 5. Letpbe a probability distribution, and
letfbe a mapping. Let us define π(p, f)by
π(p, f)(w) =p(⟨ ⟨w⟩ ⟩)p(f[w]| ⟨ ⟨f[w]⟩ ⟩)µ(w)
µ(f(w))
then one has
p=π(p, f)
One needs a few steps in order to prove
Lemma 5.
Lemma 6. Letpbe a distribution over Aand
f:A∝⇕⊣√∫⊔≀→Bbe a mapping. Then
1.π(p, f)(⟨ ⟨w⟩ ⟩) =p(⟨ ⟨w⟩ ⟩)
2.π(p, f)(f[w]) =p(f[w])
Proof. 1: one has
π(p, f)(⟨ ⟨w⟩ ⟩) =1
µ(w)/summationdisplayπ(p, f)(σ(w))with
π(p, f)(σ(w)) =p(⟨ ⟨w⟩ ⟩)p(f[σ(w)])
p(⟨ ⟨f[w]⟩ ⟩)µ(w)
µ(f(w))
and/summationdisplayp(f[σ(w)])
p(⟨ ⟨f[w]⟩ ⟩)µ(f(w))= 1
hence the result.
2: one has
π(p, f)(f[w])
=p(⟨ ⟨f[w]⟩ ⟩)p(f[f[w]]| ⟨ ⟨f[f[w]]⟩ ⟩)µ(f(w))
µ(f(w))
=p(⟨ ⟨f[w]⟩ ⟩)p(f[w]| ⟨ ⟨f[w]⟩ ⟩)µ(f(w))
µ(f(w))
=p(f[w])
Corollary 3. Letpbe a distribution over Aand
f:A∝⇕⊣√∫⊔≀→Bbe a mapping. Then
1.π(p, f)is a probability distribution.
2.π(π(p, f), f) =π(p, f).
Proof. (1): The ⟨ ⟨w⟩ ⟩form a partition of Ahence
π(p, f)(A) =/summationdisplay
⟨ ⟨⟩ ⟩π(p, f)(⟨ ⟨w⟩ ⟩)
=/summationdisplay
⟨ ⟨⟩ ⟩p(⟨ ⟨w⟩ ⟩) = 1
(2): Since π(p, f)is only computed from
p(⟨ ⟨w⟩ ⟩)andp(f[w]), with the Lemma 6 one has
the conclusion.
Remark 5. In particular, one can give another def-
inition of the set
F={q|qis factorised by f}
as
F={π(q, f)|qis a distribution }
Lemma 7. Letpandqbe two probability distribu-
tions over A, and let f:A∝⇕⊣√∫⊔≀→Bbe a mapping.
Then one has:
H(p||π(q, f))≥H(p||π(p, f))
with equality iff π(q, f) =π(p, f).10589Proof. The inequality is equivalent to
/summationdisplayp(w)/parenleftbigg
log(q(⟨ ⟨w⟩ ⟩)
p(⟨ ⟨w⟩ ⟩))
+ log(q(f[w])p(⟨ ⟨f[w]⟩ ⟩)
p(f[w])q(⟨ ⟨f[w]⟩ ⟩))/parenrightbigg
≤0
By Jensen’s inequality and concavity of the log,
and summing over ⟨ ⟨w⟩ ⟩one has
/summationdisplayp(w)/parenleftbigg
log(q(⟨ ⟨w⟩ ⟩)
p(⟨ ⟨w⟩ ⟩))/parenrightbigg
=
/summationdisplay
⟨ ⟨⟩ ⟩p(⟨ ⟨w⟩ ⟩)/parenleftbigg
log(q(⟨ ⟨w⟩ ⟩)
p(⟨ ⟨w⟩ ⟩))/parenrightbigg
≤0
with equality iff ∀w, q(⟨ ⟨w⟩ ⟩) =p(⟨ ⟨w⟩ ⟩).
By summing over ⟨ ⟨f[w]⟩ ⟩, one has
/summationdisplayq(f[w])p(⟨ ⟨f[w]⟩ ⟩)
q(⟨ ⟨f[w]⟩ ⟩)=
/summationdisplay
⟨ ⟨⟩ ⟩q(⟨ ⟨f[w]⟩ ⟩)p(⟨ ⟨f[w]⟩ ⟩)
q(⟨ ⟨f[w]⟩ ⟩)= 1
and by Jensen’s inequality and concavity of the log,
and summing over f[w]one has
/summationdisplayp(w)/parenleftbigg
log(q(f[w])p(⟨ ⟨f[w]⟩ ⟩)
p(f[w])q(⟨ ⟨f[w]⟩ ⟩))/parenrightbigg
=
/summationdisplayp(f[w])/parenleftbigg
log(q(f[w])p(⟨ ⟨f[w]⟩ ⟩)
p(f[w])q(⟨ ⟨f[w]⟩ ⟩))/parenrightbigg
≤0
with equality iff ∀w, q(f[w]| ⟨ ⟨f[w]⟩ ⟩) =
p(f[w]| ⟨ ⟨f[w]⟩ ⟩).
Because the value of π(p, f)only depends on
p(⟨ ⟨w⟩ ⟩)andp(f[w]| ⟨ ⟨f[w]⟩ ⟩), the equality holds
in the statement iff π(q, f) =π(p, f).
Proof of Lemma 5. One applies Remark 5 and
Lemma 7, and one gets the result.
Separating structure from data.
Our goal is to isolate structural information
form contextual information for an observation
(a, . . . , a).
For any permutation σ∈S, the tuple
(a, . . . , a) = (a, . . . , a)
satisfies a relation
(a, . . . , a) = (a, . . . , a)
which will be denoted σ.Definition 7. For an observation X =
(a, . . . , a), and a permutation σ∈S, let
us denote
σ(X) = (a, . . . , a)
For any probability distribution poverA, one
will define
p(X= (a, . . . , a), Y=σ) =1
n!p(σ(X))
Lemma 8. One has
p(w) =/summationdisplayp(X=σ(w), Y=σ)
p(⟨ ⟨w⟩ ⟩) =|w|!p(X=w)
µ(w)
where |w|is the length of w.
Proof. The first statement is just straightforward
from the definition of p. In particular, one has
p(w) =|w|!p(Y=id, X =w)
One has
p(⟨ ⟨w⟩ ⟩) =1
µ(w)/summationdisplayp(σ(w))
=1
µ(w)/summationdisplayp(X=ρ(σ(w)), Y=ρ)
=/summationtextp(X=σ(w))
µ(w)
and, with the fact that
∀σ∈S, p(X=w) =p(X=σ(w))
one has the result.
Definition 8. Let us define
p(X=w, Y=σ) =
p(X=w)p(Y=σ|f(X) =f(w))
Lemma 9. One has
1.p=p
2.H(p||p) =H(Y|f(X)) +H(X)
3.H(p||p) =H(p||p)−E(log(|w|!))10590Proof. 1. One has
p(X=w, Y=σ) =1
n!p(σ(w))
=1
n!p(⟨ ⟨σ(w)⟩ ⟩)p(f[σ(w)])
p(⟨ ⟨f[σ(w)]⟩ ⟩)µ(σ(w))
µ(f(σ(w)))
with, by Lemma 6 and Lemma 8,
p(⟨ ⟨σ(w)⟩ ⟩) =p(⟨ ⟨w⟩ ⟩) =n!p(X=w)
µ(w)
and
p(f[σ(w)]) =p(f[σ(w)])
=n!p(f(X) =f(w), Y=σ)
and
p(⟨ ⟨f[σ(w)]⟩ ⟩) =p(⟨ ⟨f[w]⟩ ⟩)
=n!p(f(X) =f(w))
µ(f(w)
and one has the result.
The second statement is an application of the
definition of ptogether with statement 1.
The third statement comes from the fact that
p(w) =/summationdisplayp(X=σ(w), Y=σ)
p(w) =|w|!p(X=σ(w), Y=σ)
one has
H(p||p) =−/summationdisplayp(w) log( p((w))
=−/summationdisplayp(X=σ(w), Y=σ)
log(|w|!p(X=σ(w), Y=σ))
=H(p||p)−E(log(|w|!))
Lemma 10. Letpbe a probability distribution, and
letfandgbe two mappings. One has
i(p, g◦f)≤i(p, f)
Proof. From Lemma 9, one has
i(p||f) =H(Y|z(X))−H(Y|f(X))
and one has
H(Y|f(X))≤H(Y|g◦f(X))
hence
i(p||f)≥i(p||g◦f)Lemma 11. Letpbe a probability distribution, and
letfandgbe two mappings. One has
i(p, g◦f)≤i(p, f)
Proof. With the fact that
H(f(w))≥H(g◦f(w))
one has the result.
Details of Example 2 . The two sentences are
strictly equivalent, thus we will only compute the
values for, say, u=cats eat mice .
One has p(⟨ ⟨u⟩ ⟩) =p({cats, eat, mice }=.
Letz:A∝⇕⊣√∫⊔≀→ {a}be a null mapping. By
Lemma 5, one has
p(u) =p(⟨ ⟨u⟩ ⟩)p(z[u])
p(⟨ ⟨z[u]⟩ ⟩)µ(u)
µ(z(u))
with p(z[u]) = p(aaa) = 1 andp(⟨ ⟨z[u]⟩ ⟩) =
p({a, a, a}) = 1 ,µ(u) = 1 andµ(aaa) = 6 , one
hasp(u) =and finally
H(p∥p) = log(12)
One has also p◦z(aaa) = 1 thus
H(p◦z) = 0
One has p(u) =thus
H(p∥p) = log(2) , i(p∥id) = log(6)
andp◦id=pthus
H(p◦z) = log(2) , i(p∥id) = log(2)
Letgbe the mapping
a={cats, mice, men, houses }, b={eat, build }
then one has
p(u) =p(⟨ ⟨u⟩ ⟩)p(g[u])
p(⟨ ⟨g[u]⟩ ⟩)µ(u)
µ(g(u))
with p(g[u]) = p(aba) = 1 ,p(⟨ ⟨g[u]⟩ ⟩) =
p({a, b, a}) = 1 ,µ(u) = 1 andµ(g(u)) =
µ(aba) = 2 one has p(u) =and
H(p∥p) = log(4) , i(p∥g) = log(3)
One has p◦g(aba) = 1 , thus
H(p◦g) = 0 , i(p∥g) = 010591Lethbe the mapping
c={cats, eat, mice }, d={men, build, houses }
then one has
p(u) =p(⟨ ⟨u⟩ ⟩)p(h[u])
p(⟨ ⟨h[u]⟩ ⟩)µ(u)
µ(h(u))
with p(h[u]) = p(ccc) =,p(⟨ ⟨h[u]⟩ ⟩) =
p({c, c, c}) =,µ(u) = 1 andµ(h(u)) =
µ(ccc) = 6 one has p(u) =and
H(p∥p) = log(12) , i(p∥h) = 0
One has p◦h(ccc) =, thus
H(p◦h) = log(2) , i(p∥h) = log(2)
One can check that the gain of information from
ztogis purely structural, while the gain from zto
his purely contextual.
Proof of Proposition 1. From Lemma 9, one has
i(p||f) =H(Y|z(X))−H(Y|f(X))
hence iis a sum of entropies, as well as i.
The Corollary 1 in (Antos and Kontoyiannis,
2001) states that for a countable support target dis-
tribution pwith entropy Hand its M.L.E. pwith
entropy ˆH, the plugin estimator satisfies
limˆH=H a.s.
and this directly implies the conclusion.
Lemma 12. Letpbe a probability distribution,
having a minimal factorization f. Then the inter-
section of all minimal syntaxes of pis a minimal
syntax of p:
G(p) =∩G(p, f)∈G(p)
Proof. Letfbe an optimal factorizations of p. The
property
∀w∈supp(p), p(w|f[w]) =p(w|A)
means that there is only one observed pattern of
categories of length |w|, sayb. . . b.
For any (i, n)∈N, let us define the subset
A={a∈A| ∃w∈A, p(w)>0, w=a}
Each subset Ais entirely inside a class of
the partition induced by f– otherwise there would
be at least two patterns for sequences of size n.One builds a partition mofAby merging the
subsets Awith non-empty intersection. Any
class of mis entirely included in a class induced
byf.
The mapping mis minimal by construction, and
it is a refinement of f:G(p, f)⊆ G(p, f), and, by
Lemma 10, mfactorises p.
Implicit disentanglement. We consider the fol-
lowing matrix of confusion
M=/parenleftbiggb b
a0.202 0 .049
a0.212 0 .537/parenrightbigg
with the equivalence matrix (representing the fact
that classifiers (b) = (a))
M=/parenleftbigga a
a0.251 0
a 0 0 .749/parenrightbigg
and a matrix of an independent classifier (c) with
probability µof success is
M=/parenleftbiggc c
a0.251(1−µ) 0.251µ
a0.749(1−µ) 0.749µ/parenrightbigg
and we write Mas a convex combination of M
andM:
M=λM+ (1−λ)M
This gives
λ= 0.522, µ= 0.408
which leads to the interpretations:
•an independent process of POS identification
involving HMM constraints has a 40% suc-
cess rate.
•the rate of correct classification by (b) is
0.586, decomposed in 0.195of success from
an independent process, and 0.391due to im-
plicit disentanglement.
•66.7% of the overall success rate can be im-
puted to implicit disentanglement.
The fraction of success due to implicit disentan-
glement is exactly the certainty factor F= 0.66710592(see (Tan et al., 2002)) which represents a convex
decomposition of M
M=F.M+ (1−F).M
with:
M=/parenleftbigg0.251 0 .0
0.163 0 .586/parenrightbigg
M=/parenleftbigg0.104 0 .147
0.310 0 .439/parenrightbigg
where Mrepresents a complete implication and
Mrepresents a complete independence, both
with same marginals as M. (see (Tan et al., 2002)
for a definition in the context of association rules)10593ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
section 7
/squareA2. Did you discuss any potential risks of your work?
We cannot imagine any risk
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
/square
/squareA4. Have you used AI writing assistants when working on this paper?
/square
B/squareDid you use or create scientiﬁc artifacts?
section 5
/squareB1. Did you cite the creators of artifacts you used?
section 5
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
The Stanford Log-linear Part-Of-Speech Tagger is under GNU General Public License. Wikipedia is
under (CC-BY-SA) and GDFL.
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
We don’t see any application
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
Not applicable. Left blank.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
section 5
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
section 5
C/squareDid you run computational experiments?
section 5
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
Experiments were conducted on a laptop without GPU, and were mainly illustrative10594/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
The method has no hyper-parameter
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
Not applicable. Left blank.
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
Left blank.
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
Left blank.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
Not applicable. Left blank.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
Not applicable. Left blank.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
Not applicable. Left blank.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
Not applicable. Left blank.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
Not applicable. Left blank.10595