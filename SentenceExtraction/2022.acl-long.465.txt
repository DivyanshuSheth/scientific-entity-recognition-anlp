
Andreas Grivas and Nikolay Bogoychev and Adam Lopez
Institute for Language, Cognition, and Computation
School of Informatics
University of Edinburgh
{agrivas, n.bogoych, alopez}@ed.ac.uk
Abstract
Classifiers in natural language processing
(NLP) often have a large number of output
classes. For example, neural language mod-
els (LMs) and machine translation (MT) mod-
els both predict tokens from a vocabulary of
thousands. The Softmax output layer of these
models typically receives as input a dense fea-
ture representation, which has much lower di-
mensionality than the output. In theory, the
result is some words may be impossible to be
predicted via argmax, irrespective of input fea-
tures, and empirically, there is evidence this
happens in small language models (Demeter
et al., 2020). In this paper we ask whether it
can happen in practical large language models
and translation models. To do so, we develop
algorithms to detect such unargmaxable tokens
in public models. We find that 13 out of 150
models do indeed have such tokens; however,
they are very infrequent and unlikely to impact
model quality. We release our algorithms and
code so that others can test their models.
1 Introduction
Probabilistic multiclass classifiers with a large
number of output classes are commonplace in
NLP (Chen et al., 2016). For example, the vo-
cabulary size of contemporary LMs and MT mod-
els varies from tens to hundreds of thousands (Liu
et al., 2020). Recent advances in modelling such
large vocabularies have mostly been made by im-
proving neural network feature encoders (Devlin
et al., 2019; Conneau et al., 2020). But irrespective
of a feature encoder’s expressivity (Yun et al., 2020;
Raghu et al., 2017), a classifier that linearly maps
lower dimensional features to higher dimensional
outputs has reduced expressivity (Yang et al., 2018),
with consequences that are not well understood.
In this work we elaborate on the consequences of
using argmax prediction with low-rank classifiers,Figure 1: Illustration of an unargmaxable class. Class
ccan never be predicted using argmax for this Softmax
classifier with |C|= 4classes and d= 2input features.
On the left, each feature vector xis colored according
to the class assigned the largest probability; note that
while c,candcsurface as regions, cdoes not. On
the right, we show that there is no direction in feature
space for which chas the largest probability.
classifiers that have more output classes |C|than
features d. For example, MT models often have
subword vocabularies of size |C| ≈30000 , but
haved≈1024 . The expressivity penalty for such
low-rank classifiers is that some output distribu-
tions cannot be represented. Demeter et al. (2020)
identified this weakness in Softmax LMs, showing
that, in theory, some tokens can never be assigned
the highest probability for any input, and therefore
can never be produced as argmax predictions.We
call such tokens unargmaxable (see Figure 1).
While Demeter et al. (2020) proposed an algo-
rithm to detect unargmaxable tokens and provided
evidence of their existence in small LMs, their pro-
posed algorithm provided no guarantees and they
were unable to test large LMs. In this paper we
ask: Do unargmaxable tokens exist in large mod-
els used in practice? To answer this question, we
develop algorithms to identify such tokens unam-
biguously. We tested 7LMs and 143MT models.
Out of those, only 13of the MT models exhibit
unargmaxable tokens, and even for those cases the6738tokens are all noisy and infrequent. We conclude
that although the expressivity constraints of low-
rank Softmax may have important ramifications,
most practitioners do not need to worry about to-
kens that are unargmaxable. We provide new tools
for them to confirm this on their own models.
Our contributions are the following:
•We explain how unargmaxable tokens can
arise as a consequence of a rank constrained
Softmax layer (Softmax Bottleneck).
•We extend the work of Demeter et al. (2020)
with verification algorithms that include the
Softmax bias term and provide an exact an-
swer rather than an approximate one.
•We verify a large number of commonly used
publicly available language and translation
models for unargmaxable tokens.
•We release our algorithm so that others can
inspect their models.
2 Background
2.1 Low-Rank Softmax (Softmax Bottleneck)
Neural network layers with higher dimensional
outputs than inputs impose low-rank constraints.
Such constraints commonly exist as bottlenecks
in neural network hidden layers, e.g. autoen-
coders (Hinton and Zemel, 1994) and projection
heads in multi-head transformers (Bhojanapalli
et al., 2020) among others. While bottlenecks make
a model less expressive by restricting the functions
it can represent, they are desirable both compu-
tationally (Papadimitriou and Jain, 2021), since
they require less memory and computation than
full-rank layers, and as a form of inductive bias,
since data is assumed to approximately lie in a low
dimensional manifold (McInnes et al., 2018).
In contrast, herein we focus on the undesirable
properties of a Softmax output layer with a low-
rank parametrisation, also known as a Softmax
Bottleneck (Yang et al., 2018). The crucial differ-
ence is that a Softmax Bottleneck is usually not fol-
lowed by a non-linear transformation, and as such
the rank constraint limits expressivity in a very
rigid way by restricting outputs to a subspace.
This constraint was shown to hurt LM perplex-
ity (Yang et al., 2018) and non-linear augmenta-
tions have been proposed as improvements (Yang
et al., 2018; Kanai et al., 2018; Ganea et al., 2019).
To the contrary, Sainath et al. (2013) used a low-
rank factorisation of the softmax layer to reduce the
number of parameters in their speech recognition
system by 30-50% with no increase in word-error-
rate, evidencing that the loss in expressivity does
not always impact aggregate metrics.
The consequences of the loss in expressivity due
to the Softmax Bottleneck vary depending on our
perspective. When considering the flexibility of the
probability distribution that can be learned, Ganea
et al. (2019, Theorem 2) showed that the minimum
cross entropy loss achievable decreases as we in-
crease the rank of the Softmax layer weights.
In this work we focus on the loss of expressiv-
ity from an argmax perspective. To this end, we
discretise the output space of Softmax and quan-
tify the loss in expressivity in terms of unrealisable
class rankings. From this interpretable perspec-
tive we will see that due to the Softmax Bottleneck
some rankings are not realisable and unargmaxable
classes can arise as a consequence.
2.2 Unargmaxable Classes
Demeter et al. (2020) showed that a class is
unargmaxable if its Softmax weight vector is in-
terior to the convex hull of the remaining class
weight vectors. They did so by proving that the
interior class probability is bounded above by the
probability of at least one class on the convex hull
(see Figure 2 and Cover, 1967, Figure 1). How-
ever, in their analysis they did not address Softmax
layers that include a bias term. We address this
limitation in Section 3, thus enabling us to search6739for unargmaxable classes in any released model.
To detect whether unargmaxable tokens arise in
LMs without a bias term, the authors introduce
an approximate algorithm that asserts whether a
weight vector is internal to the convex hull. It is
approximate since their method had a precision
approaching 100% but 68% recall when compared
to an exact algorithm (Qhull, Barber et al., 1996)
on the first 10dimensions of a Softmax LM. In
Section 3.3 we introduce an exact algorithm to
detect unargmaxable tokens with certainty.
The authors use their approximate algorithm to
show that AWD-LSTM LMs (Merity et al., 2018)
“steal” probability from candidate interior words
when contrasted to the probabilities assigned by
a smoothed n-gram LM. However, they find that
as they increase the dimensionality dof the Soft-
max weights to 200, the effect of stolen probability
begins to dissipate. This raises the question of
whether stolen probability is of importance for neu-
ral models used in practice which also have larger
Softmax weight dimensionality.
Herein we specifically search for unargmax-
able tokens in MT and LM models with larger
d∈[256,512,1024] . We use the term unargmax-
able rather than stolen probability to highlight that
we are focussing on whether unargmaxable tokens
exist and not whether the probability distibution
learned by low-rank Softmax is less flexible. We
extend our analysis to MT models since they have
more practical use cases than (generative) LMs: if
unargmaxable tokens exists in a MT model, then
the affected tokens can never be produced when
using greedy decoding. In our experiments we find
that while unargmaxable tokens arise in limited
cases, they are not of grave importance.
3 Detecting Unargmaxable Classes
In order to quantify whether unargmaxable classes
arise in released LMs and MT models, we first
need to introduce tractable algorithms for detecting
them. In this Section we explain how unargmax-
able classes can arise due to a Softmax Bottleneck.
Then, we introduce a fast approximate algorithm
and a slow exact algorithm which we combine to
detect vocabulary tokens that cannot be predicted.
3.1 Definitions
We use boldface for matrices and vectors. All vec-
tors are column vectors. We use wfor the ith row
ofWandbfor the ith element of b.3.1.1 Softmax
A Softmax layer gives us the probability assigned
to a target class cfor an input feature vector x∈
Ras follows:
P(C=c|x) =e
Pe(1)
= softmax( Wx+b) (2)
where W∈Rare the class weight vectors
stacked row by row, and b∈Ris the bias term.
The above are used to compute the logits y=
Wx +b. In what follows, we will refer to the
feature activations xinRas the input space and
the logits yinRas the output space of the
Softmax layer.
3.1.2 Discretising the Output Space into
Permutations
As we saw in Figure 2, there are certain arrange-
ments of Softmax weights for which a target class
ccannot be surfaced as the argmax. To understand
this phenomenon, it will be helpful to discretise
the outputs to a finer granularity: rankings (Burges
et al., 2005). In order for a classifier to predict a
classcusing an argmax decision rule, it must rank
cabove all other classes by assigning it the largest
probability. From this perspective, a classifier as-
signs each input xa permutation πthat ranks the
class indices in increasing order of probability.
(3)
As an example, if we have 4 classes and obtain
probabilities P(C|x) =
.2.4.1.3we
assign xthe permutation π, since P(c|x)<
P(c|x)< P(c|x)< P(c|x). We can
readily obtain the coarser argmax decision ( c) by
reading off the last index of the permutation.
3.2 How Can Unargmaxable Classes Arise?
A class cis unargmaxable when all permutations
that rank cabove the rest cannot be realised due
to rank constraints. We explain how this happens
by combining the following two observations.
Observation 1. We can discretise Rinto re-
gions corresponding to permutations by segment-
ing the space with hyperplanes.
The hyperplanes that partition the output space
into regions Rcorresponding to permutations are
a well known structure in Combinatorics, the Braid6740Observation (1):
Discretise Rinto permutationsObservation (2):
Observe rank constraints(1) & (2) =⇒Corollary 1:
Feasible permutations
Hyperplane Arrangement (Stanley, 2004).The
Braid Arrangement for 3 and 4 classes is illustrated
in rows 1 and 2 of Figure 3 respectively.
In order to be able to rank the classes according
to permutation R, our network needs to be able
to map an input xto region Rin the output space.
However, this is not always possible when we have
a Softmax Bottleneck as we elaborate below.
Observation 2. When we have rank constraints,
only a subspace of Ris feasible .
Case i) softmax( Wx). By calculating y=
Wx, the class logits yare a linear combination
ofdcolumns of W. Therefore, when d <|C|
we can only represent a d-dimensional subspace of
Rat best. This feasible subspace is illustrated as
a grey plane in the middle column of Figure 3.
Case ii) softmax( Wx+b). If we also have a
bias term bthe model can choose how to offset
the subspace. When the bias term bis not in thecolumn space of Wthe zero vector 0is no longer a
feasible yand instead of a linear subspace we have
an affine subspace. See Figure 7 in the Appendix
for an illustration comparing the two cases.
Corollary 1. A Softmax classifier parametrised
byWandbcan rank classes in the order of per-
mutation πiff the affine subspace spanned by W
andbintersects region Rof the Braid Arrange-
ment .When d <|C| −1there are regions that
cannot be intersected.The feasible permutations
in our example correspond to the regions formed
on the grey plane illustrated in the rightmost col-
umn of Figure 3. Note that for |C|= 4only 12 out
of 24 regions can be intersected.
As we make the Softmax Bottleneck narrower
by reducing the dimension dof the Softmax inputs,
more permutations become infeasible (Good and6741Tideman, 1977; Kamiya and Takemura, 2005). Im-
portantly, if we choose |C|anddand whether to
use a bias term, changing the values of the Softmax
weights changes the set of feasible permutations but
not the cardinality of the set (Cover, 1967; Smith,
2014). See Appendix C for more details.
Corollary 2. Class cis unargmaxable when any
permutation that would rank class cabove all
other classes is infeasible.
3.2.1 Effect of Softmax Bias Term
Without a bias term the regions corresponding to
permutations are unbounded (see the rightmost col-
umn of Figure 3). As such, imposing any range
restrictions on the Softmax layer inputs xdoes
not change the feasible regions as long as the re-
striction includes the origin. However, when we
introduce a bias term we also get bounded regions
(see Figure 7 in the Appendix that contrasts the
two situations). Therefore, in this case the scale of
the inputs to the Softmax layer also matters. If the
inputs do not have a large enough range, there will
be regions that exist but cannot be reached by the
feature encoder.
3.3 Exact Algorithm
Given a softmax layer parametrised by Wandb,
are there any classes that are unargmaxable? We
first describe a slow, but exact algorithm to answer
this question.
An exact algorithm will either prove class c
is argmaxable by returning a feasible point x:
argmax ( Wx+b) = cor it will prove cis
unargmaxable by verifying no such point exists.
To check if a region exists that ranks cabove
all others, we need to find an input x∈Rthat
satisfies the following constraints:
(4)
Each of the above constraints is equivalent to re-
stricting xto a halfspace (see Appendix A). Hence,
if all above inequalities are enforced, xis restricted
to an intersection of halfspaces.
(w−w)x+ (b−b)<0
∀i: 1≤i≤ |C|, i̸=t(5)
If the intersection of halfspaces is empty, there is
noxfor which class ccan be ranked above all
others - and hence cis unargmaxable. We can find
a point in an intersection of halfspaces via linearprogramming, albeit we found this algorithm to be
slow in practice for |C|>1000 .
3.3.1 Chebyshev Center Linear Programme
The Chebyshev center of a polytope (Boyd et al.,
2004, p. 417) is the center of the largest ball of
radius rthat can be embedded within the polytope.
We can find the Chebyshev center xand the radius
rwith the following linear programme.
maximise r
subject to wx+r∥w∥≤ −b,
x≤100
x≥ −100
r >0 (6)
Where w=w−wandb=b−b,∀i:
c̸=c. We further constrain xto guarantee the
regions are bounded, since the Chebyshev center
is not defined otherwise. This constraint also cap-
tures the fact that neural network activations are
not arbitrarily large.
If the above linear programme is feasible, we
know that class cis argmaxable and we also get
a lower bound on the volume of the region for
which it is solvable by inspecting r. On the other
hand, if the linear programme is infeasible, cis
unargmaxable.
3.4 Approximate Algorithm
The exact algorithm was too slow to run for the
whole vocabulary. In order to avoid running the ex-
act algorithm for every single vocabulary item, we
developed an incomplete algorithm (Kautz et al.,
2009) with a one-sided error, which can quickly
rule out most tokens, leaving only a small number
to be checked by the exact algorithm. It proves that
cisargmaxable by finding an input xfor which
chas the largest activation. Unlike the exact al-
gorithm, if no solution exists it cannot prove that
the token is unargmaxable . Hence, we terminate
our search after a predetermined number of steps.
We denote any tokens not shown to be argmax-
able by the approximate algorithm as potentially
unargmaxable and we run the exact algorithm on
them. An illustration of the way we combine the ex-
act and approximate algorithms to decide whether
classcis argmaxable can be seen in Figure 4.
3.4.1 Braid Reflect
The idea behind this approximate algorithm is to
use the Braid Hyperplane Arrangement as a map6742
Algorithm 1: Braid reflection step
Data: Class index c,x∈R,
W∈R,b∈Rc= argmax( Wx+b)w= (w−w)b=b−bw=d=wxx=x−2(d+)w
to guide us towards a point xfor which chas the
largest activation. To show that class cis argmax-
able, it suffices to find an input xfor which the
largest probability is assigned to c. Empirically
we found this to be easy for most classes.
We begin by interpreting the actual weight vec-
tor as the candidate input x=w. We do so since
the dot product of two vectors is larger when the
two vectors point in the same direction.While
the magnitude of the vectors affects the dot prod-
uct, we found the above initialisation worked well
empirically. When cis not the argmax for xand
cis instead, Relation 5 for candcwill have the
wrong sign. The sign of this relation defines which
side of the Braid hyperplane for candcwe are on.To correct the sign, we construct the normal vector
and offset of the Braid hyperplane (Lines 2, 3 in
Figure 5), compute the distance of xfrom it (Line
5), and reflect xacross it (Line 6).We repeat the
above operation until either cis the argmax or we
have used up our budget of Nsteps.
4 Experiments
In this Section we use the combined algorithm from
Figure 4 to search models for unargmaxable tokens.
We test 7LMs and 143MT models. We find
that unargmaxable tokens only occur in 13MT
models, but these are mostly infrequent and noisy
vocabulary tokens. We therefore do not expect such
tokens to affect translation quality per se.
We also find that nearly all vocabulary tokens
of LMs and student MT models can be verified
with less than N= 10 steps of the approximate
algorithm. In contrast, other MT models need thou-
sands of steps and also rely on the exact algorithm.
In this sense, models that need fewer steps are eas-
ier to verify: the search problem for their arrange-
ment of Softmax weights is easier.
Throughout the following experiments we as-
sumed the Softmax inputs were bounded in magni-
tude for all dimensions −100≤x≤100. As we
mentioned in Subsection 3.2.1, if we have a Soft-
max bias term, there are bounded regions. If the
bounded regions are large, even though the outputs
are not theoretically bounded, they are practically
bounded since neural network feature encoders can-
not produce arbitrarily large activations and some
regions may be unreachable. For the approxi-
mate algorithm, we search for a solution with a
patience of N= 2500 steps and resort to the ex-
act algorithm if the approximate method fails or
returns a point outside the aforementioned bounds.
We use Gurobi (Gurobi Optimization, 2021) as the
linear programme solver. We accessed the model
parameters either via NumPy (Harris et al., 2020)
or PyTorch (Paszke et al., 2019). The experiments
took 3 days to run on an AMD 3900X 12-core CPU
using 10threads and 64Gb of RAM.
4.1 Language Models (0/7 Unargmaxable)
We checked 7widely used LMs for unargmax-
able tokens. While some of these models such as6743BERT (Devlin et al., 2019) are not directly used for
generation, a recent trend is to use these large LMs
as prompt models (Liu et al., 2021) for few shot
learning. A prompt model obviates the need for
a separate classifier by rephrasing a classification
task as slot filling given a task specific template.
Prompt approaches commonly choose the answer
for the slot by argmaxing the Softmax distribution
obtained by a LM. Hence we verify that there are
no answers that are unargmaxable.
BERT, RoBERTa (Liu et al., 2019), XLM-
RoBERTa (Conneau et al., 2020) and GPT2 (Rad-
ford et al., 2019) did not exhibit any unargmaxable
tokens and can be assessed without resorting to
the exact algorithm (see Table 4 in the Appendix).
Moreover, the LMs were very easy to verify with
the approximate algorithm requiring less than 1.2
steps per token on average.
4.2 Machine Translation (13/143
Unargmaxable)
In the case of MT models, the feature encoder
comprises the whole encoder-decoder network ex-
cluding the last layer of the decoder. We first focus
on models which we found to have unargmaxable
tokens and then briefly describe models that did
not. A summary of the results and characteristics
of the models we checked can be seen in Table 1.
More detailed results can be found in Tables 5, 6,
7 and 8 in the Appendix.
Helsinki NLP OPUS (13/32 Unargmaxable).
The32models we use for this subset of experi-
ments are MT models released through Hugging
Face (Wolf et al., 2020). We use models introduced
in Tiedemann and Thottingal (2020). These mod-
els are trained on subsets of OPUS. All models are
transformer models trained using Marian (Junczys-
Dowmunt et al., 2018). They include a bias term,
have a tied encoder and decoder and d= 512 .
Unargmaxable tokens, if present, will affect gen-
eration in the target language. We therefore restrict
our analysis to the target language vocabulary. Tofacilitate this, we inspect translation models for
which the source and target languages have differ-
ent scripts. We explore 32models with source and
target pairs amongst Arabic (ar), Hebrew (he), En-
glish (en), German (de), French(fr), Spanish (es),
Finnish (fi), Polish (pl), Greek (el), Russian (ru),
Bulgarian (bg), Korean (ko) and Japanese (ja). We
rely on the script to disambiguate between source
and target language and discard irrelevant tokens
from other languages. We also ignore vocabulary
tokens containing digits and punctuation.
In Figure 6 we can see the number of Byte Pair
Encoding (BPE; Sennrich et al., 2016) tokens that
were unargmaxable for these models, sorted in
decreasing order. As can be seen, all tokens are
argmaxable for 19/32language pairs. For the re-
maining 13languages, while there can be quite
a few unargmaxable tokens, most would not be
expected to affect translation quality.
Out of the set of 427 unique unargmaxable
BPE tokens, 307/476 are single character sub-
word tokens and only 2are word stem BPE seg-
ments: erecti (bg-en) and Предварительны (en-
ru) which means “preliminary” in Russian. The
rest include the <unk> token and noisy subword
unicode tokens such as ´ к´К´К´ к,ὶῖῖandἀὐῇ.
On closer inspection of the SentencePiece to-
keniser we found that both Предварительны
and erecti come up as tokenisation alternatives
that make them rare and irregular. We found
that theПредварительны token was rare since
it is capitalised and only occurs once, while an-
other occurrence was caused by a BPE segmen-
tation corner case due to Unicode token variation
ofПредварительны-e . Other mentions having
Предварительны as a substring were split differ-
ently. In a similar vein, we found that the erecti
token occurred due to BPE corner cases for erecti-0-
n,erecti-lis-) ,erecti-l ,erecti-. and erecti-cle many
of which are misspellings or rare word forms from
clinical text. As such, the impact of these tokens
being unargmaxable is small since there are alter-
native ones the MT model can prefer over them
which could even correct spelling mistakes.
FAIR WMT’19 (0/4 Unargmaxable). We
checked 4 FAIR models (en-ru, ru-en, en-de, de-
en) submitted to WMT’19 (Ng et al., 2019). These
transformer models have d= 1024 and do not
employ a Softmax bias term.
None of the FAIR models were found to have
unargmaxable tokens, but for some tokens we had6744
to rely on the exact algorithm to show this.
Edinburgh WMT’17 (0/82 Unargmaxable).
These WMT’17 submissions (Sennrich et al., 2017)
were ensembles of left-to-right trained models (l2r)
and right-to-left trained models (r2l). These were
LSTMs trained with Nematus using d= 500 or
d= 512 and Softmax weights tied with the decoder
input embeddings. The models include a bias term.
None of the models have unargmaxable tokens.
However, we found that models that comprise an
ensemble varied a lot in how easy it was to show
that the vocabulary was argmaxable, despite them
differing solely in the random seed used for weight
initialisation. As an example, zh-en.l2r(1) had 8to-
kens that needed to be verified with the exact algo-
rithm, zh-en.l2r(2) had 3and zh-en.l2r(3) had 366.
This highlights that random initialisation alone is
enough to lead to very different arrangements of
Softmax weights.
Bergamot (0/25 Unargmaxable). The Berg-
amot projectmodel repository contains both large
transformer-base and transformer-big teacher mod-
els, as well as small knowledge distilled (Kim and
Rush, 2016) student models. Student models have
d= 256 (tiny) or d= 512 (base), while teacher
models have d= 1024 . Interestingly, we find that
it is easier to show that student models are argmax-
able when compared to teacher models, despite
student models having Softmax weights 1/2or1/4
the dimensions of the teacher model.
5 Discussion
We conclude from our experiments that it is pos-
sible to have unargmaxable tokens, but this rarely
occurs in practice for tokens that would lead to
irrecoverable errors in the MT models we checked.
A limitation of our conclusions is that beam search
is usually preferred over greedy decoding for MTmodels used in practice. We leave the question of
whether unargmaxable tokens also impact beam
search for future work.
It is challenging to make exact claims about what
can cause tokens to be unargmaxable because the
models we tested varied in so many ways. However,
we outline some general trends below.
5.1 Infrequent Tokens Are the Victims
The most general observation is that the tokens that
are more likely to be unargmaxable or are hard
to prove to be argmaxable are the infrequent ones.
This can be seen in Figures 11 and 12 in the Ap-
pendix, where the x-axis contains the vocabulary
of the models sorted left to right by increasing fre-
quency. Each dot represents the number of steps
needed to check whether a token is argmaxable or
not, and as can be seen the values to the right are
generally much higher than those to the left.
This result is in line with previous work that high-
lights the limitations of the Softmax layer when
modelling rare words for LM (Chen et al., 2016;
Labeau and Cohen, 2019) and MT (Nguyen and
Chiang, 2018; Raunak et al., 2020) and infrequent
classes for image classification (Kang et al., 2020).
5.2 Some Models Are Easier to Verify
We found that the LMs and student MT model
vocabularies can be shown to be argmaxable with
one step of the approximate algorithm on average.
On the other hand, for Helsinki NLP and FAIR MT
models more than 10steps were needed.
To put the above observations into context, we
also check the behaviour of our algorithms on ran-
domly initialised parameters. If we initialise a Soft-
max layer of |C|= 10000 classes using a uniform
distribution U(−1,1)we do not expect unargmax-
able tokens to exist after d= 30 (see Figure 10 in
the Appendix). Moreover, any randomly initialised
parameters can be checked using the approximate
algorithm with fewer steps as we increase d.
From this perspective, it is surprising that student
models were easier to show to be argmaxable than
the teacher models, despite the Softmax weight
dimensionality of the student models being much
lower (256 for tiny, versus 1024 for teacher). This
shows that effective neural MT models do not need
to be hard to check, but nevertheless neural models
trained on the original data can sometimes converge
to such an arrangement of weights.67456 Conclusions and Future Work
In this work we discretised the outputs of Soft-
max and showed how dimensionality constraints
shrink the set of feasible class rankings and can
lead to some classes being impossible to predict
using argmax. In our experiments we demonstrated
that while MT models can have unargmaxable vo-
cabulary tokens, this does not occur often in our ex-
periments. Moreover, for the models we tested the
unargmaxable tokens would not create discernible
differences in translation quality as the tokens are
noisy and infrequent. We release an algorithm to
detect whether some classes are unargmaxable with
the hope that this will be helpful to the wider com-
munity working on a plethora of different models
where the observed phenomena may vary.
In future work, we aim to investigate any learn-
ability consequences more closely. As we saw,
when using an approximate search algorithm, it is
much harder to find argmaxable classes in some
models than it is in others. Since gradient de-
scent algorithms are also iterative search algorithms
seeking optimal parameters, we hypothesise that
it will be challenging to train neural network en-
coders to map activations to regions of the input
space that a search algorithm cannot find easily.
Hence, although some tokens may not be provably
unargmaxable because of constraints imposed by
the Softmax parameters of the last layer, some to-
kens may still be very hard to produce because of
difficulties encountered by the feature encoder. To
this end, a more holistic investigation into the con-
sequences of the loss in expressivity in low-rank
classifiers is warranted.
Broader Impact
Unargmaxability directly impacts fairness, since
certain model outputs, further from being under-
represented, may not be represented at all. As we
discussed, low-rank classifiers have limited expres-
sivity compared to full rank classifiers, and thus
have to explicitly choose which rankings of classes
to retain feasible when using argmax prediction.
As such, by choosing to use a low-rank model,
we are allowing the data and training procedure to
specify which rankings should remain feasible, and
harmful biases in our data can be propagated and
further exacerbated (Hooker, 2021) by our models
due to unargmaxability. For example, it could be
the case that underrepresented groups find no rep-
resentation in the outputs of such models, in theextreme case where related outputs are unargmax-
able. As researchers, we should be aware of this
limitation when choosing how to parametrise our
models (Hooker et al., 2019) and actively seek to
either control such phenomena or verify models
are not harmful before moving them from research
into production.
In addition to the above considerations, linear
classification layers are vulnerable to targeted at-
tacks via data poisoning techniques (Goldblum
et al., 2020), especially under the scenario where
shared models are used as feature extractors (Ji
et al., 2018). A subset of such techniques, known
as feature collisions (Shafahi et al., 2018; Gold-
blum et al., 2020), exploit the arrangement of the
training examples in feature space to force the mis-
classification of a target example. Attacks such as
Convex Polytope (Zhu et al., 2019) and Bullseye
Polytope (Aghakhani et al., 2021), specifically tar-
get the unargmaxability weakness (Cover, 1967;
Demeter et al., 2020) we elaborated on in the pa-
per. While such attacks assume they are able to
inject examples into a training set used for fine-
tuning, this is not an unrealistic assumption. This
is especially true for recommender systems, where
adversarial attacks can create fake users such that
a target item is removed from a target user’s top-k
list (Christakopoulou and Banerjee, 2019).
Acknowledgements
We thank Seraphina Goldfarb-Tarrant, Elizabeth
Nielsen and Sabine Weber for help with languages,
Beatrice Alex, Sameer Bansal, Panagiotis Eu-
stratiadis, Sharon Goldwater, Chantriolnt-Andreas
Kapourani, Oli Liu, Yevgen Matusevych, Kate Mc-
Curdy, Laura Perez-Beltrachini, Jesse Sigal, Mark
Steedman, Ivan Titov and Sabine Weber for feed-
back and support, Antonio Vergari for feedback,
guidance and tirelessly discussing low-rank con-
straints and Shay Cohen for insightful suggestions
and for pointing us to OEIS. We also thank David
Demeter for an extensive discussion on Stolen Prob-
ability and the anonymous reviewers for helpful
questions and comments.This work was supported by the Engineer-
ing and Physical Sciences Research Coun-
cil [grant number EP/R513209/1] and Research and
Innovation Action Bergamot , which has received
funding from the European Union’s Horizon 2020
research and innovation programme under grant
agreement No 825303.6746References67476748
A Halfspace interpretation
As promised, here is the derivation showing that if
P(c|x)< P(c|x)thenxis constrained to a
halfspace.
We have:
P(c|x)< P(c|x)⇐⇒
e
Pe<e
Pe⇐⇒
e< e⇐⇒
e
e<1⇐⇒
e< e⇐⇒
(w−w)x+ (b−b)<0(7)
xis therefore constrained to a halfspace defined by
normal vector w−wand offset by b−b.
This linear form defined by the normal vector and
offset is the “shadow” in the input dimension of
our friend, the Braid Arrangement, as we will make
clear in the next Section (see Derivation 11).6749
B Hyperplane Arrangements
Excellent resources to learn more about hyper-
plane arrangements are Stanley (2004) and Fed-
erico Ardila’s lectures on polytopes (see Lecture
34 onwards). Connections between hyperplane ar-
rangement theory and Machine Learning can be
found in Mackay (2004, Chapter 40). For those
who prefer a more gentle introduction via a hands
on approach, Sagemath (The Sage Developers,
2021) contains implementations of many hyper-
plane arrangements and functions that we found
useful when learning this material. We give a brief
introduction to hyperplane arrangements below.
Ahyperplane in a vector space Ris an affine
subspace of dimension d−1. The hyperplane H
has one degree of freedom removed by specifying
a constraint: a normal vector w∈Rto which it is
perpendicular. The hyperplane may also be offset
bybin that direction H={x∈R:wx=b}.
Areal hyperplane arrangement Ais defined as a
set of nhyperplanes in R,A={H,H. . .H}.
The set of regions Rdefined by a hyperplane ar-
rangement Aare the connected components Xof
Euclidean space Rleft when we remove the hy-
perplanes A, namely X=R−SH. As an
example, Subfigure (a) in Figure 7 has 12 regions
while Subfigure (c) has 18 regions.
B.1 Braid Arrangement
The Braid Arrangement Bis a hyperplane arrange-
ment that partitions space into n!regions corre-
sponding to permutations. It can be constructed in
Rfrom the standard basis, the rows of the identity
matrix I,e= row(I),e∈R, by taking all 
pairs of differences between them, each differ-ence defining the normal vector of a hyperplane
Hof the Braid Arrangement.
B={H∀i, j: 1≤i < j≤n},
H={x∈R: (e−e)x= 0}(8)
The Braid Arrangement for n= 3andn= 4can
be seen in Figure 3. It has 
hyperplanes, one per
pair of dimensions in R. Hence there are 3hyper-
planes for |C|= 3and6hyperplanes for |C|= 4.
As an example, when we have 4classes the normal
vector for Hisw=
1 0 −1 0. As
can be verified by taking the dot product wx,
the result is positive if x>xand negative if vice
versa. Therefore, each hyperplane bisects space
into two regions one for each possible ranking of
the pair of coordinates.
To see how the hyperplanes intersect to give us a
region R, we express a permutation (total order)
over|C|classes, such as that in Relation 3, using a
chain of |C| −1pairwise inequalities.
P(c|x)< P(c|x),1≤i≤ |C| −1
(9)
Each above constraint is equivalent to choosing a
side of a braid hyperplane. By imposing all con-
straints, we obtain a region Ras the intersection
of|C| −1halfspaces. There is therefore bijec-
tion between permutations and regions of the Braid
Arrangement π↔ R.
B.2 Restricting the Braid Arrangement to
Lower Dimensions
In the Softmax layer of a neural network we often
compute the output space activations y∈Rby
applying a final affine layer to the Softmax input6750space x∈R.
y=Wx+b,W∈R,b∈R(10)
What do the Braid Arrangement hyperplanes look
like in the input dimension d? Let us start from the
output space Rand work backwards towards the
input space R.
y< y=⇒(e−e)y<0
ey−ey<0
e(Wx+b)−e(Wx+b)<0
wx+b−wx−b<0
(w−w)x+ (b−b)<0
(11)
We therefore see that if d < n we can think of
how the Braid Arrangement classifies outputs into
permutations from two equivalent perspectives:
•In the output space Rnot all yare feasible,
we can only classify an input xas a permu-
tation πif the affine layer can map xtoR.
This can be seen in Subfigures b and d of Fig-
ure 7 where the feasible outputs are a plane
that intersects the Braid Arrangement.
•In the input space Rallxare feasible but we
only see the projection of the Braid Arrange-
ment in this lower dimension. This can be
seen in Subfigures a and c of Figure 7.
The construction of the Braid Arrangement in
the input space is illustrated in Figure 8, albeit
without the bias term.
C Number of Regions (Feasible
Permutations) of the Restricted Braid
Arrangement
The number of feasible permutations is invariant to
specific choices of Wandb(Cover, 1967; Smith,
2014) and only depends on the dimensionality of
the softmax inputs d, the number of classes |C|
and whether we specify a bias term bnot in the
columnspace of W. Namely, the cardinality of
the set of feasible permutations does not change,
but the members of the set do - they depend on
the specific values in Wandb. There exists a
recurrence formula to obtain the number of feasible
permutations for a particular |C|andd(Good and
Tideman, 1977; Kamiya and Takemura, 2005). See
our code and the relations in (Smith, 2014) for
more details.
C.1 Softmax with no Bias Term
The number of feasible permutations as a function
of|C|anddwhen we have a Softmax with no bias
term can be seen in Table 2. When d≥ |C| −1all
permutations corresponding to ways of ranking |C|
classes are feasible (table cells with d=|C| −1
are highlighted in bold). However, as we make
the Softmax Bottleneck narrower, we can represent
less permutations, as can be seen from the numbers
reported below the diagonal.
C.2 Softmax with Bias Term
The number of feasible permutations as a function
of|C|anddwhen we have a Softmax with a bias
term is larger as can be seen in Table 3. As we
saw in Figure 7, this is because a bias term can
offset the representible linear subspace to an affine
subspace which can intersect more regions of the
Braid Arrangement.67516752D Braid Reflect Approximate Algorithm
Algorithm 2: Braid reflect
Data: Class index c,
W∈R,b∈R
Result: Whether cis unargmaxableunargmaxable = truepatience = 2500x=wwhile patience do c= argmax( Wx+b) ifc=cthen unargmaxable = false break else w= (w−w) b=b−b w= d=wx x=x−2(d+)w patience = patience - 1 endend
E Unargmaxable Token Search Results67536754675567566757F Activation Range of Softmax Layer
Inputs
Neural network activations are bounded in magni-
tude in practice, since larger activations can lead to
larger gradients and instability during training. In
this work, we made the assumption that the Soft-
max layer inputs xare bounded within a range for
all dimensions: −100≤x≤100. Below we pro-
vide some supporting empirical evidence that this
assumption is reasonable.
We checked this assumption on 2 Helsinki NLP
OPUS models for en-ru and bg-en, which were
found to have unargmaxable tokens. We took 10
million sentence pairs from OPUS as released in
Tiedemann (2020) for the corresponding language
pairs and input them to the corresponding mod-
els, decoding using the gold translations. We then
recorded the range of the minimum and maximum
activation for the Softmax layer inputs.
Since our assumption is that all 512dimensions
are bounded between −100and100, we focus on
the range of the minimum and maximum activation
for each output token across all dimensions. We
therefore calculate a 99 percentile for the min and
max activation per token across all dimensions as
well as the overall min and max activations overall.
The results can be seen in Table 9, from which we
can see that for these two models our assumption
holds for all activations produces for 10 million
sentences and the percentiles show that more than
99% of the extreme values fall within the [−50,50]
range.6758