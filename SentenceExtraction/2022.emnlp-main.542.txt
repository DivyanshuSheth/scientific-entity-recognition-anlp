
Jialiang Xu, Mengyu Zhou, Xinyi He, Shi Han, Dongmei ZhangUniversity of Illinois at Urbana-ChampaignMicrosoft ResearchXi’an Jiaotong University
jx17@illinois.edu ,hxyhxy@stu.xjtu.edu.cn ,
{mezho, shihan, dongmeiz}@microsoft.com
Abstract
Numerical Question Answering is the task of
answering questions that require numerical ca-
pabilities. Previous works introduce general
adversarial attacks to Numerical Question An-
swering, while not systematically exploring nu-
merical capabilities specific to the topic. In
this paper, we propose to conduct numerical
capability diagnosis on a series of Numerical
Question Answering systems and datasets. A
series of numerical capabilities are highlighted,
and corresponding dataset perturbations are de-
signed. Empirical results indicate that exist-
ing systems are severely challenged by these
perturbations. E.g., Graph2Tree experienced
a 53.83% absolute accuracy drop against the
“Extra” perturbation on ASDiv-a, and BART
experienced 13.80% accuracy drop against the
“Language” perturbation on the numerical sub-
set of DROP. As a counteracting approach, we
also investigate the effectiveness of applying
perturbations as data augmentation to relieve
systems’ lack of robust numerical capabilities.
With experiment analysis and empirical studies,
it is demonstrated that Numerical Question An-
swering with robust numerical capabilities is
still to a large extent an open question. We dis-
cuss future directions of Numerical Question
Answering and summarize guidelines on future
dataset collection and system design.
1 Introduction
Numeracy is an essential part for real-world NLP
applications (Sundaram et al., 2022; Thawani et al.,
2021b; Sundararaman et al., 2020; Spithourakis
and Riedel, 2018). Numerical QA (Question
Answering) is one representative group of such
number-dependent NLP tasks. E.g., Math Word
Problem Solving (Zhang et al., 2020a; Miao et al.,
2020; Koncel-Kedziorski et al., 2016), DiscreteReasoning (Dua et al., 2019; Hu et al., 2019; Al-
Negheimish et al., 2021a), Tabular Question An-
swering (Zhong et al., 2017; Chen et al., 2020b;
Zhu et al., 2021; Chen et al., 2021). These Numer-
ical QA tasks require NLP systems to arrive at a
numerical answer from the numbers in the ques-
tion and context. By studying how existing NLP
systems perform in these Numerical QA tasks, we
could take a glimpse at what capabilities are re-
quired for building NLP systems in the future.
In an ad-hoc manner, a line of work revealed
robustness issues of handling Numerical QA in
existing NLP systems. Through adversarial at-
tacks with designed dataset perturbations, number-
related limitations were exposed: E.g., utilizing
spurious correlation in datasets (Patel et al., 2021;
Kumar et al., 2021; Al-Negheimish et al., 2021b;
Pi et al., 2022b), incorrectly representing numbers
(Nogueira et al., 2021; Kim et al., 2021) and fail-
ing to extrapolate (Kim et al., 2021; Pal and Baral,
2021). This line of work inspires us to ask follow-
ing questions: 1) What is the overall landscape of
robustness issues of numerical capabilities in exist-
ing NLP systems? Can we find a more systematic
way to investigate the number-related limitations?
2) How to diagnose each numerical capability and
evaluate the severity of it not being captured in a
system? Can we further develop new adversarial
perturbation methods on Numerical QA for diag-
nosis and evaluation? 3) How to address the numer-
ical robustness issues? How do existing solutions
work and what are possible future directions ?
To answer the above questions, in this pa-
per we propose the DNC (Diagnosing Numerical
Capbilities) frameworkas shown in Figure 1.
Most existing Numerical QA systems (see §2.1)
take a two-stage approach to extract and manipu-
late numbers. As shown in the QA Stages part of
Figure 1, systems usually first recognize numbers7950
in the context and question and treat them as can-
didate operands. Then, with the understanding of
the question semantics, they select corresponding
operands, and explicitly generate logical forms or
implicitly execute operations to get the final result.
The above two stages correspond to the two
groups of numerical capabilities (see §4.1) covered
by our DNC Framework (as shown in Figure 1). In
Stage 1, we focus on a system’s capabilities to
recognize different forms of numbers (“Number
Detection”), and to parse and represent number val-
ues correctly (“Number Value Understanding”). In
Stage 2, we focus on the capabilities to correctly
choose operands (“Operand Selection”) and oper-
ations (“Operation Reasoning”) by understanding
context and question. For each of these four capa-
bilities, two perturbations (see §4.2) are proposed
by us to diagnose the capability. Each perturbation
is designed to be trivial to humans and thus cannot
easily fool humans, but it could bring down exist-
ing NLP systems (under the “Attack” setting), and
therefore expose the robustness issue of lacking its
corresponding capability.
By applying the above diagnosis to various NLP
Systems and Numerical QA Datasets (as shown
in Figure 1), in §5 we find that existing systems
experience significant performance drops, whichverifies their lack of robust numerical capabilities.
E.g., Graph2Tree experienced a 53.83% absolute
accuracy drop against the “Extra” perturbation on
ASDiv-a, and BART experienced 13.80% accuracy
drop against the “Language” perturbation on the
numerical subset of DROP.
From another point of view, the perturbations are
also applicable for data augmentation. Under the
“Defense” setting (see §4.3), perturbations are ap-
plied to all splits of the dataset. A system’s perfor-
mance of the same perturbation under both “Attack”
and “Defense” settings are compared (in §5.2) to
show if the corresponding robustness issue could
be relieved by augmenting the training data. Em-
pirical results indicate that despite the recovery in
most cases, the performance still fall lower than the
original level.
Finally, based on the “Attack” and “Defense” re-
sults in §5 and additional experiments, in §6 we
compare some existing design choices in Numer-
ical QA, such as: Is it better to generate logical
forms (and then execute the program/expression)
or predict answers directly in an end-to-end way?
Shall we break numbers into subword tokens or
substitute them with a placeholder that can be later
re-substituted? We also discuss the open questions
and future directions on the robust numerical capa-7951bilities of NLP systems, including recent relevant
development such as neural program execution and
numerical data synthesizing.
In summary, our major contributions are:
•The DNC framework is proposed by us to sys-
tematically diagnose the robustness of NLP
systems on numerical capabilities. A series
of number-related perturbation methods are
designed for the capabilities.
•Comprehensive diagnosing experiments on
adversarial attacks and data augmentations are
conducted by us on five systems over three
Numerical QA tasks. We show the overall
picture of numerical robustness issues of the
systems, and the partial effectiveness of our
simple defense mechanism.
•Based on experiments and previous work, we
provide guidelines for existing numerically-
robust NLP system designs and discussions
for future directions on robust Numerical QA.
2 Related Work
2.1 Numerical Question Answering
Previous work has proposed Numerical QA
datasets and systems. In this paper we consider
as examples the domains of Math Word Problem,
Discrete Reasoning and Tabular QA.
Math Word Problem (Kushman et al., 2014;
Upadhyay and Chang, 2017; Miao et al., 2020;
Qin et al., 2020; Lan et al., 2022) concerns arith-
metic questions collected from lower-grade el-
ementary school coursework. Neural network
are employed with different architectures such as
Seq2Seq (Wang et al., 2017; Chiang and Chen,
2019), Seq2Tree (Xie and Sun, 2019; Liang et al.,
2021) and Graph2Tree (Zhang et al., 2020b; Shen
and Jin, 2020). Recently, large end-to-end pre-
trained language models (Chowdhery et al., 2022;
Pi et al., 2022a) have also been showing impressive
results in Math Word Problem.
Discrete Reasoning (Dua et al., 2019; Al-
Negheimish et al., 2021a; Hu et al., 2019) concerns
questions requiring logistic and arithmetic opera-
tions on real-world paragraphs. Discrete Reason-
ing Systems are mainly based on Graph Attention
Networks (Chen et al., 2020a) or the Transformer
architecture (Ran et al., 2019).
Tabular QA and Semantic Parsing (Zhu et al.,
2021; Chen et al., 2021; Zhong et al., 2017; Pasu-
pat and Liang, 2015) concerns question answeringin the domain of tabular data, which often involves
a large amount of numbers and requires arithmetic
aggregations to arrive at the final answer. Tabular
QA systems (Dong et al., 2022; Liu et al., 2022;
Iida et al., 2021; Herzig et al., 2020; Yin et al.,
2020) are mainly based on Pretrained Language
Models with Transformer backbones. Tabular QA
systems mainly aim at converting natural language
utterance into executable expressions such as com-
mands in SQL language.
2.2 Numeracy Limitations in NLP Systems
Efforts have been dedicated to reveal numeracy
limitations in NLP systems. (Patel et al., 2021;
Kumar et al., 2021; Al-Negheimish et al., 2021b;
Pi et al., 2022b; Nogueira et al., 2021; Kim et al.,
2021; Pal and Baral, 2021). However, previous
work mainly focused on borrowing adversarial at-
tack methods from general QA such as re-ordering
sentences (Patel et al., 2021; Al-Negheimish et al.,
2021b; Kumar et al., 2021), substituting synonyms
(Kumar et al., 2021; Pi et al., 2022b), or adding
irrelevant information (Patel et al., 2021; Pi et al.,
2022b), while having limited exploration into ca-
pabilities specific to Numerical QA problems such
as understanding different number values, recog-
nizing different number surface forms or selecting
related numbers.
3 Preliminaries
ANumerical Question Answering problem is de-
fined to consist of a problem prompt (question) P
and a problem body (context) B. Depending on
the task type, the problem body takes the form of
either a paragraph or a mixture of free-form text
paragraphs and structured data such as tables. Let
Vbe the vocabulary of the textual words, Qbe
the set of the numerical values in P ∪ B , andQ
be the numerical values that can be arithmetically
computed with Q, then the problem prompt and
body can be formulated as P=/circleplustextp, p∈ V∪Q
andB=/braceleftigg/circleplustextb/circleplustextτ⊕/circleplustextb, τ, b∈ V∪Q .
Here⊕denotes the concatenation operation, pand
bare prompt and body textual words, and τare
the body tabular cells.
The target output Tof the problem is either
a numerical value Tthat is an element in Q
or a mathematical expression Tthat consists of
elements in the concerned numerical values Q
and the simple operators O={+,−,×,÷}.I.e.7952T=/braceleftigg
T:q∈ Q
T:/circleplustextt, t∈ Q ∪ O. With PandB
as input and Tas output, a trained Numerical QA
system can be regarded as a mapping fsuch that
f: (P,B)→ T (1)
Note that this expression not only describes the
Numerical QA tasks, but also generalizes to other
numeracy-related NLP tasks such as Tabular En-
tailment (Chen et al., 2020b) and Timeseries-based
Fraudulent Detection (Padhi et al., 2021).
In this paper, we design and apply perturba-
tions to the samples in the dataset to form per-
turbed prompt P, perturbed body Band per-
turbed ground truth target T. We show that ex-
isting systems are fragile against numerical pertu-
bation by showing that on a large portion of the
dataset, the previous mapping fails to generate cor-
rect perturbed target, i.e.:
f: (P,B)̸→ T(2)
4 DNC Framework
Our approach aims at diagnosing the numerical
weakness of existing Numerical Question Answer-
ing models. We list out and explain a series of
numerical capabilities that are critical to solving
Numerical Question Answering problems in §4.1.
We then design numerical perturbations targeting
these capabilities in §4.2. With the designed per-
turbations, we examine the weaknesses under two
different perturbations settings in §4.3.
These three sections are represented in Figure 1.
as the “ Capabilities ” stripe, the “ Perturbs ” stripe,
and the “ Attack Setting ” and “ Defense Setting ”.
4.1 Numerical Capabilities
We classify numerical capabilities into three major
categories, concerning different aspects of numeri-
cal understanding, as below:
Number Detection is the capability of recog-
nizing numbers of different surface forms. For
instance, the English word "Forty-two" and the
Arabic number "42.0" are regarded the same num-
ber in Numerical QA and should not affect the final
arithmetic answer of a question.
Number Value Understanding is the capabil-
ity of understanding numbers of different value
distributions. Systems are expected to not only
apply arithmetic calculation on a specific set of
numbers ( e.g., integers of values smaller than 500as included in the BERT tokenizer vocabulary).
Robust Numerical QA systems are also expected
to handle values such as float-point numbers and
numbers larger than 500.
Operand Selection is the capability of decid-
ing which numbers to select as the operands in the
arithmetic process. One important aspect of select-
ing related values is to exclude numbers that are 1)
irrelevant to the Numerical QA problem scenario,
or 2) relevant to the problem scenario but not essen-
tial to the question solving. Systems are expected
to select as operands the important values from the
unimportant values.
Operation Reasoning is the capability of infer-
ring operations from the logic pattern described in
the text. In an arithmetic process, the operation is
independent from the operands, therefore different
operations can be applied to the same set of selected
related numbers in different questions. Systems are
expected to decouple operation from operands and
select the operation in an operand-agnostic way.
4.2 Perturbations
Perturbations are designed according to each nu-
merical capabilities. In Table 1, an example prob-
lem is provided for each of the perturbations. The
formal definition of the perturbations is provided
in Appendix A.
Language Perturbation targets the Number De-
tection capability and diagnoses how accurate can
systems detect numbers in different surface forms.
To perturb a number string n, we replace it with
its English form of the number with Num2Words.
This perturbation changes number surface forms
but not their values.
Type Perturbation targets the Number Detec-
tion capability and challenges systems to detect
numbers in their float-point forms. To perturb a
number string n, we concatenate it with the string
“.0”. Similar to Language Perturbation, only the
number detection capability is diagnosed with this
perturbation. Contrary to the Noise perturbation in
the next paragraph, the Type perturbation does not
propose additional calculation difficulty by chang-
ing number values.
Noise Perturbation targets the Number Value
Understanding capability and challenges systems
to not only understand arithmetic operations of
not only integers but also float-point numbers. To
perturb a number n, we randomly attach a one-7953
digit fractional part with uniform distribution. This
perturbation introduces new float-point numbers
and breaks the original number value distribution
in the dataset by adding an random variable.
Distribution Perturbation targets the Number
Value Understanding capability and challenges sys-
tems to conduct arithmetic with larger integers. To
perturb a number n, we randomly offset the value
with a normal distribution. Based on the observa-
tions in Wallace et al. (2019), we choose to perturb
the majority of the numbers to larger than 500. This
perturbation introduces large numbers and breaks
original number value distribution in the dataset.
Verbosity Perturbation targets the Operand Se-
lection capability and challenges systems to select
the correct quantity in the problem by adding ex-
plicitly irrelevant numbers into the problem. To
perturb a number string n, we concatenate it with
an irrelevant number in parentheses, the irrelevant
number is preceded by “not”. This perturbation in-
troduces numbers without breaking the distributionof relevant numbers in the dataset.
Extra Perturbation targets the Operand Selec-
tion capability and challenges systems to exclude ir-
relevant numbers. To perturb a problem (B,P), An
irrelvant sentence containing numbers randomly
sampled from the corpus is added to the body B.
This perturbation breaks the number distribution
by introducing extra instances of different numbers
for the same problem.
Logic Perturbation targets the Operation Rea-
soning capability and challenges systems to choose
correct operations for the same set of numbers.
In this paper, for two datasets described in §5.1,
TATQA and ASDiv-a, the Operation perturbation
demands additional attention. On TATQA it is
based on template matching via SpaCyand auto-
matic conversions, while on ASDiv-a it is based
on manual annotation due to the diversity of pat-
terns in the ASDiv-a dataset. This perturbation7954introduces extra problems of different operations.
Order Perturbation targets the Operation Rea-
soning capability and challenges systems to choose
correct operations for the same set of numbers. On
ASDiv-a, the order of sentences in the problem
body is manually altered in a manner that changes
the order of number occurrence but not the prob-
lem logic. This perturbation does not break the
operation distribution within the dataset.
4.3 Perturbing Settings
With the aforementioned perturbations, we con-
struct perturbed datasets under different settings
to investigate systems’ numerical capabilities and
the effectiveness of the perturbations from different
perspectives. For a specific dataset with a training
/ validation / testing split, different splits are per-
turbed under different settings. In this paper we
consider the following two settings of Attack and
Defense, as compared in Table 2:
Attack . By applying the perturbations to the
testing split of the dataset, we construct a challenge
set to evaluate the corresponding numerical capa-
bility of existing systems. Systems are trained on
the original datasets and evaluated on the perturbed
challenge set.
Defense . Under the defense setting, perturba-
tions are applied to all of training, validation, and
testing split of the dataset. By comparing sys-
tems’ performance under the Defense with Attack
settings, we investigate to what extent the perfor-
mance drop can be alleviated by using the pertur-
bations as a data augmentation approach.
To perturb under Attack or Defense setting, suit-
able samples are first filtered according to a series
of conditions. The perturbations are applied only
to these filtered samples. The filtered samples in
the dataset split(s) are replaced with their perturbed
version to form the perturbed dataset. The filter-
ing conditions and the formalized algorithm are
provided in Appendix B.5 Experiments
5.1 Experiment Setup
Datasets . In this paper, we used ASDiv-a (Miao
et al., 2020), DROP (Dua et al., 2019), and TATQA
(Zhu et al., 2021) as our Numerical Question An-
swering datasets. For DROP and TATQA, we fil-
tered out DROP-num and TATQA-a, the numerical
subsets of them. The statistics of these datasets are
shown in Table 4.
Systems . We selected representative systems
on each dataset and test their performance against
perturbations. For the ASDiv-a dataset, we use
Graph2Tree (Patel et al., 2021). For the DROP
dataset, we use BART-base and T5-base from Hug-
gingface.For the TATQA dataset, we utilize
TagOps with the RoBERTa backbone as described
in the original paper.
Compute Environment . All experiments are
done on a Linux machine equipped with 4 NVIDIA
Tesla V100 16GB GPUs. The average runtime of
our experiments ranges from one to three hours.
Hyperparameters . In our experiments, we
adopt a general setting of hyperparameters of epoch
number = 40, learning rate = 1e−5and batch size
=32. It is observed in our exploratory experiments
that while the hyperparameters such as learning rate
and batchsize do affect the absolute performance
of the models, they have a modest effect on the gen-
eral trend of the models’ strengths and weaknesses
against the numerical perturbations. The details
and analysis are provided in Appendix C.
5.2 Experiment Results and Analysis
The experiment results are provided in Table 3.
The metric we report is 1) the metric on original
datasets (Original), and 2) the absolute change of
the metric on perturbed datasets, denoted by “ ∆”.
We additionally provide the raw metric and relative
drop in Table 9 and Table 10 in the Appendix. The
calculation details of the observation can be found
in Appendix D.2.
Attack . As can be observed in Table 3 and Ta-
ble 10, most systems were severely challenged un-
der the Attack setting and experienced significant
performance drop, ranging from 5% to 50% abso-
lute drop and 5% to 80% relative drop in answer
denotation accuracy. Between the two DNC goals,
Semantic Parsing causes a more severe challenge,
averaging 19.66% absolute drop and 31.79% rela-7955
tive drop, as compared to the 13.15% absolute drop
and 19.66% relative drop by Numerical Parsing.
Among the considered systems, Transformer-
based Seq2Seq systems (T5, BART, GPT2) are
more sensitive than the tasks-specific Graph2Tree
system against the perturbations stemming from
the Numerical Parsing goal. The former resulted
in 17.42% absolute drop and 27.06% relative drop,
while Graph2Tree only experienced 3.07% abso-
lute drop and 4.48% relative drop. The masking of
numbers used by Graph2Tree allows it to remain
unaffected against a portion of the perturbations
targeting the Numerical Parsing goal.
Defense . As a counteracting approach, the de-
fense mechanism helps alleviate systems’ lack of
corresponding numerical capabilities by applying
automatic perturbations to the training and valida-
tion set. Via Defense, the lack according to the Se-
mantic Parsing gets more recovery of (17.96% ab-solute improvement and 26.95% relative improve-
ment vs.6.52% absolute improvement and 11.42%
relative improvement).
Among the considered systems, Transformer-
based Seq2Seq systems benefits more from De-
fense than the Graph2Tree system (12.53% abso-
lute improvement and 20.52% relative improve-
ment vs. 11.58% absolute improvement and
16.88% relative improvement).
Despite the recovery from Defense, the chal-
lenge is still not solved. As the majority of the
defense performance is still more than 10% below
the original performance. This observation indi-
cates that the lack of Numerical Capabilities is still
an open question.
Summary . Our DNC framework provides in-
sights on two major aspects of the diagnosis to
Numerical QA systems:
1) It is demonstrated that severe numerical weak-
nesses exist in current Numerical QA systems (“At-
tack”), and they can not be trivially eliminated via,
although benefiting from, an automatic data aug-
mentation process (“Defense”).
2) The systems’ weaknesses are explicitly pro-
filed in a quantitative and interpretable manner
through the models’ susceptibility difference to7956a diversity of perturbations.
6 Guidelines and Open Directions
In this section, phenomena observed on different
systems and datasets were summarized to provide
comparison for existing methods. Also, recent re-
lated efforts corresponding to these phenomena
were discussed to point open directions in the do-
main of Numerical QA.
6.1 Target: Logical Form Generation vs.
Answer Predicting
One attribute specific to Numerical QA is the rea-
soning processes leading to the numerical answers,
which is usually described by logical forms. On
datasets where the ground truth logical forms are
provided as an additional supervision ( e.g., ASDiv-
a and TATQA), the systems have two options for
the target: 1) Logical Form Generation , where
systems generate the logical form which is later in-
put to external symbolic executing systems such as
Python scripts or SQL engines, and 2) Answer Pre-
dicting , where systems directly predict the output
answer in an end-to-end manner. On datasets where
ground truth logical forms are not provided ( e.g.,
DROP), the latter is the most frequently adopted
approach. Logical Form Generation and Answer
Predicting differ in the actual object to conduct the
executing step of the logical form insinuated by
the question (external symbolic systems vs.neural
systems). With Answer Predicting, systems are
expected to possess the capability of executing the
logical forms internally.
We investigate to what extent do existing sys-
tems possess this execution capability, by compar-
ing the impact of the problem target Tin Numer-
ical QA on ASDiv-a. The systems are trained to
predict two different targets: 1) the logical form
(i.e., the MWP equation), and 2) the logical form
and the execution result. Since most MWP-specific
systems are incapable of predicting answers di-
rectly, we choose the Transformer-based systems
GPT2, BART and T5. Results in Table 5 indicate
that: 1) on existing systems, Logical Form Genera-
tion is beneficial for higher accuracy, and 2) even
though models managed to compose equations with
high accuracy, they struggle to faithfully execute
an equation to get the correct answer.
Recent work also pays increasing attention to
the execution capability. Systems such as TAPEX
(Liu et al., 2022) and POET (Pi et al., 2022a) have
been leveraging data synthesizing and intermedi-
ate pretraining to learn neural program executors
and achieved state-of-the-art results over systems
leveraging Logical Form Generation. This recent
development shows the potential of neural systems
with enhanced execution capability on the Numeri-
cal QA task.
6.2 Numbers: Tokenization vs.Replacement
We also investigate the impact of different ways of
manipulating numbers. There are two mainstream
existing methods to process and represent num-
bers, herein referred to as the Tokenization and
Replacement methods.
Tokenization methods such as WordPiece (Wu
et al., 2016) and BPE (Sennrich et al., 2016)
adopted by existing Numerical QA systems divides
numbers into potentially multiple sub-word level
tokens. E.g., The number 768will be divided into
tokens 7and68by T5’s tokenizer. This approach
stems from the fundamental fact that existing sys-
tems’ vocabularies are finite while the occurrences
of numbers in a Numerical QA dataset can be too
diverse to include in a finite vocabulary. Tokeniza-
tion causes extra representation cost and erases the
digit integrity by potentially introducing multiple
tokens for a single number.
Replacement substitutes numbers with special
tokens in the input ( [NUM1] ,[NUM2] ,etc.), which
are later re-substituted with the original number
in the output logical forms. This approach avoids
multiple tokens by providing exactly one represen-
tation for each number, but has its own limitations
handling number diversity since the recognition
of numbers are usually performed with rule-based
matching, which is often non-exhaustive.
In this paper, T5, BART, GPT2 and TagOps
adopts Tokenization, while Graph2Tree adopts Re-7957
placement. We implement two variations of GPT2:
GPT2 and GPT2 to compare their ro-
bustness against different perturbations on the
ASDiv-a dataset.Results in Table 6 indicate that Re-
placement has an advantage when no perturbation
is present or when the perturbation only involves
changes in number value. However, when the per-
turbation changes number values, the Replacement-
based system is more severely challenged.
We hypothesize that the Replacement method re-
moves all numerical information such as the format
and value of numbers in the problem and lost nu-
meracy capabilities, therefore the system receives
only textual signals such as number order or word
frequency, which further encouraged systems to
learn from spurious correlations as stated in Patel
et al. (2021). This hypothesis is consistent with
the observations of a recent study (Thawani et al.,
2021a) that investigates of the mutual-enhancement
between numeracy and literacy.
The respective limitations of Tokenization and
Replacement are calling for more numeracy-
preserving number representation methods. Some
studies have suggested changing number surface
forms (Kim et al., 2021) or using dataset-agnostic
representation (Sundararaman et al., 2020), how-
ever they either create extra token loads or could
not generalize well on large-scale real-world
dataset. The numeracy-preserving number repre-
sentation is another bottleneck for Numerical QA.7 Conclusion
In this paper we aim at diagnosing numerical ca-
pabilities in existing NLP systems. We list out a
series of numerical capabilities and design corre-
sponding dataset perturbations. Empirical results
show that existing systems still lack numerical ca-
pabilities to a large extent, and this lack cannot
be eliminated in a trivial manner. Analysis into
the empirical results, discussion of the the existing
practices, and insights for future directions of Nu-
merical QA dataset collection and system design
are also provided.
Limitations
Our pipeline has limitations in the following two
aspects that we plan to address in the future:
Dependency on ground truth equation . Cur-
rently, three of the eight DNC perturbations have
strong dependency on the ground truth solving
equation, which is missing in datasets such as
DROP. We hope to utilize semi-supervised ap-
proaches in the future to enlarge the coverage of
the DNC perturbations.
Perturbing scalability . Currently our filters
cover only a portion of the whole dataset due to
DNC filtering and perturbing questions based on
manual rules and templates. we hope to develop
more automatic filtering and perturbing in the fu-
ture. Also, DNC can only apply perturbations to
numbers provided by the problem, which limits its
diagnosing power in questions where an unspeci-
fied number is used, e.g., when numerical common-
sense knowledge is involved.
Ethical Statements
The model implementation and datasets utilized in
this paper are based on publication and open-source
repositories. Licenses protocols are followed in the
process of our experiments. No new datasets or
NLP applications are presented in this paper and
no violation of privacy or usage of demographic
information was involved in our process of inter-
acting with the datasets. Our experiments do not
involve lots of compute time/power as reported in
the paper.7958References795979607961A Formal Definition of Perturbations
We provide the formalized definition of the pertur-
bations as follows. In all definitions, “ ⋆” denotes
perturbed version.
Noise Perturbation . To apply noise perturba-
tion to an number n, an variable Xis uniformly
sampled on the interval (1, 10). Then a fractional
part corresponding to Xis added the concerned
number n,i.e.,
X∼ U(1,10)
n=n+ 0.1× ⌊X⌋
Distribution Perturbation . The Distribution
Perturbation changes the number distribution in the
dataset by adding an normally distributed random
variable Xto the concerned number n.I.e.,
X∼ N(µ, δ)
n=n+⌊X⌋
In this paper we adopt µ= 1000 andδ= 300 .
Language Perturbation . The concerned num-
ber string nis replaced by the English word de-
scribing the same quantity, i.e.,
n=Num 2Words (n)
Type Perturbation . To apply the Type Pertur-
bation, the concerned number is expected to be an
integral number. The number string nis concate-
nated with an extra “.0” string to change the type of
the concerned number from integer to float-point,
i.e.,
n=Concat (n, Stringfy (.0))
Verbosity Perturbation . The Verbosity Pertur-
bation aims to introduce irrelevant numbers without
changing the semantics of the problem. To perturb
a number string n, we concatenate it with an irrel-
evant number in parentheses, the irrelevant number
is preceded by "not", i.e.,
X∼ N(µ, δ)
n=Concat (ns,(not, Stringfy (X)))
In this paper we adopt µ= 100 andδ= 30 .
Extra Perturbation To apply the Extra Pertur-
bation to a problem (B,P), an irrelevant sentencecontaining numbers from the corpus is added to the
bodyB,i.e.,
P=SampleOtherQs ()
P=P ⊕ P
B=B
Logic Perturbation To apply the Logic Pertur-
bation to a problem (B,P), the prompt is altered
to convert the problem logic used in the problem,
i.e.,
P=ConvertLogic (P)
B=B
Order Perturbation For the Order Perturbation,
the sentence order in the problem body is manu-
ally altered in a manner that changes the order of
number occurrence but not the problem logic, i.e.,
P=ChangeOrder (P)
B=B
B Details of the Perturbing Process
B.1 The Filtering Conditions
The filtering conditions for Perturbing Algorithms
is different across perturbations. The perturbations
can be divided into two major categories: 1) pertur-
bations that do not change the solving equation or
final results (Language, Type, Verbosity, Extra, Or-
der), and 2) perturbations that changes the solving
equation or final results (Noise, Distri, Operation).
For perturbations in category 1), there is no limi-
tation on the perturbing process, thus all questions
naturally pass the the filtering condition.
For perturbations in category 2), the filtering
conditions follow the principles of Unambiguity,
Suitability and Visibility.
Unambiguity . The filtered question should have
an unambiguous mapping between the number to
be perturbed and the their location in the context.
One example that violates this principle is when
there are duplicated numbers in the problem body,
then it cannot be determined which occurrence of
the number affects the final result.
Suitability . The number to be perturbed should
be suitable for the perturbation to be conducted.
E.g. A float-point number should not be used as the
target of the Noise perturbation which adds frac-
tional part to integral numbers. In DNC, the Noise
and Type perturbations requires the concerned num-
ber to be integral, and the Operation perturbation7962requires the question to match a manually created
template.
Visibility . The concerned number should be
occur in the the problem since the perturbations
can only be applied to known input numbers.
B.2 The Formalized Perturbing Process
Algorithm 1: The Perturbing Process
Data: D={D, D, D}
AllPert ={Noise, ... }as in §4.2
AllSet ∈ {Attack, ... }as in §4.3
Filter ={Integral, ... }as in §B
Result: D={D, D, D}
/* Decide perturbations to use */
Perturbs ←SelectBy (AllPert, D );
/* Create perturbed dataset for
each perturbation and setting */
forsetting ∈AllSet do
/* Decide split to perturb */
D, D ←
SelectBy (D, setting );
forperturb ∈Perturbs do
D← {} ;
ford∈Ddo
ifFilter(d) then
D←D+perturb (d);
end
else
D←D+d;
end
end
D={D, D}
end
end
D={D}|
C Hyperparameters
In our exploratory experiment, it it observed that
while the hyperparameters such as learning rate
and batchsize do affect the absolute performance
of the models, they have a modest effect on the gen-
eral trend of the models’ strengths and weaknesses
against the numerical perturbations. We hypothe-
size that this is due to the numerical capabilities
of a model being contributed mostly by the model
architecture instead of hyperparameters.
For example, when the hyperparameters are vary-
ing from the default setting (1e-5 for learning rate,32 for batch size), the following results are ob-
served:
On Graph2Tree, the results of changing the learn-
ing rate and batch size are shown in Table 7, the
trend of results with the varied hyperparameters
align with the default result as shown in Table 3.
Similar behavior can also be observed on large
transformer-based model such as T5, as shown in
Table 8:
Considering this observation, and the fact that
the number of our experiment is large due to the
combination of different models, datasets, DNC
settings, and DNC perturbations, we chose one
general setting to reduce search space. We chose
the setting as close as possible to the reported set-
ting in the original papers of Graph2Tree and T5.
We verified that this setting provides sufficiently
good performance to demonstrate the performance
gap corresponding to the perturbations, since our
experiment focused more on the performance of a7963same model checkpoint against the datasets before
and after the perturbations.
D DNC Results
D.1 Raw Performance And Relative
Performance Drop
We provide the original result in Table 9 and the
relative performance drop in Table 10.
D.2 Observation Calculation Details
We denote the experiment results table in Table 11.
The values, observation explanation, and the for-
mula used are provided in Table 12.
E DNC Experiments that Are Not
Applicable
The following types of experiments are not appli-
cable in current DNC framework:
E.1 The Defense of the Logic perturbation on
ASDiv-a
The Logic perturbation requires the problem to be
perturbed in a way that the logic is changed while
the semantics of the problem is still cohesive. This
requirement proposes challenge on the scalability
of the perturbation. For the Attack setting, we
utilized manually annotated labels. However, under
the Defense setting the perturbations are expected
to automatically augment the dataset. Thus, the
Defense setting results of Logic perturbation on
ASDiv-a is not applicable.
E.2 Noise and Type perturbations on
DROP-num and TATQA-a
DROP-num and TATQA-a do not provide supervi-
sion of the operand origins, therefore a mapping
from the operands in equation to the context quan-
tities cannot be built, which results in the Noise
and Distribution perturbation not applicable on the
DROP-num and TATQA-a datasets.
E.3 Logic Perturbation on DROP-num
DROP-num does not provide ground truth reason-
ing steps or logical forms, thus Logic perturbations
that has dependency on the provided supervision is
not applicable on DROP-num.
E.4 Order Perturbation on DROP-num
DROP-num is a reasonding dataset based on real-
world paragraphs that usually have logical or tem-
poral order information. Order perturbation breaksthe semantic of the paragraph and will also confuse
humans. Thus Order perturbation is not valid on
DROP-num and the results are not applicable.796479657966