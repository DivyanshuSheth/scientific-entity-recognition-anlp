
Qiang Sheng, Juan Cao, Xueyao Zhang, Rundong Li, Danding Wang, Yongchun Zhu
Key Lab of Intelligent Information Processing of Chinese Academy of Sciences,
Institute of Computing Technology, Chinese Academy of Sciences
University of Chinese Academy of Sciences
{shengqiang18z,caojuan,zhangxueyao19s}@ict.ac.cn
{lirundong20s,wangdanding,zhuyongchun18s}@ict.ac.cn
Abstract
Fake news detection is crucial for preventing
the dissemination of misinformation on social
media. To differentiate fake news from real
ones, existing methods observe the language
patterns of the news post and “zoom in” to ver-
ify its content with knowledge sources or check
its readers’ replies. However, these methods
neglect the information in the external news
environment where a fake news post is created
and disseminated. The news environment rep-
resents recent mainstream media opinion and
public attention, which is an important inspira-
tion of fake news fabrication because fake news
is often designed to ride the wave of popular
events and catch public attention with unex-
pected novel content for greater exposure and
spread. To capture the environmental signals of
news posts, we “zoom out” to observe the news
environment and propose the News Environ-
ment Perception Framework (NEP). For each
post, we construct its macro and micro news en-
vironment from recent mainstream news. Then
we design a popularity-oriented and a novelty-
oriented module to perceive useful signals and
further assist final prediction. Experiments on
our newly built datasets show that the NEP can
efficiently improve the performance of basic
fake news detectors.
1 Introduction
The wide spread of fake news on online social
media has influenced public trust (Knight Foun-
dation, 2018) and poses real-world threats on pol-
itics (Fisher et al., 2016), finance (ElBoghdady,
2013), public health (Naeem and Bhatti, 2020), etc.
Under such severe circumstances, automatically
detecting fake news has been an important counter-
measure in practice.
Besides directly observing the post’s content pat-
terns (V olkova et al., 2017; Wang et al., 2018) (Fig-Figure 1: Existing methods for fake news detection
rely on (a) the post content itself and (b) related post-
level signals like social context and knowledge. Unlike
(a) and (b), our method captures (c) signals from news
environments .
ure 1(a)), most existing methods for fake news
detection “zoom in” for finding richer post-level
signal by checking user replies to the post (Shu
et al., 2019a; Zhang et al., 2021) and verifying the
claim with knowledge sources (Popat et al., 2018;
Wang et al., 2020) (Figure 1(b)). However, these
methods neglect a different line of “zooming out”
to observe the external news environment where a
fake news post is created and disseminated. Our
starting point is that a news environment, which
represents recent mainstream media opinion and
public attention, is an important inspiration of the
fabrication of contemporary fake news. Since any
gains of fake news achieve only if it widely exposes
and virally spreads, a fake news creator would care-
fully design how to improve the post’s visibility and
attract audiences’ attention in the context (environ-
ment) of recently published news. Such intentional
design connects fake news with its news environ-
ment and conversely, we might find useful signals
from the news environment to better characterize
and detect fake news.
Figure 2 shows an example, where we name the
whole set of recent news items the macro news
environment and the event-similar subset as the4543
micro news environment. For the fake news post p
on Syria’s ceasefire thanks to a win over China in a
football match, we observe two important signals
from its news environments:
1) Popularity. In the macro news environment
that contains all recent news items, pis related
to a relatively popular event (Syria-China football
match) among the five events in different domains.
This would bring pgreater exposure and further
greater impact.
2) Novelty. In the micro news environment, the
items mostly focus on the game itself (e.g., “Wu
Lei had a shot”), while pprovides novel side in-
formation about Syria’s unusual celebration. This
would help catch audiences’ attention and boost
the spread of p(V osoughi et al., 2018).
Unfortunately, these potentially useful signals
could be hardly considered by post-only and
“zoom-in” methods, as they focus on digging in
the direction towards inherent properties of a sin-
gle post (e.g., styles, emotions and factual correct-
ness), rather than observing the surrounding envi-
ronments of the post.
To enable fake news detection systems to ex-
ploit information from news environments, we pro-
pose the News Environment Perception Framework
(NEP). As presented in Figure 3, for the post p, we
construct two news environments, M E
andM E, using recent mainstream news
data to facilitate the perception from different
views. We then design a popularity-oriented and a
novelty-oriented perception module to depict the
relationship between pand these recent news items.
The environment-perceived vectors are fused into
an existing fake news detector for prediction.Our contributions are as follows:
•Problem : To the best of our knowledge, we
are the first to incorporate news environment
perception in fake news detection.
•Method : We propose the NEP framework
which exploits the perceived signals from the
macro and micro news environments of the
given post for fake news detection.
•Data & Experiments : We construct the first
dataset which includes contemporary main-
stream news data for fake news detection. Ex-
periments on offline and online data show the
effectiveness of NEP.
2 Related Work
Fake news detection is mostly formulated as a bi-
nary classification task where models are expected
to accurately judge the given post as real or fake.
Existing works focus on discovering distinctive fea-
tures inthe post from various aspects as Figure 2
shows, which we roughly group them as:
Post-only methods aim at finding shared pat-
terns in appearances across fake news posts (Fig-
ure 1(a)). Text-based studies focus on better con-
structing features based on sentiment (Ajao et al.,
2019), writing style (Przybyla, 2020), language
use (V olkova et al., 2017), discourse (Karimi and
Tang, 2019), etc. Other works rely on deep neural
models to encode contents and handle certain sce-
narios, such as visual-based (Qi et al., 2019; Cao
et al., 2020), multi-modal (Wang et al., 2018; Qi
et al., 2021) and multi-domain (Nan et al., 2021)
detection. Our NEP provides additional news en-
vironmental information and can coordinate with
post-only methods (will show in Section 4).
“Zoom-in” methods introduce related sources
to understand the post delicately. One line is to
usesocial contexts (bottom of Figure 1(b)). Some
directly analyze the network information to find
patterns shaped by user relationship and informa-
tion diffusion (Shu et al., 2019b; Zhou and Zafarani,
2019; Nguyen et al., 2020; Silva et al., 2021), and
others leverage collective wisdom reflected by user
responses (Ma et al., 2018; Kochkina et al., 2018;
Shu et al., 2019a; Zhang et al., 2021). For example,
a refuting reply saying “FYI, this is false” would
be an important reference to make a prediction.
Another line refers to knowledge sources (top of
Figure 1(b)) and aims at verifying the post with
retrieved evidence for detection. The knowledge
sources can be webpages (Popat et al., 2018; Ma4544
et al., 2019; V o and Lee, 2021; Wu et al., 2021;
Sheng et al., 2021b), knowledge graphs (Cui et al.,
2020), online encyclopedias (Thorne et al., 2018;
Aly et al., 2021), fact-checking article bases (Au-
genstein et al., 2019; Shaar et al., 2020), etc. Our
NEP starts from a different view, for it “zooms out”
to observe the news environment where the post
spreads. Note that our method is not equivalent to
a knowledge-based method that uses news environ-
ments as evidence bases, as it does not pick evi-
dential news items to prove or disprove the given
post, but aims at reading the news “atmosphere”
when the post is published. In that sense, “zoom-in”
and “zoom-out” methods can actually be integrated
for comprehensively detecting fake news (will also
show in Section 4).
3 Proposed Method
Figure 3 overviews our proposed framework NEP,
whose goal is to empower fake news detectors
with the effective perception of news environments.
Given a post p, we first construct its macro and mi-
cro environment ( M EandM E)
using recent news data. Then we model the post-
environment relationships to generate environment-
perceived vectors vandv. Finally, the
two vectors are fused with post representation oderived from the fake news detector to predict if p
is real or fake.
3.1 News Environment Construction
The environment is the objects, circumstances, or
conditions by which one is surrounded (Merriam-
Webster, 2021). Accordingly, a news environment
should contain news reports which can reflect the
present distribution of mainstream focuses and au-
diences’ attention. To this end, we collect news
items published by mainstream media outlets as
basic environmental elements, in that their news
reports generally face a large, common audience.
LetEbe the set of all collected news items pub-
lished earlier than p. We construct a macro envi-
ronment ( M E) and a micro environment
(M E), which are defined as follows:
•M Eis the set of news items in E
released within Tdays before pis published:
E={e:e∈ E,0< t−t≤T},(1)
where tandtrespectively denote the publi-
cation date of pand the news item e.
•M Eis the set of news items in E
that are relevant to p. Here, we query E
using pand obtain the top kas the set:
E={e:e∈Topk( p,E)}, (2)4545where k=⌈r|E|⌉andr∈(0,1)deter-
mines the proportion.
Intuitively, the time-constrained environment
M Eprovides a macro perspective of what
the mass audience read and focus on recently, while
the further relevance-constrained one M E
describes the distribution of items about similar
events. We use a pretrained language model M
(e.g., BERT (Devlin et al., 2019)) to obtain the
post/news representation. For por each item in the
macro/micro environment e, the initial representa-
tion is the output of Mfor the [CLS]token:
p=M(p),e=M(e). (3)
3.2 News Environment Perception
The perception of news environments of pis to
capture useful signals from existing mainstream
news items. The signals are expected to discover
unique post-environment interactive patterns of
fake news. Starting from the motivation of fake
news creators to widely diffuse fabricated infor-
mation to the whole online news ecosystem, we
guide the model to perceive from two important
diffusion-related perspectives, i.e., popularity and
novelty, in the M Eand the M E.
Popularity-Oriented M EPerception. A
fabricated post would be more likely to go viral and
thus gain more influence when it is related to trend-
ing news. Thus, a fake news creator might consider
how to chase clouts of hot events during writing a
fake news post. Here we consider how popular the
main event of pis in the M E. We trans-
form the perception of popularity into the similarity
estimation between pand individual news items.
That is, if many items in the M Eare sim-
ilar to p, then pmight be also popular in such an
environment. Following (Reimers and Gurevych,
2019), we first calculate cosine similarity between
pand each news item (say, i) inE:
s(p,e) =p·e
∥p∥∥e∥. (4)
The similarity list {cos(p,e)} of variable
length |E|does not work well with networks
mostly taking fixed-dimensional vectors as inputs.
Thus, the list requires a further transformation,
where we expect the transformed environment-
perceived vector to reflect how similar pis to the
environment without much information loss. Fol-
lowing (Xiong et al., 2017; Liu et al., 2020), we
here choose to calculate a soft counting on the listto obtain a distribution that mimics a hard bin plot.
Specifically, we employ a Gaussian Kernel Pooling
proposed in (Xiong et al., 2017) across the range
of cosine similarity to get soft counting values. As-
suming that we use Ckernels {K}, the output
ofk-th kernel is:
K= exp
−(s(p,e)−µ)
2σ
, (5)
K(p,E) =K, (6)
where µandσis the mean and width of the k-
th kernel. In Eq. (5), if the similarity between p
andeis close to µ, the exponential term will be
close to 1; otherwise to 0. We then sum the expo-
nential terms with Eq. (6). This explains why a
kernel is like a soft counting bin of similarities. We
here scatter the means {µ}of the Ckernels in
[−1,1]to completely and evenly cover the range
of cosine similarity. The widths are controlled by
{σ}. Appendix B.1 provides the details. A
C-dim similarity feature in the M Eis ob-
tained by concatenating all kernels’ outputs and
normalizing with the summation of the outputs:
K(p,E)=NormK(p,E)
,(7)
whereis the concatenation operator and
Norm( ·)denotes the normalization.
By calculating K(p,E), we obtain a soft
distribution of similarities between pand the
M Eas the perception of popularity. To
enrich the perceived information, we generate the
M E-perceived vector for pby fusing the
similarity and semantic information. Specifically,
we aggregate the post vector, the center vector of
theM Em(E)(by averaging all vec-
tors), and the similarity feature using an MLP:
v=MLP( p⊕m(E)⊕K(p,E) ).(8)
Novelty-Oriented M EPerception. Dif-
ferent from M E,M Econtains
mainstream news items close to p, which indicates
that they are likely to share similar events. How-
ever, even in a popular event, a post may still be
not attended if it is toosimilar to others. V osoughi
et al. (2018) found that false news was more novel
than true news on Twitter with the reference to the4546tweets that the users were exposed to (could be
regarded as a user-level news environment). This
might explain why fake news spread “better”. We
thus consider how novel pis in the event-similar
M E.
If the content of a post is novel, it is expected to
be an outlier in such an event. Here, we use the cen-
ter vector m(E)ofM Eas a reference.
Specifically, we again use Eqs. (5) to (7), but
here, calculate twosimilarity features K(p,E)
andK(m(E),E). The latter serves as a ref-
erence for the former and facilitates the model “cal-
ibrate” its perception. The generation of the M-E-perceived vector for pis as follows:
u= MLP( p⊕m(E)), (9)
u=MLP(g( K(p,E),K(m(E),E))),
(10)
v= MLP( u⊕u), (11)
where the comparison function g(x,y) = ( x⊙
y)⊕(x−y)and⊙is the Hadamard product op-
erator. uandurespectively aggregate the
semantic and similarity information. The MLP s
are individually parameterized. We omit their index
numbers in the above equations for brevity.
3.3 Prediction under Perceived Environments
As our environment perception does not necessarily
depend on a certain detection model, we expect our
NEP to have a good compatibility with various fake
news detectors. In our NEP, we achieve this by gate
fusion. Take a post-only detector as an example.
We apply the gate mechanism for adaptively fusing
vandvaccording to o:
v=g⊙v+ (1−g)⊙v,(12)
where the gating vector g= sigmoid(Linear( o⊕
v)),sigmoid is to constrain the value of each
element in [0,1], andodenotes the last-layer fea-
ture from a post-only detector.oandvare fur-
ther fed into an MLP and a softmax layer for final
prediction:
ˆ y= softmax(MLP( o⊕v)). (13)
When working with more complex detectors that
rely on other sources besides the post, we can sim-
ply concatenate those feature vectors in Eq. (13).
For example, we can concatenate vwith the post-
article joint representation if the fake news detector
is knowledge-based. During training, we minimize
the cross-entropy loss.
4 Experiment
We conduct experiments to answer the following
evaluation questions:
•EQ1: Can NEP improve the performance of
fake news detection?
•EQ2: How effective does the NEP model the
macro and micro news environments?
•EQ3: In what scenarios do news environ-
ments help with fake news detection?
4.1 Datasets
We integrated existing datasets in Chinese and En-
glish and then collected news items released in the
corresponding time periods. The reasons why we
do not use a single, existing dataset include 1) no
existing dataset provides the contemporary news
items of verified news posts to serve as the ele-
ments in news environments; 2) most datasets were
collected in a short time period and some suffer
from a high class imbalance across years.The
statistics are shown in Table 1 and the details are
as follows:
Chinese Dataset
Post: We merged the non-overlapping parts of
multiple Weibo datasets from (Ma et al., 2016)
(excluding those unverified), (Song et al., 2019),
(Zhang et al., 2021) and (Sheng et al., 2021a) to
achieve a better coverage of years and avoid spuri-
ous correlation to specific news environments (e.g.,
one full of COVID-19 news). To balance the post
amount of real/fake classes across the years, we
added news posts verified by a news verification
system NewsVerifyand resampled the merged4547
set. The final set contains 39,066 verified posts on
Weibo ranging from 2010 to 2021.
News Environment: We collected the news
items from the official accounts of six represen-
tative mainstream news outlets that have over 30M
followers on Weibo (see sources in Appendix A).
The further post-processing resulted in 583,208
news items from 2010 to 2021.
English Dataset
Post: Similarly, we merged the datasets from
(Kochkina et al., 2018) (excluding unverified), (Au-
genstein et al., 2019) (excluding those without
claim dates), and (Shaar et al., 2020). For posts
or claims from fact-checking websites, we used
the provided claim dates instead of the publica-
tion dates of the fact-checking articles, to avoid
potential data contamination where the later news
environment is more likely to contain correspond-
ing fact-checking news and support direct fact ver-
ification. We obtained 6,483 posts from 2014 to
2018 after dropping the posts labeled as neutral and
re-sampling.
News Environment: We use news headlines
(plus short descriptions if any) from Huffington
Post, NPR, and Daily Mail as the substitute of news
tweets due to the Twitter’s restriction (see sources
in Appendix A). The bias rates of the three outlets
are respectively left, center, and right according
to AllSides Media Bias Chart, for enriching the
diversity of news items. We preserved the news
headlines from 2014 to 2018 and obtained a set of
1,003,646 news items.4.2 Experimental Setup
Base Models Technically, our NEP could coor-
dinate with any fake news detectors that produce
post representation. Here we select four post-only
methods and two “zoom-in” (knowledge-based)
methods as our base models.
Post-Only: 1) Bi-LSTM (Graves and Schmid-
huber, 2005) which is widely used to encode posts
in existing works (Shu et al., 2019a; Karimi and
Tang, 2019); 2) EANN(Wang et al., 2018) which
uses adversarial training to remove event-specific
features obtained from TextCNN (Kim, 2014); 3)
BERT (Devlin et al., 2019); 4) BERT-Emo (Zhang
et al., 2021) which fuses a series of emotional fea-
tures with BERT encoded features for classification
(publisher emotion version).
“Zoom-in”: 1) DeClarE (Popat et al., 2018)
which considers both the post and retrieved docu-
ments as possible evidence; 2) MAC (V o and Lee,
2021) which build a hierarchical multi-head atten-
tion network for evidence-aware detection.
Implementation Details We obtained the sentence
representation from SimCSE (Gao et al., 2021)
based on pretrained BERT models in the Trans-
formers package (Wolf et al., 2020)and were4548
post-trained on collected news items. We frozed
SimCSE when training NEP. For DeClarE and
MAC, we prepared at most five articles in advance
as evidence for each post by retrieving against
fact-checking databases.In environment mod-
eling, T= 3 ,r= 0.1, and C= 22 . We
limit|E| ≥ 10. We implemented all meth-
ods using PyTorch (Paszke et al., 2019) with
AdamW (Loshchilov and Hutter, 2019) as the op-
timizer. We reported test results w.r.t. the best
validation epoch. Appendix B provides more im-
plementation details.
Evaluation Metrics. As the test sets are roughly
balanced, we here report accuracy (Acc.), macro
F1 score (macF1) and the F1 scores of fake and
real class (F1and F1). We will use a new
metric for skewed test data (see Section 5).
4.3 Performance Comparison (EQ1)
Table 2 shows the performance of base models with
and without the NEP on the two datasets. We have
the following observations:
First, with the help of our NEP, all six base mod-
els see an performance improvement in terms of
accuracy and macro F1. This validates the effec-
tiveness and compatibility of NEP.
Second, for post-only methods, F1generally
benefits more than F1when using NEP, which
indicates that news environments might be more
helpful in highlighting the characteristics of fake
news. This is a practical property of the NEP as we
often focus more on the fake news class.
Third, the “zoom-in” knowledge-based meth-
ods outperform their corresponding post-only base
model (here, Bi-LSTM) with the help of relevant
articles, but the improvement is small. This might
be led by the difficulty of finding valuable evidence.
Our NEP brings additional gains, indicating that
the information perceived from news environments
is different from verified knowledge, and they play
complementary roles.
4.4 Evaluation on Variants of NEP (EQ2)
Ablation Study. We have two ablative groups as
shown in Table 3:
w/o Fake News Detector : We directly use one of
the two environment-perceived vectors or both to
see whether they can work when not cooperating
with the fake news detector’s output o. The macro
F1 scores on both datasets indicate their moderate
effectiveness as sole inputs, and that coordinating
with a post-only detector is a more practical setting.
w/o Environment Perception Modules : By re-
spectively removing M EandM E
from the best-performing models BERT-Emo+NEP
and DeClarE+NEP, we see a performance drop in
macro F1 when removing either of them, indicating4549
that the two environments are both necessary and
play complementary roles in detection.
Effects of the proportion factor rfor the M-E.We adjusted rfrom 0.05 to 0.30 with a
step of 0.05 on BERT-Emo+NEP to see the impact
of the scale of the M E(T= 3). As Fig-
ure 4(a) shows, the change of rleads to an increase
on the size of the M E, but only fluctua-
tions w.r.t. the accuracy. We do not see significant
improvement after r= 0.1. We speculate that a
too small rmay hardly cover enough event-similar
items while a large rmay include much irrelevant
information, bringing little gains (e.g., r= 0.3in
Chinese) or even lowering the performance (e.g.,
r= 0.15for both datasets).
Effects of the day difference Tfor the
M E.We set T= 1,3,5,7,9on BERT-
Emo+NEP to see how many days of news items to
be considered is proper ( T= 0exactly corresponds
to the base model). Figure 4(b) shows a tendency
similar to (a). We find the highest accuracy when
T= 3on both of the two datasets. This is reason-
able as the popularity should be considered in a
moderately short time interval to allow the events
to develop but not to be forgotten.
4.5 Environment Analysis (EQ3)
Categorization of macro- and micro-preferred
samples. We selected the top 1% of Chinese
fake news samples which NEP relies more on
M EorM Eaccording to the gate
vectors. Then we manually categorized these sam-
ples to probe what information the macro/micro
environment might provide. From Figure 5, we
see that M Eis more useful for samples
about natural disasters and accidents (e.g., earth-
quakes and air crashes), while M Eworks
effectively in Society & Life (e.g., robbery and
education). This is in line with our intuition:
M E-preferred fake news posts are often
related to sensational events, so the popularity inM Ewould help more; and M E-
preferred ones are often related to common events
in daily news, and thus its novelty in M E
would be highlighted. This analysis would deepen
our understanding on the applicability of different
news environments.
Case study. Figure 6 shows three fake news cases
in different scenarios. Case (a) relies more on M-Ethan M E. We can see moderate
popularity of its event about Huawei but the mes-
sage about HarmonyOS is novel among the items
on the 5G and cooperations. In contrast, the admit
card in case (b) is moderately novel but Gaokao
is the most popular event, so the NEP puts higher
weight on M E. Case (c) is a popular and
novel fake news about Japan’s great healthcare for
citizens coming back from Wuhan which is posted
during the first round of COVID-19 pandemic in
China. The exploitation of both-side information
makes a tie between the two environments. These
cases intuitively show how NEP handles different
scenarios. We incorporate further analysis on the
case that the news environment might be ineffective
in Appendix D.
5 Discussion in Practical Systems
Evaluation on skewed online data. We tested
BERT-Emo and BERT-Emo+NEP on a dump of
seven-month data from a Chinese fake news detec-
tion system. Different from offline datasets, this
real-world set is highly skewed (30,977 real vs.
309 fake, roughly 100:1).Under such skewed
circumstance, some metrics we used in Tables 2
and 3 could hardly show the differences of perfor-
mances among models (e.g., a model predicting all
samples as real will have an incredible accuracy of
0.990). Here, we report macro F1 and standardized
partial AUC with false positive rate of at most 0.1
(spAUC, McClish, 1989, see Appendix C
for the calculation detail) under different real/fake
ratios (from 10:1 to 100:1). As shown in Figure 7,
NEP brings relative improvements of 16.89% and
5.20% in macF1 and spAUC, showing its
effectiveness in skewed, real scenarios.
Friendliness to Practical Systems. The NEP is
not only a new direction for fake news detection
but also inherently friendly to practical systems: 1)
Timeliness. Our NEP works instantly as it only
requires the post and mainstream news published a
few days before. In practice, a system would not4550
construct the required collection on demand but
prepare it ahead by maintaining a queue of news
items. 2) Compatibility. Our perception module
can be integrated with existing methods, which we
validated on six representative ones (Table 2). 3)
Data Accessibility. The data to construct news en-
vironments is easy to access, especially compared
with obtaining credible knowledge sources. The
advantages may encourage the deployment of NEP
into practical systems.
6 Conclusion and Future Work
We proposed the NEP to observe news environ-
ments for fake news detection on social media. We
designed popularity- and novelty-oriented percep-
tion modules to assist fake news detectors. Exper-
iments on offline and online data show the effec-
tiveness of NEP in boosting the performance of
existing models. We drew insights on how NEP
help to interpret the contribution of macro and mi-
cro environment in fake news detection.As this is the first work on the role of news en-
vironments for fake news detection, we believe
further exploration is required for a deeper under-
standing of the effects of news environments and
beyond. In the future, we plan to explore: 1) in-
cluding historical news or background to handle
posts weakly related to the present environment;
2) modeling post-environment relationships with
diverse similarity metrics or even from other per-
spectives; 3) investigating the effects of different
news environments (e.g., biased vs. neutral ones)
to make the environment construction more princi-
pled; 4) extending this type of methodology from
the text-only detection to multi-modal and social
graph-based detection.
Acknowledgements
The authors thank Guang Yang, Peng Qi, Zihao
He, and anonymous reviewers for their insightful
comments. This work was supported by the Zhe-
jiang Provincial Key Research and Development
Program of China (No. 2021C01164).
Ethical Considerations
Application. Our framework does not present di-
rect societal consequence and is expected to benefit
the defense against the fake news issue. It can
serve as a detection module for fake news detection
systems, especially when the given post is closely
related to the events that happened recently, with
no need to wait for the accumulation of user re-
sponses or query to knowledge sources. Due to
the requirement of real-time access to open news
sources (source list can be determined as needed),4551it might be easier to deploy for service providers
(e.g., news platforms) and media outlets.
Data. Our data is mostly based on existing datasets,
except the news items for constructing news envi-
ronments. All news items (or headlines) are open
and accessible to readers and have no issues with
user privacy. The media outlets in the English
dataset might be considered “biased”, so we care-
fully select a left, a center, and a right outlet (whose
headlines are available) according to the AllSides
Media Bias Chart. In China, a media outlet might
be state-run (e.g., CCTV News), local-government-
run (e.g., The Paper), or business-run (e.g., Toutiao
News). With no widely recognized bias chart of
Chinese media as a reference, we select media out-
lets based on their influence (e.g., number of fol-
lowers) on Weibo from the three categories for the
sake of representativeness.
References455245534554
A Sources of News Items as the
Environmental Elements
Table 4 shows the selected news outlets that pro-
vides news items as the elements for news environ-
ment construction in Chinese and English.
BSupplementary Implementation Details
B.1 Kernel Settings
We use C= 22 kernels for softly counting the
cosine similarities. Following (Xiong et al., 2017),
we first determine 21 kernels whose µs scatter in
[−1,1]with an interval of 0.1 and σs are all 0.05.
Then we add a kernel with a µof 0.99 and a σ
of 0.01, specially for extremely similar situations.
The final kernel list is [(-1.0, 0.1), (-0.9, 0.1), ···,
(1.0,0.1), (0.99, 0.01)]
B.2 Post-Training SimCSE
We post-trained the BERT models for two epochs,
with the temperature coefficient τof 0.05, the
dropout rate of 0.3 (Chinese, hereafter, C) and 0.1
(English, hereafter, E), and the maximum length of
256 (C) and 128 (E).
B.3 Implementation of Base Models
•Bi-LSTM : The hidden dims are 128 (C) and
256 (E). The maximum lengths are 256 (C)
and 128 (E). The number of layers are 1
(C) and 2 (E). We use sgns.weibo.bigram-
char(Li et al., 2018) for Chinese andglove.840B.300d(Pennington et al., 2014)
for English to obtain the word embeddings.
The Chinese texts are segmented using jieba
and the English texts are tokenized using
NLTK (Bird, 2006).
•EANN: The hidden dims, maximum lengths,
and word embeddings are the same as Bi-
LSTM. The kernel size for both datasets are
[1,2,3,4]. The numbers of filters are 20 (C)
and 30 (E). We ran K-means (Hartigan and
Wong, 1979) in the scikit-learn package to
gather the training samples into 300 clusters
(corresponding to 300 events).
•BERT andBERT-Emo : We use bert-base-
chinese andbert-based-uncased for Chinese
and English, respectively. The maximum
lengths are 256 (C) and 128 (E). The dimen-
sion of each token representation is 768.
•DeClarE andMAC : The Bi-LSTM compo-
nent keeps the same settings as the post-only
Bi-LSTM. The maximum lengths of articles
are 100 (C) and 256 (E).
C Calculation of spAUC
Real-world fake news detection systems inevitably
face a challenge of high imbalance of data
(#real >>#fake), even if pre-screening procedures
like check-worthiness estimation (Hassan et al.,
2017; Atanasova et al., 2018) are equipped. In the
online test, we use the standardized partial AUC
(spAUC) (McClish, 1989) for evaluation. It is suit-
able to our scenario where we expect the method
to find fake news posts as many as possible with an
acceptable misclassification rate of real ones. The
partial AUC over the false positive rate [0, x]is:
pAUC=ROC( x) dx, (14)
where ROC is the Receiver Operating Characteris-
tic curve. The spAUC is calculated as
spAUC=1
2
1 +pAUC−x
x−x
.
(15)4555
In our experiment, we use the implementation in
thescikit-learn package.DAnalysis on the Case Weakly Related to
News Environments
Figure 8 shows a case that is weakly related to
its news environment. Its words have no intersec-
tion with the keywords in the macro environment
and the top similar events seem not very related.
In this case, our NEP has limited utility as its na-
ture of recency. That might explain why the per-
formances were mostly lower than the post-only
methods when we evaluated the NEP alone. For
this case, it actually has some novelty (a novel and
simple test of personal stress) but is involved with
a long-lasting discussed topic—mental health, in-
stead of a hot event being discussed at the very
moment. This inspires us to explore how to incor-
porate more historical and background references
to build a comprehensive understanding of the con-
nection between a fake news post and broader soci-
etal environments in the future.4556