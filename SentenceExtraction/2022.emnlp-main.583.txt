
Yizhi Li, Wei Fan, Chao Liu, Chenghua Lin, Jiang QianDepartment of Computer Science, The University of Sheffield, UKDepartment of Computer Science, University of Central Florida, USAPingan Technology, China
{yizhi.li, c.lin}@sheffield.ac.uk, weifan@knights.ucf.edu,
lliuchao666@mail.ustc.edu.cn, jqian104@126.com
Abstract
Knowledge graph embedding methods are im-
portant for the knowledge graph completion
(or link prediction) task. One existing efficient
method, PairRE, leverages two separate vectors
to model complex relations (i.e., 1-to-N, N-to-
1, and N-to-N) in knowledge graphs. How-
ever, such a method strictly restricts entities on
the hyper-ellipsoid surfaces which limits the
optimization of entity distribution, leading to
suboptimal performance of knowledge graph
completion. To address this issue, we pro-
pose a novel score function TranSHER , which
leverages relation-specific translations between
head and tail entities to relax the constraint
of hyper-ellipsoid restrictions. By introduc-
ing an intuitive and simple relation-specific
translation, TranSHER can provide more di-
rect guidance on optimization and capture more
semantic characteristics of entities with com-
plex relations. Experimental results show that
TranSHER achieves significant performance
improvements on link prediction and gener-
alizes well to datasets in different domains
and scales. Our codes are public available at
https://github.com/yizhilll/TranSHER .
1 Introduction
Knowledge graph is proposed to structurally store
human knowledge when the development of com-
puter science has brought exponentially growing
digitized information. Knowledge graphs have
been widely adopted in important applications,
such as semantic parsing (Berant et al., 2013), ques-
tion generation and answering (Lin et al., 2015a;
Hao et al., 2017; Peng et al., 2021), and informa-
tion retrieval (Xiong et al., 2017). However, due to
the expanding nature and difficulties of construc-
tion, knowledge graphs often suffer from incom-
pleteness. Thus, knowledge graph completion (or
Figure 1: A Comparison Example of Distribution
Optimization Between PairRE and TranSHER in 2-
dimensional Space.
link prediction) becomes a task of great importance
from both a research and application perspective.
To construct a knowledge graph, entities and re-
lations extracted from facts are treated as nodes and
edges. A single fact in this graph is represented as a
directed relation-specific link between two entities,
which is denoted as a triplet like (head, relation,
tail). Since knowledge graphs usually contain a
large number of entities and relations, knowledge
graph embeddings are proposed to efficiently learn
the representation of graphs and accomplish the
link prediction task with score functions . Intuitions
behind the design of score functions can be summa-
rized as two important principles: 1) logical reason-
ingrelation patterns such as symmetry (antisym-
metry), inversion, and composition; 2) statistically
categorized relation types like 1-to-1, 1-to-N, N-
to-1, and N-to-N, where the latter three are called
complex relations .
Inspired by word2vec (Mikolov et al., 2013),
TransE (Bordes et al., 2013) represents knowledge
graphs with relation-specific translations between
head and tail entities to model the connections,
where the score function works upon the transla-
tional distance ∥e+r−e∥. Following this design,
certain works (Wang et al., 2014; Lin et al., 2015b;
Xiao et al., 2016) improve TransE by conducting
relation-specific transformations on the entities be-8517fore calculating distance. Certain works (Wang
et al., 2014; Trouillon et al., 2016; Sun et al., 2019;
Chao et al., 2021) further apply the principles of
modeling relation patterns and complex relations
to refine the design of score functions.
Among these methods, the recently proposed
PairRE (Chao et al., 2021) uses separate relation
vectors for head and tail entities to better model the
complex relations and outperforms preceding meth-
ods. However, after our preliminary exploration,
we notice that PairRE imposes a strong restriction
that fixes the Lnorm of the entity vector ⃗ e, and
scales it with coefficients along all dimensions. Un-
der such a restriction, the entities are essentially dis-
tributed on the surface of hyper-ellipsoids, where
the foci are exactly laying on the axes. For the same
reason, entity embeddings are strictly limited and
can only be optimized around the hyper-ellipsoidal
surface. In other words, entity distribution can only
move along an arc path to match the true connec-
tions, as Fig. 1a shows, which may impose the
close entity embeddings entangled and bring diffi-
culties to the modeling.
To tackle the aforementioned challenges, we
propose TranSHER which has a novel score func-
tion that leverages relation-specific translations be-
tween head and tail entities to relax the constraint
of hyper-ellipsoid restrictions. We hypothesize that
introducing translations for entities of PairRE can
simplify the multi-relation modeling of entities on
hyper-ellipsoids by providing an extra degree of
freedom and thus improve the distribution learning
of entities. In order to model complex relations,
TranSHER first follows PairRE to conduct map-
pings on head and tail entities separately. Then,
TranSHER additionally performs relation-specific
translations on entities while holding the hyper-
ellipsoidal restriction. Take Fig. 1b as an exam-
ple: the mapped head entities (green) are moved
closer to the tail entities (orange) without requiring
obvious changes of the entities within the cluster
and form a better distribution for relational mod-
eling because the translational distance provides
more direct guidance in the score function. The
relation-specific translation in our score function
allows more flexible optimization by relaxing the
arc path constraint in PairRE brought by the hyper-
ellipsoidal mapping, leading to a better distribution
of entities and knowledge graph completion.
Moreover, TranSHER can better model the se-
mantic characteristics of entities and utilize themto improve entity retrieval for complex relations.
The semantic characteristics usually decide the
categories of entities (e.g., people or companies);
TranSHER can model the connected structure be-
tween entities of different categories more accu-
rately in complex relations. For those complex
relation triplets, TranSHER further enhances link
prediction by retrieving multiple candidate entities
in the correct category. For example, for a tail pre-
diction query (film, produced_by, ?), TranSHER
ranks the names of film producers at the front while
other models may be confused by the related enter-
tainment company or studio (cf. §5.6).
In addition, while achieving qualitative embed-
dings, TranSHER can further maintain the ability
to model important relation patterns, namely, sym-
metry (antisymmetry), inversion, and composition
under certain constraints (cf. §4). With such ability,
TranSHER has the potential to be generalized well
on datasets from different knowledge domains in
different real-world settings.
We conduct comprehensive experiments across
five datasets from different domains, which demon-
strate the effectiveness of TranSHER. Impressively,
TranSHER has achieved substantial improvement
compared with the best baseline: the MRR increase
has reached up to 4.6% on YAGO37 and 3.2% on
ogbl-wikikg2. We also conduct many analytical ex-
periments to study how translations of TranSHER
behave and enhance knowledge graph completion.
Some case studies further demonstrate the superi-
ority of our approach.
2 Related Work
Knowledge graph embedding methods are pro-
posed to model the intrinsic properties of facts
and to conduct knowledge graph completion. To
further complete knowledge graphs, these meth-
ods use designed score functions to model com-
plex relations and various patterns. By measuring
the relation-related distance between entities, KGE
models predict the probabilities of given triplet
queries (e, r,?)or(?, r, e)to complete the graph.
Such models are characterized by their correspond-
ing score functions and the embeddings are usually
optimized with gradient descent algorithms.
Distance-based score functions model the triplet
facts by calculating distances between entity em-
beddings in the Euclidean space. Proposed by
TransE (Bordes et al., 2013), one popular prac-
tice is to conduct a relation-specific translation on8518the given entity before distance calculation, i.e.,
lete+r≈ein the case where the fact holds.
Such a translational principle empowers the models
to conduct knowledge graph completion on large-
scale datasets while maintaining their performance.
Many score functions, such as TransH, TransR, and
ManifoldE (Wang et al., 2014; Lin et al., 2015b;
Xiao et al., 2016), followed this principle of transla-
tion and achieved fair performances. However, Ro-
tatE (Sun et al., 2019) claims these extended works
of TransE are weak in modeling certain relation pat-
terns and thus proposes a solution of modeling in
the complex space. Moreover, PairRE (Chao et al.,
2021) argues that complex relations can be better
modeled by separating relation vectors for heads
and tails. Our TranSHER aims to provide a more ef-
fective model for complex relations by bridging the
gap between translational distance-based models
and the latest model PairRE.
Semantic matching score functions aim to predict
the existence of facts by measuring the semantic
similarity among entities and the given relation in
the same representation space. RESCAL (Nickel
et al., 2011) introduces a bilinear function hMt
to represent the similarity score but suffers from
modeling complexity. Some following work such
as DistMult, HolE, and ComplEx (Yang et al.,
2015; Nickel et al., 2016; Trouillon et al., 2016)
intend to simplify the model while preserving criti-
cal features. A more recent work SEEK (Xu et al.,
2020) generalizes the existing semantic matching
score functions by segmenting the embedding to fa-
cilitate feature interactions, while keeping the same
model size. In general, the semantic matching mod-
els struggled to distinguish similar entities and lack
the ability to simultaneously model multiple rela-
tion patterns. Our TranSHER model tackles these
challenges by proposing a novel score function
which leverages relation-specific translations, yield-
ing an effective improvement in modeling complex
relations.
3 Problem Formulation
In this section, we describe the task definition and
notations for better illustration. The set of known
facts in a knowledge graph is represented by T,
which includes triplets (e, r, e). The notation
(e, r, e)∈ T will be used when the fact holds.
The set of entity eand the set of relation rare
denoted as EandR.
Knowledge graph completion (also regarded aslink prediction) aims to predict the missing links
of knowledge graphs. Specifically, given a triplet
(e, r, e)or(e, r, e), a score function fis re-
quired to output an existence probability of the
triplet. Since all the entities in Eare provided in
the training set, knowledge graph completion can
also be regarded as a ranking task. For the true
candidate entities, models are expected to assign
higher rankings than false ones.
For a given entity-relation query (e, r,?)or
(?, r, e), there may exist multiple correct answers
to complete the triplet, i.e., the quantities of those
entities satisfy ∥{e|(h, r, e)∈ T }∥ >1or
∥{e|(e, r, e)∈ T }∥ >1. According to the
average heads per tail andtails per head counted
through the dataset, relations in Rcan be cate-
gorized into 4 types: 1-to-1, 1-to-N, N-to-1, and
N-to-N (Wang et al., 2014).
Relations can also be summarized by several
significant patterns: symmetry/antisymmetry, in-
version, and composition. The definitions are given
as follows:
•A relation rissymmetric orantisymmet-
ricif(e, r, e)∈ T ,∀e, e∈ E ⇒
(e, r, e)∈ T or(e, r, e)̸∈ T.
•Relation rand relation rareinverse
if(e, r, e)∈ T ,∀e, e∈ E ⇒
(e, r, e)∈ T.
•Relation riscomposed by relation rand
rif(e, r, e)∈ T ∧ (e, r, e)∈
T,∀e, e, e∈ E ⇒ (e, r, e)∈ T.
4 TranSHER
4.1 Score Function
We propose a simple yet effective translational
distance-based score function TranSHER . The key
intuition behind TranSHER is to provide more free-
dom with the relation-specific translation to ease
the hyper-ellipsoidal restriction, while still keeping
enough ability for complex relations modeling and
training stability.
For this aim, TranSHER first maps the entity
vectors to hyper-ellipsoids with underlying fixed-
norm restriction for the actual entity embeddings
and hence brings about general training stability;
then conducts a relation-specific translation on the
restricted entities for modeling the distances be-
tween mapped head and tail clusters. Specifically,
we first define a mapping function G(e)to restrict
the entities on the hyper-ellipsoid surface. Since8519the fact triplets are directional, we use two sepa-
rate relation-specific mapping functions G(e)
andG(e)to manage the cases when an entity is
considered as head or tail, correspondingly:
G(e) =r◦e
|e|, r, h∈R(1)
G(e) =r◦e
|e|, r, t∈R(2)
where the ◦here stands for the element-wise prod-
uct. The mapping can be regarded as restricting
the entities on unit hyper-spheres by fixing the L
norm||⃗ e||= 1and conducting further linear scal-
ing w.r.t. different relations. As the softmax loss in
training intends to learn radially distributed entity
representations (Wang et al., 2017), such a fixed-
norm restriction of entity representations conse-
quently benefits the stability of TranSHER opti-
mization process (Xu and Durrett, 2018; Wang and
Isola, 2020). With GandG, we are able to map
the entity vectors to two hyper-ellipsoids accord-
ing to the relations and whether they are heads or
tails, as shown in Fig. 1a. Note that the entity em-
beddings will distribute on the unit hyper-sphere if
r= 1orr= 1.
Then, we introduce a relation-specific transla-
tion item B∈R, which not only eases the hard
hyper-ellipsoidal restriction but also encourages
to identify the hard-to-distinguish entities close in
space for complex relations. Accordingly, the final
score function of TranSHER can be derived as:
f(e, e) =γ−||G(e)+B−G(e)||(3)
where γis an adjustable constant margin. Note
that all the embeddings share the same dimension
setting k, i.e., r, r, B, e∈R. The additional
translation for the entities with hyper-ellipsoidal
restriction increases the degree of freedom of the
score function and hence could provide extra op-
timization options for modeling the distances be-
tween entity clusters connected by complex rela-
tions.
4.2 Initialization
The initialization strategy plays an important role
in neural network optimization (Erhan et al., 2009;
Hayou et al., 2018), especially in the case of knowl-
edge graph modeling that consists of enormous
numbers of entity-relation-entity interactions. Clas-
sic knowledge graph embedding works pay less at-
tention to initialization and adopt simple strategies.For example, both TransE and PairRE randomly
initialize all the embedding weights with the same
uniform distribution. After our practical implemen-
tation, we notice different initialization strategies
place different assumptions on embeddings, which
also largely influence the performances.
In this regard, all three main components in Tran-
SHER need to be well-considered and initialized,
i.e., the relation embeddings R, entity embeddings
E, and translations B. To better model the distribu-
tion of knowledge graph embeddings, we propose
to conduct initialization searching for the optimal
initial distributions for each component in Tran-
SHER. We select empirically validated strategies
from two main categories, uniform, and normal
distributions, for the component-independent ini-
tialization of TranSHER. For uniform distribution
we follow the setting in Sun et al. (2019), where
the weights are initialized with the gamma uniform
U(−,). The ϵhere is a placeholder con-
stant for the edge case that γ= 0. For the normal
distribution, the Xavier normal proposed in Glorot
and Bengio (2010) is adapted as N(0, g·/radicalig)for
TranSHER, where the gain gis defined as a scaling
factor.
Without strict distribution assumptions for the
parameters in the three components (i.e., R,E,
andB), TranSHER allows the components to be
initialized independently with different distribu-
tions. The selection of the initial distribution for
each component in TranSHER can vary through
different knowledge graphs since they do not share
the same data distribution. We will discuss in sec-
tion 5.5 that, due to a more effective optimization
process and potentially introducing appropriate in-
ductive bias, such an initialization searching strat-
egy allows TranSHER to produce better results.
4.3 Training and Optimization
Following the standard self-adversarial training
framework (Sun et al., 2019), the general loss func-
tion for optimization is:
L=−logσ(f(e, e))
+/summationdisplayp(e, r, e) logσ(−f(e, e))(4)
where σstands for the sigmoid activate function
andp(e, r, e)is the self-adversarial weight cal-
culated according to the scores.85204.4 Modeling Ability
Given the aforementioned design, our score func-
tion can be better optimized in training without
losing the ability to learn different relation pat-
terns. We prove that TranSHER can model symmet-
ric/antisymmetric, inverse, and composed relations
with the following constraints:
•symmetry :(r◦+B−r◦=
0)∧(r◦+B−r◦= 0)⇒
r=−r
•antisymmetry :(r◦+B−r◦=
0)∧(r◦+B−r◦̸= 0)⇒r̸=
−r
•inversion :(r◦+B−r◦=
0)∧(r◦+B−r◦= 0)⇒
(r◦r=r◦r)∧(B=−B)
•composition :(r◦+B−r◦=
0)∧(r◦+B−r◦= 0)∧
(r◦+B−r◦= 0)⇒(r=
r◦r)∧(r=r◦r)∧(B=r◦
B+r◦B)
This proof shows that TranSHER introduces ad-
ditional relation-specific translations for easing the
hyper-ellipsoidal restriction without losing the abil-
ity of modeling various relation patterns.
5 Experiments
5.1 Experimental Setup
Datasets and Evaluation. We conduct extensive
experimentation on five publicly available datasets
for two evaluation settings of the link prediction
task. For the classic full ranking setting that re-
quires an exhaustive search through the entity set E,
we select FB15k-237 (Toutanova and Chen, 2015),
YAGO37 (Guo et al., 2018), and DB100K (Ding
et al., 2018), which are extracted and constructed
from knowledge databases (Suchanek et al., 2007;
Bollacker et al., 2008; Bizer et al., 2009). Adopted
from the Open Graph Benchmark (OGB) (Hu et al.,
2020), the other setting of partial ranking only re-
quires distinguishing the target entity from a ran-
domly sampled entity subset. The ogbl-wikikg2
dataset with a massive number of triplets and the
ogbl-biokg dataset consisting of biomedical facts
are selected from the OGB link property prediction
leaderboard. The statistics of the dataset are listed
in Tab. 1. For both evaluation settings, the Mean
Reciprocal Rank (MRR) is regarded as the main
metric and Hits at N (HIT@N) as the auxiliary
metric. More details of the datasets and evalua-
tion protocol can be referred to in Appendix A.1
and A.2.
Baselines. Our baselines include the two main
categories of knowledge graph embedding methods
for comparison. For the similarity-based semantic
matching methods, DistMult (Yang et al., 2015),
ComplEx (Trouillon et al., 2016), and SEEK (Xu
et al., 2020) are selected. We choose the classic
TransE (Bordes et al., 2013), RotatE (Sun et al.,
2019), and the recently proposed PairRE (Chao
et al., 2021) as the baselines in the other category
ofdistance-based methods. The model PairRE is
the main baseline in our work. More details can be
referred to in Appendix A.3.
Implementation Details. Following our design in
§4.2, the three components of TranSHER are ini-
tialized with the gamma uniform (Sun et al., 2019)
and the Xavier normal (Glorot and Bengio, 2010)
distribution alternatively to achieve the best result.
Our model is also fine-tuned with light parameter
search on γand regularization weights on trans-
lation embeddings according to datasets. All the
experiments are set up in a GPU-accelerated hard-
ware environment. We follow Wang et al. (2014)
to counts hptandtphto categorize relation types
through the given dataset T. Further implementa-
tion details could be found in Appendix A.4.
5.2 Overall Results
As revealed in Tab. 2 and Tab. 3, our model
achieves significant performance improvement in
the main metric MRR on all five different link
prediction datasets compared to the strong base-
lines. On the datasets that require full ranking
through all entities, TranSHER makes substantial
improvement on the main metric MRR as shown
in Tab. 2, surpassing PairRE and SEEK. As for
results on datasets in Hu et al. (2020), TranSHER
also has considerable performance gain as shown
in Tab. 3. For the two datasets using the par-8521
tial ranking setting, TranSHER also achieves in-
cremental performances. On the very large-scale
dataset ogbl-wikikg2, TranSHER improves about
3% MRR while keeping the dimension number of
the entity and thus show its potential to extend on
a knowledge graph with a large size. On the ogbl-
biokg dataset, which distinguishes the challenge by
isolating entities by types, TranSHER also shows
its superiority at generalizing well across domains.
5.3 Complex Relations Modeling
The triplets with complex relations (1-to-N, N-to-1,
and N-to-N) hold a large portion in many datasets.
More importantly, they are more difficult to model
than 1-to-1 relations. In this regard, we conduct
experiments to analyze the performance of Tran-
SHER on different types of triplets.
Results on FB15k-237 along relation types in
Tab. 4 demonstrate that TranSHER makes stable
gains on triplets with complex relations. For the
N-to-N relation triplets (accounting for 87% of the
whole dataset), TranSHER achieves better perfor-
mances in MRR and HIT@10 on both head predic-
tion and tail prediction tasks, even compared to the
best baseline PairRE. This signifies that our pro-
posed model can actually model complex relations
better. A potential reason for this improvement of
TranSHER is its most distinct part, relation-specific
translation. We will give a more detailed analysis
in the following sections.To further learn the intrinsic influence of the
relation-specific translation of TranSHER on dif-
ferent relation types, we visualize the translation
embeddings on the FB15k-237 and DB100K by
presenting the absolute value heat maps. As shown
in Fig. 2, the translation embeddings of complex
relations have obvious color differences from those
1-to-1 relation embeddings. The embeddings of
1-to-1 relations are closer to zero than complex re-
lations; this signifies the translational item mainly
contributes to complex relations 1-to-N, N-to-1,
and N-to-N, whilst 1-to-1 relations are learned less.
Specifically, translations of N-to-N relations are the
most active, which suggests TranSHER puts more
effort into these hard-to-learn relations. The behav-
ior of translations on 1-to-1 relations implies that
the easier relations require less optimization dur-
ing training. The observation of this preference for
complex relations from the relation-specific trans-
lations provides supportive evidence for the experi-
mental results in Tab. 4.
5.4 Translation Impacts
In order to explore how exactly the relation-specific
translation affects modeling, we analyze the influ-
ence of the translations from the perspectives of
training optimization and the score function itself.
To study TranSHER from the view of the train-
ing process, the standard deviation of weight gradi-
ents for entities and relations are plotted in Fig. 3,8522
following similar settings in Glorot and Bengio
(2010). We found that TranSHER largely reduces
the gradient standard deviation of relation embed-
dings only at the beginning of training and keeps
a similar trend to the baseline for the rest epochs.
What most distinguishes the optimization process
of TranSHER from PairRE is that TranSHER main-tains a relatively low standard deviation of entity
embedding gradients along with the whole training.
Such a low standard deviation implies the stable
optimization progress of TranSHER. The adjust-
ment of entity embeddings usually requires more
effort since the number of entities is about thirty
times larger than the relations in FB15k-237 (and8523
similar cases for other datasets, see Tab. 1). We
suspect that the generally superior results of Tran-
SHER are mainly brought about by a more stable
optimization of entity embeddings.
From the perspective of the score function, the
relation-specific translation item can directly af-
fect the distance calculation. We plot the distri-
bution of L1 Norm values of the k-dimensional
translation embeddings to learn of such an impact
(Fig. 4). Most L1 Norms of translation embeddings
are larger than the margin γin both experiments on
FB15k-237 and DB100K, which suggests a promi-
nent impact from the translation in modeling.
5.5 Initialization Strategy
During the implementation, we found that the ini-
tial strategy of TranSHER components is crucial
to the performance, and thus we conduct a further
study on the initialization strategies combinations
on the FB15k-237 and DB100K datasets.
We compare the results of several initialization
methods to learn the effect of different distributions,
as revealed in Tab. 5. Specifically, the gamma uni-
form distribution Uand the Xavier normal dis-
tribution Nare alternatively adopted for three
components in TranSHER, i.e. the entities E, the
relational mapping G, and the relation-specific
translations B. Such a strategy of initialization
combination produces a set of eight experiments on
each dataset while keeping the same size of model
parameters.
Among all the initialization combinations, the
strategy of ’’ leads to the strongest perfor-
mance on FB15K-237, while the ’’ vari-
ant gets the best MRR result on DB100K. The
observation of the best initialization strategy vary-
ing through datasets suggests that the initialization
strategy of TranSHER can accommodate discrep-
ancies through different knowledge graphs, which
brings about performance gains on link prediction.
5.6 Case Study
We further provide a case study to illustrate the ef-
fectiveness of TranSHER in handling challenging
link predictions. In Tab. 6, the query asks for the
producer of a 1950 animated musical fantasy film
Cinderella (NB: the produced_by relation defined
in FB15k-237 only refers to producers). While
PairRE is capable of retrieving relevant entities like
the production studio/company, and even a com-
poser that used to work on another Walt Disney
film, it still struggles with learning the semantic
meaning of the relation and mixing the neighbor en-
tities in representation space. Meanwhile, the high-
ranking entities found by TranSHER are mostly
producers/directors and the exact subsidiary of the
production studio. This implies that TranSHER
does not only have the ability to cluster the rele-8524vant entities restricted on hyper-ellipsoids but can
also accurately model the semantic meaning of the
particular relation "who is the producer of the film"
with the relation-specific translation item. More
cases can be found in Appendix B.
6 Conclusion
We propose a novel knowledge graph embedding
model TranSHER for the link prediction task. Tran-
SHER leverages relation-specific translation on en-
tities with hyper-ellipsoidal restriction, which is
explicitly encoded into the score function. By in-
troducing the translation, TranSHER can improve
the optimization of entities distributed on hyper-
ellipsoids and shows ingenuity in understanding
semantic characteristics. Moreover, we prove that
TranSHER preserves the ability to represent logical
reasoning relation patterns. Comprehensive exper-
iments on different datasets show that TranSHER
has robust performance and improves complex re-
lation modeling.
Limitations
The proposed model TranSHER mainly provides in-
sight into how the translation item can improve the
knowledge graph embedding methods for the link
prediction task with restricted entities. However,
due to the enormous number of entities in knowl-
edge graphs, this work does not directly show the
learned entity representation distribution, which
could potentially provide further information bene-
ficial to the task.
Acknowledgement
Yizhi Li is fully funded by an industrial PhD stu-
dentship (Grant number: 171362) from the Univer-
sity of Sheffield, UK.
References85258526A Experimental Details
A.1 Datasets
Extensive experiments are conducted on five pub-
licly available datasets. The FB15k-237 dataset
is filtered from another dataset FB15k (Toutanova
and Chen, 2015; Bordes et al., 2013), which is built
from a knowledge fact database, Freebase (Bol-
lacker et al., 2008). Compared to FB15k-237,
two larger-scale knowledge graphs DB100K (Ding
et al., 2018) and YAGO37 (Guo et al., 2018) with
about ten times of entities are also selected. The
YAGO37 is a subset selected from the YAGO3
core facts (Guo et al., 2018; Suchanek et al.,
2007). and the DB100K is constructed from the
mapping-based objects of core DBpedia (Ding
et al., 2018; Bizer et al., 2009). We additionally
test our model on two distinguished link predic-
tion datasets (Hu et al., 2020). ogbl-wikikg2 is a
very large-scale dataset derived from the Wikidata
knowledge base (Vrande ˇci´c and Krötzsch, 2014).
ogbl-biokg uses data from biomedical data reposi-
tories and divides the entities into 5 types according
to domain knowledge.
To prove the generalization ability of TranSHER,
we select datasets of various entity quantities from
15k (FB15k-237) to 2,500k (ogbl-wikikg2), which
spans three orders of magnitude.
A.2 Evaluation Protocol
Following standard implementation, we use Mean
Reciprocal Rank (MRR) and Hits at N (HIT@N)
as our metrics on all the datasets, whilst MRR is
referred to as the main evaluation measure due to its
relatively comprehensive perspective. The general
evaluation settings for the link prediction task can
be recognized as the full ranking setting and the
partial ranking setting according to the selection
methods of negative samples for testing.
Except for datasets selected from Hu et al.
(2020), the ranking candidates are all entities that
appeared in the knowledge graph, i.e. a full ranking
task setting. Following the standard protocol, the
scores of the extra correct entities in each query
are filtered during full ranking testing. Note that
for ogbl-wikikg2 and ogbl-biokg, the ranking can-
didates are the positive entity and 500 randomly
sampled negative entities (with a separate 500 for
prediction head and tail tasks). Specifically, the
sampled negative entities belong to the same type
of positive ones in the ogbl-biokg.A.3 Baselines
Two main categories of knowledge graph embed-
ding methods are chosen in our work to compare
and validate the performance of TranSHER:
• Semantic matching score functions
• Distance-based score functions
The semantic matching score functions intend
to study interactions in knowledge graphs with
similarity-based score functions. We select Dist-
Mult (Yang et al., 2015) and ComplEx (Trouillon
et al., 2016) as the representatives of such meth-
ods that leverage inner-product largely. Moreover,
a recently proposed framework SEEK (Xu et al.,
2020) is selected as a strong baseline for the dataset
YAGO37. We also categorize SEEK as a semantic
matching due to its usage of inner-product calcula-
tion even if it conducts hard segmentation on the
embeddings.
Methods in the other category, distanced-based ,
design score functions to model the distance be-
tween connected entities in low-dimensional space.
Additional to the foundational distance-based func-
tion TransE (Bordes et al., 2013), we also take two
more effective models RotatE (Sun et al., 2019)
and the PairRE (Chao et al., 2021) as our baselines.
PairRE is the main baseline since it has competitive
performance and adopts the same restriction on the
entities as TranSHER.
A.4 Implementation Details
As described in §4.2, the entity embeddings in E,
mapping weights of G, and relation-specific trans-
lations Bcan be initialized either with gamma
uniform implemented in (Sun et al., 2019; Chao
et al., 2021) or the Xavier normal distribution (Glo-
rot and Bengio, 2010). The gamma uniform is
set as U(−,), ϵ= 2.0the scaling gain
for Xavier normal N(0, g·/radicalig)is set to g=
1.0. Parameter searches on γand regularization
weights on translation embeddings are adopted,
while the embedding dimension kremains the same
as PairRE. The extra effort of embedding dimen-
sion tuning is spent on the YAGO37 dataset since
the original work PairRE does not provide the im-
plementation on it.
All the experiments occupy a capacity under
16GB RAM on an RTX 3090 GPU. To get the
relation type information following Wang et al.
(2014), we count hptandtphthrough all the triplets
from the given dataset including the test split.8527
B Supplementary Case Study
We provide extra cases for further analysis on the
FB15k-237 dataset, where the head prediction task
cases are shown in Tab. 7 and tail prediction tasks
in Tab. 8, respectively.
In general, we can observe that both TranSHER
and PairRE can retrieve relevant entities in the same
or similar topic according to the given relation-
entity queries, which distribute from the entertain-
ment domain to medical knowledge facts. For in-
stance, in the jaundice case at the left of Tab. 7, the
entities recalled by the models are all terminologies
from the practice of medicine. This implies that the
score functions with hyper-ellipsoidal restriction
can model the entities in the same neighborhood
and assign close positions in the latent space with
regard to their graphical interactions such as the
n-hop distances.
However, similar to the case described in §5.6,
TranSHER shows additional precision for predict-
ing the correct entities by learning the inherent
semantic categorization of entities with the extra
relation-specific translations. Regarding the afore-
mentioned jaundice example, the query specifi-
cally asks for the symptom of the jaundice dis-
ease, which could be highly related to liver dis-eases.Although the PairRE has learned the close
relationships between jaundice and liver diseases
and distributed these entities close with the hyper-
ellipsoidal mapping, it fails to distinguish the con-
cept disease from the close concept symptom and
assigns the liver-related with high ranks. In con-
trast with PairRE, our proposed model TranSHER
can learn the nuanced differences in these two con-
cepts defined in the relations. As a result, we sus-
pect that the semantic characteristic modeling of
score functions can be improved by the additional
relation-specific translation item in TranSHER.8528