
Jingwei Ni
ETH Zürich
njingwei@ethz.chZhijing Jin
MPI & ETH Zürich
jinzhi@ethz.ch
Qian Wang
University of Zürich
qian.wang@uzh.chMrinmaya Sachan
ETH Zürich
msachan@ethz.chMarkus Leippold
University of Zürich & SFI
markus.leippold@bf.uzh.ch
Abstract
Multi-task learning (MTL) aims at achieving
a better model by leveraging data and knowl-
edge from multiple tasks. However, MTL does
not always work – sometimes negative transfer
occurs between tasks, especially when aggre-
gating loosely related skills, leaving it an open
question when MTL works. Previous studies
show that MTL performance can be improved
by algorithmic tricks. However, what tasks and
skills should be included is less well explored.
In this work, we conduct a case study in Fi-
nancial NLP where multiple datasets exist for
skills relevant to the domain, such as numeric
reasoning and sentiment analysis. Due to the
task difficulty and data scarcity in the Finan-
cial NLP domain, we explore when aggregat-
ing such diverse skills from multiple datasets
with MTL can work. Our findings suggest that
the key to MTL success lies in skill diversity,
relatedness between tasks, and choice of aggre-
gation size and shared capacity. Specifically,
MTL works well when tasks are diverse but
related, and when the size of the task aggrega-
tion and the shared capacity of the model are
balanced to avoid overwhelming certain tasks.
1 Introduction
Multi-task learning (MTL) is a machine learn-
ing paradigm where multiple learning tasks are
optimized simultaneously, exploiting commonali-
ties and differences across them (Caruana, 1997).
MTL is expected to outperform single-task learning
(STL) as it utilizes more training data and enables
inter-task knowledge sharing (Ruder, 2017). How-
ever, MTL may also bring about multi-task conflict
and negative transfer. Empirically, in many MTL
systems, only a small portion of tasks benefit from
MT joint training while others suffer from negative
transfer (Stickland and Murray, 2019; Raffel et al.,
2020; Peng et al., 2020). Therefore, it is still an
open question when MTL will work .Method TSA ↓ SC↑
GPT-3 Zero-Shot 0.3700 77 .69%
GPT-3 Few-Shot 0.3128 80 .37%
FinBERT Fine-Tune 0.2054 86 .61%
Table 1: Performance comparison of our method (Fin-
BERT Fine-Tune) and GPT-3 (text-davinci-003) base-
lines. We report the rooted mean square error ( ↓) on the
task of target-based sentiment analysis (TSA) (Cortis
et al., 2017) and accuracy ( ↑) on sentiment classifica-
tion (SC) (Malo et al., 2013). See GPT-3 prompts and
settings in Appendix B.
MTL systems have two components: MTL al-
gorithms and the tasks included for aggregation.
Recent progress in MTL has shown that appropri-
ate MTL algorithms (e.g., architecture and opti-
mization) can mitigate negative transfers (Yu et al.,
2020; Wang et al., 2021; Pfeiffer et al., 2021;
Karimi Mahabadi et al., 2021; Mao et al., 2022;
Ponti et al., 2023, inter alia ). However, it is still un-
clear when MTL works from the perspective of the
relations between tasks and skills to be aggregated
for better performance in a practical setting.
To understand this, we conduct a practical case
study on Financial NLP. We choose Financial NLP
mainly because (1) Financial NLP tasks are hard:
GPT-3 (Brown et al., 2020) does not perform well
on financial tasks (see Table 1), though it is a good
zero/few-shot learner in general domains; and (2)
Financial NLP datasets typically address differ-
ent skills (e.g., quantitative reasoning, and senti-
ment analysis), and have a limited data size (Malo
et al., 2013; Cortis et al., 2017; Lamm et al., 2018a;
Mariko et al., 2020; Chen et al., 2019a, 2020, in-
ter alia ). Therefore, it is promising to aggregate
Financial NLP tasks using MTL, which not only
compiles and augments the small datasets, but also
benefits the difficult tasks through relevant informa-
tion transfer and comprehensive reasoning. How-
ever, no previous work explores the benefits of7465aggregating Financial NLP resources using MTL.
Particularly, we explore the following hypotheses
about when MTL works:
H1. When various skills are included : Intuitively,
positive transfers are likely to happen among
tasks regarding the same skill. However, di-
versified skills might benefit the MTL system
through implicit data augmentation, attention
focusing, and feature eavesdropping (Ruder,
2017). Our empirical results also show that
skill diversity benefits MTL.
H2. When the aggregated tasks are well related :
We find that the close relation (measured qual-
itatively and quantitatively) among Financial
NLP tasks explains why diversified skills help
each other, and contributes to the success of
MTL.
H3. When the aggregation size matches shared
capacity : Too many objectives may exhaust
the MTL shared capacity and cause inter-
ference among tasks (Stickland and Murray,
2019). We find that excessive aggregation size
in a limited capacity model restricts the perfor-
mance of some tasks. Thus aggregation size
should be appropriate for the shared capacity.
To facilitate exploration of H1andH2, we survey
existing Financial NLP resources and propose Fin-
DATA (Financial DataAndTasks Aggregation),
a collection of Financial NLP tasks covering var-
ious financial text understanding skills. To check
H3, we propose SPAL-FinBERT (Shared Parallel
Attention Layer with FinBERT ), an MTL architec-
ture based on pre-trained FinBERT (Araci, 2019),
but is highly parameter-efficient – with 99.8%
fewer trainable parameters but outperforming the
vanilla FinBERT MTL on several tasks. Our con-
tributions include
1.We conduct a case study on Financial NLP to
explore what properties of task aggregation
lead to the success of MTL.
2.We survey and aggregate several existing Fi-
nancial NLP tasks and datasets, illustrating
that MTL can be a cheap and efficient im-
provement for Financial NLP performance.
3.We propose SPAL-FinBERT, a parameter-
efficient MTL architecture with good perfor-
mance. This model may also have broader use
cases in other settings.2 Background & Related Work
Previous work mainly focuses on two categories of
MTL practice: MTL as pre-training and MTL as
auxiliary training.
MTL as pre-training: Besides unsupervised pre-
training, supervised data can also be utilized for
pre-training in an MTL manner (i.e., an interme-
diate training stage) to improve the model’s multi-
aspect intelligence and generalizability to unseen
tasks. Such an approach has been shown beneficial
for various pre-trained models, including encoder-
only models (Liu et al., 2019; Aghajanyan et al.,
2021), encoder-decoder models (Aribandi et al.,
2022; Chung et al., 2022), and large language mod-
els (Wei et al., 2022; Sanh et al., 2021; Min et al.,
2022; Chung et al., 2022). Aghajanyan et al. (2021)
show that MTL pre-training does not work with
small-scale task aggregation. More recent analysis
shows that aggregating related tasks transfers better
to a known target task (Padmakumar et al., 2022).
MTL as auxiliary training: Instead of training a
target task alone, we can jointly train it with other
auxiliary tasks to improve its performance in an
MTL manner (i.e., the final training stage). How-
ever, this approach does not work in most cases,
especially when multiple skills are aggregated (e.g.,
GLUE) (Stickland and Murray, 2019; Peng et al.,
2020; Raffel et al., 2020; Mueller et al., 2022).
Previous work shows that appropriate algorithmic
tricks lead to more success in MTL: (1) MTL ar-
chitecture: Pfeiffer et al. (2021); Karimi Mahabadi
et al. (2021) and Ponti et al. (2023) propose MTL
architectures that encourage high-level knowledge
sharing instead of direct parameter-sharing; and (2)
MTL optimization: Yu et al. (2020) and Wang et al.
(2021) geometrically manipulate the gradients to
reduce the conflicts, and Mao et al. (2022) learn
to weight losses of including tasks automatically.
In computer vision (CV), Fifty et al. (2021) ad-
dress that task aggregation is also crucial for MTL
besides algorithms and proposes an algorithm to
select the best task grouping from a task collection.
However, rare previous work in NLP analyzes what
task aggregation leads to the success of MTL and
what qualities of a task aggregation are important.
3 FinDATA Compilation
We compile FinDATA, a task aggregation on Finan-
cial NLP, to facilitate the case study. We first set
the desiderata, and then survey existing Financial7466NLP tasks to select those that meet these criteria.
3.1 Desiderata
Diversified skills: We are interested in the impor-
tance of skill diversity and task-relatedness in MTL.
Therefore, included tasks should cover as many Fi-
nancial NLP skills as possible. If multiple tasks
correspond to the same skill (e.g., sentiment anal-
ysis), we prefer smaller ones that are more worth
aggregating and less likely to dominate. Some
tasks can have closer relation than others (e.g., cor-
responding to similar skills).
Aligned form of input: To enable joint training,
we prefer tasks with sentences or paragraphs as
inputs, instead of phrases, tables, or full reports.
3.2 Financial NLP
The most prevalent Financial NLP task is sentiment
analysis on financial tweets or news, as it directly
contributes to automatic decision-making tools in
the financial market. There are two types of finan-
cial sentiment analysis, the first of which defines
sentiment analysis as a coarse-grained classifica-
tion problem. Given a piece of financial news, the
system only needs to classify its sentiment into pos-
itive, negative, or neutral. Most of the financial
sentiment analysis are in this form, for example, Fi-
nancial Phrase Bank (Malo et al., 2013), and Stock-
Sen (Xing et al., 2020). The other instantiation of
financial sentiment analyses has more fine-grained
labels: Cortis et al. (2017) assigns different sen-
timent scores from −1to1to different targets in
financial news.
Numbers are ubiquitous in all forms of financial
text (e.g. news, tweets, and reports). Hence, many
tasks and datasets are proposed for number seman-
tics and numeracy. For example, FinNum shared
task of recent years proposed several datasets
focusing on financial number type understand-
ing and number attachment (Chen et al., 2018,
2019a, 2020). Chen et al. (2019b) further pro-
posed Numeracy-600K for number magnitude un-
derstanding. Zhu et al. (2021) proposed TAT-QA,
a Question Answering(QA) benchmark financial
hybrid (tabular and text) data. Similarly, Chen et al.
(2021) proposed FinQA, another QA benchmark on
financial hybrid data emphasizing numeracy skills.
Some datasets provide financial natural language
understanding (NLU) skills other than sentiment
and numbers. For instance, Lamm et al. (2018a)
proposed a dataset for analogy parsing originally,which contains financial semantic role annotations
and thus can be used for semantic role labeling
(SRL). (Mariko et al., 2020) detects causal effect
in financial news.
Not all financial NLP tasks are sentence-level.
Many tasks take entire documents as inputs, for
example, narrative summarization (El-Haj et al.,
2020) and table of content prediction (Maarouf
et al., 2021) on financial reports. Some other tasks
focus on financial concepts (phrases) (Maarouf
et al., 2020; Kang et al., 2021; Pontes et al., 2022)
instead of complete sentences. Appendix D covers
more details regarding mentioned datasets.
3.3 FinDATA
Based on our survey and desiderata, the following
4 Financial NLP skills are selected:
Financial sentiment analysis is a prevalent skill
in the Financial NLP domain, analyzing financial
news’ and investors’ sentiment toward particular
financial objects. We select two tasks for this skill:
(1) Financial Phrasebank sentiment classification
(SC, Malo et al., 2013): given a financial news
headline, classifying it into positive, negative, or
neutral; and (2) SemEval-2017 target-based senti-
ment analysis (TSA, Cortis et al., 2017): predicting
a sentiment score between -1 and 1 w.r.t. a financial
news headline and a target company.
Financial number understanding is another im-
portant Financial NLP skill, as numbers are ubiq-
uitous in all forms of financial text (e.g., news,
tweets, and reports). We select two tasks for this
skill: (1) FinNum-3 number classification (NC)
(Chen et al., 2020): given a report paragraph and
a target number, classifying it into monetary, per-
centage, temporal, and so on; and (2) FinNum-2
number attachment detection (NAD) (Chen et al.,
2019a): given a financial tweet, a target number,
and a cash tag, predicting whether the number is
attached (i.e., related) to the cash tag.
Financial semantic role labeling (FSRL) is a skill
aiming at understanding the quantitative semantic
roles (Lamm et al., 2018b) such as quantity, value,
location, date, theme, etc. We include Lamm et al.’s
(2018a) datasetfor this skill.
Causality understanding aims at understanding
the causal relationship between financial facts. For
this skill, we include FinCausal 2020 Causality7467
Detection (CD, Mariko et al., 2020).
All our datasets are in English. Other details
of included tasks can be found in Table 2. We
present several examples for each FinDATA dataset
in Appendix J.
4 Multi-Task Learning Systems
We consider various MTL systems in the form of
shared encoder + one-layer task-specific predic-
tion headers. The MTL problem is formulated as
follows:
We are given a joint dataset of multiple tasks
D={(X, Y)}where X, Ydenotes the
training corpus and labels of task t; andTdenotes
the task collection. We are also given a pre-trained
encoder (e.g., FinBERT) f(·)and task-specific
prediction headers h(·), which are parameterized
byθ= (θ,{θ}). The training loss for multi-
task fine-tuning:
L(θ,D) =w·l(h(f(X)), Y)(1)
Where ldenotes the loss function for task t, and
wdenotes the sampling weight of task t. The
generic architecture is illustrated in Figure 1. Dur-
ing training, a task is sampled for each training step,
and the corresponding prediction header and the
shared encoder are updated (e.g., the TSA example
in Figure 1).
5 Experimental Setup
We fine-tune all MTL and STL models on corre-
sponding data for 40 epochs. (Our MTL batch-
ing scheme is described in Appendix C.) For STL,
we evaluate the model every 50 steps and save the
checkpoint with the best validation score. For MTL,
we evaluate every 200 steps, saving and reporting
the best checkpoint for each task independently fol-
lowing the setting of Raffel et al. (2020) (i.e., each
task can be viewed as the target task with others
being auxiliary tasks). We follow the evaluation
metrics in Table 2 to select the best checkpoints
and report the test performance. All MTL and STL
results are averaged over random seeds from 1 to
5 with standard deviations attached. Appendix C
contains more details about data preprocessing, hy-
perparameters, and GPU usage.
Pre-trained Model Selection & STL Baselines:
Existing financial pre-trained models (Araci, 2019;
Yang et al., 2020; Liu et al., 2020; Hazourli, 2022)
are usually compared on the Financial PhraseBank
dataset (Malo et al., 2013). Such comparison is
suboptimal because (1) Financial PhraseBank sen-
timent analysis has no official test set. Existing
work separates test sets on their own, making the
scores less comparable across different work; and
(2) the models are not compared on benchmarks
other than sentiment analysis. Therefore, we com-
pare financial pre-trained models on all FinDATA
tasks to select the best one.
STL results on all publicly available financial
pre-trained models (P-FinBERT (Araci, 2019), Y-
FinBERT (Yang et al., 2020), and FinancialBERT
(Hazourli, 2022)) and BERT (Devlin et al., 2019)
are presented in the first half of Table 3. P-
FinBERT (Araci, 2019) outperforms other pre-7468trained models. Therefore, we use P-FinBERT in
all subsequent experiments.
6 Analysis
In this section, we analyze the hypotheses about
when aggregating multiple skills with MTL works.
6.1 H1: Skill Diversity
To verify the hypothesis that skill diversity ben-
efits MTL, we compare the MTL results on full
FinDATA and its subsets that ablate one skill or
focus on one skill. Specifically, ablating a skill
results in four subsets: w/o financial semantic role
labeling, w/o causality detection, w/o sentiment
analysis, and w/o number understanding. Focus-
ing on a single skill results in two subsets: only
sentiment analysis and only number understanding.
We use FinBERT (Araci, 2019) as the shared en-
coder. The results are shown in Table 3. It can be
observed that (1) skill diversity benefits MTL: the
best MTL scores of all tasks are obtained by mix-
ing several different skills while concentrating on
sentiment/number understanding skills (w/o Senti-
ment and w/o Number) leads to a performance drop
on corresponding tasks; and (2) ablating FSRL de-
creases the performance of all other tasks, illustrat-
ing that FSRL positively transfers to all other skills.
Therefore, positive transfers can happen between
different skills. Including skills other than the
target skill in MTL is a potential way to benefit
target performance.
6.2 H2: Task Relatedness
Similar to FinDATA, GLUE also aggregates mul-
tiple NLU skills. However, GLUE MTL usually
leads to a performance drop on most tasks (accord-
ing to Stickland and Murray (2019) only RTE is
improved; and according to Mueller et al. (2022), 3
out of 9 tasks are improved) while FinDATA MTL
increases the scores of 4 out of 6 included tasks.
Therefore, we hypothesize that FinDATA tasks are
more closely related than GLUE tasks though they
all cover diverse skills. We measure the relatedness
among FinDATA tasks qualitatively and quantita-
tively:
Qualitative Analysis: Many tasks relate to each
other explicitly: (1) SC and TSA: though they have
different annotations, both of them predict finan-
cial sentiment. (2) FSRL and NC: “date” is one of
the classes in NC, while FSRL helps to understand
the semantic role of time numbers. These explicittransfers can be probed by different output head-
ers of an MTL system: for an input sentence, the
MTL system outputs predictions corresponding to
different tasks, where the non-target headers’ pre-
dictions may interpret the target prediction (Geva
et al., 2021). In Appendix I, we illustrate these ex-
plicit transfers by listing examples of the prediction
header’s outputs.
Quantitative Analysis: Vu et al. (2020) propose
task and text embedding to measure the similarity
between task objectives and texts. This embedding
algorithm facilitates high-level knowledge sharing
in the MTL architecture proposed by Karimi Ma-
habadi et al. (2021), which achieves superior perfor-
mance. Therefore, we use these metrics to quantify
the relatedness among the tasks aggregated in our
MTL systems. We follow Vu et al.’s (2020) calcula-
tion setting, except that we use FinBERT instead of
BERT: we first calculate task and text embeddings
of FinDATA and GLUE tasks. Then we compute
the cosine similarity scores among embeddings.
Figure 2a shows the heatmap of task embedding
similarity scores, indicating that FinDATA tasks
are more closely clustered than GLUE tasks ,
illustrating why FinDATA MTL leads to more im-
provements than GLUE MTL. Another observation
is that TSA has the lowest similarity scores with
other FinDATA tasks , which possibly explains
why it is not improved by MTL in Table 3. Fig-
ure 2b presents the heatmap of text embedding sim-
ilarity, where financial and general data are well
separated with high in-domain similarity.
However, the similarity scores are symmetric
metrics and thus fail to explain some asymmetric
transfers (which is also observed in previous work
(Geva et al., 2021)). For example, FSRL has a mod-
erate level of text and task similarity to other tasks,
but its performance is not enhanced by MTL while
it boosts the performance of others. A possible
explanation is that financial semantic understand-
ing skill (provided by FSRL) is a necessary ability
for other FinDATA tasks, but the skills covered by
other tasks are not necessary for FSRL. Therefore,
the joint training does not benefit FSRL.
We further analyze whether gradient similari-
ties interpret task-relatedness and MTL transfer-
ability since many previous works attribute the
negative transfer among aggregated tasks to gra-
dient conflicts (Ruder, 2017; Yu et al., 2020; Wang
et al., 2021; Mueller et al., 2022). However, our
findings in Appendix F show that gradient con-7469
flicts/similarities are not good measurements.
In conclusion, the degree of task-relatedness
serves as a significant predictor of the MTL out-
come, and can be roughly measured through quan-
titative and qualitative means. To better explain
asymmetric transfer and analyze the inter-task re-
lations in a finer grain, it is essential to develop
asymmetric measurements. We reserve that explo-
ration for future work.
6.3 H3: Matched Aggregation Size with
Shared Capacity
We hypothesize that having too many tasks shar-
ing limited model capacity might cause interfer-
ence among tasks and result in poor MTL perfor-
mance. Therefore, given a fixed pre-trained model,the task aggregation size should be appropriate for
the shared capacity to achieve the best MTL prac-
tice.
Section 6.1 shows that the task combination sig-
nificantly influences the MTL performance. Alter-
ing the task aggregation may introduce unwanted
positive or negative transfers. Therefore, to ver-
ify this hypothesis, we control the task aggrega-
tion (stick to FinDATA instead of adding other
tasks) and reduce the shared capacity to simulate
the scenario where task aggregation may exhaust
the shared capacity.
To enable altering shared capacity, we propose
SPAL-FinBERT, an architecture that both lever-
ages a pre-trained model and has tunable shared7470
capacity. Figure 3 illustrates the architecture. The
FinBERT layers are frozen while the parallel at-
tention layers (PALs, Stickland and Murray, 2019)
are trainable. Different from original task-specific
PALs, ours are shared across different tasks. Thus,
we call them shared PALs (SPALs). The design
is similar to Adapters (Houlsby et al., 2019): both
consists of light-weighted trainable structures and
a frozen pre-trained model. We choose PAL as the
shared trainable structure because it has a more
complicated structure than an adapter which might
benefit multi-task knowledge sharing (Adapters are
usually for STL). We can easily change the shared
capacity by setting the SPAL hidden size to any
multiple of 12 (the number of self-attention heads).
We run FinDATA MTL with SPAL hidden size
from 12 to 816. The smallest and the largest train-
able shared capacity are roughly 228K(0.2%of
FinBERT parameters) and 47M ( 42.7%of Fin-
BERT parameters). The results are shown in Fig-
ure 4. We surprisingly find that the aggregated tasks
are not equally sensitive to the change of shared ca-
pacity: negative transfer towards CD grows while
the shared capacity becomes limited. However,
Some tasks are not significantly restricted by the
limited shared capacity: SC and NC even achieve
the best scores with relatively small shared capac-
ity.
To verify that aggregating too many tasks in lim-
ited capacity overwhelms CD, we gradually ab-
lating tasks from the MTL system with minimalshared capacity. Table 4 presents the results. The
CD performance gradually improves when we de-
crease the aggregation size (although the task com-
bination can be a confounder for the CD perfor-
mance). The highest score is achieved when only
aggregating two tasks.
Therefore, to achieve better MTL practice, the
aggregation size should be appropriate for the
shared capacity to avoid overwhelming tasks
like CD . These tasks are sensitive to capacity shar-
ing. Including too many auxiliary objectives might
exhaust the shared capacity, distracting the MTL
system from these tasks. Other tasks (e.g., SC and
NC) might be more tolerant for capacity sharing,
thus allowing larger-scale MTL auxiliary training.
6.4 Efficiency of SPAL-FinBERT
Another observation of Figure 4 is that SPAL-
FinBERT outperforms vanilla FinBERT with much
fewer trainable parameters. In the most impres-
sive case, SPAL-FinBERT outperforms vanilla Fin-
BERT on four tasks with 99.8%fewer trainable pa-
rameters (when the SPAL hidden size is 12). One
possible reason behind our model’s performance is
that the frozen FinBERT provides a strong regular-
ization and thus reduces the representation variance
of each layer. Such generalized representations are
more likely to be favored by different tasks and
thus benefit MTL (Ruder, 2017). To verify this
explanation, we compare the representation gener-
alizations of SPAL-FinBERT and FinBERT MTL
systems.
Representation generalization: Intuitively, rep-
resentation generalization measures how similar
an MTL system represents data of different tasks.
We first compute the representations for all tasks,
models, and layers, following the formula:
R=1
|D|M(x) (2)
whereRdenotes task t’s representation gener-
ated by layer lof MTL model M;Ddenotes
the dataset of task t; and (x, y)denotes the
data points. Then, we compute the cosine simi-
larity score between all task representation pairs
(R,R), averaging the similarity scores to
measure the representation generalization of model
Mlayer l:
G=1
Ccossim( R,R)(3)7471
TSA↓ SC NC NAD FSRL CD
0.2109 87.8987.9786.6668.5673.77
- 87.3188.0986.3068.3574.31
- - 87.7385.8070.6673.61
- - - 85.9969.8074.65
- - - - 67.2774.80
- - - - - 73.57
where Cdenotes combination, Tdenotes the task
collection, and cossim denotes cosine similarity.
Figure 5 shows the representation generalization
for two MTL systems at different training steps.
For simplicity, only higher layers’ results (layer 7
to12) are presented as they are modified more by
fine-tuning (Zhou and Srikumar, 2022) and related
more to the output. It can be observed that SPAL-
FinBERT generates more generalized representa-
tions than FinBERT in all shown layers (especially
for the highest ones).
Another observation is that representation gener-
alization decreases when the training step increases.
One possible explanation for this downward trend
is that the MTL system is trying to learn task-
specific knowledge (especially in higher layers)
as multi-task fine-tuning continues.
In Appendix H, we further use an ablation ex-
periment and a probing experiment to show the
contribution of the frozen FinBERT and the neces-sity of freezing.
7 Discussion
Suggestions for MTL practice: Based on the re-
sults of our case study, we recommend the follow-
ing practices for future MTL: (1) aggregate not
only the target skill but also other related skills;
(2) select tasks for aggregation based on both their
qualitative and quantitative relatedness to the target
task; and (3) check if the target task is sensitive
to capacity sharing, excluding redundant (e.g., dis-
tantly related) tasks to avoid distracting the target
task.
Aggregating multiple skills with MTL is a po-
tential way for better Financial NLP practice:
Financial NLP tasks are more complicated than
those in the general domain, and many of them
suffer from a lack of data. Obtaining new Financial
NLP data is expensive since such annotation usu-
ally requires domain expertise. Our results show7472
that aggregating Financial NLP tasks using MTL
can be a practical and relatively cheap way to im-
prove their performance: SC, NC, NAD, and CD
are improved by up to 1.45,0.64,1.09, and 0.68
percentage points accordingly through MTL aux-
iliary training (contributed by different MTL sys-
tems). In Appendix G, we also show that MTL
pre-training with Financial NLP tasks can improve
the model’s generalizability to unseen tasks. There-
fore, future research and practice in Financial NLP
may consider MTL as a potential way to achieve
better performance.
Other possible questions: We address some other
possible questions that might be of interest to our
readers in Appendix A.
8 Conclusion
In this work, we conduct a case study on Fi-
nancial NLP to analyze when aggregating multi-
ple skills with MTL works from a perspective of
task relations and skills to be included. We pro-
pose a parameter-efficient MTL architecture SPAL-
FinBERT. Our empirical analyses point out poten-
tial directions to improve task aggregation for fu-
ture MTL practice: (1) considering diversified non-
target skills that might be supportive; (2) filtering
tasks with their relatedness; and (3) caring whether
capacity sharing overwhelms the target task. We
also show that aggregating resources through MTL
can be a cheap and efficient way to improve Finan-
cial NLP performance.Limitations
Firstly, the transferability between different tasks
within an MTL system is not well measured in
current work. We also find such transferability is
asymmetric and thus hard to quantify using sym-
metric measurements such as cosine similarity be-
tween task embeddings or gradients: for example,
TSA positively transfers to SC, but SC negatively
transfers to TSA (see the “Only Sentiment” row
in Table 3); FSRL positively transfer to all other
tasks, but other tasks negatively affect FSRL. Fu-
ture work may consider exploring better indicators
that address the asymmetry of task transferability
(e.g., similar to inter-task affinity scores (Fifty et al.,
2021) in the CV domain).
Secondly, some of the conclusions drawn from
our case study only point in a vague direction for
future MTL practice. For example, we find that
some tasks are more sensitive to capacity sharing
in Section 6.3. Therefore, aggregating an excessive
number of tasks with those tasks might overwhelm
them. However, it is hard to determine exactly each
task’s sensitivity to capacity sharing and the opti-
mal number of aggregated tasks without some trials
on different task combinations. Future work may
explore why some tasks are easily overwhelmed by
capacity sharing and propose methods to identify
them.
Thirdly, in this work, we analyze the influence
of multiple factors on MTL performance. However,
the factors are usually entangled and confound each
other. For example, we decrease the number of
tasks aggregated with CD to show that too large
aggregation overwhelms CD in a limited shared
capacity. But the tasks included (a confounder for
MTL performance) are also changed. Future work
may conduct rigorous causal analyses, exploring
how much each factor affects MTL performance.
Ethical Considerations
Data Privacy and Bias : All datasets used in this
research are published in previous studies and pub-
licly available: datasets for TSA, SC, FSRL, CD,
and Numeracy-600K can be downloaded from the
internet, while datasets for NC, NAD, and Stock-
Sen require signing corresponding agreements and
requesting from the authors.
Licenses: TSA is under Apache License 2.0; SC
is under CC BY-NC-SA 3.0; CD and StockSen are
under CC BY 4.0; and Numercay-600K, NC, and7473NAD are under CC BY-NC-SA 4.0. The license of
FSRL data is not explicitly specified, but the author
allows data usage with a proper citation in their
GitHub repository.
Most of the datasets are widely used in the Fi-
nancial NLP domain (e.g., shared tasks). We also
manually checked for offensive content in the data.
There is no data bias against certain demographics
with respect to these datasets.
Reproducibility : We make all of our code public
on GitHub. For data, we include links to request
NC, NAD, and StockSen, and provide data splits
for TSA, SC, FSRL, CD, and Numeracy-600K. We
also provide detailed instructions to reproduce all
the experiment results on GitHub.
Potential Use : The potential use of this study is to
improve future practice in MTL and the Financial
NLP domain.
Author Contributions
Jingwei Ni designed the project and the storyline,
and conducted the MTL analyses and the survey in
Financial NLP.
Zhijing Jin helped design the storyline and pro-
vided essential suggestions on what experiments
and analyses are important.
Qian Wang contributed to the financial back-
ground of the storyline, collected the first version
of FinDATA, and gave insights on what skills are
important from a financial perspective.
Mrinmaya Sachan andMarkus Leippold guided
the project and substantially contributed to the
storyline and experiment design.
Everyone contributed to writing the paper.
Acknowledgements
We sincerely thank the authors of Chen et al.
(2019a), Chen et al. (2020), and Xing et al. (2020)
for granting us access to their proposed datasets for
research.
References747474757476
A Possible Questions and Answers
A.1 Are H1 and H2 proposed in our work
conflict goals?
H1 encourages aggregating diverse skills for better
MTL practice, while H2 suggests that the related-
ness among tasks is also important, which seems
contrary to H1. However, these goals do not con-
flict with each other because: (1) skill diversity
does not imply distant inter-task relationships and
vice versa (e.g., NC is well related to SC and CD
in Figure 2a though they correspond to different
skills). (2) It is possible to achieve skill diversity
and good task-relatedness simultaneously: real-
world MTL practice can first consider the target
skill and other skills that might be supportive or
in the same domain. Then select the tasks that are
(qualitatively or quantitatively) closely related to
the target task to achieve better MTL performance.
A.2 Our work mainly addresses Financial
NLP. Are the conclusions generalizable to
other domains?
Although we only provide analyses in Financial
NLP, the heuristics for MTL practice are generic
for other domains. For H1, non-target skills in
the same domain are potentially helpful as variousskills are based on similar data. For H2, the quali-
tative and quantitative analyses for task-relatedness
are domain agnostic, meaning that we can select the
most related tasks from those with diversified skills.
For H3, continuously increasing the aggregation
size will finally reach a threshold that overwhelms
some tasks if the shared capacity is fixed.
B GPT-3 Prompts
In Table 1 we present the GPT-3 zero-shot and few-
shot performance on two Financial NLP tasks. We
use the official API provided by OpenAIto access
GPT-3. We choose the GPT-3 checkpoint Davinci-
003 to conduct the experiments (completion mode,
max token 5, temperature 0). The example prompts
we use for TSA and SC are illustrated in Table 5.
C Experimental Details
MTL Batching Scheme : During MTL, we first
randomly batchify training data of all tasks. Then,
we randomly mix the mini-batches and pass them
to the MTL data loader. This method is equivalent
to the temperature-based batch sampling scheme of
Karimi Mahabadi et al. (2021) where temperature
T= 1 (i.e., each task is sampled proportional to
its data size). We choose T= 1as FinDATA tasks
are not highly unbalanced in data size.
Data Preprocessing : SC and FSRL are in nature
text classification and token classification tasks.
Thus we use the raw texts from their datasets as
inputs. NC, NAD, and TSA are text classification
tasks, but they also require target companies or tar-
get numbers as inputs. Therefore, we use “|COM-
PANY|” to denote target companies and “<NUM-
BER>” to denote target numbers in input texts. CD
is originally a span prediction task. For simplic-
ity, we model it as a token classification task by
converting the span labels to BIO tags (i.e., begin-
ning and ending cause/effect spans to “B-CAUSE
I-CAUSE...” and “B-EFFECT I-EFFECT...”).
Hyperparameters : All models are fine-tuned with
a initial learning rate of 0.00005 , warm up steps
of500, and weight decay of 0.01. Batches sizes
we used for TSA, SC, NC, NAD, FSRL, and CD
are16,16,24,32,16, and 16correspondingly. For
the prediction header, we use a single feed-forward
layer followed by Softmax.
Evaluation Metrics Selection and Reporting :
The evaluation metrics are used not only for test-7477ing but also for best checkpoint selection during
validation. Therefore, we report single metrics
for all results to reflect MTL’s effect on each task.
We choose Accuracy for SC, NC, and NAD since
these datasets have no severe label imbalance. For
simplicity, we equivalently model CD, which is
originally a span prediction task, as a token classi-
fication task, and use Accuracy as the metric. TSA
is officially measured with cosine similarity (Cortis
et al., 2017). We find RMSE, as a regular metric
for regression tasks, has a high correlation with co-
sine similarity (see Table 6). Therefore, RMSE is
suitable for TSA measurement. Besides, we avoid
reporting average scores across tasks like related
work because it makes no sense to average RMSE
with Accuracy and F1 scores.
Evaluation Tools : We use sklearn 1.0.2 for se-
quence classification evaluation, and seqeval 1.2.2
for token classification evaluation.
GPU Usage : Experiments are trained on NVIDIA
RTX2080 GPUs. A single run of STL experiments
takes 4 to 16 GPU hours (4 GPU hours for the
small datasets; 16 GPU hours for the large ones).
A single run of MTL experiments takes 16 to 96
GPU hours (16 GPU hours for the smallest subsets
of FinDATA, e.g., SC and TSA; 96 GPU hours for
full FinDATA).
D Financial NLP Datasets
The detailed information of Financial NLP datasets
discussed in Section 3.2 is shown in Table 7. We
only cover English datasets, and include the En-
glish subset for those multilingual datasets (e.g.,
FNS and FinTOC). Most of the datasets have less
than10K data points in total, with fewer samples
for training. Some data sizes are even fewer than
2K.
E Dataset Splits
For FinDATA tasks, we use the official test set
and development set if they exist and are publicly
available: for TSA and FSRL, we use official test
sets; for NC and NAD, we use both official test and
development sets. If there is no available official
test or development set, we split the datasets with
a random seed of 42: for SC, we split 10% for
test and 10% for validation. For TSA, we split
20% for validation. For FSRL, we split 10% for
validation. For CD, we split 20% for test and 20%
for validation. All these data splits are available in
our GitHub repository.
F Gradient Analysis
We are curious whether gradient similarities re-
flect task-relatedness. Furthermore, do gradient
conflicts/similarities interpret why some task ag-
gregation works better than others? During MTL,
we record each task’s gradient (averaged over the
whole training set) every 2000 training steps. Then
we calculate the pairwise cosine similarity between
the gradients of all task pairs.
Gradient similarity fails to reflect task-
relatedness : Figure 6 shows the gradient similarity
within sentiment and number tasks (intra-skill gra-
dient similarity), and the average pairwise gradient
similarity in-between the sentiment and number
tasks (inter-skill gradient similarity). It can be ob-
served that intra-skill gradients are not significantly
more similar than inter-skill gradients, indicating
that gradient similarity might not be a good mea-
surement for task-relatedness.
Gradient similarity does not indicate transfer-
ability within task aggregation : Figure 7 shows
the average pairwise gradient similarity of two
MTL systems with different task aggregation: one
is trained on full FinDATA, and the other ab-
lates FSRL. Although ablating FSRL leads to
worse scores on all tasks (see Table 3), the gra-
dient conflict of “w/o FSRL” is not significantly
higher than full FinDATA. Therefore, gradient con-
flicts/similarities are not a good indicator of task
aggregation quality.7478
G MTL Pre-training & Unseen task
Generalization
MTL pre-training may increase the model’s gener-
alizability to unseen tasks (Aghajanyan et al., 2021;
Karimi Mahabadi et al., 2021; Ponti et al., 2023),
which might be extremely helpful when there is
a shortage in target training data (a few-shot set-
ting). Therefore, we test the few-shot generaliz-
ability of our MTL systems on two unseen tasks:
StockSen and Numeracy-600K. StockSen is a bi-
nary (positive or negative) sentiment classification
dataset on financial tweets. Numeracy-600K classi-
fies numbers into one of seven magnitudes. It has
two subtasks on different domains (financial news
and market comment). We first train the models
on FinDATA for 2000 steps. Then we resume the
shared encoder and fine-tune it on the target unseen
task for 10epochs, reporting the best checkpoint’s
score. We use a few-shot setting (randomly sam-
ple400training and 400validation data points) for
unseen tasks to stimulate the lack of training data
in the target task. For test sets, we split (with a
random seed of 42)60K samples ( 10% of data) for
Numeracy-600K and 6.2K samples (official devel-
opment set) for StockSen. The results are shown
in Table 8. In all tasks, the MTL-pre-trained sys-
tem beats vanilla FinBERT when generalizing to
unseen tasks.
H Importance of Freezing Pretrained
Model
To illustrate the importance of freezing the pre-
trained model, we first compare SPAL-FinBERT
(SPAL hidden size = 204) with an ablation setting
where FinBERT is not frozen. The comparison
is shown in Table 9, where unfreezing FinBERT
compromises the MTL performance drastically on
most tasks (CD prefers larger shared capacity and
thus benefits from unfreezing).
Then we add weighting parameters to probe the
frozen FinBERT’s contribution to the layer outputs.
Figure 8 shows the probing architecture. We add
probing parameters aandb, which weigh the frozen
FinBERT output and the SPAL output. After MTL,
the contribution of each structure can be measured
by the final (softmaxed) weights. The results are
shown in Figure 9. In all layers except the last
layer, the frozen FinBERT layers contribute more
to the output than PALs, illustrating the importance
of the frozen part.
I Task-relatedness Examples
Through MT fine-tuning, the shared encoder un-
derstands an input sentence from comprehensive
aspects that positively transfer to each other. To
probe the explicit transfer, we analyze the non-
target output headers’ outputs to illustrate that the
inputs are understood comprehensively. For ex-
ample, Figure 10a shows that the FSRL header
correctly identifies the semantic role of “2018” in
an NC input. Such time awareness may benefit NC7479
when classifying the date numbers. Similarly, Fig-
ure 10b shows that the TSA header assigns proper
sentiment score to an SC input. More examples of
explicit transfer are shown below:
Positive transfer from TSA to SC (target header:
SC, non-target header: TSA). All examples are
from SC test set:
•Finnish Aldata Solution has signed a contract
of supply its G.O.L.D. system to two French
retail chains. Golden label: positive; TSA
output: 0.40566313
•Kaupthing Bank will publish its annual results
for 2007 before markets open on Thursday 31
January. Golden label: neutral; TSA output:
-0.00095879
•In food trade , sales amounted to EUR320.1
m , a decline of 1.1% . Golden label: negative;
TSA output: -0.42561457
•The company did not distribute a dividend
in 2005. Golden label: neutral; TSA output:
-0.35266992
•Panostaja did not disclose the purchase
price. Golden label: neutral; TSA output:
0.02710678
•Operating profit rose to EUR 13.5 mn from
EUR 9.7mn in the corresponding period in
2006. Golden label: positive; TSA output:
0.42477337
•As production of other products will continue
normally, temporary lay-offs concern simulta-
neously at most 80 employees. Golden label:
negative; TSA output: -0.49556375•According to Viking Line’s Managing Direc-
tor, Nils-Erik Eklund, the company’s Board of
Directors is very satisfied with Viking Line’s
performance. Golden label: positive; TSA
output: 0.28375068
•The port operator, however, favors retaining
the port fees in 2010, citing the owner, the gov-
ernment of Estonia, committing the port to pay
EEK 400mn (EUR 25.56 mn USD 36.44 mn)
in dividends to the state in 2009 and another
EEK 300mn in 2010. Golden label: neutral;
TSA output: 0.05767085
•Uponor maintains its full-year guidance for
2010. Golden label: neutral; TSA output:
0.08272883
Positive transfer from FSRL to NC (date classifica-
tion). Semantic role labeling outputs are in a form
of [(token, label)] entries. Time semantic roles are
bold . All examples are from NC test set:
•Looking ahead the 150000 people at Optum
are incredibly enthusiastic about <2019> and
our opportunities for longer-term growth and...
FSRL output: [(’looking’, ’O’), (’ahead’, ’O’),
(’the’, ’O’), (’150000’, ’I-WHOLE’), (’peo-
ple’, ’I-WHOLE’), (’at’, ’I-WHOLE’), (’op-
tum’, ’B-SOURCE’), (’are’, ’O’), (’incredi-
bly’, ’O’), (’enthusiastic’, ’O’), (’about’, ’O’),
(’<’, ’B-TIME’), (’2019’, ’B-TIME’) , (’>’,
’I-QUANT’), (’and’, ’O’), (’our’, ’O’), (’op-
portunities’, ’O’), (’for’, ’O’), (’longer’, ’O’),
(’-’, ’O’), (’term’, ’O’), (’growth’, ’O’), (’and’,
’O’) ...
•Now before I turn it over to Carroll just
a few comments on our improved <2018>
outlook and some early thoughts on 2019
... FSRL output: [(’now’, ’B-TIME’), (’be-
fore’, ’O’), (’i’, ’O’), (’turn’, ’O’), (’it’,
’O’), (’over’, ’O’), (’to’, ’O’), (’carroll’, ’O’),
(’just’, ’O’), (’a’, ’O’), (’few’, ’O’), (’com-
ments’, ’O’), (’on’, ’O’), (’our’, ’I-QUANT’),
(’improved’, ’I-QUANT’), (’<’, ’B-TIME’),
(’2018’, ’B-TIME’) , (’>’, ’I-QUANT’), (’out-
look’, ’I-QUANT’), (’and’, ’O’), (’some’,
’O’), (’early’, ’O’), (’thoughts’, ’I-QUANT’),
(’on’, ’O’), (’2019’, ’I-QUANT’) ...
•Now before I turn it over to Carroll just a
few comments on our improved 2018 out-
look and some early thoughts on <2019.> ...7480
FSRL output: [(’now’, ’O’), (’before’, ’O’),
(’i’, ’O’), (’turn’, ’O’), (’it’, ’O’), (’over’,
’O’), (’to’, ’O’), (’carroll’, ’O’), (’just’, ’O’),
(’a’, ’O’), (’few’, ’O’), (’comments’, ’O’),
(’on’, ’O’), (’our’, ’I-QUANT’), (’improved’,
’I-QUANT’), (’2018’, ’I-QUANT’), (’out-
look’, ’I-QUANT’), (’and’, ’O’), (’some’,
’O’), (’early’, ’O’), (’thoughts’, ’I-QUANT’),
(’on’, ’I-QUANT’), (’<’, ’I-TIME’), (’2019’,
’I-TIME’), (’.’, ’I-TIME’), (’>’, ’I-TIME’) ...
J FinDATA Examples
In this section we provide 10examples for each
FinDATA task:
TSA : (Cortis et al., 2017) the target companies are
enclosed by “| |”:
•NYSE owner |ICE| considers offer for LSE.
Label: 0.096
•NYSE owner ICE considers offer for |LSE|.
Label: 0.396
•|Diageo| sales disappoint as currency and com-
paratives leave bitter taste. Label: -0.545
•AB InBev attacks |SABMiller| bid rebuffal.
Label: -0.158
•Are ARM Holdings plc, |Domino’s Pizza
Group plc| and ASOS plc 3 must-have growth
stocks?. Label: 0.063
• Drugmaker |Shire| to buy Baxalta for $32 bil-
lion after 6-month pursuit. Label: 0.437• Drugmaker Shire to buy |Baxalta| for $32 bil-
lion after 6-month pursuit. Label: 0.75
•Centrica extends gas deals with Gazprom,
|Statoil|. Label: 0.239
•|Aggreko| 2015 Profit Declines - Quick Facts.
Label: -0.441
•|HSBC| shakes up board with two new busi-
ness chiefs, three departures. Label: -0.074
SC(Malo et al., 2013):
•The business to be divested generates consol-
idated net sales of EUR 60 million annually
and currently has some 640 employees. Label:
neutral
•Svyturys-Utenos Alus, which is controlled by
the Nordic group Baltic Beverages Holding
(BBH), posted a 6.1 percent growth in beer
sales for January-September to 101.99 million
liters. Label: positive
•The Department Store Division’s sales fell by
8.6% to EUR 140.2 mn. Label: negative
•Production capacity will rise gradually from
170,000 tonnes to 215,000 tonnes. Label: pos-
itive
•Rautalinko was resposnible also for Mobility
Services, and his job in this division will be
continued by Marek Hintze. Label: neutral7481•Circulation revenue has increased by 5% in
Finland and 4% in Sweden in 2008. Label:
positive
•The changes will take effect on 1 January
2010, and they are not estimated to have an
impact on the number of employees. Label:
neutral
•F-Secure Internet Security 2010 is a security
service for surfing the web, online banking
and shopping, e-mail, and other online activi-
ties. Label: neutral
•Earnings per share (EPS) were EUR0.03, up
from the loss of EUR0.083. Label: positive
•Production capacity will increase from 36000
to 85000 tonnes per year and the raw material
will continue to be recycled paper and board.
Label: positive
NC: (Chen et al., 2020) the targeted numbers are
enclosed by “< >”:
•Finally we experienced roughly $<104> mil-
lion of hurricane-related expenses in the quar-
ter for items like people-cost increased secu-
rity in our affected stores and storm damage.
So while our year-over-year sales growth was
positively impacted by the hurricanes our op-
erating profit was negatively impacted by $51
million. Label: money
•In Asia we expect to acquire 51% of our
Philippines bottler from Coca-Cola FEMSA
during the fourth quarter. This will become a
part of our Bottling Investments Group which
is now comprised primarily of Southwest and
Southeast Asian bottlers. These <2>trans-
actions should roughly offset each other re-
sulting in a minimal structural impact in our
P&L in 2019. Label: money Label: quan-
tity_absolute
•From a capital allocation perspective year-to-
date we have generated $6.3 billion of free
cash flow returned $<8.6>billion to sharehold-
ers including $2.8 billion in dividends and
$5.8 billion in buybacks repurchasing 117 mil-
lion shares. Label: money
•Next on Aviation which had another great
quarter. Orders of $8.8 billion were up 12%.
Equipment orders grew 20% driven by thecontinued strong momentum of the LEAP en-
gine program up 56% versus the prior year.
Military engine orders were up 69% driven by
the F414 and service orders grew 7%. Rev-
enues of $8.5 billion grew <21>%. Equipment
revenues were up 13% on higher commercial
engines partially offset by lower military vol-
ume. Label: relative
•We’ll release 2 new movies from Pixar in fis-
cal <2018>. We’re thrilled with the early re-
action to Coco which opens at Thanksgiving
and we’re also looking forward to the summer
release of The Incredibles 2. Label: date
•I would like to remind you that some of
the statements that we make during today’s
call may be considered forward-looking state-
ments within the meaning of the safe harbor
provision of the U.S. Private Securities Litiga-
tion Reform Act of <1995>. Label: other
•We ended 2017 with franchised restaurants
representing <92>% of our total restaurant
base up from 81% 3 years ago. As a result
franchise margins now comprise more than
80% of our total restaurant margin dollars.
For the fourth quarter franchise margin dollars
increased across all segments reflecting sales-
driven performance and the shift to a more
heavily franchised system. Label: absolute
•Today we announced that we will increase
our quarterly dividend by 15% or by $0.07 to
$0.55 per share beginning in the first quarter
of 2019. In addition, the board has approved
an additional $<10> billion share repurchase
authorization giving us approximately $18
billion in share repurchase capacity. Label:
money
•Looking back on 2017 I could not be more
proud of our team and all they have ac-
complished. As I look to our <50>th year
I’m more optimistic and confident than I’ve
ever been about Intel’s future. Label: quan-
tity_absolute
•Non-GAAP gross margin was <76>% in
the quarter an increase of roughly 70 basis
points versus the third quarter of 2016. Fa-
vorable product mix driven by KEYTRUDA
and ZEPATIER was the largest contributor7482to the year-over-year improvement. Non-
GAAP operating expenses of $4.2 billion in-
creased 4% year-over-year primarily driven
by higher R&D expense reflecting increased
investments in early drug development. Taken
together we earned $1.11 per share on a non-
GAAP basis up 4% excluding exchange. Note
that our GAAP EPS loss of $0.02 reflects the
charge of $2.35 billion related to the formation
of the strategic oncology collaboration with
AstraZeneca announced earlier in the quarter.
Label: absolute
NAD : (Chen et al., 2019a) target numbers and cash
tags are indicated by “< >” and “| |” correspond-
ingly:
•$|XXII| Scott Gottlieb, Commissioner of FDA
speech transcript from November <3>rd, less
than 2 months left in year then. Label: at-
tached
•$|DPW| that was quite a roller coaster. Glad
it ended well. Should see <5>in 7 days Label:
attached
•Took me <5>minutes to conclude: #Snooze-
fest \ud83d \ude34\ud83d \ude34 \ud83d
\ude34 \ud83d \ude34 Advancers 6 to Declin-
ers 5 NYSE + NASDAQ $|SPY| $QQQ $DIA
$IWM Label: unattached
•Take moment <2>note $Crypto Superiority
trades 24/7 365 No dead time 4 Thanksgiv-
ing $BTC.X $LTC.X $|ETH.X| $DASH.X
$XRP.X $BCH.X $TSLA $MNKD Label:
unattached
•2nd TP for $|JDST| is 94.05 according to my
algo. Take it to the bank. Gold headed <4>
major intermediate bottom b4 spike in Jan
2018. $JNUG Label: unattached
•2nd TP for $|JDST| is 94.05 according to my
algo. Take it to the bank. Gold headed 4 major
intermediate bottom b4 spike in Jan |2018|.
$JNUG Label: unattached
•$|BABA| hit +$<3>pre-market - Futures up
100 - $BSTI Big Buying @ close after Re-
bound Holds 2nd day Heading Back to $13
Label: attached•$|BABA| hit +$3 pre-market - Futures up
<100>- $BSTI Big Buying @ close after Re-
bound Holds 2nd day Heading Back to $13
Label: attached
•$|BABA| hit +$3 pre-market - Futures up 100
- $BSTI Big Buying @ close after Rebound
Holds <2>nd day Heading Back to $13 Label:
attached
•$|BABA| hit +$3 pre-market - Futures up 100
- $BSTI Big Buying @ close after Rebound
Holds 2nd day Heading Back to $<13> Label:
attached
FSRL : (Lamm et al., 2018a) we use different col-
ors to denote different semantic roles: purple for
WHOLE, red for THEME, blue for MANNER,
forestgreen for V ALUE, orange for TIME, gold-
enrod for QUANT, pink for AGENT, cyan for
SOURCE, and sepia for CAUSE. For a detailed
definition of each semantic role, please refer to
Lamm et al. (2018b).
•Commodities: Dow Jones futures index
129.72, off 0.15; spot index 130.16, up 0.91.
•Between 50% and 75% of today’s workers are
covered by such plans, up from 5% five years
ago.
•Cary Computer, which currently employs 241
people, said it expexts a work force of 450 by
the end of 1990.
•Colgate-Palmolive advanced 1 5/8 to 63 af-
ter saying it was comfortable with analysts’
projections that third-quarter net income from
continuing operations would be between 95
cents and $1.05 a share, up from 69 cents a
year ago.
•In addition, CMS reported third-quarter net
of $68.2 million, or 83 cents a share, up from
$66.8 million, or 81 cents a share, a year ago.
•Chateau Yquem, the leading Sauternes, now
goes for well over $100 a bottle for a lighter
vintage like 1984; the spectacularly rich 1983
runs $179.
•For the nine months, Arco reported net in-
come of $1.6 billion, or $8.87 a share, up 33%
from $1.2 billion, or $6.56 a share a year ear-
lier.7483•Citing its reduced ownership in the Lyon-
dell Petrochemical Co., Atlantic Richfield re-
ported that net income slid 3.1% in the third
quarter to $379 million, or $2.19 a share, from
$391 million, or $2.17 a share, for the compa-
rable period last year.
•Quarter revenue was $232.6 million, up 12%
from $206 million last year.
•Life insurers fared similarly, with Legal &
General advancing 3 to 344, although Pruden-
tial fell 2 to 184 1/2.
CD: (Mariko et al., 2020) we use blue to denote
causes, and red to denote effects:
•Florida is unique in that it also draws a large
proportion of higher net-worth individuals -
more than 85 percent of its net inflow of in-
come came from people earning at least six-
figures.
•CLICK HERE TO GET THE FOX BUSI-
NESS APP Data from the U.S. Census Bu-
reau showed that while Florida received more
movers than any other state last year, New
York’s outflows to the Sunshine State were the
highest - 63,772 people.
•New York had the third-largest outflows of any
state, with 452,580 people moving out within
the past year. Individuals earning $650,000
can save more than $69,700 in taxes per year
by moving from New York to Florida.
•The stock increased 1.02% or $0.23 during
the last trading session, reaching $22.69.
•(NASDAQ:SBRA) has declined 1.62% since
September 21, 2018 and is downtrending. It
has underperformed by 1.62% the S&P500.
•Weyerhaeuser Company (NYSE:WY) has de-
clined 25.53% since September 21, 2018 and
is downtrending. It has underperformed by
25.53% the S&P500.
•After $0.46 actual EPS reported by Sabra
Health Care REIT, Inc. for the previous quar-
ter, Wall Street now forecasts 2.17% EPS
growth.
•Investors sentiment increased to 1.25 in Q2
2019. Its up 0.38, from 0.87 in 2019Q1. It
increased, as 23 investors sold SBRA shares
while 68 reduced holdings.•It also reduced its holding in Qualcomm
Inc. (NASDAQ:QCOM) by 24,294 shares
in the quarter, leaving it with 158,167 shares,
and cut its stake in Wells Fargo& Co (New)
(NYSE:WFC).
•Investors sentiment decreased to 1.02 in 2019
Q2. Its down 0.11, from 1.13 in 2019Q1. It
worsened, as 43 investors sold WY shares
while 242 reduced holdings.748474857486ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
The Limitation section
/squareA2. Did you discuss any potential risks of your work?
Ethical Considerations
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
Abstract; Introduction
/squareA4. Have you used AI writing assistants when working on this paper?
Left blank.
B/squareDid you use or create scientiﬁc artifacts?
Section 3, 4, 5, and 6
/squareB1. Did you cite the creators of artifacts you used?
Section 3, 5, and 6
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
Ethical Considerations
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
Section 3 and Ethical Considerations
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
Ethical Considerations
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
Section 3 and Appendix C
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
Section 3 and Appendix D, F
C/squareDid you run computational experiments?
Introduction, Section 6, and Appendix E,F ,G
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
Section 6, and Appendix B7487/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
Section 5, 6 and Appendix B
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
Section 3, 6 and Appendix E,F ,G
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
Appendix B
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
Left blank.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
No response.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
No response.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
No response.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
No response.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
No response.7488