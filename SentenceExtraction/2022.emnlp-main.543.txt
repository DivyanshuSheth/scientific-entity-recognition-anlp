
Mengxiao Song, Bowen Yu, Quangang Li,
Yubin Wang ,Tingwen Liu ,Hongbo Xu
Institute of Information Engineering, Chinese Academy of Sciences. Beijing, China
School of Cyber Security, University of Chinese Academy of Sciences. Beijing, China
{songmengxiao,yubowen,liquangang}@iie.ac.cn
{wangyubin,liutingwen,hbxu}@iie.ac.cn
Abstract
Multi-intent detection and slot filling joint
model attracts more and more attention since
it can handle multi-intent utterances, which is
closer to complex real-world scenarios. Most
existing joint models rely entirely on the train-
ing procedure to obtain the implicit correlation
between intents and slots. However, they ig-
nore the fact that leveraging the rich global
knowledge in the corpus can determine the in-
tuitive and explicit correlation between intents
and slots. In this paper, we aim to make full
use of the statistical co-occurrence frequency
between intents and slots as prior knowledge
to enhance joint multiple intent detection and
slot filling. To be specific, an intent-slot co-
occurrence graph is constructed based on the
entire training corpus to globally discover cor-
relation between intents and slots. Based on the
global intent-slot co-occurrence, we propose a
novel graph neural network to model the inter-
action between the two subtasks. Experimen-
tal results on two public multi-intent datasets
demonstrate that our approach outperforms the
state-of-the-art models.
1 Introduction
Spoken language understanding (SLU) aims to en-
able the machine to understand user’s utterance,
which contains two typical subtasks: intent de-
tection and slot filling (Tur and De Mori, 2011).
Intent detection obtains the user’s intent from the
input utterance and slot filling recognizes entities
carrying detailed information of the intent. Gan-
gadharaiah and Narayanaswamy (2019) found that
complex scenarios of real-world may often include
multiple intents in an utterance. Take an example
in Figure 1, the utterance indicates two intents:
"GetWeather" and "BookRestaurant" .
Jeong and Lee (2008) suggested that solving
the two subtasks jointly makes better perfor-
mance because of the correlation between in-Figure 1: An example of joint multiple intent detection
and slot filling for an utterance.
tents and slots (e.g. "BookRestaurant"
andB-restaurant_type ). Therefore, re-
searchers in recent years (Gangadharaiah and
Narayanaswamy, 2019; Qin et al., 2020, 2021b)
pay more attention to joint multiple intent detec-
tion and slot filling.
Gangadharaiah and Narayanaswamy (2019) first
tried to explore the joint model for multiple intent
detection and slot filling based on attention with a
slot-gated mechanism to model dependencies be-
tween intents and slots. Qin et al. (2020) proposed
an adaptive graph-interactive framework (AGIF)
where the core is an adaptive intent-slot interaction
multilayer graph attention network. It makes it pos-
sible for each token to capture different relevant
intent information, thus enabling fine-grained inte-
gration of multiple intents. On the basis of AGIF,
Qin et al. (2021b) proposed a global-locally graph-
interaction network (GL-GIN), which builds a local
slot-aware graph and a global intent-slot graph for
each utterance to model slot dependency and intent-
slot interaction. Nevertheless, these works rely
entirely on model training to obtain implicit intent-
slot correlation for interaction between the two sub-
tasks. And existing works often construct graphs
for each individual utterance, which neglects global
statistical knowledge from the entire corpus. The
simplified example is illustrated in Figure 2(a).
To overcome the above limitations, inspired by
the success of leveraging global knowledge from
training sets to help model optimization in multi-
label classification (Zhang et al., 2018; Chen et al.,
2019; Ma et al., 2021), we decide to explicitly lever-
age the intent-slot correlation summarized from the7967
entire training corpus. By counting co-occurrence
numbers between intents and slots in utterances
and calculating the frequency, we visualize the sta-
tistical results on the MixATIS (which is a public
multi-intent utterance dataset) in Figure 2(c). We
can clearly see that there are significant differences
in co-occurrence frequency between different in-
tents and slots. Based on the observation, we pro-
pose to regard the co-occurrence frequency as prior
knowledge for guiding the model to mine the cor-
relation between intents and slots.
Methodologically, we devise an intent-slot graph
with intent and slot labels as vertices, and the sta-
tistical co-occurrence frequency between intents
and slots across the entire training corpus is for-
mulated as weighted edges. Figure 2(b) shows the
simplified example of our graph. The weight be-
tween each intent and each slot can be regarded
as the correlation degree of them. Then, we ap-
ply the graph convolutional network (GCN) to the
intent-slot graph to propagate information and up-
date vertices embeddings. In this way, integrated
global knowledge from the corpus is capable of
helping the model capture explicit correlation be-
tween intents and slots, thereby facilitating inter-
actions between the two subtasks to boost perfor-
mance. Moreover, we explore several attention and
fusion mechanisms to extract label-related infor-
mation from each utterance and the global training
corpus, for the purpose of incorporating semantic
information of tokens that play an important role
in judging slots and intents, while reducing noisefrom irrelevant tokens.
We conduct experiments on two public multi-
intent utterance datasets. Experimental results
show that our approach significantly outperforms
the previous state-of-the-art model in the overall
accuracy of utterances. And extensive experimen-
tal analyses justify that our approach can make
better use of the global intent-slot co-occurrence
to help the model capture more accurate correla-
tions between intents and slots, so that enhance
joint multiple intent detection and slot filling. The
source code for this paper can be obtained from
https://github.com/smxiao/GISCo .
2 Methodology
Problem Definition Given input utterance U=
[u,u, ...,u], where nis the length of the utter-
ance. Joint multiple intent detection and slot filling
contains two subtasks: (1) multiple intent detection
can be seen as a multi-label classification task that
predicts the multiple intents O= [o, ...,o]of
the input utterance, where mindicates the number
of output intent labels; (2) slot filling can be de-
fined as a sequence labeling task that predicts the
slot label for each token of the input utterance and
output a slot label sequence O= [o, ...,o].
As shown in Figure 3, our approach is composed
of four major components: (1) an utterance en-
coder; (2) intent and slot label embedder; (3) intent-
slot co-occurrence graph network; (4) multi-intent
detection and slot filling decoders. And we use a
joint training scheme to optimize multiple intent7968
detection and slot filling simultaneously. Next, we
will describe each component in detail.
2.1 Utterance Encoder
Following Qin et al. (2020) and Qin et al. (2021b),
we leverage task-shared and task-specific encoders
to obtain the representation of utterance.
Task-shared Utterance Encoder For the input
utterance U, we first utilize a self-attentive en-
coder to obtain the shared utterance representa-
tion of two subtasks. Concretely, we first use a
Bi-LSTM (Hochreiter and Schmidhuber, 1997) to
obtain content representation Cwith timing in-
formation of the input utterance. Then, we em-
ploy a self-attention mechanism (Vaswani et al.,
2017) over the embedding of the input utterance
to capture the context-aware features C. After
that, we concatenate the output of Bi-LSTM and
self-attention as the task-shared utterance represen-
tationE=C⊕C.
Task-specific Utterance Encoder We utilize
two different Bi-LSTMs to capture intent-aware
and slot-aware contexts as task-specific features
for intent detection and slot filling respectively.
More specifically, we feed the task-shared ut-
terance representation E= [e,e, ...,e]into
an intent-aware Bi-LSTM, and apply e=
BiLSTM( e,e,e)repeatedly to obtain the
task-specific representation E= [e,e, ...,e].
The slot-aware Bi-LSTM is modeled similarly and
outputs E.2.2 Intent and Slot Label Embedder
In this subsection, we describe how to represent
intent and slot labels. We devise an intra-utterance
attention mechanism and an intra-corpus attention
mechanism to collect label features from the input
utterance and the training corpus, which are merged
together with an adaptive fusion mechanism.
Intra-utterance Attention Mechanism Our mo-
tivation comes from the observation that each word
in one utterance has a different effect on different
labels (Xiao et al., 2019), so we consider extracting
label-related semantic components from utterance
to represent intent and slot labels. Concretely, we
first compute the label-word attention score (Lin
et al., 2017). Then, we can capture label-related
contextual information from utterance as the repre-
sentation of the label with the attention score. The
process is calculated as follows:
B= Softmax( Wtanh(EW))E,(1)
where W∈RandW∈Rare the
parameters to be trained, δ∈ {I, S}(Idenotes
intent label and Sdenotes slot label), |δ|is the
number of pre-dedfined labels. BandBare the
obtained intent label representation and slot label
representation from utterance, respectively.
Intra-corpus Attention Mechanism While the
intra-utterance attention mechanism dynamically
collects utterance-specific label features from each
input utterance, we argue that it ignores the shared
features among all the utterances in the training
corpus. Thus, we also devise an intra-corpus at-7969tention mechanism as a supplement. Specifically,
we first randomly initialize the intent and slot label
matrices M∈R(δ∈ {I, S}), respectively.
Then we update Maccording to its relevance with
each utterance in the training corpus as follows:
M= (ME)E, (2)
where the relevance is calculated by the simple
dot product operation. So that, after seeing all
the instances in the training corpus, Mis desired
to capture the shared label-specific utterance fea-
tures. After training, Mis fixed during inference,
while Bis dynamically generated for each test
utterance. This is the most significant difference
between them.
Adaptive Fusion Mechanism We utilize an
adaptive attention fusion strategy to fully and ap-
propriately fuse BandM. The fusion strategy
adaptively extracts a reasonable proportion of in-
formation from the two parts to generate the fused
label representation. To be specific, we apply fully
connected layer to get the proportion of each type
of representation in the fusion operation:
α=σ(BW)
σ(BW) +σ(MW), (3)
where W,W∈Rare the parameters to be
trained, and σdenotes the Sigmoid function. Once
having the fusion weights, we can get the fused
label representation as follows:
H=αB+ (1−α)M. (4)
Therefore, the intent labels and slot labels can be
embedded into representations HandH.
2.3 Intent-Slot Co-occurrence Graph
Graph Construction We construct the intent-
slot co-occurrence graph G= (V,E)where ver-
tices refer to intent and slot labels, and edges refer
to the statistical co-occurrence frequency between
intents and slots counted from the training corpus.
Vertex There are two kinds of vertices in the
graph: one is the intent label vertex; the other is
slot label vertex. The number of vertices is |I|+|S|.
The initial embeddings of vertices in the graph are
produced by H= [H,H].
Edge We define the adjacent matrix of the
graph based on the co-occurrence frequency be-
tween intents and slots on the training set:
A=/braceleftigg, if i and j co-exist,
0 , otherwise ,(5)where iandjare different types of vertices, i.e. if i
is an intent vertex then jis a slot vertex, Count (·)
denotes the cumulative number of occurrence, and
particularly A= 1 for self-loop. The shape of
Ais(|I|+|S|)×(|I|+|S|). Then the adjacent
matrix Ais normalized by the method in Kipf and
Welling (2016) as follows:
ˆA=DAD, (6)
in which Dis a diagonal degree matrix with entries
D=/summationtextA.
Graph Network The graph convolutional net-
work (GCN) (Kipf and Welling, 2016) is a convo-
lutional neural network working on a graph, which
updates vertex embedding by propagating infor-
mation between neighboring vertices via adjacent
edges. K-layers GCN can aggregate information
from K-hops neighbors. Noted that, one layer of
GCN is enough for our graph because we only con-
sider the information interaction between intent
label and slot label, and they are one-hop neigh-
bors to each other, otherwise irrelevant information
may be aggregated. Hence, the interaction between
intent and slot labels can be formulated as:
H=ˆAHW, (7)
where Wis a transformation matrix to be learned.
Then the His split into HandHwhich are
the updated intent and slot label representations,
respectively.
2.4 Intent and Slot Decoders
Multiple Intent Detection Decoder First, we
simply calculate the dot product of intent label rep-
resentation and utterance representation to obtain
their similarity for intent detection. Then, a multi-
layer perception is applied to get the predicted prob-
ability of each intent label. The process is defined
as follows:
I=σ(f((HE)W)W), (8)
where σand fdenotes the Sigmoid and
LeakyReLU activation function respectively.
The above formula is designed for token-level
intent detection. To get final sentence-level intent
labels, we apply the same voting mechanism as Qin
et al. (2021b) to output intents Ocontained in the
input utterance:
O= [o|(/summationdisplay1[I>0.5])>n
2], (9)7970where Idenotes the prediction probability of
token tfor the intent o.
Slot Filling Decoder Inspired by Qin et al.
(2021a), in order to make better use of intent infor-
mation to guide slot filling, we further fuse intent
and slot information implicitly via a feed-forward
network for slot label prediction. We firstly lever-
age the attention mechanism to obtain the corre-
sponding intent and slot information from utter-
ance:
E= (EH)H+E. (10)
Next, the intent and slot information are combined
by concatenation E=E⊕E. And we lever-
age word neighbour features for each token as
Zhang and Wang (2016):
ˆe=e⊕e⊕e. (11)
Then, we integrate the intent information and con-
text features ˆE= [ˆe, ...,ˆe]into the slot in-
formation by a feed-forward layer, and we add it to
Eto obtain the enhanced slot information:
S= ReLU( ˆEW)W+E, (12)
After that, we apply a multi-layer perception to
predict the corresponding slot label for each token:
S= Softmax( f(SW)W), (13)
where fis the LeakyReLU activation function. Fi-
nally, the output O=argmax (S)is the result of
slot filling.
2.5 Joint Training
We apply the joint training to learn parameters. The
loss function of multi-intent detection is defined as:
CE(ˆy, y) = ˆylog(y) + (1−ˆy) log(1 −y),(14)
L≜−/summationdisplay/summationdisplayCE( ˆo, o), (15)
where ˆois the gold intent label. Similarly, the
loss function of slot filling is formulated as:
L≜−/summationdisplay/summationdisplayˆo, o, (16)
where ˆois gold slot label. So that, the final
joint training objective is as follows:
L=λL+ (1−λ)L, (17)
in which λis hyper-parameter.3 Experiments
3.1 Datasets
We conduct experiments on two public multi-intent
utterance datasets: MixATIS (Hemphill et al.,
1990; Qin et al., 2021b) and MixSNIPS (Coucke
et al., 2018; Qin et al., 2021b). There are 13,162,
756, 828 utterances for training, validation and test-
ing on the MixATIS dataset, respectively. MixS-
NIPS includes 39,776, 2,198, 2,199 utterances for
training, validation and testing, respectively.
3.2 Experimental Settings
In our experiments, the word embedding is ran-
domly initialized with 128-dimensional word vec-
tors. The dimension of the BiLSTM hidden units
is 256. The dimension of the label representation
is 384. For the hyper-parameter λin the loss func-
tion of joint training, it is set 0.8 and 0.7 for the
MixATIS and MixSNIPS respectively. We set the
train batch size to 16. The whole model is trained
via AdamW (Loshchilov and Hutter, 2017) with
the learning rate being 1e-3, and the weight decay
is set 1e-6 and 5e-4 for the MixATIS and MixS-
NIPS respectively. All experiments are conducted
in Tesla T4.
3.3 Baselines
We compare our model with the following base-
lines: (1) Attention BiRNN (Liu and Lane, 2016):
It introduces attention mechanism into the bidi-
rectional RNN network for joint intent detection
and slot filling. (2) Slot-Gated Attention (Goo
et al., 2018): It proposes a slot-gated mechanism to
learn dependencies between intents and slots. (3)
Bi-Model (Wang et al., 2018): It considers intent
detection and slot filling interacting bidirectionally.
(4)SF-ID Network (Niu et al., 2019): It utilizes
an iterative mechanism to enhance the correlation
between intents and slots. (5) Stack-Propagation
(Qin et al., 2019): It proposes a joint model with
stack-propagation which performs the token-level
intent detection to guide slot filling. (6) Joint Mul-
tiple ID-SF (Gangadharaiah and Narayanaswamy,
2019): It applies the slot-gated mechanism to joint
multiple intent detection and slot filling. (7) AGIF
(Qin et al., 2020): It utilizes an adaptive graph
interactive framework which can capture the multi-
intent information for slot filling. (8) GL-GIN
(Qin et al., 2021b): It proposes a global-local graph
interaction network which is the recent state-of-the-
art for the joint task.7971ModelOverall(acc)
MixATIS MixSNIPS
Attention BiRNN 39.1 59.5
Slot-Gated 35.5 55.4
Bi-Model 34.4 63.4
SF-ID Network 34.9 59.9
Stack-Propagation 40.1 72.9
Joint Multiple ID-SF 36.1 62.9
AGIF 40.8 74.2
GL-GIN 43.5 75.4
Ours 48.2 75.9
3.4 Main Results
Following Goo et al. (2018) and Qin et al. (2021b),
we evaluate the performance using the sentence-
level overall accuracy (Overall Acc): the prediction
of an utterance is correct only when its intents and
slots are all correctly predicted.
Table 1 shows experiment results of different
models on the two multi-intent datasets. We can
see that our approach achieves 4.7% and 0.5% im-
provements in overall accuracy compared with the
best baseline GL-GIN on the MixATIS and MixS-
NIPS datasets, respectively. One interesting finding
is that, our approach achieves comparable results
compared with the best baseline on the slot F1
score and intent accuracy which are metrics used to
evaluate the two subtasks. Slot F1 score and intent
accuracy results are in Appendix A.
We attribute the above gains to our model use
of the global statistic result over the entire cor-
pus to provide more information than independent
utterance. In this way, taking the intent-slot co-
occurrence frequency as prior knowledge can help
the neural network capture the more explicit and
high-confidence correspondence between intents
and slots. In the case that intents (slots) predic-
tion is correct, our approach can better guide the
prediction of slots (intents), so that our model can
accurately predict all intents and slots of an utter-
ance, thus improving the overall accuracy.
In particular, it is obvious that the improvement
on the MixATIS is significant. We intuitively sus-
pect that this is due to the characteristic of the
MixATIS dataset: it is collected from an airline
travel information system, which has very simi-lar intent labels and slot labels (e.g. "Flight"
vs."Aircraft" ;"B-airline_code" vs.
"B-aircraft_code" ). Therefore, the global
intent-slot co-occurrence knowledge is more bene-
ficial to distinguishing similar intents and slots. In
contrast, the performance improves slightly on the
MixSNIPS. We guess that, for this dataset with few
label types and obvious label semantic differences
(e.g."GetWeather" vs."PlayMusic" ), the
previous works are also capable of making the
model capture partial correlations between intents
and slots. Whereas, through leveraging well-
informed global statistical knowledge, our method
can further help the model to distinguish the corre-
lations between those few labels whose semantic
are similar.
3.5 Analysis
3.5.1 Ablation Test
To study the effectiveness of each component in
our model, we perform ablation experiments on
MixATIS and MixSNIPS datasets.
Effectiveness of the Intent-Slot Co-occurrence
Graph Module We remove the global intent-slot
co-occurrence in the graph module. That is, all in-
tent vertices and slot vertices are connected to each
other with unweighted edges, which is named as
w/o Intent-Slot Co-occurrence in Table 2. We can
observe that overall accuracy drops significantly
by 9.2% and 3.4% on MixATIS and MixSNIPS
datasets, respectively. This demonstrates that the
intent-slot co-occurrence is a very necessary com-
ponent which captures the correspondence between
intent and slot and enhance the joint of two sub-
tasks effectively.
Effectiveness of Attention and Fusion Mecha-
nisms for Label Representation In order to jus-
tify the effectiveness of using intra-utterance at-
tention and intra-corpus attention mechanisms to-
gether, we use only one of them for intent and
slot label representation, which are referred to w/o
Intra-corpus Attention andw/o Intra-utterance Self-
Attention in Table 2. We can observe that only us-
ing intra-utterance attention for the representation
of labels, results in overall accuracy decreases of
7.0% and 8.6% on the two datasets respectively.
And only using intra-corpus attention leads to 5.1%
and 4.4% overall accuracy drops. Because of intra-
utterance leveraging independent utterance context
to represent the label, but it overlooks common fea-
tures of all utterances or tokens with the same intent7972
or slot label in the training corpus. While intra-
corpus attention makes up for the defect but ig-
nores the specific context of each utterance. Hence,
coupling with them is rational and necessary.
Moreover, we verify the effectiveness of the
adaptive fusion mechanism through replacing it
with simply adding the two attention mechanisms
outputs together, which is named as w/o Adap-
tive Fusion Mechanism in Table 2. We can see
that removing the component hurts the results by
0.9% and 0.7% overall accuracy on the two datasets.
It justifies adaptive fusion mechanism can indeed
help fusing intent (slot) label represent by extract-
ing proper amount of information from indepen-
dent utterance context and shared label-related fea-
tures among all utterances in the entire training
corpus.
3.5.2 Speedup
We compare the inference speed of our approach
with GL-GIN which is the recent fastest baseline.
Specifically, we run the model on the MixATIS test
set in an epoch, and the batch size is set to 16. The
inference latency of our model and the GL-GIN
is 1.7 seconds and 4.6 seconds respectively. So
our approach implements the ×2.7 speedup com-
pared with GL-GIN, which demonstrates that our
approach is efficient. The possible reason for this
fact that GL-GIN requires the predict results of in-
tent detection to construct the graph on each utter-
ance for slot filling, whereas our approach decodes
the two subtasks in parallel.
3.5.3 Low-Resource Setting
We test our approach and the best baseline GL-
GIN by varying the ratio of training set from {10,
30, 50, 70, 100} on the MixATIS dataset to com-
pare the overall accuracy of them in low-resource
scenarios. The comparison results are shown in
Figure 4. We can clearly observe that our approach
outperforms the baseline on all five proportions of
the MixATIS training set. This demonstrates that
the global intent-slot co-occurrence from the entire
training corpus is beneficial to boosting the model
performance. In addition, it is worth noting that,
when the ratio of training set exceeds 70%, the
strength of our approach in the overall accuracy
is significant. We attribute this to the fact that the
richer corpus is more helpful to statistic to deter-
mine more accurate correlation between intents and
slots, so that the more effective global intent-slot
co-occurrence graph structure can be constructed.
3.5.4 Case Study
To further understand how the intent-slot co-
occurrence graph works, we provide two cases
from the MixATIS and MixSNIPS datasets
and show the output results of our approach
and of the best baseline GL-GIN. From Fig-
ure 5(a), we can see that our model predicts
the slot label "B-aircraft_code" of to-
ken "j31" correctly, while GL-GIN predicts
it as “O” incorrectly. Based on the statisti-
cal result of intent-slot co-occurrence frequency
on the entire training corpus as prior knowl-
edge, it can be learned that there is strong
correlation between the intent "Quantity"
and the slot "B-aircraft_code" . It helps
our model predict the token "j31" as a slot
"B-aircraft_code" that carries detailed in-
formation of the utterance rather than the la-
bel"O". A similar phenomenon can be
found in the case from the MixSNIPS dataset
as shown in Figure 5(b). The slot label
"B-artist" and"B-entity_name" are
sometimes indistinguishable, which can con-
fuses the model and leads to false predic-
tions. However, the statistical co-occurrence fre-7973
quency of the intent "AddToPlaylist" and
the slot "B-entity_name" is greater than
that of "AddToPlaylist" and"B-artist" ,
which can guide our model correctly predict
the slot label of token "born" and "free" as
"B-entity_name" and"I-entity_name"
respectively.
4 Related Work
The study of joint model for intent detection and
slot filling has been central to spoken language
understanding in recent years. Because of strong
dependency between intent categories and slot la-
bels, jointly solving the two tasks is not only more
effective through guiding each other, but also usu-
ally requires only one model to be trained and fine-
tuned, which reduces the impact of cascading er-
ror compared with pipeline models to some extent.
Jeong and Lee (2008) proposed the first joint model
named triangular chain conditional random fields
for slot filling and intent detection, and the model
outperforms the most advanced pipeline methods
at that time. Guo et al. (2014) applied neural net-
work on utterance parsing tree to solve the joint
task. Liu and Lane (2016) explored the strategy
of integrating explicit alignment information for
slot filling, and further applies attention mecha-
nism to a recurrent neural network (RNN). Goo
et al. (2018) introduced the slot-gated mechanism
which was the first attempt to explicitly guide slot
filling with intent information. Wang et al. (2018)
adopt a bidirectional interaction attention module,
which means that the interaction is not only from
intent to slot, but also from slot to intent oppo-
sitely. Zhang et al. (2020) first attempted to use
graph neural network to solve the problem of non-
parallelization of RNN and inability to capture the
remote dependency. Qin et al. (2021a) consideredthe cross-impact between intent detection and slot
filling and proposes a co-interactive transformer for
the joint task.
However, the above joint models can mainly
deal with single intent utterance, and cannot han-
dle complex cases with multiple intents. Based on
the observation that 52% of utterances in an Ama-
zon internal dataset contain more than one intent,
Gangadharaiah and Narayanaswamy (2019) first
focused on multiple intent scenario. It utilizes atten-
tion with slot-gated mechanism to construct a joint
framework for multiple intent detection and slot
filling. But their model predicts the slot for each
token guided with same intent information. For
more fine-grained integration of intent information,
Qin et al. (2020) applied multi-layer graph atten-
tion network for adaptive interaction from intent
to slot. Further, aiming at the issue of slow infer-
ence speed of existing autoregressive models, Qin
et al. (2021b) proposed the first non-autoregressive
model for multiple intent detection and slot filling,
which is a global-local graph framework to model
slot dependency locally and propagate information
from multiple intents to slots globally.
In our work, as far as we know, we are the first
to consider leveraging the global intent-slot co-
occurrence across the entire training corpus to en-
hance the joint of the two subtasks. Because taking
full advantage of the well-informed co-occurrence
information between intents and slots from the en-
tire corpus can help model determine more intuitive
and accurate correlation between them than con-
structing a graph for each independent utterance in
previous studies.
5 Conclusions
In this paper, we present a new perspective of in-
tegrating global intent-slot co-occurrence across7974the entire corpus to enhance joint multiple intent
detection and slot filling. Specifically, we construct
a global intent-slot co-occurrence graph to discover
correlation between intents and slots. Then, we
combine it with a GCN-based model to guide the
information propagation and achieve interaction for
the joint task. Besides, we explore several attention
mechanisms for dynamically extracting related in-
formation from independent utterance context and
capturing shared label-specific features among all
utterances in the training corpus, then fuse them
adaptively to represent intent and slot label. Experi-
mental analyses on two public multi-intent datasets
justify that our approach is effective and efficient.
Limitations
The performance of our approach will be limited in
the case of insufficient corpus resources. Because
our approach requires rich corpus to statistic the
intent-slot co-occurrence to discover accurate cor-
relation between intents and slots, and only in this
way can an effective graph structure be determined.
Besides, if there is too much noise in the training
corpus, accurate graph structure cannot be built.
Acknowledgements
We would like to thank the anonymous review-
ers for their insightful comments and sugges-
tions. This work is supported by the National
Key Research and Development Program of China
(Grant No.2021YFB3100600), the Strategic Pri-
ority Research Program of Chinese Academy of
Sciences (Grant No.XDC02040400), the Youth In-
novation Promotion Association of CAS (Grant
No.2021153).
References79757976
A Additional Results
The experimental results in Table 3 show the perfor-
mance of our approach compared with baselines on
additional metrics for evaluating the two subtasks:
F1 score of slot filling (Slot F1) and accuracy of in-
tent detection (Intent Acc). We can see that our ap-
proach achieves comparable results compared with
the best baseline on the slot F1 score and intent ac-
curacy. It is worth noting that our approach makes
significant improvements on the overall accuracy.
Because the global intent-slot co-occurrence across
the entire training corpus help the model enhance
the joint of the two subtasks. That is to say, in the
case that intents (slots) prediction is correct, our
approach can better guide the prediction of slots
(intents), so that our model can accurately predict
all intents and slots of an utterance, hence improv-
ing the overall accuracy. Besides, Table 4 shows
additional ablation study results of our approach
on the slot F1 score and intent accuracy.7977