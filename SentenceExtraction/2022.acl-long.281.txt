
Costanza Conforti, Jakob Berndt, Mohammad Taher Pilehvar,
Chryssi Giannitsarou, Flavio Toxvaerd, Nigel CollierLanguage Technology Lab, University of CambridgeFaculty of Economics, University of CambridgeTehran Institute for Advanced Studies, Khatam University, Iran
{cc918,jb2088}@cam.ac.uk
Abstract
Research in stance detection has so far focused
on models which leverage purely textual in-
put. In this paper, we investigate the integra-
tion of textual and ﬁnancial signals for stance
detection in the ﬁnancial domain. Speciﬁcally,
we propose a robust multi-task neural archi-
tecture that combines textual input with high-
frequency intra-day time series from stock
market prices. Moreover, we extend–,
an existing stance detection dataset which col-
lects tweets discussing Mergers and Acquisi-
tions operations, with the relevant ﬁnancial sig-
nal. Importantly, the obtained dataset aligns
with S , an existing news stance detec-
tion dataset, thus resulting in a unique multi-
modal, multi-genre stance detection resource.
We show experimentally and through detailed
result analysis that our stance detection sys-
tem beneﬁts from ﬁnancial information, and
achieves state-of-the-art results on the–
dataset: this demonstrates that the combina-
tion of multiple input signals is effective for
cross-target stance detection, and opens inter-
esting research directions for future work.
1 Introduction
Stance detection (SD) is the task of automatically
classifying the writer’s opinion expressed in a text
towards a particular target (Küçük and Can, 2020).
Starting from Mohammad et al. (2016)’s seminal
work, research on Twitter SD gained increasing
popularity (Ghosh et al., 2019), embracing new
topics (Derczynski et al., 2017; Aker et al., 2017a;
Conforti et al., 2020b) and languages (Gorrell et al.,
2019; Vamvas and Sennrich, 2020a; Zotova et al.,
2020). In recent years, research on SD has mainly
focused on cross-target generalization, in which an
SD system is tested on targets unseen during train-
ing (Xu et al., 2018). Cross-target generalization
constitutes one of the biggest challenges in Twitter
SD (AlDayel and Magdy, 2021): in this context,
researchers investigated a wide range of techniques,including adversarial training (Wang et al., 2020;
Allaway et al.), cross-lingual transfer (Mohtarami
et al., 2019), knowledge transfer using semantic
and emotion lexicons (Zhang et al., 2020), weak
supervision through synthetic samples (Conforti
et al., 2021b; Li and Caragea, 2021), and various
types of cross-domain transfer (Schiller et al., 2021;
Hardalov et al., 2021a).
In this paper, we study multimodality as a means
to enhance cross-target generalization in Twitter
SD. Multimodal Machine Learning studies the inte-
gration and modeling of multiple modalities (Elliott
et al., 2016), where a modality refers to the way in
which something happens (Baltrusaitis et al., 2019).
Our contributions are as follows:
1.We study multimodal learning for Twitter SD.
Despite being an established research area in
NLP (Elliott et al., 2016), SD in a multimodal
context is still understudied.
2.We extend–, an SD dataset which col-
lects English tweets discussing four Mergers
and Acquisitions operations (M&As or merg-
ers, Conforti et al. (2020b)), with high fre-
quency intra-day stock market data for the
involved companies, which we release for fu-
ture research. We note that the union of
our ﬁnancial signal with–and with
S , an SD corpus collecting news ar-
ticles discussing the same mergers (Conforti
et al., 2020a), will constitute the ﬁrst multi-
genre, multi-modal parallel resource for SD
and, more generally, one of the very few of
this kind in NLP.
3.We propose SDTF ( Stance Detection with
Texual and Financial signals), a novel multi-
task, multimodal architecture for Twitter SD,
which integrates textual and ﬁnancial signals.40744.Finally, we show experimentally that SDTF
beneﬁts from the information encoded in the
ﬁnancial signal, achieving state-of-the-art re-
sults on the–dataset; the integration
of multiple input signals thus constitutes a
promising research direction to tackle cross-
target generalization for SD.
2 Problem Formulation
We study SD in the ﬁnancial domain and consider
tweets discussing M&A operations, i.e. ﬁnancial
transactions in which the ownership of a company
(thetarget ) is transferred to another company (the
buyer , Bruner and Perella (2004)). An M&A pro-
cess usually comprises many stages, ranging from
informal talks between the companies’ boards to
acquisition planning, negotiations, and external ap-
provals, up to the closing of the deal (or its rejec-
tion, e.g. by antitrust bodies). M&As account for
billions of dollars of investment globally and have
been widely studied under many aspects (Gomes
and Maldonado, 2020). They are well known in
NLP (Lefever and Hoste, 2016; Yang et al., 2020;
Conforti et al., 2020a,b) and constitute an important
application in other AI ﬁelds, with a strong focus on
automatic prediction of the M&A outcome (Yan
et al., 2016; Jetley and Ji, 2010; Moriarty et al.,
2019; Venuti, 2021).
In our task, a model receives a tweet and a target
merger, and has to predict the stance expressed by
the tweet’s author with respect to the likelihood of
the merger to succeed:
• Target .Company A will merge with company B
• Tweet .Federal judge rejects A’s bid to buy B!!!
• Stance .Refute
All existing models for ﬁnancial SD only leverage
the tweet’s text as input (Conforti et al., 2020b;
Liang et al., 2021; Li and Caragea, 2021). How-
ever, a user tweeting at a particular time is im-
mersed into a context which shapes their view of
the world: their opinion about an M&A’s outcome
will be inﬂuenced by how the involved companies
are perceived.
In this paper, we use a variation of the stock
market prices from the ndays prior to a tweet’s
posting as a means to provide a model with such
context. According to the Efﬁcient Market Hypoth-
esis (Fama, 1970), stock market prices reﬂect all
publicly known information. Even though the Efﬁ-
cient Market Hypothesis is controversial (Malkiel,
2003), stock market prices still reﬂect a consider-able amount of publicly known information. There-
fore, we argue that they can be used as a proxy
for the available knowledge about the merger at a
given time.
The relationship between rumors about an M&A
operation and their effect on the involved compa-
nies’ stocks is mutual and has been widely stud-
ied in ﬁnance (Ma and Zhang, 2016; Betton et al.,
2018; Jia et al., 2020; Gorman et al., 2021; Davis
et al., 2021), but never investigated in NLP. To our
knowledge, the integration of textual and ﬁnancial
data signals has been studied for ﬁnancial forecast-
ing (Schumaker and Chen, 2009; Hu et al., 2018;
Sawhney et al., 2020a,b, 2021c; Ni et al., 2021),
but has yet to be investigated for SD.
3 Background
3.1 Twitter SD
Traditionally, research on SD has focused on user-
generated data, such as blogs and commenting sec-
tions on websites (Skeppstedt et al., 2017; Hercig
et al., 2017), apps (Vamvas and Sennrich, 2020b),
online debate forums (Somasundaran and Wiebe,
2009), Facebook posts (Klenner et al., 2017) and,
above all, Twitter. Since Mohammad et al. (2016)’s
seminal work, Twitter has been used as a data
source for collecting corpora covering a wide range
of domains, from US politics (Mohammad et al.,
2017; Inkpen et al., 2017) to mental health (Aker
et al., 2017b), breaking news events (Zubiaga et al.,
2016; Gorrell et al., 2019), ﬁnance (Conforti et al.,
2020b), and the COVID pandemic (Hossain et al.,
2020; Glandt et al., 2021).
SD has been studied both as a stand-alone, iso-
lated task, and integrated as a sub-component of
more complex NLP pipelines (Hardalov et al.,
2021b). Starting from the pioneering work by Vla-
chos and Riedel (2014), SD has been identiﬁed as
a key step in fake news detection (Lillie and Mid-
delboe, 2019) and automated fact-checking (Popat
et al., 2017; Thorne and Vlachos, 2018; Baly et al.,
2018).
3.2 Multimodal SD
Multimodal learning has proven successful for
many NLP tasks (Tsai et al., 2019; Zadeh et al.,
2020), including grounding (Beinborn et al., 2018),
visual question answering (Ben-Younes et al., 2017;
Yu et al., 2018), sentiment analysis (Rahman et al.,
2020), and humor detection (Hasan et al., 2019).
To the best of our knowledge, only one4075
dataset exists for multimodal SD, M S -
C(Taulé et al., 2018; Segura-Bedmar, 2018),
released for IberEval2018.M S C
collects 11,398 tweets in Spanish and Catalan dis-
cussing the Catalan 2017 Independence referen-
dum: according to Taulé et al. (2018), the corpus
is multimodal because it contains, along with the
tweets’ text, contextual information and up to 10
images downloaded from the authors’ timeline. We
note that, unfortuntately, almost all research build-
ing on M S Cconsidered only the pro-
vided textual features, thus ignoring its multimodal
component. As mentioned in Taulé et al. (2018,
p. 157), only 1 out of the 4 teams participating
in the task integrated images into their model, by
training a CNN on Spanish and Catalan ﬂags (with
the underlying intuition that using them would hint
to the user’s stance with respect to the topic of
Catalan independence). Interestingly, no positive
impact was observed on SD results when including
such multimodal signals.
Our work differs in a number of respects: (1) the
size of our corpus is considerably larger, thus allow-
ing for more robust training; (2) we do not consider
visual signals, such as images, but – consistently
with–’s domain – ﬁnancial time-series sig-
nals from stock market prices; and (3) most notably,
M S C’s multimodal signal consistsof a maximum of 10 images taken from the user’s
timeline: therefore, the images might not be related
to the tweet, might have been posted at a very dif-
ferent timestamp, or might be the same for multiple
tweets published by the same author. In contrast,
our ﬁnancial signal is speciﬁc to each tweet and is
perfectly aligned with its time of posting.
3.3 Finance and NLP
In recent years, there has been an increasing in-
terest in research at the intersection between ﬁ-
nance and NLP (Hahn et al., 2018; El-Haj et al.,
2018), with a rich stream of work focusing on ﬁ-
nancial textual analysis (Lang and Stice-Lawrence,
2015; Loughran and McDonald, 2016), sentiment
analysis (Giachanou and Crestani, 2016; Chan and
Chong, 2017; Krishnamoorthy, 2018), stance de-
tection (Conforti et al., 2020b,a, 2021a), volatility
prediction (Rekabsaz et al., 2017; Kolchyna et al.,
2015) and, above all, ﬁnancial forecasting (Qasem
et al., 2015; Ranco et al., 2015; Pagolu et al., 2016;
Pimprikar et al., 2017; Oliveira et al., 2017).
3.4 Multimodality in Financial Forecasting
While multimodality has not been investigated for
ﬁnancial SD, it constitutes a very active research
direction in ﬁnancial forecasting, i.e. the task
of predicting a business’ future ﬁnancial perfor-
mance (Abu-Mostafa and Atiya, 1996).
Given the importance of psychological and
behaviorial elements on stock-price move-
ments (Malkiel, 2003), researchers in economics4076have started to explore models which leverage
features beyond simple numerical values (Nikou
et al., 2019; Liu and Chen, 2019). In this context,
a stream of work analyzed the integration of
historical price data with social media texts (Sawh-
ney et al., 2020a) and other audio or textual
features (Zhao et al., 2019; Qin and Yang, 2019;
Sawhney et al., 2021b; Lee and Yoo, 2020;
Sawhney et al., 2021b,a; Das et al., 2021; Chen
and Huang, 2021).
4 Extending the–Dataset
Text Signal. As our text signal, we use Will-
They-Won’t-They (Conforti et al., 2020b,–), which collects English tweets discussing
four M&As between US companies (Table 1).–is expert-annotated for stance with respect to
the likelihood of the merger happening according
to the opinion expressed in the text, following a
four-class classiﬁcation schema: support, refute,
comment andunrelated (i.e. the tweet does not dis-
cuss the merger). Below, we report one example
for each of the considered labels (targets in squared
brackets):
• Support [_]CVS, Aetna $69B merger
wins DOJ approval < URL>
• Refute [ _]Big-name lawmakers want
to block Aetna-Humana and Anthem-Cigna!
• Comment [ _]Anthem-Cigna deal
would create ‘Big 3’: If the deal is approved
• Unrelated [_]Urge Your Legislators
to Oppose CVS and Walmart Takeover of Med-
ical Care Delivery!!! < URL>#MSSNY
Financial Signal. For the four healthcare M&As
in–, we obtain historical prices in 30-min
intervals for the involved stocks. The ﬁnancial
data has been bought from FirstRate Data LLC
(700MB) at market price.
Each entry in the data has the following ﬁelds:
DateTime, Open, High, Low, Close, Volume .
DateTime is in US Eastern Time, in the format
YY-MM-DD h:m:s . Only minutes with trading
volume are included: times with zero volume, such
as during weekends or holidays, are omitted. Pricesare adjusted for dividends and splits. We used
Python’s datetime library to align Twitter time
values (UTC) with the ﬁnancial signal (EST, New
York Stock Exchange)
Note that price variations in 30-minutes intervals
are considerably more granular than the ﬁnancial
signal used in NLP work, which is mostly limited to
daily data (Sawhney et al., 2020a). Such granular-
ity is necessary when monitoring tweets, which are
highly reactive to real-time, on-topic information
from the outside world (ALRashdi and O’Keefe,
2019).
Analysis. Figure 1 shows an example of the inte-
gration of the two signals. On the day the antitrust
complaint was made to the Department of Justice
regarding the M&A operation, ’s price in-
creased while’s decreased. Such movements tes-
tify that the event changed the world’s view: people
believe that the merger is less likely to happen, and
this is reﬂected by their investment decisions. The
direction of the price variation reﬂects standard
M&A theory (Bruner and Perella, 2004): the buyer
will not buy the target’s shares at a premium, thus
the owners of target’s stocks will not proﬁt from
the acquisition.
The price variation is useful for classifying a
tweet on that day, as it implies that the likelihood
of arefute label is higher. This is reﬂected in the
tweet distribution in the lower part of the Figure:
the distribution of tweets on that day shows that
most of them were indeed refuting . We report one
more example in Appendix A.
5 Models
As shown in Figure 2, our multitask SDTF model is
composed of a textual , aﬁnancial and a multimodal
component.
5.1 Text Encoder
Following previous work in SD (Hardalov et al.,
2021a), we obtain a vector representation h2
Rfor the textual input by averaging the token-
level hidden states from the last layer of a large
transformer (in our case, BerTweet (Nguyen et al.,4077
2020)). The input text is provided as:
[CLS] tweettext [SEP] target [SEP]
where target consists of the string: B(b;t)
will merge with T(t;t), whereB,b, andt, are
the buyer’s name, acronym and Twitter username
(same for the target company).
5.2 Price Encoder
Input. For each tweet posted at time s, we con-
sider a window of wdays in the past. At each
timestepi, infs w;s w+ 1;:::;sg, we con-
sider two price vectors p;p2Rwhich consist
of:
(1)p=ppp
= [o;c;h;l][o;c;h;l]
[v;r;c
cr
c]
whereo,c,h,landvare resp. the opening, closing,
highest, lowest price and volume of transactions at
timeifor the buyer’s stock (superscript b) or for
the overall market index (superscript m); ﬁnally,
ris the return at time iand is deﬁned as (c 
c)=c(Law (2018), same for the target).
Price Embeddings . We obtain a vector represen-
tationefor each time point iby concatenating:
pee (2)whereeandeare the time embeddings for
pandp(same for the target). We use
Time2Vec (Kazemi et al., 2019) for time embed-
dings, and we jointly learn embeddings for the
buyer and the target.
Price Encoder . As in Du and Tanaka-Ishii (2020)
and Kostkova et al. (2017), we use a Gated Recur-
rent Unit (Cho et al., 2014, GRU) to encode the
price variations over time. We implement two sep-
arateGRUandGRUfor the buyer and the target.
At timei, theGRU’s output consists of:
h=GRU(e;h)s wis (3)
To model the inter-dependencies between the
two stocks, we use multi-head attention mecha-
nism (Vaswani et al., 2017) which, in our experi-
ments, proved to be more effective for SD than the
“classic” temporal attention used in ﬁnancial fore-
casting (Feng et al., 2019). In practice, we obtain a
uniﬁed price vector representation h as:
h=(H;H) (4)
h=(H;H) (5)
h=hh (6)
whereandH(resp.andH) are the buyer’s
(and target’s) multi-head attention mechanism and
the matrix consisting of GRU’s (resp.GRU’s)
outputs.
5.3 Blending Multimodal Signals
Signals from different modalities encode comple-
mentary information (Schumaker and Chen, 2009):
we avoid simple concatenation (Li et al., 2016),4078which would treat such signals equally, and im-
plement a bilinear transformation to integrate the
tweet’s encoded representation with the historical
prices of the involved companies (Sawhney et al.,
2020a). Given the price and the text vector repre-
sentationsh2Randh2R, we obtain
a combined vector representation h2Ras:
h=relu(hWh+b) (7)
whereW2Randb2Rare the learned
weight matrix and bias.
5.4 Multi-Task Training
We jointly train our model to learn two sets of tasks:
SD and ﬁnancial forecasting (FF).
Stance Detection. We expect the ﬁnancial signal
to be relevant only in the case of related stance
labels (i.e. support, refute, comment ). In order to
assist the model in differentiating between those
two macro-classes, we predict a binary label re-
lated/unrelated along with the stance label y :
y =softmax (h)y =(h)(8)
Financial Forecasting. As it has been previously
studied in ﬁnance, rumors about a merger can affect
the stock prices of the involved companies (Jia
et al., 2020; Davis et al., 2021). To encourage
our model to learn such inﬂuence, we also add
two binary ﬁnancial-related outputs, in which we
predict the stock movement of the two companies:
y =(h) (9)
y =(h) (10)
whereh (resp.h ) is the concatenation of
the last output vector of GRUandh, andy
(resp.y )2f";#g(i.e., stock closing price for
the considered company will resp. move up, or fall).
The ﬁnal loss is:
L=L + 0:5L
+ 0:2L + 0:2L(11)
ForL we use categorical cross-entropy loss,
whileL;L andL use binary cross-
entropy loss function. The weights of the last three
loss components were empirically set in an initial
pilot.6 Experimental Setting
Preprocessing. We perform minimal preprocess-
ing on the textual signal. Concerning the ﬁnancial
signal, we consider a window of 30 timepoints in
the past, and price variations every 30 minutes: de-
pending on the tweet’s posting time, this accounts
for the previous2.5 days.
For FF, we predict ups or downs in the con-
sidered company’s closing price 2 hours after the
tweet(see Appendix B.1 for details).
Training Setup and Evaluation. Details on the
training setup and (hyper-)parameter settings are
reported in Appendix B.2 for replication. Fol-
lowing Hanselowski et al. (2018); Conforti et al.
(2020b), we consider macro-averaged precision,
recall andFscore. To account for performance
ﬂuctuations (Reimers and Gurevych, 2017), we av-
erage three runs for each model (standard deviation
is reported in Appendix B.2).
Baselines. We consider six published baseline
models, including the four best models of Conforti
et al. (2020b):
•SVM , a linear-kernel SVM leveraging bag of
ngrams (over words and characters) features,
similar as in Mohammad et al. (2017);
•CrossNet , a cross-target SD model (Xu et al.,
2018) consisting of a bidirectional conditional
encoding model over LSTMs, augmented with
self-attention and two dense layers;
•SiamNet , a siamese network similar to San-
tosh et al. (2019), which is based on a BiL-
STM followed by a self-attention layer;
•HAN , a Hierarchical Attention Network as
in (Sun et al., 2018)) which uses two levels of
attention to leverage the tweet representation
along with linguistic information (sentiment,
dependency and argument);
and two further baselines from Liang et al. (2021):
•BERT , a strong vanilla BERT-based model
ﬁne-tuned on–;
•TPDG , a sophisticated network based on a
target-adaptive pragmatics dependency graph.4079
Finally, we also consider BerTweet , a model re-
lying on textual signal only; it is a BerTweet
model (Nguyen et al., 2020) ﬁne-tuned on–.
7 Results and Discussion
Table 3 shows our experimental results. We observe
that using BerTweet as main text encoder alone
achieves considerable gains in performance with
respect to all stance labels considering all baselines,
including the strong vanilla BERT baseline.
This is unsurprising, given the peculiarities of
Twitter language (Hu et al., 2013) which are cap-
tured by BerTweet.
Adding the ﬁnancial signal. Adding our ﬁnancial
component proves to be effective over all consid-
ered targets, with improvements in Fscores up to
+5.8 (_ ).
Single-label performance seems to suggest that
price variations encode very useful information for
all labels, resulting in notable improvements not
only on the unrelated (+3.7), but also on the refute
andsupport samples (resp. +2.1 and +5.4 in accu-
racy): this is important because those labels, apart
from being the minority classes, arguably consti-
tute the most relevant information for downstream
tasks (Scarton et al., 2020).
Adding Multi-Task Objectives and Ablation Ex-
periments. Results of ablation experiments (Ta-
ble 3) show that including the ﬁnancial forecast
(+FF) task alone brings moderate improvements in
performance, while considering binary SD (+Bi-
nary) alone moderately degrades it: their combina-
tion, however, achieves the best results over three
of the four mergers.
Interestigly, jointly modeling FF and binary SD
seems to be beneﬁcial not only for SD: as shown
in Table 4, best results on both ancillary tasks are
obtained in the multitask setting. Binary SD perfor-
mance is very satisfactory over all mergers, with a
correlation with M&As with a higher proportion of
unrelated samples.
Moving to the other ancillary tasks, FF results
are encouraging, even if we considered a consid-
erably shorter time window of historical pricing
than architectures speciﬁcally designed for FF (Du-
mas et al., 2009; Kim et al., 2019; Ho et al., 2021).
This suggest that the learned multimodal textual
and ﬁnancial vectors constitute an informative in-
put for the FF predictors.
Single-Label Performance. An analysis of
single-label performance (Table 3) shows that mod-
els including the ﬁnancial component, with or with-
out ancillary tasks, achieve best performance on all
related labels.4080
Interestingly, however, best performance overall
for the unrelated samples is obtained with the sim-
plest of the considered models, a strong SVM over
character- and word-ngrams similar to (Moham-
mad et al., 2017). A similar situation, in which a
model leveraging simple lexical features achieved
best results on the unrelated samples, was already
observed not only for–(Conforti et al.,
2020b), but also for other SD datasets, such as
FNC-1 (Pomerleau and Rao, 2017; Hanselowski
et al., 2019).
We note that, in both datasets, related-unrelated
vs.support/comment/refute classiﬁcations can be
seen as constituting two different tasks: the for-
mer is more similar to topic detection, where even
surface-level methods can do well, whereas the
latter is an inference task which requires deeper
semantic knowledge (Conforti et al., 2018).
The analysis of the confusion matrices (reported
in detail in Appendix B.2) shows that most errors
concern support orrefute samples which were mis-
classiﬁed as comment : as already observed in Con-
forti et al. (2020b), the difference between a com-
ment and a stance-bearing label such as support
(orrefute ) depends on argumentative nuances in
the tweet, which are sometimes subjective and ulti-
mately depends on the annotator’s preferences. A
number of comment-unrelated misclassiﬁcations
are also present, especially for M&As with a high
number of unrelated samples (such as_
and _).
Performance When “Silencing” Different Sig-
nals. In order to estimate the relative importance
of the two signals considered in the SDTF model,
we consider a scenario in which we silence one
of the two signals: for the textual signal, this cor-
responds to replacing the target and the tweet’s
text with two empty strings (i.e., [CLS] [SEP]
[SEP] as input to the right component in Fig-
ure 2); for the ﬁnancial signal, we input two empty
price vectors for the considered companies (i.e. the
left components in Figure 2).
Results of such ablation experiments (Table 5)
show that, as expected, the textual signal provides
the biggest contribution for SD, and the ﬁnancial
signal alone is not sufﬁcient at all to perform SD.
Blending together both signals, however, provides
the most informative input to the model: a con-
sistent drop in performance over all labels, includ-
ingunrelated , is observed with models exposed to
empty price vectors.
Robustness Over Parameters Freezing. More-
over, we investigate the model robustness over
freezing BerTweet: we consider two scenarios, in
which we freeze the complete weights or BerTweet,
or all but its last three layers (Wang et al. (2019),
see Appendix B.2 for details on number of parame-
ters for the different settings).
As expected (Mosbach et al., 2020), perfor-
mance degrades with fewer layers trained (Table 6),
with the exception of the BerTweet architecture
when freezing all but its last three layers. Notably,
our multitask SDTF model is more robust over pa-
rameter freezing than the vanilla BerTweet, achiev-
ing higher performance over all considered metrics:
this suggests that, when less powerful textual en-
coders are provided, the presence of the ﬁnancial
signal supports SD classiﬁcation.
Adding Synthetic Data. As mentioned in the In-
troduction, a recent stream of work investigates the
usage of synthetically generated data to compen-
sate for data scarcity in Twitter SD. In particular,
Li and Caragea (2021) used Auxiliary Sentence
based Data Augmentation (ASDA), a conditional4081
data augmentation method, to double the size of
SD datasets, achieving state-of-the-art results on–with a model trained on the union of gold
and synthetic samples.
In a last set of experiments, we investigate the
impact of adding such synthetically generated ex-
amples to an SDTF model. As synthetic samples
aren’t associated to any price vectors from the stock
market, we proceed as follows: we ﬁrst ﬁne tune a
BerTweet model on ASDA, which we obtain
from the ASDA paper’s authors; then, we use such
model’s weights to initialize the textual encoder
of an SDTF multitask model (the left components
in Figure 2), which we ﬁnally train on the gold–as described in Section 5.
Results in Table 7 show that models trained on
ASDA(gold and synthetic samples) achieve
better results than SDTF trained on gold data alone.
Including synthetic signal from ASDAseems
to be effective for all considered training settings:
even using a simple pretraining strategy as de-
scribed above allows an SDTF model to capture
useful textual features from the synthetic samples,
which are retained over the ﬁnetuning stage and
allow for better cross-target generalization.
Our ﬁnetuned model (ASDA+SDTF in Table 7)
reaches state-of-the-art results on the–
dataset and best results over three of the four con-
sidered mergers, with gains in Fscores ranging
from +1:4( _) to+3:2(_ ).
8 Conclusions
In this paper, we studied the well-established task
of Twitter SD in a multitask scenario, focusing on
the ﬁnancial domain. We proposed SDTF, a novel
model which integrates two modalities, text and
ﬁnancial time series data. We extended–, a
large dataset for ﬁnancial SD, with ﬁnancial signals
from stock market prices. Our detailed analysis of
models’ results demonstrated that ﬁnancial SD on
tweets beneﬁts from such signals: models whichinclude textual and ﬁnancial features showed bet-
ter cross-target generalization capabilities, and ob-
tained better results on all stance labels. Finally,
we proposed a simple but effective setting to lever-
age useful signals encoded in synthetic samples,
reaching state-of-the-art results on–.
We release the ﬁnancial signal collected to com-
plement–: together with the S cor-
pus of news SD, which discusses the same mergers,
it constitutes an invaluable and unique resource to
foster research on multi-modal, multi-genre SD,
and to model the integration and mutual inﬂuences
between stock market variations, tweets, and au-
thoritative news sources.
Ethics and Broader Impact
Data Collection. Daily ﬁnancial data is pub-
licly available and can be freely downloaded
(e.g. through Yahoo Finance). However, granular
ﬁnancial data needs to be purchased. We bought
the historical ﬁnancial data from FirstRate Data
LLC, who source their data directly from major
exchanges. We tested all signals for consistency
and completeness, and found that it reﬂects the
actual trading in the stocks.
Presence of Bias. As textual input, we used–, a publicly available dataset which we obtained
from the authors after signing a data sharing agree-
ment (Academic Free License). Given that many
NLP tasks are somehow subjective (Poesio et al.,
2019), and the choice of annotators might reinforce
the emergency of bias (Waseem, 2016; Sap et al.,
2019; Geva et al., 2019) we note that–might
contain annotation bias, which could be ampliﬁed
by our models (Shah et al., 2020; Waseem et al.,
2021). Moreover, the BerTweet model we are using
as main text encoder might encode biases due to
the data it was trained on (Bender et al., 2021). We
observe, however, that both elements are beyond
our control.
Data Sharing. In accordance with FirstRate Data,
we release the relevant portion of the data under
Academic Free License at the link: https:
//github.com/cambridge-wtwt/
acl2022-wtwt-stocks . We are aware
of the many ethical issues surrounding social
media research (Hovy and Spruit, 2016). Virtually
all models trained on social media data are
dual-use (Benton et al., 2017): in order to avoid4082potential misuse, we will share our ﬁnancial
signals, which is complementary to–, only
upon signing a data sharing agreement restricting
the data usage to research only.
Environmental Factors. We are conscious that
training transformers such as BerTweet produces
large quantity of COemissions (Strubell et al.,
2019; Henderson et al., 2020). We observe that,
in our case, we are not training such models from
scratch, thus considerably limiting the training time.
Moreover, we also experimented with (partially)
frozen transformers (Lee et al., 2019; Sajjad et al.,
2020; Mosbach et al., 2020), which in turn require
less parameters to be optimized.
Acknowledgments
We thank the anonymous reviewers of this paper
for their efforts and for the constructive comments
and suggestions. We gratefully acknowledge fund-
ing from the Keynes Fund, University of Cam-
bridge (grant no. JHOQ). CC is grateful to NERC
DREAM CDT (grant no. 1945246) for partially
funding this work. CG and FT are thankful to the
Cambridge Endowment for Research in Finance
(CERF).
References4083408440854086408740884089A Data Analysis
In addition to the example discussed in Section 4,
we report a further case study from ﬁnancial data
aligned to–, this time from one of the suc-
ceeded mergers,_. As shown in Figure 3,
on the day in which the_ merger was
ofﬁcially announced, the buyer’s price decreased,
while the target’s price increased. This is in line
with the theory (Bruner and Perella, 2004) and also
makes intuitively sense: the deal was worth $69 bil-
lion and was likely to need to pay a premium
to acquire’s shares.
This knowledge is captured by the stock market’s
movements, and constitutes very valuable informa-
tion for a stance classiﬁer, as it implicitly increases
the likelihood of a supporting stance. The lower
plot in Figure 3 shows not only a peak in the tweets
number, but also in the relative proportion of sup-
porting tweets.
B Experimental Speciﬁcation
B.1 Detailed Data Preprocessing
We perform minimal preprocessing on the tex-
tual input: differently than in the BerTweet pa-
per (Nguyen et al., 2020), we perform only URL
normalization and lowercasing. We leave the user-
names as in their original form: this was done be-
cause, in many cases, the usernames are the only
clue in the tweet that points to one of the consid-
ered companies. To create the string representation
for the target, we follow Conforti et al. (2020b)’s
representation of company names and acronyms,
and add the ofﬁcial (at the time of data collection)4090
Twitter account(s) for both the buyer and the target
(Table 8).
B.2 Experimental Setup
(Number of) Hyper-Parameters. All models use
Adam (Kingma and Ba, 2014) with weight decay
3e 5,1 = 0:9,2 = 0:999. Models are trained
for a maximum of 7 epochs, with early stopping
monitoring the eval loss with a patience of 3. All
hyper-parameters used are reported in Table 9 and
have been optimized on the development set. Ta-
ble 10 reports on the total number of (trainable)
parameters for each considered model.
Training Setting. All models are trained using
cross-validation, testing on one target and train-
ing on the other three. The–dataset does
not provide any ofﬁcial development set. Follow-
ing (Conforti et al., 2020b), we randomly select a
15% of the training sample as development set.
Evaluation Framework. We use sklearn’s im-
plementationof accuracy and macro-averaged
precision, recall and Fscores (Pedregosa et al.,
2011).
Computing Infrastructure and Runtime Speci-
ﬁcations. Models were trained on Google Colab’s
GPU. On average, each experiment took 1:30
hours to train.
Confusion Matrices. Detailed confusion matri-
ces for all cross-validation settings are reported in
Figure 4.4091