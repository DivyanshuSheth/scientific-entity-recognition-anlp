
Malik H. Altakrori
School of Computer Science
McGill University / Mila
Montreal, Canada
malik.altakrori@mail.mcgill.caThomas Scialom
Meta AI
Paris, France
tscialom@meta.com
Benjamin C. M. Fung
School of Information Studies
McGill University / Mila
Montreal, Canada
ben.fung@mcgill.caJackie Chi Kit Cheung
School of Computer Science
McGill University / Mila
Montreal, Canada
jcheung@cs.mcgill.ca
Abstract
Authorship obfuscation techniques have com-
monly been evaluated based on their ability to
hide the author’s identity (evasion) while pre-
serving the content of the original text. How-
ever, to avoid overstating the systems’ effec-
tiveness, evasion detection must be evaluated
using competitive identiﬁcation techniques in
settings that mimic real-life scenarios, and the
outcomes of the content-preservation evalua-
tion have to be interpretable by potential users
of these obfuscation tools. Motivated by re-
cent work on cross-topic authorship identiﬁ-
cation and content preservation in summariza-
tion, we re-evaluate different authorship ob-
fuscation techniques on detection evasion and
content preservation. Furthermore, we pro-
pose a new information-theoretic measure to
characterize the misattribution harm that can
be caused by detection evasion. Our results
reveal key weaknesses in state-of-the-art ob-
fuscation techniques and a surprisingly com-
petitive effectiveness from a back-translation
baseline in all evaluation aspects.
1 Introduction
Authorship obfuscation is the task of masking the
writing style of an author of a document to pre-
vent authorship identiﬁcation techniques from us-
ing stylistic patterns to reveal the author’s iden-
tity (Kacmarcik and Gamon, 2006). The motivation
for this task is to protect the public from the misuse
of authorship identiﬁcation techniques to suppress
freedom of speech or to persecute whistle-blowers.
When a new authorship obfuscation technique is
proposed, it is crucial to compare its effectiveness
to state-of-the-art obfuscation tools in settings thataccurately depict the real-life environment where
such a tool may be used. One important assump-
tion that should be made is that a de-anonymizer is
likely to use the most competitive authorship iden-
tiﬁcation tool available to identify the author of a
document. Using an inferior or brittle authorship at-
tribution technique, or a weak obfuscation baseline
will overstate the performance of such obfuscation
tools. For example, previous work on obfuscation
has evaluated obfuscation techniques against an
identiﬁcation tool that uses the exact same features
and classiﬁer that were used to obfuscate it in the
ﬁrst place (Mahmood et al., 2019). This could lead
to misleadingly high impression of the system’s
effectiveness.
Similarly, obfuscation techniques must convey
the same intended message both before and after
obfuscation. Therefore, when a new obfuscation
tool is proposed, it is evaluated on both the qual-
ity of obfuscation and its ability to preserve the
content. With the recent development in language
models and their ability to generate text, many au-
tomatic measures have been introduced to evaluate
the quality of this generated text (Novikova et al.,
2017), and some of these measures have been used
in obfuscation techniques.
The problem with existing content-preservation
measures, however, is that they only provide an ab-
stract, numerical score that limits the user’s ability
to pinpoint the part of the text that suffered from
loss of information and requires re-modiﬁcation.
Recently, question answering-based approaches
were proposed and shown to provide meaningful
feedback in the form of questions that tell the user
which information in the text has been changed and
in which part (Durmus et al., 2020).
The concept of evasion in authorship obfusca-2391tion has a critical, potential harmful side-effect that
we raise for the ﬁrst time. In a classiﬁcation setting,
the typical setting in which evasion of obfuscation
techniques are evaluated, a classiﬁer has to pick
one author from the set of candidate authors. An
obfuscation technique may obfuscate a document
by imitating another potential author, in effect un-
fairly “framing” another person. To investigate this
behavior, we use an information-theoretic approach
to evaluate the potential for misattribution of the
obfuscating technique. Speciﬁcally, we propose
a new evaluation measure; namely, misattribution
harm where the goal is to characterize the conﬁ-
dence in the attribution algorithm rather than its
output.
In this work, we highlight a number of issues
with the existing work on obfuscation with respect
to two dimensions: obfuscation effectiveness, and
content preservation. We further propose a new
evaluation dimension namely, misattribution. Our
key contributions are the following:
•We show that a carefully selected baseline
can outperform state-of-the-art obfuscation
techniques.
•We use question answering as an evaluation
measure for content preservation instead of
token- and embedding-based approaches.
•Using information theory, we conduct a de-
tailed analysis of the harming effect of misat-
tributing a document to a different author to
achieve detection evasion.
2 Background
Authorship obfuscation (Brennan et al., 2012) tech-
niques aim to hide an author’s writing style which
can be used by authorship identiﬁcation tools to
reveal the true identity of that author. Here, the
assumption is that the author has already taken
the precautions to hide their identity by removing
any identifying information such as their name or
address from the text. By using obfuscation tech-
niques, users aim to hide their writing habits which
may or may not be known to them. With that in
mind, it is important that the obfuscated text con-
tains the same conveyed message after obfuscation.
2.1 Obfuscation
Obfuscation tools can be divided into two groups:
generic off-the-shelf tools, and application-speciﬁc
obfuscation tools.Generic Tools. Examples of off-the-shelf tools
include machine translation and data augmentation
approaches (Mansoorizadeh et al., 2016). These
tools have been adapted for the purpose of gen-
erating a slightly modiﬁed version of a docu-
ment. Commonly, these tools are used as base-
lines to be compared against obfuscation-speciﬁc
techniques (Brennan et al., 2012; Keswani et al.,
2016) because they are easy to use, require no fur-
ther training or extra data from the user, and need
minimal knowledge about the obfuscation process.
Table 1 is an example of these tools where trans-
lating a sentence into different languages and then
back to the original one creates a modiﬁed version
of the original sentence.
Text Language
How is it going bro - En
Wie geht es dir, Bruder? En De
Comment vas-tu mon frére? De Fr
How are you my brother? Fr En
When machine translation approaches were ini-
tially used, only statistical machine translation
(SMT) methods such as Moses (Koehn et al., 2007)
and Google’s previous Translate API (Wu et al.,
2016) were available. They were shown to suffer
from low obfuscation effectiveness and generated
text with poor linguistic ﬂuency compared to obfus-
cation techniques. In contrast, more recent neural
machine translation approaches are able to gener-
ate higher-quality translations compared to SMT
approaches according to some evaluation metrics.
This development warrants re-evaluating their per-
formance, especially as both Brennan et al. (2012)
and Keswani et al. (2016) used SMT approaches.
In this work, we use well-tuned baselines that are
expected to be competitive with obfuscation tech-
niques as opposed to using simple and primitive
ones. An example of excluded baselines is Ran-
dom Replacement which tries to obfuscate a docu-
ment by replacing words in that document with a
random word from the author’s vocabulary set, or
with a synonym from a dictionary. Such baselines
have been explored heavily in the literature and are
known for their poor obfuscation performance and
incoherent output.2392Obfuscation-speciﬁc Tools. By contrast, obfus-
cation tools are built speciﬁcally to hide the au-
thor’s identity and are tested against state-of-the-
art authorship attribution techniques. While these
tools require further training and/or additional data,
they have been shown to be more effective than
generic tools.
In this work, we evaluate two different ap-
proaches that focus speciﬁcally on obfuscation.
Mutant-X (Mahmood et al., 2019) is a genetic algo-
rithm that utilizes GloVE (Pennington et al., 2014)
word embeddings to replace words in a document
with similar ones to create a modiﬁed version of a
document. This technique requires knowledge of
the authorship attribution classiﬁer, speciﬁcally, the
probability of each author, to do the obfuscation.
Heuristic Obfuscation Search (Bevendorff et al.,
2019, 2020) was initially developed as an imitation
approach to obfuscation. The algorithm requires
a target author proﬁle which is the tri-grams fre-
quency and the goal is to generate a document with
a similar author proﬁle. This is a rule-based ap-
proach where changes to the text—based on differ-
ent rules—are associated with costs, and the goal
is to generate a document with high similarity to
the target proﬁle with the minimum cost; i.e., by
making the smallest number of changes.
There exists another category of approaches
where the obfuscation is done on the feature repre-
sentation of the document, e.g., the n-gram vector
representation, and not on the actual document.
This category of obfuscation is used to protect the
identity of the author while performing another
task, such as sentiment analysis. Since the original
text remains intact, we consider the literature on
this category out of the scope of this work. An
example of this work is Weggenmann and Ker-
schbaum (2018).
Finally, neural-based, obfuscation-speciﬁc ap-
proaches, e.g., (Emmery et al., 2018; Bo et al.,
2021), are still deemed impractical for the author-
ship obfuscation domain where researchers would
attribute this impracticality to the lack of large
training datasets which these neural approaches
require (Bevendorff et al., 2020).
2.2 Identiﬁcation
As mentioned earlier, it is important to use a
state-of-the-art authorship identiﬁcation approach
to evaluate evasion in authorship obfuscation.
In the authorship attribution domain, it is well-established that a cross-topic authorship identiﬁ-
cation tool should have a realistic performance that
mimics real-life applications (Goldstein-Stewart
et al., 2009; Sundararajan and Woodard, 2018;
Stamatatos, 2017, 2018; Custódio and Paraboni,
2019; Barlas and Stamatatos, 2020, 2021; Altakrori
et al., 2021). Because of that, we use a state-of-the-
art (Altakrori et al., 2021) cross-topic, authorship
identiﬁcation technique to evaluate evasion of ob-
fuscation techniques namely, (Stamatatos, 2018).
2.3 Evaluating Content Preservation
Evaluating content preservation in text is important
even if we value safety (Potthast et al., 2016). This
is because people want to maintain their privacy
while sharing their opinions freely. Besides obfus-
cation, content evaluation techniques are applicable
to other NLG tasks such as machine translation and
summarization, and these techniques fall within
one of three groups.
Token-based evaluation metrics depend on token
overlap between a source and a target document.
Examples of these metrics are METEOR (Banerjee
and Lavie, 2005), BLEU (Papineni et al., 2002),
and ROUGE-L (Lin, 2004). While these metrics
were among the early ones to be used, they have
been shown to have a lower correlation with hu-
man scores for fact preserving in text summariza-
tion (Maynez et al., 2020; Honovich et al., 2021).
With recent advances in representation learning,
particularly in word and sentence embeddings, new
model-based metrics were adopted where a smaller
change in the sentence embedding indicates higher
content preservation. Examples of such metrics are
the Universal Sentence Encoder (USE) (Cer et al.,
2018) and BERTScore (Zhang et al., 2020).
More recently, the summarization community
proposed a new, question-answering-based ap-
proach to evaluate the content preservation in sum-
marization. The argument for this work is that the
content is considered preserved if we can give the
same answer to a particular question both before
and after summarization. Examples of this work
are (Wang et al., 2020) and (Scialom et al., 2021).
Here, using such a system, providing feedback to
the users of obfuscation techniques would become
easier since the unanswered questions and the spans
from which the questions are taken can be shown.23933 A Multifaceted Evaluation Framework
Ideally, authorship obfuscation should only mod-
ify the author’s writing style in a document while
retaining all the original information. However,
due to the topic–writing style entanglement, modi-
fying the document is likely to cause information
loss; i,e., some content is not preserved. Based on
that, obfuscation techniques are evaluated in two
dimensions: evasion, and content preservation.
In the following subsections, we formally de-
scribe obfuscation, evasion and content preserva-
tion and we discuss the state of the tools used to
evaluate them. Finally, we propose a novel eval-
uation dimension to characterize a potential side
effect of a successful detection evasion namely,
misattribution.
3.1 Obfuscation
Letdbe a document written by author a. To hide
their identity, a∗uses an obfuscation technique
O:d→ˆdthat takes a document das an input,
modiﬁes it, and outputs an obfuscated version of
this document, namely, ˆdsuch that d/negationslash=ˆd.
For example, suppose we have a document d,
where d= “The decision caused the team a big
loss!”, which was written by author a= “Q”.
Next, “Q”uses an obfuscation technique Othat
modiﬁes the document dby changing it to ˆd, where
O(d) =ˆd= “The advice caused the team a huge
loss”.
3.2 Evading Detection
We use an authorship identiﬁcation technique to
evaluate the performance of authorship obfuscation.
If the identiﬁcation technique was able to identify
the original author before obfuscation but failed
to identify that author after obfuscation then the
obfuscated document has evaded detection.
The evaluation process is as follows. We start
by training and tuning an authorship identiﬁcation
tool on the training and validation documents, re-
spectively. Then, we record the identiﬁcation accu-
racy on the original test documents. Next, we use
an obfuscation technique to modify the test docu-
ments to hide the authors’ writing styles in theses
document. Finally, without further training/ﬁne-
tuning to the identiﬁcation tool, we measure the
authorship identiﬁcation performance on the ob-
fuscated test documents. The effectiveness of an
obfuscation technique is quantiﬁed by the differ-
ence in identiﬁcation performance before and afterobfuscation over all the test documents in the in-
vestigated dataset.
Formally, let Ibe an authorship identiﬁcation
technique I: (d, T)→athat takes a document d
and a set of candidate authors of this document T
as input, and outputs aas the most plausible author
of this document d. LetT= [a, a, . . . , a]and
n=|T|. We say that author ahas evaded detec-
tion using the obfuscation tool OifI(d, T) =a∗,
I(O(d), T) =a, where a/negationslash=a; and a, a∈T.
Note that, if I(d, T)/negationslash=a∗thenddoes not require
obfuscation against I.
To evaluate the obfuscation performance over a
whole test dataset D, letS: (a, a)→Z∈[0,1]
be an indicator function given by Eq. 1. Finally,
letAccuracy =/summationtextS(I(d, T), a)/m, where
m=|D|is the number of test documents.
S(a, a) =/braceleftbigg1,ifa=a
0,otherwise/bracerightbigg
(1)
Continuing from the example in Sec. 3.1, let T
be [“G”, “Q”, “B”, “M”, “W”], the predicted au-
thor before obfuscation, i.e., I(d,T) beQ, and the
predicted author after obfuscation, i.e., I(O(d), T)
beG. Here, the obfuscation tool Ohas evaded
detection successfully.
3.3 Preserving the Content
After evaluating evasion, content preservation is
evaluated to investigate whether loss of informa-
tion has occurred due to obfuscation. An author-
ship obfuscation technique should maximize the
content preservation, or equally minimize the loss
of information. After evaluation, the result of this
evaluation is communicated to the author to de-
cide whether to accept the obfuscation outcome, or
reject it if the information loss is drastic.
Formally, let P: (d, O(d))→Rbe a content-
preservation evaluation tool that takes an original
document dand an obfuscated document O(d)as
input, compares their content and outputs a content-
preservation score that represents the amount of
information preserved from the original document
dafter obfuscation.
For example, suppose that the content-
preservation tool of choice is based on the word-
level, uni-grams overlap between the original docu-
mentd, and the obfuscated document O(d), where
d= “The decision caused the team a big loss!”
andO(d)= “The advice caused the team a huge
loss”. Suppose that splitting d, and O(d)into2394word-level uni-grams yields [“The”, “decision”,
“caused”, “the”, “team”, “a”, “big”, “loss!” ]
and [“The”, “advice”, “caused”, “the”, “team”,
“a”, “huge”, “loss”], respectively. Here, the goal
is to maximize content-preservation score where
P: (d, O(d)) = 5 .
3.4 Fairness, and the Potential of
Misattribution Harm
In real-life applications of authorship identiﬁcation,
misattribution can have severe outcomes. For exam-
ple, if the obfuscated text is a threatening message,
then it is important to identify the real culprit to
avoid persecuting an innocent person.
Conﬁdence in the identiﬁcation outcome is a
core concept in authorship identiﬁcation that has
not been emphasized in the obfuscation literature.
Instead of imitating a writing style of one of the
candidate authors, an obfuscation technique may
output a generic writing style that is difﬁcult to
attribute to a speciﬁc author. In that case, the iden-
tiﬁcation technique will still provide a candidate
author, but its conﬁdence in this output would be
low. As a result, if an obfuscation technique can
lower the conﬁdence of an identiﬁcation method,
then its outcome will be in a position of doubt,
hence, neither the original author nor the identiﬁed
one will have to suffer.
Formally, let C:(I,d,T)→Rbe a tool that takes
as input an authorship identiﬁcation tool I, a doc-
ument d, and a set of candidate authors for that
document Tand outputs a probability distribution
over the candidate authors [c, c, . . . , c], where
c=P(a|d)is the likelihood of author abeing
the original author of document dwhen author-
ship identiﬁcation tool Iis used, 0≤c≥1, and/summationtextc= 1.
In this work, we consider the model’s conﬁdence
to be a high when the probability distribution for
the one author is much higher compared to the other
authors. For example, a model is the most conﬁdent
when it predicts author Awith probability 1. In
contrast, a model is the least conﬁdent, or rather
clueless, when the probability distribution over all
the authors is uniform, i.e. when the probability of
each author is, where Tis the number of authors.
Note that the model can predict the wrong author
and have high conﬁdence in its prediction. Luckily,
this conﬁdence can be measured by computing the
entropy (Eq. 2) for the attribution model, and the
effect of misattribution harm can be characterizedby the difference in entropy before and after obfus-
cating a document ( d). While there exists a number
of approaches to measure the difference between
the two entropy values, such as cross-entropy or
KL-divergence, we chose the difference in entropy
for simplicity. Other measure could potentially be
explored in future work.
H(X) =−/summationdisplayP(x) logP(x) (2)
Furthermore, this approach can provide a more
ﬁne-grained measure of performance than the iden-
tiﬁcation accuracy. For example, let us assume
that the attribution model had to identify the most
plausible authors from a set of three authors: a,
a, and a. Before obfuscation, The model cor-
rectly identiﬁes aas the most plausible author
with the maximum conﬁdence in its prediction, i.e.,
the probability distribution over the authors was 1
foraand 0 otherwise.
After obfuscation using technique A, the model
identiﬁes aas the most plausible authors, i.e., a
has successfully evaded detection. The model, how-
ever, outputs a probability distribution of 0.7 for
a, 0.2 for aand 0.1 awith a high conﬁdence
in its prediction. Alternatively, after obfuscation
using technique B, the identiﬁcation model also
identiﬁes aas the most plausible author, outputs
a probability distribution of 0.4 for a, 0.3 for a
and ﬁnally, 0.3 a.
Clearly, both techniques generated the same au-
thor prediction, and so, both techniques evaded
detection. However, technique B would be consid-
ered better because it caused the attribution model
to have lower conﬁdence in its prediction.
4 Experimental Setup
Our overall evaluation procedure is as follows. We
started by establishing the authorship identiﬁca-
tion accuracy on the original datasets. Note that,
the training and testing split is predeﬁned for each
dataset as shown in Table 2. For validation, how-
ever, we shufﬂed the training set and took 20% of
the samples for validation.
We followed that by creating different obfus-
cated copies of the test sets, one for each obfusca-
tion technique. Next, we evaluated the detection
evasion and misattribution on each obfuscated copy
in one step. We concluded our evaluation with con-
tent preservation. We provide below the details of
each step separately.23954.1 Corpora
For this work, we use two different corpora:
the Extended Brennan–Greenstadt Corpus (EBG)
dataset (Brennan et al., 2012) and the Reuters Cor-
pus V olume 1 (RCV1) (Teahan, 2000; Khmelev,
2000; Kukushkina et al., 2001), commonly referred
to as C50 dataset. For each dataset, we use two
authors conﬁgurations: ﬁve authors, and 10 authors.
We provide corpus statistics in Table 2.
4.2 Authorship Obfuscation
The evasion performance of an obfuscation tech-
nique is compared to a set of baselines as well as
state-of-the-art obfuscation techniques. Here, the
role of a baseline is to set a lower bound on the per-
formance while requiring little knowledge about
the problem, and a fairly low effort to use.
In this work, we use a neural machine translation
model in the back-translation baseline to replace
statistical models that were used in previous stud-
ies (Brennan et al., 2012; Keswani et al., 2016).
Additionally, we use a contextual language model
namely, BERT to replace words based on their con-
text, instead of replacing them with synonyms or
random words from the author’s vocabulary set.
Back Translation (BT) uses Facebook’s many-
to-many translation model (El-Kishky et al., 2020;
Fan et al., 2021; Schwenk et al., 2021) imple-
mented by the HuggingFace (Wolf et al., 2020)
library. This model has two advantages. Firstly,
it is open-source and its results can be replicated
in contrast to commercial translation products that
are costly and can be replaced at any time.Secondly, this model translates between lan-
guages directly without using English as a refer-
ence/pivot language. Many of the existing neural
machine translation models use English as a pivot
language where translation is done either from En-
glish or toEnglish. For example, if the task is the
translate from French to Chinese, one has to trans-
late from French to English, then from English to
Chinese. This approach defeats the whole point
of multi-hop translation where the goal is to use
the differences between languages in phrasing the
same idea to change the writing style of a sentence.
Lexical Substitution Using BERT (LSB)
(Mansoorizadeh et al., 2016) masks random words
in a sentence, then use BERT language model to
replace these words with ones that ﬁt the context.
Mutant-X (Mahmood et al., 2019) replaces
words based on their GloVE word embeddings
given that the candidate replacement has the same
sentiment. This technique requires knowledge of
the authorship attribution classiﬁer, speciﬁcally, the
probability of each author, to do the obfuscation.
Heuristic Obfuscation Search (A*) (Bevendorff
et al., 2019) was originally developed as an imi-
tation approach to obfuscation. The algorithm re-
quires a target author proﬁle which is the tri-grams
frequency. This rule-based approach changes the
text while incurring costs, and the goal is to gen-
erate a document with a high similarity to a target
proﬁle with minimum cost.
4.3 Authorship Identiﬁcation
For authorship identiﬁcation, we use the state-of-
the-art (Altakrori et al., 2021) cross-topic, author-
ship identiﬁcation technique to evaluate evasion
of obfuscation techniques namely, Masking (Sta-
matatos, 2018). The main idea of this approach
is to mask words in a document, where masking
is done by replacing the characters in the word
with asterisks, then use word- or character-level
n-grams to represent as features. The choice of
which words are masked is based on the hyperpa-
rameter k. In a document, any word that is not in
thek-most frequent words in the British National
Corpus (BNC) must be masked. After masking and
extracting the n-gram features, a Support Vector
Machines (SVM) with linear kernel is used as a
classiﬁer.2396
4.4 Content Preservation
To evaluate the content preservation, we chose the
EBG dataset with the ten authors conﬁguration.
From all the original test documents and the four
obfuscated versions, we randomly selected 10% of
the documents. These documents were split into
sentences, and a sentence was included or excluded
from the evaluation samples based on a coin ﬂip.
This resulted in 212 sampled sentences, an average
of 42 sentences per obfuscation techniques. To
avoid cherry-picking samples that favor one metric
vs. another, we did not exclude any of the sampled
sentences. However, we discuss the consequence
of this in the results section below.
To evaluate content preservation of these sam-
ples, we used HuggingFace implementation for
both token-based and model-based evaluation
tools. For the question answering approach, we
used (Scialom et al., 2021) that generated the ques-
tions from the original document instead of needing
a reference.
In brief, we used BLEU (Papineni et al., 2002),
ROUGE-1, 2, and L (Lin, 2004), METEOR (Baner-
jee and Lavie, 2005), BERTScore (Zhang et al.,
2020), and QuestEval (Scialom et al., 2021) to eval-
uate content preservation. For example, for BLEU,
we consider the obfuscation text as the translation
of the original text and we report the average BLEU
score over the 212 sampled sentences.
Appendix A.6 provides various obfuscated exam-
ples for each obfuscation technique. With these ex-
amples, we inspect what was each technique good
at, and what did it fail to do. A more detailed
study on the types of errors made by obfuscation
techniques can be found in (Gröndahl and Asokan,
2020).4.5 Characterizing Misattribution
As described in Sec. 3.4, we calculate the change
in entropy before and after training. We follow the
same training procedure that was used for identi-
ﬁcation. However, instead of using the authors’
probabilities to ﬁnd the most likely author we cal-
culate the entropy for that output distribution.
Finally, we normalize the entropy scores to make
them comparable with other content-preservation
scores that are bounded between zero and 1. To do
that, we divide the entropy scores by the entropy
of the uniform distribution with K authors, where
K is the number of authors in each dataset.
5 Experimental Results
5.1 Evaluating Evasion
As mentioned earlier in Sec. 3.2, the successful
evasion of an obfuscation technique is measured
by the drop in authorship identiﬁcation accuracy
after obfuscation. In Table 3, the ﬁrst row shows
the identiﬁcation accuracy on the original test doc-
uments, i.e., before obfuscation. The rows below it
show the identiﬁcation accuracy after obfuscating
the test documents. Here, the lower the attribution
accuracy after obfuscation the better is an obfusca-
tion algorithm at evading detection.
We make the following observations from Ta-
ble 3. First, despite being a baseline, back transla-
tion outperforms both obfuscation techniques on
the EBG dataset, and comes as a close second on
the C50 dataset after A* of Bevendorff et al.. Con-
trast to the literature, back translation is not a weak
baseline anymore.
The other general observation that we make is
that identifying the original author –even without
obfuscation– becomes much harder as the num-
ber of candidate author increases. Speciﬁcally, as
the number of authors increased from ﬁve authors2397
to ten authors, the authorship attribution accuracy
dropped by around %20 and %10 on the EBG and
the C50 dataset, respectively. We conduct more
analysis on the robustness of the evaluated obfusca-
tion techniques in Sec. 6. Speciﬁcally, we use dif-
ferent identiﬁcation techniques, with various writ-
ing style features, and report the results of this
analysis in Table 6.
5.2 Content Preservation
Table 4 shows the result of content preservation
using various evaluation metrics. Naturally, A* has
the best performance on the token-based metrics
given that most of the modiﬁcations are done at the
character level, i.e., has lower tendency to change
words. Similarly, Mutant-X has the highest model-
best scores because words are replaced based on
their embeddings.
Conversely, back translation has the worst scores
in both token-based an model-based measures. In
contrast, it has the closest score to the original text
using the QA-based approach which, as mentioned
earlier, has better correlation with human scores
than token-based and model-based metrics.
We manually investigated the quality of sen-
tences that were obfuscated using the back transla-
tion technique (See Appendix A.6). In these sen-
tences, one can see that back translation rephrases
the sentence and maintains the original content
despite using different tokens. This is a clear indi-
cation that the QA-based approach is more trust-
worthy to measure the content preservation thanthe commonly used token-based approaches.
5.3 Characterizing Unfair Misattribution
Using Entropy
Table 5 shows the normalized entropy scoresthat
are used to characterize unfair misattribution. The
higher the normalized entropy, the closer the prob-
ability distribution of the predicted authors is to the
uniform distribution. In that case, the model has
no preference for one particular author, or has low
conﬁdence in its outcome. Back translation has the
best performance on this evaluation metric, mea-
sured by the increase in normalized entropy from
that before obfuscation (the ﬁrst row). Our interpre-
tation is that by translating to different languages,
back translation is generating text in a generic style
that is hard to attribute to one particular author.
In contrast, A* tries to imitate a speciﬁc author’s
writing style to avoid detection, while Mutant-X
requires a set of candidate authors and a classiﬁer
to do the obfuscation, and only stops when the
obfuscated text is attributed to a different author.
6 Analysis of Robustness
In this section, we conduct a battery of tests on
different attribution features. The goal of this study2398Identiﬁcation technique
Stylo. N-grams MaskingAverageAnon. tech. - POS Ch. W. Ch. W.
No Anon. 81.2 90.0 91.5 96.4 88.8 96.4 90.7±5.2
A* 51.3 78.0 91.5 94.6 76.4 93.5 80.9±15.1
Back Translation 59.7 67.3 89.7 96.4 83.1 84.0 80.0±12.7
Lexical Sub (BERT) 68.2 80.2 89.7 96.4 95.3 91.5 86.9±9.9
Mutant-X 81.2 84.7 91.5 96.4 95.5 86.4 89.3±5.6No Anon. 58.8 53.9 73.3 75.1 53.1 77.6 65.3±10.3
A* 47.8 37.2 74.2 71.8 51.7 71.1 59.0±14.1
Back Translation 46.2 43.5 66.3 73.2 59.5 64.2 58.8±10.7
Lexical Sub (BERT) 55.0 52.0 71.5 73.7 58.7 78.4 64.9±10.1
Mutant-X 55.0 52.2 74.1 77.0 52.3 73.6 64.0±11.0No Anon. 65.3 68.0 84.0 84.0 61.3 76.0 73.1±8.9
A* 65.3 66.7 81.3 85.3 58.7 72.0 71.6±9.2
Back Translation 64.0 65.3 82.7 81.3 58.7 73.3 70.9±9.0
Lexical Sub (BERT) 65.3 68.0 85.3 88.0 62.7 76.0 74.2±9.7
Mutant-X 60.0 62.7 84.0 84.0 54.7 74.7 70.0±11.6No Anon. 58.7 69.3 69.3 64.0 53.3 67.3 63.6±5.9
A* 56.7 69.3 68.0 61.3 54.7 64.0 62.3±5.4
Back Translation 55.3 64.7 65.3 62.0 52.0 65.3 60.8±5.2
Lexical Sub (BERT) 56.7 70.7 68.7 62.0 54.7 67.3 63.4±6.0
Mutant-X 56.0 67.3 69.3 62.7 52.7 66.7 62.4±6.1
is to characterize the obfuscation performance un-
der different types of writing style features that
vary between stylometric features and content fea-
tures. The results are shown in Table 6. As can be
shown, the performance of obfuscation techniques
varies drastically based on the choice of obfusca-
tion technique. Because of that, it is important to
evaluate a proposed technique against authorship
identiﬁcation techniques with different feature rep-
resentations.
7 Conclusion
In this work, we demonstrated the importance of us-
ing state-of-the-art evaluation tools to measure the
performances of authorship obfuscation techniques.
In addition, our experiments revealed that current
obfuscation techniques have key weaknesses and
have been outperformed by a baseline, namely back
translation in multiple evaluation aspects. Further-
more, we identiﬁed a critical issue with respect to
the fairness of obfuscation techniques. Our pro-
posed misattribution measure investigates the side-
effect of a successful detection evasion by identi-
fying another author as the most plausible authorof the obfuscated text. As a result, we argue that
an attack on the conﬁdence of the identiﬁcation
model, by generating text in a generic style would
confuse the identiﬁcation model and make it unus-
able in real-life applications. Finally, we argue that
evaluation of authorship obfuscation tools should
follow the rapidly evolving domain of evaluation
tools while keep the potential users and real-life
applications when developing and evaluating novel
obfuscation techniques.
Acknowledgments
We would like to thank the reviewers for their valu-
able discussion during the rebuttal period.
The ﬁrst author is supported by the Doctoral
Scholarship from Fonds de Recherche du Quebec
Nature et Technologies (FRQNT-275545). In ad-
dition, this research is supported in part by the
Discovery Grants (RGPIN-2018-03872) and CRE-
ATE Grants (CREATE-554764-2021) from the Nat-
ural Sciences and Engineering Research Council
of Canada, and Canada Research Chairs Program
(950-230623). The fourth author is supported by a
Canada CIFAR AI Chair.23998 Limitations
One potential limitation of this work is that ob-
fuscation can be misused in a similar way that au-
thorship identiﬁcation can be misused. However,
it is important that the public be aware of the ex-
istence of such tools, and for researchers to have
better obfuscation techniques to raise the bar for
identiﬁcation techniques. Another limitation is that
we could have used more datasets in our analysis.
We note that, our results —particularly, where a
baseline outperforms state-of-the-art obfuscation
techniques— would still be interesting regardless
off the number of datasets. In addition, all the
datasets for authorship obfuscations similar charac-
teristics in terms of size.
Another potential limitation of this work is the
lack of human evaluation for content preservation.
While question answering approaches have been
shown to correlate well with human evaluation
scores for factual consistency, it would have been
interesting to analyze the cases when such tech-
niques fail. In particular, what type of errors do
such techniques make? For example, do these tech-
niques produce ungrammatical sentences or gener-
ate grammatical but nonsensical sentences.
References24002401
A Appendices
A.1 Hardware and Runtime
The experiments for this paper where run on a work-
station with one GPU type Quadro RTX 8000, with
four CPUs and 32GB of RAM. Run time (estimated
by wandb.com) is as follows.
1.Obfuscation run-time: ∼10 days, that is∼256
Hrs total.
2. Authorship identiﬁcation run time: ∼0.6 day,
that is∼14.5 Hrs total.
A.2 Hyperparameters
Table 7 shows the ranges of hyperparameters that
were used for Masking (the main identiﬁcation
technique) and the other writing style features that
were used in the ablation study in Table 6.
A.3 Corpus Statistics, with Mean and SD
See Table 8.2402A.4 Misattribution Harm
Table 9 shows the normalized entropy scores (with
SD) while Table 10 shows the identiﬁcation ac-
curacy on the left of the table and unnormalized
entropy scores to characterize the misattribution
behavior. The goal of this table is to show that raw
entropy scores are less intuitive than the normalized
values bound between zero and one.
A.5 Stylometric Features
Table 11 shows details of the static, stylometric
features that were used in the ablation study.2403C50 EBG
Authors 5 10 5 10
Training set
Docs 75 150 55 110
Docs / authors: 15 (0.0) 15 (0.0) 11 (0.0) 11 (0.0)
Avg. doc Len (W) 478 (46.4) 452 (60.8) 496 (6.1) 494 (4.8)
Avg. doc Len (C) 3007 (273.1) 2861 (366.9) 3157 (24.0) 3120 (41.8)
Testing set
Docs 75 150 55 110
Docs / authors: 15 (0.0) 15 (0.0) 7 (4.0) 6 (3.2)
Avg. doc Len (W) 480 (86.2) 479 (77.6) 496 (14.1) 497 (12.5)
Avg. doc Len (C) 3032 (567.2) 3036 (473.9) 3068 (102.7) 3046 (130.8)
Total docs 150 300 90 169
Anon. Tech.EBG C50
5 Authors 10 Authors 5 Authors 10 Authors
None (Original text) 73.9±4.4 83.3±3.8 79.4±6.8 84.3±2.9
A* 78.8±4.9 86.8±4.0 79.0±6.5 84.4±2.1
Back Translation 82.3±4.3 88.8±2.1 83.1±4.8 87.3±3.1
Lexical Sub (BERT) 80.5±4.5 84.6±2.5 80.2±6.6 85.3±2.4
Mutant-X 72.6±4.7 85.2±2.8 82.0±5.4 83.2±2.6
Identiﬁcation accuracy (%) Entropy
Anon. T.EBG C50 EBG C50
5 Au. 10 Au. 5 Au. 10 Au. 5 Au. 10 Au. 5 Au. 10 Au.
None 96.4 77.6 76.0 67.3 1.72±0.1 2.77±0.1 1.84±0.2 2.80±0.1
A* 93.5 71.1 72.0 64.0 1.83±0.1 2.88±0.1 1.83±0.1 2.81±0.1
Back T. 84.0 64.2 73.3 65.3 1.91±0.1 2.95±0.1 1.93±0.1 2.90±0.1
LS BERT 91.5 78.4 76.0 67.3 1.87±0.1 2.81±0.1 1.86±0.2 2.84±0.1
Mutant-X 86.4 73.6 74.7 66.7 1.69±0.1 2.83±0.1 1.90±0.1 2.76±0.1
Lexical Features - Character-Level
1. Characters count (N)
2. Ratio of digits to N
3. Ratio of letters to N
4. Ratio of uppercase letters to N
5. Ratio of tabs to N
6. Frequency of each alphabet (A-Z), ignoring
case (26 features)
7. Frequency of special characters: <>%|{}
[]/\@#˜ +-*=$ˆ &_()’ (24 features).Lexical Features - Word-Level
1. Tokens count (T)
2. Average sentence length (in characters)
3. Average word length (in characters)
4. Ratio of alphabets to N
5. Ratio of short words to T (a short word has a
length of 3 characters or less)
6. Ratio of words length to T. Example: 20% of the
words are 7 characters long. (20 features)
7. Ratio of word types (the vocabulary set) to T
Syntactic Features
1. Frequency of Punctuation: , . ? ! : ; ’ " (8 features)
2. Frequency of each function words (O’Shea, 2013) (277 features)2404A.6 Qualitative Analysis
In this section, we provide examples for each obfuscation system, and comment on what each one does.
Note that the examples were cherry-picked in order to highlight the different issues in each approach.
Tables 12 to 15 provide examples for A*, Mutant-X, back translation, and lexical substitution with
BERT, respectively. A more detailed study on categorizing the types of errors made by an obfuscation
technique can be found in (Gröndahl and Asokan, 2020).
OriginalThedecline of the Kongo due to a series of wars with the Portuguese in the seventeenth
century ,
ModiﬁedThedecrease of the Kongo due to ab polynomial of wars with the Portuguese in the
seventeenth week ,
OriginalThe continued fragmentation of its nationalist movements set Angola apart from other
Portuguese colonies.
ModiﬁedThe continued fragmentation of its nationalist movements set Angola apart from other
Portuguese colonies!
OriginalThe oppressive tropical climate and hostile African neighbors made life difﬁcult
for settlers , many of whom lacked agricultural experience or expertise .
ModiﬁedTheopperss tropical control andtroops African neighbors made life difﬁcult fsettlers ,
many of whom lacked agricutlural bonanza ro xepertise .
Changes Word replacement, punctuation replacement, ﬂipping characters and introducing typos.
ObservationIn some cases, the replaced words ﬁt the context to some extent. In other cases, the
new words were completely out of context. This is mainly because word replacement
did not consider the whole sentence but rather the word to be replaced.
Original Protect personal information with the MyID identity theft monitoring solution.
Modiﬁed Protect personal info with the MyID identity theft monitoring solution.
OriginalThepossibility that Internet users will be able to hide what they do from the ubiquitous
ad tracking is a big win for consumers concerned with Internet privacy.
ModiﬁedTheprospect that Internet users will be able to hide what they do from the ubiquitous
ad tracking is a big victorious for consumers concerned with Internet privacy.
Original The other example was that of a woman who had fallen and broken her arm.
Modiﬁed The other example was that of a schoolgirl who had fallen and broken her arm.
Changes Controlled word replacement that is based on the sentiment of the word to be replaced.
ObservationSimilar to other techniques that use word replacement, sometimes the replaced word
either have the wrong part of speech, or changes the meaning. It does better than naive
word replacement techniques because of the added rules on candidate words.2405OriginalSome of the relevant items with regard to maintaining and strengthening health sys-
tems include :Neither side purposely disrupted health systems during the conﬂict.
ModiﬁedSome of the relevant points regarding the preservation and strengthening ofhealth
systems are : no side that targeted health systems during the conﬂict.
Original Zimbabwe lost over two thirds of their physicians in the 1990s.
Modiﬁed Zimbabwe lost more than two-thirds of its doctors in the 1990s.
Original The initial reasons for United States intervention in Angola were primarily economic.
Modiﬁed The initial reasons for the U.S. intervention in Angola were mainly economic.
OriginalTwo important US ofﬁcials in Luanda, Robert W. Hultslander, the CIA station chief ,
and Tom Killoran, the American Consul General , agreed that ...
ModiﬁedTwo main U.S. ofﬁcials in Luanda, Robert W. Hultslander, the CIA head of stat e, and
Tom Killoran, the U.S. consulate , accepted that ...
Original Over half of Cuba’s doctors left during the revolution.
Modiﬁed More than half of the Cuban doctors were abandoned during the revolution.
OriginalSince 1961, the US had been supporting Holden Roberto with a modest stipend of
$10,000 a year.
ModiﬁedSince 1961, the United States has supported Holden Roberto with a modest
stock exchange of $10,000 per year.
ChangesWord replacement, rephrasing sentences, contracting/expanding acronyms, and adding
spaces.
ObservationBack translation is a powerful text generation tool. Rephrasing a sentence implicitly
replaces some words with synonyms that ﬁt the context, and in some cases changes
the grammatical structure of the sentence as well. In addition, expanding an acronym,
e.g., replacing US with United States, or vise versa or adding proper spacing might
hide some writing habits of the author.
OriginalDu Mortier and Coninx describe their use of MHUs with the International Committee
of the Red Cross during the conﬂict in Columbia in 2005.
ModiﬁedDu Mortier and Coninx describe hisuse of MHUs with the International Committee
of the white Cross during the conﬂict in maryland in 2005.
OriginalThey are generally expensive, however, and the fact that they only provide services
intermittently tends to affect when they are appropriate for use.
ModiﬁedThey are notexpensive, however, so the fact that they canprovide services intermit-
tently tends toward affect when they are appropriate for use.
Original Sloppy dressers generally look as if they slept in the clothes they are wearing.
Modiﬁed Sloppy dressers generally look as if they slept on the clothes they are wearing.
Changes Word replacement.
ObservationAs shown in the examples, word replacement, even when the context is considered,
sometimes lead to choosing the wrong word. Here, the chosen word ﬁts the context,
i.e. sensible, but changes the meaning compared to the original sentence.2406