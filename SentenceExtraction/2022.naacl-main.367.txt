
Yuan Liang, Zhuoxuan Jiang, Di Yin and Bo Ren
Tencent Cloud, China
{ericyliang, alexzxjiang, endymecyyin, timren}@tencent.com
Abstract
In document-level event extraction (DEE) task,
event arguments always scatter across sen-
tences (across-sentence issue) and multiple
events may lie in one document (multi-event
issue). In this paper, we argue that the rela-
tion information of event arguments is of great
significance for addressing the above two is-
sues, and propose a new DEE framework which
can model the relation dependencies, called
Relation-augmented Document-level Event Ex-
traction (ReDEE). More specifically, this frame-
work features a novel and tailored transformer,
named as Relation-augmented Attention Trans-
former (RAAT). RAAT is scalable to cap-
ture multi-scale and multi-amount argument
relations. To further leverage relation in-
formation, we introduce a separate event re-
lation prediction task and adopt multi-task
learning method to explicitly enhance event
extraction performance. Extensive experi-
ments demonstrate the effectiveness of the
proposed method, which can achieve state-of-
the-art performance on two public datasets.
Our code is available at https://github.
com/TencentYoutuResearch/RAAT .
1 Introduction
Event extraction (EE) task aims to detect the event
from texts and then extracts corresponding argu-
ments as different roles, so as to provide a structural
information for massive downstream applications,
such as recommendation (Gao et al., 2016; Liu
et al., 2017), knowledge graph construction (Wu
et al., 2019; Bosselut et al., 2021) and intelligent
question answering (Boyd-Graber and Börschinger,
2020; Cao et al., 2020).
Most of the previous methods focus on sentence-
level event extraction (SEE) (Ahn, 2006; Liao and
Grishman, 2010; Li et al., 2013; Chen et al., 2015;
Nguyen et al., 2016; Zhao et al., 2018; Sha et al.,
2018; Yan et al., 2019; Du and Cardie, 2020; Liet al., 2020; Paolini et al., 2021; Lu et al., 2021),
extracting events from a single sentence. However,
SEE is mostly inconsistent with actual situations.
For example, event arguments may scatter across
different sentences. As illustrated in Figure 1, the
event argument [ORG1] of event role Pledger is
mentioned in Sentence 4 and the corresponding
argument [ORG2] of event role Pledgee is in Sen-
tence 5 and 6. We call this across-sentence issue .
Another situation involves the multi-event issue ,
which means that multiple events may exist in the
same document. As seen in the example in Fig-
ure 1, where two event records coincide, we should
recognize that they may partially share common
arguments.
Recently, document-level event extraction (DEE)
attracts great attention from both academic and in-
dustrial communities, and is regarded as a promis-
ing direction to tackle the above issues (Yang et al.,
2018; Zheng et al., 2019; Xu et al., 2021b; Yang
et al., 2021; Zhu et al., 2021). However, by our
observation, we discover that the relations between
event arguments have patterns which are an impor-
tant indicator to guide the event extraction. This
information is neglected by existing DEE meth-
ods. Intuitively, the relation information could
build long-range relationship knowledge of event
roles among multiple sentences, which could re-
lieve the across-sentence issue. For multi-event is-
sue, shared arguments within one document could
be distinguished to different roles based on the dif-
ferent prior relation knowledge. As illustrated in
Figure 1, [ORG1] and [ORG2] have a prior relation
pattern of Pledger andPledgee , as well as [ORG1]
and [SHARE1] for the relation pattern between
Pledger and its Pledged Shares . Therefore, the re-
lation information could increase the DEE accuracy
if it is well modeled.
In this paper, we propose a novel DEE frame-
work, called Relation-augmented Document-level
Event Extraction (ReDEE), which is able to model4985
the relation information between arguments by de-
signing a tailored transformer structure. This struc-
ture can cover multi-scale and multi-amount rela-
tions and is general for different relation model-
ing situations. We name the structure as Relation-
augmented Attention Transformer (RAAT). To
fully leverage the relation information, we intro-
duce a relation prediction task into the ReDEE
framework and adopt multi-task learning method
to optimize the event extraction task. We conduct
extensive experiments on two public datasets. The
results demonstrate the effectiveness of modeling
the relation information, as well as our proposed
framework and method.
In summary, our contributions are as follows:
•We propose a Relation-augmented Document-
level Event Extraction (ReDEE) framework.
It is the first time that relation information
is implemented in the document-level event
extraction field.
•We design a novel Relation-augmented At-
tention Transformer (RAAT). This network is
general to cover multi-scale and multi-amount
relations in DEE.
•We conduct extensive experiments and the
results demonstrate that our method outper-form the baselines and achieve state-of-the-art
performance by 1.6% and 2.8% F1 absolute
increasing on two datasets respectively.
2 Related Work
2.1 Sentence-level Event Extraction
Previously, most of the related works focus on
sentence-level event extraction. For example, a
neural pipeline model is proposed to identify trig-
gers first and then extracts roles and arguments
(Chen et al., 2015). Then a joint model is created
to extract triggers and arguments simultaneously
via multi-task learning (Nguyen et al., 2016; Sha
et al., 2018). To utilize more knowledge, some stud-
ies propose to leverage document contexts (Chen
et al., 2018; Zhao et al., 2018), pre-trained language
models (Yang et al., 2019), and explicit external
knowledge (Liu et al., 2019a; Tong et al., 2020).
However, these sentence-level models fail to ex-
tract multiple qualified events spanning across sen-
tences, while document-level event extraction is a
more common need in real-world scenarios.
2.2 Document-level Event Extraction
Recently, DEE has attracted a great attention from
both academic and industrial communities. At first,
the event is identified from a central sentence and4986other arguments are extracted from neighboring
sentences separately (Yang et al., 2018). Later, an
innovative end-to-end model Doc2EDAG, is pro-
posed (Zheng et al., 2019), which can generate
event records via an entity-based directed acyclic
graph to fulfill the document-level event extraction
effectively. Based on Doc2EDAG, there are some
variants appearing. For instance, GIT (Xu et al.,
2021b) designs a heterogeneous graph interaction
network to capture global interaction information
among different sentences and entity mentions. It
also introduces a specific Tracker module to mem-
orize the already extracted event arguments for
assisting record generation during next iterations.
DE-PPN (Yang et al., 2021) is a multi-granularity
model that can generate event records via limit-
ing the number of record queries. Not long ago, a
pruned complete graph-based non-autoregressive
model PTPCG was proposed to speedup the record
decoding and get competitive overall evaluation re-
sults (Zhu et al., 2021). In summary, although those
existing works target for solving across-sentence
and multi-event issues of the DEE task from vari-
ous perspectives, to our best knowledge, we con-
duct a pioneer investigation on relation modeling
towards this research field in this paper.
2.3 Trigger-aware Event Extraction
Previously a lot of works((Ji and Grishman, 2008;
Liao and Grishman, 2010; Li et al., 2013; Chen
et al., 2015; Nguyen et al., 2016; Liu et al., 2018))
deal with event extraction in two stages: firstly, trig-
ger words are detected, which are usually nouns or
verbs that clearly express event occurrences. And
secondly, event arguments, the main attributes of
events, are extracted by modeling relationships be-
tween triggers and themselves. In our work, we
unify task as a whole to avoid error propagation
between sub-tasks.
3 Preliminaries
Firstly, we clarify several key concepts in event
extraction tasks. 1) entity : a real world object, such
as person, organization, location, etc.2) entity men-
tion: a text span in document referring to an entity
object. 3) event role : an attribute corresponding a
pre-defined field in an event. 4) event argument :
an entity playing a specific event role. 5) event
record : a record expressing an event itself, includ-
ing a series of event arguments.
In document-level event extraction task, one doc-ument can contain multiple event records, and an
event record may miss a small set of event argu-
ments. Further more, a entity can have multiple
event mentions.
4 Methodology
In this section, we introduce the proposed architec-
ture first and then the key components in detail.
4.1 Architecture Overview
End-to-end training methods for DEE usually in-
volve a pipeline paradigm, including three sub-
tasks: named entity recognition, event role predic-
tion and event argument extraction. In this paper,
we propose the Relation-augmented Document-
level Event Extraction (ReDEE) framework coordi-
nated with the paradigm. Our framework features
leverage the relation dependency information in
both encoding and decoding stages. Moreover, a
relation prediction task is added into the framework
to fully utilize the relation knowledge and enhance
the event extraction task.
More specifically, shown in Figure 2, there are
four key components in our ReDEE framework:
Entity Extraction and Representation(EER), Doc-
ument Relation Extraction(DRE), Entity and Sen-
tence Encoding(ESE), and Event Record Genera-
tion(ERG). In the following, we would introduce
the detailed definition of each component.
4.2 Entity Extraction and Representation
We treat the component of entity extraction as
a sequence labeling task. Given a document D
with multiple sentences {s, s, ..., s}, we use a
native transformer encoder to represent the token
sequence. Specifically, we use the BERT (Devlin
et al., 2019) encoder pre-trained in Roberta setting
(Liu et al., 2019). Then we use the Conditional Ran-
dom Field(CRF) (Lafferty et al., 2001) to classify
token representations into labels of named entities.
We adopt the classical BIOSE sequence labeling
scheme. The labels are predicted by the follow-
ing calculation: ˆy=CRF (Trans (D)). Then
all the intermediate embeddings of extracted entity
mentions and sentences are concatenate into a ma-
trixM∈Rby max-pooling operation
on each sentence and entity mention span, where
jandiare the numbers of entity mentions and
sentences, and dis the dimension of embeddings.
The loss function for named entity recognition is4987
denoted:
where sdenotes the isequence sentence in doc-
ument, and yis the corresponding ground truth
label sequence.
4.3 Document Relation Extraction
The DRE component takes the document text
(D) and entities ( {e, e, ..., e}) extracted in
the previous step as inputs, and outputs the
relation pairs among entities, in a form of
triples ( {[e, e, r],[e, e, r], ...,[e, e, r]}).
[e, e, r] means the head entity, the tail entity
and the relationship of the ktriple respectively.
An important aspect is how to define and collect
the relations from data. Here we assume that every
two arguments in an event record can be connected
by a relation. For example, Pledger andPledgee
in the EquityPledge event could have a relation
named as Pledge2Pledgee , and the order of head
and tail entities is determined by the pre-order of
event arguments (Zheng et al., 2019). In this way,
every event record with narguments could cre-
ateCrelation samples. Note that this method to
build relations is general to event extraction tasks
from various domains, and the supervised relation
information just comes from event record data it-
self, without any extra human labeling work. We
do statistics for the relation types for ChiFinAnn
dataset. Table 1 shows a snippet of statistics and
the full edition can be found in Appendix A.3.
To predict the argument relations in this step,
we adopt the structured self attention network (Xu
et al., 2021a) which is the latest method for
document-level relation extraction. However, dif-
ferent from previous work using multi-class binary
cross-entropy loss, we use normal cross-entropy
loss to predict only one label for each entity pair.
The relation type is inferred by this function:
where e, e∈Rdenote entity embedding from
encoder module of DRE and dis the dimension of
embeddings. W∈Rdenotes biaffine ma-
trix trained by DRE task and cis the total number
of relations. And the loss function for optimize the
relation prediction task is denoted:
where ydenotes ground truth label between the
iandjentity, Dfor document text and Yfor
set of all relation pairs among entities.4988
4.4 Entity and Sentence Encoding
Now we have embeddings of entity mentions and
sentences from EER component and a list of pre-
dicted triple relations from DRE component. Then
this component encodes data mentioned above and
output embeddings effectively integrated with re-
lation information. In this subsection, we would
introduce the method that translates triple relations
to calculable matrices and the novel RAAT struc-
ture for encoding all the above data.
4.4.1 Entity and Sentence Dependency
First, we introduce a mechanism: entity and sen-
tence dependency, which not only includes relation
triples, but also describes links among sentences
and entities beyond triples.
Co-relation andCo-reference are defined to rep-
resent entity-entity dependency. For the former
one, two entities have a Co-relation dependency
between them if they belong to a predicted relation
triple. Entity pairs are considered having differ-
entCo-relation if their involved triples have dif-
ferent relations. Co-reference shows dependency
between entity mentions pointing to same entities.
That is, if an entity has several mentions existing
across document, then each two of them has Co-
reference dependency. However, in the case that
head and tail entities in relation triple are the same
(i.e. StartDate andEndDate share same entities
in some event records), then Co-relation andCo-
reference are both held between them.
We use Co-existence to describe dependency be-
tween entities and sentences where entity mentions
come from. To be more specific, the entity men-
tion together with its belonged sentence has Co-
existence . For remaining entity-entity and entity-
sentence pairs without any dependency mentioned
above, we uniformly treat them as NAdependency.
Table 2 shows the complete dependency mecha-
nism. Co-relation differs from NA,Co-reference ,
andCo-existence in that it has several sub-types,
with number equaling to that of relation types de-
fined in document relation extraction task.
4.4.2 RAAT
In order to effectively encode entity and sentence
dependencies, we design the RAAT which takes ad-
vantage of a calculable matrix representing depen-
dencies and integrates it into attention computation.
According to the architecture shown in Figure 3,
RAAT is inherited from native transformer but has
a distinct attention computation module which is
made up of two parts: self-attention and relation-
augmented attention computation.
Given a document shown as D={s, s, ...s},
all entity mentions in this document as E=
{e, e, ..., e}, where edenotes entity men-
tions with the superscript mdenotes mention, and
the subscript idenotes index, and a list of triples
{[e, e, r],[e, e, r], ...,[e, e, r]}, we build
a matrix T∈Rwhere cfor the num-
ber of dependencies, and tandjfor the num-
ber of sentences and entity mentions respectively.
Tis comprised of c matrices with same dimen-
sions R∈R, and each Rrepresents one
type of dependency r∈ {Co−relation, Co−
reference, Co −existence, NA }, k= 1,2, ...N ,
Nas the number of relation types. For element
within T,trepresent the dependency between
nodeandnode. Specifically, t= 1 if they
have the kdependency, otherwise, t= 0.
Here, node∈ {e, e, ..., e, s, s, ...s}can4989be either entity mention or sentence.
However, Twould be giant and sparse if we
use the above strategy. To squeeze Tand de-
crease training parameters, we cluster Co-relation
dependency based on the type of head entity in
relation triple. For example, Pledger2Pledgee
andPledger2PledgedShares are clustered as one
Co-relation dependency, and two matrice R
andRcorresponding to them are merged into
one matrix. As a result, we finally get T∈
Rwhere H denotes the num-
ber of head entity type in Co-relation , and 3
covers NA,Co-reference , and Co-existence . Let
X∈Ras input embeddings of atten-
tion module, W, W, W, W, W∈R,
M∈Ras weight matrices, we com-
pute relation-augmented attention in the following
steps:
where Sdenotes score matrix of relation-
augmented attention, ·denotes element-wise mul-
tiplication. We compute self attention score and
combine it with Sin the following way:
where Ois the output of attention module. Similar
to the structure of native transformer, RAAT has
multiple identical blocks stacking up layer by layer.
Furthermore, Tis extensive since the number of
Co-relation can be selected. RAAT can be adaptive
to the change of input length, which is equivalent to
the total number of sentences and entity mentions.
4.5 Event Record Generation
With the outputs from previous component, the em-
beddings of entities and sentences, this ERG com-
ponent actually includes two sub-modules: event
type classifier and event record decoder.
4.5.1 Event Type Classifier
Given the embeddings of sentences, we adopt sev-
eral binary classifiers on every event type to predict
whether the corresponding event is identified ornot. If there is any classifier identifying an event
type, the following event record decoder would be
activated to iteratively generate every argument for
the corresponding event type. The loss function to
optimize this classifier is as the following:
where ydenotes the label of the ievent type,
y= 1if there exists event record with event type
i, otherwise, y= 0.Sdenotes input embeddings
of sentences.
4.5.2 Event Record Decoder
To iteratively generate every argument for a spe-
cific event type, we refer to the entity-based di-
rected acyclic graph (EDAG) method (Zheng et al.,
2019). EDAG is a sequence of iterations with the
length equaling to number of roles for certain event
type. The objective of each iteration is to predict
event argument of certain event role. Inputs of each
iteration are come up with entities and sentences
embeddings. And the predicted arguments of out-
puts will be a part of inputs for next iteration. How-
ever, different from EDAG, we substitute its vanilla
transformer part with our proposed RAAT structure
(i.e. RAAT-2 as shown in Figure 2). More specif-
ically, the EDAG method uses a memory struc-
ture to record extracted arguments and adds role
type representation to predict current-iteration ar-
guments. However, this procedure hardly captures
dependency between entities both in memory and
argument candidates and sentences. In our method,
RAAT structure can connect entities in memory and
candidate arguments via relation triples extracted
by the DRE component, and it can construct a struc-
ture to represent dependencies. In detail, before
predicting event argument for current iteration, Ma-
trixTis constructed in the way shown above so
that dependency is integrated into attention compu-
tation. After extracting the argument, it is added
into memory, meanwhile, a new Tis generated to
adapt next iteration prediction.
Therefore, the RAAT can strengthen the relation
signal for attention computation. The RAAT-2 has
the same structure with RAAT-1 but independent
parameters. The formal definition of loss function
for event recorder decoder is:
where Vdenotes node set in event records graph,
vdenotes extracted event arguments of event record4990by far, sdenotes embedding of sentences and event
argument candidates, and ydenotes label of argu-
ment candidate ein current step. y= 1means eis
the ground truth argument corresponding to current
step event role, otherwise, y= 0.
4.6 Model Training
To train the above four components, we leverage
the multi-task learning method (Collobert and We-
ston, 2008) and integrate the four corresponding
loss functions together as the following:
where the λpre-set to balance the weight among
the four components.
5 Experiments
In this section, we report the experimental results
to prove the effectiveness of our proposed method.
In summary, the experiments could answer the fol-
lowing three questions:
•To what degree does the ReDEE model out-
perform the baseline DEE methods?
•How well does ReDEE overcome across-
sentence and multi-event issues?
•In what level does the each key component of
ReDEE contribute to the final performance?
5.1 Datasets
DEE is a relatively new task and there are only
a few datasets published. In our experiments we
adopt two public Chinese datasets, i.e. ChiFinAnn
(Zheng et al., 2019) and DuEE-fin (Li, 2021).
ChiFinAnn includes 32,040 documents with 5
types of events, involving in equity-related ac-
tivities for the financial domain. Statistics show
that about 30% of the documents contain multiple
event records. We randomly split the dataset into
train/dev/test sets in the ratio of 8/1/1. Readers can
refer to the original paper for details.
DuEE-fin is also from the financial domain with
around 11,900 documents in total. The dataset is
downloaded from an online competition website.
Since there is no ground truth publicly available
for the test set, we can only submit our extracted
results to the website as a black-box online eval-
uation. Compared to ChiFinAnn, there are twodifferences. The DuEE-fin dataset has 13 different
event types and its test set includes a large size
of document samples that do not have any event
records, which both make it more complicated. We
get the distribution information of the dataset from
Appendix A.1.
5.2 Baselines and Metrics
Five different baseline models are taken into con-
sideration: 1) DCFEE (Yang et al., 2018), the first
model proposed to solve DEE task. 2) Doc2EDAG
(Zheng et al., 2019), proposed an end-to-end model
which transforms DEE as directly filling event ta-
bles with entity-based path expending. 3) DE-PPN
(Yang et al., 2021), a pipeline model firstly intro-
ducing the non-autoregressive mechanism. 4) GIT
(Xu et al., 2021b), a model using heterogeneous
graph interaction network as encoder and maintain-
ing a global tracker during the decoding process.
5)PTPCG (Zhu et al., 2021), a light-weighted and
latest DEE model.
For evaluation metrics, we use precision, recall,
and F1 score at the entity argument level for fair
comparison with baselines. The overall "Avg" in
the result tables denotes the micro average value
of precision, recall, and F1 score. We conduct
several offline evaluations for ChiFinAnn, but only
an online test for DuEE-fin.
5.3 Settings
In our implementation, for text processing, we con-
sistently set the maximum sentence number and
the maximum sentence length as 128 and 64 sep-
arately. We use BERT encoder in the EER com-
ponent for fine-tuning and Roberta-chinese-wwm
(Yiming et al., 2020) as the pre-trained model. Both
RAAT-1 and RAAT-2 have four layers of identical
blocks. More training details can be found in Ap-
pendix A.5.
5.4 Results and Analysis
Overall Performance Table 3 shows the compar-
ison between baselines and our ReDEE model on
the ChiFinAnn dataset. The ReDEE can achieve
the state-of-the-art performance in terms of micro
average recall and F1 scores on almost every type
of events (i.e. EF, ER, EU, EO, EP), consistent with
the Avg. results increased by 1.5% and 1.6% re-
spectively. Our model also performs competitively
well on precision results.
Table 4 shows the comparison results of our
model with baselines on the developing set of4991
DuEE-fin and its online testing. Seeing from for-
mer results, our model outperforms in a great leap
by increasing 6.7% on F1 score. For the online
testing evaluation, our model has a distinct growth
of 2.8% on F1 score than the baselines. This ex-
periment demonstrates our model could achieve a
superior performance than existing methods.
Argument Scattering The across-sentence issue
widely exists in datasets. By our statistics, the train-
ing sets of ChiFinAnn and DuEE-fin have about
98.0% and 98.9% records that scatter across sen-
tences respectively. To evaluate the performance of
our model in different argument scattering degree,
we compute the average number of sentences in-
volved in records for each document and sort them
in the increasing average number order. Then, all
documents for testing are evenly divided into four
sets, namely, I, II, III and IV , which means the I
set is a cluster of documents that have the smallestaverage number of involved sentences while the
IV set has the largest ones. According to table 5,
our model outperforms other baseline models in
all settings, and meets the largest growth of 2.2%
F1 score in IV , the most challenging set of all. It
indicates that our model is capable of capturing
longer dependency of records across sentences via
relation dependency modeling, thus alleviating the
argument scattering challenge.
Single v.s. Multi Events To illustrate how well
our model performs in the multi-event aspect, we
split the test set of ChiFinAnn into two parts: one
for documents with single event record, and the
other for documents including multiple events. Ta-
ble 6 shows the comparison results of all baselines
and ReDEE. We find ReDEE performs much better
in the multi-event scenario and outperforms base-
line models dramatically in all five event types, im-
proving ranging from 1.9% to 3.2% F1 scores. The
results suggest that our relation modeling method
is more effective to overcome the multi-event issue
than existing baseline models.
5.5 Ablation Study
To probe the impact of RAAT structure for different
components in ReDEE, we conduct ablation studies
on whether to use RAAT or vanilla transformer.
In this experiment, we implement tests on three
variants: 1) -RAAT-1 substitutes the RAAT in the
ESE component with vanilla transformer. 2) -
RAAT-2 substitutes the RAAT in the event record
generation module with vanilla transformer. 3) -
RAAT-1&2 substitutes the RAATs in both the above
places with vanilla transformers, so that our model
degrades to only import a relation extraction task
via multi-task learning.
The results in Table 7 indicate that both two
RAATs have positive influence on our model. Es-
pecially on ChiFinAnn, RAAT-2 makes more con-4992
tribution than RAAT-1, with a decrease of 0.7%
versus 0.4% in F1 scores once been substituted.
After replacing both two RAATs, the value of re-
lation extraction task becomes more weak and the
model encounters a 1.5% drop in F1 score. When
it comes to DuEE-fin, a similar phenomenon can
be observed that both the RAATs can contribute
positively to our model.
6 Conclusion
In this paper, we investigate a challenging task of
event extraction at document level, towards the
across-sentence and multi-event issues. We pro-
pose to model the relation information between
event arguments and design a novel framework
ReDEE. This framework features a new RAAT
structure which can incorporate the relation knowl-
edge. The extensive experimental results can
demonstrate the effectiveness of our proposed
method which makes the state-of-the-art perfor-
mance on two benchmark datasets. In the future,
we will make more efforts to accelerate training
and inference process.
Acknowledgements
We thank the anonymous reviewers for their careful
reading of our paper and their many insightful com-
ments and suggestions. This work was supported
by Tencent Cloud and Tencent Youtu Lab.References49934994
A Appendix
In the appendix, we incorporate the following de-
tails that are omitted in the main body due to the
space limit.
A.1 Distribution of Event Type DuEE-fin
Table 8 shows the complete event type and corre-
sponding distribution of DuEE-fin dataset. Overall,
there are 13 event types in total with uneven distri-
bution. Only train and development sets are shown
since test set is not publicly available.
A.2 Complete Relation Triples
Table 9 demonstrates the complete of relation
triples of the document event extraction example
shown in Figure 1.
Entities in blue are involved in both two event
records, while those in green and orange are exclu-
sive to record 1 and 2 respectively. Heavy coupling
of arguments among events increases the difficulty
of multi-event issue.
A.3 Relation Statistics for ChiFinAnn
Table 10 shows the relation statistics of ChiFinAnn
dataset. There are 85 relation types in total, and
train, development, and test sets have similar pat-
tern in distribution.
A.4 Case Study
Figure 4 shows the prediction results of our model
and the best baseline model GIT on the example
in Figure 1. Compared with the ground truth, our
model correctly predicts all event arguments except
one, while GIT only captures one event, with an
argument missed. This example explicitly shows
the superiority of our model in dealing with multi-
events issue.
A.5 More Training Settings
For all native transformers and RAATs, the dimen-
sions of hidden layers and feed-forward layers are
set to 768 and 1,024 respectively. During train-
ing, we set the learning rate lr= 5e, batch
sizeb= 64 . The four loss weights are set to
λ=λ= 0.05, λ2 = 1 .0, λ= 0.95. We use 8
V100 GPUs and set gradient accumulation steps
to 8. The train epoch are set to 100, and the best
epoch are selected by the best validation score on
development set for the evaluation of test set. And
we use Adam to optimize the whole learning task.499549964997