
Ekin Akyürek Jacob Andreas
Massachusetts Institute of Technology
{akyurek,jda}@mit.edu
Abstract
In tasks like semantic parsing, instruction fol-
lowing, and question answering, standard deep
networks fail to generalize compositionally
from small datasets. Many existing approaches
overcome this limitation with model archi-
tectures that enforce a compositional process
of sentence interpretation. In this paper, we
present a domain-general and model-agnostic
formulation of compositionality as a constraint
onsymmetries of data distributions rather than
models. Informally, we prove that whenever a
task can be solved by a compositional model,
there is a corresponding data augmentation
scheme—a procedure for transforming exam-
ples into other well-formed examples—that
imparts compositional inductive bias on any
model trained to solve the same task. We de-
scribe a procedure called LSthat discov-
ers these transformations automatically, then
applies them to training data for ordinary neu-
ral sequence models. Unlike existing composi-
tional data augmentation procedures, LS
can be deployed agnostically across text, struc-
tured data, and even images. It matches or sur-
passes state-of-the-art, task-specific models on
C semantic parsing, S and
instruction following, and C -CGT
visual question answering datasets.
1 Introduction
A central challenge in natural language processing
is the design of models and learning algorithms
that are simultaneously flexible enough to capture
the variability of human language and structured
enough to generalize in predictable and human-
like ways. One important source of structure is
theprinciple of compositionality , which (in one
formulation) states that sentence meanings can be
computed from a lexicon of word meanings and a
set of composition rules governing how meanings
combine (Montague, 1970b). A long line of lan-
guage processing research has operationalized the
principle of compositionality as a constraint onmodel architectures , via independence assump-
tions or parameter tying schemes that ensure a com-
positional process of sentence interpretation (Lewis
and Stearns, 1968; Andreas et al., 2016). Composi-
tional models enjoy sample-efficient learning and
strong generalization in tasks from machine trans-
lation to question answering (McCoy et al., 2020).
But much of human language is not (or at least
not straightforwardly) compositional. Idioms, dis-
fluencies, and context-sensitive meanings present
major challenges to models in which all predic-
tions must derive from a sequence of local com-
position operations. In recent years, more generic
model architectures such as recurrent neural net-
works (RNNs) and transformers, with no explicit
compositional scaffolding, have consistently out-
performed compositional models in language pro-
cessing tasks with natural data (Wu et al., 2016).
However, these models capture linguistic regular-
ities only when trained on enormous amounts of
data, and make surprising or problematic predic-
tions when presented with novel word collocations
or syntactic structures (Lake and Baroni, 2018).
How can we train unstructured neural sequence
models that generalize compositionally? Recent
work has introduced several compositional data
augmentation schemes: rule-based procedures or
learned models that synthesize artificial training ex-
amples to promote generalization (Andreas, 2020;
Shaw et al., 2021; Akyürek et al., 2021; Zhang
et al., 2022, inter alia ). While often effective, exist-
ing methods are specialized to specific data modal-
ities or datasets. The conditions under which they
succeed, and their relationships to the formal prin-
ciple of compositionality, have remained unclear.
This paper presents a framework for understand-
ing and improving such data-centric approaches
to compositional modeling. We first provide a
mathematical characterization of the principle of
compositionality as a constraint on data distribu-
tions rather than model architectures. Intuitively,639
we show that whenever a language understanding
task can be solved compositionally, that task’s data
distribution is guaranteed to exhibit specific symme-
tries. These symmetries are functions that modify
data points while preserving semantic acceptabil-
ity. Fig. 1c gives an example of a symmetry in a
visual question answering problem: in any well-
formed (image, question, answer) triple, swapping
the words yellow andgreen and their associated
pixel values yields a valid new triple. Such sym-
metries exist even in complex tasks like instruction
following (Fig. 1a), where they may depend not
only on word-to-meaning mappings but relations
between meanings (like the fact that red and green
mix to produce brown).
Building on this formal link between compo-
sitionality and symmetry, we introduce a proce-
dure called LSthat discovers symmetries
automatically, then uses them to synthesize new
training examples guaranteed to be correct and in-
formative. Crucially, LSdoes not require a
complete compositional theory for a given problem
domain—only a lexicon of word meanings. These
lexicons may themselves be automatically derived
for most tasks. This makes LSvery flexible:
it requires little or no task-specific engineering, can
be combined with any predictor, and unlike other
compositional data augmentation schemes does not
require tree-structured or even sequential data.
Applied to ordinary neural sequence models,
LSoutperforms state-of-the-art models on
theC CGTvisual question answering
benchmark (Johnson et al., 2017) by a wide margin.
LSis general, and matches or outperforms
some specialized data augmentation schemes and
models on the C semantic parsing task (Kimand Linzen, 2020; Kim et al., 2022), and the S
and instruction following tasks (Lake
and Baroni, 2018; Long et al., 2016).
This paper thus offers two contributions: a the-
oretical contribution, in the form of a new lens on
the principle of compositionality via symmetries
of data distributions; and an empirical contribution,
in the form of a data augmentation scheme that
improves generalization on diverse language under-
standing tasks. The recent success of data augmen-
tation approaches highlight the fact that composi-
tional inductive bias need not require compositional
models. Our work formalizes and generalizes this
“data-centric” account of compositionality.
2 Background & Approach
We begin with a discussion on the more general
role of symmetry in machine learning applications.
Definition 1. Asymmetry of a set Xis a function
fsatisfying:
{f(x) :x∈X}=X (1)
That is, applying fto each element of Xleaves X
unchanged.
A familiar example from computer vision is re-
flection symmetry : in object recognition problems,
image classes are generally invariant under reflec-
tion (a zebra seen in a mirror is still a zebra). The
set of (image, class) pairs thus has as a symmetry
the function (x, y)∝⇕⊣√∫⊔≀→(reflect (x), y). In many
domains, especially those (like computer vision
and computational chemistry) that are constrained
by physical laws, knowledge of the symmetries640exhibited by a problem domain can dramatically re-
duce the difficulty of learning (Batzner et al., 2022;
Simeonov et al., 2022).
Past work has incorporated symmetry into ma-
chine learning problems in two ways. Invari-
ant and equivariant modeling approaches struc-
turally enforce symmetries via specialized architec-
tures (improving generalization by decreasing the
size of the hypothesis class; Cohen and Welling,
2016). Data augmentation approaches generate
new training examples by applying known symme-
tries like reflections directly to training data (im-
proving generalization by increasing dataset size;
Shorten and Khoshgoftaar, 2019). Data augmen-
tation, the focus of this paper, is model-agnostic,
and can be used in conjunction with pre-training
while producing the same asymptotic effects as
specialized model architectures (Chen et al., 2020).
The question this paper aims to answer is
whether compositionality, like other domain-
specific constraints, can be formalized in the lan-
guage of symmetry. We are not the first to con-
sider this question: Kiddon and Domingos (2015)
define a theory of semantic equivalence in terms
of symmetries of the set of natural language sen-
tences, and Gordon et al. (2020) propose a model
architecture for compositional semantic parsing via
a symmetry that enforces permutation invariance
of lexicon entries. LSalso derives symme-
tries from lexicons. It builds on past work by (1)
characterizing the algebraic relationship between
compositionality and symmetry, explaining the ef-
fectiveness of both Gordon et al. (2020)’s approach
as well as other data augmentation schemes based
on token and phrase substitution (Andreas, 2020;
Wang et al., 2018); (2) discovering symmetries au-
tomatically, and (3) showing how to leverage them
in a model- and modality-agnostic way. Additional
related work is discussed in Sec. 6.
3 Compositionality as Lexical Symmetry
Our main theoretical result, and the foundation of
our modeling approach, can be stated as follows:
in any language understanding task that can be
modeled compositionally, data for the task exhibits
symmetries in the sense of Definition 1 . We explain,
formalize, and prove this statement below.
We consider tasks defined by a space of possi-
ble examples X, of which a subset of examples
Xarewell-formed . We assume each example
x∈ X is a discrete sequence [x, . . . , x], with xdrawn from a vocabulary Σ. Finally, we assume
that well-formedness can be computed by a a bi-
nary interpretation function I:X → { 0,1}with
I(x) = 1 iffx∈X. A wide variety of language
understanding problems, from very simple to very
complex, may be defined in this way:
Example 1a :Arithmetic Language Modeling . Ex-
amples xare true sentences of the form aplus bis
c, where a,bandcare numbers: I(one plus two is
three) = 1 butI(two plus two is five ) = 0 .
Example 1b :Semantic Parsing . Examples xare
pairs (x,x), where xis an sentence, x
is a logical form, and I(x,x) = 1 iffx
represents a possible meaning of x(Fig. 1b).
Example 1c :Visual Question Answering . Ex-
amples xare triples (x,x,x), where xis a
question, xis a (rasterized) image, xis an an-
swer, and I(x,x,x) = 1 iffxis the answer
toxinx(Fig. 1c).
Notice that the vocabulary Σcontains not just natu-
ral language words, but other kinds of data: logical
symbols (1b) or even image patches (1c).
“Language understanding” in each of these tasks
is encapsulated by the function I. What does it
mean for Ito be compositional ? Under most def-
initions, a compositional language understanding
procedure should factorize into a lexicon, which
captures meanings of words, and a composition
procedure, which derives example-level interpreta-
tions from these meanings. We model word mean-
ings in terms of relations between items in Σ. In
arithmetic, to know the meaning of the word five
is to know that it is a number, less than seven , the
successor of four, etc. In semantic parsing, the
meaning of the word catis encapsulated by the fact
that it is of the same type as dog, and translatable
into the logical symbol cat. We model this no-
tion of word meaning by equipping Σwith extra
structure describing these relations:
Definition 2. Alexical algebra is a collection of re-
lations r, . . . , rbetween vocabulary items, where
eachr: Σ→ {0,1}. A lexical algebra can rep-
resent type information, like “ dogis a noun”, as
a unary relation; semantic correspondence, like
“sings maps to sing”, as a binary relation; and
richer semantic knowledge, like “ three is the sum
ofoneandtwo”, with higher-order relations.
We may then represent individual examples in
purely relational terms:641
Definition 3. Denote the lexical representation
L(x) = ( R(x), . . . , R(x)).R(x)is an order-
ptensor whose (i, . . . , j )entry is equal to
r(x, . . . , x). (If ris a binary relation, R(x)is
an|x| × |x|matrix and R(x)specifies whether r
holds between xandx.) See Fig. 2 for examples.
Finally, we use this relational representation to
define compositionality of interpretation functions:
Definition 4. XisL-compositional ifI(x) =
C(L(x))for some composition procedure C. In
other words, Xis compositional if it compute the
well-formedness of xfrom word-level meanings
and a generic composition procedure.
This definition makes no assumptions about C
beyond the fact that it can be defined purely in
terms of L(x). It can be applied to many tasks:
Example 2a :Arithmetic Language Modeling . De-
finerto be the ternary relation (a, b, c )∝⇕⊣√∫⊔≀→
1. Then Ctakes an example and checks
whether the index corresponding to its three num-
ber words is true in R.
Example 2b :Semantic Parsing . A sketch of asemantic parser factorizable into a lexicon and an
abstract composition function is depicted in Fig. 2.
As a real-world example, in the factored CCG se-
mantic parser of Kwiatkowski et al. (2011), words
are assigned types and logical forms via a lexicon.
These logical fragments are then composed by a
parsing algorithm that depends only their types.
Example 2c :Natural Language Inference . Mac-
Cartney and Manning (2014)’s Natural Logic
framework provides a procedure for determining
entailment relations between sentences via a set of
sentence rewriting operations that use only word-
level information about entailment relations.
Under Definition 4, a sentence interpretation pro-
cedure is compositional if the meaning of a sen-
tence can be derived in a generic way ( C) from the
meanings of its lexical items ( L).We remark, fi-
nally, that the parsing procedure depicted in Fig. 2
is an idealization used to motivate our approach;
our experiments use more flexible models.
We are now ready to describe how, for composi-
tionalI, structure in Ltranslates into structure in
the set of well-formed examples X.
Definition 5. A function fis ahomomorphism
of (ΣΣΣ,LLL) (an “L-homomorphism”) if:
∀r∈ L,∀x. . . x∈Σ :
r(x, . . . , x) =r(f(x), . . . , f (x)) (2)
f“preserves the structure” of L, ensuring that pair-
wise relationships are preserved among symbols.
Fig. 1 shows examples: in (c), for instance, the
words yellow andgreen and the corresponding col-
ors must be swapped to satisfy Eq. 2.
Finally, we may state our main result:
Theorem 1. IfXisL-compositional, fis an
L-homomorphism, and x∈X, then f(x) =
[f(x), . . . , f (x)]∈X. Thus every homomor-
phism of Lwell-formed examples ∈X.
Proof. From Definition 3 and 5, R(f(x)) =
R(x)∀i. Then,
1=I(f(x))
=C(L(f(x)))
=C(R(f(x)), . . . , R(f(x)))
=C(R(x), . . . , R(x))
=I(x) =1642Corollary 1. With the additional constraint that f
is anL-isomorphism (i.e., has an inverse), then f
is a symmetry of Xin the sense of Eq. 1.
Here it suffices to show that the preimage of
every x∈Xis also in X; the proof is the same as
Theorem 1 with fin place of f.
Despite their simplicity, Theorem 1 and its corol-
lary have an important consequence: if we can
identify candidate entries in L,even if Cis un-
known , we can construct new examples x∈X
that respect, and provide evidence for, the compo-
sitional structure of X. There is an intriguing (if
inexact) structural similarity between Corollary 1
and Noether’s theorem (Noether, 1918), which es-
tablishes an equivalence between symmetries of
physical systems and their conserved quantities.
Here, such symmetries imply constraints not on
conservation laws but interpretation functions.
4 LS: Data Augmentation with
LLL-homomorphisms
Given a lexicon describing symbols and their rela-
tions, we have shown how to turn homomorphisms
of the lexicon into transformations of a dataset.
Each such function fthat takes an example xas
input, replaces each token x∈xwith a new one,
and returns a well-formed example xas output.
EveryL-homomorphism may thus be viewed as a
recipe for synthesizing training examples from a
small initial training set (Japkowicz et al., 2000).
However, to make this a practical modeling tool, we
need some way of constucting L-homomorphisms
for a task of interest. Below, we describe how to
do so automatically: first, starting with only a task-
specific lexicon L(Sec. 4.1); next, starting with
only a dataset and no initial lexicon (Sec. 4.2). We
term the resulting approach LS.
4.1 Deriving Homomorphisms from Lexicons
Even in complex sequence modeling problems, use-
ful lexicons are often simple enough that they can
be specified by hand (Jones et al., 2012; Gordon
et al., 2020). Given a pre-specified algebraic L,
there is a straightforward procedure for generating
the associated symmetries by enumerating all func-
tions Σ→Σand testing which ones satisfy Eq. 2.
(See Algorithm 1 in Appendix B.) This algorithm
is inefficient, but simple and practical for small |L|.4.2 Deriving Lexicons from Datasets
For some tasks, it may be difficult to manually
specify an algebraic lexicon. We next describe how
to infer one automatically. We focus on an im-
portant and extremely common class of language
understanding problems with special structure. In
semantic parsing andinstruction following , exam-
plesxconsist of (input, output) pairs in which
inputs are sentences, outputs are meaning repre-
sentations, and word meaning is characterized by
a lexicon with two components. First, a set of
unary type predicates {r}that assign words to
types (like in semantic parsing). Sec-
ond, a semantic correspondence relation rthat
specifies which actions or logical symbols can be
derived from words (like sings→sing). With
ntypes, the lexicon required for these problems
isL= (r, . . . , r, r), which we abbreviate
({r}, r)below. We now show how to improve
upon the procedure in Sec. 4.1 by deriving Lfrom
data and sampling L-homomorphisms in constant
time.
Learning LLLWe build on past work noting that
dictionaries of semantic correspondences can be
constructed using alignment algorithms (Brown
et al., 1993). Given an input xconsisting of a pair
(x,x ), we use existing algorithms to align
tokens in individual training examples. Finally, we
identify the most frequently occurring alignments
and add these to the semantic correspondence rela-
tion. We may similarly use existing procedures to
infer types by deriving them from part-of-speech
tags or distributional patterns. See Appendix D for
details of the alignment and type inference algo-
rithms used in our experiments. These algorithms
produce lexicons with three properties that are use-
ful for the sampling scheme we describe next: types
aredisjoint , and semantic correspondences are one-
to-many andtype-preserving (if two words are of
the same type, so are their translations).
Sampling LLL-homomorphisms Once we have
identified types and semantic correspondences,
sampling L-homomorphisms is straightforward:
Theorem 2. Letxandx∈Σhave the same type
r(x) =r(x) = 1 . For convenience, let E=
{x:r(x, x) = 1}denote possible translations of643x. The fis anL-homomorphism:
f(x) =

x ifx=x
x ifx=x
x∈Eifx∈E
x∈Eifx∈E
x otherwise(3)
Proof is given in Appendix A. Theorem 2 yields an
intuitive data augmentation procedure: select two
(input, output) pairs of the same type, and swap
them and any of their meanings wherever they oc-
cur. Fig. 1b shows an example. Eq. 3 is related to
data augmentation schemes described by Andreas
(2020) and Liu et al. (2021b), which synchronously
substitute words or phrases (equivalent to removing
cases 2 and 4). Unlike LS, these methods
cannot guarantee correctness: in Fig. 1c, substitut-
inggreen in place of yellow yields an image with
two green objects and an incorrect answer.
5 Experiments
Our experiments aim to evaluate whether LS
can improve compositional generalization in down-
stream models. The main goal of these experi-
ments is to evaluate generality across tasks and data
modalities. Evaluation focuses on three diverse
classes of language understanding problems: com-
plex, context-dependent computations (Sec. 5.1),
large, automatically derived lexicons (Sec. 5.2),
and multi-modal data (Sec. 5.3).
5.1 Complex computations
We first test LSon the task from
the benchmark (Long et al., 2016)—a prob-
lem involving a complex sentence interpretation
procedure that makes it challenging to apply exist-
ing data augmentation schemes.
Data In (Fig. 1a), models must exe-
cute a sequence of human-written English instruc-
tionsx, on an initial state xconsisting of
beakers of colored liquids (textually represented
as sequence of symbols “1: gg, 2: ...”), to pre-
dict the final state x. Initial and final states are
encoded as sequences of color tokens. Predicting
final states requires both grounding colors in state
variables (brown →b, red→g) and model-
ing what happens when colors are combined (e.g.
mixing gand ryields b).LS We manually construct a lexicon to
showcase how to inject prior knowledge into
LS. We encode word meaning in two re-
lations: a semantic equivalence relation between
color words and colors:
r(c, c) =

1c=brown , c=b
1c=red, c=r
1c=green , c=g
...
0otherwise
and a ternary relation that encodes the result of
mixing colors:
r(c, c, c) =

1c=c=c
1c̸=c∧c=b
0otherwise
Together, (r, r,{r}), where {r}assigns dif-
ferent types to color words, colors, and remaining
tokens. The homomorphic transformations of this
lexicon exchange color words and colors but pre-
serve mixing relations.
Models and Training We train an LSTM
(Hochreiter and Schmidhuber, 1997) and fine-
tune a T5 transformer (Raffel et al., 2020)
on the sequence-to-sequence prediction problem
(x,x)→x Training details may be
found in Appendix C. We compare these baseline
models to their LS-augmented versions as
well as the existing compositional data augmenta-
tion scheme of Liu et al. (2021b).
Results See Table 1. LSTM+ LSimproves
substantially over an LSTM. Preserving the homo-
morphism condition in Eq. 2 is extremely impor-
tant: the procedure of Liu et al. (2021b), which
naively substitutes aligned color pairs, actually
hurts performance. Pre-trained models achieve
strong initial results; combining pre-training with
LSgives additional improvements.
5.2 Learned lexicons
We next show that for more conventional sequence-
to-sequence problems, we may apply LS
with automatically derived lexicons.644
Data We study two standard compositional gen-
eralization benchmarks: the S (Lake and
Baroni, 2018) instruction following and C
(Kim and Linzen, 2020, Fig. 1b) semantic pars-
ing datasets. S consists of simple instruction
following tasks in which strings are translated into
sequences of actions. We focus on the jump split,
which measures models’ ability to compose words
that only appeared in isolation during training, and
thearound right split, which measures general-
ization to novel collocations. The C dataset
tests compositional generalization in semantic pars-
ing. The dataset includes English (sentence, log-
ical form) pairs, with systematic differences be-
tween train and test set sentence structure. We
include a variant containing nonce words (Kimet al., 2022) to disentangle general compositional
skills from lexical knowledge acquired during pre-
training. See Appendix G for dataset statistics.
LS We use automatic lexicon extraction
to find semantic correspondence relations ( r) and
types ( {r}) as described in Appendix D. Next,
we apply swap-based augmentation (Eq. 3).
Models We use the same models as Sec. 5.1,
along with a strong semi-structured model, LeAR
(Liu et al., 2021a) tailored for C, and another
substitution based augmentation (Andreas, 2020)
tailored for SCAN. Following Akyurek and An-
dreas (2021), we equip the LSTM for C with a
copy mechanism as it achieves significantly better
results than Kim and Linzen (2020)’s baseline.
Results OnS,LSobtains near-perfect
accuracy in both jump andaround right splits. On
the original C datasets, LSsubstantially
outperforms the LSTM model and GECA augmen-
tation, and is comparable to a neural sequence
model specialized for lexical generalization (LexL-
STM). Stronger results can be achieved with mod-
els specifically tailored toward semantic parsing
tasks (LeAR). In both tasks, LSalso im-
proves upon large-scale pre-training.
5.3 Multi-modal data
Finally, we combine learned lexicons with non-
sequential data to advance the state of the art on a
long-standing visual question answering challenge.
Data TheC dataset (Johnson et al., 2017,
Fig. 1c) contains English-language questions about
generated 3D scenes containing multiple objects.645Questions involve complex computational oper-
ations including quantification, comparison, and
spatial reasoning. C has been a popular
testbed for evaluating composition in visual ques-
tion answering models. Our main experiment uses
theCGTsplit of the dataset, which focuses
on compositional generalization. In the C -
CGTtraining set (Split A), which contains
roughly 700K(question, image, answer) triples,
all cubes are gray, blue, brown or yellow, while all
cylinders are red, green, purple or cyan. In the test
set (validation set of Split B), these are reversed.
LS In VQA and other multi-modal tasks,
part of the input is continuous (e.g. images and
videos). Recent work has shown that it is possi-
ble to learn high-quality discrete representations
of continuous input data. For example, in the VQ-
V AE model of van den Oord et al. (2017), a con-
tinuous image is transformed into a grid of cate-
gorical codes, with individual codes representing
color, and in some cases materials and illumination
(examples in Table 3). We use this discretization
procedure for our experiments (see Appendix C.1
for details). We use the same algorithm as previous
section to extract lexical relations.
Models Most prior work on visual question an-
swering has used pre-trained convolutional net-
works to encode images, and recurrent networks
to encode questions and generate answers. For ex-
periments on C , we use a simplified model in
which both questions and images are mapped to an-
swers by a transformer model, similarly to Ramesh
et al. (2021). See Appendix C.2 for details.
Both LSaugmentation and this VQA-
Transformer model operate over sequences of dis-
crete visual codes produced by a vector-quantized
variational autoencoder. Once these discrete repre-
sentations have been produced, we infer lexicons
and perform data augmentation directly to these
representations, without re-synthesizing images
(though such synthesis is possible, as in Table 3, to
interpret model behavior).
The CGTtask is very different from the
sequence modeling tasks discussed above: inputs
contain many tokens, and the training set is orders
of magnitude larger. GECA and CSL-Aug, which
have a high polynomial dependence on sequence
length, could not be applied as they fail to terminate
within a reasonable amount of time.Results In Table 2, a transformer model with
LSachieves state-of-the-art results on the
C -CGTdataset, reducing errors by
roughly 33% relative to the best existing system.
LSalso outperforms substitution based-data
augmentation (Liu et al., 2021b), particularly on
semantically complex utterances involving quan-
tification (App. Table 4). On the IID C split,
LS’s performance is comparable to humans,
and somewhat behind pre-trained models.
6 Other Related Work
Lexicalized neural models Word-level align-
ments between input and output sequences were
an essential feature of statistical phrase- and tree-
based sequence models (Chiang et al., 2005; Koehn
et al., 2003). Neural scoring functions were some-
times integrated into these models (Misra and Artzi,
2016). Neural models with attention (Bahdanau
et al., 2015) do not require explicit alignment,
though several pieces of past work have shown that
incorporating explicit token-level correspondences
improves generalization (Akyurek and Andreas,
2021; Prabhu and Kann, 2020; Pham et al., 2018).
The semantic correspondence function in Sec. 4
plays the same role as the input–output dictionary
in these methods, but LSas a whole is more
general: it is not restricted to modeling sequence-
to-sequence problems, and can infer and exploit
correspondence relations between component of an
example. To the best of our knowledge, this paper
is also the first to make use of token-level align-
ments in joint neural models of text and images.
Compositionality in representation learning
While we have focused on compositionality as a
property of data distributions or interpretation func-
tions, another line of work in machine learning and
language evolution has studied compositionality
as an emergent property of learned representations
(Andreas, 2019; Resnick et al., 2019; Brighton and
Kirby, 2006). In settings where representational
compositionality is desirable (e.g. to train commu-
nication protocols that can generalize to new states),
LSmight provide a tool for promoting it.
Equivariant Sequence Models As mentioned
in Sec. 2, our work builds on existing ap-
proaches that control generalization with spe-
cialized model architectures designed to be
equivariant to permutations of a pre-specified
lexicon (if f(x···x) = y···ythen646f(π(x)···π(x)) = π(y)···π(y)for a per-
mutation π) (Gordon et al., 2020; White and Cot-
terell, 2022). LSdiffers from these ap-
proaches in three ways. First, LSis model-
agnostic and compatible with pre-training. Second,
LSis compatible with (and automatically
derives transformations for) more complicated re-
lations than input–output correspondences, making
it possible to apply to tasks like where
such relations are important. Finally, LS
gracefully handles (possibly noisy) learned lexi-
cons, making it applicable to tasks like CGT
with complex or uninterpretable token mappings.
Data Augmentation Data augmentation ap-
proaches are widely used across machine learning
application domains featuring known invariances
of the data distribution (Japkowicz et al., 2000; Jia
and Liang, 2016; Shaw et al., 2021). Substitution-
based schemes that replace words with synonyms,
or synchronously replace words and their transla-
tions, are widely used for machine translation and
general de-biasing (Liu et al., 2021b; Wang et al.,
2018; Wei and Zou, 2019).
7 Limitations and Future Directions
While Sec. 3 characterizes the effect of general L-
homomorphisms, LSspecifically produces
single-token swaps. In images represented as dis-
crete symbol sequences, if a single symbol simul-
taneously encodes multiple visual features (e.g.
color and texture), these features will remain entan-
gled in synthesized examples. It will not exchange
substructures larger than a single token, and thus
will not synthesize examples longer than those al-
ready present in the training set (Lake et al., 2019).
This is because LStargets compositionality
but not recursion , which is also required to model
the full range of human-like generalizations in se-
quence learning problems.
LSis also sensitive to the nature of the
tokenization scheme itself. In morphologically
rich languages, for example, LSmay need
to be applied not on top of words or segments,
but instead canonicalized morphemes produced
by learned morphological analyzers (Narasimhan
et al., 2015; Bergmanis and Goldwater, 2017; Cot-
terell and Schütze, 2018) (analogous to the use
of learned image patch representations rather than
pixels in our VQA experiments).
Finally, LSdoes not induce some of the
generalizations obtained other methods for improv-ing compositional generalization, especially those
that exploit extra structure (e.g. tree-shaped inputs
and outputs) in the semantic parsing domain (e.g.
Liu et al., 2021a). It might serve as a platform for
future versions of those methods that offer greater
generality and formal guarantees.
8 Conclusion
We have presented LS, a new data augmen-
tation method that improves compositional gen-
eralization of neural models in multiple domains.
LSis derived from a characterization of the
principle of compositionality as a constraint on the
symmetries of data distributions, and a procedure
for automatically identifying these symmetries us-
ing token-level alignments. Our results highlight
the fact that many inductive biases targeted by spe-
cialized models in NLP can be alternatively, and
often more flexibly, expressed as a hypothesis about
the structure of the distribution to be modeled.
Acknowledgements
This work was supported by the Machine-
LearningApplications initiative at MIT CSAIL, the
MIT–IBM Watson AI lab, and the National Science
Foundation under grant CCF-2217064. Computing
resources were provided by a gift from NVIDIA
through the NV AIL program and by the Lincoln
Laboratory Supercloud.
Ethics Statement
We do not anticipate any ethical issues associated
with the techniques decribed in this paper.
References647648649650A Proof of Theorem 2
Proof. The lexicons that we learn only unary type
relations and a semantic correspondence relation
L= ({r}, r). As noted there, we make the
following additional assumptions (satisfied by our
lexicon learning algorithms):
(i)Types are disjoint , i.e. every symbol belongs
to a single type: ∀∈Σ,|τ|=|{r|
r(x) = 1}|= 1.
(ii)Semantic correspondences are one-to-many
from text to meaning . This means that no
two text symbols can translate into the same
meaning symbol: E∩E=1and all
r(x /∈x, y) =r(y, x /∈x ) = 0 .
(iii) Semantic correspondence is type preserving :
all symbols in a correspondence class have the
same type τ={r}.
To show that fis anL-homomorphism, we want
to show that r(f(x), f(x)) =r(x, x)for any
x, x. The transformation function and all the def-
initions are symmetric to indices iandj(i−j
symmetry), so it is sufficient to show the corre-
spondence relations stay the same for below cases
only:
(a)x=x, x=x:
r(f(x), f(x)) =r(x, x) = 0 = r(x, x)
(by ii)
(b)x=x, x=x:
r(f(x), f(x)) =r(x, x) = 0 = r(x, x)
(by ii)
(c)x=x, x∈E:
r(f(x), f(x)) =r(x, x∈E)
= 1 = r(x, x)
(by definition of EandE)
(d)x=x, x∈E:
r(f(x), f(x)) =r(x, x∈E)
=1=r(x, x)
(by ii)(e)x=x, x/∈ {{x} ∪ {x} ∪E, E}:
r(f(x), f(x)) =r(x, x)
= 0 = r(x, x)
(f)x=x, x/∈ {{x} ∪ {x} ∪E, E}:
same steps as (e)
(g)x∈E, x=x:
r(f(x), f(x)) =r(x∈E, x)
= 0 = r(x, x)
(by ii)
(h)x∈E, x=x:same steps as (g)
(i)x∈E, x∈ {{x} ∪ {x} ∪E, E}:
r(f(x), f(x)) =r(x∈E, x)
= 0 = r(x, x)
(by ii)
Finally, we require r(x) =r(f(x))for any x
andτ. Since we assume all items in Ebelong to
a type matching x(likewise for j), and types are
disjoint, this follows immediately from the defini-
tion of f, which only swaps symbols of the same
type.
B Enumerating L-homomorphisms
A simple algorithm is given below:
Algorithm 1 L-homomorphism enumeration
C Implementation Details
C.1 VQV AE Details
We use a discrete variational auto-encoder (van den
Oord et al., 2017) to encode the images 16×16
grids of discrete codes. We used a code-book with
n= 32 tokens associated with d= 64 dimensional651
learned latent vectors. The original image size
(480,320) is cropped to (440,300) and resize our
images into (128,128) pixels. The encoder convo-
lutional neural network has three down-sampling
layers which output 16×16×dsize hidden rep-
resentations. For encoder and decoder CNN archi-
tectures, we follow the implementation provided in
a public Pytorch implementationby adding one
more up-sampling and down-sampling layer to ad-
just our image size.
We use exponential moving average to update
latent vectors as in official implementationWe
train the model on the images of the same training
data and did not use any external data.
We use batch size of 512, and learning rate
0.0003 with the Adam optimizer (Kingma and
Ba, 2015). We clip the gradients to 5.0. Hy-
perparameters were selected by sweeping dover
{64,128}, image sizes over {128,144}, andnover
{24,32,48}to maximize the the number of aligned
tokens in the lexicon. For each experiments in Ta-
ble 2, we run VQV AE for 4 random seeds and select
the codebook that gives the largest IBM model like-
lihood for training data. Each experiment takes 10
hours in 4 NVIDIA V100 GPUs.C.2 VQA Transformer Details
The Transformer takes tokenized images xand
the question xand outputs answers as follows:
c= VQVAE(x)
e=Wx+ 1D (x)
e=Wc+ 2D (c)
h= Transformer([ ee])
x= argmax softmax (Wh)(4)
We follow the hyper-paramters provided in (Popel
and Bojar, 2018). Transformers have 4 heads, 512-
dimensional hidden vectors (same with embedding
sizes) and 10layers. We provide the dimensions in
Eq. 4:
x: 3×128×128
c: 32×16×16
W: 512×32
e: 512×(16×16)
e: 512× |V|
W: 512× |V|
h: 512×(|Q|+ 16×16)
h: 512×1
W: 512× |V|(5)
Models are trained using the Adam optimizer with
and Noam learning rate scheduler (Vaswani et al.,
2017) with lr= 1.0and16kwarming steps as
provided in Popel and Bojar (2018). We use a
batch size of 1024 and we train for 200ksteps,652which takes 48 hours on 8 NVIDIA V100 GPUs.
In Fig. 3, we provide the sketch of overall pipeline.
C.3 Baselines: LSTM Details
We use the implementation provided by (Akyurek
and Andreas, 2021), increasing the number of
training iterations from 8kto15kfor augmented
training runs in C,S datasets. For the dataset, we optimize iteration count
over{8k,15k,25k,50k}based on validation ac-
curacy, and found 25kto be optimal. For
theC dataset, we optimize itreation count
over{8k,15k,25k,50k}forC andC -
CGTdataset based on C ’s validation ac-
curacy.
C.4 Baselines: T5 Details
We use the Huggingface (Wolf et al., 2019) imple-
mentation T5-base model. The difference between
our T5 baselines results and the results in Qiu et al.
(2022) due to their usage of different intermediate
representation for the output in order to keep our
evaluation consistent with other previous work. We
try to optimize (learning rate, learning rate sched-
uler) and training parameters (iteration count) of
Qiu et al. (2022) and (Akyurek and Andreas, 2021),
use the best setting for the given dataset.
C.5 Alignment Model Details
In our experiments, we use the best alignment
method reported in (Akyurek and Andreas, 2021),
which is IBM Model 2 for all datasets except the
SCAN dataset that uses their proposed algorithm,
to obtain our initial alignments A={(x, x): set
of tuples contains aligned tokens. We run align-
ment algorithms between xandx . For
S andC,xis the actual inputs, x
is the actual outputs. In ,xis instruc-
tions, x is beaker states. In VQA experi-
ments, xquestion and answer words, x
VQV AE codes. We disable diagonalization in
FastAlign as it includes non-language structured
VQV AE codes.
D Lexicons
D.1 Lexicon Learning
Extracting semantic correspondences r(x,x)
Given the initial alignments Ain Appendix C.5,
we remove every xthat is not aligned to at least
1% of occurrences of xin the dataset. We then
produce a one-to-many lexicon by deleting lexiconentries (x, x)and(x, x)when both exist. With,
these alignment creates entries in r(x, x) =
1
Extracting Types r(x) Given the partition of
the data points ( x,x ), our type finding
algorithm is essentially unsupervised clustering of
the text symbols in x. The types of matching
x symbols are automatically determined by
the correspondence relation, rfound above. In all
our datasets xis English, so the symbols that
goes into following clustering algorithm are actual
words.
Following Clark and Eyraud (2007) and An-
dreas (2020), we assign types to individual words
based on their environments. For each symbol,
x∈Σ, that has at least one equivalent symbol
inA, we define the context κ(x) ={(α, β) :
αxβ∈X}: the set of strings (α, β)that ap-
pear surrounding xin the training set. (If the
two examples in Fig. 1 formed the entire train-
ing set, we would have κ(yellow ) =κ(green ) =
{(Q: How many ,objects? A: 1 )}.).We then rep-
resent Σas a graph with an edge between each
xandxwhere κ(x)∩κ(x)̸=∅(Clark and
Eyraud’s syntactic congruence relation) and xand
xhas same part-of-speech tag according to spaCy
pipeline with en-core-web-lm language model.
We assign each connected component of this graph
a distinct type. This is only one possible approach
to typing; alternatives might use clustering of dis-
tributed representations.
D.2 Extracted Lexicons
In this section, we present lexicon entries for sym-
bols that we learned through our typing algorithm.
S We present equivalance relations that
we extracted from S training dataset.653Source symbol Type Target Symbol(s)
jump t I_JUMP
walk t I_WALK
run t I_RUN
look t I_LOOK
left t I_LEFT
right t I_RIGHT
C Since the extracted lexicon is large for
semantic parsing, we present only some of the
equivalance relations that we extracted from C
training data for reference.
Source symbol Type Target Symbol(s)
baked t bake
noticed t notice
helped t help
dog t dog
boy t boy
sailor t sailor
CGTWe present equivalance relations that
we extracted C -CGTtraining data. The
lexicon we found includes all the color symbols.
The target symbols given here are learned VQV AE
codes. In Appendix E, we show these codes on top
of the images to qualitatively verify the alignments.
Source Symbol Type Target Symbols
red t 9
purple t 25, 29
cyan t 28
blue t 20
green t 11
yellow t 23, 18
gray t 6
brown t 2
E Samples & Statistics
We present examples generated by LSin
Table 3. As we performed augmentation random
and online during training, and we do not have
a static augmented set to calculate statistics
for. Instead, we run a single iteration of our
augmentation function over all examples with
our augmentation function and obtain following
statistics:
Note that, in C , we consider the nov-
elty based on (question + answer) string since
the generated image codes can be novel but the
resulting image not. The following differences are
significant under a paired t-test:
E.1 Statistical Significance Tests for Table 1
The following differences in Table 1 are significant
under a paired t-test:
Alchemy:
• T5+LS> T5 (p < 0.05)
•LSTM+ LS > LSTM+Substitute,
LSTM, LexLSTM (p < .00001)
COGS:
• T5+LS> T5 (p < .00001)
• LSTM+LS> LSTM, (p < .00001)
F C -CGT Detailed Results
CGT results are presented in Table 4.
G Data
ForC -CGT(Johnson et al., 2017), we
use training set for Split-A as our training set, val-
idation set for Split-B as our validation set, and
validation set of Split-B as our test set. The C
and datasets is released under the Cre-
ative Commons CC BY 4.0 license. The C
datasets (Kim and Linzen, 2020; Kim et al., 2022)
are released under MIT license. S (Lake and
Baroni, 2018) datasets are released under BSD li-
cense. The train, validation and test set sizes are
given as below.654
Dataset Train Validation Test 18285 1225 4495
S
(jump) 14670 – 7706
(around right) 15225 – 4476
C
(original) 24155 3000 21000
(nonce) 24155 3000 21000
C
(original) 699989 149991
(CoGenT) 699960 – 150000655ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
8 (Limitations)
/squareA2. Did you discuss any potential risks of your work?
9 (Impact Statement)
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
Left blank.
/squareA4. Have you used AI writing assistants when working on this paper?
Left blank.
B/squareDid you use or create scientiﬁc artifacts?
Left blank.
/squareB1. Did you cite the creators of artifacts you used?
Left blank.
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
Left blank.
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
Not applicable. Left blank.
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
Not applicable. Left blank.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
Left blank.
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
Left blank.
C/squareDid you run computational experiments?
Left blank.
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
Left blank.656/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
Left blank.
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
Left blank.
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
Left blank.
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
Left blank.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
Not applicable. Left blank.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
Not applicable. Left blank.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
Not applicable. Left blank.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
Not applicable. Left blank.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
Not applicable. Left blank.657