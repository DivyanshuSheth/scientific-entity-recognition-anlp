
Tulika Saha, Saichethan Reddy, Anindya Das, Sriparna Saha, Pushpak BhattacharyyaIndian Institute of Technology Patna, IndiaIndian Institute of Technology Bombay, India
(sahatulika15,sriparna.saha,pushpakbh)@gmail.com
Abstract
Mental Health Disorders continue plaguing hu-
mans worldwide. Aggravating this situation is
the severe shortage of qualified and competent
mental health professionals (MHPs), which un-
derlines the need for developing Virtual Assis-
tants (V As) that can assist MHPs. The data+ML
for automation can come from platforms that
allow visiting and posting messages in peer-
to-peer anonymous manner for sharing their
experiences (frequently stigmatized) and seek-
ing support. In this paper, we propose a V A that
can act as the first point of contact and comfort
for mental health patients. We curate a dataset,
Motivational VA: MotiVAte comprising of 7k
dyadic conversations collected from a peer-to-
peer support platform. The system employs
two mechanisms: (i) Mental Illness Classifica-
tion: an attention based BERT classifier that
outputs the mental disorder category out of the
4 categories, viz., Major Depressive Disorder
(MDD), Anxiety, Obsessive Compulsive Dis-
order (OCD) and Post-traumatic Stress Disor-
der (PTSD), based on the input ongoing dialog
between the support seeker and the V A; and
(ii)Mental Illness Conditioned Motivational
Dialogue Generation (MI-MDG) : a sentiment
driven Reinforcement Learning (RL) based mo-
tivational response generator. The empirical
evaluation demonstrates the system capability
by way of outperforming several baselines.
1 Introduction
With an estimated 970 million individuals suffer-
ing from some sort of mental or neural diseases,
mental health disorders are regarded one of the pri-
mary causes of disability globally. Poor access,
stigma, and prejudice, on the other hand, are likely
to limit clinical care to only 15% of individuals
who are affected. As a means of expressing their
emotions and experiences (generally stigmatized),
millions of people (also known as support seekers)frequently turn to looking for emotional or mental
health-related support (Eysenbach et al., 2004) on a
variety of text-based peer-to-peer support platforms
(De Choudhury and De, 2014), ( talklife.co ).
While peer supports on these platforms are well-
intentioned and willing to aid and help seekers, they
are often untrained and unaware of best-practices
in therapy, resulting in wasted opportunities to
provide effective and mutually engaging solutions
(Gage-Bouchard et al., 2018). As a result, devel-
oping human-computer interfaces in the form of
Virtual Assistants (V As) that can effectively reply
and provide support to online support seekers be-
comes even more critical.
Empathy, or empathetic interactions (Elliott
et al., 2018), has been studied extensively in recent
years (Sharma et al., 2021, 2020) as one of the most
important aspects in providing successful support
and triggering beneficial results in support-based
dialogues. In addition to empathy, imparting hope
andmotivation (the process of thinking about and
the willingness to move towards one’s goals) have
been recognised as important affective elements
(Dowling and Rickwood, 2016) in uplifting the
spirits of support seekers in distress during support-
ive talks. This is critical because support seekers
often engage in escapist or avoidant behavior in
anticipation of negative consequences, making it
difficult for them to cope with the crisis (Hecht,
2013). Quantitative research shows that instilling
optimistic behaviour fueled by hope and motivation
improves symptoms in terms of positive psycho-
logical transformation and a favourable alliance in
mental health support (Jahanara, 2017).
In this paper, we propose a V A acting as the first
point of contact for mentally distressed support
seekers afflicted with some form of mental illness.
The V A’s efforts are aimed at reassuring and allow-
ing support seekers to anonymously communicate
and express their thoughts, emotions, challenges
and seek support. The V A’s response should be2436competent and proficient enough to provide sup-
port seeker with a natural human experience fo-
cused on imparting hope and motivation based on
positive perspective. To mimic this human-like be-
havior of mental health supporters in a V A is quite
challenging and the tasks employed are two folds.
Firstly, for the V A to provide a conversational sup-
port in the absence of electronic health records or
psychiatric notes, it is critical to recognise and dif-
ferentiate various mental diseases because they are
frequently communicated using similar language
patterns and overall sentiment polarity. In the case
of anxiety, for example, the supporter’s purpose is
to reduce avoidant behaviour and assist the patient
in disconfirming a feared consequence. In depres-
sion, however, the goal is to assist the mental health
seeker in experiencing positive feeling, a burst of
energy, or another sort of pleasant contact with the
world. Subsequently, the task of the V A is to gener-
ate response conditioned on the identified mental
illness for modelling motivational conversations
with positive outcome.
Due to the unavailability of conversational data
for our proposed task, we introduce a dataset, Moti-
VAte comprising of 7k conversations between sup-
port seekers and V A collected from a peer-to-peer
support platform. The key contributions of this pa-
per are as follows : (i) To the best of our knowledge,
this work is the first to propose a V A for providing
motivational support and comfort to mental health
patients; (ii) We curate a conversational dataset,
MotiVAte , to advance research in mental health
based support; (iii) Our end-to-end system em-
ploys two sub-modules, viz., Mental Illness Classi-
fication (MIC) framework, a dual attention based
BERT classifier to identify the mental health dis-
order of the support seeker in the on-going con-
versation and Mental Illness Conditioned Motiva-
tional Dialogue Generation (MI-MDG) framework
to generate mental illness conditioned sentiment
driven Reinforcement Learning (RL) based motiva-
tional responses mimicing an ideal mental health
supporter; (iv) Empirical results indicate that our
proposed system outperforms several baseline mod-
els.
2 Related Works
In this section, we explore mental health based
analysis from social media posts and computational
models for therapy (Pérez-Rosas et al., 2019).
Mental Health Identification. There are nu-
merous studies over the years that use multi-modalcues such as images and (Yazdavar et al., 2020)
to diagnose diagnose from social media posts and
activity (Gaur et al., 2018; Yazdavar et al., 2018;
Qureshi et al., 2019; Yazdavar et al., 2017). Inves-
tigations have also been conducted on recognising
mental illness in online users by their posts on
social media (Syarif et al., 2019; Ji et al., 2020).
The authors of (Patra et al., 2020) proposed a Bi-
LSTM (Hochreiter and Schmidhuber, 1997) based
classifier for classifying mental severity as crisis,
red, amber, and green using data from a psycho-
logical forum. For detecting mental diseases from
daily posts of an online user, (Rao et al., 2020) sug-
gested a knowledge augmented ensemble learning
classifier. Authors of (Ji et al., 2021) proposed a
pre-trained transformer model named MentalBERT
trained on a large corpora of data belonging to
mental health care. (Saha et al., 2022) presented
a hierarchical attention based classifier to detect
mental illnesses from motivational conversations.
(Martínez-Castaño et al., 2021) proposed a BERT
classifier for detecting severity of depression and
likeliness towards self harm for social media users.
Mental Health in Conversations. (Althoff
et al., 2016) presents an investigation on a large-
scale counselling dialogue gathered from an SMS
text-based counselling service. As a result of these,
exploring empathic relationships in therapy has
grown in popularity (Sharma et al., 2020; Morris
et al., 2018). In order to help mental health sup-
porters, (Sharma et al., 2021) investigated empathy
rewriting as a text generation task. Authors of
(Fitzpatrick et al., 2017) presented a conversational
agent, named Woebot to deliver cognitive behav-
ioral therapy by initiating daily conversations for
mood tracking. Our work differs in the sense that
our end-to-end system does not provide any clini-
cal suggestions or therapy recommendations. The
role of competence in responses to help-seeking
posts on mental health was investigated in (Lahnala
et al., 2021).
Sentiment/Emotion aware Dialogue Systems.
To make the V A user-adaptive, the authors in (Saha
et al., 2020c,d, 2018), proposed using a sentiment-
based reward function for learning a dialogue pol-
icy in a task-oriented conversation. The authors of
(Saha et al., 2020a) demonstrated how reinforce-
ment learning may be used to generate meaningful
responses while training generation frameworks.
In (Saha et al., 2020b, 2021a,b,c), the authors show
how subtleties in human communication, such as2437
sentiment and emotion, can help different infor-
mation elicitation models in dialogues work better.
Apart from these, several other work (Wei et al.,
2019; Ide and Kawahara, 2021; Huo et al., 2020)
that suggests using sentiment and/or emotion as an
additional input in generation frameworks either
during decoding or as reward to guide the models
for generating responses aligned with the user’s
mood or feelings.
3 Motivational V A : MotiVAte Dataset
The MotiVAte dataset contains 7067 dyadic con-
versations with support seekers who have one of
the four mental disorders: MDD, PTSD, anxiety,
or OCD. Supplementary material contains descrip-
tions of these illnesses as they appear in ICD-10.
Table 1 displays the dataset statistics as well as
the sample distribution amongst illnesses. Sample
conversations from the dataset are shown in Figure
1. As evident from the conversations, we expect
our V A to perform simple, ordinary and expected
things in the form of providing comfort and assis-
tance to the support seekers at the time of crisis and
the curated dataset is full of such statements.
Data Collection. Existing mental health
databases had limitations in the context of our
proposed work. Some of the datasets, for ex-
ample, (Choudhury et al., 2017; Yazdavar et al.,
2017, 2018, 2020) were social media contents of
anonymized users comprising of self-disclosures
and self-expressive posts with no specific dyadic
or multi-party discussions to draw on. Some ofthe text-based counseling conversational datasets
(Althoff et al., 2016; Dowling and Rickwood,
2014) were no longer open-sourced for research
usage. Some of the open-sourced datasets such
as DAIC-WOZ (Gratch et al., 2014) contained
small-scale conversations. Recent support-based
datasets (Sharma et al., 2020; Lahnala et al., 2021),
on the other hand, featured pairs of seeker post
and supporter response with no dialogic structure.
Inspired by previous research, we create the Mo-
tiVAte dataset, which was acquired via a peer-to-
peer support platform and is ideal for our objective.
Pyschcentralis a text based support forum where
anonymous individuals can talk about their mental
health problems and get help and advice from oth-
ers who have had similar emotions, troubles, and
grievances. It has various subforums about mental
health, such as MDD, bipolar disorder, anxiety and
panic attacks, schizophrenia, and so on. We gath-
ered 10k multi-party interactions from four distinct
subforums: OCD, Anxiety, PTSD and MDD. A
manual assessment of the raw data confirmed that
the chats were acceptable and can be utilised to
develop a V A after some post-processing.
Data Preparation. The challenge next was to
convert these multi-party dialogues into dyadic
ones, so that they resembled a conversation be-
tween a support seeker (with a mental disability)
and the V A providing mental health support. We
presume that a source conversation starts with a
post by a support seeker known as the poster (say).
The commenters (say) are forum users who make
comments on the poster’s statement. The poster
and the commentators engage in a multi-party con-
versation in order to assist the poster. We worked
with one of the noted psychiatrists, who is cur-
rently working at a government-run hospital of na-
tional importance, to develop standards for chang-
ing multi-party dialogues and confirming the qual-2438ity of the amended dataset. We hired three crowd-
workers for the task of modifying the dialogues
and trained them in an interactive session using
the instructions that had been developed ( Details
of the training session conducted is drafted in the
Supplementary material ). Some of the important
guidelines are as follows : (i)In the modified di-
alogue, the poster in the source conversation be-
comes the support seeker, and the comments of a
specific commenter creating the longest conversa-
tional thread with the poster become the responses
of the V A. From the responses of the poster and
commenter, the crowd-workers were instructed to
develop a turn-by-turn exchange of dialogue be-
tween the seeker and the V A, making the most of
the responses from the source conversation; (ii)The
V As’ response should be helpful and positive, with
the goal of raising the user’s morale. So, negative
utterances from the commenter such as “I know,
nothing can change, we have to struggle through-
out” were changed to exhibit optimism and hope
like “life indeed is a struggle for all, but one needs
to always fight back and be strong in the face of
adversities” etc; (iii)A V A cannot provide medical
advise, even if the poster requests it (as evident in
the source conversation), because we do not advo-
cate that the V A can replace MHP. As a result, in
such a circumstance, the utterances of the commen-
tators providing medicinal advice were completely
eliminated, while utterances such as “I suggest you
to visit a doctor or a psychiatrist before resorting
to such medicines” were incorporated as part of
V A’s response. Following these rules, a total of 7k
dyadic conversations were created ( The process of
rejecting 3k remaining conversations along with
the other guidelines and inter-annotator agreement
are detailed in the Supplementary material ).
4 Proposed Methodology
Problem Definition. The problem statement in-
volves two parts : Firstly , we aim to identify a
textual on-going communication between a sup-
port seeker and the V A as the conversation pro-
gresses in order to detect and differentiate mental
health conditions. For a conversation T, given a
seeker utterance, X= (x, x, ..., x), a con-
versational context/history, C= (c, c, ..., c),
the task is to assign the most appropriate men-
tal illness tag (say y) among a set of tags ( Y=
{y, y, ...y}, where iis the number of disorders
considered). Thus, it is a multi-class classifica-
tion problem. Formally, it can be represented as:y=argmaxF(y|X, C), where F is the
developed classifier. The subsequent or the second
part involves to solve the task of generating the
next textual response of the V A given the seeker
utterance, its context of t−1turns (say) and con-
ditioned on the output y(say) of the mental ill-
ness identification classifier. Formally, given a
seeker utterance, X= (x, x, ..., x), a con-
versational context/history, C= (c, c, ..., c),
where c= (X, Z)and mental illness category,
y, the task is to generate next textual response of
the V A, Z= (z, z, ..., z).
Summarization. While analyzing the dataset,
we observed that the utterances in a dialogue have
longer sequences implying longer context (also ev-
ident from Table 1). Intuitively, an effective en-
coding strategy needs to be employed to counter
loss of information. In this regard, we first sum-
marize each of the utterances of the individual
speakers in every time-step of the dialogue to pre-
serve the content and curate it to be concise for
modeling long-term dependencies. In the absence
of gold-standard summary of utterances, we ob-
tain summaries from a state of the art summa-
rization model named BART-large by Facebook
AI (Lewis et al., 2019). For our setting, we use
the BART-large model fine-tuned on the CNN/DM
summarization dataset (Hermann et al., 2015) to
obtain summaries of the individual utterance of
theMotiVAte dataset. So, for a given utterance,
X= (x, x, ..., x), its corresponding sum-
mary is, M= (m, m, ..., m)(Evaluation
of the summaries obtained is presented in the Sup-
plementary material ). Consequently, we utilize the
summarised version of the dataset for developing
the system (handling longer sequences as in the
original dataset will be dealt as a sub-task in the
future).
4.1 Mental Illness Classification (MIC)
Framework
In this section, we discuss the details of the atten-
tion based classification framework.
Feature Extraction. The classification frame-
work inputs two different kind of features. (i) Em-
bedding Features : To extract textual features of an
utterance Uhaving nnumber of words, the repre-
sentation of each of the words, w, ..., w, where
w∈R,ws are obtained from BERT (Devlin
et al., 2019), where dimension, d= 768 . (ii) Se-
mantic Features : An examination of the dataset
revealed that users who expressed their emotions2439
and pains reflected their overall sentiment to some
level. These details must also be recorded in or-
der to create a more accurate sentence representa-
tion that takes into account the user’s mental state.
We achieved this by using the Vader Sentiment In-
tensity Analyzer (VSIA) to count the number of
positive and negative utterances in each speaker’s
encoding and using them as features. From strongly
negative (-1) to strongly positive (+1), this rating
seeks to convey the overall affect of the entire text.
Network Architecture. Three key components
make up the proposed classification network : (i)
Utterance Encoders (UE) : the features retrieved
above for each of the speakers (here V A and sup-
port seeker) for a particular conversation are fed
into UE which generate relevant speaker encodings,
(ii)Dual Attention Subnetwork (DAS) that encom-
passes self and cross attention, (iii) Classification
Layer (CL) : the output channel for classification
is contained in the CL.
Utterance Encoders. The embedding features
produced for each of the speakers’ utterances (de-
scribed above) are then processed through two dis-
crete Bi-LSTMs for a specific time-step of the con-
versation. For a user level view (say), the final
hidden state matrix for the textual representation of
the utterances is H∈R.drepresents the
number of hidden units in each LSTM and nis
the number of utterances of the respective speaker.
Dual Attention Subnetwork. We employ a sim-
ilar notion proposed by the authors of (Vaswani
et al., 2017), in which attention is computed by
mapping a query and a set of key-value pairs to
an output. The speaker level context encodings
are passed through three fully-connected layers,each termed as queries, Qand keys, Kof di-
mension d=dand values, Vof dimension
d=d. Thus, we obtain two triplets of ( Q, K, V )
as :(Q, K, V),(Q, K, V). These triplets are
then combined in various ways to compute atten-
tion scores for specific reasons.
Self Attention. We compute self attention (SA)
for each of these speaker encoders to learn the inter-
dependence between the current and the previous
part of the same speaker’s conversation. In a sense,
we want to connect distinct positions of utterances
in order to estimate a final representation for each
speaker (Vaswani et al., 2017). Thus, the SA score
for individual speaker level is calculated as :
SA=softmax (QK)V (1)
where SA∈RforSA,SA∈R
forSA.
Cross Attention. Similarly, we compute cross
attention (CA) amongst triplets of the speaker
level encodings to learn interdependence between
speaker queries as :
CA=softmax (QK)V (2)
This is done to relate different positions of the
utterances of the different (cross) speakers and to
identify significant contributions amongst different
speakers for a particular time-step to learn optimal
features for the task. Thus, we obtain two CA
scores as CA∈RandCA∈R.
Attention Fusion. Next, we concatenate each
of these computed SAandCAvectors to obtain
the conversational representation as :
C=concat (CA, CA, SA, SA) (3)
Classification Layer. To identify one of the
mental disorders, the final representation of the2440ongoing discussion received from the DAS mod-
ule is transmitted through a fully-connected layer,
which then connects it to the output channel of the
classifier consisting of output neurons.
4.2 Mental Illness conditioned Motivational
Dialogue Generation (MI-MDG)
Framework
In this section, we discuss the details of the pro-
posed MI-MDG framework.
Text Generation. For a long time, Sequence-
to-Sequence (Seq2Seq) (Sutskever et al., 2014)
and Hierarchical Encoder Decoder (HRED) mod-
els (Serban et al., 2017, 2016) were being used
for different text generation tasks. However, the
main issue with RNN based model is its inabil-
ity to provide parallelization while processing and
is incapable of preserving context at the encoder
side for longer sequences, similar to our case as
explained above. To counter this, we use the Di-
aloGPT (Zhang et al., 2020) model for our task.
DialoGPT is based on the GPT-2 model from Ope-
nAI (Radford et al., 2019), pre-trained on Reddit
conversations. We fine-tune the DialoGPT-small
model on the summarised version of the MotiVAte
dataset. For a given dialogue, we first concatenate
the dialog turns till the kth seeker-V A response pair
along with the context available and speaker identi-
fier into a long text, m, ..., m(N-1 is the
sequence length), ended by the end-of-text token.
To generate responses conditioned on the mental ill-
ness of the support seeker, we also concatenate the
predicted mental illness category (for the kth seeker
utterance from the MIC framework), y(say) as a
mental state identifier after the kth seeker utterance
in the sequence, making the sequence length as
N. With the dialogue history, S=m, ..., m
and the V A utterance (ground truth response) as
T=m, ..., m, the conditional probability
P(T|S)can be written as:
p(T|S) =/productdisplayp(m|m, ..., m, y)(4)
To generate semantically acceptable responses,
the DialoGPT model is first fine-tuned with the neg-
ative log likelihood, i.e., the maximum likelihood
estimation (MLE) objective function in a super-
vised way. This trained model is later initialized to
produce motivational and optimistic responses by
the V A (explained below).
Reinforcement Learning (RL) based Train-
ing. The sequence of tokens in an utterance canbe considered as actions chosen by the DialoGPT
model based on a policy it has learned. The model
is then tweaked using the MLE parameters to learn
a policy that maximises long-term future rewards
(Li et al., 2016). The elements of RL based training
are addressed below.
State and Action. The state is similar to the
input of the DialoGPT model, i.e., context compris-
ing of history and the kth seeker utterance along
with the speaker and mental illness identifiers (ex-
plained above), [ S(H, H, H)] where h,sandy
represent history tokens, speaker and mental illness
category tokens, respectively. The action a, is the
V A response to be generated in the kth time-step,
i.e.,Z. Because the sequence generated might be
of any length, the action space is unlimited. As a
result, the policy, Π(Z|S(H, H, H))is defined
by its parameters and is based on learning how to
map states to actions.
Reward. Here, we discuss the task-specific re-
ward functions, r, used to evaluate the predicted
output Zagainst the true output.
•BLEU Metric Score (r) : This metric ensures
n-gram content similarity (1-gram here) between
the predicted and the true output.
•ROUGE-L Metric Score (r) : This metric
ensures the matching of the longest common sub-
sequence between the predicted and the true output.
•Sentiment Score (r) : For the V A to be mo-
tivational and optimism inducing, the generated
response should exhibit positive sentiment. Since,
emotion focuses on a deeper analysis of human
sensitivities and is based on a wide spectrum of
moods, sentiment provides an overall impression or
view people get from consuming a piece of content.
So, we quantify optimism with respect to being
positively-oriented. The V A should always work
towards uplifting the mood of the user, provide
reliable suggestions which are positively-oriented.
The V A should not oblige with the negative mindset
of the support seeker barred from hope and motiva-
tion from moving forward in life. This will ensure
that the sentiment state of the generated output by
the V A is consistent with the true output. Thus, the
reward is :
r=/braceleftigg
1, ifSC(Z) = + ve
1−ss, ifSC(Z) =−ve(5)
where SCis the pre-trained distillBERT based
uncased model (Sanh et al., 2019), fine-tuned on
the SST-2 English dataset for the sentiment clas-
sification task. ssis the sentiment score obtained
from the classifier.2441Thus, the final reward (R) is the weighted aver-
age of all the above terms as given below:
R= (r∗(1−α−β) +r∗α+r∗β)/3
(6)
where αandβare parameters of the model. Pol-
icy Gradient algorithm (Zaremba and Sutskever,
2015) is used to optimize these rewards. The pol-
icy model Πis initialized using the fine-tuned Di-
aloGPT model (using the MLE objective function).
So, the final loss back-propagated to the DialoGPT
model is a combined objective function as :
L=ηL+ (1−η)L (7)
where LandL are the losses calculated
from the RL and MLE objective, respectively.
5 Experiments
Since the MotiV Ate dataset is imbalanced for dif-
ferent mental illness categories, we sample 50%
of the dialogue from MDD subforum along with
other categories to be utilized in the MIC frame-
work . Thus, the mental illness classification mod-
ule is trained on 5067 conversations, out of which
70% of the dialogues were used for training and
remaining were utilized as test set. To encode dif-
ferent speaker utterances in the MIC framework,
a 300 dimensional Bi-LSTM layer was used. d
is a dense layer of 100 dimension. The four men-
tal health categories are represented by 4 neurons
in the output channels. In the final experiment, a
learning rate of 0.01, textitCategorical crossentropy
loss function, and Adam optimizer were utilised.
All of these parameters were chosen following a
thorough sensitivity study.
For training the MI-MDG framework , MIC
model is used as a pre-trained classifier provid-
ing additional input. For the MI-MDG model, we
decode using default temperature and top-k values
of the DialoGPT model. Adam optimizer is used
to train the model. A learning rate of 0.00004 was
found to be optimum. Standard measures, such
as the BLEU-1 score (Papineni et al., 2002), per-
plexity, ROUGE-L score (Lin, 2004) and embed-
ding based metric (Serban et al., 2017) are used
to automatically evaluate generation-based models.
Three independent human users were recruited to
score the quality of 250 simulated conversational
responses based on these metrics : (i) Fluency :
The V A’s generated responses should be grammati-
cally and syntactically acceptable; (ii) Adaptability
: An effective V A should generate responses based
on the current trajectory of the conversation, i.e.,
what is now being discussed; and (iii) Motivational
: The response generated by the V A should be
positively-oriented imparting hope and motivation.
Finally, we report the average of the human rated
scores across different users.
6 Results and Analysis
A series of experiments were carried out in order
to evaluate the proposed framework.
Evaluation of Summaries. To analyse the qual-
ity of the summaries obtained from the state-of-the-
art BART-large model, we presented 100 conversa-
tions to three human users from authors affiliation
to rate the quality of the summaries on a scale of
1 (worst) to 5 (best) based on two metrics, namely,
fluency : to ensure that the obtained summary at
each time-step of the conversation is syntactically
or grammatically correct; content preservation : to
ensure that the content of an utterance in the con-
versation is preserved in the summarised version.
We report the average of the human rated scores
across different users. Based on the human evalua-
tion, for fluency , we obtained an average score of
4.1, whereas for content preservation , we observed
an average score of 3.65.
MIC Framework. Experiments were conducted
in three different set-up as : for first kseeker ut-
terances, where k= 1,2,andt(here trepresents
the last seeker utterance), along with the available
context of the dialogue in order to analyse the com-
petence of the MIC model in assisting the V A as
the dialogue progresses. Table 2 summarises the2442
findings of the proposed MIC model, as well as
a detailed ablation analysis of its various compo-
nents. As can be seen, textual encoding based on
Bi-LSTM yields the best results in terms of sev-
eral classification criteria. Also, the conversational
level ( k=t) models performed consistently better
with different encoding strategies. This advantage
is self-evident, as the conversational level models,
unlike the other two set-up, have the complete dia-
logue at their disposal to exploit and learn from. As
visible, BERT based embedding features attained
better results in all combinations as compared to
the GloVe embeddings which is in conformity with
the existing literature. The addition of semantic in-
formation, such as utterance wise sentiment polar-
ity, improved the models’ performance consistently
across all model combinations. This demonstrates
that the user’s sentiment is crucial in determining
its mental state. We have also demonstrated the im-
portance of different attentions used for the best per-
forming model, i.e., BERT+Bi-LSTM+Senti . The
results show that each of these factors aided the
proposed MIC framework’s performance signifi-
cantly. The detailed results of the MIC framework
and the baseline models in terms of precision and
recall is reported in the Appendix section . Welch’s
t-test (Welch, 1947) at 5% significance level was
conducted to ensure that all of the presented results
are statistically significant.
We as well report the confusion matrix of the pro-
posed model for the conversational level ( k=t)
set-up to examine the model’s performance in depth
and understand its limits in Figure 3a. As can be
seen, there was a lot of confusion between MDD
and anxiety pairs. The model is limited in its abil-
ity to distinguish between these two illnesses at a
finer level. Even though people experience these in
various ways, they use similar or overlapping termi-
nology to convey their symptoms. The fine-grained
characteristics that identify different illnesses in
terms of text must be investigated in depth and
discovered, and this will be the subject of future
research.
MI-MDG Framework. As the task of motiva-
tional response generation has not been studied pre-
viously, we compare it to baseline approaches from
related tasks such as dialogue generation which are
SEQ2SEQ, HRED and DialoGPT and its varying
combinations. Table 3 shows the automatic eval-
uation results of different baselines and MI-MDG
framework. All of the fine-tuned DialoGPT-based
models outperformed the classic SEQ2SEQ and
HRED models, as shown in the table. This shows
that long-term assimilation of memory for a par-
ticular utterance and across the dialogue was not
appropriately learnt by the traditional SEQ2SEQ
and HRED models due to their inability to capture
context for longer sequences. The models trained to
optimize long-term rewards produced better results
in comparison to DialoGPT without RL training.
This suggests that the RL objective, rather than sim-
ply learning to be accurate at the token level, helped
generate affirmative responses compatible with the
context. This validates the fact that the proposed
MI-MDG framework is capable of generating over-2443
all better responses. In Figure 3b, we report the
results of the MI-MDG and baselines models dur-
ing the human evaluation phase. As evident, the
MI-MDG framework attained the highest average
fluency, adaptability and motivational scores of 3.9,
2.63 and 3.82 respectively. However, all the models
generated moderate replies consistent with the con-
text, thus, demonstrating the need to address longer
context/sequences more effectively. We present
few examples of generated responses from the MI-
MDG and baseline model in Table 4. As evident,
the baseline DialoGPT model without any MIC
input or RL training generated generic responses,
devoid of motivation and unaware of seeker’s men-
tal state. Whereas the MI-MDG framework learnt
a fair trade-off between being consistent with the
seeker’s mental state and providing optimism.
Additionally, to analyse whether the responses
generated are positively-oriented, we report the
sentiment polarities of the generated V A utterances
for different models using an existing sentiment
analyzer, namely, VSIA. The results of the same
is shown in Figure 3a. As visible, all the models
consistently generated positive sentences, more so
for MI-MDG model and for all the baseline models
which are trained with sentiment based RL objec-
tive. This shows that the addition of sentiment
based RL objective aided the model’s capability
to generate positive-oriented responses of the V A.
A thorough qualitative analysis uncovered several
common errors made by the MI-MDG framework.
In few cases, the model kept on repeating phrases
from the ground truth as “ glad that you are busy
keep busy keep busy and do better ”. In some in-
stances, responses were mostly generic (without
optimism and hope imparting expressions) and un-
aligned with the mental state of the seeker such as
for anxiety, OCD due to their fewer representation
in the dataset. Several efforts are being undertaken
to increase the scale of the conversations in the Mo-
tiV Ate dataset after clarifying ambiguities from therejected modified conversations in the future (refer
to Appendix).
7 Conclusion and Future Work
Online mental health support platforms that make
use of peer supporters suffers from the biggest chal-
lenge of effectively training or scaffolding the peer
supporters. In this research, we use AI to propose
a virtual assistant (V A) to provide support seekers
with comfort and mental health support. As a first
step, we created the MotiV Ate dataset, which con-
tains dyadic conversations collected from a peer-
to-peer support network. We mold this system as a
combination of two mechanism : (i) Mental Illness
Classification (MIC) Framework: a dual attention
classifier that outputs the mental disorder category
based on the ongoing dialog between the support
seeker and the V A; and (ii) Mental Illness con-
ditioned Motivational Dialogue Generation (MI-
MDG) Framework: a sentiment driven RL based
motivational response generator conditioned on the
mental state of the seeker. Empirical results, both
quantitative and qualitative validates the efficacy
of the proposed approach. We surmise that this
preliminary step will lead to promising direction
for developing computational models to assist peer
mental health support seekers and allow researchers
to extend works on mental-health which is really
the need of the hour.
Acknowledgements
Author, Dr. Sriparna Saha, acknowledges
the Young Faculty Research Fellowship (YFRF)
Award, supported by Visvesvaraya Ph.D. Scheme
for Electronics and IT, Ministry of Electronics and
Information Technology (MeitY), Government of
India, being implemented by Digital India Corpo-
ration (formerly Media Lab Asia) for conducting
this research.
Privacy and Ethical Concerns. The use of on-
line posts in health forums for psychiatric research2444presents a number of ethical questions about user
privacy that must be addressed (Valdez and Keim-
Malpass, 2019; Hovy and Spruit, 2016). Following
the ethical guidelines established in previous re-
search on various web-based platforms (Benton
et al., 2017), we created our dataset using only
publicly available discussions without using any
personal profile information. Before presenting the
data to the annotators, we manually anonymized
the profile and removed any disclosure of personal
information (if any). Despite the fact that the
chats gathered from the online health forum were
anonymized by their policy, the annotators pledged
not to contact or deanonymize any of the users
or share the data with others. This paper makes
no therapy recommendations or clinical diagnostic
claims. All the copyrights of the data belong to
psychcentral.org. Refer to the supplementary sec-
tion for more details . We also acknowledge that in
designing computational models for mental health
support, there is a risk that responses trying to aid
can have the opposite effect, which can be lethal
resulting in self-harm. Thus, risk mitigation steps
are appropriate in this context. We stress on the fact
that the system does not intend to make any clinical
diagnosis or treatment of the disorder. It focuses
on distinguishing mental state of the seekers based
on semantic and linguistic evidence for the V A to
learn a generation policy. In such cases, even if the
mental disorder is mis-classified, the V A is focused
on providing comfort and motivational support to
the seekers. This is perfectly benign.
References244524462447
A Appendix
Motivational V A : MotiV Ate Dataset The de-
scription of the mental disorders (considered in this
paper) as mentioned in ICD-10 is listed in Table 5.
Interactive Training of Crowd-workers. The
crowd-workers were initially provided with the
entire guidelines for modifying the conversations
along with ten such examples of raw and modified
conversation pair. After this initial training, we
scheduled an hour long phone call with them to
discuss our instruction guidelines. Crowd-workers
also raised questions about the guidelines during
the phone conference, which substantially aided in
resolving any potential issues. We gave them each
20 instances to modify after the phone call (ran-
domly chosen; different for each crowd-worker).
We manually evaluated the modified dyadic con-
versation on those 20 raw multi-party conversa-
tion. We either decided to discontinue with the
crowd-worker (there was one) or gave them further
manual input based on the results of the evaluation.
Crowd-workers actively asked questions depend-
ing on their reservations during the process. We
also ran spot checks on quality beyond the initial
training phase (at least two times for each crowd-
worker; on more than 10 conversation each) to
offer them with additional feedback. This check
on quality was also conducted by the psychiatristwith whom we collaborated for preparing the guide-
lines for modifying the source conversation. His
feedback was also conveyed to the crowd-workers.
Guidelines Prepared. Some of the other impor-
tant guidelines for modifying the conversations
were : (i)The poster’s messages/responses were
changed to remove any references to a group of
people as a whole. For example, phrase such as
“does anyone here go through” was converted to
“do you go through”, similarly “thank you friends
for helping me out” to “thank you for helping me”
and so on. Similarly, a V A cannot respond by shar-
ing its experiences because it is a machine robot
with no life experience to draw on for example,
“I have also faced a similar thing” etc. Also, a
V A cannot refer to the poster about an anonymous
seeker and share the seeker’s experience (seen in
the source conversation), as the communication
between V A and the seeker is meant to be purely
confidential and anonymized. As a result, the com-
menter’s comments or utterances of these patterns
were removed from the conversation in the context
of V A; (ii)In the changed version, source conversa-
tions relating to the original topic of the subforum,
such as MDD, were marked as MDD. We made no
attempt to further categorise the chats by the con-
templated category because we assumed that the
poster would have picked the right category based
on their needs. This is due to the fact that we have
no other evidence to base our analysis on than what
the poster chose for themselves. We recognise that
this is a potential drawback because posters may
not always have the mental health status that they
perceive, and its impact should be examined further
in the future.
Inter-annotator Agreement. The modified con-
versation from each of the crowd-workers were
inter-changed and presented to the remaining
crowd-workers to approve the quality of the mod-
ified conversations (in the sense that the modified
conversations should be aligned with the guide-
lines provided). When any of the quality check
crowd-workers disapproved of a chat that did not
match the standards, it was removed from the Moti-
V Ate dataset’s final set. Only those dialogues were
included in the final set that received unanimous
approval from all crowd-workers. Following this
criteria, we rejected 3k conversations from the 10k
modified conversation and only 7067 conversation
were included in the MotiV Ate dataset. As a re-2448
sult, we observed a 71% inter-annotator agreement,
which is regarded credible. To extend the scale of
the MotiV Ate dataset, we expect to clarify ambigu-
ities in the rejected modified chats in the future.
Ethical Concerns. The acquisition of raw data
and, as a result, the development of the dataset were
done in accordance with all ethical principles or
codes of conduct. Initially, an opinion on data us-
age and privacy was requested from an IPR lawyer
during the data creation stage, and the response
stated that “Section 107 of the U.S. Copyright Law
which provides that “the fair use of a copyrighted
work . . . for purposes such as . . . research, is
not an infringement of copyright. ” Similarly, Sec-
tion 52 of the Copyright Act, 1957 provides that
“fair dealing with any work, for the purposes of
— (i) private or personal use, including research”
does not constitute an infringement of copyright
in the said work. This statutory exception of fair
use/ fair dealing in the website’s content is also
reflected in the Terms of Use of PsychCentral.org:
“provided however, that users may download one
copy of any Content on any single computer and
print a copy of that Content solely for their per-
sonal, private, non-commercial use. ” The use of the
content for research may be deemed to fall within
this exception provided it was “personal, private,
non-commercial use”." . Following that, the current
study is being conducted in collaboration with a
psychiatrist from a nationally recognised institu-
tion. The psychiatrist has assisted us with every
element of this work, including developing data an-
notation criteria and carefully reviewing the quality
of the data.2449