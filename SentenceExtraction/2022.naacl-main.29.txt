
Tom Knoll, Francesco Moramarco, Alex Papadopoulos Korfiatis,
Rachel Young, Claudia Ruffini, Mark Perera, Christian Perstl,
Ehud Reiter, Anya Belz, Aleksandar SavkovBabylonUniversity of AberdeenADAPT Research Centre, Dublin City University{tom.knoll, francesco.moramarco, alex.papadopoulos,
rachel.young, claudia.ruffini, mark.perera,
christian.perstl, sasho.savkov}@babylonhealth.co.uk{r01fm20, ehud.reiter, anya.belz}@abdn.ac.uk
Abstract
A growing body of work uses Natural Lan-
guage Processing (NLP) methods to automati-
cally generate medical notes from audio record-
ings of doctor-patient consultations. However,
there are very few studies on how such sys-
tems could be used in clinical practice, how
clinicians would adjust to using them, or how
system design should be influenced by such
considerations. In this paper, we present three
rounds of user studies, carried out in the context
of developing a medical note generation system.
We present, analyse and discuss the participat-
ing clinicians’ impressions and views of how
the system ought to be adapted to be of value to
them. Next, we describe a three-week test run
of the system in a live telehealth clinical prac-
tice. Major findings include (i) the emergence
of five different note-taking behaviours; (ii) the
importance of the system generating notes in
real time during the consultation; and (iii) the
identification of a number of clinical use cases
that could prove challenging for automatic note
generation systems.
1 Introduction
With the introduction of Electronic Health Records
(EHR), clinicians are required to keep a detailed
record of each patient interaction (Menachemi and
Brooks, 2006). While this creates a wealth of use-
ful data and may lead to better medical outcomes,
Arndt et al. (2017) show that the burden of ad-
ministrative tasks is a major contributor to clini-
cian burnout. To address this, some recent studies
(Zhang et al., 2018; Enarvi et al., 2020; Joshi et al.,
2020; Zhang et al., 2021) propose to use Speech
Recognition to transcribe the audio of a medical
consultation and then to train sequence-to-sequence
models to summarise the transcript into a consul-
tation note (Figure 1). While intrinsic evaluations(Moramarco et al., 2021; Yim and Yetisgen-Yildiz,
2021; Chintagunta et al., 2021; Moramarco et al.,
2022) show that these methods may be effective at
capturing the salient points of a medical consulta-
tion, most studies focus on the technical difficulties
of developing the systems with little consideration
for the Human-Computer Interaction (HCI) and us-
ability challenges involved in putting such a system
into clinical practice. This is especially important
for “human in the loop” systems, like Note Gen-
eration, that still involve manual checking of any
automatically generated content.
In this paper we present methodology and find-
ings of three rounds of user research and design:
(i)Current Note-Taking Discovery to gather user
requirements and initial impressions; (ii) Initial
User Interface (UI) Testing where clinicians were
shown video mock-ups of three potential design op-
tions and asked to provide feedback; and (iii) Mock
Consultations , in which the clinicians interacted
with a Wizard-of-Oz (Dahlbäck et al., 1993) proto-
type, with another clinician acting as the automated
system.
Following these, we developed a Note Genera-
tion system informed by the user studies and car-
ried out a live test with five clinicians who used the
system to aid them in the task of writing a consul-
tation note for each consultation. The experiment
lasted three weeks, during which over 300 consul-
tations were carried out with the system.
We document the insights gathered through in-
terviews, post-consultation surveys, and analysis
of the generated notes, reporting the major require-
ments for developing a Note Generation system
into a useful product while highlighting the impor-
tance of user research and design alongside NLP
research. Among our main findings are the emer-
gence of five note-taking behaviours (Figure 2) and
the need for the Note Generation system to produce
output in real time during the consultation. We also
identify three clinical use cases that could prove409
challenging to a Note Generation system: patient
dishonesty, multiple presenting complaints, and
clinicians’ non-verbal observations.
2 Related Work
The task of automatically generating consultation
notes from clinician-patient interactions is rapidly
gaining interest in the research community (Zhang
et al., 2018; MacAvaney et al., 2019; Enarvi et al.,
2020; Joshi et al., 2020; Chintagunta et al., 2021;
Yim and Yetisgen-Yildiz, 2021; Moramarco et al.,
2022; Zhang et al., 2021). The prevalent methods
employ pre-trained, generic summarisation mod-
els and fine-tune them on dedicated datasets of
consultation transcripts and corresponding notes.
However, the two tasks have differences; in particu-
lar, Note Generation has a component of language
translation as well as summarisation, whereby the
note uses medical terminology and inferred state-
ments that aren’t present in the original transcript
(Figure 1 and Table 2 for examples). Therefore,
generic summarisation evaluation methods and UX
principles may not apply to this task.
Some of the Note Generation studies include an
intrinsic human evaluation of the generated con-
sultation notes to measure common Natural Lan-
guage Generation (NLG) criteria such as accuracy,
fluency, and completeness; also, Moramarco et al.(2021) propose post-editing as a way clinicians may
incorporate the generated notes into their work-
flows. However, there is very limited work on user
needs, design decisions, and system requirements
for a note-taking tool to be useful in live clinical
practice. In this paper, we aim to address these
questions for the task of medical note generation.
In the broader medical domain, there has been
a marked increase in studies on the interaction be-
tween human users and different tools with clini-
cal applications since 2013 (Stowers and Mouloua,
2018), with usability-related studies making up
25% of them. Clarke et al. (2013) review 17 papers
that identify human-computer interaction (HCI) is-
sues in the use of Electronic Health Records in med-
ical practice, and categorise them into four types:
poor display of information, cognitive overload,
navigation issues and workflow issues. Jalil et al.
(2019) investigate the UX experience of patients
managing their type 2 diabetes with an in-home
monitoring device. The authors conduct a contex-
tual inquiry followed by semi-structured interviews
with 9 patients and report the patients’ experiences
and emotions while using the device, perceived ben-
efits and limitations. Megges et al. (2018) present a
usability study of wearable GPS devices for people
with dementia. The study ran for 4 weeks and com-
prised two alternative devices and 17 participants.
It measured clinical effectiveness, revealed a clear
preference for one of the two devices, and informed
subsequent design decisions (such as software fea-
tures, buttons, and battery life).
In the NLG space, Reiter et al. (2003) conduct a
clinical trial with 2553 smokers to show whether
system-generated tailored cessation letters would
be more effective than a generic cessation letter
written by medical practitioners. Portet et al. (2009)
carry out a clinical off-ward experiment in a Neona-
tal Intensive Care Unit where medical practition-
ers compare the effect on decision-making that a
data-to-text system has versus human expert tex-
tual descriptions of neonatal signals. Bickmore
et al. (2009) describe an animated, empathic virtual
nurse interface for counseling hospital patients with
low health literacy. Their results indicate patients
found the system easy to use, were satisfied with
the system, and most said they preferred receiving
the discharge information from the agent over their
doctor or nurse.4103 UX Exploration
This work was conducted at Babylon, a digital
healthcare company that employs clinicians to
carry out virtual, video consultations with patients
through a platform referred to as the Clinical Por-
tal. As part of their workflow, Babylon clinicians
write medical notes for each consultation; the notes
are useful for any future healthcare professionals
interacting with the patient, but they are also made
available to the patient after the consultation and
serve as a medico-legal record of the interaction.
In order to investigate the value of a Note Gen-
eration system and to design an interface that best
supports clinicians, we carried out three experi-
ments with the following aims: (i) learning about
the clinicians’ current note-taking behaviours (Sec-
tion 3.1), (ii) gathering their initial thoughts about
Note Generation systems using low-fidelity designs
(Section 3.2), and (iii) collecting hands-on insights
from using fully interactive designs (Section 3.3).
The research participants throughout the study
were all UK clinicians with diverse backgrounds
and at least one year’s experience working at Baby-
lon, who regularly used the Clinical Portal to carry
out consultations with patients. As part of our
ethical consideration, we obtained consent from
the participants to use their feedback for research
and development (excluding marketing purposes).
Their time was paid at £70 per hourand they were
aware they could withdraw at any point.
3.1 Phase One: Current Note-Taking
Discovery & Initial Reactions to Note
Generation
Prior to the creation of any interface designs for
the Note Generation system, we conducted a round
of user research to get a detailed understanding of
how the clinicians currently record notes during
consultations, their thoughts about the tools they
use, factors that impede effective note-taking, and
initial impressions on using Note Generation sys-
tems to support note-taking.
3.1.1 Methods
Seven UK clinicians (four women and three men)
across multiple clinical disciplines, including five
UK General Practitioners (GPs) and two Advanced
Nurse Practitioners, participated in 60-minute one-
on-one interviews with a User Researcher (the leadauthor). The focus of these sessions was to under-
stand current note-taking behaviours. Discussion
topics included:
• What constitutes a “good note”
• The format and structure of consultation notes
•Balancing note-taking and interacting with pa-
tients
• Time management and note-taking
• Reviewing notes prior to submission
• Role of note-taking in decision making
•Initial thoughts about supporting note-taking
with automated systems
The study was carried out through semi-
structured interviews, with a list of pre-determined
open questions we asked all participants. One or
two note-takers were present in each interview, tran-
scribing everything the participant said. The video
and audio of the interviews were also captured (for
reference should the notes not be clear or detailed
enough). All qualitative feedback was then anno-
tated with a standard UX software, Dovetail.
3.1.2 Findings
The research sessions revealed several insights that
influence the way consultation notes are captured:
•Six of the seven participants said that having
limited consultation time (typically ten minutes
in the UK) forces them to capture notes while
talking to the patient, rather than waiting until
after the call to write up their notes. This is
because delaying note-taking until after the call
would make them late for their next appointment.
They reported they would prefer to dedicate their
full attention to the patient during the call, rather
than having to capture notes simultaneously.
•In order to minimise the amount of manual typ-
ing required to write up consultation notes, two
clinicians reported using text expanders (Lackey
et al., 2014) (macros that trigger a pre-written
section of text when a keyword is typed), three
use pre-written templates (such as Word doc-
uments, created by clinicians themselves, that
they copy and paste from), and one clinician
uses dictation software to speed up the creation
of action plans.
•Two out of the seven clinicians find value in
the manual act of note-taking to help them or-
ganise their thought processes and guide them411
towards a suitable action plan. However, the
remaining five clinicians saw note-taking as a
record-keeping exercise rather than something
that improves their medical decision making. To
these clinicians, having to type up notes is an
administrative task that takes up time they would
rather be spending with patients.
•All participating clinicians reported that they
review the notes that they have taken before fi-
nalising a consultation (which is most often after
the end of the call with the patient). Common ed-
its during this review include resolving spelling
and grammatical errors, restructuring some of
the notes and expanding any placeholder text
they might have added.
•Finally, clinicians identified some areas that
could be hard to handle for an automatic Note
Generation system:
–Patient dishonesty. In some cases, patients
could withhold information or exaggerate
their symptoms (Palmieri and Stern, 2009).
According to six of the seven participants,
recording notes in situations where they be-
lieve a patient is being dishonest is challeng-
ing, as Babylon patients have access to the
consultation notes. Clinicians need to be
diplomatic and avoid conflict while still mak-
ing sure that the notes accurately reflect their
own justification for diagnosis and treatment
decisions.
–Multiple presenting complaints. Some-
times, patients seek advice for multiple medi-
cal issues. Two clinicians mentioned trying to
dissuade patients from doing this. However,
all clinicians reported they would attempt to
address additional patient problems if time al-
lows. Five of them explained they would deal
with this by separating the notes for different
medical issues into separate paragraphs.–Non-verbal communication. All clinicians
mentioned their notes often include informa-
tion that is not verbalised, such as observa-
tions from that patient’s video feed or their
general demeanour; such information would
be impossible for a Note Generation system
to capture.
The research also revealed five note-taking be-
haviours that were adapted into mini personas (Fig-
ure 2). These personas have persisted throughout
the research studies, with all observed clinicians
fitting comfortably into one or more of the five cat-
egories. In all subsequent studies described in this
paper, approximately 90% of interviewed clinicians
fall under the “Touch-Typer”, “Sketcher”, or “Doo-
dler” personas. This provided focus for the types
of note-taking behaviours that a Note Generation
system could help to support.
3.2 Phase Two: Initial UI Testing
With a better understanding of current note-taking
behaviours, an initial low-fidelity design for the
system interface was created to gather clinician
feedback. Due to the complexity of actually imple-
menting a Note Generation system in real clinical
practice, a video mock-up of the design was shown
to clinicians.
3.2.1 Methods
Five Babylon clinicians (all GPs, three women and
two men) who were uninvolved in the previous
round of research participated in 60 minute one-
on-one semi-structured interviews (following the
study design described in Section 3.1.1). They were
asked to provide feedback on the general concept
of Note Generation and on three potential design
directions for the Note Generation system. The
three design variations (Figure 5 in the Appendix)
simulated how Note Generation content could be412made available to them during consultations and
were presented to the clinicians as videos of mock
consultations. The variations were:
•Design 1: A full live transcript of the conversa-
tion between the patient and the clinician being
shown in near real time. At the end of the call,
the Note Generation system would produce a
note based on the entire transcript, and the note
would additionally appear on screen (Figure 5a).
•Design 2: No real time output during the call.
At the end of the call, the Note Generation sys-
tem would produce a note based on the entire
transcript, and only that note would appear on
screen (Figure 5b).
•Design 3: The Note Generation system would
produce a note and show it on screen during
the call in near real time using the transcript
available up to that point (Figure 5c).
3.2.2 Findings
Overall, all clinicians found the concept of the Note
Generation system useful and believed that a tool
that could produce consultation notes would help
them to focus more on their patients due to the re-
duced need for them to type simultaneously. How-
ever, they also raised concerns about perceived lim-
itations of a Note Generation system, including the
worry that it would take control of the notes away
from them; that it may just be a straight transcrip-
tion service; and that it may fail to capture notes
with medical terminology and instead report layper-
son’s terminology (Table 2 in the Appendix shows
the stylistic differences of transcripts and notes).
Contrary to our initial belief that the main value
of a Note Generation system would be time-saving,
all clinicians felt that the tool would be more use-
ful in improving the quality of the consultation by
allowing them to focus more on the patient.
When shown the potential designs, all clinicians
reacted negatively to the verbatim transcript being
shown on their screen (Design 1), as it would be too
distracting due to the large amount of text and infor-
mation and the inherent delay of displaying each
sentence. Furthermore, all clinicians expressed
concerns at having to wait until the end of the con-
sultation for the generated note to appear (Designs
1 and 2) as they wouldn’t know whether the model
was capturing all the salient points. The real time
note display of Design 3 was strongly preferred, as
it would allow them to easily check whether themodel is correct during the consultation; the real
time note could also act as a cognitive artefact, re-
minding them what they’ve already asked. This
finding indicates that the output speed of the Note
Generation tool might impact clinician uptake; if
too slow, clinicians would need to revert back to
manual note-taking to avoid missing important pa-
tient information.
3.3 Phase Three: Mock Consultations using
Wizard of Oz
Up to this point, Babylon clinicians had been pro-
viding feedback on designs without being able to
interact with the system in any way. In order to
allow clinicians to experience what using a Note
Generation system might actually be like, we used
a Wizard-of-Oz approach. This was an inexpensive
way to allow hands-on interaction as well as a bet-
ter replication of the complex nature of real-world
consultations.
3.3.1 Methods
Five Babylon GPs (four women, one man) who
were uninvolved with any of the previous rounds
of research were recruited for 90 minute one-on-
one workshops. They were asked to conduct
mock consultations with a remote patient, using
a mocked-up representation of the Clinical Portal,
with a prototype version of the Note Generation sys-
tem available to them to support their note-taking.
We then conducted semi-structured interviews to
gather their feedback (following the study design
described in Section 3.1.1).
The Clinical Portal mock-up, with an additional
section for displaying the generated notes, was
recreated in Google Slides, which was chosen
as a freely available application allowing multiple
users to edit a document simultaneously. The clini-
cian (research participant) was able to record their
own manual notes as well as having the option to
supplement these with the Note Generation out-
put. Behind the scenes, the generated notes were
not produced by an automated system, but by an-
other Babylon clinician, the ‘Wizard’ (one of the
authors), who had been instructed to respond as the
Note Generation system would: to insert the notes
(one sentence at a time) in the mock Clinical Portal
by editing the appropriate field.
In order to make the job of the Wizard easier, the413
patient (an actor) was asked to present with one
of a series of predefined medical complaints that
were tightly scripted on case cards; this allowed the
Wizard to use pre-written responses that matched
with the script being followed by the patient.
In total, the five clinicians (research participants)
were each able to conduct three mock consultations
over video call which spanned common primary
medicine topics: urinary tract infection, sinusitis,
and mental health. A diagram of the above setup
can be found in Figure 3.
3.3.2 Findings
The interactive research sessions revealed a number
of Note Generation usage patterns:
•We observed that all clinicians’ first consulta-
tions were more disjointed, as they were glanc-
ing at the system output from time to time in-
stead of focusing on the patient. In subsequent
mock consultations, they took fewer manual
notes and relied more on the system. By the
end of the research session all clinicians were
observed to use parts of the automated notes in
their own note-taking.•After using the system, two clinicians reported
that the generated note output speed was too
slow. When asked, all clinicians mentioned that
a close to real time speed would be highly de-
sirable, as it would allow them to confirm that
important information has been captured by the
Note Generation system before the conversation
moves onto another topic.
•Based on the way they interacted with the Note
Generation system output, we categorised the
participating clinicians in three different styles,
described in Figure 4. All clinicians were ‘Post-
Call Comparers’ in their first mock consultation;
yet, by their last consultation, 40% of them used
the Real-Time Augmenting style, with the rest
divided between ‘Post-Call Comparers’ (35%)
and ‘Real-Time Observers’ (25%).
•When prompted, all research participants re-
ported that the Note Generation system output
was of value to the note-taking process.
•Two clinicians were observed reading the gener-
ated note back to the patient towards the end of
the call as a way of confirming the notes matched
the patient’s perspective.
•Clinicians either copied the whole generated
note before post-editing it (two thirds of all con-414
sultations), or copied selected statements into
their own notes (one third of all consultations).
4 Note Generation system
The UX Exploration detailed so far gave us, among
other insights, indications that: (i) a Note Gener-
ation tool could be of value to clinicians; (ii), it
would need to generate notes in real time, in order
for clinicians to evaluate its output as the consulta-
tion is progressing; and (iii), clinicians would still
want to be able to take manual notes during the
consultation.
Prior to this UX Exploration, we had developed a
Note Generation system based on a publicly avail-
able BART sequence-to-sequence model (Lewis
et al., 2020) pre-trained on the CNN summarisa-
tion dataset (Nallapati et al., 2016), which we fur-
ther fine-tuned on a proprietary Babylon dataset
of 10,000 transcripts and consultation notes. In
Moramarco et al. (2022) we detail a non-production
evaluation of the system, and in Papadopoulos Kor-
fiatis et al. (2022) we release the mock transcript
and note dataset used to evaluate it. Examples of
model inputs and outputs from this mock dataset
can be found in Appendix A.2.
The following modifications were made as a re-
sult of the three studies in the UX Exploration:
•The previous system could only generate
notes in an end-to-end fashion from the com-
plete consultation transcript. This is not com-
patible with the clinicians’ preferred design,
so we retrained the model to produce notes
from incremental chunks of the transcript.
This was achieved by mapping sentences of
the notes and sentences of the transcript witha similarity function and generating incremen-
tal training pairs for each consultation. This
system will only append text to the previously
generated note, preserving anything that the
clinician might have previously validated.
•Automatically generated notes often contain
inaccuracies or omissions (Moramarco et al.,
2022). Using a Note Generation system in a
live clinical setting might mislead the clinician
into introducing errors in their consultation
notes or influence the clinical decision making
process. In order to mitigate those risks, we
re-trained the Note Generation system to only
generate the history and examination portions
of the notes (Pearce et al., 2016), preventing
it from producing any diagnosis or treatment
advice by removing it from the training data.
5 Live Test
In order to test the usability of the updated Note
Generation system in clinical practice, we incorpo-
rated the real-time system into the Clinical Portal
and allowed a limited number of clinicians to use
it in a supervised environment for a period of three
weeks. Our goal from this live test was to answer
the following questions:
•How well is the Note Generation system able to
cope in a live setting?
•How many consultations does it take clinicians
to start making use of the output from the Note
Generation system?
•Are there any safety issues that need to be ad-
dressed?
•What is the current and potential value of the
Note Generation system during consultations?415•Are there any usability issues that need to be
addressed?
5.1 Methods
In order to maximise the learnings from the live test,
the research approach needed to allow us to observe
the Note Generation system being used live, ask
follow-up questions and understand the clinicians’
overall experience. The research approach for the
live test had the following steps:
•Interviews with clinicians before and after the
three week live test.
•Weekly observation of clinicians using the Note
Generation system during real-world consulta-
tions.
•A post-consultation survey on the use and value
of the system during that particular consultation.
•Ad-hoc questions about the clinician experience
so far via private messages.
•Analytics on the Clinical Portal (such as UI event
timestamps) to quantify Note Generation system
usage.
As the Note Generation software is a clinician-
facing tool and falls under Babylon normal service
delivery, the patients were not participants of the
live test. However, for all consultations observed,
explicit consent to do so was obtained from the
patients (consent form in Appendix A), and the
observations were completely passive (no interac-
tion) to minimise inconvenience and distress both
to patient and clinician. As an extra mitigation for
any generated note inaccuracy, we also clearly in-
structed clinicians to continue manually recording
the key information of the consultation.
Five Babylon clinicians (GPs, three women, two
men) were invited to participate in the three-week
live test. The inclusion criteria were: (i) UK clin-
icians having worked at Babylon for at least 6
months, (ii) consulting at Babylon for at least 10
hours a week, (iii) willing to use the Note Genera-
tion system during their consultations for the three-
week period, (iv) agreeing to have a small number
of their consultations with patients observed by the
researchers, (v) minimum bandwidth (download
5Mb/s, upload: 3Mb/s; to support the observing
researchers), (vi) be willing to participate in all our
research activities related to the project (such as
the interviews and post-consultation surveys). The
participants’ time in consultations was under their
normal working hours at Babylon. The extra timeParticipant # Cons. % copied Overlap
A 101 97% 50%
B 81 23% 13%
C 69 42% 22%
D 18 50% 34%
E 38 13% 19%
for interviews and training was paid at the study
standard rate.
Prior to the start of the live test, the clinicians
were provided with 60 minutes one-on-one up-front
training on how to use the tool. The training con-
sisted of showing them videos of the Note Genera-
tion system during a mock consultation, warning
them that the system is not able to capture non-
verbal observations, and that the medico-legal re-
sponsibility for the notes still rested with them (the
clinicians). They were then provided with access
to the Note Generation system and enabled to use
it during their real-world consultations. Through
initial interviews, we gathered that three of our
participants fit in the Sketchers note-taking style;
one in Doodlers; and one in Touch Typers (see Fig-
ure 2). Throughout the experiment, we observed a
total of 4 hours of live consultations for each clini-
cian. Finally, we collected their summary feedback
through 60-minute, one-on-one closure interviews.
5.2 Findings
Here are the key points uncovered by observing
and interviewing the clinicians using the Note Gen-
eration system in live practice:
•In the initial observation sessions, all clinicians
took manual notes, ignoring the output of the
Note Generation system. However, by the end
of the experiment, all clinicians were making
use of the generated notes by copying them at
least partly into their notes. Copying occurrence
varied between clinicians (see Table 1).
•During difficult consultations (for example, con-
sultations with multiple interconnected medical
issues, over-explaining patients, or mental health
cases), we observed all clinicians reverting to416manual note-taking instead of using the Note
Generation output.
•Analysis of the notes showed that clinicians al-
ways made amendments to the Note Generation
output before using it. These included: fixing
any identified errors, reorganising the output
into distinct paragraphs, changing references of
days to dates (‘on Saturday’ -> ‘14/01/21’), and
changing the use of pronouns to match their pre-
ferred style.
•In order to measure the impact of the Note Gen-
eration tool, we asked all clinicians the following
questions both before and after their usage of the
tool. The answers to these questions were col-
lected through a rating scale (from very difficult
‘1’ to very easy ‘10’); we report the average for
all 5 clinicians.
–How easy is it to write up your notes within
the ten minutes allocated for the consultation?
(before: 4.8, after: 5.5)
–How easy is it to focus on the patient during
consultations? (before: 6.2, after: 8.3)
–How easy is it to multitask during consulta-
tions with patients? (before: 5.8, after: 6.8)
•Finally, when asked in the post-experiment in-
terviews, all clinicians reported that they would
like to continue using the Note Generation tool
in their clinical practice.
6 Discussion and Conclusion
In this paper we presented a series of user re-
search studies and described how they influenced
the development of a Natural Language Processing
system for automatically generating consultation
notes.
Some of the main challenges in putting such
a system into clinical practice are not due to the
system’s technology or limitations, but instead to
the user experience design choices around it. User
research and live testing is essential to ensure the
system is actually useful for clinicians. Among the
list of tools available, we found that a low-fidelity
Wizard-of-Oz prototype was both incredibly valu-
able to gather hands-on feedback from clinicians
and significantly easier to implement than a func-
tional product prototype.
More specifically, the need to generate notes
in real time is a requirement that was identifiedthrough the UX Exploration and confirmed in both
the Wizard-of-Oz and live test phases. To our
knowledge, this has not been covered in similar
studies and we believe it will be a key challenge
for future systems. Similarly, the user interviews
uncovered three clinical use cases that could prove
challenging to a Note Generation system: patient
dishonesty, multiple presenting complaints, and
clinicians’ non-verbal observations.
We observed an interest for the tool beyond the
live test, even from clinicians who were initially
skeptical of automatically generated notes. We
also highlight the individual differences in personal
note-taking styles, which mean that clinicians use
it in different, but still valuable ways.
One limitation of our work so far is the relatively
small sample of clinicians (no more than 7 in each
round) and the short time frame (3 weeks) in which
they used the tool in our live test. The results we
present from three weeks of live testing might not
be representative of long-term usage of the Note
Generation tool. Another limitation is that the de-
sign, based on data and processes from the UK,
may not transfer easily to other regions without
substantial changes.
In conclusion, we find that user experience stud-
ies, currently not commonly carried out in NLP
research, revealed essential requirements for the
design of our Note Generation system. We believe
that to design an interactive tool it is crucial to
test with active users from the start and hope that
this work may help further studies in the field of
medical Note Generation.
Acknowledgements
We would like to thank all the clinicians who par-
ticipated in the UX studies and the live test of the
Note Generation system. We are grateful to Oriol
Valldeperas for the beautiful diagram of the Wizard
of Oz setup. Lastly, a warm ‘thank you’ to all the
patients who have consented to their consultations
being observed for the purpose of this study.
References417418419A Appendix
A.1 Patient consent form
The following is the consent form we obtained from patients prior to a consultation observation.
“At Babylon, we sometimes have training doctors and support staff observe our clinics for learning
how we use our internal systems. I have [X] participants observing today who have completed all relevant
security checks and received specific training to enable them to safely observe consultations. So before we
continue, we always check consent with patients - are you happy to proceed?”
A.2 Example mock transcript and corresponding note
Transcript Note
Clinician So, um, tell me what’s been going on. You’ve been
saying there’s a problem with your hearing. Is that right?History:
Hx of difficulty hearing left ear
for 6 weeks with tinnitus and
slight nausea/ dizziness.
One previous similar episode in
the past- resolved spontaneously.
No discharge/fever/itchiness/pain
Doesn’t use cotton wool buds
No Pmhx of note
Ex: Looks well, not in pain.
Imp: need to exclude impacted
wax in ear canal first
Pln: for face to face GP
appointment in 5 days to examine
ear
If any problems in interim to
ring us back
Pt happy with and understands
planPatient Yeah, so I just feel I can’t really hear as well as I used
to, like my hearing is kind of deteriorating in some way.
Clinician Right, OK. How long has this been going on for?
Patient Uh about six weeks.
Clinician Six weeks, OK. Um, and before that have you had any
hearing problem at all?
Patient Um I had something maybe, about a year ago, but it only
lasted a couple of days, it wasn’t anything as long as
this.
Clinician Right, OK, OK. And, um, in this six week period, have
you had anything else happen? Have you had any other
ear symptoms at all?
Patient Um, I occasionally get like a ringing in my left ear, uh
just on the one side and um there’s actually been a few
times when I felt kind of a bit sick or a bit dizzy as well.420421