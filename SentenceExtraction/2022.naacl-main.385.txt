
Le Zhang
Fudan University
zhangle18@fudan.edu.cnZichao Yang
CMU
yangtze2301@gmail.com
Diyi Yang
Georgia Tech
dyang888@gatech.edu
Abstract
Data augmentation is an effective approach to
tackle over-fitting. Many previous works have
proposed different data augmentations strate-
gies for NLP, such as noise injection, word
replacement, back-translation etc. Though ef-
fective, they missed one important characteris-
tic of language–compositionality, meaning of a
complex expression is built from its sub-parts.
Motivated by this, we propose a compositional
data augmentation approach for natural lan-
guage understanding called TreeMix. Specifi-
cally, TreeMix leverages constituency parsing
tree to decompose sentences into constituent
sub-structures and the Mixup data augmenta-
tion technique to recombine them to generate
new sentences. Compared with previous ap-
proaches, TreeMix introduces greater diversity
to the samples generated and encourages mod-
els to learn compositionality of NLP data. Ex-
tensive experiments on text classification and
SCAN demonstrate that TreeMix outperforms
current state-of-the-art data augmentation meth-
ods.
1 Introduction
Data augmentation (DA) has won great popular-
ity in natural language processing (NLP) (Chen
et al., 2021; Feng et al., 2021) due to the increas-
ing demand for data and the expensive cost for
annotation. DA aims at increasing the quantity
and diversity of the datasets by generating more
samples based on existing ones, which helps make
the training process more consistent and improves
the model’s capacity for generalization (Xie et al.,
2020). For instance, existing DA methods often
leverage word-level manipulation (Wei and Zou,
2019; Kobayashi, 2018; Karimi et al., 2021) and
model-based sentence generation (Edunov et al.,
2018; Ng et al., 2020). As mixup-based (Zhang
et al., 2018) augmentation achieving huge success
in computer vision (Yun et al., 2019; Uddin et al.,
2021; Kim et al., 2021), some recent works start
Table 1: Input-level DAs for Text-Classification. EDA
includes random deletion, swapping, and insertion.
AEDA randomly inserts punctuation. SSMix swaps
tokens based on their saliency. The replacement method
randomly substitutes words with synonyms. In Back-
translation, the source sentences are first translated into
another language, and then back again.
to adapt mixup to NLP, such as at the hidden level
(Guo et al., 2019; Chen et al., 2020b) and at the
input level (Yoon et al., 2021; Shi et al., 2021).
Despite these empirical success, DA methods
still suffer from key limitations. Simple rules
based augmentation methods (Wei and Zou, 2019;
Kobayashi, 2018; Karimi et al., 2021) show little
to none effect over large pretrained language mod-
els. While mixup-based augmentation methods
demonstrate huge potential, such interpolation at
the hidden or input level has limited capability to
capture explicit linguistic properties in text (Guo
et al., 2019; Chen et al., 2020b; Yoon et al., 2021).
Moreover, current DA methods exhibit limited abil-
ity in compositional generalization. Take a look at
the following example from a BERT-based model
that is fine-tuned using the SST2 dataset from the5243GLUE Benchmark:
The first two examples are correctly classified. De-
spite that the last one is composed of fragments
from the first two, the model fails to produce a
correct or plausible label (in terms of characteriz-
ing a sentence’s sentiment), demonstrating poor
performance in compositional generalization.
However, compositionality is one key aspect of
language that the meaning of a complex sentence is
built from its subparts. Prior work also shows that
syntax trees (e.g., tree-based LSTMs) are helpful
to model sentence structures for better text clas-
sification (Shi et al., 2018). However, leveraging
compositional structures for data augmentation has
not received much attention in the language tech-
nologies communities, with a few exceptions in
semantic parsing (Andreas, 2020; Herzig and Be-
rant, 2021).
To this end, we propose a compositional data
augmentation method for natural language under-
standing, i.e., TreeMix (Figure 1). TreeMix is an
input-level mixup method that utilizes constituency
parsing information, where different fragments
(phrase of a subtree) from different sentences are re-
combined to create new examples that were never
seen in the training set; new soft labels will also
be strategically created based on these fragments
at the same time. In this way, TreeMix not only ex-
ploits compositional linguistic features to increase
the diversity of the augmentation, but also provides
reasonable soft labels for these mixed examples.
Empirically, we find that TreeMix outperforms
existing data augmentation methods significantly
on a set of widely used text classification bench-
marks. To validate the compositional effective-
ness of TreeMix, we experiment with SCAN (Lake
and Baroni, 2018)—a task requires strong compo-
sitional generalization, and find that TreeMix ex-
hibits reasonable ability to generalize to new struc-
tures built of components observed during training.
2 Related Work
2.1 Generic Data Augmentation
Most prior work operates data augmentation at dif-
ferent levels (Chen et al., 2021). Token-level DAmethods manipulate tokens or phrases while pre-
serving syntax and semantic meaning as well as
labels of the original text, such as synonymy words
substitutions (Wang and Yang, 2015; Zhang et al.,
2015; Fadaee et al., 2017; Kobayashi, 2018; Miao
et al., 2020) where synonyms are detected follow-
ing pre-defined rules or by word embedding simi-
larities. These methods has limited improvement
(Chen et al., 2021) over large pretrained language
models (PLMs). Besides, introducing noise by
random insertion, replacement, deletion, and swap-
ping (Wang et al., 2018; Wei and Zou, 2019; Karimi
et al., 2021; Xie et al., 2020) is expected to improve
the robustness of the model. Sentence-Level DA
methods increase the diversity by generating dis-
tinct examples, such as via paraphrasing (Yu et al.,
2018; He et al., 2020; Xie et al., 2020; Kumar et al.,
2020; Chen et al., 2020b; Cai et al., 2020) or back
translation (Sennrich et al., 2016; Edunov et al.,
2018). Other line of work used label-conditioned
generation methods that train a conditional gener-
ation model such as GPT-2 or V AE to create new
examples given labels as conditions (Bergmanis
et al., 2017; Liu et al., 2020b,a; Ding et al., 2020;
Anaby-Tavor et al., 2020). Although these methods
can produce novel and diverse text patterns that do
not exist in the original datasets, they require exten-
sive training. Hidden-Level DA methods mainly
manipulate hidden representations by perturbation
(Miyato et al., 2019; Zhu et al., 2020; Jiang et al.,
2020; Chen et al., 2020c; Shen et al., 2020; Hsu
et al., 2017, 2018; Wu et al., 2019; Malandrakis
et al., 2019) and interpolation like mixup (Zhang
et al., 2018) to generates new examples (Miao et al.,
2020; Cheng et al., 2020; Chen et al., 2020b; Guo
et al., 2019, 2020; Chen et al., 2020a).
2.2 Compositional Data Augmentation
Compositional augmentation aims at increasing the
diversity of the datasets and improving the com-
positional generalization capability of the result-
ing models (Jia and Liang, 2016; Andreas, 2020).
These methods often recombine different compo-
nents from different sentences to create new exam-
ples following a set of pre-designed linguistic rules
such as lexical overlaps (Andreas, 2020), neural-
symbolic stack machines (Chen et al., 2020d), and
substructure substitution (Shi et al., 2021). Compo-
sitional methods have been applied in a set of NLP
tasks, such as sequence labeling (Guo et al., 2020),
semantic parsing (Andreas, 2020), constituency5244
parsing (Shi et al., 2020, 2021), dependency pars-
ing (Dehouck and Gómez-Rodríguez, 2020; Shi
et al., 2021), named entity recognition (Dai and
Adel, 2020), text generation (Feng et al., 2020),
and text classification (Yoon et al., 2021; Shi et al.,
2021). Our work also falls into this category.
The most relevant are Shi et al. (2021) and
Yoon et al. (2021). However, Shi et al. (2021)
only performs constituent substructure combina-
tions with examples from the same category, thus
inadequate in creating diverse enough augmenta-
tion with newly created labels.
Besides, Yoon et al. (2021) simply swaps the
most and least salient spans, heavily relying on the
model’s performances in estimating salient spans,
and failing to consider these sentences’ linguistic
structures. Our proposed TreeMix fills these gaps
by allowing the composition of sentences from dif-
ferent label categories, by utilizing rich consistency
based structures in text, and by strategically gener-
ating soft labels for these augmented instances.
3 Method
Our work is motivated by Mixup (Zhang et al.,
2018), which creates virtual samples by mixing
inputs. Given two random drawn examples (x,y)
and(x,y), where xdenotes the input sample and
yis the corresponding one-hot label, Mixup creates
a new sample by:
x=λx+ (1−λ)x,
y=λy+ (1−λ)y,
where λ∈[0,1]. Mixup can be easily implemented
in continuous space, hence some prior works (Chenet al., 2020b) have extended it to NLP by perform-
ing interpolation in hidden space.
We improve upon Mixup by incorporating com-
positionality of language, a key characteristic that
is essential to generalization but neural models of-
ten fall short in capturing (Lake and Baroni, 2018).
Instead of interpolating with the whole sample,
TreeMix, our newly proposed method, creates new
sentences by removing phrases of sentences and
reinserting subparts from other sentences. TreeMix
makes use of constituency trees to decompose a
sentence into meaningful constituent parts, which
can then be removed and recombined to generate
new augmentation samples. We aim to improve
models’ compositionality generalization ability by
training on large amount of samples produced by
TreeMix. An example of using TreeMix for single
sentence classification is shown in Figure 1.
3.1 TreeMix
Letx={x, x, ..., x}denotes a sequence with
length land its corresponding label in one-hot en-
coding as y. We run a constituency parser on x
to get its parsing tree as T(x). In order to get
meaningful subparts of a sequence, we traverse
the parsing tree recursively and get all the subtrees
with more than one child. Denote the collection
of subtrees as S(x) ={t}, where tdenotes
thek-th subtree of sample x. For a subtree t,
it covers a continuous span t≜[x, ..., x]
ofxthat starts with index rand ends with in-
dexs. For example, as shown in the left part
of Figure 1, the subtrees of the example sentence
can cover spans such as this poor film ,in
this poor film ,no interest etc.5245
For a given sample (x,y), we randomly sam-
ple another data point (x,y)from the training set.
We run the constituency parser on both sentences
and get their subtree sets S(x)andS(x), based
on which we can sample subtrees to exchange. We
introduce two additional hyper-parameters λand
λto constraint the length of subtrees to sample.
λandλ, measured in terms of length ratio of the
subtree to the original sentences, sets the lower and
upper limits of the subtrees to sample. Intuitively,
λcontrols the granularity of the phrases that we
aim to exchange. We would like that the length of
phrase to exchange to be reasonable. If it is too
short, then the exchange cannot introduce enough
diversity to the augmented sample; otherwise if it
is too long, the process might inject too much noise
to the original sentence. We set λto be the ratio in
order to be invariant to the length of original sen-
tences. Table 2 shows some subtree examples with
different length constraints. We define the length
constrained subtree set as:
S(x)≜{t|t∈S(x), s.t.|t|
|x|∈[λ, λ]}.
Here|.|denotes the length of a sequence or a sub-
tree. For two sentences xandx, we randomly
sample two subtrees t∈S(x)andt∈S(x)
and construct a new sample by replacing twitht,
i.e.
¯x≜[x, ..., x, x, ..., x/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright, x, ...x](1)
where t= [ x, ..., x]replaces t=
[x, ..., x]. Figure. 1 shows an example
of TreeMix, where the subtree a touching
transcend love story replaces the subtree
this poor film .
Label Creation for TreeMix Creating a valid
label for the augmented sample ¯xis a challenging
problem. Similar to that of Mixup (Zhang et al.,
2018), we use a convex combination of originalAlgorithm 1: Dataset construction
Input: Original dataset D; data size
multiplier β; parameters λandλ
Output: Augmentation Dataset D
while|D|<β|D|do
Randomly select two samples (x,y)
and(x,y)∈ D
(¯x,¯y) =TreeMix ((x,y),(x,y))
D← D∪ {(¯x,¯y)}
end
labels of two sentences as the new label for the
augmented sample:
¯y=l− |t|
l− |t|+|t|y+|t|
l− |t|+|t|y,(2)
where lis the length of xand|t|,|t|are the
length of the subtrees. In the new sentence, l−
|t|words from xare kept and |t|words from
sentence xare inserted.
In Equation 2,is the fraction of words
that come from x, which determines the weight
ofy. The label is then created based on the con-
jecture that the change in labels is proportional
to the length changes in the original sentences.
We provided a set of augmentation examples from
TreeMix in Table A.1 in Appendix.
Pairwise Sentence Classification Task The
above mainly used single sentence classification as
the running example for TreeMix. Here we argue
that TreeMix can easily be extended to pairwise
sentence classification problem, where the relation-
ship between the sentences is the label.
Formally, for a given sample (x,x,y), we ran-
domly sample another sample (x,x,y)and run
the parser and get the subtree sets of each sentence
S(x), S(x)andS(x), S(x). Then we ran-
domly sample subtrees t∈S(x), t∈S(x)
andt∈S(x), t∈S(x). We construct ¯xby
replacing twithtand¯xby replacing twith
t. The new label is created as:
¯y=l+l− |t| − |t|
l+l− |t| − |t|+|t|+|t|y+(3)
|t|+|t|
l+l− |t| − |t|+|t|+|t|y.
The meanings of the notations are the same as in
Equation 2.5246Our main algorithm is shown in Algorithm 1.
Although not all sentences created by TreeMix are
fluent or even valid new sentences, they contains
subparts with different meanings that encourage the
models to build rich representation of sentences in
a compositional manner. Note that the augmented
labels are convex combination of original labels,
only when the model learns the representations of
two parts together can they predict both labels with
different weights.
3.2 Training Objective
Our model is trained on a combination of the orig-
inal samples and augmentation samples to obtain
a trade-off between regularization and noise injec-
tion. The final training objective is:
L=E[−ylogP(y|x)]
+γE[−¯ylogP(¯y|¯x)],(4)
γis the weighton the augmentation samples.
4 Experiment
4.1 Datasets
To test TreeMix’s effectiveness, we experiment
with a variety of text classification benchmarks,
as shown in Table 3. We use accuracy as a met-
ric, and exclude datasets from GLUE (Wang et al.,
2019) that are not suitable for mixup, including
CoLA that measures linguistic acceptability and
will be ruined by mixup operations, and WNLI that
is too small to show a method’s validity.
4.2 Experiment Setup
The proposed TreeMix method creates new sam-
ples by combining text spans based on the con-
stituency tree’s information, thus we use the Stan-
ford CoreNLP toolkitto obtain parsing related
information (Manning et al., 2014). We use the pre-
trained language model bert-base-uncased for se-
quence classification task from HuggingFace. With
seeds ranging from 0 to 4 and λ= 0.1, λ= 0.3,
we use TreeMix to generate twice and five times
more samples than the original training set. We
replicate the original dataset to the same size as
the augmentation datasets in the training stage to
ensure that the model receives the same amount of
data from the original dataset and the augmentation
dataset for each training batch.
If not specified, we train the model for 5 epochs,
with a maximum sequence length of 128 and batch
size of 96. The model is optimized using the
AdamW optimizer with an eps of 1e-8 and a learn-
ing rate of 2e-5. Table C.1 in Appendix contains
detailed hyper-parameter settings for each dataset.
4.3 Baseline
We compare TreeMix with the following bench-
marks: (1) No augmentation (BERT): standard
training without any augmentation, (2) EDA that
randomly performs insertion, replacement, swap
and deletion to the text. (3) AEDA that randomly
inserts punctuation to the text. (4) Back transla-
tion(BT) (Edunov et al., 2018): texts are translated
between English and German using Transformer
architectures trained on WMT16 English-German.
(5) GPT3Mix(Yoo et al., 2021) designs prompts
and utilizes GPT3 to generate new examples to
train the model. (6) SSMix (Yoon et al., 2021) ap-
plies mixup based on the saliency (Simonyan et al.,
2014) of tokens, similar to PuzzleMix (Kim et al.,
2020) and SaliencyMix (Uddin et al., 2021). (7)
EmbedMix is the pretrained-language-model ver-
sion of WordMixup in Guo et al. (2019), which
performs mixup on the embedding level. (8) TMix
(Chen et al., 2020b) first encodes two inputs sep-
arately, then performs the linear interpolation of
two embeddings at a certain encoder layer, and fi-5247nally forward-passes the combined embedding in
the remaining layers.
5 Results and Analysis
5.1 Performance On Full Dataset
The results of TreeMix on the entire datasets are
shown in Table 4. TreeMix outperforms all base-
lines significantly on single sentence classification
tasks, demonstrating the superiority of using com-
positional substructure for substitution and aug-
mentation. For instance, On SST2, it improves by
0.98%. Compared to other methods, the improve-
ment was more than doubled.
This is because that, unlike SSMix which sub-
stitutes the text spans based on the saliency, our
TreeMix makes use of the constituency information
to help identify linguistically informed sentence
substructures, and by recombining these compo-
nents, the compositional diversity of the datasets
can be maximized. With our TreeMix generated
samples, the model can see more combinations of
the substructures in the training stage that aren’t
available in the original corpus, leading to better
generalization ability.
When it comes to sentence relationship classi-
fication tasks, TreeMix is also very effective. For
example, It improves by 2.47% on the RTE data set,
whereas the best improvement of other methods is
only 0.3%, and it improves by 0.82% on QNLI,
where other data augmentation methods have little
effect. We hypothesized that, when two constituent
parts from one sentence pair are embedded into
another sentence pair, the inherent relationship is
also embedded. This better helps the models on
how to to identify two pairs of relationships in a sin-
gle sample, which further increases its capacity to
categorize these challenging adversarial sentences.
Since TreeMix works by increasing dataset diver-
sity and providing models with more text patterns
to learn, it has very significant improvements for
these relatively small datasets such as RTE and
TREC, compared to these large datasets such as
AG NEWS,QQP and MNLI that already have a lot
of diversity and text patterns.
5.2 Influence of Constituency Information
To determine the importance of constituency infor-
mation, we designed a Random Mixup (RandMix)
that randomly selects text spans as long as the ra-
tio of span length to sentence length is less than
a particular threshold λ. The rest setting of
RandMix is the same as TreeMix. We compare
TreeMix and RandMix on single sentence classifi-
cation datasets in Figure 2.
We found that, both RandMix and TreeMix are
quite effective, but TreeMix outperforms RandMix
on most datasets. For instance, TreeMix exceeds
RandMix by 0.8% on SST2, 0.6% on TREC-f, and
0.5% on TREC-c. One exception is on IMDb,
where the average sentence length is much longer.
The reason for the poorer performance of TreeMix
is due to the sparse parsing results on long sen-
tences; since there are many subtrees, substituting
any single part might bring very minimal change
to the entire sentence.
5.3 Influence of Training Set Size
To examine the influence of TreeMix with different
training set sizes, we uniformly sample 1%, 2%,
5%, 10%, and 20% of the data from the training set
to investigate TreeMix in low-resource situations.
The entire test set is used to evaluate the model’s
generalization ability. Since TreeMix generates
more examples for training, we use RandMix to
generate the same number of extra samples as a
comparison to ensure the data size is fair. The
results are summarized in Figure 3.
We found that, (1) TreeMix outperforms Rand-
Mix in all settings, further demonstrating the advan-
tage of the compositional substructure with the con-
stituency information over the randomly selected
spans. (2) Both mixup methods can significantly
improve the model’s performance in the case of
extreme data scarcity (e.g, 1% and 2%). (3) When
the amount of data is sufficient (e.g, more than5248
5%), TreeMix outperforms RandMix by a signifi-
cant margin. However, TreeMix only slightly out-
performs RandMix when there is a severe lack of
data (e.g, 1% and 2%). This is due to that the too
small datasets often contain very limited structures,
thus constraining TreeMix’s ability to increase text
patterns and compositional diversity. (4) The rel-
ative improvement of TreeMix over conventional
training without augmentation diminishes as the
amount of data increases, largely due to that addi-
tional augmented text patterns might overlap with
those already existing in the dataset, resulting in
limited improvement.
5.4 Influence of Cross-Category Mixing
Different from prior work Shi et al. (2021),
TreeMix allows the composition of sentences from
different label categories. To test whether this
cross-label category mixup is more effective than
a within-label category mixup, we conducted abla-
tion studies with TreeMix on samples in the same
class. Table 5 shows the results. Across all
datasets, we found that TreeMix that combines data
from different classes is more effective than com-
bining data from the same class, consistent with
findings in Zhang et al. (2018). When given only
labels from one category, current models have a ten-
dency to make simple or spurious judgments based
on the most frequently occurring words. However
the semantics of the sentence are complicated be-
yond simple words. For example, the model is
likely to classify a sentence like “I like this good
movie" as positive because of the words “like" and
“good" , but if “good movie" is replaced with “bad5249film" , the model must perceive the different con-
stituent parts within the sentence. This ability can
only be obtained when the model is trained on the
cross-category generated samples.
5.5 Influence of Length Ratio
The only constraint we impose on TreeMix is
the length ratio of the subtree controlled by λ. We
select subtrees that are between 10% and %30 and
between 30% and 50% of the length of the sentence,
respectively. Table 6 shows the results.
On all datasets, λ= [0 .1,0.3]outperforms
λ= [0.3,0.5], which is in line with Zhang et al.
(2018)’s observation that giving too high mixup
ration values can lead to underfitting. Another lin-
guistic explanation for the scenario follows: When
λ= [0.3,0.5], TreeMix may select longer text
spans, which usually contain unique constituency
components like SBAR ; The exchange of these
spans will severely damage the sentence’s semantic
and grammatical structure, causing the model to
become confused. As a result, TreeMix with larger
switching spans performs poorly, and even worse
than baseline on some datasets.
5.6 Compositional Generalization
To quantify TreeMix’s overall ability of composi-
tional generalization beyond classification tasks,
we conducted experiments on SCAN (Lake and Ba-
roni, 2018) dataset, which is a command execution
dataset widely used to test for systematic compo-
sitionality. It contains simple source commands
and target action sequences. We test on commonly
used challenging splits: addprim-jump, addprim-
turn-left, around-right , where primitive commands
(e.g “ jump ”) only appear alone during training but
will be combined with other modifiers (e.g “ jump
twice ”) during testing. A model that works well
for this task should learn to compose the primi-
tive commands with the modifiers and generates
corresponding execution. With TreeMix, we can
generate the compositional commands that are not
seen in the training set.
The new command generation process is the
same as in single sentence classification, except
that we increase the length constraint λto 1 to
allow the exchange of the commands with only
one word. After we synthesize new commands,
we follow the rules in Lake and Baroni (2018) to
translate valid commands into actions and filter
out ungrammatical commands. We follow the set-
tings in Andreas (2020) and use the following data
augmentation methods as baselines: (1) WordDrop
that drops words randomly; (2) SwitchOut (Wang
et al., 2018) that randomly replaces words with
other random words from the same vocabulary; (3)
SeqMix (Guo et al., 2020) which creates new syn-
thetic examples by softly combining in-put/output
sequences from the training set, and (4) GECA
(Andreas, 2020) that performs enumerated valid
swaps.
As shown in Table 7, TreeMix outperforms
SwitchOut and WordDrop for all splits. TreeMix
by itself does not perform as well as GECA, but
when being combined with GECA, it demonstrates
very strong results. TreeMix outperforms SeqMix
in all splits, due to the fact that TreeMix can more
precisely find the linguistically rich compositional
segments of a sentence, as evidenced by the re-
sults of the comparisons of TreeMix and SSMix
in Section 5.1 and TreeMix and RandMix in Sec-
tion 5.3. A closer look at these augmented samples
show that TreeMix can generate all possible com-
binations of “ jump ” and other modifiers like “ left”5250and “ around ”; these previously unseen command
combinations further validates TreeMix’s ability
to improve the dataset’s compositional diversity.
TreeMix demonstrates weak performances on the
around-right split, where the model observes com-
mands “ around ” and “ right ” in isolation at the
training stage, and it has to derive the meaning of
“around right ” at the test time. Because the word
“around ” cannot be parsed as a single subtree for
swap. Instead, it always appears in a subtree with
the word “ left”, preventing TreeMix from generat-
ing the phrase “ turn right ”. Despite its limitations
onaround-left , TreeMix performs well on all other
splits and can be easily combined with other data
augmentation methods, demonstrating the compo-
sitional generalization ability of TreeMix beyond
classification tasks.
6 Conclusion
This work introduced TreeMix, a compositional
data augmentation approach for natural language
understanding. TreeMix leverages constituency
parsing tree to decompose sentences into sub-
structures and further use the mixup data augmen-
tation technique to recombine them to generate
new augmented sentences. Experiments on text
classification and semantic parsing benchmarks
demonstrate that TreeMix outperforms prior strong
baselines, especially in low-resource settings and
compositional generalization.
Acknowledgements
The authors would like to thank reviewers for their
helpful insights and feedback. This work is funded
in part by a grant from Salesforce.
References5251525252535254A Augmentation examples
B The necessity of merged loss techniques
We provide a detailed discussion of the techniques proposed in 3.2. We first investigate the noise contained
in the augmentation dataset, then we figure out how the unbalance dataset will affect the performance. In
the second part, we vary the weight parameter γto see how it affects the model’s learning process.
B.1 Noise and Unbalance
All mixup methods, as previously stated, introduce noise into the dataset. This noise in the text includes
grammatical structure confusion and multiple semantic meanings in the sentences. The model will be
overwhelmed by the noise if trained solely on the generated augmentation dataset, and will even perform
worse than the baseline. In terms of the unbalance problem, we find that training the model without
replicating the original dataset to the same size as the augmentation dataset hurts the model’s performance.
The results are shown in the table B.1.
B.2 Weight parameter
We vary weight parameter γto find optimal balance point between diversity and linguistic grammar,
the results are shown in figure 4. Performance on the two classification tasks follows a similar pattern.
Both increase with increasing weight and then rapidly decrease with increasing weight after reaching
the highest point. Performance is weaker than the baseline when the weight value exceeds 0.7. We find
the model achieves the best performance with γ∈ {0.2,0.5}. For single sentence classification tasks,
when γ= 0.5the model always gets higher accuracy, and γ= 0.2is better for these sentence relation
classification datasets.5255
C Hyper-parameters for each datasets
We explore different parameter combinations and find the best ones for each task, as in Tab C.1. There are
some exceptions, such as TREC datasets, where the model cannot converge even with 10 epochs, so we
increase the training epochs to 20 for this dataset. IMDb’s examples are extremely long, with an average
length of more than 200 words. Along with this change, we increased the truncation length to 512 and the
batch size to 8 to fully capture the semantic meaning. RTE is the most unusual. First, when we train using
original RTE datasets, the accuracy deviation is really substantial, reaching up to 4%. Second, we find
thatγ=−0.2is optimum for this set, which contradicts previous findings.
D Ablation Study
Shi et al. (2021) has proposed a similar study that uses constituency information for mixup. There are a
few significant differences between our approaches. To begin with, their method is too restricted; they only
perform mixup between examples from the same category, and they require the substituted subtree’s label
to be the same. Second, because they are limited to the same class examples, they are unable to devise a
method for adding a soft label to the example. Instead, we only use TreeMix in the previous settings with
the length constraint. Several other constraints in the subtree selection process are investigated in this
section, and we achieve better performance than Shi et al. (2021) by giving the subtree selection process
more freedom, and we validate that their work is a special case of our method by examining how other
constraints affect the performance. This section’s values are the averages of five runs with seeds ranging
from 0 to 4
D.1 What is the difference between different amounts of data?
TreeMix has the potential to generate an infinite amount of augmented data in theory. However, due to
TreeMix’s principle, it can only improve performance to a point when the size of the augmentation data5256set reaches a certain limit. We investigated how many augmentation datasets the model needs. Table D.1
shows the results of producing twice and five times the augmentation data for experiments.
The key to getting the best results is to strike a balance between the original datasets and the aug-
mentation datasets in terms of diversity and linguistic confusion. With more augmentation datasets, the
model will learn more patterns while also observing more grammatically poor samples, which could
negatively impact performance. We discovered that augmentation datasets twice the size of the original
dataset produce the best results for larger datasets. This is in line with our previous theoretical analysis:
large datasets inherently include more patterns and diversity, which helps the model generalize better.
Maintaining the original linguistic grammar while increasing diversity in these datasets is, therefore, more
important. When working with smaller datasets, it’s better to train with more augmentation data. For
models to train on these datasets, we believe diversity is more important than linguistic grammar.
TREC-fine is an exception. We attribute it to the datasets’ excessive classes (up to 47 classes within only
5.5k training samples): each class has a very limited number of samples, and if we create overly augmented
dataset samples, the limited samples of each category are insufficient to resist injected linguistic noise. As
a result, for TREC-fine, x2 is preferable to x5. For a smaller dataset, we recommend generating five times
as much augmentation data as possible, and for a larger dataset, we recommend generating twice as much
augmentation data.
D.2 Is it beneficial to keep the swapped subtree’s label or length the same?
Each subtree has its own label (e.g., VP and NP) and corresponds to a specific text span. When
selecting subtrees, we can use these characteristics as additional constraints. Figure 5 shows the results.5257When we impose restrictions on the subtree selection process, the experimental results clearly show that
performance suffers.
We hypothesize that this is because in datasets with similar sentence lengths, subtrees of the same
phrase label or phrase length tend to have similar structures (e.g., tree height, relative position in the
sentence). Although the exchange of such subtrees can retain the original linguistic grammar of the text
to some extent (e.g., replacing a noun phrase with another noun phrase will not significantly disrupt the
sentence) and maintain similar sentence length, it cannot exploit the potential compositional diversity in
the datasets as efficiently as TreeMix without any constraints, resulting in lower diversity augmentation
datasets and limited improvement compared to the baseline. In terms of the comparison of TreeMix(label)
andTreeMix(length) , we find that TreeMix(label) prefers simple phrases such as NP and VP because these
are the most common phrases occurring in sentences, and this exchange will not improve the diversity
of the datasets. For example, in "I like this apple," replacing "apple" with "orange" will not provide
innovative text patterns.5258