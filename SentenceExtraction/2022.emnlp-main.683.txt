
Xueliang Zhao, Lemao Liu, Tingchen Fu, Shuming Shi, Dongyan Zhao, Rui YanWangxuan Institute of Computer Technology, Peking UniversityTencent AI LabCenter for Data Science, AAIS, Peking UniversityGaoling School of Artificial Intelligence, Renmin University of ChinaBeijing Institute for General Artificial Intelligence
{xl.zhao,zhaody}@pku.edu.cn {redmondliu,shumingshi}@tencent.com
lucas.futingchen@gmail.com ruiyan@ruc.edu.cn
Abstract
With the availability of massive general-
domain dialogue data, pre-trained dialogue gen-
eration appears to be super appealing to transfer
knowledge from the general domain to down-
stream applications. In most existing work,
such transferable ability is mainly obtained by
fitting a large model with hundreds of millions
of parameters on massive data in an exhaustive
way, leading to inefficient running and poor
interpretability. This paper proposes a novel di-
alogue generation model with a latent structure
that is easily transferable from the general do-
main to downstream tasks in a lightweight and
transparent way. Experiments on two bench-
marks validate the effectiveness of the proposed
model. Thanks to the transferable latent struc-
ture, our model is able to yield better dialogue
responses than four strong baselines in terms of
both automatic and human evaluations, and our
model with about 22% parameters particularly
delivers a 5x speedup in running time compared
with the strongest baseline. Moreover, the pro-
posed model is explainable by interpreting the
discrete latent variables.
1 Introduction
Conversation between humans and machines has
long been a goal of artificial intelligence (AI).
Building an open-domain dialogue system with
data-driven techniques has gotten a lot of attention
in the AI and NLP fields in recent years, thanks
to breakthroughs in deep learning (Sutskever et al.,
2014; Gehring et al., 2017; Vaswani et al., 2017).
In particular, with the availability of massive hu-
man dialogue data (e.g., the Reddit comments) on
social media (Adiwardana et al., 2020), pre-trained
dialogue generation appears to be super appealing
to alleviate potential discrepancies between general
domain and downstream applications (Zhang et al.,
2020; Bao et al., 2020, 2021; Li et al., 2021).The common idea behind the pre-trained dia-
logue generation can be highlighted as a two-step
pipeline: a) it firstly trains a deep neural model on
massive general-domain dialogue data, b) and then
transfers the model into downstream tasks via fine-
tuning or zero-shot learning. Under this pipeline,
the transferability is mainly obtained by fitting a
large model with millions of parameters on mas-
sive data in an exhaustive way. Consequently, the
downsides in existing works are obvious: their run-
ning is inefficient and their outputs are difficult to
explain.
This paper thereby aims to build a pre-trained
dialogue model which is easily transferable from
the general domain to downstream tasks in a
lightweight andtransparent way. To this end, we
propose a novel dialogue model with a latent struc-
ture consisting of several latent variables. By using
some self-supervised tasks to endow its latent vari-
ables with some prior properties during training,
the latent structure makes the knowledge better
transferable across different domains. Specifically,
we first propose to incorporate the transformer ar-
chitecture with a discrete conversation flow. Given
a dialogue session, our model will sequentially
infer the discrete state for each utterance which
provides essential hints for future states and has
an effect on the generation of the associated ut-
terance. We further propose a method to disen-
tangle the context-sensitive information from the
conversation flow, which is achieved by two dis-
entangled latent variables to capture the context-
sensitive information (e.g., topic and persona) and
the context-independent information (e.g., dialogue
logic for each utterance) respectively. Through
tailor-designed self-supervised tasks, the context-
sensitive latent variable is able to capture the holis-
tic information of a dialogue session while the
context-independent variable is supposed to reflect
the dynamic flow of dialogue in each utterance.
Meanwhile, the model is optimized with variational10051inference by maximizing the evidence lower bound
of the likelihood.
We conduct experiments with two multi-turn di-
alogue generation benchmarks, including DailyDi-
alog (Li et al., 2017) and ConvAI2 (Dinan et al.,
2020). Thanks to the transferable latent structure,
our model is able to yield better dialogue responses
than four strong baselines in terms of both auto-
matic and human evaluations, and our model in-
cluding about 22% - 66% parameters particularly
delivers a 2x - 30x speedup in running time. More-
over, the proposed model is explainable by visual-
izing the discrete latent variables.
Our contributions in the paper are three-fold: (1)
We present a context-free dialogue structure that
captures the prior knowledge about state transition
in a large-scale dialogue corpus. Furthermore, with
the help of this dialogue structure, our model out-
performs the state-of-the-art dialogue pre-training
method with much fewer parameters. (2) We pro-
pose a disentangled structure learning framework to
induce a context-free dialogue structure that enjoys
better transferability and interpretability. (3) We
empirically verify the effectiveness and efficiency
of the proposed model on two benchmarks.
2 Related Work
The success of neural networks in machine transla-
tion promotes early research on end-to-end open-
domain dialogue generation (Ritter et al., 2011;
Shang et al., 2015; Vinyals and Le, 2015). Various
adaptations to the vanilla encoder-decoder archi-
tecture have been built to model the structure of
dialogue contexts (Serban et al., 2016, 2017; Zhang
et al., 2019); improve response diversity (Li et al.,
2015; Zhao et al., 2017; Tao et al., 2018); introduce
external knowledge (Dinan et al., 2019; Zhao et al.,
2020a,b); and control response qualities (Xu et al.,
2019; Zhou et al., 2017; Zhang et al., 2018; Wang
et al., 2018; See et al., 2019).
Large-scale pre-training for open-domain dia-
logue generation has recently become promising as
a way to bridge the gap between conversation with
existing systems and conversation with humans. In-
spired by the successfulness of GPT-2 (Radford
et al., 2019), Zhang et al. (2020) propose to train
the transformer models on a very large dialogue
dataset to generate informative text. Bao et al.
(2020) further use discrete latent variables to ad-
dress the one-to-many mapping problem in open-
domain dialogue. Despite prior successes, the di-alogue context is simply concatenated as a long
sequence, which may fail to capture the discourse-
level coherence among utterances. To this end, Gu
et al. (2021) and Li et al. (2021) introduce more
self-supervision objectives to capture the discourse-
level coherence and the dynamic information flow
respectively.
The concept of dialogue structure has proven
useful in modeling the complicated relationships
between utterances. In the field of task-oriented
dialogue, Shi et al. (2019) propose a discrete varia-
tional recurrent neural network (DVRNN) to learn
the dialogue structure through unsupervised learn-
ing; Qiu et al. (2020) further propose to enhance
prior work with a structured attention mechanism;
and Sun et al. (2021) propose a conversational
graph to represent deterministic dialogue structure,
where nodes and edges represent the utterance and
context information, respectively. In the field of
open-domain dialogue, Xu et al. (2021) construct a
large dialogue structure graph with around 1.6mil-
lion vertices to cover a wide range of topics. This
work introduces a disentangled structure learning
framework, which can induce a transferable sub-
structure and an interpretable dialogue substruc-
ture, to incorporate the structural bias in dialogue
pre-training. Thanks to the tailor-designed self-
supervised tasks, our latent structure is more gen-
eral than the dialogue structure in existing work.
3 Approach
3.1 Overview
LetX= (u, u,···, u)denote a dialogue ses-
sion, with u= (w, w,···, w)denoting
thet-th utterance and wthei-th token in it. The
number of utterances in a session and the number
of tokens in each utterance are represented by n
andm, respectively. The conversational context for
uisu= (u, u,···, u). Our ultimate goal
is to develop a generation model p(u|u)that can
predict the next utterance based on the context of
the conversation.
Figure 1 illustrates the overview of our graphical
model, which includes the proposed latent struc-
ture consisting of three kinds of latent variables,
i.e.,c= [c, c,···, c],z= [z, z,···, z]
andz. Specifically, cdepicts the flow of a con-
versation, and each c∈ {1,···, N}is a discrete
latent variable with Nas a hyper-parameter. It is
worth noting that cis designed for interpretability :
by interpreting these discrete variables, humans are10052
able to understand the logical flow of the conversa-
tion as to be shown in Section 5.4. Moreover, z
andzare two disentangled latent variables to cap-
ture the context-sensitive information and context-
independent information in a dialogue session re-
spectively. In this way, through disentangling z
andzwith tailor-designed self-supervised learn-
ing objectives (as will be described in Section 3.4),
our model is able to capture intrinsic conversation
flow for better generalization to different domains
(i.e., transferability ).
With our designed latent structure, given a con-
versational context u, the generation of the
next utterance ucan be roughly decomposed
into two steps: (1) infer the conversation flow
[c, c,···, c]and the context-sensitive variable
zbased on context information, as shown in Fig-
ure 1 (left). (2) compute the priors of candz,
and then generate the next utterance uwithzand
z, as shown in Figure 1 (right).
3.2 Generation
Context Encoding. We first obtain the contex-
tualized representations of utterances through pre-
trained language models (PLMs). Specifically, we
exploit GPT- 2(Radford et al., 2019), which is pre-
trained using the causal language modeling ob-
jective and achieves state-of-the-art results on a
range of text generation tasks, as the backbone of
our model. Note that our technical novelty lies
in the proposal of a disentangled structure learn-
ing framework that injects a transferable dialogue
structure into PLMs. Given a dialogue session
X= (u, u,···, u), we first construct the in-
putIby concatenating all utterances as a singleconsecutive token sequence:
I=[BOS] u[EOS] u[EOS] . . .[EOS] u[EOS] ,
(1)
where [BOS] and [EOS] are special tokens de-
signed to separate sentences. The input Iis then
fed into the PLM and the contextualized represen-
tation for Xis defined as the hidden states at the
last layer:
h,···, h,···, h=f(I)∈R,
(2)
where f(·)denotes the transformer
model (Vaswani et al., 2017) and h∈R
denotes the hidden state corresponding to token
w. It’s notable that we use uni-directional atten-
tion since the learning objectives are applied to all
utterances (as will be illustrated in Section 3.4) and
a bi-directional architecture will leak the future
information.
The vector representation of the t-th utterance
is obtained through attentive pooling (Wu et al.,
2020), which is defined as follows:
h=/summationdisplayαh, α=e
/summationtexte,(3)
where q∈Ris the attention query vector.
Prior of Discrete Latent Variable. The discrete
latent variables [c, c,···, c]are used to auto-
matically discover the structural representation in
dialogues, which is beneficial to analyze how con-
versation flow from one utterance to the next one
and promotes interpretability. We exclude the im-
pact of uoncsince there is usually a domain dis-
crepancy between the pre-trained and downstream
data, which limits the transferability of the learned
conversation flow. As a result, we directly model
the influence of concin the prior. We employ
the transformer model with uni-directional atten-
tion to generate the contextualized representation
ofc:
Then the probability of predicting cis defined as:
p(c|c) =Softmax (f(h)),(5)
where f(·)denotes a MLP network. Differ-
ent from Shi et al. (2019), our model preserves the
capacity to represent n-gram transition probability,
which is superior for capturing long-term depen-
dency in the conversation flow of open-domain
dialogues.10053Priors of Context-Sensitive and Context-
Independent Variables. Despite the fact that the
discrete latent variables can intuitively characterize
conversation flow, the complexity of open-domain
conversation necessitates a large number of dia-
logue states to address fine-grained semantics (Xu
et al., 2021), making model training highly chal-
lenging and resulting in poor generalization ca-
pacity. To alleviate the aforementioned difficul-
ties, we introduce two latent variables to decouple
the conversation flow and contextual information,
namely the context-sensitive latent variable zand
the context-independent latent variable z.
The prior of context-sensitive latent variable z
is defined as a standard Gaussian distribution:
p(z) =N(0,I), (6)
whereIdenotes the unit matrix.
The context-independent latent variable is re-
sponsible for capturing dynamic information in
each utterance. To achieve this, we condition the
prior of zon both contextualized representation
of the previous utterance and the predicted discrete
state for the current utterance:
p(z|u, c) =N(µ, σI),
µ, σ=f([h;e(c)]),(7)
where f(·)denotes a MLP network, e(·)is
the embedding of a latent state and [·;·]denotes
vector concatenation. We employ the Gumbel
trick (Jang et al., 2017) to handle the discrete and
undifferentiable process of sampling c.
Decoding. Given the contextualized representa-
tionhfor token w, the original GPT- 2model
calculates the pre-softmax logit vector through a
linear head, i.e., p=Wh, where Wis a
learnable parameter. To explicitly guide the gener-
ation through the context-independent latent vari-
ablezand the context-sensitive latent variable z,
we first project them into the space of hand then
calculate two pre-softmax logit vectors similar to
p:
p=WWz, p=WWz,(8)
whereWandWare learnable parameters. We
employ the reparameterization trick (Kingma and
Welling, 2013) to allow gradient passing through
the sampling of zandz. The probability of
generating the next token is then defined as:The parameterization of the generative model
results in the following factorization:
where the probability of generating u
is formulated as: p(u|u, z, z) =/producttextp(w|u, w, z, z).
3.3 Inference
For the inference of latent variables, we employ
a lightweight transformer that is initialized by the
first6layers of the GPT- 2model. The vector rep-
resentation of utterance uis denoted as hand is
defined in the same way as Eq.3. We introduce
three auxiliary distributions q(c|X),q(z|X)
andq(z|X)which approximate to the posteri-
ors of the discrete latent variable c, the context-
independent latent variable zand the context-
sensitive latent variable zrespectively.
Since the context-sensitive latent variable z
captures the holistic information about the whole
session, we construct the posterior distribution
q(z|X)by summarizing the representations for
each utterance:
q(z|X) =N(ˆµ,ˆσI),
ˆµ,ˆσ=f(h),(11)
where h=/summationtexthandf(·)denotes a
MLP network. Similarly, the posterior distribution
q(z|X)is defined as:
q(z|X) =/productdisplayq(z|X),
q(z|X) =N(ˆµ,ˆσI),
ˆµ,ˆσ=f(h),(12)
where hencodes the contextual information of
u. The posterior distribution q(c|X)could
be factorized as/producttextq(c|X)where q(c|X)
is a Categorical distribution parameterized by
Softmax (f(h)). The inference process is
depicted in Figure 1.
3.4 Learning
The log-likelihood of the conversation session
Xis maximized using variational approxima-
tion, yielding the evidence lower bound objective10054(ELBO) (Hoffman et al., 2013):
where D(·∥·)refers to Kullback–Leibler diver-
gence. Detailed derivations are presented in Ap-
pendix C.
In addition to optimizing the ELBO objective,
we also exploit disentanglement to distill the holis-
tic information into the context-sensitive latent vari-
able while keeping the dynamic information in the
context-independent latent variable and the discrete
latent variable as demonstrated in the rest of this
section.
Holistic Information Discrimination. The la-
tent variable zis supposed to only focus on the
holistic information that refers to the time-invariant
factors (e.g., interlocutor persona) and remains con-
sistent throughout the whole dialogue session. To
achieve this, we design a self-supervised task to
eliminate the dynamic information from z. Ide-
ally, the holistic information of a session Xis insen-
sitive to a random shuffle of its internal utterances
(i.e., X), but varies across randomly picked
different dialogue sessions (i.e., X). Thus we
could maximize the following objective:
L= loge
e+e,
(14)
where zandzdenote the context-sensitive
latent variables of X andXrespectively,
andf(·,·)is implemented as the cosine similar-
ity between two vectors.
Dynamic Information Restoration. Since each
utterance contains some utterance-specific features
that are independent of the conversational con-
text, it is reasonable to encourage the context-
independent latent variable zto be aware of the
dynamic information flow in a session. Specifi-
cally, we design a surrogate task to recover the
verbs in an utterance ugiven the correspondingcontext-independent latent variable z:
L=/summationdisplay/summationdisplayδlogp(w|z), (15)
where δ= 1 if the token wis a verb, other-
wise δ= 0.p(w|z) = Softmax (Wz)
outputs a probability distribution over all verbs in
the vocabulary with Wa learnable parameter.
Mutual Information Minimization. Since the
task of Dynamic Information Restoration can not
guarantee that the holistic information is exclusive
inz, we further introduce the mutual information
objective as a regularization to minimize the rela-
tionship between zandz:
L =−/summationdisplay[H(z) +H(z)−H(z, z)],
(16)
where H(·)denotes the entropy which is estimated
through minibatch-weighted sampling (Chen et al.,
2019; Zhu et al., 2020):
forz=z,zor(z, z), where udenotes
uin the i-th data point, z(u)is a sample from
q(z|u),MandBare the data size and minibatch
size respectively.
The final learning objective is defined as:
L=L +α(L+L+L ),(18)
where αis a hyper-parameter to balance the objec-
tive of evidence lower bound and those related to
disentanglement.
4 Experimental Setup
4.1 Datasets
We follow Zhang et al. (2020) to adopt the Reddit
comments as our pre-training data. We evaluate our
model on two benchmark datasets for multi-turn di-
alogue generation, including DailyDialog (Li et al.,
2017) and ConvAI2 (Dinan et al., 2020). More de-
tails about all datasets are provided in Appendix A.10055
4.2 Evaluation Metrics
Automatic Evaluation. We choose three
commonly used reference-based metrics including
BLEU (Papineni et al., 2002), METEOR (Lavie
and Agarwal, 2007) and ROUGE (Lin, 2004),
where BLEU and METEOR are computed with
an open source NLG evaluation tool available
at https://github.com/Maluuba/nlg-eval ,
and ROUGE is calculated with the code pub-
lished at https://github.com/bckim92/
language-evaluation . We report the F1 scores
for ROUGE- 1, ROUGE- 2and ROUGE-L. We
also use Distinct (Li et al., 2015) to evaluate the
lexical diversity with Distinct-1 and Distinct-2
denoting ratios of distinct unigrams and bigrams in
responses, respectively.
Human Evaluation. We randomly sample 300
examples from the test sets of DailyDialog and
ConvAI2 respectively, and recruit 6well-educated
native speakers to do qualitative analysis on the
responses generated by our model and all competi-
tive baselines, which are randomly shuffled to hide
identification. The annotators judge the quality
of the responses from four aspects: (1) Fluency :whether the response is fluent without any gram-
matical errors; (2) Relevance : whether the response
is coherent with the context; (3) Informativeness :
whether the response contains informative content;
(4)Engagement : how much does the annotator like
the response. Each annotator assigns a score from
{0,1,2}(representing “bad”, “fair” and “good” re-
spectively) to each response for each aspect. Each
response obtains four scores for the aforementioned
four aspects, and the agreement among all annota-
tors is measured via Fleiss’ kappa (Fleiss, 1971).
4.3 Baseline Models
The following models are selected as baselines:
(1)DialoGPT. A model that is pre-trained on the
Reddit comments and attains a performance close
to human in single-turn dialogues (Zhang et al.,
2020). We adopt the medium -sized model which
achieves the best performance in the original pa-
per. (2) DialogBERT. A model that encodes the
dialogue context with a hierarchical transformer
architecture (Gu et al., 2021). (3) PLATO-2. A
model that learns a fine-grained one-to-many gen-
eration with the advent of a discrete latent vari-
able (Bao et al., 2021). It is notable that the per-10056
formance of PLATO-2 is superior to PLATO (Bao
et al., 2020) by introducing more parameters and
training data. (4) DialoFlow. A model that is pre-
trained on the Reddit comments and incorporates a
dynamic flow mechanism to model the context flow
in dialogues (Li et al., 2021). We adopt the large -
sized model which achieves the best performance
in the original paper.
All the baselines are taken from their open-
source implementations. We continue to train Di-
alogBERT and PLATO-2 on the Reddit comments
for the sake of fairness. The parameter sizes of all
baselines are shown in Table 4. We provide more
implementation details in Appendix B.
5 Results and Discussion
5.1 Main Results
In this section, we will compare the performance
of various models on DailyDialog and ConvAI2, as
well as provide some further analyses. We conduct
experiments in two different settings, including
zero-resource and full-resource, both of which are
commonly employed by pre-trained language mod-
els. All models solely use the Reddit comments
during training in the zero-resource scenario, how-
ever, in the full-resource situation, all models are
pre-trained on the Reddit comments and then fine-
tuned on downstream tasks. Table 1 and Table 2
show the performance of our model on DailyDia-
log and ConvAI2 respectively. From the results, we
can observe that: (1) Although our model is much
smaller than the other baseline models, it achieves
the best performance on appropriateness-related
metrics (i.e., BLEU, ROUGE and METEOR) and
performs comparably on distinctness-related met-
rics (i.e., Distinct) at the same time, demonstrating
the effectiveness of a context-free dialogue struc-
ture. Additionally, our model takes advantage of
zandzto capture both the time-invariant and
time-varying factors and generate a coherent re-
sponse. (2) DialoFlow outperforms DialoGPT on
most metrics after fine-tuning, but not as good asours. This verifies the necessity of capturing the
dialogue flow in PLMs, and the proposed context-
free dialogue structure is more competent. (3) On
the DailyDialog, our model outperforms baselines
by a larger margin than that on the ConvAI2. This
is possibly due to the introduction of dialogue act
flow in the construction of DailyDialog, which has
a similar effect to the dialogue structure.
Human Evaluation. Table 3 shows the results of
the human evaluation. While our model achieves
comparable performance to the others in terms of
Fluency andInformativeness , it outperforms them
on both Relevance andEngagement , agreeing with
the results of automatic evaluation. All kappa val-
ues are more than 0.6, indicating that the annotators
are in agreement.
Speed Test. We further compare our model with
baselines in terms of decoding speed. Specifically,
we calculate the average prediction time per word
in response generation in both zero-resource and
full-resource settings utilizing all dialogues in the
test sets. The experiments are conducted on an
RTX 3090. Table 4 shows the speed comparison
results. The discrete variable clearns a general
transition pattern from the entire corpus, which
compensates for the small parameter scale. As a
consequence, our model significantly outperforms
all competitive baselines thanks to its lightweight
architecture.10057
5.2 Ablation Study
To understand the impact of different variables on
model performance and the effect of disentangle-
ment, we compare the full model with the follow-
ing variants: (1) - c: the discrete latent variable is
removed; (2) - z: the context-sensitive latent vari-
able is removed; (3) - z: the context-independent
latent variable is removed; (4) -disentangle: the
model is only trained with L . All models are
evaluated under the zero-resource setting to gain a
full grasp of the transferability of our model. Table
5 reports the evaluation results. We can conclude
that: (1) The discrete latent variable cplays a cru-
cial role in both datasets, as eliminating the variable
causes a dramatic performance drop. It is reason-
able since our model can capture state transitions
between utterances thanks to the latent structure.
(2) Though the removal of the context-sensitive
or the context-independent variables both results
in a performance drop, the context-sensitive latent
variable zis much more beneficial because it can
eliminate context-independent information from
the dialogue structure, allowing the model to be
more transferable. (3) The self-supervised tasks
designed for disentanglement are effective because
removing them leads to a decline in performance.
5.3 Further Analysis on Transferability
This part will move one step further to understand
the transferability of the dialogue structure learned
from the large-scale corpus. A dialogue struc-
ture with strong transferability is supposed to be
well adapted to downstream tasks even without
fine-tuning structure-related parameters, which is
much more challenging. Therefore, to further ver-
ify the transferability of our methods, we freeze
the parameters of f (in Eq.4) and f
(in Eq.5), and only fine-tune the remaining param-
eters on downstream tasks. We additionally pro-
vide a variant in which the context-sensitive and
context-independent latent variables are removed.
Table 6 reports the results. It can be seen that our
model still performs well once some parameters are
frozen, thanks to the proposed disentangled struc-
ture learning framework. On the other hand, when
context-sensitive and context-independent latent
variables are removed, freezing the parameters will
result in a significant performance drop. The rea-
son is that our proposed approach can disentangle
the holistic information from the dialogue struc-
ture, allowing it to be used for various downstream
tasks.
5.4 Case Study on Iterpretability
Figure 2 shows an example from the test set of
DailyDialog. The left column gives the states of
the discrete latent variable along with the probabil-
ities predicted by our model and the right column
shows the corresponding utterances. We employ10058human experts to consistently interpret each state
by going through utterances assigned to the same
state. We only present the top- 3states due to space
constraints. We can observe that: (1) our model can
accurately infer the states of context utterances and
the ground-truth response given the posterior dis-
tribution of c; (2) thanks to the dialogue structure
our model can give a more appropriate response to
catch up with the context than baseline models.
6 Conclusion
We propose a novel dialogue model with structural
bias which is explainable to humans and easily
transferable to general dialogue tasks. Empirical
experiments on two benchmark datasets indicate
that our model with only 22% parameters outper-
forms the strongest baseline DialoFlow in both de-
coding speed and response quality measured by
automatic and human evaluations. We further show
that the learned latent structure enjoys superior
transferability and interpretability compared to the
conventional methods.
Limitations
In this paper, we propose a dialogue pre-training
model that featured a discrete transition structure.
By introducing a series of latent variables into
the pre-training process, the pre-trained model
could be easily adapted into downstream applica-
tion scenarios in a transparent and interpretable
way. However, all technologies built upon the
large-scale PLM more or less inherit their potential
harms (Bender et al., 2021). Besides, we iden-
tify some limitations within our work and describe
them below:
(1) Although the conversation flow is discrete
and interpretable, it is laborious to interpret the
implication of each state in the conversation flow
by going through utterances assigned to the same
state. Besides, large-scale human evaluation in our
experiments is also costly and time-consuming.
(2) The vocabulary size of the latent conversa-
tion flow Nis an important parameter that requires
to be carefully tuned, especially when the model
is agnostic to the downstream task. The optimum
Nmay vary according to the different languages
or different domains. It is particularly challeng-
ing to shift to uncommon languages because of its
reliance on large-scale pre-training corpus.
(3) In this paper, we use discrete latent vari-
ables to model the conversation flow for better in-terpretability. From another perspective, we are
distributing utterances into clusters according to
their latent flow variable c. However, this may
incur high intra-cluster diversity, especially when
generalizing to out-of-distribution data. A possible
remedy is to introduce some regularity in training
fto push its predicted distribution towards
one-hot distribution.
(4) The adoption of our method can lead to better
dialogue systems that improve the quality of life for
many people. But our method could also affect the
human interlocutors in a negative way if used for
malicious intent. We advise that any plan to apply
our method should consider carefully all potential
groups of stakeholders as well as the risk profiles of
applied domains to maximize the overall positive
impacts.
Ethics Statement
This paper studies open-domain dialogue pre-
training and proposes a disentangled structure
learning framework that allows the transformer ar-
chitecture to capture the prior knowledge about
state transition in a large-scale dialogue corpus.
There are no ethical issues with this research. The
datasets we used are commonly utilized by other re-
searchers and are typically accessible to the public.
The proposed approach does not introduce ethical
or societal prejudice.
Acknowledgements
We appreciate the anonymous reviewers for their
constructive comments. This work was sup-
ported by National Natural Science Foundation
of China (NSFC Grant No. 62122089 and No.
61876196), Beijing Outstanding Young Scientist
Program NO. BJJWZYJH012019100020098, and
Intelligent Social Governance Platform, Major In-
novation & Planning Interdisciplinary Platform for
the “Double-First Class” Initiative, Renmin Uni-
versity of China. This work was also supported in
part by Independent Research Fund Denmark under
agreement 8048-00038B. This work was also sup-
ported by the National Key Research and Develop-
ment Program of China (No. 2020AAA0106600).
We wish to acknowledge the support provided and
contribution made by Public Policy and Decision-
making Research Lab of RUC. Rui Yan is sup-
ported by Beijing Academy of Artificial Intelli-
gence (BAAI) and Tencent Collaborative Research
Fund.10059References100601006110062A Details of Datasets
We follow Zhang et al. (2020) to adopt the Red-
dit comments as our pre-training data, which con-
tains various domains and topics. We crawl the
online discussions over a period spanning from
2011 through 2016 , and there are 60,579,645and
685,881dialogues in the training set and the val-
idation set respectively. Each dialogue has 7.9ut-
terances on average, with each utterance including
27.5words.
We evaluate our model on two benchmark
datasets for multi-turn dialogue generation. (1) Dai-
lyDialog Dataset. This dataset is manually labeled
and contains conversations about daily life (Li et al.,
2017). This dataset is split into training set, valida-
tion set, and test set by the data owners. (2) Con-
vAI2 Dataset. This dataset is collected by having
two workers at Amazon Mechanical Turk chat with
each other based on their assigned profiles (Dinan
et al., 2020). The profiles define speakers’ personas
and provide characteristic knowledge for dialogues.
Since the test set of ConvAI2 has not been made
public, we randomly select 5%sessions from the
original training set as our validation set and use
the original validation set as our test set.
To facilitate reproducibility, we adopt the
datasets shared at ParlAIand conduct pre-
processing with the code available there. More
statistics of the two datasets are shown in Table 7.
B More Implementation Details
The total number of discrete latent states (i.e., N)
is set as 100for all experiments. The dimension
of context-sensitive and context-independent latent
variables are both set as 768. The embedding size
of discrete latent states is set as 768. The MLP
network in fhas two layers with the input,
hidden and output dimensions being 768,100and
100respectively. We choose GPT- 2(117M) as the
backbone of our model. All models are learnedwith Adam (Kingma and Ba, 2015) optimizer with
β= 0.9andβ= 0.999. We set the initial tem-
perature, the minimum temperature, and the anneal
rate of Gumbel Softmax as 1.0,0.5, and 4e−5
respectively. In the training phase, the batch size is
set as 64, and the learning rate is set as 2e−5. In
the test phase, we employ beam search in response
decoding with beam size = 5. Early stopping on
validation is adopted as a regularization strategy.
In our experiments, the profiles in ConvAI2 are
concatenated as a long sequence and serve as the
first sentence in a session. In both DailyDialog and
ConvAI2, 7turns before an utterance are used as
conversation history. All utterances are padded to
a maximum length of 32tokens.
C Derivation of ELBO
L =/summationdisplayElogp(u|u, z, z)
−D(q(c, z, z)∥p(c, z, z)).
(19)
According to the mean-field approximation,
q(c, z, z)∼q(c)q(z)q(z). Therefore, the last
term can be re-written as:10063