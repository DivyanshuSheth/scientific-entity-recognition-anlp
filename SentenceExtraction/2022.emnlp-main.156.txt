4
Binwei Yao, Chao Shi, Likai Zou, Lingfeng Dai
Mengyue Wu, Lu Chen, Zhen Wangand Kai YuSJTU X-LANCE Lab, Department of Computer Science and EngineeringMoE Key Lab of Artificial Intelligence, SJTU AI InstituteShanghai Jiao Tong University, Shanghai, ChinaShanghai Mental Health CenterShanghai Jiao Tong University School of Medicine, Shanghai, China
{yaobinwei, mengyuewu, chenlusz, kai.yu}@sjtu.edu.cn
Abstract
In a depression-diagnosis-directed clinical ses-
sion, doctors initiate a conversation with ample
emotional support that guides the patients to
expose their symptoms based on clinical diag-
nosis criteria. Such a dialogue system is distin-
guished from existing single-purpose human-
machine dialog systems, as it combines task-
oriented and chit-chats with uniqueness in di-
alogue topics and procedures. However, due
to the social stigma associated with mental ill-
ness, the dialogue data related to depression
consultation and diagnosis are rarely disclosed.
Based on clinical depression diagnostic cri-
teria ICD-11 and DSM-5, we designed a 3-
phase procedure to construct D: a Chinese
Dialogue Dataset for Depression-Diagnosis-
Oriented Chat, which simulates the dialogue
between doctors and patients during the diag-
nosis of depression, including diagnosis results
and symptom summary given by professional
psychiatrists for each conversation. Upon the
newly-constructed dataset, four tasks mirror-
ing the depression diagnosis process are estab-
lished: response generation, topic prediction,
dialog summary, and severity classification of
depressive episode and suicide risk. Multi-
scale evaluation results demonstrate that a more
empathy-driven and diagnostic-accurate consul-
tation dialogue system trained on our dataset
can be achieved compared to rule-based bots.
1 Introduction
Given the increasing worldwide health threat
brought by depression, researchers have been ex-
ploring effective methods for depression detection
and diagnosis. Besides automatic depression de-
tection from posts on social media (Orabi et al.,
2018), speech (Zhang et al., 2021b) and multi-
modality (Cummins et al., 2013), the dialogueFigure 1: Comparison of Different Dialogue Types
system is considered an effective tool for large-
scale depression detection (Pacheco-Lorenzo et al.,
2021). It is believed that conversation agents could
reduce the concealment of sensitive information
such as suicidal thoughts caused by social expec-
tations (Schuetzler et al., 2018) and the emotional
hindrance due to the pressure of being judged in
face-to-face conversation (Hart et al., 2017). In past
research, chatbots initiated for depression diagno-
sis are generally implemented based on self-rating
scales (Jaiswal et al., 2019; Arrabales, 2020) or
diagnostic criteria (Philip et al., 2017). The final
diagnosis results are obtained by asking fixed ques-
tions on the scale and corresponding the user’s an-
swers to each question to the scale options. These
chatbots present good sensitivity and specificity in
diagnosis and are more attractive and acceptable
(Vaidyam et al., 2019; Abd-Alrazaq et al., 2019)
than the original self-rating scales. Nevertheless,
the fixed dialogue flow limiting the user’s expres-
sions to specific answers can not realize person-
alized consultation and give emotional support at
an appropriate time, for which there still exists a
big gap between the conversation experience cur-
rent depression diagnosis agents provide and the
face-to-face interview in the process of clinical di-
agnosis.
Interview-based clinical diagnosis in psychia-
try is a complex procedure with the purpose of
collecting and summarizing key symptom infor-2438mation about one patient while providing a chat-
like conversation experience. In clinical practice,
psychiatrists communicate with patients and offer
diagnosis results based on practical experience and
multiple diagnostic criteria. The most clinically-
adopted criteria involve ICD-11 (The World Health
Organization, 2022), DSM-5 (American Psychi-
atric Association, 2013), etc., which define core
symptoms for the depression diagnosis. At the
same time, psychiatrists provide emotional support
such as empathy and comfort during the consulta-
tion to better prompt patients’ self-expression. The
practice of clinical depression diagnosis displays
the possibility of the depression diagnosis dialogue
system in further improving the accuracy of diag-
nosis and user engagement.
Accordingly, the depression diagnostic conver-
sation belongs to a distinguished dialogue from
previously defined dialogue typologies, which is
a combination of task-oriented dialogue and chit-
chat. Such a compound dialogue type could be
defined as Task-Oriented Chat as shown in Figure
1. This type of dialogue requires multiple assess-
ments regarding task completion and chit-chat ex-
perience, which are extremely challenging and still
under-investigated. As a specific domain of Task-
Oriented Chat, the depression diagnosis dialogue
has a clear purpose of the task-oriented dialogue
aiming at medical diagnosis: to collect the patient’s
symptom information and draw a diagnosis conclu-
sion while simultaneously bearing the needs of a
chit-chat dialogue with emotional support: to start
a user-oriented chat and provide emotional support
from time to time. Currently, no datasets are spec-
ified for depression diagnosis, mainly due to the
social stigma associated with clinical privacy and
the complexity of the diagnosis process.
To construct a clinically sound and empa-
thetic depression-diagnosis-oriented dialogue sys-
tem close to clinical practice, we conduct dialogue
collection through consultation dialogue simula-
tion. We devise a three-phase approach to collect
depression diagnostic dialogues (see Figure 2). P1:
Tosimulate medical records , we collect actual pa-
tients’ portraits with a consultation chatbot web
app that asks users fixed questions abstracted from
clinical depression diagnosis criteria ICM-11 and
DSM-5. P2:Torestore psychiatric consultation
conversations , we employ workers to conduct the
consultation dialogue simulation based on the col-
lected portraits. The workers are divided into pa-tients and doctors for separate training by profes-
sionals. The doctor actor is required to obtain fixed
symptom information involved in the diagnostic cri-
teria in the chat, while the patient actor needs to ex-
press according to the symptoms in the portrait. P3:
Toreinforce the clinical setting , professional psy-
chiatrists and psychotherapists supervise the whole
process and filter out unqualified dialogues. In
addition, they provide diagnosis summaries based
on the portrait and dialogue history. We further
annotate the conversation procedure with 10 topic
tags and the symptom summaries with 13 symptom
tags (grouped by core depressive symptoms listed
in DSM-5 and ICD-11). In this way, we propose
D: a Chinese Dialogue Dataset for Depression-
Diagnosis-Oriented Chat. The key contribution of
this paper is as follows:
•A close-to-clinical-practice depression diag-
nosis dataset with 1,339 conversations gen-
erated from actual populations’ portraits, ac-
companied by psychiatrists’ diagnosis sum-
maries, under the framework of most applied
clinical diagnosis criteria ICD-11 and DSM-
5, with multi-dimensional analysis suggesting
that our simulated diagnosis data are reliable
and up to professional standards.
•Experimental validation on four tasks that mir-
ror the real-life diagnosis process: response
generation, topic prediction, dialog summary,
and severity classification of depression and
suicide risk;
•To the best of our knowledge, this is the
first diagnosis dialogue dataset for mental
health, aiming to advance the realization of
an Avante-Garde clinical diagnosis-oriented
dialogue system that combines characteristics
of task-oriented dialogue and chit-chat.
2 Data Collection
To maximize doctor and patient authenticity in a
diagnosis dialogue, we devise a 3-phase collection
paradigm (see Figure2) instead of the commonly-
adopted vanilla crowdsourcing scheme: P1. We
collected natural populations’ portraits (in particu-
lar actual depressive patients) to form pre-diagnosis
records; P2.Simulated natural diagnostic consulta-
tion dialogues based on the portraits; P3.Psychi-
atrists proofread dialogue history and prescribed
professional symptom summaries.2439
2.1 Human-to-Machine Portrait Collection
To overcome the impracticability in obtaining pa-
tients’ medical records covered by doctor-patient
confidential protocol, we designed a consultation
chatbot based on the state machine, which utilizes
fixed questions from clinical criteria to document
each user’s depression symptoms and demographic
information such as age, gender, marital status and
occupation .Depression symptoms are prompted
accordingly, including mood, interest, mental sta-
tus, sleep, appetite, social function, and suicidal
tendency . Users are invited to respond concisely,
e.g., yes/no answer and severity estimation. Com-
bined, we obtained a voluntary and legit depression
portrait. As of the submission of the paper, we
have collected a total of 478 patient portraits. We
estimate the severity of depressive episodes and
suicide risk based on clinical criteria ICD-11 and
DSM-5 for each patient portrait . The result is
shown in Table 1. Sixty-eight portrait providers
reported being diagnosed with depression in an
authorized clinic. Among these providers, 53 are
currently experiencing a depressive episode.
2.2 Human-to-Human Dialogue Collection
To guarantee the quantity, quality, and profession-
alism of our consultation dialogues, we conducted
conversation simulations under the guidance of psy-
chiatrists, following portraits collected in Phase 1.In particular, we first gathered a small number of
dialogues between doctors and patients in real sce-
narios. Based on the prerequisites mentioned above
and clinical depression diagnosis criteria ICD-11
and DSM-5, we released the simulation tasks to
crowdsourcing workers. The whole procedure is
introduced accordingly: 1) Design and Training:
the workers first go through specialized training
and are then divided into doctor and patient roles;
2) Annotation: During the conversation, they are
required to annotate topic transitions; 3) Peer As-
sessment: doctor and patient roles rate each other
on multiple dimensions after the conversation.
2.2.1 Design and Training
Acting Patients It should be noted that most of
our patient actors are not depressive patients. To
help them better interpret the symptoms in the pa-
tient portraits, we provide detailed explanations,
including the severity and duration, and some pa-
tients’ self-reports to help them understand their
inner feelings. Based on the accurately expressed2440symptoms, they extend the natural expressions of
each aspect following doctors’ inquiries in the con-
versation.
Acting Doctors Firstly, we invite licensed psy-
chiatrists and clinical psychotherapists to initiate
consultation conversations with actual depressive
patients, from which we collect reference conver-
sations. Then based on these essential histories,
combined with ICD-11 and DSM-5, we compile
41 symptom items necessary when diagnosing de-
pression and design the questioning logic between
questions of symptoms from mild to severe. The
inquiries weren’t set as specific expressions for
data diversity. Thus, the acting doctors needed to
use colloquial rhetoric to ask relevant information
involved in these questions and obtain enough in-
formation from the patient. Meanwhile, to further
improve the dialogue experience, we require the
acting doctors to conduct a user-oriented dialogue
and provide emotional support when necessary. All
acting doctors start the dialogue simulation after
completing the training process.
2.2.2 Topic Annotation
Considering that the depression diagnostic dialogue
has ambiguity between the chat and task-oriented
dialogue, it’s difficult to define a clear ontology as
other task-oriented dialogues(Chen et al., 2022b).
To facilitate dialogue generation, we conducted
topic annotation on doctors’ utterances. According
to core symptoms covered in the clinical criteria,
we categorized the dialogue topics into mood, in-
terest, mental status, sleep, appetite, somatic symp-
toms, social function, suicidal tendency, and screen-
ing. Notably, we included empathy as a special
topic since it is an essential part of clinical practice.
The doctor actors were asked to mark the topics for
each utterance during the conversation.
2.2.3 Peer Assessment
After the conversation, both sides are required to
rate each other in several dimensions for the need
for quality control which will be detailed in 2.4.
2.3 Professional Diagnosis Collection
To ensure the accordance with clinical protocol, we
further invite professional psychiatrists and clinical
psychotherapists to screen the dialogues that meet
the diagnostic standards and provide psychiatric
diagnostic results and symptom summaries. At the
same time, they score the acting doctors and pa-
tients separately with the real-scenario resemblance
degree.
2.4 Quality Control
Hierarchical screenings are conducted to control
the data quality: whether it is up to clinical standard
and can satisfy our model training purpose. Be-
sides psychiatrists’ clinical protocol screening men-
tioned in part 2.3, we adopt a variety of paradigms
to conduct quality examinations for better training.
We set minimum limits on the length of the dia-
logue, the average utterance length per dialogue
of the doctor, the mutual scores, and the scores
given by the psychiatrist shown in the Table 2. The
unqualified dialogues are excluded.
Ultimately, we collected a total of 4,428 conver-
sations and finally retained 1,339 (30%) after our
stringent up-to-clinical-standard quality screenings.
3 Data Characteristics
3.1 Statistics
The overall statistics of the dataset are shown in
Table 3. As seen in such a diagnosis scenario, suf-
ficient dialogue turns are required: our diagnosis
dialogue exhibit avg. 21.6 turns and avg. 877.6
tokens per dialogue, significantly longer than pre-
vious related datasets, suggesting the discrepancies
of a diagnosis dialogue task and its distinguished
data requirements. Meanwhile, our dataset has col-
loquial and diverse expressions shown by the num-
ber of n-grams and avg. 14.4 tokens per utterance.
3.2 Depression Severity Analysis
To observe differences in patients with different
depression severity, we analyzed conversational
and summary symptom statistics by seriousness.2441
Distribution Feature We present statistics on pa-
tients’ severity of depressive episodes in Table 4.
As the degree of depression worsens, the turns and
dialog lengths get longer due to doctors’ more in-
depth questions on specific topics. The diagnostic
summaries are also longer to include more symp-
toms. The most frequent topics are also subject
to change with severity: suicidal tendency is more
likely to be questioned among severer patients.
Analysis of Symptom Summary We annotated
the 13 core symptoms in the symptom summary
according to ICD-11. From Figure 3, we observe a
difference in the symptom number and ratio from
diagnosis summaries of varying severity. As shown
in Chart (a), control participants have only a few
symptoms, and most are superficial symptoms like
sleep changes and worthlessness, commonly in
healthy populations. As the condition worsens,
the patient has more symptoms, the proportion of
each symptom in the summary is gradually aver-
aged, and suicide thoughts become more frequent.
The moderate and severe patients share the sameaverage symptom number, indicating that a more
fine-grained classification of depression severity
requires additional information besides the number
of symptoms, such as the duration and severity of
each symptom.
3.3 Topic Analysis
To analyze the characteristics of the doctor’s con-
sultation method, we provide perspectives on topic
distribution, transition, and lexical features of em-
pathy.
Topic Distribution To better analyze the propor-
tion of different symptoms, we regrouped the 10
topics annotated by acting doctors. mood, interest,
mental status, social function are grouped into core
andsleep, appetite, somatic symptom are grouped
intobehavior . Figure 4 shows the propotion of re-
grouped topics. Core andbehavior occupy 63.17%
of the conversation, followed by empathy at 23.1%,
indicating that empathy plays an important role in
such a psychiatric diagnosis-oriented dialogue.
Topic Transition Figure 5 illustrates the topic-
transition process. Unlike other commonly seen
dialogues where the topic rarely extends over one
turn, diagnosis topics consistently occur across
turns. Further, core symptoms like mood ,inter-
estare usually inquired in the beginning, gradually
move to behavior symptom such as somatic symp-
tomandsuicide , which are normally experienced
by severe patients. This echoes clinical practice
where a consultation follows a gradual in-depth2442manner and provides emotional support from time
to time.
Lexical Analysis of Empathy As shown in Fig-
ure 4, empathy accounts for a large proportion,
indicating its importance and commonness. We
extract its lexical features and observe that the em-
pathy expressions in our dataset could mainly be
divided into 4 aspects: 1) understanding : "will
understand/is normal" to express understanding
of the patient’s situation; 2) encouragement : "is
valuable" to help patients regain confidence; 3)
suggestions : "you can try/try" to encourage pa-
tients to make changes and try; 4) blessings :
"you will get well soon" to express blessings to
the patient. In actual practice, providing empa-
thetic and emotional support improves the medical
experience and is a critical component of ensuring
the success and completion of a diagnostic ses-
sion(Hardy, 2019).
4 Comparison with Related Datasets
Dis compared with related datasets and mani-
fested its characteristics as having more dialogue
turns and utterances with a sufficient number of
dialogues for model training (see Table 5). This
again emphasizes that depression diagnosis is dis-
tinguished from current dialogue types and exhibits
specific challenges with existing data.
Task-Oriented Dialogue Datasets Task-
oriented dialogue dataset is one of the most
essential components in dialogue systems
study (Ni et al., 2021), consisting of various
datasets for this purpose (Chen et al., 2022a),
i.e. MultiWOZ (Budzianowski et al., 2018),
MSR-E2E (Li et al., 2018), CamRest (Wen et al.,
2016) , Frames (Asri et al., 2017). However, these
dialogue datasets mainly involve daily scenarios
instead of clinical practice. Therefore, the number
of dialogue turns is relatively small, with little
attention paid to providing emotional support.
Emotional Support Datasets A few dialogue
studies on mental health address users’ emotions
in the dialogue process and endeavor to motivate
users suffering from a mood disorder. For exam-
ple, Saha et al. (2021) presents the dialogue dataset
MotiV Ate to impart optimism, hope, and motiva-
tion for distressed people. Recently, works like
ESConv (Liu et al., 2021) switch their attention
to construct a professional emotional support dia-
log Systems. However, they are mainly concerned
with providing encouragement and advice to pa-
tients instead of providing professional diagnoses
for screening purposes.
Medical Diagnosis Dialogue Datasets Some
medical dialogue datasets target at diagnosis, such
as MedDG (Liu et al., 2020) and MedDialog (Zeng
et al., 2020). Meanwhile, some datasets aim
at biomedical language understanding such as
CBLUE (Zhang et al., 2021a). However, these
efforts focus mainly on somatic symptoms and
physical diseases. MedDialog, although containing
a small amount of psychiatric data, lacks profes-
sional psychiatric annotations, limiting its usage for
a depression diagnosis dialogue system. It should
be noted that the diagnosis process of depression
essentially differs from that of somatic disorders.
According to ICD-11 (The World Health Organi-
zation, 2022), in addition to somatic symptoms,
patients often have multiple dimensions of symp-
toms such as mood, interest, mental status, and
social function disorder. For this reason, psychi-
atrists need comprehensive information extracted
from patients’ subjective statements to provide un-
biased diagnoses, leading to a longer, multi-domain
dialogue process.2443Depression-Related Dialogue Dataset Along
with the worldwide attention on depression, a few
dialogue datasets strongly related to depression are
constructed, such as DAIC-WOZ (Gratch et al.,
2014), a multi-modal dataset. The dataset consists
of face-to-face counseling conversations between
a wizard interviewer and patients who suffer from
depression, anxiety, etc. However, DAIC-WOZ
only includes 189 dialogues without specific anno-
tations, which is insufficient for dialogue genera-
tion training.
5 Experiments
5.1 Tasks
Upon the construction of Dwith 1,339 well-
annotated and up-to-clinical-standard depression
diagnosis conversations, we can support an en-
tire generation and diagnosis process mirroring
the real-life clinical consultation scenario. We
split the entire depression diagnosis dialogue proce-
dure into 4 subtasks: Response Generation aims
to generate doctors’ probable response based on
the dialog context; Topic Prediction predicts the
topic of the response based on the dialogue con-
text. In our experiments, we jointly optimize the
topic prediction model and the response genera-
tion model. We take the topic as a special first
token of dialogue response; Dialogue Summary
generates symptom summaries based on the entire
dialog history; Severity Classification separately
predicts the severity of depressive episodes and the
suicide risk based on the dialogue context and di-
alogue summary. Binary (positive/negative) and
fine-grained 4-class (positive further classed into
mild, medium, and severe) classifications are both
investigated.
5.2 Backbone Models
We use Transformer (Vaswani et al., 2017)
pretrained on MedDialog (Zeng et al., 2020),
BART (Lewis et al., 2019) pretrained on Chinese
datasets (Shao et al., 2021), CPT (Shao et al., 2021)
and BERT (Devlin et al., 2019) as backbone models
to conduct the experiments.
5.3 Objective Evaluation
Generation and Summarization We evaluate
theresponse generation task anddialog summary
taskwith objective metrics including BLEU-2 (Pa-
pineni et al., 2002), Rouge-L (Lin, 2004), ME-
TEOR (Banerjee and Lavie, 2005) to measure the
similarity between model generated responses and
labels. To show the generation diversity, we also
compute DIST-2 (Li et al., 2015). We implement
jiebafor tokenization and compute the metrics at
the word level.
Results for the response generation task are pre-
sented in Table 6. Five observations can be drawn:
1) BART and CPT exhibit similar generation per-
formance on our dataset; 2) Both models vastly
outperform Transformer, which is pretrained on
the medical corpus, suggesting that, on the one
hand, pertrained language models with more pa-
rameters could improve generation performance;
on the other hand, depression diagnosis is differ-
ent from traditional somatic-oriented medical dia-
logues; 3) Based on the topic of response predicted
by the model itself, the model could generate a
more accurate response, which is of great signifi-
cance for the model to be applied in real human-
machine interaction scenarios; 4)Based more accu-
rate topics predicted by BERT, response generation
performance is enhanced, indicating that higher
topic prediction accuracy can effectively improve
generation accuracy. 5) Given golden topics, gen-
eration performance can be further enhanced.
Topic Prediction accuracy results are shown as
Topic ACC. in Table 6. We adopted the topic cate-
gory regrouped in 4 and similar trend is observed:
BART ≈CPT>Transformer. The F1 of each topic
(see Table 7) shows that the accuracy of empathy
is the bottleneck of this task, indicating that proper
timing of empathy remains challenging for models
and is a potential direction for further work.2444Results for Dialog Summary are listed in Table
8, CPT is on par with BART regarding the N-gram
overlap with human references. Nevertheless, CPT
exhibits a higher DIST-2 score, suggesting its su-
periority in generation diversity. We manually an-
notated summaries by 13 symptoms from ICD-11
and calculated the summaries’ sample average F1
score on the multi-label classification task of symp-
toms, where CPT and BART perform the same. It
shows that the summary generated by the model
can accurately summarize most symptoms.
Severity Classification Binary and 4-class clas-
sification are evaluated by average weighted pre-
cision, recall, and F1 by sklearn, and results of
depression severity and suicide risk severity are
shown in Table 9 and Table 10. For the classifi-
cation of depression severity, we conducted ex-
periments based on dialogue history and symp-
tom summaries respectively. The evaluation re-
sults show that the accuracy of 2-classification
and 4-classification based on summaries is signif-
icantly improved, indicating that symptom sum-
maries have extracted vital information from the
dialogue, being extremely helpful for diagnosis.
Although the results of 4-classification tasks are
relatively poor compared with the performance in
2-classification tasks, as a screening tool, the bi-
nary classification results are already sufficient in
the practical application of the system.
5.4 Human Interactive Evaluation
To comprehensively evaluate the model’s conver-
sation experience with the user, we include human
interactive evaluation for CPT with a rule-based
chatbot. Evaluators were invited to chat with both
bots in a random order upon the provided patient
portrait and rated on 4 aspects with a 1-5 scale:
Fluency measures how fluently the conversation
flows; Comforting measures how comforting the
responses are; Doctor-likeness measures to what
extent does the chatbot flexibly adjust the topic ac-
cording to the patient’s description; Engagingness
measures to what time could the chatbot maintain
their attention to continue the chat.
The interactive human evaluation results are il-
lustrated in Table 11. The CPT-based chatbot out-
performs rule-based bots on all four metrics, sug-
gesting that dialogue models can help us build more
human-like and user-friendly depression diagnosis
systems. In particular, the discrepancy in engag-
ingness indicates that users prefer chatbots that can
better understand and comfort users in completing
the depression screening process. We give some
empathy examples of human interactive evaluation
in Table 12, indicating that the model can gener-
ate diverse empathy representations from different
aspects.
6 Conclusion
In this paper, we designed a 3-phase data collec-
tion and constructed a close-to-clinical-practice
and up-to-clinical-standard depression diagnosis
dataset with 1,339 conversations accompanied by
psychiatrists’ diagnosis summaries. Further, we
conduct experimental validation on multiple tasks
with state-of-art models and compare the results2445
with objective and human evaluation. The eval-
uation results show that the model-based chatbot
outperforms traditional rule-based dialogue bots
in all metrics, indicating that a more user-friendly
dialogue system can be built with our dataset. How-
ever, the model is still not effective enough in gen-
erating appropriate empathic responses suggesting
that the model needs further improvement to gener-
ate more appropriate empathy during the consulta-
tion process.
Limitations
Our work has some limitations. The principal limit
of our work is that our dataset Dis in Chinese,
which in line with Chinese culture and expression
habits. Therefore, it may not be applicable to trans-
late the conversations into another language di-
rectly, so further exploration is required for our
work to transfer to other languages. However,
considering that there are no similar datasets in
other languages published before, we hope that
our data collection method and data form (dia-
log+summary+diagnosis) could inspire more re-
search on this unique type of dialogue in the future.
Additionally, for patient privacy protection, our
dialogue data is collected in a simulated manner,
not from real scenarios. This approach helps con-
struct a more secure and generalizable consultation
dialogue system because we have defined the act-
ing doctors’ behaviors during the data collection
process, that is, the system behavior range. But it
should be mentioned that our dataset cannot restore
the expressions of actual patients and doctors. For
this reason, the textual features of acting patients
in our dataset are not sufficient for the classifica-
tion of depression. Therefore, it is meaningful to
explore the construction of a more empathy-driven
and diagnostic-accurate consultation dialogue sys-
tem based on our dataset rather than conduct textual
depression classification.Ethics Statement
This research study has been approved by the
Ethics Review Board at the researchers’ institution
(Ethics Approval No. I2022158P). Different stages
in data collection comply with corresponding ethi-
cal requirements and we endeavour to protect pri-
vacy and respect willingness of our data providers
and annotators.
Specifically, our data collection falls under the
Personal Information Protection Law of the Peo-
ple’s Republic of China. In the phase of portrait
collection, the collection application was developed
as a WeChat mini program, which complied with
the privacy protection agreement and passed the se-
curity and privacy check of WeChat mini program
before releasing on the platform. Furthermore, all
the portrait providers signed an informed consent
form to give permission to collect their anonymous
information for research purposes.
In the phase of the dialogue collection process,
all the workers and annotators are informed about
the purpose of our data collection and equally
paid for their workload. In the phase of the dia-
logue examination process, the psychiatrists and
psychotherapists are licensed to practice and paid
equally for their workload.
To protect users’ privacy, we anonymized the
portraits by storing them without a one-to-one cor-
respondence between the identification informa-
tion required for user login and the data we use
in research. Therefore, all the information that
could uniquely identify individual people is ex-
cluded from our dataset and research process. Re-
garding offensive content, we rigorously filtered
the dataset manually to ensure that it did not con-
tain any offensive content or words encouraging
patients to self-harm and commit suicide. We will
also require the users of Dto comply with a data
usage agreement to prevent the invasion of privacy
or other potential misuses.
Acknowledgements
This project is supported by National Natural Sci-
ence Foundation of China (Grant No.61901265,
92048205), Shanghai Municipal Science and Tech-
nology Major Project (2021SHZDZX0102), SJTU
Medicine-Engineering Project (No.YG2020YQ25),
and Xuhui District Artificial Intelligence Medical
Hospital Cooperation Project (2021-005).2446References24472448A Data Example
The portrait (Figure 6), the dialogue (Figure 8 and
Figure 9), and diagnosis (Figure 10) belong to the
same data example in our dataset. We marked
the topic (if any) of the doctor’s responses in the
conversation history. In this example, the doctor
combined sleep and appetite into one question, so
only one topic of appetite was marked. In addition,
for the convenience of presentation, we have com-
bined the doctor’s multiple utterances of the same
turn into one sentence. To compare machine gener-
ation performance with humans, we provide data
examples of the same portrait in this section and
Section E - Human Interactive Example. Dialogues
in Dwere simulated based on diverse portraits
showed in Section B. More data examples can be
found in website https://x-lance.github.io/D4.
B Data Characteristics
Statistics of Portraits’ Demographic Informa-
tion The aggregated demographic information of
478 portraits is provide in Figure 7.
Topic Examples In Figure 11, we present the 10
topics with their typical examples and hot words.Lexical Feature of Empathy In Figure 12, we
show the lexical feature of empathy words in our
dataset in the sunburst figure.
C Backbone Model Introduction
Rule-based Model Without existing chatbots
having the same function, we built the rule-based
chatbot by state machine as the baseline. Based
on ICD-11 (The World Health Organization, 2022),
DSM-5 (American Psychiatric Association, 2013),
the bot covers the same topics as the dialogue sim-
ulation process mentioned in 2.2.2. This robot has
fixed question templates and recognizes the user’s
answer based on regular matching, based on which
it performs state jumps until all symptom informa-
tion is acquired.
Transformer We use the classic sequence-to-
sequence model (Vaswani et al., 2017) to conduct
the response generation and topic prediction exper-
iment. The implementation used is HuggingFace.
The parameters are loaded from the transformer
pretrained on MedDialog (Zeng et al., 2020), a
Chinese Medical Dialogue Dataset.
BART BART (Lewis et al., 2019) is a denoising
sequence-to-sequence pre-trained model, which is
a start-of-art model for both text generation and
summary tasks. For this reason, we use Bart pre-
trained on Chinese datasets (Shao et al., 2021) to
conduct the response generation and dialog sum-
mary task.
CPT CPT (Shao et al., 2021) is a novel Chinese
pre-trained un-balanced transformer model, which
is not only effective in generation tasks but also has
powerful classification ability, so we choose it as
our backbone model to conduct the generation task
and also compare its performance of classification
task with BART.
BERT Bert (Devlin et al., 2019) is effectively
used for a wide range of language understanding
tasks, such as question answering and language
inference. Thus, we use the versionwhich is pre-
trained on eight popular Chinese NLP datasets, to
conduct the classification task.
D Training Details
The division of train, validation, and test sets for
all experiments is close to 8:1:1, and the data of24492450
different depression severity are also internally dis-
tributed according to the above ratio.
Response Generation For BART and CPT mod-
els, the initial parameters are pretrained on Chinese
datasets (Shao et al., 2021). We use a cosine learn-
ing rate scheduler with the initial learning rate of
1e-5, 100 warm-up steps, and the AdamW opti-
mizer (Loshchilov and Hutter, 2019). Beam search
where the number of beams is 4 is used in response
generation. Models are trained for 30 epochs. The
one with the best BLEU-2 metric on the evaluation
set is selected for the test.
For the Transformer, we use the implementation
by HuggingFace. We load the parameters of the
Transformer pretrained on MedDialog (Zeng et al.,
2020). The weight parameters were learned with
Adam and a linear learning rate scheduler with the
initial learning rate of 1.0e-4 and 100 warm-up
steps. The batch size was set to 16. Top- krandom
sampling (Fan et al., 2018) is used in response
generation. The model is trained for 20 epochs.
The one with the highest BLEU-2 score on the
evaluation set is chosen for the test.
We spliced multiple sentences of the doctor in
the same round into the dialogue history, and se-
lected the last topic as the topic of the new sentence.
Due to the limitation of models’ positional embed-
ding, we intercepted data with a length over 512.
In the response generation task, we try to keep the
most recent conversations as they are more instruc-
tive to the current response.2451Dialog Summary Both BART and CPT models
are trained for 50 epochs. We use a cosine learning
rate scheduler with the initial learning rate of 1e-5
and 100 warm-up steps and the AdamW optimizer.
The one with the highest rouge-1 metric on the
evaluation set is selected for the test.
If the input dialog history is longer than the
model’s input size, we retain the 512 tokens in
the middle of the dialog.
Severity Classification For BERT, BART, and
CPT models, we use a cosine learning rate sched-
uler with the initial learning rate of 1e-5, 100 warm-
up steps, and the AdamW optimizer (Loshchilov
and Hutter, 2019). Models are trained for 30
epochs. The one with the best F1-score metric
on the evaluation set is selected for the test.
For the classification based on dialog history,
we retain 512 tokens in the middle of the dialog.
For the classification based on dialog summary, we
retain 128 tokens in the middle of the summary.
E Generation Examples
Response Generation As shown in Figure 13,
we selected one representative example of the gen-
erated responses by different models. The exam-
ples in the figure show us that the correct topic
helps the model generate more reliable and secure
replies.
Dialog Summary Generation In Figure 14, we
present an example of the generated summary by
different models. The models list most symptoms
of the patient.
Human Interactive Example We give a dia-
logue example with dialog summary and depressive
severity generated by CPT during human evalua-
tion in Figure 15 and human evaluation in Figure
16. In parentheses before the chatbot’s sentence,
we marked the topic predicted by the model. To
clarify the correspondence between dialogue and
summary, We have identified the correct symptom
in the symptom summary with the same color as its
location in the conversation. It can be seen that the
model completed the entire consultation dialogue
task and gave a dialogue summary covering almost
all symptoms accurately.
F Worker Training Method
Acting Patients To help acting patients better
interpret the symptoms in the patient portraits, we2452
provide detailed explanations of the symptoms in
Figure 17 and Figure 18, including the severity and
duration. Besides expressing symptom accurately,
they are required to imagine possible life events
of the portrait’s provider and talk with a doctor
about it to express the patient’s inner feelings in
the process of telling the events.
Acting Doctors We compile the 41 symptom
items in Figure 19 and Figure 20 that doctors need
to know when diagnosing depression, and design
the questioning logic between questions of asking
symptoms from mild to severe. The basic require-
ment is to obtain enough information from the pa-
tient during the conversation. At the same time, in
order to further improve the dialogue experience,
we require the acting doctors to: 1) Conduct the
dialogue centered on the patient’s complaint, that
is, give priority to asking the patient’s initiative
symptom-related questions; 2) Ask further ques-
tions based on the patient’s experience to elicit
additional disclosure; 3) Give the patient certain
feedback, e.g., empathy or comfort words when the
patient talks about what they are going through.
G Quality Control
To create transparency about quality control, the
statistics of dialogues removed is provided in Ta-
ble 13. We have collected 4,457 dialogues, and
961 dialogues are removed because they haven’t
completed the entire diagnosis dialogues. 1,814 di-
alogues are automatically dropped by the stringent
quality control criteria in Table 2. Professional psy-chiatrists and clinical psychotherapists screening
the dialogues dropped 342 dialogues which unsuc-
cessfully meet clinical standards. Eventually, we
selected 1,339 dialogues into D.
H The Data Collection Platform
Figure 21 is screenshot of doctors’ user interface,
and Figure 22 is screenshot of the patients’.2453245424552456245724582459