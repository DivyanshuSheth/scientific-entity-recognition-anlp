
Shib Sankar Dasgupta, Michael Boratko, Siddhartha Mishra ,
Shriya Atmakuri , Dhruvesh Patel , Xiang Lorraine Li , Andrew McCallum
Manning College of Information & Computer Sciences
University of Massachusetts Amherst
{ssdasgupta,mboratkro,siddharthami,satmakuri,
dhruveshpate,xiangl,mccallum}@cs.umass.edu
Abstract
Learning representations of words in a con-
tinuous space is perhaps the most funda-
mental task in NLP, however words interact
in ways much richer than vector dot prod-
uct similarity can provide. Many relation-
ships between words can be expressed set-
theoretically, for example adjective-noun com-
pounds (eg. “red cars” ⊆“cars”) and homo-
graphs (eg. “tongue” ∩“body” should be sim-
ilar to “mouth”, while “tongue” ∩“language”
should be similar to “dialect”) have natural
set-theoretic interpretations. Box embeddings
are a novel region-based representation which
provide the capability to perform these set-
theoretic operations. In this work, we provide
a fuzzy-set interpretation of box embeddings,
and learn box representations of words using
a set-theoretic training objective. We demon-
strate improved performance on various word
similarity tasks, particularly on less common
words, and perform a quantitative and qualita-
tive analysis exploring the additional unique
expressivity provided by W2B.
1 Introduction
The concept of learning a distributed representa-
tion for a word has fundamentally changed the field
of natural language processing. The introduction
of efficient methods for training vector representa-
tions of words in Word2Vec (Mikolov et al., 2013),
and later GloVe (Pennington et al.) as well as Fast-
Text (Bojanowski et al., 2017) revolutionized the
field, paving the way for the recent wave of deep
architectures for language modeling, all of which
implicitly rely on this fundamental notion that a
word can be effectively represented by a vector.
While now ubiquitous, the concept of represent-
ing a word as a single point in space is not partic-
ularly natural. All senses and contexts, levels of
abstraction, variants and modifications which the
word may represent are forced to be captured byFigure 1: Given a corpus, Gumbel Boxes are trained
as a fuzzy sets representing sets of windows with
given center or context words. The representations
can then be queried using multiple set-theoretic oper-
ations. In the graphic, bank\river overlaps highly
withfinance , and we would also expect high over-
lap with other boxes (not depicted) such as firm or
brokerage (see Table 6). Similarly, we would expect
boxes for chemical properties such as hardness or
solubility to overlap with the dotted region indicat-
ingproperty \finance ∩chemistry , and indeed
we do observe such overlaps in the W2Bmodel
(see Table 7).
the specification of a single location in Euclidean
space. It is thus unsurprising that a number of
alternatives have been proposed.
Gaussian embeddings (Vilnis and McCallum,
2015) propose modeling words using densities in
latent space as a way to explicitly capture uncer-
tainty. Poincaré embeddings (Tifrea et al., 2019)
attempt to capture a latent hierarchical graph be-
tween words by embedding words as vectors in
hyperbolic space. Trained over large corpora via
similar unsupervised objectives as vector baselines,
these models demonstrate an improvement on word2263similarity tasks, giving evidence to the notion that
vectors are not capturing all relevant structure from
their unsupervised training objective.
A more recent line of work explores region-
based embeddings, which use geometric objects
such as disks (Suzuki et al., 2019), cones (Vendrov
et al., 2016; Lai and Hockenmaier, 2017; Ganea
et al., 2018), and boxes (Vilnis et al., 2018) to rep-
resent entities. These models are often motivated
by the need to express asymmetry, benefit from par-
ticular inductive biases, or benefit from calibrated
probabilistic semantics. In the context of word rep-
resentation, their ability to represent words using
geometric objects with well-defined intersection,
union, and difference operations is of interest, as
we may expect these operations to translate to the
words being represented in a meaningful way.
In this work, we introduce W2B, a
region-based embedding for words where each
word is represented by an n-dimensional hyperrect-
angle or “box”. Of the region-based embeddings,
boxes were chosen as the operations of intersec-
tion, union, and difference are easily calculable.
Specifically, we use a variant of box embeddings
known as Gumbel boxes, introduced in (Dasgupta
et al., 2020). Our objective (both for training and
inference) is inherently set-theoretic, not proba-
bilistic, and as such we first provide a fuzzy-set
interpretation of Gumbel boxes yielding rigorously
defined mathematical operations for intersection,
union, and difference of Gumbel boxes.
We train boxes on a large corpus in an unsu-
pervised manner with a continuous bag of words
(CBOW) training objective, using the intersection
of boxes representing the context words as the rep-
resentation for the context. The resulting model
demonstrates improved performance compared to
vector baselines on a large number of word simi-
larity benchmarks. We also compare the models’
abilities to handle set-theoretic queries, and find
that the box model outperforms the vector model
90% of the time. Inspecting the model outputs
qualitatively also demonstrates that W2B
can provide sensible answers to a wide range of
set-theoretic queries.
2 Background
Notation LetV={v}denote the vocabu-
lary, indexed in a fixed but arbitrary order. A sen-
tence s= (s, . . . , s)is simply a (variable-length)
sequence of elements in our vocab s∈V. Weview our corpus C={s}as a multisetof all sen-
tences in our corpus. Given some fixed “window
size” ℓ, for each word sin a sentence swe can
consider the window centered at i,
w= [s, . . . , s, . . . , s],
where we omit any indices exceeding the bounds
of the sentence. Given a window wwe denote the
center word using cen(w) =s, and denote all
remaining words as the context con(w). We let
Cbe the multiset of all windows in the corpus.
2.1 Fuzzy sets
Given any ambient space Ua set S⊆Ucan be
represented by its characteristic function 1:U→
{0,1}such that 1(u) = 1 ⇐⇒ u∈S. This
definition can be generalized to consider functions
m:U→[0,1], in which case we call the pair
A= (U, m)afuzzy set andm=mis known
as the membership function (Zadeh, 1965; Klir
and Yuan, 1996). There is historical precedent for
the use of fuzzy sets in computational linguistics
(Zhelezniak et al., 2019a; Lee and Zadeh, 1969).
More generally, fuzzy sets are naturally required
any time we would like to learn a set representation
in a gradient-based model, as hard membership
assignments would not allow for gradient flow.
In order to extend the notion of set intersection to
fuzzy sets, it is necessary to define a t-norm , which
is a binary operation ⊤:[0,1]×[0,1]→[0,1]
which is commutative, monotonic, associative, and
equal to the identity when either input is 1. The
min and product operations are common exam-
ples of t-norms. Given any t-norm, the intersec-
tion of fuzzy sets AandBhas membership func-
tionm(x) =⊤(m(x), m(x)). Any t-norm
has a corresponding t-conorm which is given by
⊥(a, b) = 1 − ⊤(1−a,1−b); for min the t-
conorm is max, and for product the t-conorm is
the probabilistic sum, ⊥(a, b) =a+b−ab.
This defines the union between fuzzy sets, where
m(x) =⊥(m(x), m(x)). Finally, the com-
plement of a fuzzy set simply has member function
m(x) = 1−m(x).
2.2 Box embeddings
Box embeddings, introduced in (Vilnis et al., 2018),
represent elements xof some set Xas a Cartesian2264product of intervals,
Box(x):=Y[x, x]
= [x, x]× ··· × [x, x]⊆R.(1)
The volume of a box is simply the multiplication
of the side-lengths,
|Box(x)|=Ymax(0 , x−x),
and when two boxes intersect, their intersection is
Box(x)∩Box(y)
=Y[max( x, y),min(x, y)].
Boxes are trained via gradient descent, and these
hard min andmax operations result in large ar-
eas of the parameter space with no gradient signal.
Dasgupta et al. (2020) address this problem by mod-
eling the corners of the boxes {x}with Gumbel
random variables, {X}, where the probability of
any point z∈Rbeing inside the box Box(x)is
given by
P(z∈Box(x)) =YP(z> X)P(z< X).
For clarity, we will denote the original (“hard”)
boxes as Box, and the Gumbel boxes as Box. The
Gumbel distribution was chosen as it was min/max
stable, thus the intersection Box(x)∩Box(y)
which was defined as a new box with corners mod-
eled by the random variables {Z}where
Z:= max( X, Y)andZ:= min( X, Y)
is actually a Gumbel box as well. Boratko et al.
(2021) observed that
P(z∈Box(x)∩Box(y)) =
P(z∈Box(x))P(z∈Box(y)),(2)
and also provided a rigorous probabilistic inter-
pretation for Gumbel boxes when embedded in a
space of finite measure, leading to natural notions
of “union” and “intersection” based on these op-
erations of the random variables (Boratko et al.,
2021).
In this work, we do not embed the boxes in a
space of finite measure, but instead interpret them
asfuzzy sets , where the above probability (of a
point zbeing inside the Gumbel box) acts as a soft
membership function.3 Fuzzy Sets of Windows
In this section, we describe the motivation for
using fuzzy sets to represent words, starting with
an approach using traditional sets.
First, given a word v∈V, we can consider the
windows centered at v,
cen(v):={w∈C:cen(w) =v},
and the set of windows whose context contains v,
con(v):={w∈C:con(w)∋v}.
Note that cenis a function which takes in a word
and returns a set of windows, whereas cenis a
function which takes in a window and returns the
center word, and a similar distinction holds for
conandcon.
A given window is thus contained inside the
intersection of the sets described above, namely
[w, . . . , w, . . . , w]
∈cen(w)∩\con(w).
As an example, the window
w=“quick brown fox jumps over” ,
is contained inside the cen(“fox” )set, as
well as con(“quick” ),con(“brown” ),
con(“jumps” ),con(“over” ). With this formu-
lation, the intersection of the consets provide a
natural choice of representation for the context. We
might hope that cen(v)provides a reasonable
representation for the word vitself, however by
our set theoretic definition for any u̸=vwe have
cen(u)∩cen(v) =∅.
We would like the representation of uto overlap
withvifuhas “similar meaning” to v, i.e. we
would like to consider
]cen(v):={w∈W:cen(w)similar to v}.
A crisp definition of meaning orsimilarity is not
possible (Hill et al., 2015; Finkelstein et al., 2001)
due to individual subjectivity. Inter-annotator
agreement for Hill et al. (2015) is only 0.67, for
example, which makes it clear that ]cen(v)could
not possibly be represented as a traditional set. In-
stead, it seems natural to consider ]cen(v)as rep-
resented by a fuzzy set (W, m ), where m(w)∈2265[0,1]can be thought of as capturing graded similar-
ity between vandcen(w).In the same way, we
can define
^con(v):={w∈W:con(v)∋wsimilar to v},
which would also be represented as a fuzzy set.
As we wish to capture these similarities with a
machine learning model, we now must find train-
able representations of fuzzy sets.
Remark 1. Our objective of learning trainable rep-
resentations for these sets provides an additional
practical motivation for using fuzzy sets - namely,
the hard assignment of elements to a set is not dif-
ferentiable. Any gradient-descent based learning
algorithm which seeks to represent sets will have
to consider a smoothed variant of the characteristic
function, which thus leads to fuzzy sets.
4 Gumbel Boxes as Fuzzy Sets
In this section we will describe how we model
fuzzy sets using Gumbel boxes (Dasgupta et al.,
2020). As noted in Section 2.2, the Gumbel Box
model represents entities x∈XbyBox(x)
with corners modeled by Gumbel random variables
{X}. The probability of a point z∈Rbeing
inside this box is
Since this is contained in [0,1], we have that
(R, P(z∈Box(x))is a fuzzy set. For clarity,
we will refer to this fuzzy set as Box(x).
The set complement operation has a very nat-
ural interpretation in this setting, as Box(x)
has membership function 1−P(z∈Box(x)),
that is, the probability of znot being inside the
Gumbel box. The product t-norm is a very natu-
ral choice as well, as the intersection Box(x)∩
Box(y)will have membership function P(z∈
Box(x))P(z∈Box(y)), which is precisely the
membership function associated with Box(x)∩
Box(y), where here the intersection is between
Gumbel boxes as defined in Dasgupta et al. (2020).
Finally, we find that the membership function forthe union Box(x)∪Box(y)is given (via the
t-conorm) by
P(z∈Box(x)) +P(z∈Box(y))−
P(z∈Box(x)P(z∈Box(y)).(3)
Remark 2. Prior work on Gumbel boxes had not
defined a union operation on Gumbel boxes, how-
ever (3)has several pleasing properties apart from
being a natural consequence of using the product
t-norm. First, it can be directly interpreted as the
probability of zbeing inside Box(x)orBox(y).
Second, if the Gumbel boxes were embedded in a
space of finite measure, as in Boratko et al. (2021),
integrating (3)would yield the probability corre-
sponding to P(Box( x)∪Box(y)).
To calculate the size of the fuzzy set Box(x)
we integrate the membership function over R,
|Box(x)|=ZP(z∈Box(x))dz.
The connection between this integral and that
which was approximated in Dasgupta et al. (2020)
is provided by Lemma 3 of Boratko et al. (2021),
and thus we have
where µ, µare the location parameters for the
Gumbel random variables X, X, respectively.
As mentioned in Section 2.2, Gumbel boxes are
closed under intersection, i.e. Box(x)∩Box(y)
is also a Gumbel box, which implies that the size
of the fuzzy intersection
|Box(x)∩Box(y)|
=ZP(z∈Box(x))P(z∈Box(y))dz
=ZP(z∈Box(x)∩Box(y))dz
can be approximated as well. As both of these
are tractable, integrating (3)is also possible via
linearity. Similarly, we can calculate the size of
fuzzy set differences, such as
|Box(x)\Box(y)|=ZP(z∈Box(x))[1−P(z∈Box(y))]dz.
By exploiting linearity and closure under intersec-
tion, it is possible to calculate the size of arbitrary
fuzzy intersections, unions, and set differences, as
well as any combination of such operations.2266Remark 3. If our boxes were embedded in a space
of finite measure, as in Boratko et al. (2021), the
sizes of these fuzzy sets would correspond to the
intersection, union, and negation of the binary ran-
dom variables they represent.
5 Training
In this section we describe our method of training
fuzzy box representations of words, which we refer
to as W2B.
In Section 3 we defined the fuzzy sets ]cen(v)
and]cen(v), and in Section 4 we established that
Gumbel boxes can be interpreted as fuzzy sets, thus
forW2Bwe propose to learn center and
context box representations
cen(v):= Box(]cen(v))
con(v):= Box(^con(v)).
Given a window, w= [w, . . . , w, . . . , w],
we noted that wmust exist in the intersection,
]cen(w)∩\^con(w) (4)
and thus we consider a max-margin training objec-
tive where the score for a given window is given as
f(w):=cen(w)∩\con(w). (5)
To create a negative example wwe follow the
same procedure as CBOW from Mikolov et al.
(2013), replacing center words with a word sam-
pled from the unigram distribution raised to the 3/4.
We also subsample the context words as in Mikolov
et al. (2013). As a vector baseline, we compare
with a W2Vmodel trained in CBOW-style.
We attach the source code with supplementary ma-
terial.
6 Experiments and Results
We evaluate both W2VandW2B
on several quantitative and qualitative tasks that
cover the aspects of semantic similarity, related-
ness, lexical ambiguity, and uncertainty. Follow-
ing the previous relevant works (Athiwaratkun
and Wilson, 2018; Meyer and Lewis, 2020; Ba-
roni et al., 2012), we train on the lemmatized
WaCkypedia corpora (Baroni et al., 2009), specif-
ically ukWaC which is an English language cor-
pus created by web crawling. After additionalpre-processing (details in appendix A) the corpus
contains around 0.9 billion tokens, with just more
than 112k unique tokens in the vocabulary. Noting
that an n-dimensional box actually has 2nparam-
eters (for min and max coordinates), we compare
128-dimensional W2Vembeddings and 64-
dimensional W2Bembeddings for all our
experiments. We train over 60 different models for
both the methods for 10 epochs using random sam-
pling on a wide range of hyperparameters (please
refer to appendix C for details including learning
rate, batch size, negative sampling, sub-sampling
threshold, etc.). In order to ensure that the only dif-
ference between the models was the representation
itself, we implemented a version of W2Vin
PyTorch, including the negative sampling and sub-
sampling procedures recommended in (Mikolov
et al., 2013), using the original implementation as
a reference. As we intended to train on GPU, how-
ever, our implementation differs from the original
in that we use Stochastic Gradient Descent with
varying batch sizes. We provide our source code at
https://github.com/iesl/word2box .
6.1 Word Similarity Benchmarks
We primarily evaluate our method on several word
similarity benchmarks: SimLex-999 (Hill et al.,
2015), WS-353 (Finkelstein et al., 2001), YP-130
(Yang and Powers, 2006), MEN (Bruni et al., 2014),
MC-30 (Miller and Charles, 1991), RG-65 (Ruben-
stein and Goodenough, 1965), VERB-143 (Baker
et al., 2014), Stanford RW (Luong et al., 2013),
Mturk-287 (Radinsky et al., 2011) and Mturk-771
(Halawi et al., 2012). These datasets consist of
pairs of words (both noun and verb pairs) that are
annotated by human evaluators for semantic simi-
larity and relatedness.
In table 1 we compare the W2Band
W2Vmodels which perform best on
the similarity benchmarks. We observe that
W2Boutperforms W2V(as well
as the results reported by other baselines) in the
majority of the word similarity tasks. We outper-
form W2Vby a large margin in Stanford
RW and YP-130, which are the rare-word datasets
for noun and verb respectively. Noticing this ef-
fect, we enumerated the frequency distribution of
each dataset. The datasets fall in different sections
of the frequency spectrum, e.g., Stanford RW (Lu-
ong et al., 2013) only contains rare words which
make its median frequency to be 5,683, whereas2267
WS-353 (Rel) (Finkelstein et al., 2001) contains
many more common words, with a median fre-
quency of 64,490. We also observe a larger relative
performance improvement over W2Von
other datasets which have low to median frequency
words, e.g. MC-30, MEN-Tr-3K, and RG-65, all
with median frequency less than 25k. The order
they appear in the table and the subsequent plots
is lowest to highest frequency, left to right. Please
refer to Appendix B for details.
In figure 2, we see that W2Boutper-
forms W2Vmore significantly with less
common words. In order to investigate further, we
selected four datasets (RW-Stanford (rare words),
Simelex-999, SimVerb-3500,WS-353 (Rel)), trun-
cated them at a frequency threshold, and calculated
the correlation for different levels of this thresh-
old. In figure 3, we demonstrate how the perfor-
mance gap between W2BandW2V
changes as increasing amount frequent words are
added to these similarity datasets. We posit that the
geometry of box embeddings is more flexible in the
way it handles sets of mutually disjoint words (such
as rare words) which all co-occur with a more com-
mon word. Boxes have exponentially many corners,
relative to their dimension, allowing extreme flexi-
bility in the possible arrangements of intersection
to represent complicated co-occurrances.
6.2 Set Theoretic Operations
All the senses, contexts and abstractions of a word
can not be captured accurately using a point vector,
and must be captured with sets. In this section,
we evaluate our models capability of representing
sets by performing set operations with the trained
models.6.2.1 Dataset
Homographs, words with identical spelling but dis-
tinct meanings, and polysemous words are ideal
choice of probe for this purpose, as demonstrated
by the “bank”, “river” and “finance” example of
Figure 1. We constructed set-theoretic logical op-
erations on words based on common polysemous
words and homographs (Nelson et al., 1980). For
example, the word “property” will have association
with words related both “asset” and “attribute”, and
thus the union of the later two should be close to the
original word “property”. Likewise, the intersec-
tion set of “property” and “math” should contain
many words related to mathematical properties or
concepts.
To this end, we created a dataset consisting of
triples (A, B, C )where A◦Bshould yield a set
similar to C, for various set-theoretic operations
◦. In this task, given two words AandBand a
set theoretic operation ◦, we try to find the rank of
word Cin the sorted list based on the set similar-
ity (vector similarity scores for the vectors) score
between A◦Band all words in the vocab. The
dataset consists of 52 examples for both Union and
Negation, and 20 examples for Intersection. The
details of the dataset can be found in Appendix D.
6.2.2 Quantitative Results
In Table 2, we report the percentage of times
W2Boutperforms W2V, i.e. the
model yields better rank for the word C. Note
that it is not clear how to design the union, dif-
ference or the intersection operations with vectors.
We consider several relevant choices, including
component-wise operations (addition, subtraction,
min and max) which yield a representation for
A◦B, as well as operations which operate on the
scores - eg. score max pooling ranks each word X
using max( A·X, B·X), and similarly for score
min pooling. The purpose of these operations is
to mimic the essence of union and intersection in
the vector space, however, it is evident that the
trained vector geometry is not harmonious to this
construction as well.
We observe that almost of all the values are more
than 0.9, meaning that W2Byields a higher
rank for the target Cthan W2Vover 90% of
the time. This empirically validates that our model
is indeed capturing the underlying set theoretic
aspects of the words in the corpus.2268
W2VW2BA∩BA\BA∪B
(A+B)·X 0.90 0.92 0.98
(A−B)·X 0.90 0.65 0.80
max( A, B)·X 0.95 0.86 0.86
min(A, B)·X 0.90 0.75 0.92
max( A·X, B·X)0.95 0.84 0.94
min(A·X, B·X)1.0 0.80 0.84
6.2.3 Qualitative Analysis
In this section, we present some interesting exam-
ples of set theoretic queries on words, with different
degrees of complexities. For all the tables in this
section, we perform the set-operations on the query
words and present the ranked list of most similar
words to the output query. Many of these queries
are based on the aforementioned homographs, for
which there are natural expectations of what var-
ious set-theoretic operations should capture. Our
results are presented in Table 3-7.
The results in Table 4 look reasonable for both
models, as is to be expected since this is simply the
similarity function for each model. Even increas-
ing to a single intersection, as in Table 5, starts
to demonstrate that W2Vmay often return
very low-frequency words. In Table 6, we observe
that set difference of “property” and “land” yields aset of words that are related to attributes of science
subjects, eg. algebra or chemistry. We wanted
to examine how the model would handle more
complicated queries, for example if we first per-
form “property” \“finance” and then further inter-
sect with “algebra” or “chemistry”, does the intro-
duction of the relatively high-frequency “finance”
term cause the model to struggle to recapture these
items? In Table 7 we observe that the outputs for
W2Bdo indeed correspond to properties of
those sub-fields of science, whereas the results in
W2Vfocus strongly on “finance”. In gen-
eral, we observe better consistency of W2B
with all the example logical queries.
7 Related Work
Learning distributional vector representations from
a raw corpus was introduced in Mikolov et al.
(2013), quickly followed by various improvements
(Pennington et al.; Bojanowski et al., 2017). More
recently, vector representations which incorporate
contextual information have shown significant im-
provements (Peters et al., 2018; Devlin et al., 2019;
Radford et al., 2019; Brown et al., 2020). As these
models require context, however, Word2Vec-style
approaches are still relevant in settings where such
context is unavailable.
Hyperbolic representations (Nickel and Kiela,
2017; Ganea et al., 2018; Chamberlain et al., 2017)
have become popular in recent years. Most re-
lated to our setting, Tifrea et al. (2019) propose a
hyperbolic analog to GloVe, with the motivation
that the hyperbolic embeddings will discover a la-22692270
tent hierarchical structure between words.Vilnis
and McCallum (2015) use Gaussian distributions
to represent each word, and KL Divergence as a
score function.Athiwaratkun and Wilson (2018)
extended such representations by adding certain
thresholds for each distribution. For a different
purpose, Ren and Leskovec (2020) use Beta Distri-
butions to model logical operations between words.
Our work can be seen as a region-based analog to
these models.
Of the region-based embeddings, Suzuki et al.
(2019) uses hyperbolic disks, and Ganea et al.
(2018) uses hyperbolic cones, however these are
not closed under intersection nor are their inter-
sections easily computable. Vendrov et al. (2016)
and Lai and Hockenmaier (2017) use an axis-
aligned cone to represent a specific relation be-
tween words/sentences, for example an entailment
relation. Vilnis et al. (2018) extends Lai and Hock-
enmaier (2017) by adding an upper-bound, prov-
ably increasing the representational capacity of the
model. Li et al. (2019) and Dasgupta et al. (2020)
are improved training methods to handle the diffi-
culties inherent in gradient-descent based region
learning. Ren et al. (2020) and Abboud et al. (2020)
use a box-based adjustment of their loss functions,
which suggest learning per-entity thresholds are
beneficial. Chen et al. (2021) use box embeddings
to model uncertain knowledge graphs, Onoe et al.
(2021) use boxes for fined grained entity typing,
and Patel et al. (2022) use boxes for multi-label
classification.
Fuzzy sets, a generalization of sets, have been
widely studied in the context of clustering (Bezdek
and Harris, 1978), decision theory (Zimmermann,
1987) and linguistics (De Cock et al., 2000). How-
ever, the use of fuzzy sets in NLP has been fairly
limited. Bhat et al. (2020) normalized each dimen-
sion of a word vector against all the word vectorsin the vocabulary and interpret them as probability
features that enabled them to perform fuzzy set the-
oretic operations with the words. Zhao and Mao
(2018) and Zhelezniak et al. (2019b) build fuzzy set
representations of sentences using pre-trained vec-
tor embeddings for words and show the usefulness
such representations on semantic textual similarity
(STS) tasks. Jimenez et al. (2013, 2014) use the
soft-cardinality features for a fuzzy set representa-
tion of a sentence to perform the task of entailment
and textual relatedness. All these works, use pre-
trained vector embeddings for the words to form
fuzzy sets representing sentences. However, in this
work we learn fuzzy set representations for words
from corpus.
8 Conclusion
In this work we have demonstrated that box em-
beddings can not only effectively train to repre-
sent pairwise similarity but also can capture the
rich set-theoretic structure of words via unsuper-
vised training. This is a consequence of the fact
that Gumbel boxes are an efficient parameteriza-
tion of fuzzy sets, with sufficient representational
capacity to model complicated co-occurrance in-
teractions while, at the same time, allowing for
tractable computation and gradient-based training
of set-theoretic queries. The set-theoretic repre-
sentation capabilities of box models allow them
to generalize in a calibrated manner, leading to a
more coherent and self-consistent model of sets.
Acknowledgments
The authors would like to thank the members of
the Information and Extraction Synthesis Labo-
ratory (IESL) at UMass Amherst for helpful dis-
cussions. This work was partially supported by
IBM Research AI through the AI Horizons Net-
work and the Chan Zuckerberg Initiative under the
project Scientific Knowledge Base Construction.
Additional support was provided by the National2271Science Foundation (NSF) under Grant Numbers
IIS-1514053 and IIS-2106391, the Defense Ad-
vanced Research Projects Agency (DARPA) via
Contract No. FA8750-17-C-0106 under Subaward
No. 89341790 from the University of Southern Cal-
ifornia, and the Office of Naval Research (ONR)
via Contract No. N660011924032 under Subaward
No. 123875727 from the University of Southern
California. The U.S. Government is authorized to
reproduce and distribute reprints for Governmen-
tal purposes notwithstanding any copyright nota-
tion thereon. The views and conclusions contained
herein are those of the authors and should not be
interpreted as necessarily representing the official
policies or endorsements, either expressed or im-
plied, of IBM, CZI, NSF, DARPA, ONR, or the
U.S. Government.
References227222732274A Preprocessing
The WaCKypedia corpus has been tokenized and
lemmatized. We used the lemmatized version of
the corpus, however it was observed that various
tokens were not split as they should have been (eg.
“1.5billion” -> “1.5 billion”). We split tokens us-
ing regex criteria to identify words and numbers.
All punctuation was removed from the corpus, all
numbers were replaced with a “<num>” token, and
all words were made lowercase. We also removed
any words which included non-ascii symbols. Af-
ter this step, the entire corpus was tokenized once
more, and any token occurring less than 100 times
was dropped.
B Dataset Analysis
DatasetMedian
Frequency
Men-Tr-3K 23942
Mc-30 25216
Mturk-771 43128
Simlex-999 40653
Verb-143 309192
Yp-130 23044
Rw-Stanford 5683
Rg-65 13088
Ws-353-All 58803
Ws-353-Sim. 57514
Ws-353-Rel 64490
Mturk-287 32952
Simverb-3500 39020
C Hyperparameters
As discussed in Section 6, we train on 128
dimensional W2Vand 64 dimensional
W2Bmodels for 10 epochs. We ran at
least 60 runs for each of the models with random
seed and randomly chose hyperparamter from the
following range - batch_size:[2048, 4096, 8192,
16384, 32768], learning rate log_uniform[exp(-1),
exp(-10)], Window_size: [5, 6, 7, 8, 9, 10], nega-
tive_samples: [2, 5, 10, 20], sub_sampling thresh-
old: [0.001, 0.0001]. The best working hyperpa-
rameter sets and the corresponding checkpoints can
be found here:A B A∩B
girl boy child
pet wolf dog
winner medal gold
video entertainment movie
ocean sound wave
finance river bank
parent woman mother
bird America eagle
car sea boat
farm animal cow
fruit yellow banana
house royal palace
property chemistry solubility
bank river basin
policy government legislation
incense odor candle
spirit drink beer
dance song ballad
work art painting
instrument wind flute
D Dataset for Set Theoretic Queries
In this section, we describe the dataset for set the-
oretic evaluation. We evaluate on set-intersection ,
set-difference ,set-union queries. For each of these
tasks, we create queries of the form < A, B, A ◦
B > , where, ◦is any of the mentioned set oper-
ation. In case of set-union , we find homographs
to be an excellent choice as they are words de-
scribing multiple different choices of words. We
choose commonly used homographs from list of
homographs available in wikipedia (Wikipedia con-
tributors, 2022) to construct this dataset. We manu-
ally eliminated many of the words which are rare
or when the homographs are referring to concepts
which are semantically similar. We provide some
examples of the dataset for union queries in table
10. Also, note that we can perform the task for set-
difference by just swapping the BandA∪B, since
B= (A∪B)\A, i.e., if we subtract one concept
from the homographs then we must get back a set
containing the other concept. So the same table is
being used for set-difference task. We manually
create a small evaluation set for the set-intersection
task, listed in Table 9.2275A B A∪B
table chair furniture
car plane transportation
city village location
wolf bear animal
shirt pant clothes
computer phone electronics
red blue color
movie book entertainment
school college education
doctor engineer profession
box circle shape
big small size
dog tree bark
fish tone bass
sports wing bat
carry animal bear
sadness color blue
bend weapon bow
hit food buffet
combine building compound
happy list content
acquire agreement contract2276