
Leilei Gan, Yuxian Meng, Kun Kuang, Xiaofei Sun
Chun Fan, Fei Wuand Jiwei LiCollege of Computer Science and Technology, Zhejiang University,Shannon.AIShanghai Institute for Advanced Study of Zhejiang University,Shanghai AI LaboratoryPeng Cheng Laboratory,National Biomedical Imaging Center, Peking UniversityComputer Center, Peking University
{leileigan, kunkuang, wufei, jiwei_li}@zju.edu.cn
{yuxian_meng, xiaofei_sun}@shannonai.com, fanchun@pku.edu.cn
Abstract
Higher-order methods for dependency parsing
can partially but not fully address the issue
that edges in dependency trees should be con-
structed at the text span/subtree level rather
than word level. In this paper, we propose a
new method for dependency parsing to address
this issue. The proposed method constructs de-
pendency trees by directly modeling span-span
(in other words, subtree-subtree) relations. It
consists of two modules: the text span pro-
posal module which proposes candidate text
spans, each of which represents a subtree in
the dependency tree denoted by (root, start,
end); and the span linking module , which con-
structs links between proposed spans. We use
the machine reading comprehension (MRC)
framework as the backbone to formalize the
span linking module, where one span is used
as query to extract the text span/subtree it
should be linked to. The proposed method has
the following merits: (1) it addresses the fun-
damental problem that edges in a dependency
tree should be constructed between subtrees;
(2) the MRC framework allows the method
to retrieve missing spans in the span proposal
stage, which leads to higher recall for eligi-
ble spans. Extensive experiments on the PTB,
CTB and Universal Dependencies (UD) bench-
marks demonstrate the effectiveness of the pro-
posed method.
1 Introduction
Dependency parsing is a basic and fundamental
task in natural language processing (NLP) (Eis-
ner, 2000; Nivre, 2003; McDonald et al., 2005b).
Among existing efforts for dependency parsers,
graph-based models (McDonald et al., 2005a; Pei
et al., 2015) are a widely used category of models,
which cast the task as ﬁnding the optimal maxi-
mum spanning tree in the directed graph. Graph-Ilove Tim’s cat
Ilove Tim’s cat
Figure 1: Two possible dependency trees for sentence
“I love Tim’s cat”. For the tree on the right hand side,
if we look at the token-token level, ‘love" being linked
to “cat" is correct. But at the subtree-subtree level, the
linking is incorrect since the span/subtree behind “cat"
is incorrect.
based models provide a more global view than shift-
reduce models (Zhang and Nivre, 2011; Chen and
Manning, 2014), leading to better performances.
Graph-based methods are faced with a challenge:
they construct dependency edges by using word
pairs as basic units for modeling, which is insufﬁ-
cient because dependency parsing performs at the
span/subtree level. For example, Figure 1 shows
two possible dependency trees for the sentence “I
love Tim’s cat”. In both cases, at the token level,
“love" is linked to “cat". If we only consider token-
token relations, the second case of ‘love" being
linked to “cat" is correct. But if we view the tree
at the subtree-subtree level, the linking is incor-
rect since the span/subtree behind “cat" is incorrect.
Although higher-order methods are able to allevi-
ate this issue by aggregating information across
adjacent edges, they can not fully address the is-
sue. In nature, the token-token strategy can be
viewed as a coarse simpliﬁcation of the span-span
(subtree-subtree) strategy, where the root token in
the token-token strategy can be viewed as the av-
erage of all spans covering it. We would like an
approach that directly models span-span relations
using exact subtrees behind tokens, rather than the
average of all spans covering it.
To address this challenge, in this work, we pro-
pose a model for dependency parsing that directly2427operates at the span-span relation level. The pro-
posed model consists of two modules: (1) the text
span proposal module which proposes eligible can-
didate text spans, each of which represents a sub-
tree in the dependency tree denoted by (root, start,
end); (2) and the span linking module , which con-
structs links between proposed spans to form the
ﬁnal dependency tree. We use the machine reading
comprehension (MRC) framework as the backbone
to formalize the span linking module in an MRC
setup, where one span is used as a query to ex-
tract the text span/subtree it should be linked to.
In this way, the proposed model is able to directly
model span-span relations and build the complete
dependency tree in a bottom-up recursive manner.
The proposed model provides beneﬁts in the fol-
lowing three aspects: (1) ﬁrstly, it naturally ad-
dresses the shortcoming of token-token modeling
in vanilla graph-based approaches and directly per-
forms at the span level; (2) with the MRC frame-
work, the left-out spans in the span proposal stage
can still be retrieved at the span linking stage, and
thus the negative effect of unextracted spans can be
alleviated; and (3) the MRC formalization allows
us to take advantage of existing state-of-the-art
MRC models, with which the model expressivity
can be enhanced, leading to better performances.
We are able to achieve new SOTA performances
on PTB, CTB and UD benchmarks, which demon-
strate the effectiveness of the proposed method.
2 Related Work
Transition-based dependency parsing incrementally
constructs a dependency tree from input words
through a sequence of shift-reduce actions (Zhang
and Nivre, 2011; Chen and Manning, 2014; Zhou
et al., 2015; Dyer et al., 2015; Yuan et al., 2019;
Han et al., 2019; Mohammadshahi and Henderson,
2020a). Graph-based dependency parsing searches
through the space of all possible dependency trees
for a tree that maximizes a speciﬁc score (Pei et al.,
2015; Wang et al., 2018; Zhang et al., 2019).
Graph-based dependency parsing is ﬁrst intro-
duced by McDonald et al. (2005a,b). They formal-
ized the task of dependency parsing as ﬁnding the
maximum spanning tree (MST) in directed graphs
and used the large margin objective (Crammer et al.,
2006) to efﬁciently train the model. Zhang et al.
(2016) introduced a probabilistic convolutional neu-
ral network (CNN) for graph-based dependency
parsing to model third-order dependency informa-tion Wang and Chang (2016); Kiperwasser and
Goldberg (2016) proposed to employ LSTMs as
an encoder to extract features, which are then used
toscore dependencies between words. Zhang and
Zhao (2015); Zhang et al. (2019); Wang and Tu
(2020) integrated higher-order features across ad-
jacent dependency edges to build the dependency
tree. Ji et al. (2019) captured high-order depen-
dency information by using graph neural networks.
The biafﬁne approach (Dozat and Manning, 2016)
is a particular kind of graph-based method improv-
ing upon vanilla scoring functions in graph-based
dependency parsing. Ma et al. (2018) combined
biafﬁne classiﬁers and pointer networks to build
dependency trees in a top-down manner. Jia et al.
(2020); Zhang et al. (2020) extended the biafﬁne
approach to the conditional random ﬁeld (CRF)
framework. Mrini et al. (2020) incorporated la-
bel information into the self-attention structure
(Vaswani et al., 2017b) for biafﬁne dependency
parsing.
3 Method
3.1 Notations
Given a sequence of input tokens s= (w;w;:::;
w), wherendenotes the length of the sentence
andwis a dummy token representing the root of
the sentence, we formalize the task of dependency
parsing as ﬁnding the tree with the highest score
among all possible trees rooted at w.
^T= arg maxscore (T) (1)
Each token win the input sentence corresponds
to a subtree Trooted atwwithin in the full
treeT, and the subtree can be characterized by
a text span, with the index of its leftmost token
beingT:sin the original sequence, and the index
of its rightmost token being T:ein the original
sequence. As shown in the ﬁrst example of Figure
1, the span covered by the subtree Tis the full
sentence “I love Tim’s cat”, and the span covered
by the subtree Tis “Tim’s cat”. Each directional
arcw!winTrepresents a parent-child relation
betweenTandT, whereTis a subtree of
T. This implies that the text span covered by T
is fully contained by the text span covered by T.
It is worth noting that the currently proposed
paradigm can only handle the projective situation.
We will get back to how to adjust the current
paradigm to non-projective situation in Section 3.5.2428
3.2 Scoring Function
With notations deﬁned in the previous section, we
now illustrate how to compute the score (T)in
Eq.(1). Since we want to model the span-span
relations inside a dependency tree, where the tree
is composed by spans and the links between them,
we formalize the scoring function as:
score (T) =Xscore(T)
+Xscore(T;T)(2)
where score(T)represents how likely the sub-
tree rooted at wcovers the text span from T:sto
T:e.score(T;T)represents how likely tree
Tis a subtree of T, i.e. there is an arc from
wtow, andis a hyper-parameter to balance
scoreandscore. We will illustrate the details
how to compute score(T)andscore(T;T)
in the following sections. Table 1 shows all the
spans and links for the left tree in Figure 1.
3.3 Span Proposal Module
In this section, we introduce the span proposal
module. This module gives each tree Ta score
score(T)in Eq.(2), which represents how
likely the subtree rooted at wcovers the text span
fromT:stoT:e. The score can be decomposed
into two components – the score for the left half
span fromwtoT:s, and the score for the right
half span from wtoT:e, given by:
score(T) =score(T:sjw)
+score(T:ejw)(3)
We propose to formalize score(T:sjw)as the
score for the text span starting at T:s, ending
atw, by transforming the task to a text span ex-
traction problem. Concretely, we use the biafﬁne
function (Dozat and Manning, 2016) to score the
text span by computing score(jji)– the scoreof the tree rooted at at wand staring at w:
score(jji) =xUx+wx(4)
whereU2Randw2Rare trainable param-
eters, x2Randx2Rare token representa-
tions ofwandwrespectively. To obtain xand
x, we pass the sentence sto pretrained models
such as BERT (Devlin et al., 2018). xandxare
the last-layer representations output from BERT for
wandw. We use the following loss to optimize
the left-half span proposal module:
L= Xlogexp( score(T:sji))Pexp( score(jji))(5)
This objective enforces the model to ﬁnd the correct
span startT:sfor each word w. We ignore loss
forw, the dummy root token.
score(T:ejw)can be computed in the sim-
ilar way, where the model extracts the text span
rooted at index wand ending at T:e:
score(jji) =xUx+wx (6)
The loss to optimize the right-half span proposal
module:
L= Xlogexp( score(T:eji))Pexp( score(jji))(7)
Using the left-half span score in Eq.(4) and the
right-half span score in Eq.(6) to compute the full
span score in Eq.(3), we are able to compute the
score for any subtree, with text span starting at
T:s, ending atT:eand rooted at w.
3.4 Span Linking Module
Given two subtrees TandT, the span linking
module gives a score –score(T;T)to rep-
resent the probability of Tbeing a subtree of T.
This means that Tis the parent of T, and that
the span associated with T, i.e., (T:s;T:e)
is fully contained in the span associated with T,
i.e.,(T:s;T:e).
We propose to use the machine reading compre-
hension framework as the backbone to compute
this score. It operates on the triplet {context ( X),
query (q) and answer ( a)}. The context Xis the
original sentence s. The query qis the child span
(T:s;T:e). And we wish to extract the answer,
which is the parent span (T:s;T:e)from the
context input sentence s. The basic idea here is2429that using the child span to query the full sentence
gives direct cues for identifying the corresponding
parent span, and this is more effective than simply
feeding two extracted spans and then determining
whether they have the parent-child relation.
Constructing Query Regarding the query, we
should consider both the span and its root. The
query is thus formalized as follows:
<sos>;T:s;T:s+ 1;:::;T 1;<sor>;
T;<eor>;T+ 1;:::;
T:e 1;T:e;<eos> (8)
where <sos> ,<sor> ,<eor> , and <eos> are
special tokens, which respectively denote the start
of span, the start of root, the end of root, and the
end of span. One issue with the way above to con-
struct query is that the position information of T
is not included in the query. In practice, we turn
to a more convenient strategy where the query is
the original sentence, with special tokens <sos> ,
<sor> ,<eor> , and<eos> used to denote the po-
sition of the child. In this way, position information
for childTcan be naturally considered.
Answer Extraction The answer is the parent,
with the span T:s;T:erooted atT. We can
directly take the framework from the MRC model
by identifying the start and end of the answer span,
respectively denoted by score(T:sjT)and
score(T:ejT). We also wish to identify
the rootTfrom the answer, which is character-
ized by the score of wbeing the root of the span,
denoted by score(wjT). Furthermore, since
we also want to identify the relation category be-
tween the parent and the child, the score signifying
the relation label lis needed to be added, which is
denoted by score(ljT;w).
For quadruple (T:s;T:e;T;l), which de-
notes the span T:s;T:erooted atw, the ﬁnal
score for it being the answer to T, and the rela-
tion between the subtrees is l, is given by:
score(TjT) =
score(wjT) +score(T:sjT)+
score(T:ejT) +score(ljT;w)
(9)
In the MRC setup, the input is the concatena-
tion of the query and the context, denoted by
f<cls>;query;<sep>;contextg, where <cls>
and<sep> are special tokens. The input is fedto BERT, and we obtain representations for each in-
put token. Let hdenote the representation for the
token with index toutput from BERT. The probabil-
ity ofttoken being the root of the answer, which
is denoted by score(wjT)is the softmax
function over all constituent tokens in the context:
score(wjT) =exp (hh)P exp(hh)
(10)
where his trainable parameter. score and
score can be computed in the similar way:
score(wjT) =exp (hh)P exp(hh)
score(wjT) =exp (hh)P exp(hh)
(11)
Forscore(ljT;w), which denotes the rela-
tion label between TandT, we can compute it
in a simple way. Since halready encodes infor-
mation for hthrough self-attentions, the repre-
sentation hforwis directly fed to the softmax
function over all labels in the label set L:
score(ljT;w) =exp (hh)Pexp(hh)
(12)
Mutual Dependency A closer look at Eq.(9) re-
veals that it only models the uni-directional depen-
dency relation that Tis the parent of T. This
is suboptimal since if Tis a parent answer of
T,Tshould be a child answer of T. We thus
propose to use Tas the query qandTas the
answera.
score(TjT) =
score(wjT) +score(T:sjT)+
score(T:ejT) +score(ljT;T)
(13)
The ﬁnal score scoreis thus given by:
score(T;T) =score(TjT)
+score(Tjw)(14)
Since one tree may have multiple children but
can only have one parent, we use the multi-label
cross entropy loss L forscore(TjT)
and use the binary cross entropy loss L for
score(TjT). We jointly optimize these two
lossesL=L +Lfor span linking.24303.5 Inference
Given an input sentence s= (w;w;w;:::;w),
the number of all possible subtree spans
(w;T:s;T:e)isO(n), and therefore running
MRC procedure for every candidate span is com-
putationally prohibitive. A naive solution is to use
the span proposal module to extract top-k scored
spans rooted at each token. This gives rise to
a set of span candidates Twith size 1 +nk
(the root token wproduces only one span), where
each candidate span is associated with its subtree
span score score(). Then we construct the
optimal dependency tree based only on these ex-
tracted spans by linking them. This strategy ob-
tains a local optimum for Eq.(2), because we want
to compute the optimal solution for the ﬁrst partPscore(T)depending on the second part
of Eq.(2), i.e.,Pscore(T;T).
But in this naive strategy, the second part is com-
puted after the ﬁrst part.
It is worth noting that the naive solution of us-
ing only the top-k scored spans has another severe
issue: spans left out at the span proposal stage
can never be a part of the ﬁnal prediction, since
the span linking module only operates on the pro-
posed spans. This would not be a big issue if top-
k is large enough to recall almost every span in
ground-truth. However, span proposal is intrinsi-
cally harder than span linking because the span
proposal module lacks the triplet span information
that is used by the span linking module. Therefore,
we propose to use the span linking module to re-
trieve more correct spans. Concretely, for every
spanTproposed by the span proposal module,
we use arg max score(TjT)to retrieve its
parent with the highest score as additional span
candidates. Recall that span proposal proposed
1 +nkspans. Added by spans proposed by
the span linking module, the maximum number of
candidate spans is 1+2nk. The MRC formal-
ization behind the span linking module improves
the recall rate as missed spans at the span proposal
stage can still be retrieved at this stage.
Projective Decoding Given retrieved spans har-
vested in the proposal stage, we use a CKY-style
bottom-up dynamic programming algorithm to ﬁnd
the projective tree with the highest score based on
Eq.(2). The algorithm is present in Algorithm 1.
The key idea is that we can generalize the deﬁnition
ofscore (T)in Eq.(2) to any wby the followingAlgorithm 1: Projective Inference
deﬁnition:
score (T) =Xscore(T)
+Xscore(T;T)(15)
wherefTjTT;i= 0;1;:::;ngis all
subtrees inside T, i.e. there is a path in Tlike
w!w!:::;!w
Using this deﬁnition, we can rewrite score (T)in
a recursive manner:
score (T) =score(T)
+X[score (T) +score(T;T)]
(16)
whereC(T) =fTj(w!w)2T;i=
0;1;:::ngis the set of all direct subtrees of T.
Non-Projective Decoding It is noteworthy that
effectively ﬁnding a set of subtrees composing a
treeTrequires trees to be projective (the projective
property guarantees every subtree is a continuous
span in text), and experiments in Section 4 show
that this algorithm performs well on datasets where
most trees are projective, but performs worse when2431a number of trees are non-projective. To address
this issue, we adapt the proposed strategy to the
MST (Maximum Spanning Tree) algorithm (Mc-
Donald et al., 2005b). The key point of MST is to
obtain the score for each pair of tokens wandw
(rather than spans) , denoted by score(w;w).
We propose that the score to link wandwis the
highest score achieved by two spans respectively
rooted atwandw:
score(w;w) = max[score(T)
+score(T) +score(T;T)](17)
The ﬁnal score for tree Tis given by:
score (T) =Xscore(w;w)(18)
Here, MST can be readily used for decoding.
4 Experiments
4.1 Datasets and Metrics
We carry out experiments on three widely used de-
pendency parsing benchmarks: the English Penn
Treebank v3.0 (PTB) dataset (Marcus et al., 1993),
the Chinese Treebank v5.1 (CTB) dataset (Xue
et al., 2002) and the Universal Dependency Tree-
banks v2.2 (UD) (Nivre et al., 2016) where we
select 12 languages for evaluation. We follow Ma
et al. (2018) to process all datasets. The PTB
dataset contains 39832 sentences for training and
2416 sentences for test. The CTB dataset contains
16091 sentences for training and 1910 sentences for
test. The statistics for 12 languages in UD dataset
are the same with Ma et al. (2018). We use the
unlabeled attachment score (UAS) and labeled at-
tachment score (LAS) for evaluation. Punctuations
are ignored in all datasets during evaluation.
4.2 Experiment Settings
We compare the proposed model to the following
baselines: (1) Biafﬁne , (2) StackPTR , (3)GNN ,
(4)MP2O , (5) CVT , (6) LRPTR , (7) HiePTR ,
(8)TreeCRF , (9) HPSG , (10) HPSG+LA , (11)
MulPTR , (12) SynTr . The details of these base-
lines are left to the supplementary materials due
to page limitation. We group experiments into
three categories: without pretrained models, with
BERT and with RoBERTa. To implement a span-
prediction parsing model without pretrained mod-
els, we use the QAnet (Yu et al., 2018) for spanprediction. To enable apple-to-apple comparisons,
we implement our proposed model, the Biafﬁne
model, MP2O (Wang and Tu, 2020) based on
BERT(Devlin et al., 2018) and RoBERTa
(Liu et al., 2019) for PTB, BERT and RoBERTa-
wwm(Cui et al., 2019) for CTB, BERTBase-
Multilingual-Cased and XLM-RoBERTa for
UD. We apply both projective decoding and non-
projective MST decoding for all datasets. For all
experiments, we concatenate 100d POS tag em-
bedding with 1024d pretrained token embeddings,
then project them to 1024d using a linear layer.
Following Mrini et al. (2020), we further add 1-3
additional encoder layers on top to let POS embed-
dings well interact with pretrained token embed-
dings. POS tags are predicted using the Stanford
NLP package (Manning et al., 2014). We tried two
different types of additional encoders: Bi-LSTM
(Hochreiter and Schmidhuber, 1997) and Trans-
former (Vaswani et al., 2017a). For Bi-LSTM, the
number of hidden size is 1024d. For Transformer,
the number of attention heads and hidden size re-
main the same as pretrained models (16 for atten-
tion heads and 1024d for hidden size). We use 0.1
dropout rate for pretrained models and 0.3 dropout
rate for additional layers. We use Adam (Kingma
and Ba, 2014) as optimizer. The weight parameter
is tuned on the development set. The code is
implemented by PyTorch 1.6.0 and MindSpore.
4.3 Main Results
Table 2 compares our model to existing state-of-the-
art models on PTB/CTB test sets. As can be seen,
for models without pretrained LM, the proposed
span-prediction model based on QAnet outper-
forms all baselines, illustrating the effectiveness of
the proposed span-prediction framework for depen-
dency parsing. For BERT-based models, the pro-
posed span-prediction models outperform Biafﬁne
model based on BERT, along with other competi-
tive baselines. On PTB, performances already out-
perform all previous baselines, except on the LAS
metric in comparison to HiePTR (95.46 vs. 95.47)
on PTB, but underperform RoBERTa-based mod-
els. On CTB, the proposed span-prediction model
obtains a new SOTA performance of 93.14% UAS.
For RoBERTa-based models, the proposed model
achieves a new SOTA performance of 97.24% UAS
and 95.49% LAS on PTB. As PTB and CTB con-
tain almost only projective trees, the projective de-
coding strategy signiﬁcantly outperforms the non-2432
projective MST algorithm. It is worth noting that,
since MulPTR, HPSG and HPSG+LA rely on addi-
tional labeled data of constituency parsing, results
for HPSG are not comparable to ours. We list them
here for reference purposes.
Table 3 compares our model with existing state-
of-the-art methods on UD test sets. Other than es,
where the proposed model slightly underperforms
the SOTA model by 0.02, the proposed model en-
hanced with XLM-RoBERTa achieves SOTA per-
formances on all other 11 languages, with an aver-
age performance boost of 0.3. As many languages
in UD have a notable portion of non-projective
trees, MST decoding signiﬁcantly outperforms pro-
jective decoding, leading to new SOTA perfor-
mances in almost all language sets.
5 Ablation Study and Analysis
We use PTB to understand behaviors of the pro-
posed model. As projective decoding works best
for PTB, scores reported in this section are all from
projective decoding.
5.1 Effect of Candidate Span Number
We would like to study the effect of the number
of candidate spans proposed by the span proposal
module, i.e., the value of k. We vary the value of k
from 1 to 25. As shown in Table 4, increasing val-
ues ofkleads to higher UAS, and the performance
stops increasing once kis large enough ( k >15).
More interestingly, even though kis set to 1, which
means that only one candidate span is proposed for
each word, the ﬁnal UAS score is 96.94, a score
that is very close to the best result 97.24 and sur-
passes most existing methods as shown in Table 2.
These results verify that the proposed approach can
accurately extract and link the dependency spans.
5.2 Effect of Span Retrieval by Span Linking
As shown in Table 5, span recall signiﬁcantly im-
proves with the presence of the span linking stage.
This is in line with our expectation, since spans
missing at the proposal module can be retrieved
by QA model in the span linking stage. Recall
boost narrows down when kbecomes large, which
is expected as more candidates are proposed at the
proposal stage. The span linking stage can improve
computational efﬁciency by using a smaller num-
ber of proposed spans while achieving the same
performance.
5.3 Effect of Scoring Functions
We study the effect of each part of the scoring func-
tions used in the proposed model. Table 6 shows
the results. We have the following observations:
(1)token(query)-token(answer) : we simplify the
model by only signifying root token in queries
(child) and extract the root token in the context
(parent). The model actually degenerates into a
model similar to Biafﬁne by working at the token-
token level. We observe signiﬁcant performance
decreases, 0.57 in UAS and 0.34 in LAS.
(2)token(query)-span(answer) : signifying only
token in queries (child) and extracting span in an-
swers (parent) leads to a decrease of 0.13 and 0.082433
respectively for UAS and LAS.
(3)span(query)-token(answer) : signifying spans
in queries (child) but only extracting token in an-
swers (parent) leads to a decrease of 0.07 and 0.05
respectively for UAS and LAS. (1), (2) and (3)
demonstrate the necessity of modeling span-span
rather than token-token relations in dependency
parsing: replacing span-based strategy with token-
based strategy for either parent or child progres-
sively leads to performance decrease.
(4) Removing the Mutual Dependency module
which only uses child !parent relation and ig-
nores parent!child relation also leads to perfor-
mance decrease.
5.4 Analysis
Following Ma et al. (2018); Ji et al. (2019), we an-
alyze performances of the Biafﬁne parser and the
proposed method with respect to sentence length,
dependency length, and subtree span length. Re-
sults are shown in Figure 2.
Sentence Length. As shown in Figure 2(a), the
proposed parser achieves better performances on
long sentences compared with Biafﬁne. Specially,
when sentence length is greater than 50, the perfor-
mance of the Biafﬁne parser decreases signiﬁcantly,
while the proposed parser has a much smaller drop
(from 0.97 to 0.964).
Dependency Length. Figure 2(b) shows the re-
sults with respect to dependency length. The pro-
posed parser shows its advantages on long-range
dependencies. We suppose span-level information
is beneﬁcial for long-range dependencies.
Subtree Span Length. We further conduct ex-
periments on subtree span length. We divide the
average lengths of the two spans in the span linking
module into seven buckets. We suppose our parser
should show advantages on long subtree span, and
the results in Figure 2(c) verify our conjecture.
In summary, the span-span strategy works sig-
niﬁcantly better than the token-token strategy, es-
pecially for long sequences. This explanation is as
follows: the token-token strategy can be viewed as
a coarse simpliﬁcation of the span-span strategy,
where the root token in the token-token strategy
can be viewed as the average of all spans cover-
ing it, while in the span-span strategy, it represents
the exact span, rather than the average. The de-
viation from the average is relatively small from
the extract when sequences are short, but becomes
larger as sequence length grows, since the number
of spans covering the token exponentially grows
with length. This makes the token-token strategy
work signiﬁcantly worse for long sequences.
6 Conclusion
In this paper, we propose to construct dependency
trees by directly modeling span-span instead of2434token-token relations. We use the machine reading
comprehension framework to formalize the span
linking module, where one span is used as a query
to extract the text span/subtree it should be linked
to. Extensive experiments on the PTB, CTB and
UD benchmarks show the effectiveness of the pro-
posed method.
Acknowledgement
This work is supported by the Science and Technol-
ogy Innovation 2030 - “New Generation Artiﬁcial
Intelligence” Major Project (No. 2021ZD0110201),
the Key R & D Projects of the Ministry of Science
and Technology (2020YFC0832500) and CAAI-
Huawei MindSpore Open Fund. We would like
to thank anonymous reviewers for their comments
and suggestions.
References24352436A Baselines
We use the following baselines:
•Biafﬁne : Dozat and Manning (2016) fed pairs
of words into a biafﬁne classiﬁer to determine
the dependency relations between them.
•StackPTR : Ma et al. (2018) combined pointer
network with transition-based method to make
it beneﬁts from the information of whole sen-
tence and all previously derived subtree struc-
tures.
•GNN : Ji et al. (2019) used graph neural net-
works (GNN) to learn token representations
for graph-based dependency parsing.
•MP2O : Wang and Tu (2020) used message
passing to integrate second-order information
to biafﬁne backbone.
•CVT : Clark et al. (2018) proposed Cross-
View Training, a semi-supervised approach
to improve model performance.
•LRPTR : Fernández-González and Gómez-
Rodríguez (2019) also took advantage of
pointer networks to implement transition-
based parser, which contains only nactions
and is more efﬁcient than StackPTR.
•HiePTR : Fernández-González and Gómez-
Rodríguez (2021) introduced structural knowl-
edge to the sequential decoding of the left-
to-right dependency parser with Pointer Net-
works.
•TreeCRF : Zhang et al. (2020) presented a
second-order TreeCRF extension to the bi-
afﬁne parser.
•HPSG : Zhou and Zhao (2019) used head-
driven phrase structure grammar to jointly
train constituency and dependency parsing.
•HPSG+LA : Mrini et al. (2020) added a label
attention layer to HPSG to improve model
performance. HPSG+LA also relies on the
additional constituency parsing dataset.
•MulPTR : Fernández-González and Gómez-
Rodríguez (2020) jointly trained two separate
decoders responsible for constituent parsing
and dependency parsing.
•SynTr : Mohammadshahi and Hender-
son (2020b) proposed recursive non-
autoregressive graph-to-graph Transformers
for the iterative reﬁnement of dependency
graphs conditioned on the complete graph.2437