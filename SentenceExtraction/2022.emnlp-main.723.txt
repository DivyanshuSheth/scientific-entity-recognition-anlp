
Kailai Sun, Zuchao Li, and Hai ZhaoDepartment of Computer Science and Engineering, Shanghai Jiao Tong UniversityMoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong UniversitySchool of Computer Science, Wuhan University
kaishu2.0@sjtu.edu.cn, zcli.charlie@gmail.com, zhaohai@cs.sjtu.edu.cn
Abstract
Discontinuous constituency parsing is still kept
developing for its efficiency and accuracy are
far behind its continuous counterparts. Moti-
vated by the observation that a discontinuous
constituent tree can be simply transformed into
a pseudo-continuous one by artificially reorder-
ing words in the sentence, we propose a novel
reordering method, thereby construct fast and
accurate discontinuous constituency parsing
systems working in continuous way. Specif-
ically, we model the relative position changes
of words as a list of actions. By parsing and per-
forming this actions, the corresponding pseudo-
continuous sequence is derived. Discontinuous
parse tree can be further inferred via integrat-
ing a high-performance pseudo-continuous con-
stituency parser. Our systems are evaluated on
three classical discontinuous constituency tree-
banks, achieving new state-of-the-art on two
treebanks and showing a distinct advantage in
speed.
1 Introduction
Constituency parses represent the syntactic struc-
ture by hierarchical constituent trees, which de-
compose the sentence into constituents and estab-
lish hierarchical relations between constituents and
words (Corro, 2020). In continuous constituent
trees, the sequence of words that compose the con-
stituent must be contiguous. This type of structure
is enough for representing most of the syntactic
structure (Fernández-González et al., 2021a) and
has been extensively studied.
Nevertheless, some syntactic phenomena, such
as long-distance dependencies and extractions, re-
quire discontinuous words to form a constituent,
which have been argued to be unavoidable (Mc-
Cawley, 1982; Bunt et al., 1987; Müller, 2004).
Thus, discontinuous constituent trees with crossingFigure 1: An example of converting a discontinuous
tree into a pseudo-continuous one.
branches are introduced to describe all the syntactic
phenomena present in human language.
Compared to continuous constituency parsing,
discontinuous parsing is a more complicated prob-
lem, so that the high computational cost is par-
ticularly prominent. Many researches (Ruprecht
and Mörbitz, 2021; Coavoux and Crabbé, 2017;
Coavoux et al., 2019) have focused on how to re-
duce the time complexity of discontinuous parsing
algorithm to reduce or get rid of the constraint of
sentence length.
Based on the observation that a discontinuous
tree can be converted into a pseudo-continuous one
by simply reordering the words in the sentence,
as an example in Figure 1, and the advantage that
parsing a continuous tree is much simpler than
parsing a discontinuous one. Fernández-González
et al. (2021b) develops a pointer network to gen-
erate reordered word sequence by predicting the
position of each word in the pseudo-continuous
sequence, and then applies off-the-shelf continu-
ous constituency parser to get the constituent tree.
This method is intuitive to achieve improvement in
speed, and its Fscore is also greatly improved.
However, the accuracy of existing reordering
methods still lags behind. We find that the per-
formances of the pseudo-continuous constituency
parser outperforms all the existing discontinuous
works by a wide margin if the input pseudo-
continuous sequences are completely correct in
word positions. In order to preserve the high perfor-
mance of pseudo-continuous parser as completely10575as possible, it is an urgent problem to study how to
improve the accuracy of reordering and the influ-
ence of reordering accuracy on the overall discon-
tinuous constituency parsing result.
In this work, we construct fast and accurate dis-
continuous constituency parsing systems working
in continuous way by designing a novel method of
reordering the words in sentences. Specifically, we
model the relative position changes of words when
converting the original sentence to the pseudo-
continuous sequence as a list of actions that moving
words forward and backward in the sentence. We
employ an action graph which indicates these ac-
tions by directed edges with action labels. Since the
action graph and the semantic dependency graph
have similar structure, we adopt the semantic de-
pendency parsing model (Wang and Tu, 2020) as
our basic model for parsing the action graph. We
further establish a robust rearrangement algorithm
with time complexity of O(n), which derives the
pseudo-continuous sequence by performing the ac-
tions in the predicted graph.
With our action schema and rearrangement al-
gorithm, we achieve a considerable improvement
in reordering accuracy than current state-of-the-art
method and remain comparable efficiency. Mean-
time, we innovatively revise the architecture of the
parser to better adapt to the structural characteris-
tics of action graph and achieve better results. After
deriving the pseudo-continuous sequence, any well-
performed continuous constituency parsing model
can be used as our pseudo-continuous parser to
parse this sequence into a pseudo-continuous tree.
Finally, we can restore the corresponding discon-
tinuous tree by reducing the pseudo-continuous
sequence to the original sentence.
We evaluate our systems on three classical dis-
continuous constituency treebanks: Discontinu-
ous English Penn Treebank (DPTB) (Evang and
Kallmeyer, 2011), Tiger (Brants et al., 2002) and
Negra (Skut et al., 1997). Two continuous con-
stituency parsing models: a span-based model (Ki-
taev et al., 2019) and a transition-based model
(Yang and Deng, 2020), are used as the pseudo-
continuous parser for experiments. Our method
is faster than most of the existing discontinuous
parsers. We achieve new state-of-the-art results on
Tiger and Negra, and comparable to state-of-the-art
results on DPTB.2 Related Work
Syntax shows its effect in language understand-
ing (He et al., 2018; Li et al., 2021a,b; Sun et al.,
2021; Li et al., 2022; Zhang et al., 2022). Discontin-
uous constituency parsing, as a special constituency
parsing form has drawn much attention.
Grammar-based Method Inheriting and ex-
panding the grammar-based methods of continu-
ous constituency parsing, mildly context-sensitive
grammar such as linear context-free rewriting sys-
tems (LCFRS) (Vijay-Shanker et al., 1987) and
multiple context-free grammars (MCFGS) (Seki
et al., 1991) has been applied for discontinu-
ous parsing, which has higher parsing complex-
ity than its continuous counterpart. For example,
the complexity of accurate CKY-style LCFRS is
O(n), where grammar-specific fan-out is
greater than 1 (Kallmeyer, 2010). To reduce the
limit on the sentence length, Ruprecht and Mör-
bitz (2021) proposes a supertagging-based parser
for LCFRS. However, there is still a considerable
gap in speed and accuracy between discontinuous
parsing and continuous parsing.
Span-based Method In continuous constituency
parsing, span-based methods generally excel in
both speed and accuracy (Stern et al., 2017; Ki-
taev and Klein, 2018; Kitaev et al., 2019). Span-
based methods are also proposed for discontinu-
ous constituency parsing (Corro, 2020; Stanojevi ´c
and Steedman, 2020), but their discontinuous ac-
curacy is not good enough. Through error analy-
sis, Coavoux (2021) concludes that compared to
transition-based parser, span-based parser has less
fine-grained features which are particularly help-
ful for predicting discontinuous constituents. Thus,
first converting the discontinuous tree into a pseudo-
continuous one and then utilizing span-based parser
may be a better choice.
Transition-based Method In continuous con-
stituency parsing, transition-based methods based
on shift-reduce strategy (Zhu et al., 2013; Sagae
and Lavie, 2005) are widely used. Some works
propose to add specific transition actions to change
the order of words (Maier, 2015; Stanojevi ´c and
Alhama, 2017) for discontinuous parsing. How-
ever, this type of extension may make transition se-
quences so long that affecting efficiency and accu-
racy. To alleviate this problem, methods of dealing
directly with discontinuous sequences (Coavoux
and Crabbé, 2017) and designing new data struc-
tures and corresponding actions (Coavoux et al.,10576
2019; Coavoux, 2021) are used to reduce the length
of the transition sequence. These methods are in-
deed effective, but there is still room for improve-
ment in terms of speed and accuracy.
Conversion-based Method Several works also
aim to convert discontinuous constituency parsing
to a simpler task. For example, some works re-
duce discontinuous constituency parsing to non-
projective dependency parsing by encoding the
constituents to arc labels (Fernández-González and
Martins, 2015; Fernández-González and Gómez-
Rodríguez, 2020) , while Vilares and Gómez-
Rodríguez (2020) converts the task to sequence
tagging by representing the discontinuous tree as
a sequence of tag. In this work, we convert the
discontinuous parsing task into continuous parsing
task by modeling, parsing and presenting the words
relocating actions, and thus reduce the complexity
of the problem.
3 Method
The flow of our systemis shown in Figure 2. In
data pre-processing stage, we first build a pseudo-
continuous constituency treebank based on discon-
tinuous treebank by reordering the words in the
sentences. The reordering strategy is consistent
with Fernández-González et al. (2021b) and is de-
scribed in detail in Appendix A. Then, we construct
an action graph dataset based on our action schema
by modeling the relative position changes of words
as action edges. In training stage, we train an ac-
tion graph parser on the action graph dataset and
a pseudo-continuous constituency parser on the
pseudo-continuous treebank. In prediction stage,
we first parse the original sentence: Xinto action
graph: G. Then, we propose an algorithm which
derives the reordered sequence: ˆXand the ID list:
Orders from Xby performing actions in G.ˆXis
then used as input to the pseudo-continuous con-
stituency parser for pseudo-continuous tree ˆYpars-ing. Finally, Orders which indicates the original
positions of the words in X, is used for discontinu-
ous tree Yrestoration.
3.1 Action Graph
Denote the original sentence as X=w, w, ...
, w, and the reordered sequence as ˆX. For each
word w(i= 1,2, ..., N ), its index in Xisiand in
ˆXisr. That means wandwrepresent the same
word in different positions in XandˆXrespectively.
In addition, we use the index of each word in Xas
its ID, which remains the same in XandˆX.
According to our observation, reordering words
in a sentence is identical to moving some of the
words forward or backward. Therefore, we design
an action schema that indicates the specific relative
positions to which some words need to be moved
forward or backward when converting XtoˆX.
The criteria for judging whether a word needs to
be moved are as follows:
•Move Forward : For w(w), if there exist a
word which is to the left of winXand to the
right of winˆX,wis considered to be moved
forward.
∃w: 1≤j < i &N≥r> r
•Move Backward : For w(w), if there exist a
word which is to the right of winXand to the
left of winˆX,wis considered to be moved
backward.
∃w:N≥j > i &1≤r< r
On this basis, we indicate movements by anno-
tating edges pointing from head to child and thus
forming an action graph. The criteria for assigning
edges and labels are as follows:
•Forw(w), if it needs to be moved forward and
w̸=w. We use was the positioning
forwand assign an edge with label MOVE-L :
(w→w), which indicates the action that
moving wafterw.
•For a continuous segment w, w, ..., w
(s≥1) inX, if it is also a continuous segment in10577ˆXand it needs to be moved forward. We assign
an edge with label SPAN : (w→w), which
indicates that words from wtowshould be
moved forward as a whole.
•Forw(w), if it needs to be moved backward
andw̸=w. We use was the position-
ing for wand assign an edge with label MOVE-R :
(w→w), which indicates the action that
moving wbefore w.
•For a continuous segment w, ..., w, w
(s≥1) inX, if it is also a continuous segment in
ˆXand it needs to be moved backward. We assign
an edge with label SPAN : (w→w), which
indicates that words from wtowshould be
moved backward as a whole.
We introduce an example from DPTB in the first
block of Figure 3 to show the gold bi-directional
action graph where the green edges indicate for-
ward movements, and the purple edges indicate
backward movements. An "END" virtual node is
appended because several words may be moved
backward to the end of the sequence in some in-
stances, which requiring a node to be the head of
such edges. It is worth noting that only using the
edges of a single direction is sufficient to derive
an accurate pseudo-continuous sequence. How-
ever, there is no guarantee that the action graph
parser can make decisions exactly, so it is neces-
sary to combine the forward and backward actions
together and let them complement each other to
achieve higher reordering accuracy.
3.2 Action Graph Parsing Model
Since there are action edges of two directions, we
introduce two parsing configurations. The first
one is to merge the forward and backward edges
into one graph and employ a single parser for bi-
directional action prediction directly. The other
one is to train two separate parsers to predict the
forward and backward edges respectively.
Bi-directional Parsing Model In semantic de-
pendency parsing, a dependency is represented by
an annotated edge pointing from head to depen-
dent. A word can be regarded as a dependent or
head multiple times in different dependencies, or
it may not belong to any dependency. Therefore,
our bi-directional action graph has a similar struc-
ture to semantic dependency graph. In this case,
we employ a second-order graph-based semantic
dependency model (Wang et al., 2019) for parsing
our bi-directional action graph. We make a simpleclarification for this model as follows.
First, the model uses four single-layer feedfor-
ward layers (FNNs) to differentiate the output of
the encoder: H= [h, h, ..., h]into four hid-
den states with different functions: H, where
o∈[edge,label]andm∈[head,dep]. Then, the
first-order scores of edge: S∈ Rand
the first-order scores of label: S∈ R
are calculated by biaffine attention, where Cis the
number of labels:
Biaff(v, v) :=vUv+b,
s=Biaff(h , h ), o∈[edge,label].
Meantime, His also differentiated into other
three hidden states for second-order scoring:
H, where q∈[grand ,head,dep]. Three
kinds of second-order scores of edge, siblings:
S, co-parents: Sand grandparents: S
are calculated by trilinear functions:
Trilin (v, v, v) :=vvUv+b.
For label prediction, softmax function is per-
formed on Sto calculate the probability of
each label given the edge. For edge prediction, a
conditional random field (CRF) inference is defined
to determine the existence of edges. The unary po-
tential is defined by Sand the binary potential
is defined by S,SandS. For efficiency,
mean field variational inference (MFVI) is used for
approximate inference on this CRF.
During training, cross entropy losses are mea-
sured for both edge and label, and the optimization
objective is the weighted average of the two losses.
L=λL+ (1−λ)L.
Uni-directional Parsing Model Semantic depen-
dency parsing model suited well for parsing bi-
directional action graph. However, for the uni-
directional action graph parsing, because of its rel-
atively simple chain structure (compared to full
graph), it is not suitable to use such model with
graph constraints. Instead, we adopt and revise
the syntactic dependency parsing model with tree
constraints for better adaptation.
In uni-directional action parsing, due to the tree
constraint characteristic that there is at most one
head per word, we revise the basic biaffine model
with a single-layer MLP as a binary classifier that
receives the output of the encoder and predicts
whether each word has a head or not.
S=MLP(H)∈ R.10578
The process of calculating SandSis con-
sistent with the bi-directional action graph parser
using biaffine attention. Then, we perform soft-
max on S,SandSto calculate the
probability of the presence and absence of the head
of each word, the probability of each edge given
the child, and the probability of each label given
the edge. While in the inference, we first decide
the nodes with heads according to S, and per-
forms greedy search on SandSfor ac-
tion prediction.
Denote Gas the gold action graph for sentence
X, we define the following cross entropy losses:
where θis the parameters of our model and 1(·)
denotes the indicator function. 1(g )equals 1
when whas head in Gand 0 otherwise. The final
optimization objective is the weighted average of
the three losses.
L=λL+ (1−λ)(L+L).
With the removal of complicate second-order scor-
ing of edges, the uni-directional action graph parser
has fewer parameters and less time complexitycompared with the bi-directional version, so it is
more efficient at parsing a single graph.
3.3 Rearrangement Algorithm
After predicting the action graph, we design an
algorithm performing the actions in the graph to
derive the reordered sequence. The algorithm is
shown in Algorithm 1 which consists of two phases:
forward placement and backward adjustment. For
convenience, we perform actions directly on the
IDs of the words and map the IDs to the words at
the end of the algorithm. Since the implementation
of backward adjustment are complicated, we de-
fine several functions to simplify the writing of the
pseudo code:
•MoveRAble (curID,chID): If chID is placed by
Nature and it is to the left of curID, return true.
•SpanRAble (curID,span ): If the entire span is
placed by Nature and it is a contiguous segment
inOrders and it is to the left of curID, return
true.
•Adjust (curID,segment ): Move the segment ,
which can be a span or a single ID, before curID.
In the forward placement, we place the words
from left to right according to the forward edges.
Since the first word never moves, we first add ID=
1to the ID list: Orders . In each loop, we take the
last ID in Orders as the currently observed object:10579Algorithm 1,[1] ;
curID, and iterate through all edges with it as the
head until we find a feasible action. The MOVE-L
action works if its child has not been placed in
Orders . The SPAN action works if the entire span
has not been placed in Orders andcurID is placed
inOrders byMOVE-L . If no feasible action, the one
which is the smallest ID that has not been placed in
Orders , is placed by Nature . The first phase ends
when all IDs have been placed in Orders .
In the backward adjustment, we scan Orders
from right to left, looking for possible missing ac-tions based on the backward edges. We assume
that the forward actions we have used are cor-
rect. Therefore, we only focus on the IDs that
are placed by Nature and ignore those that have
already been moved forward. In each loop, we iter-
ate through all edges with curID as the head until
we find a feasible action. The MOVE-R action works
ifMoveRAble (curID,chID) is true. The SPAN ac-
tion works if SpanRAble (curID,span ) is true and
curID is adjusted by MOVE-R . If no feasible action,
move curID one to the left. The second phase ends
when we move to the first ID.
To make our algorithm robust to errors in the
action graph parse, we filter out some unreason-
able actions through the feasibility judgment, and
use the backward edges to supplement the result
derived by the forward edges. This is important for
high-accuracy reordering. As an example shown
in the second block of Figure 3, the predicted ac-
tion graph is not completely correct: two edges are
missing and two edges are redundant compared to
the gold action graph in the first block. However,
we can still derive the correct reordered sequence
with our algorithm.
3.4 Time Complexity
The bi-directional action graph parser has a time
complexity of O(d+d+n)and the uni-
directional action graph parser has a time com-
plexity of O(d+n), where danddare the
hidden sizes of the biaffine and trilinear and n
is the sentence length. The rearrangement algo-
rithm has a time complexity of O(n). The con-
tinuous constituency parsing models (Kitaev et al.,
2019; Yang and Deng, 2020) used as our pseudo-
continuous constituency parser in our experiments
both have a time complexity of O(d+n). There-
fore, the whole time complexity of our system
isO(d+d+n)which is comparable to that
of the most efficient methods currently, includ-
ing Fernández-González et al. (2021b) and Corro
(2020) both with a time complexity of O(d+n).
4 Experiments
Data Setup We conduct our experiments on En-
glish treebank DPTB with standard split and Ger-
man treebanks: Tiger and Negra with common split
(Seddah et al., 2013; Dubey and Keller, 2003). We
transform these three treebanks into correspond-
ing action graph datasets and pseudo-continuous
constituency treebanks for training and evaluating10580
action graph parsers and pseudo-continuous con-
stituency parsers. The data statistics of action graph
datasets are shown in Appendix B.
Evaluation Metric For action graph parsing, we
calculate the labeled edge Fscore (LF) as the
metric to select the best model on the development
set. For pseudo-continuous constituency parsing,
we use the continuous constituency Fscore as the
metric to select the best model on the development
set. For overall results, we use official discodop
to calculate continuous Fscore and discontinuous
Fscore (DF). Parsing speed is measured by the
average number of sentences our systems process
per second (sent/s).
Implementation The hyper-parameters of our ac-
tion graph parsing models are shown in Appendix C
and the hyper-parameters of the pseudo-continuous
constituency parser are consistent with Kitaev et al.
(2019) and Yang and Deng (2020). For DPTB,
word embedding is initialized with Glove (Pen-
nington et al., 2014) while it is randomly initial-ize for Tiger and Negra. We introduce BERT,
BERT(Devlin et al., 2019), RoBERTa(Liu
et al., 2019) and XLNet(Yang et al., 2019)
as the pre-trained models. We use BERTfor
fixed pre-trained embedding and fine-tune other
pre-trained models as the encoder. Our models are
trained and tested on Intel(R) Core(TM) i9-7900X
CPU @ 3.30GHz and a single NVIDIA RTX TI-
TAN GPU. All the results we report are averages
of the results of five seeds.
Discontinuous Constituency Parsing Results
We report Fscores, DFscores and speeds of our
systems on test splits in Table 1 compared with cur-
rent discontinuous constituency parsers. When us-
ing bi-directional action graph parser, we achieved
state-of-the-art Ffor all the three treebanks and
state-of-the-art DFfor German treebanks. When
using uni-directional action graph parser, our re-
sults are even better. Merging the forward and back-
ward action edges parsed by two uni-directional
action parsers together achieves the best results10581
on two German treebanks, and the forward uni-
directional action parser achieves the best results
on DPTB. Our results using span-based continuous
constituency parsing model (Kitaev et al., 2019)
are generally better than those of using transition-
based one (Yang and Deng, 2020). Therefore, we
infer that compared with the left-to-right parsing of
transition-based method, the bottom-up parsing of
span-based method is more suitable for sequences
with rearranged word order. It is worth noting that
in the case of using the same pseudo-continuous
constituency parser, our DFscores are greatly im-
proved compared with Fernández-González et al.
(2021b), which is due to our higher reordering ac-
curacy. This shows that our reordering method is
effective.
The speeds of our systems are slightly slower
than those of Fernández-González et al. (2021b)
in which the reordering is achieved by a pointer
network, and faster than other methods with pre-
trained models. Since the time complexity of our
rearrangement algorithm is O(n)and it has no
network part, its execution time is almost negli-
gible compared to the total time. Therefore, the
reason why our systems are slower than Fernández-
González et al. (2021b) is that our action graph
parser is more complex than the pointer network.
However, the more complex reordering component
gives better performance and this tradeoff of sacri-
ficing speed for accuracy is valuable, because it is
the reordering performance that limits the accuracyof discontinuous parsing in the ‘reorder and then
parse’ method.
Obviously, large pre-trained models usually im-
ply higher accuracy but lower speed. Thus, speed
limits some relatively complex methods to further
use large pre-trained models for performance im-
provement. However, the high efficiency of our sys-
tems allows us to maintain their practicality when
including large pre-trained models. In other word,
we can have cake and eat it too.
Reordering Accuracy Because the LFscore
can not directly reflect the accuracy of the re-
ordered sequences derived by the rearrangement
algorithm, we only show the results of action graph
parsing on the dev splits in Appendix D. In order to
better demonstrate the performance of our whole
reordering method, we include a series of metrics
for evaluating the reordered sequences in Table
2. All of these metrics illustrate the reordering
accuracy, but they may also lose their comprehen-
siveness in some cases. For example, LCS only
counts the longest common substring and ignore
the rest part of the sequence. LSD pays too much
attention to the absolute location and ignores the
relative position between words that might form a
single constituent.
Referring to the final discontinuous constituency
results, we find that R-Rec and RFhave a more
stable measurement for reordering accuracy than
other metrics. In addition, the R-Prec of a single10582uni-directional action graph parser is high, but the
R-Rec is relatively low. When merging the forward
and backward action graphs parsed by two uni-
directional action parsers together, although the R-
Prec is slightly reduced, the R-Rec is significantly
higher, thus improving the reordering accuracy.
Pseudo-continuous Parsing Performance We
also include the performance of the pseudo-
continuous constituency parsers when using gold
reordered pseudo-continuous sequences in Table 3.
We restore the predicted pseudo-continuous trees
to discontinuous trees and score using discontin-
uous constituency metrics. The Fscores of the
pseudo-continuous constituency parsers are much
higher than current state-of-the-art discontinuous
parsers, and the DFscores show a huge increase
of over 10% in all three treebanks. This shows
that the reordering is the bottleneck, the overall
discontinuous performance still has much room
of improving if better reordering is achieved. In
addition, span-based models perform better than
transition-based models, especially DF1. This fur-
ther verifies that the span-based continuous con-
stituency parsing method is more suitable than the
transition-based method for parsing the rearranged
word sequences.
Ablation Study In Table 4, we report results of
our bi-directional action graph parser under dif-
ferent configurations on test splits. Training the
bi-directional action parser with both the forward
and the backward edges is better than training with
only one direction. This verifies that information
from both directions can reinforce each other and
help the learning process of bi-directional parser.
By comparing Fwith BandF (& B) with (F &)
B, we find that the models learn backward actions
better than forward actions. Besides, the results
ofB & F andF & B are better than those of F (&
B)and(F &) B , which suggests that our rearrange-
ment algorithm using one direction for placement
and the other for adjustment is effective.
5 Conclusion
In this work, we build fast and accurate discon-
tinuous constituency parsing systems working in
continuous way by innovatively propose a novel
reordering method. Results show that our method
is able to preserve the high performance of the
pseudo-continuous constituency parser with high
efficiency. We not only achieve state-of-the-art re-
sults on two treebanks, but also demonstrate that
the bottleneck of discontinuous constituency pars-
ing is reordering.
Limitations
The method has only been validated in two lan-
guages: English and German. Therefore, the uni-
versality of the method needs to be further veri-
fied. The metrics for evaluating action graph parser,
which further determine the performance of re-
ordering, are not effective enough that limit the
selection of the best action graph parsing model.
We have tried using the RFscore of reordered
pseudo-continuous sequences as the metric for ac-
tion graph parsing model selection, but have gotten
similar results to using the LFscore. The perfor-
mance of our systems are still behind that of the
pseudo-continuous constituency parser using gold
reordered sequences. Therefore, the research on
improving the reordering still needs to be carried
on.10583References105841058510586A Reordering Strategy
Set the priority of each node in the discontinuous
tree to the smallest one among the priorities of
its children, and the priority of a leaf node is its
word index in the original sentence. Assuming that
all sibling nodes are sorted by priority from small
to large, the word order given by a pre-order or
post-order traversal of the discontinuous tree is the
target pseudo-continuous sequence. The pseudo-
continuous tree can be obtained by adjusting the
original sentence into the pseudo-continuous se-
quence.
During the experiment, we convert the discontin-
uous treebank into a pseudo-continuous treebank
by the following process: The training data for dis-
continuous constituency parsing can be represented
in parentheses notation, where the integer to the left
of ‘=’ indicates the index of the word, which is to
the right of ‘=’, in the original sentence. From left
to right, the parenthesis notation shows a pre-order
traversal of the discontinuous tree, so the words
from left to right are already in our target order.
We only need to remove ‘=’ and the index to its
left to get the training data for pseudo-continuous
constituency parsing.
B Action Graph Dataset Statistics
In Table 6, we list the statistical results of the ac-
tion graph datasets. The forward and backward
graphs based on the same treebank contain about
the same number of edges. The number of label
SPAN is 0.5 to 0.7 times that of MOVE-L (orMOVE-R ),
indicating that more than half of the words are
moved by a form of continuous segments. Since
the bi-directional action graph parser we used con-
tains three second-order scores of edge, we count
the number of occurrences of these three kinds
of second-order pairs in the bi-directional action
graph datasets. Because of the chain structure of
uni-directional action graph, the number of grand-
parent is very large, followed by the number of
co-parent, and the number of sibling is small but
not negligible. Therefore, it is reasonable to use the
second-order parsing model as our bi-directional
action parser.
C Hyper-parameters Detail
D Action Graph Parsing Results
In Table 7, we show the results of the action graph
parsers on dev splits. For the same kind of action
graph, the trend of LFscore is positively corre-
lated with the reordering accuracy. However, the
scores of different kinds of action graph, includ-
ing the bi-directional graph, the forward graph and
the backward graph, cannot be directly compared.
Therefore, although it is reasonable to use LFas
the metric to select the best action graph parser, it
cannot be used as a stable measure of reordering
accuracy.1058710588