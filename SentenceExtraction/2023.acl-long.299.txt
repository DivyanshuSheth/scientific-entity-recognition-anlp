
Yihong Tang, Bo Wang, Miao Fang,
Dongming Zhao, Kun Huang, Ruifang He, Yuexian HouSchool of New Media and Communication, Tianjin University, Tianjin, ChinaCollege of Intelligence and Computing, Tianjin University, Tianjin, ChinaAI Lab, China Mobile Communication Group Tianjin Co., Ltd.School of Computer and Communication Engineering,
Northeastern University at Qinhuangdao, Qinghuangdao, China
{toyhom, bo_wang}@tju.edu.cn
Abstract
The personalized dialogue explores the consis-
tent relationship between dialogue generation
and personality. Existing personalized dialogue
agents model persona profiles from three re-
sources: sparse or dense persona descriptions
and dialogue histories. However, sparse struc-
tured persona attributes are explicit but unin-
formative, dense persona texts contain rich per-
sona descriptions with much noise, and dia-
logue history query is both noisy and uninfor-
mative for persona modeling. In this work, we
combine the advantages of the three resources
to obtain a richer and more accurate persona.
We design a Contrastive Latent Variable-based
model ( CLV ) that clusters the dense persona
descriptions into sparse categories, which are
combined with the history query to generate
personalized responses. Experimental results
on Chinese and English datasets demonstrate
our model’s superiority in personalization.
1 Introduction
In order to develop personalized dialogue agents,
current approaches enhance the personality of gen-
erated responses mainly utilizing three kinds of
resources: (1) Defined sparse persona attributes
(Zhang et al., 2018a; Song et al., 2019; Wolf et al.,
2019; Liu et al., 2020; Song et al., 2021); (2)
Dense persona description texts (Qian et al., 2018;
Zheng et al., 2020; Song et al., 2021); (3) Historical
queries of current dialogue (Li et al., 2016b; Ma
et al., 2021). Each of the three resources has its
advantages and disadvantages.
Sparse persona attributes (e.g., gender, age) are
highly interpretable and have high information uti-
lization, but the information is limited and cannot
express complex persona features. Dense persona
description text contains rich and flexible persona
information but suffers from noisy expressions.Modeling personality directly from dialogue histo-
ries is free of additional persona information, but
the persona information in history queries is both
noisy and uninformative.
To address these issues, in this paper, we im-
prove personalized dialogue generation by com-
bining the advantages of the three resources. We
design a contrastive latent variable (CLV)-based
model that clusters the dense persona descriptions
into sparse categories, which are combined with the
history query to generate personalized responses.
Specifically, first, the dialog’s latest query and re-
sponse together with dense persona description
texts are encoded. Then the recognition distribu-
tion of query and response is jointly modeled with
a pre-designed dual conditional variational autoen-
coder (CV AE (Sohn et al., 2015)). Simultaneously,
the persona information is automatically separated
into multiple parts to participate in the above pro-
cess in parallel. These partitioned persona pieces
of information are considered to hide different an-
gles of portrayal. This process is also reinforced by
contrastive learning. Next, a decider decides which
category of persona information is used for persona
modeling. Finally, a personalized generator com-
bines the history query and additional persona infor-
mation for response generation. Without explicit
supervised signals, we design a pseudo-labeling
and joint training method to train the decider.
Our contributions are summarized as follows:
(1) We design a framework named CLV based on
contrastive latent variables to combine the advan-
tages of three persona resources for personalized
dialogue generation. The framework contains a
self-separation algorithm and a decider, which are
jointly trained to work in conjunction with each
other. In this way, our work can both extract infor-
mation more efficiently from the cluttered persona
description text and not require persona informa-5456tion in the inference phase.
(2) Under the designed CLV-based framework,
we propose a self-separation algorithm to mine
and categorize dense persona description text into
sparse persona profiles. Furthermore, a decider is
proposed to decide whether the dialogue should in-
volve persona information and choose appropriate
persona profiles among the persona profiles gener-
ated by the self-separation algorithm. This process
helps to improve the consistency of personalized
dialogue generation.
(3) We conduct extensive experiments on the
Chinese and English personalized dialogue datasets
to demonstrate our model’s superiority. We also
propose a refined evaluation framework for per-
sonalized dialogue generation, which considers the
consistency, coherence, and diversity of dialogue
generation at the same time.
2 Related Work
Personalized Dialogue Generation Open-
domain dialogue has been studied in depth for a
long time (Koehn et al., 2003; Ni et al., 2021),
and under the influence of the psychological
theory, personality has been incorporated into
the requirements for dialogue generation. Per-
sonalized dialogue generation has three typical
approaches: (1) Using well-defined sparse persona
attributes (e.g., gender, age), the model can utilize
different attributes efficiently and interpretably,
and knowledge-enhanced dialogue generation
approaches can be borrowed (Zhang et al.,
2018a; Song et al., 2019; Wolf et al., 2019; Liu
et al., 2020; Bao et al., 2020; Song et al., 2021).
However, sparse attributes can only provide little
persona information without complex semantics.
(2) Mining information from dense textual persona
descriptions, which contain rich and deep persona
information but are very noisy (Qian et al., 2018;
Song et al., 2020; Zheng et al., 2020; Song et al.,
2021). (3) Implicitly modeling persona profiles
from historical dialogue query (Li et al., 2016b;
Ma et al., 2021; Zhong et al., 2022). This approach
does not rely on additional persona information,
but it is difficult to acquire personality implicitly
from dialogue history without reference objects.
Dialogue generation based on CV AE Besides
personalization, another essential goal of personal-
ized dialogue generation is the diversity of dialog
expression. To this end, existing works have ex-
plored hidden variable models that model the vari-ables in the dialogue process as Gaussian distribu-
tions, which can enhance the diversity of dialogue
generation by introducing randomness (Zhao et al.,
2017; Song et al., 2019; Hu et al., 2022). In this
direction, one typical approach is to include per-
sona information as a condition in regular Seq2Seq
constructs and to model responses and queries as
recognition distributions in CV AE (Li et al., 2018);
another approach is to combine persona informa-
tion or other external conditions and responses as
generation targets before modeling joint distribu-
tions together with queries (Lee et al., 2021). In
addition, many CV AE text generation models focus
on other tasks, and they modify model details as
well as probability maps for different tasks, which
are not considered in this paper.
3 Methodology
3.1 Overview
Given multi-turn dialogue of two users
u, u. The dialogue context of uis
U={(Q, R),···,(Q, R)}.Qis the
query initiated by utou. The goal of the
personalized dialogue is to generate a personalized
response Rusing the corresponding personal
information Pin text form.
The overview of our model is shown in Figure 1.
The overall model is composed of four modules:
encoder, self-separation module, decider, and gen-
erator (marked in Figure 1 with orange borders).
Specifically, the encoder module encodes dialogue
queries, persona information, and responses respec-
tively. The self-separation module separates the
persona information in the hidden sentence vec-
tor space to form the grouping of persona infor-
mation with implicit categories. We use multiple
CV AEs to process the grouping persona informa-
tion and get the grouping latent variables. The de-
cider then automatically selects the latent variable
to use from the group and feeds it into the gener-
ator along with the query. Finally, the generator
autoregressively generates personalized responses
based on the query and latent variables.
3.2 Encoder
we use a pre-trained GPT-2 (Radford et al., 2019)
to encode the personal information text P, dia-
log query Q, and dialog response R. We take
the hidden vector of the last time step in the last
layer of GPT-2 as the representation of the whole5457
paragraph:
p= GPT-2 (P), (1)
q= GPT-2 (Q), (2)
r= GPT-2 (R), (3)
where p, q, r∈R, anddis the dimension of the
hidden state.
Algorithm 1: Persona Self-Separation
Input: p∈R: the vector representation of
original sentence;
N: hyper-parameter, the self-separation
coefficient;
d: the dimension of the hidden state;
Output: P∈R: vector representations of
persona information after processing, in this
context, it is the form of a set;Initialize P;Sets←the integer of d/N ;fori= 1toNdo Initialize augment vector
c←(0,0, . . . , 0); Setc[(i−1)×s+ 1 : i×s]←
(1,1, . . . , 1);P[i,:]←MLP( p+c;c);end forreturn P3.3 Self-Separated Module
After obtaining the hidden state representation of
P,QandR, their representation vectors are further
processed. As mentioned above, sparse personal in-
formation is more explicit and interpretable, while
dense information text contains rich information
but needs to be more organized. Therefore, re-
ferring to the research of Sun et al. (2021), we
propose a self-separation method of persona infor-
mation, which implicitly divides dense text persona
information into Ncategories:
P= P-Sepa( p), (4)
where P={p, p,···, p}, and Prepresents
the persona information after grouping, which is
composed of multiple parallel persona information.
For the algorithm of P-Sepa, see Algorithm 1.
In order to let the model automatically clas-
sify the grouped persona information, we use con-
trastive learning on the data in the same batch to
let the model learn the similarities between the
grouped persona information. Specifically, for two
data points, PandP, we use a contrastive loss to
help the model better represent group persona infor-
mation.Following simcse, we denote h=f(p)
where p∈P. Then we get the training objective:
L=−loge
/summationtexte, (5)5458where τis a temperature hyperparameter and
sim(h, h)is the cosine similarity.
The model samples the persona latent variable
zfrom the persona distribution and the response
latent variable zfrom the potential response dis-
tribution. Since zandzrespectively represent
different aspects of the generated responses ( z
contains the persona, and zcaptures the spe-
cific query-response association), we assume that
zandzare independent of each other, namely
z⊥z. So, the response generation process can
be said to use the following conditional distribution
p(r, z, z|q) =p(r|q, z, z)p(z|q)p(z|q). Our
goal is to use the deep learning method to approxi-
mate p(r|q, z, z),p(z|q)andp(z|q), in which,
according to Zhao et al. (2017) and Song et al.
(2019), we refer to p(r|q, z, z)as a response gen-
erator and p(z|q),p(z|q)as aprior network . In
order to approximate the posterior distribution of
the true, we refer to q(z|q, p)andq(z|q, r)as
recognition networks.
We train this CV AE using Stochastic Gradient
Variational Bayes(SGVB) (Kingma and Welling,
2013) by maximizing the variational lower bound
of conditional log-likelihood. Following Zhao et al.
(2017) and Song et al. (2019), we assume that po-
tential variables zandzfollows a multivariate
Gaussian distribution with the diagonal covariance
matrix. The lower bound of the variation of CLV-
CV AE can be written as:
Because we assume that the underlying variables
zandzfollow isotropic multivariate gaussian dis-
tribution, both recognition networks q(z|q, p)∼
N(µ, σI)andq(z|q, r)∼ N (µ, σI), both
prior networks p(z|q)∼ N (µ, σI)and
p(z|q)∼ N (µ, σI). In order to sample z
andzfrom the prior network and recognition net-
work in training and to make the sampling oper-
ation differentiable, using the reparameterization
technique (Kingma and Welling, 2013), we have:
/bracketleftbiggµ
σ/bracketrightbigg
=W/bracketleftbiggq
p/bracketrightbigg
+b, (7)
/bracketleftbiggµ
σ/bracketrightbigg
=W/bracketleftbiggq
r/bracketrightbigg
+b, (8)
/bracketleftbiggµ
σ/bracketrightbigg
=Wq+b, (9)/bracketleftbiggµ
σ/bracketrightbigg
=Wr+b, (10)
where p, r, q are the representation vectors obtained
in Section 3.2.
Finally, zis fed into the generator to generate
rtogether with the dialogue query q, where: z=
z+z. How to get the final zis explained in
detail in Section 3.4.
3.4 Decider
In fact, in order to make the model can find the ap-
propriate persona information, we do not let CLV
choose from the grouped persona information di-
rectly, but first, use the recognition network or prior
network to obtain the grouped persona information
latent variables Z={z, z,···, z}, which is
obtained by sampling a set of distributions con-
structed separately for each vector in P. Then, the
Decider is trained to choose between them. We call
it the Decider because it also includes the decision
not to use personal information.
Specifically, the decider is a classification neu-
ral network composed of multi-layer sensing units
which use a soft decision method to make a selec-
tion. The decider-matrix is composed of classifica-
tion probability, and the classification probability
is multiplied by the grouping persona information
latent variable to get the final persona information
latent variable z. For grouped persona information
latent variable Z:
W= Softmax(MLP([ Z;q])), (11)
z=W·Z, (12)
where Z∈R,W∈Randz∈R.
It is difficult to directly let the decider learn how
to choose from the latent variables of grouping
persona information generated by sampling the per-
sona distribution of implicit clustering. Therefore,
we introduce the pseudo-label to guide the learning
of the decider. The more intuitive idea is that if a
latent variable in the group of persona information
latent variables can achieve a minor decoding loss
in the generator, then it may be a better latent vari-
able. Based on this idea, we designed the decision
loss to train the decider:
y= Argmin(GPT-2(Z)), (13)
L=−ylog(W), (14)
where yis the index corresponding to zinput into
the generator to obtain the minimum decoding loss.5459
3.5 Generator
We use a pre-trained GPT-2 as the generator, which
uses the dialogue query as input and adds cross-
attention to the latent variable z:
ˆR= GPT-2 (Pre(z), q), (15)
where Pre(z)is the pre-cross attention object
added before the standard GPT-2, which autore-
gressively generates a personalized response ˆR.
3.6 Training and Optimizer
In our practice, we find that there are some chal-
lenges in training the decider, which is probably
the reason for the mutual influence between loss
functions. Firstly, there will be conflicts between
the KL divergence and the decoding loss of the gen-
erator. Secondly, the loss of the decider depends
on the dummy label monitoring signal set by us.
Finally, for the purpose of implicit clustering of
persona information, the contrastive enhancement
loss is largely independent of the above losses.
In order to promote gradient learning involving
the above loss functions, a joint training process
is designed to train CV AE and decider alternately.
Specifically, in each training iteration, we first sam-
ple query Q, response R, and persona information
Pof two data points from batch data D, conduct
contrastive training on encoders encoding persona
information according to the self-separation algo-
rithm 1, and then generate latent variables after self-
separation respectively according to the method de-
scribed in Section 3.4. The generator’s loss value
creates a dummy label y (Eq. 13), which is used to
train the decider by optimizing the loss L(Eq. 14).
Further, we traverse D, generate a personalized
response R, and update the generator and CV AE
MLP by optimizing loss L(Eq. 6).
4 Experiments
4.1 Datasets
ConvAI2 (Dinan et al., 2019) is an English dataset
containing rich personal information, and the dia-
logues in this dataset are based on the personal facts
corresponding to the characters. It is derived from
PersonaChat (Zhang et al., 2018b) and obtainedafter filtering and refinement. It is a crowdsourced
dataset covering rich persona features, and we have
processed it to remove some noise.
Baidu PersonaChat, which is a personaliza-
tion dataset collected and open-sourced by Baidu,
is similar to ConvAI2, although it’s Chinese.
We summarize the key statistics of the two per-
sonalized dialogue datasets in Table 1. As men-
tioned earlier, we only use the persona information
of the two datasets during training.
4.2 Baselines
We compare the proposed model with 6 baselines,
which can be classified into 3 categories.
Non-Personalized Approaches Seq2Seq with
Attention (Sutskever et al., 2014) is a sequence-
to-sequence model with an attention mechanism
(Luong et al., 2015). The pre-trained GPT-2 (Rad-
ford et al., 2019) performs well in various text gen-
eration tasks and is used as a dialogue generation
model after training on a dialogue corpus.
Approaches based on Dense Persona Informa-
tion These methods use persona information to
construct knowledge enhancement models, and for
better model comparison, we tested these methods
using the dialogue history as an approximation of
the persona information. PerCV AE (Zhao et al.,
2017) encodes the persona information text as a
conditional representation and uses CV AE to gener-
ate personalized responses. BoB (Song et al., 2021)
uses the Bert model for personalized dialogue gen-
eration and integrates the consistency generation
task with the consistency inference task jointly to
provide insight into the evaluation mechanism of
personalized dialogue generation.
The Dialogue History-based Approach DHAP
(Ma et al., 2021) uses historical memory to store
and construct dynamic query-aware user profiles
from dialogue histories and then uses a personal-
ized decoder to generate responses. MSP (Zhong
et al., 2022) enhances personalized dialogue gen-
eration by retrieving similar conversations from
similar users via User Refiner and Topic Refiner
and uses a Token Refiner to find the relevant tokens
to be used during training, which is the best overall
performance model for persona-free information
personalized dialogue generation.
Implementation Details are in Appendix A.1.5460
4.3 Evaluations
In order to obtain accurate performance compar-
isons, we use both automatic and human evalua-
tions.
Automatic Evaluation We divide the automatic
evaluation methods into three categories in order to
evaluate and model the diversity, consistency, and
coherence of the generated dialogues.
(1)Diversity Distinct-1/2 (Li et al., 2016a) con-
siders the number of single or double frames in
the generated responses and is usually used to eval-
uate diversity. Most experiments do not specify
the object of evaluation for Distinct-1/2, whether
it is the whole corpus or multiple sentences, so
we propose C-Dist-1/2(Corpus-Distinct-1/2) and
S-Dist-1/2(Sentence-Distinct-1/2) according to the
different objects of evaluation, the former evaluat-
ing the dialogue responses generated by the model
on the whole test set, and the latter evaluating mul-
tiple responses (set to generate five responses in
this paper). S-Dist-1/2 provides a better evalua-
tion of whether the model can generate interesting
responses in the same situation.
(2)Consistency The personalized dialogue gen-
eration task requires consistency between the gener-
ated responses and the persona information, and we
propose Con.Score (Consistency Score) based on
C.score (Madotto et al., 2019), which is obtained
based on the referee model and can be defined as:
where the NLI model is a triple classificationmodel and can be found in Appendix A.
(3)Coherence BLEU-1 (Papineni et al., 2002)
and ROUGE-L (Lin and Och, 2004) are classical
words overlap-based metrics for measuring the sim-
ilarity between generated responses and factual re-
sponses, which we believe can indirectly measure
the coherence of dialogues. The reason we didn’t
look at BLEU-2/3/4 because we think that too
much rigid coverage doesn’t reflect the coherence
of the model. And similar to the Con.Score, we pro-
pose the Coh-Con.Score (Coherence-Consistency
Score), which is also obtained based on the NLI
model:
Human Evaluation Taking into account the un-
certainty of the criteria when evaluating, we per-
form human evaluations of all models, and we
convert the scoring method to a ranking method.
Specifically, we extract 100 data points(queries, re-
sponses, and persona information) and hire three
well-educated annotators to score the responses
generated by the different models in a ranking style
and to normalize them into specific scores on a
scale of [0,1]at the end. We focus on four aspects:
readability, diversity, consistency, and coherence,
and ask the evaluators to rank eight options for the
seven model-generated responses and the factual
responses.
4.4 Experimental Results
Automatic Evaluation Table 2 shows the perfor-
mance of all models on different automatic met-
rics for both Chinese and English datasets, and5461
it can be clearly observed that our CLV model
improves on key metrics and these improvements
are statistically significant (t-test with p-value <
0.05). Specifically, we can observe that: (1) Di-
versity . CLV shows different results on the two
diversity evaluation dimensions. For S-Dist-1/2,
CLV leads the other models, which indicates that
our model is able to make more diverse and flexible
responses compared to other models when facing
the same situation. However, C-Dist-1/2 is lower
than most models, which indicates that our model
makes some sacrifices to improve consistency and
coherence, and we will analyze this reason fur-
ther in Section 5. (2) Consistency . The lead of
the consistency personalization metric Con.Score
implies that our approach can integrate persona in-
formation into the generation, especially when this
integration is done without information generation,
which is more indicative of the superiority of CLV .
(3)Coherence . The performance of our model
in coherence is also outstanding, whether it is the
coverage index BLEU-1, Rouge-L, or the learn-
ing index Coh-Con.Score, which also shows that
it is feasible to use the coverage index as a kind
of evaluation basis for dialogue coherence. Our
task diversity, coherence, and consistency can be
used as three key bases for evaluating personalized
dialogue generation, and the findings in the exper-
iments suggest that our model is able to produce
more personalized responses than all baselines.
Human Evaluation Human evaluation results
on ConvAI2 are shown in Table 3. We calculated
the Fleiss Kappa among the three annotators and
obtained a Kappa of 0.67, which implies that the
three annotators are in substantial agreement (Lan-
dis and Koch, 1977). In general, the results of hu-
man annotations are consistent with the results of
automatic evaluations. They both demonstrate the
advantages of our model in terms of personalizeddialogue generation and basic readability.
5 Further Analysis
We further describe our model through a series of
analyses. All analyses are based on the ConvAI2
dataset, and similar phenomena can be observed on
Baidu PersonaChat.
Ablation Study To investigate the effects of dif-
ferent modules in CLV , we conducted an ablation
study by removing modules. The results of the
ablation study are shown in Table 5. We first in-
vestigated the impact of the core mechanism of the
model, the self-separation algorithm. After remov-
ing the complete self-separation mechanism, the
model degenerates to the most basic GPT-2 model,
and it can be observed that the performance is on
par with GPT-2. If we just remove the contrastive
learning in the self-separation algorithm and keep
the CV AE, we can see that the performance of the
model also has a large decline, but the model’s
C-Dist-1/2 has an improvement, which is due to
the global diversity due to the randomness of the
sampled hidden variables in CV AE, which also in-
dicates that CLV does sacrifice global diversity for
other performance. Then , for the decider , we elim-
inate persona information by directly computing
the mean of the grouped persona information la-
tent variables, and we can find that the decider also
plays an important role in CLV , especially when
many dialogues are generated without considering
persona, which shows that our decider can make
decisions automatically. Finally , we conducted an
experiment to validate our proposed joint training,
and its performance degradation shows that it is dif-
ficult for the decider to learn how to make decisions
without additional supervised signals.
Effect of Self-Separation Coefficients In CLV ,
the self-separation mechanism categorizes the per-
sona information in an approximate implicit clus-
tering way, and the self-separation coefficient N
corresponds to the number of categories in the clus-
ters. Intuitively, the self-separation factor will af-
fect the model’s performance, and we report this
effect in Figure 2. The self-separation mechanism
cannot do much good when the N is small. When
N is set too large, the decider is also unable to make
good decisions, which is due to the increased noise
caused by too many categories, making the persona
information too scattered, which is also consistent
with the fact that the descriptive texts are always5462
confined to several fixed perspectives.
To demonstrate the model’s effectiveness more
concretely, we conduct case studies. The results are
shown in Table 4, which show that CLV can extract
personal information, reconstruct persona profiles
from queries alone, extract personal information,
and generate fluent, personalized responses.
In Case 1, both CLV and BoB accurately an-
swered "music" when asked about their hobbies,while CLV also used "How about you? " to keep
the conversation going. In Case 2, CLV not only an-
swered the address accurately but also flexibly used
"school teacher" and "Affiliated Primary School of
Renmin University" in the persona information to
generate the response. In Case 3, all four models
failed to accurately answer the question consistent
with personality, but CLV still connected "lawyer"
and "legal affairs".
By observing Cases 1 and 2, we can see that
CLV can balance consistency and coherence, and
its generation is consistent with persona and main-
tains context coherence. GPT-2 can only achieve
basic sentence fluency. BoB and MSP can also
generate good answers due to the help of context
in reasoning. In Case 3, CLV creates a slightly fit
answer, which is also better than the other models.
6 Conclusion
In this work, we propose a CLV model for person-
alized dialogue generation. Unlike existing works,
we integrate the advantages of sparse and dense per-
sona information. We use a self-separation mecha-
nism to implicitly cluster the persona information
in the dense persona information text so that the
decider can consider different sparse categories of
persona information during dialogue and enhance
the personalization of dialogue generation. We also
propose a more effective evaluation metric frame-
work for personalized dialogue generation. The
experimental results confirm the effectiveness of
the model in generating personalized responses.5463Limitations
First, our model is a method of approximating clus-
tering by contrastive learning, but due to the limi-
tations of the model structure, we cannot directly
explore the performance of past clustering algo-
rithms on this task. Secondly, due to the large scale
of the experiment, our dialogue generator only con-
siders GPT-2. Although the ablation study proves
the effectiveness of our model, it is a limitation.
Finally, this paper proposes a complete evaluation
framework for personalized dialogue generation. It
is very effective, but the specific indicators in it still
need to be discussed and further studied. In addi-
tion, the model assumes that response and persona
are independent Gaussian distributions in CV AE.
Although it performs well in the experiment, it does
not conform to realistic cognition.
Ethics Statement
From a general moral point of view, the generation
of personalized dialogue in a broad sense may in-
deed cause problems such as identity forgery and
the spread of false information. However, in this
study, personalized corpus and responses are lim-
ited to the scope of experiments, which are not
enough to threaten the real conversation.
Furthermore, all models in this paper are trained
on public corpus. The used datasets do not contain
unethical language. We also ensure the anonymiza-
tion of the human evaluation.
Acknowledgements
This work was supported by National Natural Sci-
ence Foundation of China(62272340, 61876128,
61876129, 62276187, 61976154, 61402323), State
Key Laboratory of Communication Content Cogni-
tion(Grant No.A32003).
References54645465
A Appendix
A.1 Default Parameter Settings
Our experiments are done based on pre-trained
GPT-2, and we tried various model structures and
hyperparameters, and the final hyperparameters
are as follows: the size of GPT-2 embedding and
GPT-2 hidden vector is 768. All word embedding
dimensions are set to 768, and we use word2vec to
initialize word embedding. The number of layers of
Transformer is 12. The self-separation coefficientN is set from 2 to 16(default is 4), the MLP input
dimension and output dimension in the model are
kept the same as the hidden vector, and the number
of batches was set to 16. The maximum learning
rate is 1e-4. The training of the proposed model
was done on an Nvidia Telsa V100 16G GPU. The
total training time takes approximately 10 hours.
The temperature hyperparameter τis0.5. The pre-
trained models used in these experiments of this pa-
per include gpt2, gpt2-chinese-cluecorpussmall,
xlm-roberta-base, and chinese-roberta-wwm-ext.
We use kernel sampling (Holtzman et al., 2020)
as our decoding strategy, use the Adam (Kingma
and Ba, 2014) optimizer to train the model and use
AdamW (Loshchilov and Hutter, 2019) to warm up
the generator. Please refer to the published project
for additional details, which is publicly available.
A.2 NLI Model
NLI model is a triple classification model and can
be design as:
NLI(P, Q, R )
=

2,ifP is consistent with R
and Q is coherent with R ,
1,ifP is consistent with R
but Q is not coherent with R
0,otherwise ,(18)
Here NLI (Welleck et al., 2019) is a pre-trained
RoBERTa model (Liu et al., 2019), fine-tuned us-
ing a dataset constructed based on ConvAI2 and
Baidu PersonaChat, and the test set accuracy of
NLI model on Chinese and English is 83.2% and
83.1%, respectively.5466ACL 2023 Responsible NLP Checklist
A For every submission:
/squareA1. Did you describe the limitations of your work?
limitations, 4.1 Datasets and 4.4 Evaluations.
/squareA2. Did you discuss any potential risks of your work?
Ethics Statement.
/squareA3. Do the abstract and introduction summarize the paper’s main claims?
Abstract, 1 Introduction.
/squareA4. Have you used AI writing assistants when working on this paper?
Left blank.
B/squareDid you use or create scientiﬁc artifacts?
4.1 Datasets, 4.4 Evaluations, A.1.
/squareB1. Did you cite the creators of artifacts you used?
4.1 Datasets, 4.4 Evaluations, A.1.
/squareB2. Did you discuss the license or terms for use and / or distribution of any artifacts?
4.1 Datasets.
/squareB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided
that it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is
compatible with the original access conditions (in particular, derivatives of data accessed for research
purposes should not be used outside of research contexts)?
4.1 Datasets.
/squareB4. Did you discuss the steps taken to check whether the data that was collected / used contains any
information that names or uniquely identiﬁes individual people or offensive content, and the steps
taken to protect / anonymize it?
In the original text of the dataset, the relevant data description has been included.
/squareB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and
linguistic phenomena, demographic groups represented, etc.?
4.1 Datasets.
/squareB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,
etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the
number of examples in train / validation / test splits, as these provide necessary context for a reader
to understand experimental results. For example, small differences in accuracy on large test sets may
be signiﬁcant, while on small test sets they may not be.
4.1 Datasets.
C/squareDid you run computational experiments?
A.1 Default Parameter Settings, 4.5 Experimental Results.
/squareC1. Did you report the number of parameters in the models used, the total computational budget
(e.g., GPU hours), and computing infrastructure used?
A.1 Default Parameter Settings.5467/squareC2. Did you discuss the experimental setup, including hyperparameter search and best-found
hyperparameter values?
A.1 Default Parameter Settings.
/squareC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary
statistics from sets of experiments), and is it transparent whether you are reporting the max, mean,
etc. or just a single run?
4.5 Experimental Results.
/squareC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did
you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,
etc.)?
A.1 Default Parameter Settings.
D/squareDid you use human annotators (e.g., crowdworkers) or research with human participants?
4.4 Evaluations.
/squareD1. Did you report the full text of instructions given to participants, including e.g., screenshots,
disclaimers of any risks to participants or annotators, etc.?
4.4 Evaluations.
/squareD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)
and paid participants, and discuss if such payment is adequate given the participants’ demographic
(e.g., country of residence)?
4.4 Evaluations.
/squareD3. Did you discuss whether and how consent was obtained from people whose data you’re
using/curating? For example, if you collected data via crowdsourcing, did your instructions to
crowdworkers explain how the data would be used?
4.4 Evaluations.
/squareD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?
It will be mentioned later in the acknowledgments.
/squareD5. Did you report the basic demographic and geographic characteristics of the annotator population
that is the source of the data?
4.4 Evaluations.5468