
Junjie Chen,Xiangheng HeandYusuke Miyao
Department of Computer Science, The University of Tokyo, Tokyo
GLAM – Group on Language, Audio, & Music, Imperial College London, UK
{christopher, yusuke}@is.s.u-tokyo.ac.jp
x.he20@imperial.ac.uk
Abstract
In this paper, we propose a mixture model-
based end-to-end method to model the
syntactic-semantic dependency correlation in
Semantic Role Labeling (SRL). Semantic de-
pendencies in SRL are modeled as a distribu-
tion over semantic dependency labels condi-
tioned on a predicate and an argument word.
The semantic label distribution varies depend-
ing on Shortest Syntactic Dependency Path
(SSDP) hop patterns. We target the variation
of semantic label distributions using a mixture
model, separately estimating semantic label dis-
tributions for different hop patterns and proba-
bilistically clustering hop patterns with similar
semantic label distributions. Experiments show
that the proposed method successfully learns
a cluster assignment reflecting the variation of
semantic label distributions. Modeling the vari-
ation improves performance in predicting short
distance semantic dependencies, in addition to
the improvement on long distance semantic de-
pendencies that previous syntax-aware methods
have achieved. The proposed method achieves
a small but statistically significant improvement
over baseline methods in English, German, and
Spanish and obtains competitive performance
with state-of-the-art methods in English.
1 Introduction
Semantic Role Labeling (SRL) answers an essen-
tial question about sentence semantics: “[Who]
[does what] [to whom]”. A core problem of SRL is
identifying semantic dependencies that specify the
semantic role of arguments in relation to predicates
(He et al., 2018; Kasai et al., 2019). For exam-
ple, [who] (argument) is the agent (semantic role)
to [does what] (predicate). Semantic dependency
parsers (Dozat and Manning, 2018a) identify se-
mantic dependencies by giving a distribution over
semantic dependency labels (denoted as semantic
label distribution) for all predicate-argument pairs.Figure 1: An example illustrating the impact of SSDPs
on semantic label distributions. The solid underline
highlights the predicate, and the dashed underline high-
lights the arguments.Figure 2: An illustration of the proposed mixture model-
based method for semantic dependency parsing.
In this paper, we propose a mixture model (Pear-
son, 1894) based semantic dependency parser for
SRL where we target the dependence of semantic
label distributions on Shortest Syntactic Depen-
dency Path (SSDP) patterns. SSDP is the short-
est path connecting a predicate-argument pair in a
syntactic dependency tree. Bunescu and Mooney
(2005) and Cai et al. (2016) claim that SSDP en-
codes most information about bigram relations,
such as the semantic dependency. Indeed, previous
research (He et al., 2018; Xia et al., 2019) shows
that modeling the correlation between SSDPs and
semantic dependencies is crucial for building a
high-performance SRL system.7959Semantic label distributions vary depending on
SSDPs, even when the SSDPs connect predicate-
argument pairs with the same surface words. Figure
1 shows an example where two predicate-argument
pairs have different semantic dependency labels
while sharing the same surface words. SSDP pat-
terns help discriminate semantic labels between the
two pairs. The example indicates the dependence
of semantic label distributions on SSDP patterns.
We propose a mixture model-based method (Figure
2) to model the dependence in two steps: (1) Sep-
arately estimating semantic label distributions for
different SSDP patterns as component distributions,
and (2) Probabilistically clustering SSDP patterns
with similar semantic label distributions using a
mixture weight. The mixture model estimates the
semantic label distribution by aggregating the com-
ponent distributions using the mixture weight. We
focus on SSDP hop patterns in this paper as we ob-
served a drastic variation in semantic label distribu-
tions for different hop patterns through the change
in mutual information (Shannon et al., 1949) (Sec-
tion 2).
We evaluate the proposed method using the
CoNLL-2009 dataset (Haji ˇc et al., 2009), the
most popular multi-lingual SRL dataset with paral-
lel syntactic and semantic dependency annotations.
Experiments show that the proposed method cor-
rectly learns a mixture weight reflecting the varia-
tion in semantic label distributions. Modeling the
variation improves performance in predicting short
distance semantic dependencies in addition to long
distance dependencies that previous syntax-aware
methods (He et al., 2018; Roth and Lapata, 2016;
Strubell et al., 2018) improve only on. Previous
syntax-aware methods improve their performance
on long distance dependencies at the expense of
the performance on short distance dependencies. In
comparison, the proposed method makes no such
compromise, improving its performance over se-
mantic dependencies of all ranges. In general, the
proposed method obtains a small but statistically
significant improvement over baseline methods in
English, German, and Spanish and achieves com-
petitive performance with state-of-the-art methods
in English.
Our contributions are: (1) studying the variation
in semantic label distributions for different SSDP
hop patterns, (2) proposing a mixture model-based
method capturing the variation, and (3) conduct-
ing a detailed experiment evaluating the proposed
method.
2 Motivation
As mentioned in Section 1, SSDP affects the choice
of semantic dependency labels. We study the im-
pact of SSDP hop patterns on semantic label distri-
butions through the change in mutual information
(Shannon et al., 1949) in this section. We observe a
drastic change in mutual information only for hop
patterns that frequently co-occur with semantic de-
pendencies.
SSDP is the path connecting a predicate-
argument pair in a syntactic dependency tree. Its
hop pattern describes the number of transitions
needed to transit from the predicate to the argument.
We denote the hop pattern by (α, β), where αis the
number of dependent-to-head transitions and βis
the number of head-to-dependent transitions. In a
syntactic dependency tree, syntactic dependencies
are arcs pointing from syntactic heads to syntac-
tic dependents. The head-to-dependent transition
moves in the same direction as the syntactic depen-
dencies, whereas the dependent-to-head transition
moves in the opposite direction. In Figure 1, the
SSDP connecting “eliminate” and “it” consists of a
dependent-to-head transition moving from “elimi-
nate” to “will”, and a head-to-dependent transition
moving from “will” to “it”. The hop pattern of this
SSDP is (1, 1).
We denote the syntactic random variable for hop
patterns as Xand the semantic random variable for
semantic labels as Y.Xmaps predicate-argument7960word pairs (p, a)in a sentence sto their hop pat-
terns, whereas Ymaps the pairs to their semantic
labels. Their mutual information MI(X, Y )mea-
sures the reduction in uncertainty about Yafter
knowing X. High mutual information indicates
relatively low uncertainty in the conditional distri-
bution P.
To highlight the impact of hop patterns on se-
mantic label distributions, we compare the mutual
information of two ideal models, a syntax-aware
model (X, Y)and a syntax-agnostic model
(X, Y). We define the syntactic variables X
andXas Equation 1 and 2. This definition makes
the variable Xsensitive only to the hop pattern
(α, β)andXblind to any hop pattern information.
We define the mutual information gain of (α, β)as
the difference in mutual information between the
syntax-aware model and the syntax-agnostic model
(Equation 3).
Figure 3 reports the mutual information gain of
each hop pattern using the English training set of
the CoNLL-2009 dataset. The figure shows that
different hop patterns have drastically varying mu-
tual information gains. A sharp spike of mutual
information gain occurs in the hop pattern (0, 1)
with a gain value of 0.149 bits, indicating a strong
impact of the hop pattern (0, 1) on semantic label
distributions. Hop patterns with relatively short
transitions have non-zero gains ranging from 0.011
bits to 0.149 bits, which indicates the degree of
impact differs drastically. These hop patterns fre-
quently co-occur with semantic dependencies (He
et al., 2018). On the other hand, hop patterns co-
occurring rarely with semantic dependencies have
long transitions. These hop patterns have near-zero
mutual information gains in Figure 3, which indi-
cates the weak impact of the patterns. The varying
degree of impact motivates the separate estimation
of semantic label distributions for different hop pat-
terns. The amount of hop patterns with a weak
impact motivates the clustering of hop patterns that
share similar semantic label distributions.
3 Background
In this section, we present background information
about syntactic and semantic dependency parsingand mixture models. We also present a brief survey
about syntax-aware SRL methods using SSDP in-
formation and compare the proposed method with
the previous methods.
3.1 Syntactic and Semantic Dependency
Parsing
Both syntactic and semantic dependencies describe
bigram relations between words, namely heads and
dependents. The heads and the dependents corre-
spond to syntactic heads and dependents in syn-
tactic dependencies and predicates and arguments
in semantic dependencies. The similarity suggests
that a mechanism, such as the biaffine parser (Dozat
and Manning, 2017, 2018b), can capture the two
dependencies. For semantic dependencies, the bi-
affine parser estimates a distribution P(r|p, a)over
relations r∈ RS{ϵ}between a predicate pand an
argument a.Rdenotes the set of semantic relation
labels, and ϵdenotes no relation occurring between
panda. For syntactic dependencies, the biaffine
parser estimates a distribution P(h|d), predicting
the syntactic head hof the syntactic dependent d.
Neural biaffine parsers estimate the two distribu-
tions as Equation 4, 5, 6, and 7. e,e,eande
denote the feature vectors of p,a,handdfrom a
sentence encoder.
3.2 Mixture Model and Latent Variable
Model
Mixture models assume data to be generated from
a mixture distribution whose component distri-
butions belong to the same distributional family,
such as the Gaussian distributions, but possess
distinct parameters. The mixture of component
distributions grants additional flexibility to the
mixture model. For example, the Gaussian mix-
ture model can capture multi-mode phenomena as
opposed to the simple Gaussian model (Bishop
and Nasrabadi, 2007). A mixture model contains
two core variables: an observable data variable7961Xand a latent variable Cindexing the compo-
nent distribution that generates the data. The
mixture model computes the marginal likelihood
P(x) :=PP(x|c)P(c)by aggregating its
component distributions P(x|c)using the mix-
ture weight P(c). The optimal parameter (i.e.,
the mixture weight and the parameters of compo-
nent distributions) can be estimated by maximiz-
ing the log-likelihood logP(x). However, direct
maximum likelihood estimation on the marginal
log-likelihood is intractable for mixture models
(Murphy, 2012), and the conventional Expectation-
Maximization algorithm (Dempster et al., 1977) re-
quires finding optimal parameters at each iteration.
Variational Inference (Xu et al., 2015; Ba et al.,
2015) maximizes a variational lowerbound of the
log-likelihood (Equation 8), simultaneously opti-
mizing the component distributions and the mixture
weight.
3.3 Syntactic Dependency Information in
Semantic Dependency Parsing
Inspired by the close connection of syntactic and
semantic dependencies, He et al. (2018), Roth and
Lapata (2016), and Shi et al. (2020) attempt to build
high-performance SRL systems using SSDP infor-
mation. While the research improves performance
over syntax-agnostic methods, their methods ei-
ther require language-specific hyperparameters or
exhibit a behavior challenging to interpret.
The pruning method (He et al., 2018, 2019) is
readily interpretable but requires language-specific
hyperparameters. The method utilizes a statistical
bias that most SSDPs rarely co-occur with seman-
tic dependencies. It eliminates predicate-argument
pairs of the infrequent SSDPs using heuristics.
Whether an SSDP can co-occur with semantic de-
pendencies is hardcoded in heuristics, making the
method highly interpretable. However, the heuris-
tics are language-specific, requiring manual tuning
for every language.
The neural methods (Roth and Lapata, 2016;
Foland and Martin, 2015) are more language-
independent but suffer from limited interpretability.
The methods implicitly encode SSDP information
using neural network encoders. Roth and Lapata
(2016) and Foland and Martin (2015) encode SS-
DPs in a continuous embedding using an Long-Short Term Memory (LSTM) model or a Convo-
lutional Neural Network model. Shi et al. (2020)
jointly learns SSDP and semantic dependency infor-
mation using a Transformer (Vaswani et al., 2017)
by merging SSDP information with semantic de-
pendency labels. The research reports performance
improvements in one or more languages. How-
ever, interpreting the model’s behavior is challeng-
ing. Neural encoders, such as the LSTM model in
Roth and Lapata (2016), project SSDPs in a high-
dimensional space. The high-dimensional space
has a complex structure, rendering clustering anal-
yses based on Euclidean distances less effective.
Roth and Lapata (2016) interprets the behavior of
their model using the clustering analysis, suggest-
ing that their model captures many linguistic phe-
nomena. However, the linguistic phenomena are
fragmental and limited to a few syntactic construc-
tions.
In contrast, the proposed method is generic like
the neural methods and interpretable like the prun-
ing method. The proposed method optimizes its
parameters using gradients of the back-propagated
errors, which makes the proposed method more
language-independent. As a result, the proposed
method learns a mixture weight reflecting the im-
pact of SSDP hop patterns on semantic label dis-
tributions, enabling analyses using the mixture
weight.
4 Proposal
In this section, we present the proposed mixture
model-based semantic dependency parser to model
the dependence of semantic label distributions on
SSDP hop patterns. In Section 2, we discussed
the need to separately estimate semantic label dis-
tributions for different hop patterns and the need
to cluster hop patterns sharing similar semantic la-
bel distributions. The proposed parser estimates
semantic label distributions for different hop pat-
terns using the component distributions and clus-
ters hop patterns using the mixture weight of a
mixture model.
Figure 2 illustrates the model architecture of the
proposed method. The model contains a conven-
tional biaffine parser for syntactic dependencies
and a mixture model-based biaffine parser for se-
mantic dependencies. The syntactic parser provides
a syntactic dependency tree from which the clus-
tering component extracts hop patterns and deter-
mines the mixture weights. The biaffine parsers in7962the semantic parser estimate the component distri-
butions. The semantic parser computes the seman-
tic label distribution by aggregating the component
distributions using the mixture weight. The syn-
tactic and the semantic parser share a backbone
sentence encoder, a Transformer model in our im-
plementation. We jointly optimize the parameters
of the syntactic and the semantic parser by optimiz-
ing the log-likelihood of the syntactic dependencies
and a variational lowerbound of the log-likelihood
(ELBo) of the semantic dependencies. We use
the lowerbound as an approximation to the log-
likelihood for inference because we find it works
best in predicting semantic dependencies.
We expand on the training objective of the se-
mantic parser. The objective is to maximize the
likelihood P(r|p, a)of the observed semantic la-
belrconditioned on the predicate pand the argu-
ment a. We rewrite the likelihood as a marginal of
the joint likelihood P(r, c|p, a)where cis the in-
dex of the component distributions. The joint like-
lihood can be decomposed as Equation 12 where
the former term corresponds to the component dis-
tributions and the latter term corresponds to the
mixture weight. Since we are interested in separat-
ing semantic label distributions by hop patterns, we
replace the term P(c|p, a)withP(c|ssdp( p, a))
where ssdp( p, a)maps predicate-argument pairs to
their hop patterns. P(c|ssdp( p, a))also serves
as the variational approximation q(c|r, p, a )be-
cause we assume the hop pattern, together with
the predicate-argument pair, determines the seman-
tic dependency label. This assumption removes
the need to condition the component index con
the semantic label rin the variational approxima-
tionq. In this implementation, we encode hop
patterns with orthogonally initialized embeddings
and estimate the mixture weight of a hop pattern
by applying a multi-layer perceptron followed by a
softmax layer to the embedding.
Equation 16 depicts the full objective of the pro-posed model. It consists of a log-likelihood objec-
tive of the syntactic parser (Equation 17) and the
ELBo objective of the semantic parser (Equation
15).Gstands for the set of all syntactic depen-
dencies (h, d), whereas Gstands for the set of
all semantic dependencies (r, p, a ).
5 Experiment
In this section, we present experimental results for
the proposed method. We call the proposed method
as MM (mixture-model) in this section. We use the
labeled attachment score (LAS) (Haji ˇc et al., 2009)
as the primary metric. LAS is a micro-F1 score
measuring how well a model recovers semantic
dependencies. We conduct our experiments com-
paring MM with five baseline methods (Table 1)
using the CoNLL-2009 dataset. We perform the
comparison on all languages using the correspond-
ing development sets. Each model will run using
four randomly generated seeds to mitigate the im-
pact of the seeds. We also compare the semantic
scores (Haji ˇc et al., 2009) of MM with state-of-the-
art syntax-aware methods using the English test set.
The semantic score is a micro-F1 score evaluating
models’ performance in the predicate identification
in addition to the semantic dependency recovery.
We use preidentified predicates extracted from the
mate-tools (Björkelund et al., 2010), following the
evaluation method of Roth and Lapata (2016).
We evaluate MM using three word embed-
dings: a non-context-sensitive embedding, Fast-
Text (Joulin et al., 2016), and two context-sensitive
embeddings, ELMo (Peters et al., 2018) and BERT
(Devlin et al., 2019). When comparing with state-
of-the-art methods, we report results on the GloVe
(Pennington et al., 2014) and the FastText embed-
ding. However, the result on the FastText embed-
ding is for reference only because the state-of-the-
art methods report results mainly on the GloVe
embedding. We use an 8-layer Transformer as the
backbone encoder for MM and baseline models.
We set the batch size to 5000 words, the maximum
size that a P100 device can accommodate. We use
the Adam optimizer (Kingma and Ba, 2015) with7963
parameters lr= 4e,β= 0.9, and β= 0.98
for training.
We set the number of component distributions
kin MM to 5 for all languages. We find that this
number works for most languages in a preliminary
experiment exploring k= 1,3,5,7,10. Fork >5,
some components will not be assigned to any hop
pattern, resulting in a waste of model parameters.
Fork <5, some components are forced to estimate
semantic label distributions for hop patterns of dif-
ferent nature, resulting in a loss of performance.
We do not perform back-propagation between the
syntactic and the semantic parser in MM because
we found the back-propagation causes negative im-
pacts on the two parsers.
5.1 Comparison with Baselines
We find that MM significantly improves over base-
line methods on the English development set. Fig-ure 4 reports the LAS of MM and baseline methods
using box plots. MM achieves better LAS than
baseline methods in all three embeddings. We con-
duct a series of significance tests against a null
hypothesis that MM performs equally to each base-
line method. The p-values of the hypothesis tests
are shown in Table 2. Each cell in the table shows
the p-value of a test comparing MM with a base-
line method (shown in the row) on an embedding
(shown in the column). The table suggests that
MM significantly outperforms all baseline methods
on the three embeddings, except the PathLSTM
method on the FastText embedding. The signif-
icance test confirms the effectiveness of MM in
modeling semantic dependencies.
We find that MM learns a mixture weight reflect-
ing the impact of hop patterns on semantic label
distributions. Table 3 reports the component assign-
ment extracted from the learned mixture weight.
We extract the component assignment for hop pat-
terns up to (5, 3). Most evidently, MM consistently
assigns the hop pattern (0, 1) to a unique compo-
nent in all three embeddings. This behavior agrees
with our findings in Section 2 that the hop pattern
has the highest mutual information gain. MM also
consistently assigns hop patterns with near-zero
mutual information gains to a single component.
Moreover, MM clusters hop patterns with similar
non-zero gains to a single component. These re-
sults suggest that semantic label distributions of
different hop patterns have unique properties.7964
MM is readily applicable for other languages
beyond English using the same hyperparameter
setting. Figure 5 reports the comparison of MM
with the Transformer and the Multitask method on
the development sets of German, Spanish, Catalan,
Chinese, and Czech. The Multitask method con-
sistently outperforms the Transformer method in
all languages. In comparison, MM significantly
outperforms the Multitask method in German and
Spanish. MM also has an arguable improvement
over the Multitask method in Catalan. In Chinese,
MM performs similarly to the Multitask method
but better than the Transformer method. In Czech,
MM somehow fails to learn and achieves a con-
siderably low LAS. We might need to tune the
architecture or hyperparameters here, while MM
stably outperforms the baseline methods in other
languages.
Using the Transformer method as a baseline,
we find MM improves on both short and long
distance semantic dependencies, whereas syntax-
aware baseline methods improve only on long dis-
tance dependencies. To illustrate the finding, we
group the semantic dependencies by their linear
lengthand evaluate the methods’ performance on
each group. We group the semantic dependencies
into four bins: the short-distance bin (0-2) and
the long-distance bins (3-5, 6-8, 9-inf). We then
compute the relative performance scoreof each
syntax-aware method using the model with the me-
dian LAS score. Figure 6 reports the relative scores
of LAS, Precision, and Recall. MM has the best rel-
ative LAS among syntax-aware methods in predict-7965
ing short distance dependencies. On the FastText
and the ELMo embedding, MM is the only method
scoring a positive relative LAS (i.e., MM is the only
method improving over the Transformer method).
The reason is that MM achieves significantly bet-
ter precision than baseline syntax-aware methods,
which allows MM to overcome the lower recall.
Meanwhile, MM has a performance improvement
similar to the baseline syntax-aware methods in
predicting long distance dependencies.
5.2 Comparison with the State-of-the-arts
MM achieves competitive performance with state-
of-the-art syntax-aware methods. Table 4 reports
the median semantic scores of MM and the reported
scores of state-of-the-art methods on the English
test set. The test set contains two sections: WSJ
(in-domain) section and Brown (out-of-domain)
section. MM achieves the best performance on the
WSJ section on the GloVe and the ELMo embed-
ding and performs comparably to other methods
on the BERT embedding. MM also scores the best
performance on the Brown section on the ELMoand the BERT embedding. We also find that MM
on the FastText embedding performs better than
MM on the GloVe embedding. This result is in line
with a study evaluating non-context-sensitive word
embeddings (Wang et al., 2019) where the FastText
embedding outperforms the GloVe embedding on
downstream NLP tasks.
6 Conclusion
This paper presented a mixture model-based
method for syntax-aware semantic dependency
parsing in SRL. The method models the depen-
dence of semantic label distributions on SSDP
patterns. We focused on SSDP hop patterns be-
cause we observed a drastic variation in semantic
label distributions through the change in mutual
information. The proposed method successfully
learned a mixture weight reflecting the variation.
The method improved performance in predicting
both short and long distance semantic dependen-
cies, whereas baseline syntax-aware methods im-
proved only on long distance dependencies. The
method outperformed baseline methods by a small7966but statistically significant margin in many lan-
guages. Moreover, the proposed method achieved
performance competitive with state-of-the-art meth-
ods in English. Nonetheless, hop patterns contain
only limited information about SSDP. In the future,
we plan to apply the proposed method to more in-
formative SSDP patterns, such as labeled SSDP
patterns.
7 Acknowledgement
This research was supported by JST, CREST Grant
Number JPMJCR2114, Japan.
References796779687969