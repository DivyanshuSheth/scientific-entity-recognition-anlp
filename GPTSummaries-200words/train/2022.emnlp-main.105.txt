Summary:

The research paper investigates the use of unlabeled data in improving instruction learning for zero-shot cross-task generalization. The proposed method, Unlabeled Data Augmented Instruction Tuning (UDIT), constructs pseudo-labeled data from unlabeled plain texts and incorporates them into instruction tuning. The experiments demonstrate that UDIT outperforms other methods in various scenarios with or without labeled data. The results show that PLMs can learn to follow human-written instructions even with few or no annotated samples. UDIT also improves the performance of instruction tuning in both text classification and language generation tasks. The findings highlight the importance of instruction semantics, task diversity, and domain diversity in zero-shot cross-task generalization. The paper provides insights into using unlabeled data to enhance instruction learning and suggests future directions for further research.