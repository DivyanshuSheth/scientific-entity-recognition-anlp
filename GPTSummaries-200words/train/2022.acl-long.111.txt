Summary:

This research paper proposes a framework called Few-Shot Transformer based Enrichment (FeSTE) for enriching tabular datasets using unstructured data. FeSTE utilizes a pretrained language model (LM) and a novel fine-tuning approach to generate high-quality features. The paper evaluates FeSTE on 17 datasets and compares it to two baseline methods: target dataset fine-tuning and MT-DNN fine-tuning. The evaluation metrics used include AUC and F-score. FeSTE outperforms the baselines in terms of AUC, achieving an average improvement of 9.2% when combined with the datasets' original features. The proposed approach shows promising results even when applied to datasets with limited size, and it demonstrates generalization capabilities by leveraging knowledge from multiple datasets. Additional experiments using a different entity linking approach also validate the effectiveness of FeSTE.