Summary:
The paper proposes quality-aware decoding for neural machine translation (NMT) to improve translation quality. It combines recent advancements in reference-free and reference-based evaluation metrics with NMT decoding. The authors experiment with various candidate generation and ranking methods and evaluate their performance on four datasets using metrics such as BLEU, COMET, and BLEURT. They find that quality-aware decoding consistently outperforms MAP-based decoding according to both automatic metrics and human assessments. The authors compare N-best reranking and minimum Bayes risk (MBR) decoding and explore a two-stage ranking approach that combines both methods. The experiments show that N-best reranking performs better than MBR decoding, and the two-stage approach provides the best results according to fine-tuned metrics. The paper also highlights the importance of using powerful evaluation metrics and their potential impact on translation quality.