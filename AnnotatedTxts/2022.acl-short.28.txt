  Bohan Zhang   University of Michigan   zbohan@umich.eduPrafulla Kumar Choubey   Salesforce Research   pchoubey@salesforce.comRuihong Huang   Texas A&M University   huangrh@tamu.edu   Abstract   Document - level text simplification often   deletes some sentences besides performing   lexical , grammatical or structural simpli-   fication to reduce text complexity . In this   work , we focus on sentence deletions for text   simplification and use a news genre - specific   functional discourse structure , which cate-   gorizes sentences based on their contents   and their function roles in telling a news   story , for predicting sentence deletion . We   incorporate sentence categories into a neural   net model in two ways for predicting sentence   deletions , either as additional features or   by jointly predicting sentence deletions and   sentence categories . Experimental results using   human - annotated data show that incorporating   the functional structure improves the recall   of sentence deletion prediction by 6.5 % and   10.7 % respectively using the two methods , and   improves the overall F1 - score by 3.6 % and   4.3 % respectively .   1 Introduction   Text simplification aims to rewrite complex texts in   order to make them easier to read and understand .   This task can benefit vast low literacy readers , in-   cluding children , language learners and people with   aphasia , and has recently attracted increasing at-   tention from the research community ( Xu et al . ,   2016 ; Zhao et al . , 2018 ; Martin et al . , 2019 ; Dong   et al . , 2019 ) . However , most previous research has   focused on sentence - level text simplification and   aim to simplify one sentence at a time . As a result ,   few discourse - level phenomena have been exam-   ined or understood for achieving document - level   text simplification .   Sentence deletion is a commonly used strategy   to achieve intense simplification ( Drndarevic and   Saggion , 2012 ; Woodsend and Lapata , 2011 ) , i.e. ,   some less important sentences from an originalarticle are simply deleted and ignored for simplifi-   cation . While professional re - writers may consider   many factors and use several measures of impor-   tance to decide if a sentence should be deleted ,   some discourse structures provide automated mea-   sures to derive importance for sentences in a doc-   ument . In particular , functional discourse struc-   tures categorize text units ( sentences or paragraphs )   based on their contents and their function roles in   serving the purpose of a specific text - genre , such   as scientific papers ( Teufel et al . , 1999 ; Liakata   et al . , 2012 ) and news articles ( Yarlott et al . , 2018 ;   Choubey et al . , 2020 ) , and are therefore , expected   to directly reveal the importance of a sentence   within a document .   In this work , we explore the use of news genre-   specific functional structures for predicting sen-   tence deletions in news documents . Specifically ,   we use news discourse profiling structure , which   categorizes contents of news articles around the   main news event , constructed through a publicly   available system ( Choubey et al . , 2020 ) . This sys-   tem labels each sentence with one of eight content   types reflecting common discourse roles of a sen-   tence in telling a news story , including two content   types for sentences describing the main news event   and its immediate consequences ( main content ) ,   two content types for sentences providing context-   informing contents and four content types for sen-   tences providing further supportive information in   a news article .   We perform experiments using the Newsela cor-   pus ( Xu et al . , 2015 ) , a widely used dataset for   text simplification research that contains 1492 En-   glish news articles and four simplified versions   for each news article targeting audience of differ-   ent reading levels ( from elementary to high school   students ) . Since we aim to achieve maximal sim-   plification , we predict sentence deletions for tar-255get reading level corresponding to the elementary   school students . We first build a document - level   neural network as the basic model for predicting   sentence deletions . We then incorporate content   types of sentences into the prediction system using   two methods , 1 ) by using content type labels as ad-   ditional features to enrich sentence representations ,   and 2 ) by jointly predicting both sentence deletion   labels and discourse content type labels . Experi-   mental results show that , with little to no drop on   precision , both methods for incorporating sentence   content type information improve the recall ( F1   score ) on the sentence deletion prediction task by   6.5 % ( 3.6 % ) and 10.7 % ( 4.3 % ) respectively . Anal-   ysis on the development set shows that the addi-   tional deletions correctly recognized by our system   are all sentences providing context - informing or   supportive contents .   2 Related Work   The previous research on text simplification has   focused on word or phrase level simplification   ( Yatskar et al . , 2010 ; Biran et al . , 2011 ; Specia et al . ,   2012 ; Paetzold and Specia , 2017 ) , or sentence-   level simplification ( Wubben et al . , 2012 ; Sutskever   et al . , 2014 ; Nisioi et al . , 2017 ; Zhao et al . , 2018 ;   Dong et al . , 2019 ) , few research has been con-   ducted for document - level text simplification .   Sentence deletion , as an interesting phenomenon   for document - level text simplification , has been   studied in several pilot studies . ( Petersen and Os-   tendorf , 2007 ) conducted a corpus analysis and   showed that sentence position and content influ-   ence sentence deletion or retention . The recent pi-   lot research for sentence deletion prediction ( Zhong   et al . , 2019 ) considers sentence position in a doc-   ument , document length and topic , as well as ex-   ploits rhetorical discourse structures that capture   text coherence in general and can be used to derive   thesalience of a sentence in a discourse . However ,   while sentence position and the two document char-   acteristics are shown useful for sentence deletion   prediction , discourse features based on rhetorical   discourse structures are shown to have little im-   pact for this task . Compared to general rhetorical   discourse structures that do not consider genre spe-   cialties , the genre - specific functional structure we   examine in this paper can more directly reveal the   importance of a sentence within a document.3 The News Discourse Structure and   Sentence Types   News discourse profiling ( Choubey et al . , 2020 )   categorizes sentences in news articles into eight   schematic categories that describe the common dis-   course roles of sentences in telling a news story ,   following the news content schemata proposed by   Van Dijk ( Teun A , 1986 ; Van Dijk , 1988a , b ) . These   eight sentence categories fall into three groups .   Main Contents : are the most relevant informa-   tion of news articles , including sentences that intro-   duce the main event as the major subjects of a news   article ( Main Event ) , and sentences that describe   consequence events immediately triggered by the   main event ( Consequence ) .   Context Informing Contents : provide infor-   mation of the actual situation in which main event   occurred , including sentences that describe the re-   cent events that act as possible causes or precon-   ditions for the main event ( Previous Events ) , and   sentences that describe ongoing situation and other   context informing contents ( Current Context ) .   Additional Supportive Contents : contain the   least relevant information , including sentences that   describe past events that precede the main events   in months and years ( Historical Event ) , sentences   that describe unverifiable situations , fictional or   personal account of incidents of an unknown per-   son ( Anecdotal Event ) , opinionated contents that   describe reactions from immediate participants , ex-   perts , known personalities as well as journalist or   news source ( Evaluation ) , and speculations on the   possible consequences of the main or contextual   events ( Expectation )   3.1 Analysis of Deletions w.r.t Sentence Types   We conducted an analysis on deletion rate for each   sentence category using the development set ( Sec-   tion 5.1 ) which was manually annotated with sen-   tence deletion labels . The discourse content type   labels of sentences were predicted by the news   discourse profiling system ( Choubey et al . , 2020 ) .   Table 1 shows the results . We can see that Main   Event sentences have the lowest deletion rate of   14.7 % , much lower than other types of sentences .   Previous Event sentences , as one type of context   informing contents , have a relatively low deletion   rate as well to provide necessary context , i.e. , pos-   sible causes or preconditions , to understand the   main news events . While additional supportive con-   tents overall have a high deletion rate , Anecdotal256   Event sentences have a low deletion rate , possibly   because personal account of incidents present espe-   cially interesting contents for elementary students ,   the target group of our chosen simplification level .   Figure 1 shows an example document where   both deleted sentences ( colored in purple ) are of   one additional supportive content type , Historical   Event .   4 ModelsAs a baseline model , ( shown in Figure 2 ) , we   built a document - level neural network model to   learn context aware sentence representations for   predicting sentence deletions . Similar architectures   have been shown useful for several other discourse-   level tasks ( Nallapati et al . , 2016 ; Choubey et al . ,   2020 ) .   Specifically , the model takes a document as in-   put and has two document - level BiLSTM layers   ( Hochreiter and Schmidhuber , 1997 ) stacked up   with a self - attention layer between them , to suffi-   ciently exploit document wide contexts for building   sentence representations . In addition , for each sen-   tence , we further concatenate its sentence represen-   tation with two vectors obtained by max pooling   over representations of its surrounding sentences   ( two sentences to each side ) , to obtain the final   sentence representation R , that is better aware of   the local context . We use a feed forward neural   network with 1024 - 2 units to predict a binary label   ( deleted or not ) for each sentencebased on its fi-   nal sentence representation . We apply base BERT   ( Devlin et al . , 2019 ) to obtain the initial sentence   representations of 768 dimensions . Both BiLSTMs257   have the hidden dimension size of 512 .   Next , we present two methods to utilize the func-   tional structure for sentence deletion prediction .   4.1 Feature Concatenation   For each sentence , we create a feature vector F   with eight dimensions corresponding to the eight   discourse content types , and values in the vec-   tor are probabilities of content types for the target   sentence as output by the news discourse profil-   ing system . We concatenate the feature vector F   with the final sentence representation Rand feed   the concatenated vector to the sentence deletion   prediction layer .   4.2 Joint Learning   Instead of creating features , we learn to jointly   predict both sentence deletion labels and discourse   content type labels ( system predicted ) using shared   sentence representations ( Figure 3 ) . Specifically ,   we add a new prediction layer with 1024 - 9units   to predict discourse content types for sentences ,   and learn to jointly predict both types of labels   by minimizing the aggregated loss of two tasks :   L = L+γ∗L , where Lis the cross - entropy   loss for the sentence deletion prediction task and L   is the mean squared loss for the discourse content   type prediction task.5 Evaluation   5.1 Dataset   We conduct experiments using the Newsela corpus   for text simplification ( Xu et al . , 2015 ) . This corpus   contains 1492 English news articles and four sim-   plified versions for each article targeting students   ranging from grade 2 to grade 12 . In our study , we   focus on predicting sentence deletions to achieve   the relatively aggressive level of simplification that   targets elementary school students ( grades 2 to 5 ) .   Test and Development Data : We created a new   annotated dataset . The annotated dataset of 50   documents used in Zhong et al . ( 2019 ) was not   released yet when we started to work on this project .   Our code and the method to obtain our annotated   dataset can be found on github .   Different from the crowd - sourcing based annota-   tion method of Zhong et al . ( 2019 ) that decomposes   the document - level sentence alignment task to a   paragraph alignment task followed by a paragraph-   level sentence alignment task , we ask our two an-   notators to read through a whole news article and   its simplified article before annotating alignment   sentence by sentence , which enables thorough an-   notations . Then , for each sentence in an original   article , we instruct our annotators to align it with   all the sentences in the simplified article that con-   tain part or all of its contents ( or paraphrases ) , one   sentence in an original article will be labeled as   “ deleted ” if nosentence in its simplified article is   aligned with this sentence .   We annotated 95 ( containing 4,334 sentences )   randomly selected news articles . The two anno-   tators first annotated five news articles ( 228 sen-   tences ) in common and achieved a high kappa   agreement ( Artstein and Poesio , 2008 ) of 0.911 .   Then , each of them annotated 45 more articles . We   randomly selected 25 annotated articles and use   them as the development set , and use the other 70   articles as the test set . 48 % and 38 % of sentences   are annotated as deleted in the test and development   sets respectively . We will publish our annotations .   Training Data : We create noisy supervision to   train the systems by applying an automatic sen-   tence alignment tool CATS(Štajner et al . , 2018 )   to the remaining 1397 unlabeled news articles and   quickly obtained alignments between these news258   articles and their simplified articles . 82.11 % of   sentence alignments produced by CATS are correct   when evaluated on our development set .   5.2 Experimental Settings   For regularization , we use dropout of 0.5 on the out-   put of both BiLSTMs and the self - attention layer .   We apply Adam optimizer ( Kingma and Ba , 2014 )   for training , and the learning rate is set to 3e-4 . All   the neural models are trained for 15 epochs and we   use the epoch yielding the best validation perfor-   mance . We searched the hyper - parameter γvalue   over the range [ 0 , 3 ] with a step size of 0.5 , and its   best value equals to 1.5 .   5.3 Results and Analysis   In Table 3 , we report the performance of our base-   line and the two news discourse profiling structure-   aware models . For better positioning of our work ,   we also re - implemented the model proposed in a   recent work by Zhong et al . ( 2019 ) , a feedforwardneural network ( FNN ) model with sparse features .   First , our baseline system performs better than the   feature based FNN model with 5.3 % and 5.0 %   higher F1 score on validation and test datasets re-   spectively . Then , both methods for incorporating   discourse information have noticeably improved   the performance on sentence deletion prediction .   We also evaluate the models on the dataset from   Zhong et al . ( 2019 ) . As shown in Table 4 , similar   trends were observed on this dataset as well .   Since the performance gains of both discourse-   aware models are mainly on recall , we analyze   the distribution of additional deleted sentences cor-   rectly predicted by the two models . As shown in   Table 2 , the additional deleted sentences are either   context informing contents or additional supportive   contents , but none is main content . This observa-   tion corroborates our analysis in section 3.1 .   6 Conclusion   We study sentence deletion prediction to achieve   document - level text simplification . We have   showed that a genre - specific functional discourse   structure improves the prediction performance by   large margins , when incorporated into a neural net   model either as new features or for joint learn-   ing . For future work , we will study other useful   discourse - level factors for sentence deletion predic-   tion , we will also investigate multi - task learning   to benefit both sentence deletion prediction and   discourse parsing tasks .   7 Acknowledgements   We gratefully acknowledge support from National   Science Foundation via the awards IIS-1942918 .   We would also like to thank the anonymous review-   ers for their feedback.259References260261