-DOCSTART- -X- O
2023.acl-short.69.txt -X- _ O
Seyed -X- _ O
Morteza -X- _ O
Mirbostani -X- _ O
, -X- _ O
Yasaman -X- _ O
Boreshban -X- _ O
Dpt -X- _ O
. -X- _ O
of -X- _ O
Computer -X- _ O
Engineering -X- _ O
, -X- _ O
University -X- _ O
of -X- _ O
Guilan -X- _ O
, -X- _ O
Rasht -X- _ O
, -X- _ O
Iran -X- _ O
{ -X- _ O
m.mirbostani -X- _ O
, -X- _ O
boreshban -X- _ O
} -X- _ O
@ -X- _ O
msc.guilan.ac.ir -X- _ O
Salam -X- _ O
Khalifa -X- _ O
, -X- _ O
Seyed -X- _ O
Abolghasem -X- _ O
Mirroshandel -X- _ O
, -X- _ O
and -X- _ O
Owen -X- _ O
Rambow -X- _ O
Dpt -X- _ O
. -X- _ O
of -X- _ O
Linguistics -X- _ O
and -X- _ O
Institute -X- _ O
for -X- _ O
Advanced -X- _ O
Computational -X- _ O
Science -X- _ O
( -X- _ O
IACS -X- _ O
) -X- _ O
Stony -X- _ O
Brook -X- _ O
University -X- _ O
, -X- _ O
Stony -X- _ O
Brook -X- _ O
, -X- _ O
USA -X- _ O
{ -X- _ O
first.last -X- _ O
} -X- _ O
@ -X- _ O
stonybrook.edu -X- _ O
Abstract -X- _ O
Building -X- _ O
a -X- _ O
system -X- _ O
for -X- _ O
morphological -X- _ B-TaskName
processing -X- _ I-TaskName
is -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
in -X- _ O
morphologically -X- _ O
complex -X- _ O
languages -X- _ O
like -X- _ O
Arabic -X- _ O
. -X- _ O
Although -X- _ O
there -X- _ O
are -X- _ O
some -X- _ O
deep -X- _ O
learning -X- _ O
based -X- _ O
models -X- _ O
that -X- _ O
achieve -X- _ O
successful -X- _ O
results -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
annotated -X- _ O
data -X- _ O
. -X- _ O
Building -X- _ O
such -X- _ O
datasets -X- _ O
, -X- _ O
specially -X- _ O
for -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
lower -X- _ O
- -X- _ O
resource -X- _ O
Arabic -X- _ O
dialects -X- _ O
, -X- _ O
is -X- _ O
very -X- _ O
difficult -X- _ O
, -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
, -X- _ O
and -X- _ O
expensive -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
some -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
annotated -X- _ O
data -X- _ O
do -X- _ O
not -X- _ O
contain -X- _ O
useful -X- _ O
information -X- _ O
for -X- _ O
training -X- _ O
machine -X- _ O
learning -X- _ O
models -X- _ O
. -X- _ O
Active -X- _ O
learning -X- _ O
strategies -X- _ O
allow -X- _ O
the -X- _ O
learner -X- _ O
algorithm -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
informative -X- _ O
samples -X- _ O
for -X- _ O
annotation -X- _ O
. -X- _ O
There -X- _ O
has -X- _ O
been -X- _ O
little -X- _ O
research -X- _ O
that -X- _ O
focuses -X- _ O
on -X- _ O
applying -X- _ O
active -X- _ O
learning -X- _ O
for -X- _ O
morphological -X- _ B-TaskName
inflection -X- _ I-TaskName
and -X- _ O
morphophonological -X- _ B-TaskName
processing -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
deep -X- _ B-MethodName
active -X- _ I-MethodName
learning -X- _ I-MethodName
method -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
on -X- _ O
Egyptian -X- _ O
Arabic -X- _ O
show -X- _ O
that -X- _ O
with -X- _ O
only -X- _ O
about -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
annotated -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
the -X- _ O
same -X- _ O
results -X- _ O
as -X- _ O
does -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
whole -X- _ O
dataset -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Recently -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
lots -X- _ O
of -X- _ O
interest -X- _ O
in -X- _ O
morphological -X- _ B-TaskName
( -X- _ I-TaskName
re- -X- _ I-TaskName
) -X- _ I-TaskName
inflection -X- _ I-TaskName
processing -X- _ I-TaskName
( -X- _ O
Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Kirov -X- _ O
and -X- _ O
Cotterell -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Belth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Having -X- _ O
an -X- _ O
acceptable -X- _ O
model -X- _ O
for -X- _ O
morphological -X- _ B-TaskName
processing -X- _ I-TaskName
will -X- _ O
help -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
tasks -X- _ O
like -X- _ O
speech -X- _ O
synthesis -X- _ O
( -X- _ O
Halabi -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
morphological -X- _ O
disambiguation -X- _ O
( -X- _ O
Khalifa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Inoue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
Sennrich -X- _ O
and -X- _ O
Haddow -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Erdmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Alhafni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
recent -X- _ O
progress -X- _ O
in -X- _ O
this -X- _ O
field -X- _ O
of -X- _ O
study -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
lots -X- _ O
of -X- _ O
challenges -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O
Especially -X- _ O
for -X- _ O
utilizing -X- _ O
successful -X- _ O
but -X- _ O
data -X- _ O
- -X- _ O
hungry -X- _ O
deep -X- _ O
learning -X- _ O
( -X- _ O
DL -X- _ O
) -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
annotated -X- _ O
data -X- _ O
is -X- _ O
vital -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
data -X- _ O
annotation -X- _ O
is -X- _ O
a -X- _ O
hard -X- _ O
, -X- _ O
expensive -X- _ O
, -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
task -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
lots -X- _ O
of -X- _ O
annotated -X- _ O
data -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
useful -X- _ O
information -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
learning -X- _ O
algorithm -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
deep -X- _ B-MethodName
active -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ O
DAL -X- _ B-MethodName
) -X- _ O
algorithm -X- _ O
for -X- _ O
morphophonological -X- _ B-TaskName
processing -X- _ I-TaskName
that -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
decrease -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
annotated -X- _ O
data -X- _ O
, -X- _ O
by -X- _ O
using -X- _ O
only -X- _ O
informative -X- _ O
samples -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
chosen -X- _ O
Arabic -X- _ O
, -X- _ O
a -X- _ O
morphologically -X- _ O
rich -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
lots -X- _ O
of -X- _ O
Arabic -X- _ O
dialects -X- _ O
are -X- _ O
very -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
from -X- _ O
this -X- _ O
study -X- _ O
can -X- _ O
help -X- _ O
in -X- _ O
building -X- _ O
required -X- _ O
datasets -X- _ O
in -X- _ O
a -X- _ O
smarter -X- _ O
way -X- _ O
. -X- _ O
Among -X- _ O
Arabic -X- _ O
dialects -X- _ O
, -X- _ O
Cairene -X- _ O
Egyptian -X- _ O
Arabic -X- _ O
has -X- _ O
been -X- _ O
selected -X- _ O
, -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
well -X- _ O
- -X- _ O
studied -X- _ O
and -X- _ O
has -X- _ O
many -X- _ O
resources -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
appropriate -X- _ O
for -X- _ O
our -X- _ O
DAL -X- _ B-MethodName
simulation -X- _ O
experiments -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
not -X- _ O
specific -X- _ O
to -X- _ O
Arabic -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
on -X- _ O
other -X- _ O
languages -X- _ O
or -X- _ O
dialects -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
chosen -X- _ O
a -X- _ O
very -X- _ O
successful -X- _ O
transformer -X- _ O
model -X- _ O
for -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
transduction -X- _ O
tasks -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
pool -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
DAL -X- _ I-MethodName
method -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
. -X- _ O
To -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
uncertain -X- _ O
( -X- _ O
informative -X- _ O
) -X- _ O
samples -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
an -X- _ O
entropy -X- _ O
strategy -X- _ O
with -X- _ O
a -X- _ O
clustering -X- _ O
method -X- _ O
to -X- _ O
keep -X- _ O
an -X- _ O
acceptable -X- _ O
balance -X- _ O
between -X- _ O
the -X- _ O
uncertainty -X- _ O
and -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
chosen -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
selected -X- _ O
dataset -X- _ O
show -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
DAL -X- _ B-MethodName
method -X- _ O
. -X- _ O
2 -X- _ O
Previous -X- _ O
Work -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
a -X- _ O
brief -X- _ O
review -X- _ O
of -X- _ O
morphological -X- _ B-TaskName
inflection -X- _ I-TaskName
processing -X- _ I-TaskName
methods -X- _ O
. -X- _ O
Some -X- _ O
recent -X- _ O
DAL -X- _ B-MethodName
methods -X- _ O
will -X- _ O
also -X- _ O
be -X- _ O
reviewed -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
several -X- _ O
approaches -X- _ O
for -X- _ O
applying -X- _ O
DL -X- _ O
models -X- _ O
for -X- _ O
the -X- _ O
morphological -X- _ B-TaskName
inflection -X- _ I-TaskName
problem -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Wehrli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Batsuren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Dankers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
achieve -X- _ O
successful -X- _ O
results -X- _ O
on -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
use -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
neural -X- _ O
transducers -X- _ O
using -X- _ O
transformers -X- _ O
, -X- _ O
data -X- _ O
augmentation -X- _ O
, -X- _ O
and -X- _ O
recurrent793neural -X- _ O
network -X- _ O
( -X- _ O
RNN -X- _ O
) -X- _ O
s -X- _ O
. -X- _ O
In -X- _ O
Arabic -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
also -X- _ O
much -X- _ O
non -X- _ O
- -X- _ O
neural -X- _ O
research -X- _ O
on -X- _ O
morphological -X- _ O
modeling -X- _ O
, -X- _ O
including -X- _ O
finite -X- _ O
state -X- _ O
technology -X- _ O
( -X- _ O
Habash -X- _ O
and -X- _ O
Rambow -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
precompiled -X- _ O
tabular -X- _ O
morphological -X- _ O
analyzers -X- _ O
( -X- _ O
Buckwalter -X- _ O
, -X- _ O
2002 -X- _ O
, -X- _ O
2004 -X- _ O
; -X- _ O
Graff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Taji -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
allomorphy -X- _ O
modeling -X- _ O
through -X- _ O
linguistically -X- _ O
descriptive -X- _ O
rules -X- _ O
( -X- _ O
Habash -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
DAL -X- _ B-MethodName
has -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
some -X- _ O
sub -X- _ O
- -X- _ O
fields -X- _ O
of -X- _ O
NLP -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Ru -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
achieved -X- _ O
satisfactory -X- _ O
results -X- _ O
in -X- _ O
text -X- _ O
classification -X- _ O
using -X- _ O
active -X- _ O
learning -X- _ O
( -X- _ O
AL -X- _ O
) -X- _ O
with -X- _ O
convolutional -X- _ O
neural -X- _ O
networks -X- _ O
and -X- _ O
adversarial -X- _ O
uncertainty -X- _ O
sampling -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Different -X- _ O
acquisition -X- _ O
functions -X- _ O
using -X- _ O
the -X- _ O
conditional -X- _ O
random -X- _ O
field -X- _ O
model -X- _ O
have -X- _ O
been -X- _ O
applied -X- _ O
in -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Prabhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
Peris -X- _ O
and -X- _ O
Casacuberta -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
used -X- _ O
an -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
applied -X- _ O
a -X- _ O
reinforcement -X- _ O
learning -X- _ O
method -X- _ O
. -X- _ O
In -X- _ O
another -X- _ O
study -X- _ O
, -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
word -X- _ O
frequency -X- _ O
- -X- _ O
based -X- _ O
acquisition -X- _ O
function -X- _ O
to -X- _ O
train -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
actively -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
Muradoglu -X- _ O
and -X- _ O
Hulden -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
introduced -X- _ O
a -X- _ O
DAL -X- _ O
method -X- _ O
for -X- _ O
lemma -X- _ O
inflection -X- _ O
in -X- _ O
written -X- _ O
modern -X- _ O
standard -X- _ O
Arabic -X- _ O
and -X- _ O
some -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O
Their -X- _ O
method -X- _ O
uses -X- _ O
entropy -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
max -X- _ O
of -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
entropy -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
performs -X- _ O
best -X- _ O
. -X- _ O
3 -X- _ O
Background -X- _ O
and -X- _ O
Problem -X- _ O
Definition -X- _ O
Morphophonology -X- _ O
involves -X- _ O
studying -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
morphology -X- _ O
and -X- _ O
phonology -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
analyze -X- _ O
data -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
discover -X- _ O
the -X- _ O
underlying -X- _ O
forms -X- _ O
and -X- _ O
ordered -X- _ O
rules -X- _ O
that -X- _ O
explain -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
( -X- _ O
Hayes -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
Arabic -X- _ O
morphophonology -X- _ O
is -X- _ O
particularly -X- _ O
interesting -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
complex -X- _ O
templatic -X- _ O
and -X- _ O
concatenative -X- _ O
morphology -X- _ O
. -X- _ O
Changes -X- _ O
in -X- _ O
morphophonology -X- _ O
can -X- _ O
happen -X- _ O
on -X- _ O
the -X- _ O
stem -X- _ O
pattern -X- _ O
and -X- _ O
also -X- _ O
on -X- _ O
word -X- _ O
boundaries -X- _ O
and -X- _ O
stem -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
phonological -X- _ O
alterations -X- _ O
can -X- _ O
be -X- _ O
triggered -X- _ O
by -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
morphemes -X- _ O
in -X- _ O
concatenative -X- _ O
morphology -X- _ O
cases -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
problem -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
morphophonological -X- _ B-TaskName
generation -X- _ I-TaskName
, -X- _ O
in -X- _ O
which -X- _ O
an -X- _ O
underlying -X- _ O
representation -X- _ O
( -X- _ O
UR -X- _ O
) -X- _ O
is -X- _ O
transformed -X- _ O
into -X- _ O
a -X- _ O
surface -X- _ O
form -X- _ O
( -X- _ O
SF -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
investigate -X- _ O
analysis -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
learning -X- _ O
to -X- _ O
transform -X- _ O
a -X- _ O
SF -X- _ O
to -X- _ O
a -X- _ O
UR.UR -X- _ O
SF -X- _ O
SF -X- _ O
Arabic -X- _ O
# -X- _ O
$ -X- _ O
Ayil -X- _ O
= -X- _ O
In -X- _ O
= -X- _ O
uh -X- _ O
# -X- _ O
# -X- _ O
$ -X- _ O
aylInu -X- _ O
# -X- _ O
# -X- _ O
HAfiZ -X- _ O
= -X- _ O
In -X- _ O
= -X- _ O
hA -X- _ O
# -X- _ O
# -X- _ O
HafZinha -X- _ O
# -X- _ O
# -X- _ O
bi -X- _ O
- -X- _ O
ti -X- _ O
- -X- _ O
SAdf -X- _ O
= -X- _ O
U -X- _ O
# -X- _ O
# -X- _ O
bitSadfu -X- _ O
# -X- _ O
TRAIN -X- _ O
All -X- _ O
13,170 -X- _ O
OOV -X- _ O
-DEV -X- _ O
EV -X- _ O
AL -X- _ O
5,180 -X- _ O
6,974 -X- _ O
2,189 -X- _ O
2,271 -X- _ O
4 -X- _ O
Dataset -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Arabic -X- _ B-DatasetName
morphophonology -X- _ I-DatasetName
dataset -X- _ O
created -X- _ O
by -X- _ O
Khalifa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
uses -X- _ O
a -X- _ O
broad -X- _ O
phonemic -X- _ O
transcription -X- _ O
. -X- _ O
They -X- _ O
generated -X- _ O
URs -X- _ O
from -X- _ O
the -X- _ O
CALIMA -X- _ O
morphological -X- _ O
analyzer -X- _ O
( -X- _ O
Habash -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
for -X- _ O
every -X- _ O
SF -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
ECAL -X- _ O
dataset -X- _ O
( -X- _ O
Kilany -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
added -X- _ O
the -X- _ O
analyzer -X- _ O
’s -X- _ O
segmentation -X- _ O
to -X- _ O
the -X- _ O
UR -X- _ O
part -X- _ O
, -X- _ O
delimiting -X- _ O
word -X- _ O
boundaries -X- _ O
with -X- _ O
# -X- _ O
, -X- _ O
prefixes -X- _ O
with -X- _ O
− -X- _ O
, -X- _ O
and -X- _ O
suffixes -X- _ O
with -X- _ O
= -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
contains -X- _ O
pairs -X- _ O
of -X- _ O
( -X- _ O
UR -X- _ O
, -X- _ O
SF -X- _ O
) -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
split -X- _ O
of -X- _ O
this -X- _ O
dataset -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
ECAL -X- _ O
’s -X- _ O
split -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
TRAIN -X- _ O
, -X- _ O
DEV -X- _ O
, -X- _ O
and -X- _ O
EV -X- _ O
AL -X- _ O
subsets -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
ECAL -X- _ O
’s -X- _ O
splits -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
running -X- _ O
texts -X- _ O
, -X- _ O
some -X- _ O
words -X- _ O
can -X- _ O
occur -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
split -X- _ O
. -X- _ O
Therefore -X- _ O
Khalifa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
also -X- _ O
created -X- _ O
subsets -X- _ O
of -X- _ O
the -X- _ O
DEV -X- _ O
and -X- _ O
EV -X- _ O
AL -X- _ O
sets -X- _ O
, -X- _ O
called -X- _ O
DEV -X- _ O
- -X- _ O
OOV -X- _ O
and -X- _ O
EV -X- _ O
AL -X- _ O
- -X- _ O
OOV -X- _ O
, -X- _ O
which -X- _ O
only -X- _ O
contain -X- _ O
non -X- _ O
- -X- _ O
overlapping -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
TRAIN -X- _ O
split -X- _ O
. -X- _ O
The -X- _ O
sizes -X- _ O
of -X- _ O
these -X- _ O
splits -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
5 -X- _ O
Proposed -X- _ O
Method -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
a -X- _ O
brief -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
baseline -X- _ O
network -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
DAL -X- _ B-MethodName
method -X- _ O
will -X- _ O
be -X- _ O
explained -X- _ O
in -X- _ O
more -X- _ O
detail -X- _ O
. -X- _ O
5.1 -X- _ O
Baseline -X- _ O
Network -X- _ O
We -X- _ O
have -X- _ O
done -X- _ O
several -X- _ O
experiments -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
most -X- _ O
successful -X- _ O
model -X- _ O
for -X- _ O
our -X- _ O
AL -X- _ O
experiments -X- _ O
. -X- _ O
Among -X- _ O
different -X- _ O
existing -X- _ O
successful -X- _ O
approaches -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
( -X- _ O
Wehrli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
’s -X- _ O
system -X- _ O
as -X- _ O
our -X- _ O
baseline -X- _ O
system -X- _ O
for -X- _ O
conducting -X- _ O
the -X- _ O
DAL -X- _ B-MethodName
experiments -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
successful -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
utilized -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
that -X- _ O
outperformed -X- _ O
existing -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
RNN -X- _ O
for -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
transduction -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as794morphological -X- _ B-MethodName
inflection -X- _ I-MethodName
generation -X- _ I-MethodName
, -X- _ O
and -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
in -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
transduction -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
dataset -X- _ O
sizes -X- _ O
are -X- _ O
significantly -X- _ O
smaller -X- _ O
than -X- _ O
other -X- _ O
tasks -X- _ O
like -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
smaller -X- _ O
transformer -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
next -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
describe -X- _ O
our -X- _ O
proposed -X- _ O
algorithm -X- _ O
. -X- _ O
5.2 -X- _ O
Active -X- _ O
Learning -X- _ O
Method -X- _ O
In -X- _ O
this -X- _ O
research -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
used -X- _ O
the -X- _ O
pool -X- _ O
- -X- _ O
based -X- _ O
AL -X- _ O
method -X- _ O
in -X- _ O
combination -X- _ O
with -X- _ O
the -X- _ O
entropy -X- _ O
strategy -X- _ O
and -X- _ O
clustering -X- _ O
to -X- _ O
determine -X- _ O
uncertain -X- _ O
samples -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
prediction -X- _ O
preserving -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
chosen -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
AL -X- _ B-MethodName
method -X- _ O
considers -X- _ O
all -X- _ O
the -X- _ O
available -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
pool -X- _ O
, -X- _ O
U -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
13,170samples -X- _ O
, -X- _ O
unannotated -X- _ O
. -X- _ O
Initially -X- _ O
, -X- _ O
about -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
samples -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
1,400 -X- _ O
samples -X- _ O
) -X- _ O
are -X- _ O
chosen -X- _ O
randomly -X- _ O
from -X- _ O
Ufor -X- _ O
the -X- _ O
data -X- _ O
annotation -X- _ O
process -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
cycle -X- _ O
of -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
500samples -X- _ O
from -X- _ O
these -X- _ O
1,400annotated -X- _ O
samples -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
tuning -X- _ O
, -X- _ O
T -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
labeled -X- _ O
samples -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
900samples -X- _ O
) -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
L. -X- _ O
The -X- _ O
tune -X- _ O
dataset -X- _ O
is -X- _ O
fixed -X- _ O
throughout -X- _ O
the -X- _ O
procedure -X- _ O
and -X- _ O
determines -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
accuracy -X- _ O
during -X- _ O
each -X- _ O
AL -X- _ O
training -X- _ O
cycle -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
L -X- _ O
, -X- _ O
is -X- _ O
increased -X- _ O
by -X- _ O
δsamples -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
250samples -X- _ O
) -X- _ O
per -X- _ O
training -X- _ O
cycle -X- _ O
. -X- _ O
After -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Ldataset -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
pool -X- _ O
samples -X- _ O
are -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
UR -X- _ O
, -X- _ O
the -X- _ O
probability -X- _ O
values -X- _ O
are -X- _ O
determined -X- _ O
by -X- _ O
computing -X- _ O
the -X- _ O
softmax -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
output -X- _ O
logits -X- _ O
. -X- _ O
Most -X- _ O
data -X- _ O
sampling -X- _ O
strategies -X- _ O
in -X- _ O
the -X- _ O
AL -X- _ B-MethodName
method -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
some -X- _ O
uncertainty -X- _ O
criteria -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
focusing -X- _ O
on -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
sampling -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
entropy -X- _ O
criteria -X- _ O
is -X- _ O
a -X- _ O
suitable -X- _ O
choice -X- _ O
for -X- _ O
uncertainty -X- _ O
detection -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
logits -X- _ O
for -X- _ O
each -X- _ O
character -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
SF -X- _ O
word -X- _ O
, -X- _ O
w -X- _ O
, -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
elements -X- _ O
of -X- _ O
a -X- _ O
character -X- _ O
vocabulary -X- _ O
generated -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
predicted -X- _ O
SF -X- _ O
words -X- _ O
. -X- _ O
Using -X- _ O
Equation -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
each -X- _ O
set -X- _ O
of -X- _ O
logits -X- _ O
, -X- _ O
ch -X- _ O
, -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
probability -X- _ O
vector -X- _ O
of -X- _ O
a -X- _ O
character -X- _ O
in -X- _ O
w. -X- _ O
Here -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
ielement -X- _ O
in -X- _ O
the -X- _ O
probability -X- _ O
vector -X- _ O
, -X- _ O
chis -X- _ O
the -X- _ O
logit -X- _ O
of -X- _ O
the -X- _ O
ielement -X- _ O
, -X- _ O
and -X- _ O
Nis -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
. -X- _ O
P -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
/ -X- _ O
summationtexte -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
entropy -X- _ O
of -X- _ O
a -X- _ O
character -X- _ O
ch -X- _ O
, -X- _ O
E -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
calculated -X- _ O
by -X- _ O
Equation -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
probability -X- _ O
values -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
generated -X- _ O
characters -X- _ O
vocabulary -X- _ O
. -X- _ O
E -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
/ -X- _ O
summationdisplayP -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
logP -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Equation -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
determines -X- _ O
the -X- _ O
entropy -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
wby -X- _ O
choosing -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
among -X- _ O
all -X- _ O
its -X- _ O
characters -X- _ O
’ -X- _ O
entropy -X- _ O
values -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
predicted -X- _ O
labels -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
confidence -X- _ O
have -X- _ O
the -X- _ O
highest -X- _ O
entropy -X- _ O
. -X- _ O
E -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
= -X- _ O
maxE -X- _ O
( -X- _ O
ch -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
In -X- _ O
each -X- _ O
AL -X- _ O
cycle -X- _ O
, -X- _ O
the -X- _ O
trained -X- _ O
model -X- _ O
selects -X- _ O
the -X- _ O
next -X- _ O
cycle -X- _ O
’s -X- _ O
additional -X- _ O
( -X- _ O
informative -X- _ O
) -X- _ O
samples -X- _ O
. -X- _ O
δ -X- _ O
number -X- _ O
of -X- _ O
UR -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
wentropy -X- _ O
are -X- _ O
sampled -X- _ O
without -X- _ O
replacement -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
Equation -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
these -X- _ O
most -X- _ O
informative -X- _ O
samples -X- _ O
, -X- _ O
w -X- _ O
, -X- _ O
are -X- _ O
annotated -X- _ O
and -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
current -X- _ O
L -X- _ O
dataset -X- _ O
to -X- _ O
be -X- _ O
utilized -X- _ O
by -X- _ O
the -X- _ O
baseline -X- _ O
system -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
AL -X- _ O
cycle -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
w -X- _ O
= -X- _ O
argmaxE -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
We -X- _ O
augment -X- _ O
this -X- _ O
approach -X- _ O
with -X- _ O
a -X- _ O
clustering -X- _ O
technique -X- _ O
to -X- _ O
maintain -X- _ O
diversity -X- _ O
during -X- _ O
the -X- _ O
sampling -X- _ O
process -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
approach -X- _ O
, -X- _ O
αnumber -X- _ O
of -X- _ O
UR -X- _ O
words -X- _ O
, -X- _ O
α -X- _ O
> -X- _ O
δ -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
wentropy -X- _ O
are -X- _ O
selected -X- _ O
for -X- _ O
clustering -X- _ O
. -X- _ O
The -X- _ O
optimal -X- _ O
number -X- _ O
of -X- _ O
clusters -X- _ O
is -X- _ O
determined -X- _ O
by -X- _ O
computing -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
squared -X- _ O
error -X- _ O
( -X- _ O
SSE -X- _ O
) -X- _ O
for -X- _ O
various -X- _ O
cluster -X- _ O
counts -X- _ O
, -X- _ O
k. -X- _ O
In -X- _ O
each -X- _ O
observation -X- _ O
, -X- _ O
S -X- _ O
, -X- _ O
centroids -X- _ O
are -X- _ O
determined -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
mean -X- _ O
value -X- _ O
, -X- _ O
µ -X- _ O
, -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
points -X- _ O
, -X- _ O
w -X- _ O
, -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O
The -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
deviation -X- _ O
of -X- _ O
the -X- _ O
points -X- _ O
from -X- _ O
centroids -X- _ O
for -X- _ O
all -X- _ O
clusters -X- _ O
combined -X- _ O
determines -X- _ O
SSE -X- _ O
. -X- _ O
An -X- _ O
observation -X- _ O
’s -X- _ O
cluster -X- _ O
count -X- _ O
, -X- _ O
k -X- _ O
, -X- _ O
is -X- _ O
optimal -X- _ O
only -X- _ O
if -X- _ O
its -X- _ O
SSE -X- _ O
is -X- _ O
minimal -X- _ O
among -X- _ O
all -X- _ O
observations -X- _ O
. -X- _ O
SSE -X- _ O
= -X- _ O
/ -X- _ O
summationdisplay -X- _ O
/ -X- _ O
summationdisplay||w−µ|| -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
The -X- _ O
best -X- _ O
cluster -X- _ O
count -X- _ O
in -X- _ O
each -X- _ O
AL -X- _ O
cycle -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
clustering -X- _ O
. -X- _ O
The -X- _ O
ultimate -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
δmost -X- _ O
informative -X- _ O
UR -X- _ O
words -X- _ O
with -X- _ O
an -X- _ O
acceptable -X- _ O
diversity -X- _ O
of -X- _ O
total -X- _ O
α -X- _ O
( -X- _ O
i.e -X- _ O
. -X- _ O
,1,000 -X- _ O
) -X- _ O
samples -X- _ O
. -X- _ O
A -X- _ O
character -X- _ O
- -X- _ O
based -X- _ O
word -X- _ O
embedding -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
RNN -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
datasets -X- _ O
LandTto -X- _ O
extract -X- _ O
features -X- _ O
for -X- _ O
performing -X- _ O
efficient -X- _ O
clustering -X- _ O
. -X- _ O
Using -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
model -X- _ O
enables -X- _ O
us -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
sense795of -X- _ O
UR -X- _ O
words -X- _ O
and -X- _ O
their -X- _ O
semantic -X- _ O
relations -X- _ O
with -X- _ O
their -X- _ O
corresponding -X- _ O
SF -X- _ O
words -X- _ O
, -X- _ O
considering -X- _ O
LandTdata -X- _ O
points -X- _ O
are -X- _ O
labeled -X- _ O
. -X- _ O
A -X- _ O
word -X- _ O
embedding -X- _ O
model -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
vectorize -X- _ O
αsamples -X- _ O
selected -X- _ O
from -X- _ O
U. -X- _ O
Two -X- _ O
sequences -X- _ O
of -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
vectors -X- _ O
, -X- _ O
representing -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
UR -X- _ O
and -X- _ O
SF -X- _ O
, -X- _ O
pass -X- _ O
through -X- _ O
two -X- _ O
long -X- _ O
short -X- _ O
- -X- _ O
term -X- _ O
memory -X- _ O
( -X- _ O
LSTM -X- _ O
) -X- _ O
networks -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
output -X- _ O
embeddings -X- _ O
is -X- _ O
fed -X- _ O
to -X- _ O
a -X- _ O
sigmoid -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O
A -X- _ O
sample -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
related -X- _ O
pair -X- _ O
, -X- _ O
and -X- _ O
samples -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
Levenshtein -X- _ O
distance -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
are -X- _ O
non -X- _ O
- -X- _ O
related -X- _ O
. -X- _ O
These -X- _ O
samples -X- _ O
are -X- _ O
combined -X- _ O
and -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
network -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
converts -X- _ O
a -X- _ O
word -X- _ O
to -X- _ O
a -X- _ O
vector -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
character -X- _ O
vocabulary -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
unique -X- _ O
characters -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
After -X- _ O
standardizing -X- _ O
the -X- _ O
vectors -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
fed -X- _ O
to -X- _ O
principal -X- _ O
component -X- _ O
analysis -X- _ O
( -X- _ O
PCA -X- _ O
) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
retain -X- _ O
the -X- _ O
most -X- _ O
significant -X- _ O
features -X- _ O
and -X- _ O
minimize -X- _ O
the -X- _ O
computational -X- _ O
costs -X- _ O
by -X- _ O
reducing -X- _ O
dimensions -X- _ O
. -X- _ O
The -X- _ O
features -X- _ O
dimension -X- _ O
is -X- _ O
reduced -X- _ O
to -X- _ O
3 -X- _ O
components -X- _ O
for -X- _ O
clustering -X- _ O
. -X- _ O
αsamples -X- _ O
were -X- _ O
divided -X- _ O
into -X- _ O
clusters -X- _ O
using -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
means -X- _ O
method -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
clusters -X- _ O
, -X- _ O
δsamples -X- _ O
are -X- _ O
selected -X- _ O
from -X- _ O
each -X- _ O
group -X- _ O
. -X- _ O
These -X- _ O
samples -X- _ O
will -X- _ O
be -X- _ O
annotated -X- _ O
and -X- _ O
moved -X- _ O
to -X- _ O
Lfor -X- _ O
the -X- _ O
next -X- _ O
AL -X- _ O
training -X- _ O
cycle -X- _ O
. -X- _ O
6 -X- _ O
Experimental -X- _ O
Results -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
parameters -X- _ O
and -X- _ O
other -X- _ O
variables -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
To -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
DAL -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
run -X- _ O
all -X- _ O
experiments -X- _ O
5 -X- _ O
times -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
accuracy -X- _ O
are -X- _ O
visualized -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
reported -X- _ O
random -X- _ B-MethodName
training -X- _ I-MethodName
( -X- _ O
passive -X- _ O
learning -X- _ O
) -X- _ O
, -X- _ O
AL -X- _ B-MethodName
with -X- _ I-MethodName
entropy -X- _ I-MethodName
, -X- _ O
and -X- _ O
AL -X- _ B-MethodName
with -X- _ I-MethodName
combined -X- _ I-MethodName
entropy -X- _ I-MethodName
and -X- _ I-MethodName
clustering -X- _ I-MethodName
method -X- _ O
for -X- _ O
each -X- _ O
cycle -X- _ O
of -X- _ O
training -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
DAL -X- _ B-MethodName
method -X- _ O
( -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
clustering -X- _ O
) -X- _ O
grows -X- _ O
much -X- _ O
faster -X- _ O
than -X- _ O
the -X- _ O
random -X- _ O
curve -X- _ O
and -X- _ O
presents -X- _ O
an -X- _ O
asymptotical -X- _ O
shape -X- _ O
which -X- _ O
shows -X- _ O
that -X- _ O
it -X- _ O
has -X- _ O
extracted -X- _ O
all -X- _ O
the -X- _ O
useful -X- _ O
information -X- _ O
present -X- _ O
in -X- _ O
Uwhen -X- _ O
it -X- _ O
reaches -X- _ O
the -X- _ O
asymptote -X- _ O
using -X- _ O
only -X- _ O
4,000 -X- _ O
samples -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
about -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
random -X- _ O
( -X- _ O
passive -X- _ O
) -X- _ O
learner -X- _ O
requires -X- _ O
the -X- _ O
entire -X- _ O
training -X- _ O
set -X- _ O
to -X- _ O
achieve -X- _ O
maximum -X- _ O
performance -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
true -X- _ O
for -X- _ O
all -X- _ O
evaluation -X- _ O
sets -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
EV -X- _ O
AL -X- _ O
- -X- _ O
OOV -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
random -X- _ O
( -X- _ O
passive -X- _ O
) -X- _ O
learner -X- _ O
reaches -X- _ O
maximum -X- _ O
performance -X- _ O
after -X- _ O
6,000 -X- _ O
samples -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
no -X- _ O
explanation -X- _ O
for -X- _ O
this -X- _ O
unusual -X- _ O
behavior -X- _ O
of -X- _ O
EV -X- _ O
AL -X- _ O
- -X- _ O
OOV -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
do -X- _ O
observe -X- _ O
thatthe -X- _ O
overall -X- _ O
top -X- _ O
performance -X- _ O
on -X- _ O
EV -X- _ O
AL -X- _ O
- -X- _ O
OOV -X- _ O
is -X- _ O
2 -X- _ O
percentage -X- _ O
points -X- _ O
lower -X- _ O
than -X- _ O
on -X- _ O
DEV -X- _ O
- -X- _ O
OOV -X- _ O
, -X- _ O
while -X- _ O
EV -X- _ O
AL -X- _ O
and -X- _ O
DEV -X- _ O
have -X- _ O
similar -X- _ O
results -X- _ O
. -X- _ O
This -X- _ O
supports -X- _ O
the -X- _ O
hypothesis -X- _ O
that -X- _ O
EV -X- _ O
AL -X- _ O
- -X- _ O
OOV -X- _ O
contains -X- _ O
some -X- _ O
very -X- _ O
difficult -X- _ O
cases -X- _ O
which -X- _ O
the -X- _ O
underlying -X- _ O
system -X- _ O
( -X- _ O
with -X- _ O
active -X- _ O
or -X- _ O
passive -X- _ O
learning -X- _ O
) -X- _ O
can -X- _ O
not -X- _ O
learn -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
active -X- _ O
and -X- _ O
passive -X- _ O
learning -X- _ O
converge -X- _ O
earlier -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
not -X- _ O
obtain -X- _ O
evidence -X- _ O
from -X- _ O
this -X- _ O
dataset -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
hybrid -X- _ O
method -X- _ O
( -X- _ O
combining -X- _ O
entropy -X- _ O
and -X- _ O
clustering -X- _ O
) -X- _ O
is -X- _ O
effective -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
be -X- _ O
language -X- _ O
and -X- _ O
model -X- _ O
independent -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
on -X- _ O
different -X- _ O
languages -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
different -X- _ O
character -X- _ O
- -X- _ O
based -X- _ O
DL -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
should -X- _ O
be -X- _ O
applied -X- _ O
on -X- _ O
new -X- _ O
languages -X- _ O
and -X- _ O
dialects -X- _ O
in -X- _ O
further -X- _ O
studies -X- _ O
. -X- _ O
We -X- _ O
expect -X- _ O
that -X- _ O
further -X- _ O
studies -X- _ O
will -X- _ O
show -X- _ O
that -X- _ O
clustering -X- _ O
can -X- _ O
be -X- _ O
effective -X- _ O
, -X- _ O
especially -X- _ O
if -X- _ O
many -X- _ O
diverse -X- _ O
phenomena -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
7 -X- _ O
Error -X- _ O
Analysis -X- _ O
We -X- _ O
performed -X- _ O
an -X- _ O
error -X- _ O
analysis -X- _ O
on -X- _ O
100 -X- _ O
randomly -X- _ O
chosen -X- _ O
errors -X- _ O
from -X- _ O
the -X- _ O
DEV -X- _ O
- -X- _ O
OOV -X- _ O
set -X- _ O
, -X- _ O
generated -X- _ O
by -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
1,900 -X- _ O
samples -X- _ O
using -X- _ O
AL -X- _ B-MethodName
with -X- _ I-MethodName
entropy -X- _ I-MethodName
and -X- _ O
random -X- _ B-MethodName
selection -X- _ I-MethodName
methods -X- _ O
. -X- _ O
On -X- _ O
this -X- _ O
sample -X- _ O
size -X- _ O
, -X- _ O
the -X- _ O
random -X- _ B-MethodName
selection -X- _ I-MethodName
approach -X- _ O
achieves -X- _ O
an -X- _ O
error -X- _ B-MetricName
rate -X- _ I-MetricName
of -X- _ O
12.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
which -X- _ O
reduces -X- _ O
to -X- _ O
7.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
through -X- _ O
AL -X- _ B-MethodName
( -X- _ O
a -X- _ O
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
error -X- _ O
reduction -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
distinguish -X- _ O
three -X- _ O
basic -X- _ O
types -X- _ O
of -X- _ O
errors -X- _ O
: -X- _ O
the -X- _ O
system -X- _ O
deletes -X- _ O
a -X- _ O
letter -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
phoneme -X- _ O
) -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
; -X- _ O
the -X- _ O
system -X- _ O
changes -X- _ O
a -X- _ O
letter -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
; -X- _ O
the -X- _ O
system -X- _ O
adds -X- _ O
a -X- _ O
letter -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
, -X- _ O
or -X- _ O
does -X- _ O
not -X- _ O
delete -X- _ O
a -X- _ O
letter -X- _ O
it -X- _ O
should -X- _ O
. -X- _ O
We -X- _ O
summarize -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Starting -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
letter -X- _ O
deletion -X- _ O
is -X- _ O
greatly -X- _ O
reduced -X- _ O
by -X- _ O
moving -X- _ O
from -X- _ O
random -X- _ O
selection -X- _ O
to -X- _ O
AL -X- _ B-MethodName
; -X- _ O
affix -X- _ O
deletion -X- _ O
is -X- _ O
a -X- _ O
special -X- _ O
case -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
entire -X- _ O
affix -X- _ O
is -X- _ O
not -X- _ O
realized -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
problem -X- _ O
is -X- _ O
eliminated -X- _ O
. -X- _ O
Letter -X- _ O
change -X- _ O
is -X- _ O
also -X- _ O
greatly -X- _ O
reduced -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
a -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
letter -X- _ O
change -X- _ O
becomes -X- _ O
more -X- _ O
prominent -X- _ O
: -X- _ O
vowel -X- _ O
length -X- _ O
changes -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
effect -X- _ O
in -X- _ O
Arabic -X- _ O
phonology -X- _ O
due -X- _ O
to -X- _ O
changes -X- _ O
in -X- _ O
syllabification -X- _ O
resulting -X- _ O
from -X- _ O
adding -X- _ O
affixes -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
letter -X- _ O
addition -X- _ O
remains -X- _ O
a -X- _ O
problem -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
the -X- _ O
system -X- _ O
failing -X- _ O
to -X- _ O
delete -X- _ O
a -X- _ O
letter -X- _ O
in -X- _ O
fact -X- _ O
increasing -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
case -X- _ O
which -X- _ O
is -X- _ O
reduced -X- _ O
is -X- _ O
the -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
i -X- _ O
- -X- _ O
deletion -X- _ O
in -X- _ O
the -X- _ O
active -X- _ O
participle -X- _ O
, -X- _ O
which -X- _ O
the -X- _ O
AL -X- _ B-MethodName
setting -X- _ O
appears -X- _ O
to -X- _ O
learn -X- _ O
much -X- _ O
better -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
have -X- _ O
a -X- _ O
fairly -X- _ O
small -X- _ O
category -X- _ O
with -X- _ O
multiple -X- _ O
errors -X- _ O
, -X- _ O
which -X- _ O
remains -X- _ O
about -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
expect -X- _ O
when -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
goes -X- _ O
down -X- _ O
, -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
problem -X- _ O
cases -X- _ O
in -X- _ O
the796 -X- _ O
corpus -X- _ O
goes -X- _ O
up -X- _ O
. -X- _ O
We -X- _ O
distinguish -X- _ O
three -X- _ O
cases -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
foreign -X- _ O
words -X- _ O
have -X- _ O
lexically -X- _ O
idiosyncratic -X- _ O
rules -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
learned -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
almost -X- _ O
all -X- _ O
Arabic -X- _ O
dialects -X- _ O
replace -X- _ O
the -X- _ O
/ -X- _ O
l -X- _ O
/ -X- _ O
of -X- _ O
the -X- _ O
definite -X- _ O
determiner -X- _ O
/ -X- _ O
Al -X- _ O
/ -X- _ O
with -X- _ O
the -X- _ O
first -X- _ O
letter -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
noun -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
coronal -X- _ O
( -X- _ O
“ -X- _ O
sun -X- _ O
- -X- _ O
letter -X- _ O
assimilation -X- _ O
” -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Egyptian -X- _ O
optionally -X- _ O
also -X- _ O
does -X- _ O
this -X- _ O
for -X- _ O
/ -X- _ O
j -X- _ O
/ -X- _ O
and -X- _ O
/ -X- _ O
k -X- _ O
/ -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
optionality -X- _ O
is -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
which -X- _ O
makes -X- _ O
consistent -X- _ O
learning -X- _ O
impossible -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
the -X- _ O
corpus -X- _ O
has -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
actual -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
standard -X- _ O
, -X- _ O
usually -X- _ O
in -X- _ O
the -X- _ O
UR -X- _ O
. -X- _ O
So -X- _ O
in -X- _ O
summary -X- _ O
, -X- _ O
the -X- _ O
AL -X- _ B-MethodName
system -X- _ O
has -X- _ O
improved -X- _ O
in -X- _ O
all -X- _ O
error -X- _ O
types -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
letter -X- _ O
addition -X- _ O
categories -X- _ O
. -X- _ O
Error -X- _ O
Type -X- _ O
AL -X- _ O
Random -X- _ O
letter -X- _ O
deletion -X- _ O
11 -X- _ O
25 -X- _ O
affix -X- _ O
deletion -X- _ O
0 -X- _ O
2 -X- _ O
letter -X- _ O
change -X- _ O
11 -X- _ O
17 -X- _ O
no -X- _ O
v -X- _ O
shortening -X- _ O
5 -X- _ O
2 -X- _ O
v -X- _ O
shortening -X- _ O
7 -X- _ O
4 -X- _ O
letter -X- _ O
addition -X- _ O
8 -X- _ O
6 -X- _ O
no -X- _ O
letter -X- _ O
deletion -X- _ O
6 -X- _ O
2 -X- _ O
no -X- _ O
AP -X- _ O
i -X- _ O
deletion -X- _ O
2 -X- _ O
5 -X- _ O
multiple -X- _ O
errors -X- _ O
14 -X- _ O
13 -X- _ O
foreign -X- _ O
1 -X- _ O
1 -X- _ O
sun -X- _ O
letter -X- _ O
10 -X- _ O
8 -X- _ O
gold -X- _ O
error -X- _ O
25 -X- _ O
15 -X- _ O
Sum -X- _ O
100 -X- _ O
1008 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
deep -X- _ O
active -X- _ O
learning -X- _ O
method -X- _ O
for -X- _ O
the -X- _ O
morphological -X- _ B-TaskName
inflection -X- _ I-TaskName
processing -X- _ I-TaskName
task -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
method -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
on -X- _ O
different -X- _ O
languages -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
focused -X- _ O
on -X- _ O
the -X- _ O
Egyptian -X- _ O
Arabic -X- _ O
dialect -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
experiment -X- _ O
demonstrate -X- _ O
the -X- _ O
outstanding -X- _ O
efficiency -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
: -X- _ O
With -X- _ O
only -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
the -X- _ O
same -X- _ O
accuracy -X- _ O
as -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
whole -X- _ O
dataset -X- _ O
. -X- _ O
Future -X- _ O
research -X- _ O
includes -X- _ O
applying -X- _ O
this -X- _ O
method -X- _ O
to -X- _ O
different -X- _ O
low -X- _ O
- -X- _ O
resources -X- _ O
Arabic -X- _ O
dialects -X- _ O
and -X- _ O
other -X- _ O
languages -X- _ O
for -X- _ O
building -X- _ O
datasets -X- _ O
, -X- _ O
using -X- _ O
other -X- _ O
baseline -X- _ O
algorithms -X- _ O
, -X- _ O
working -X- _ O
on -X- _ O
new -X- _ O
uncertainty -X- _ O
measures -X- _ O
, -X- _ O
and -X- _ O
exploring -X- _ O
for -X- _ O
which -X- _ O
datasets -X- _ O
the -X- _ O
clustering -X- _ O
method -X- _ O
can -X- _ O
be -X- _ O
helpful -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
intend -X- _ O
to -X- _ O
investigate -X- _ O
how -X- _ O
we -X- _ O
can -X- _ O
exploit -X- _ O
our -X- _ O
insight -X- _ O
from -X- _ O
the -X- _ O
error -X- _ O
analysis -X- _ O
that -X- _ O
the -X- _ O
letter -X- _ O
addition -X- _ O
cases -X- _ O
remain -X- _ O
high -X- _ O
( -X- _ O
or -X- _ O
even -X- _ O
increase -X- _ O
) -X- _ O
. -X- _ O
Acknowledgements -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
three -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
comments -X- _ O
. -X- _ O
Experiments -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
SeaWulf -X- _ O
HPC -X- _ O
cluster -X- _ O
maintained -X- _ O
by -X- _ O
RCC -X- _ O
and -X- _ O
the -X- _ O
Institute -X- _ O
for -X- _ O
Advanced -X- _ O
Computational -X- _ O
Science -X- _ O
( -X- _ O
IACS -X- _ O
) -X- _ O
at -X- _ O
Stony -X- _ O
Brook -X- _ O
University -X- _ O
and -X- _ O
made -X- _ O
possible -X- _ O
by -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
( -X- _ O
NSF -X- _ O
) -X- _ O
grant -X- _ O
No -X- _ O
. -X- _ O
1531492.797Limitations -X- _ O
Like -X- _ O
lots -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
algorithms -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
also -X- _ O
needs -X- _ O
GPU -X- _ O
resources -X- _ O
. -X- _ O
In -X- _ O
common -X- _ O
learning -X- _ O
problems -X- _ O
, -X- _ O
models -X- _ O
will -X- _ O
be -X- _ O
trained -X- _ O
once -X- _ O
on -X- _ O
the -X- _ O
existing -X- _ O
training -X- _ O
datasets -X- _ O
, -X- _ O
using -X- _ O
dev -X- _ O
sets -X- _ O
for -X- _ O
tuning -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
trained -X- _ O
model -X- _ O
would -X- _ O
be -X- _ O
ready -X- _ O
for -X- _ O
use -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
in -X- _ O
active -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
several -X- _ O
times -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
whenever -X- _ O
new -X- _ O
annotated -X- _ O
samples -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
be -X- _ O
re -X- _ O
- -X- _ O
trained -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
increases -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
GPU -X- _ O
resources -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
GPU -X- _ O
, -X- _ O
is -X- _ O
not -X- _ O
related -X- _ O
to -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
run -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
method -X- _ O
once -X- _ O
( -X- _ O
rather -X- _ O
than -X- _ O
iteratively -X- _ O
) -X- _ O
for -X- _ O
building -X- _ O
an -X- _ O
acceptable -X- _ O
dataset -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
designed -X- _ O
the -X- _ O
algorithm -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
be -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
utilized -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
tested -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
Egyptian -X- _ O
Arabic -X- _ O
dialect -X- _ O
and -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
be -X- _ O
investigated -X- _ O
on -X- _ O
other -X- _ O
languages -X- _ O
and -X- _ O
dialects -X- _ O
using -X- _ O
different -X- _ O
learning -X- _ O
models -X- _ O
in -X- _ O
further -X- _ O
studies -X- _ O
. -X- _ O
Ethics -X- _ O
Statement -X- _ O
The -X- _ O
current -X- _ O
work -X- _ O
is -X- _ O
a -X- _ O
fundamental -X- _ O
research -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
essentially -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
particular -X- _ O
application -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
predict -X- _ O
any -X- _ O
ethical -X- _ O
concerns -X- _ O
from -X- _ O
the -X- _ O
algorithms -X- _ O
and -X- _ O
technologies -X- _ O
proposed -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
utilized -X- _ O
publicly -X- _ O
available -X- _ O
dataset -X- _ O
and -X- _ O
open -X- _ O
source -X- _ O
libraries -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
published -X- _ O
before -X- _ O
. -X- _ O
References798 -X- _ O
A -X- _ O
Implementation -X- _ O
Details -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
transducer -X- _ O
based -X- _ O
on -X- _ O
transformers -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
our -X- _ O
computational -X- _ O
experiments -X- _ O
. -X- _ O
A -X- _ O
transformer -X- _ O
with -X- _ O
4 -X- _ B-HyperparameterValue
encoder -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
decoder -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
, -X- _ O
4 -X- _ B-HyperparameterValue
self -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
the -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
1024 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layer -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
these -X- _ O
specifications -X- _ O
is -X- _ O
7.37 -X- _ O
M -X- _ O
, -X- _ O
excluding -X- _ O
embeddings -X- _ O
and -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
softmax -X- _ O
linear -X- _ O
layer -X- _ O
. -X- _ O
Experiments -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
a -X- _ O
system -X- _ O
with -X- _ O
an -X- _ O
Intel -X- _ O
Core -X- _ O
i7 -X- _ O
- -X- _ O
8700 -X- _ O
K -X- _ O
CPU -X- _ O
3.70GHz -X- _ O
6 -X- _ O
- -X- _ O
Core -X- _ O
, -X- _ O
a -X- _ O
GeForce -X- _ O
GTX -X- _ O
1080 -X- _ O
8 -X- _ O
GB -X- _ O
, -X- _ O
and -X- _ O
64 -X- _ O
GB -X- _ O
of -X- _ O
memory -X- _ O
. -X- _ O
The -X- _ O
minimum -X- _ O
resources -X- _ O
required -X- _ O
for -X- _ O
each -X- _ O
AL -X- _ O
training -X- _ O
cycle -X- _ O
is -X- _ O
3.38GBs -X- _ O
of -X- _ O
GPU -X- _ O
and -X- _ O
3.5GBs -X- _ O
of -X- _ O
RAM -X- _ O
. -X- _ O
A -X- _ O
training -X- _ O
cycle -X- _ O
completes -X- _ O
in -X- _ O
less -X- _ O
than -X- _ O
60 -X- _ O
minutes -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
experiment -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
A.1 -X- _ O
. -X- _ O
We -X- _ O
conducted -X- _ O
multiple -X- _ O
experiments -X- _ O
with -X- _ O
different -X- _ O
values -X- _ O
. -X- _ O
For -X- _ O
AL -X- _ O
cycle -X- _ O
sampling -X- _ O
, -X- _ O
various -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
maximum -X- _ O
entropy -X- _ O
, -X- _ O
maximum -X- _ O
entropy -X- _ O
limited -X- _ O
to -X- _ O
vowel -X- _ O
letters -X- _ O
, -X- _ O
and -X- _ O
mean -X- _ O
entropy -X- _ O
were -X- _ O
employed -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
maximum -X- _ O
entropy -X- _ O
outperformed -X- _ O
others -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
all -X- _ O
the -X- _ O
experiments -X- _ O
5 -X- _ O
times -X- _ O
and -X- _ O
reported -X- _ O
the -X- _ O
average799and -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
Regarding -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
algorithm -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
used -X- _ O
PyTorch -X- _ O
, -X- _ O
NumPy -X- _ O
, -X- _ O
Pandas -X- _ O
, -X- _ O
Matplotlib -X- _ O
, -X- _ O
scikit -X- _ O
- -X- _ O
learn -X- _ O
, -X- _ O
and -X- _ O
chars2vec -X- _ O
software -X- _ O
packages -X- _ O
. -X- _ O
Parameter -X- _ O
Value -X- _ O
AL -X- _ O
Initial -X- _ O
Sampling -X- _ O
Method -X- _ O
random -X- _ O
AL -X- _ O
Cycle -X- _ O
Sampling -X- _ O
Method -X- _ O
entropy -X- _ O
AL -X- _ O
Cycle -X- _ O
Clustering -X- _ O
Method -X- _ O
k -X- _ O
- -X- _ O
means -X- _ O
AL -X- _ O
Initial -X- _ O
Training -X- _ O
Samples -X- _ O
Counts -X- _ O
900 -X- _ O
AL -X- _ O
Tuning -X- _ O
Samples -X- _ O
Counts -X- _ O
500 -X- _ O
AL -X- _ O
Pre -X- _ O
- -X- _ O
clustering -X- _ O
Samples -X- _ O
Counts -X- _ O
1000 -X- _ O
AL -X- _ O
Cycle -X- _ O
Samples -X- _ O
Counts -X- _ O
250 -X- _ O
Training -X- _ O
Batch -X- _ O
Size -X- _ O
400 -X- _ O
Evaluation -X- _ O
Batch -X- _ O
Size -X- _ O
16 -X- _ O
Dropout -X- _ O
0.3 -X- _ O
Character -X- _ O
Embedding -X- _ O
Dimension -X- _ O
50 -X- _ O
PCA -X- _ O
Components -X- _ O
3 -X- _ O
Max -X- _ O
Cluster -X- _ O
Counts -X- _ O
8 -X- _ O
B -X- _ O
Additional -X- _ O
Results -X- _ O
Employing -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
the -X- _ O
experiments -X- _ O
in -X- _ O
the -X- _ O
reversed -X- _ O
direction -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
SF -X- _ O
to -X- _ O
UR -X- _ O
) -X- _ O
for -X- _ O
morphophonological -X- _ O
analysis -X- _ O
. -X- _ O
As -X- _ O
demonstrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
DAL -X- _ B-MethodName
methods -X- _ O
outperformed -X- _ O
random -X- _ O
training -X- _ O
by -X- _ O
extracting -X- _ O
all -X- _ O
the -X- _ O
informative -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
pool -X- _ O
set -X- _ O
, -X- _ O
U -X- _ O
, -X- _ O
when -X- _ O
reaching -X- _ O
the -X- _ O
asymptote -X- _ O
using -X- _ O
8,000 -X- _ O
samples -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
current -X- _ O
baseline -X- _ O
is -X- _ O
designed -X- _ O
for -X- _ O
morphophonological -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
its -X- _ O
performance -X- _ O
is -X- _ O
diminished -X- _ O
for -X- _ O
SF -X- _ O
to -X- _ O
UR -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
, -X- _ O
a -X- _ O
more -X- _ O
suitable -X- _ O
baseline -X- _ O
model -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
would -X- _ O
achieve -X- _ O
higher -X- _ O
accuracies -X- _ O
in -X- _ O
morphophonological -X- _ O
analysis -X- _ O
for -X- _ O
both -X- _ O
passive -X- _ O
and -X- _ O
active -X- _ O
learning.800801ACL -X- _ O
2023 -X- _ O
Responsible -X- _ O
NLP -X- _ O
Checklist -X- _ O
A -X- _ O
For -X- _ O
every -X- _ O
submission -X- _ O
: -X- _ O
/ -X- _ O
squareA1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
describe -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
In -X- _ O
the -X- _ O
Limitation -X- _ O
section -X- _ O
after -X- _ O
Paper -X- _ O
’s -X- _ O
conclusion -X- _ O
. -X- _ O
/ -X- _ O
squareA2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
any -X- _ O
potential -X- _ O
risks -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
In -X- _ O
Ethics -X- _ O
Statement -X- _ O
section -X- _ O
after -X- _ O
Limitation -X- _ O
section -X- _ O
. -X- _ O
/ -X- _ O
squareA3 -X- _ O
. -X- _ O
Do -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
introduction -X- _ O
summarize -X- _ O
the -X- _ O
paper -X- _ O
’s -X- _ O
main -X- _ O
claims -X- _ O
? -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
introduction -X- _ O
( -X- _ O
Section -X- _ O
1 -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
/ -X- _ O
squareA4 -X- _ O
. -X- _ O
Have -X- _ O
you -X- _ O
used -X- _ O
AI -X- _ O
writing -X- _ O
assistants -X- _ O
when -X- _ O
working -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
B -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
or -X- _ O
create -X- _ O
scientiﬁc -X- _ O
artifacts -X- _ O
? -X- _ O
Sections -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
. -X- _ O
/ -X- _ O
squareB1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
cite -X- _ O
the -X- _ O
creators -X- _ O
of -X- _ O
artifacts -X- _ O
you -X- _ O
used -X- _ O
? -X- _ O
Sections -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
, -X- _ O
and -X- _ O
appendix -X- _ O
A. -X- _ O
/ -X- _ O
squareB2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
license -X- _ O
or -X- _ O
terms -X- _ O
for -X- _ O
use -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
distribution -X- _ O
of -X- _ O
any -X- _ O
artifacts -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
speciﬁed -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identiﬁes -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
provide -X- _ O
documentation -X- _ O
of -X- _ O
the -X- _ O
artifacts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
coverage -X- _ O
of -X- _ O
domains -X- _ O
, -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
linguistic -X- _ O
phenomena -X- _ O
, -X- _ O
demographic -X- _ O
groups -X- _ O
represented -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB6 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
relevant -X- _ O
statistics -X- _ O
like -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
, -X- _ O
details -X- _ O
of -X- _ O
train -X- _ O
/ -X- _ O
test -X- _ O
/ -X- _ O
dev -X- _ O
splits -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
for -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
you -X- _ O
used -X- _ O
/ -X- _ O
created -X- _ O
? -X- _ O
Even -X- _ O
for -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
include -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
train -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
provide -X- _ O
necessary -X- _ O
context -X- _ O
for -X- _ O
a -X- _ O
reader -X- _ O
to -X- _ O
understand -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
small -X- _ O
differences -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
large -X- _ O
test -X- _ O
sets -X- _ O
may -X- _ O
be -X- _ O
signiﬁcant -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
small -X- _ O
test -X- _ O
sets -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
. -X- _ O
Sections -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
. -X- _ O
C -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
run -X- _ O
computational -X- _ O
experiments -X- _ O
? -X- _ O
Appendix -X- _ O
A. -X- _ O
/ -X- _ O
squareC1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
computational -X- _ O
budget -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPU -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
infrastructure -X- _ O
used -X- _ O
? -X- _ O
Appendix -X- _ O
A.802 -X- _ O
/ -X- _ O
squareC2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
including -X- _ O
hyperparameter -X- _ O
search -X- _ O
and -X- _ O
best -X- _ O
- -X- _ O
found -X- _ O
hyperparameter -X- _ O
values -X- _ O
? -X- _ O
Appendix -X- _ O
A. -X- _ O
/ -X- _ O
squareC3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
descriptive -X- _ O
statistics -X- _ O
about -X- _ O
your -X- _ O
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
error -X- _ O
bars -X- _ O
around -X- _ O
results -X- _ O
, -X- _ O
summary -X- _ O
statistics -X- _ O
from -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
it -X- _ O
transparent -X- _ O
whether -X- _ O
you -X- _ O
are -X- _ O
reporting -X- _ O
the -X- _ O
max -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
or -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
? -X- _ O
Section -X- _ O
5 -X- _ O
, -X- _ O
Appendix -X- _ O
A -X- _ O
, -X- _ O
and -X- _ O
Appendix -X- _ O
B. -X- _ O
/ -X- _ O
squareC4 -X- _ O
. -X- _ O
If -X- _ O
you -X- _ O
used -X- _ O
existing -X- _ O
packages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
preprocessing -X- _ O
, -X- _ O
for -X- _ O
normalization -X- _ O
, -X- _ O
or -X- _ O
for -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
implementation -X- _ O
, -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
parameter -X- _ O
settings -X- _ O
used -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
NLTK -X- _ O
, -X- _ O
Spacy -X- _ O
, -X- _ O
ROUGE -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
? -X- _ O
Appendix -X- _ O
A. -X- _ O
D -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
human -X- _ O
annotators -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdworkers -X- _ O
) -X- _ O
or -X- _ O
research -X- _ O
with -X- _ O
human -X- _ O
participants -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
of -X- _ O
instructions -X- _ O
given -X- _ O
to -X- _ O
participants -X- _ O
, -X- _ O
including -X- _ O
e.g. -X- _ O
, -X- _ O
screenshots -X- _ O
, -X- _ O
disclaimers -X- _ O
of -X- _ O
any -X- _ O
risks -X- _ O
to -X- _ O
participants -X- _ O
or -X- _ O
annotators -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
you -X- _ O
recruited -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdsourcing -X- _ O
platform -X- _ O
, -X- _ O
students -X- _ O
) -X- _ O
and -X- _ O
paid -X- _ O
participants -X- _ O
, -X- _ O
and -X- _ O
discuss -X- _ O
if -X- _ O
such -X- _ O
payment -X- _ O
is -X- _ O
adequate -X- _ O
given -X- _ O
the -X- _ O
participants -X- _ O
’ -X- _ O
demographic -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
country -X- _ O
of -X- _ O
residence -X- _ O
) -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
whether -X- _ O
and -X- _ O
how -X- _ O
consent -X- _ O
was -X- _ O
obtained -X- _ O
from -X- _ O
people -X- _ O
whose -X- _ O
data -X- _ O
you -X- _ O
’re -X- _ O
using -X- _ O
/ -X- _ O
curating -X- _ O
? -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
collected -X- _ O
data -X- _ O
via -X- _ O
crowdsourcing -X- _ O
, -X- _ O
did -X- _ O
your -X- _ O
instructions -X- _ O
to -X- _ O
crowdworkers -X- _ O
explain -X- _ O
how -X- _ O
the -X- _ O
data -X- _ O
would -X- _ O
be -X- _ O
used -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD4 -X- _ O
. -X- _ O
Was -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
protocol -X- _ O
approved -X- _ O
( -X- _ O
or -X- _ O
determined -X- _ O
exempt -X- _ O
) -X- _ O
by -X- _ O
an -X- _ O
ethics -X- _ O
review -X- _ O
board -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
basic -X- _ O
demographic -X- _ O
and -X- _ O
geographic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
annotator -X- _ O
population -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
? -X- _ O
No -X- _ O
response.803 -X- _ O

2023.acl-long.111.txt -X- _ O
Yuxin -X- _ O
RenZihan -X- _ O
ZhongXingjian -X- _ O
ShiYi -X- _ O
ZhuChun -X- _ O
YuanMu -X- _ O
LiTsinghua -X- _ O
University -X- _ O
, -X- _ O
Boson -X- _ O
AI -X- _ O
{ -X- _ O
ryx20 -X- _ O
, -X- _ O
zhongzh22 -X- _ O
} -X- _ O
@ -X- _ O
mails.tsinghua.edu.cn -X- _ O
, -X- _ O
{ -X- _ O
xingjian -X- _ O
, -X- _ O
yi -X- _ O
, -X- _ O
mu -X- _ O
} -X- _ O
@ -X- _ O
boson.ai -X- _ O
yuanc -X- _ O
@ -X- _ O
sz.tsinghua.edu.cn -X- _ O
Abstract -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
commonly -X- _ O
observed -X- _ O
that -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
with -X- _ O
superior -X- _ O
performance -X- _ O
does -X- _ O
not -X- _ O
necessarily -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
stronger -X- _ O
student -X- _ O
, -X- _ O
highlighting -X- _ O
a -X- _ O
discrepancy -X- _ O
between -X- _ O
current -X- _ O
teacher -X- _ O
training -X- _ O
practices -X- _ O
and -X- _ O
effective -X- _ O
knowledge -X- _ O
transfer -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
guidance -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
distillation -X- _ O
influence -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
distillation -X- _ O
from -X- _ O
each -X- _ O
training -X- _ O
sample -X- _ O
on -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
ability -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Learning -X- _ B-MethodName
GoodTeacher -X- _ I-MethodName
Matters -X- _ I-MethodName
( -X- _ O
LGTM -X- _ B-MethodName
) -X- _ O
, -X- _ O
an -X- _ O
efficient -X- _ O
training -X- _ O
technique -X- _ O
for -X- _ O
incorporating -X- _ O
distillation -X- _ O
influence -X- _ O
into -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
learning -X- _ O
process -X- _ O
. -X- _ O
By -X- _ O
prioritizing -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
ability -X- _ O
, -X- _ O
our -X- _ O
LGTM -X- _ B-MethodName
outperforms -X- _ O
10 -X- _ O
common -X- _ O
knowledge -X- _ O
distillation -X- _ O
baselines -X- _ O
on -X- _ O
6 -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
The -X- _ O
recent -X- _ O
success -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
is -X- _ O
driven -X- _ O
by -X- _ O
the -X- _ O
adoption -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
scaling -X- _ O
up -X- _ O
in -X- _ O
depth -X- _ O
and -X- _ O
width -X- _ O
, -X- _ O
they -X- _ O
become -X- _ O
increasingly -X- _ O
computational -X- _ O
and -X- _ O
storage -X- _ O
intensive -X- _ O
, -X- _ O
making -X- _ O
deployment -X- _ O
difficult -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
different -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
for -X- _ O
crafting -X- _ O
efficient -X- _ O
models -X- _ O
with -X- _ O
minimal -X- _ O
loss -X- _ O
in -X- _ O
performance -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
weight -X- _ O
pruning -X- _ O
( -X- _ O
Fan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
, -X- _ O
network -X- _ O
quantization -X- _ O
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
KD -X- _ O
) -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Among -X- _ O
these -X- _ O
methods -X- _ O
, -X- _ O
KD -X- _ O
has -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
applications -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
is -X- _ O
widely -X- _ O
adopted -X- _ O
. -X- _ O
The -X- _ O
idea -X- _ O
of -X- _ O
KD -X- _ O
involves -X- _ O
asking -X- _ O
a -X- _ O
lightweight -X- _ O
stu -X- _ O
- -X- _ O
dent -X- _ O
model -X- _ O
to -X- _ O
mimic -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
large -X- _ O
teacher -X- _ O
model -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
transfer -X- _ O
the -X- _ O
knowledge -X- _ O
. -X- _ O
Ideally -X- _ O
, -X- _ O
a -X- _ O
teacher -X- _ O
with -X- _ O
better -X- _ O
performance -X- _ O
should -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
transfer -X- _ O
more -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
Therefore -X- _ O
in -X- _ O
most -X- _ O
knowledge -X- _ O
distillation -X- _ O
algorithms -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
network -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
maximize -X- _ O
its -X- _ O
own -X- _ O
performance -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
multiple -X- _ O
studies -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
; -X- _ O
Cho -X- _ O
and -X- _ O
Hariharan -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
observed -X- _ O
that -X- _ O
a -X- _ O
teacher -X- _ O
with -X- _ O
higher -X- _ O
performance -X- _ O
does -X- _ O
not -X- _ O
necessarily -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
betterperforming -X- _ O
student -X- _ O
, -X- _ O
and -X- _ O
may -X- _ O
even -X- _ O
cause -X- _ O
a -X- _ O
performance -X- _ O
degradation -X- _ O
. -X- _ O
Stanton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
attributed -X- _ O
this -X- _ O
inefficiency -X- _ O
in -X- _ O
knowledge -X- _ O
distillation -X- _ O
to -X- _ O
challenges -X- _ O
during -X- _ O
optimization -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
model -X- _ O
capacity -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
the -X- _ O
teacher -X- _ O
increases -X- _ O
, -X- _ O
the -X- _ O
optimization -X- _ O
process -X- _ O
becomes -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
trapped -X- _ O
in -X- _ O
local -X- _ O
optima -X- _ O
( -X- _ O
Cho -X- _ O
and -X- _ O
Hariharan -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Mirzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
way -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
performance -X- _ O
degradation -X- _ O
in -X- _ O
KD -X- _ O
is -X- _ O
to -X- _ O
update -X- _ O
the -X- _ O
teacher -X- _ O
via -X- _ O
feedback -X- _ O
from -X- _ O
student -X- _ O
’s -X- _ O
performance -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
learning -X- _ O
to -X- _ O
teach -X- _ O
( -X- _ O
L2 -X- _ O
T -X- _ O
) -X- _ O
( -X- _ O
Fan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
L2 -X- _ O
T -X- _ O
allows -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
to -X- _ O
adjust -X- _ O
its -X- _ O
“ -X- _ O
teaching -X- _ O
agenda -X- _ O
” -X- _ O
by -X- _ O
interacting -X- _ O
with -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
L2 -X- _ O
T -X- _ O
algorithms -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
trains -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
teacher -X- _ O
concurrently -X- _ O
and -X- _ O
enforces -X- _ O
similarity -X- _ O
between -X- _ O
their -X- _ O
outputs -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
focuses -X- _ O
on -X- _ O
transferring -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
on -X- _ O
training -X- _ O
set -X- _ O
without -X- _ O
explicitly -X- _ O
considering -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
student -X- _ O
will -X- _ O
perform -X- _ O
on -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
meta -X- _ O
distillation -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
takes -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
student -X- _ O
on -X- _ O
the -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
validation -X- _ O
set -X- _ O
into -X- _ O
account -X- _ O
, -X- _ O
and -X- _ O
guides -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
learning -X- _ O
process -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
optimization -X- _ O
objective -X- _ O
of -X- _ O
meta -X- _ O
distillation -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
degraded -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
only -X- _ O
receives -X- _ O
supervision -X- _ O
from -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
that -X- _ O
humans -X- _ O
are -X- _ O
more -X- _ O
efficient1990learners -X- _ O
when -X- _ O
their -X- _ O
teachers -X- _ O
provide -X- _ O
guidance -X- _ O
on -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
attention -X- _ O
they -X- _ O
should -X- _ O
devote -X- _ O
to -X- _ O
certain -X- _ O
problems -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
current -X- _ O
knowledge -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
could -X- _ O
be -X- _ O
trained -X- _ O
more -X- _ O
effectively -X- _ O
if -X- _ O
it -X- _ O
receives -X- _ O
such -X- _ O
guidance -X- _ O
from -X- _ O
a -X- _ O
teacher -X- _ O
. -X- _ O
To -X- _ O
accomplish -X- _ O
this -X- _ O
goal -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
should -X- _ O
prioritize -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
ability -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
thus -X- _ O
allowing -X- _ O
the -X- _ O
student -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
on -X- _ O
the -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
influence -X- _ O
function -X- _ O
( -X- _ O
Pruthi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Koh -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
distillation -X- _ O
influence -X- _ O
to -X- _ O
estimate -X- _ O
how -X- _ O
distilling -X- _ O
on -X- _ O
each -X- _ O
training -X- _ O
sample -X- _ O
impacts -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
interpret -X- _ O
existing -X- _ O
L2 -X- _ O
T -X- _ O
methods -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
influence -X- _ O
function -X- _ O
, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
gain -X- _ O
a -X- _ O
deeper -X- _ O
understanding -X- _ O
of -X- _ O
their -X- _ O
limitations -X- _ O
. -X- _ O
The -X- _ O
optimization -X- _ O
process -X- _ O
of -X- _ O
existing -X- _ O
L2 -X- _ O
T -X- _ O
methods -X- _ O
are -X- _ O
often -X- _ O
impacted -X- _ O
by -X- _ O
outliers -X- _ O
, -X- _ O
because -X- _ O
they -X- _ O
assign -X- _ O
all -X- _ O
training -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
the -X- _ O
same -X- _ O
weight -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
our -X- _ O
L2 -X- _ O
T -X- _ O
framework -X- _ O
, -X- _ O
Learning -X- _ B-MethodName
GoodTeacher -X- _ I-MethodName
Matters -X- _ I-MethodName
( -X- _ O
LGTM -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
assigns -X- _ O
loss -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
samples -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
distillation -X- _ O
influence -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
LGTM -X- _ B-MethodName
enables -X- _ O
more -X- _ O
effective -X- _ O
knowledge -X- _ O
transfer -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1.We -X- _ O
propose -X- _ O
distillation -X- _ O
influence -X- _ O
to -X- _ O
quantify -X- _ O
how -X- _ O
distilling -X- _ O
from -X- _ O
each -X- _ O
training -X- _ O
sample -X- _ O
impacts -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
ability -X- _ O
. -X- _ O
2.We -X- _ O
introduce -X- _ O
finite -X- _ O
difference -X- _ O
approximation -X- _ O
to -X- _ O
efficiently -X- _ O
incorporate -X- _ O
distillation -X- _ O
influence -X- _ O
into -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
learning -X- _ O
process -X- _ O
. -X- _ O
3.Comparing -X- _ O
to -X- _ O
10 -X- _ O
common -X- _ O
KD -X- _ O
baselines -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
LGTM -X- _ B-MethodName
demonstrates -X- _ O
consistently -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
6 -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
2 -X- _ O
Notations -X- _ O
Suppose -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
denoted -X- _ O
as -X- _ O
T -X- _ O
( -X- _ O
· -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
denoted -X- _ O
as -X- _ O
S -X- _ O
( -X- _ O
· -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
corresponding -X- _ O
model -X- _ O
parameters -X- _ O
are -X- _ O
θandθ -X- _ O
. -X- _ O
ηandηare -X- _ O
the -X- _ O
learning -X- _ O
rates -X- _ O
adopted -X- _ O
for -X- _ O
model -X- _ O
update -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
|t|and|s|to -X- _ O
denote -X- _ O
the -X- _ O
dimensions -X- _ O
ofθandθ -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
θ∈Randθ∈R. -X- _ O
The -X- _ O
time -X- _ O
step -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
model -X- _ O
parameter -X- _ O
updates -X- _ O
are -X- _ O
denoted -X- _ O
as -X- _ O
mandm+ -X- _ O
1 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
track -X- _ O
the -X- _ O
evolution -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
labeled -X- _ O
training -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
a -X- _ O
batch -X- _ O
ofBtraining -X- _ O
samples -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
labels -X- _ O
are -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
z= -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
r -X- _ O
indicates -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
index -X- _ O
each -X- _ O
sample -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
batch -X- _ O
zasz -X- _ O
. -X- _ O
Similarly -X- _ O
for -X- _ O
validation -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
batch -X- _ O
of -X- _ O
samples -X- _ O
as -X- _ O
z= -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
eindicates -X- _ O
validation -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
notation -X- _ O
of -X- _ O
the -X- _ O
Jacobian -X- _ O
matrix -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
working -X- _ O
with -X- _ O
the -X- _ O
chain -X- _ O
rule -X- _ O
and -X- _ O
gradient -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
let -X- _ O
f -X- _ O
: -X- _ O
R→Rbe -X- _ O
a -X- _ O
differentiable -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
let -X- _ O
v∈ -X- _ O
Rbe -X- _ O
a -X- _ O
vector -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
notation∈R -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
Jacobian -X- _ O
matrix -X- _ O
of -X- _ O
f -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
dimensions -X- _ O
k×n -X- _ O
. -X- _ O
For -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
annotate -X- _ O
as∇. -X- _ O
We -X- _ O
use -X- _ O
Xto -X- _ O
denote -X- _ O
the -X- _ O
transpose -X- _ O
of -X- _ O
the -X- _ O
matrix -X- _ O
X. -X- _ O
3 -X- _ O
Revisiting -X- _ O
Learning -X- _ O
to -X- _ O
Teach -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
distillation -X- _ O
given -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Under -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
already -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
manner -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
either -X- _ O
derived -X- _ O
from -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
or -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
unsupervised -X- _ O
manner -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
Vanilla -X- _ O
distillation -X- _ O
The -X- _ O
typical -X- _ O
approach -X- _ O
to -X- _ O
knowledge -X- _ O
distillation -X- _ O
is -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
process -X- _ O
. -X- _ O
It -X- _ O
involves -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
teacher -X- _ O
model1991to -X- _ O
maximize -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
. -X- _ O
Once -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
has -X- _ O
converged -X- _ O
, -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
closely -X- _ O
imitate -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
optimization -X- _ O
objective -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
at -X- _ O
each -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
is -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
αL -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−α -X- _ O
) -X- _ O
L -X- _ O
( -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
update -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
follows -X- _ O
: -X- _ O
θ -X- _ O
= -X- _ O
θ−η∇L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
limitation -X- _ O
of -X- _ O
vanilla -X- _ O
distillation -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
allow -X- _ O
teacher -X- _ O
to -X- _ O
adjust -X- _ O
its -X- _ O
behavior -X- _ O
according -X- _ O
to -X- _ O
student -X- _ O
’s -X- _ O
feedback -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
parameters -X- _ O
are -X- _ O
fixed -X- _ O
during -X- _ O
the -X- _ O
distillation -X- _ O
process -X- _ O
. -X- _ O
Online -X- _ O
distillation -X- _ O
To -X- _ O
achieve -X- _ O
student -X- _ O
- -X- _ O
aware -X- _ O
distillation -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
proposed -X- _ O
which -X- _ O
involves -X- _ O
the -X- _ O
simultaneous -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
teacher -X- _ O
models -X- _ O
in -X- _ O
one -X- _ O
- -X- _ O
stage -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
minimizing -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
labels -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
constrained -X- _ O
to -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
through -X- _ O
the -X- _ O
minimization -X- _ O
of -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
between -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
αL -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−α -X- _ O
) -X- _ O
L -X- _ O
( -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
The -X- _ O
training -X- _ O
process -X- _ O
involves -X- _ O
iteratively -X- _ O
updating -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
both -X- _ O
models -X- _ O
: -X- _ O
θ -X- _ O
= -X- _ O
θ−η∇L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
θ -X- _ O
= -X- _ O
θ−η∇L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Through -X- _ O
iterative -X- _ O
update -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
learning -X- _ O
curve -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
improves -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
given -X- _ O
task -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
focuses -X- _ O
on -X- _ O
transferring -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
on -X- _ O
training -X- _ O
set -X- _ O
without -X- _ O
explicitly -X- _ O
considering -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
will -X- _ O
perform -X- _ O
on -X- _ O
unseen -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
might -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
only -X- _ O
memorizing -X- _ O
the -X- _ O
training -X- _ O
examples -X- _ O
without -X- _ O
generalizing -X- _ O
well -X- _ O
to -X- _ O
new -X- _ O
ones -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
.Meta -X- _ O
distillation -X- _ O
Meta -X- _ O
distillation -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
technique -X- _ O
that -X- _ O
takes -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
feedback -X- _ O
from -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
and -X- _ O
guides -X- _ O
the -X- _ O
optimization -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
The -X- _ O
generalization -X- _ O
error -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
computed -X- _ O
between -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
labels -X- _ O
and -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
L -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Meta -X- _ O
distillation -X- _ O
decomposes -X- _ O
models -X- _ O
’ -X- _ O
learning -X- _ O
process -X- _ O
into -X- _ O
two -X- _ O
stages -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
stage -X- _ O
is -X- _ O
to -X- _ O
finetune -X- _ O
a -X- _ O
good -X- _ O
teacher -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
similar -X- _ O
to -X- _ O
vanilla -X- _ O
distillation -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
involves -X- _ O
iterative -X- _ O
update -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
compared -X- _ O
to -X- _ O
online -X- _ O
distillation -X- _ O
, -X- _ O
meta -X- _ O
distillation -X- _ O
obtains -X- _ O
the -X- _ O
student -X- _ O
feedback -X- _ O
from -X- _ O
validation -X- _ O
data -X- _ O
, -X- _ O
not -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
first -X- _ O
updated -X- _ O
through -X- _ O
the -X- _ O
standard -X- _ O
distillation -X- _ O
process -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
distillation -X- _ O
loss -X- _ O
in -X- _ O
eq -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
optimized -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
updated -X- _ O
student -X- _ O
’s -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
ensures -X- _ O
it -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
student -X- _ O
towards -X- _ O
better -X- _ O
generalization -X- _ O
. -X- _ O
During -X- _ O
this -X- _ O
process -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
is -X- _ O
only -X- _ O
trained -X- _ O
for -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
knowledge -X- _ O
transfer -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
updated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
θ -X- _ O
= -X- _ O
θ−η∇L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
The -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
then -X- _ O
updated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
θ -X- _ O
= -X- _ O
θ−η∇L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
optimization -X- _ O
objective -X- _ O
of -X- _ O
meta -X- _ O
distillation -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
degraded -X- _ O
teacher -X- _ O
model -X- _ O
because -X- _ O
it -X- _ O
only -X- _ O
receives -X- _ O
supervision -X- _ O
from -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
This -X- _ O
will -X- _ O
prevent -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
from -X- _ O
continuing -X- _ O
to -X- _ O
learn -X- _ O
and -X- _ O
improve -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
stage -X- _ O
, -X- _ O
thus -X- _ O
impeding -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
new -X- _ O
data -X- _ O
. -X- _ O
4 -X- _ O
Methods -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
aforementioned -X- _ O
limitations -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
our -X- _ O
L2 -X- _ O
T -X- _ O
framework -X- _ O
, -X- _ O
Learning -X- _ B-MethodName
Good -X- _ I-MethodName
Teacher -X- _ I-MethodName
Matters -X- _ I-MethodName
( -X- _ O
LGTM -X- _ B-MethodName
) -X- _ O
to -X- _ O
enable -X- _ O
more -X- _ O
effective -X- _ O
knowledge -X- _ O
distillation -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
introduce -X- _ O
distillation -X- _ O
influence -X- _ O
, -X- _ O
which -X- _ O
estimates -X- _ O
how -X- _ O
much -X- _ O
will -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
performance -X- _ O
on -X- _ O
validation -X- _ O
data -X- _ O
change1992if -X- _ O
we -X- _ O
put -X- _ O
one -X- _ O
training -X- _ O
sample -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
distillation -X- _ O
process -X- _ O
. -X- _ O
Afterwards -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
efficient -X- _ O
training -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
finite -X- _ O
difference -X- _ O
approximation -X- _ O
for -X- _ O
incorporating -X- _ O
distillation -X- _ O
influence -X- _ O
into -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
update -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
interpret -X- _ O
current -X- _ O
L2 -X- _ O
T -X- _ O
methods -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
influence -X- _ O
function -X- _ O
. -X- _ O
Distillation -X- _ O
influence -X- _ O
Influence -X- _ O
function -X- _ O
( -X- _ O
Pruthi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Koh -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
measuring -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
predictions -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
identify -X- _ O
instances -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
disproportionate -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
behavior -X- _ O
, -X- _ O
whether -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
status -X- _ O
as -X- _ O
outliers -X- _ O
or -X- _ O
due -X- _ O
to -X- _ O
incorrect -X- _ O
labeling -X- _ O
( -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ghorbani -X- _ O
and -X- _ O
Zou -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Hara -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
calculating -X- _ O
the -X- _ O
influence -X- _ O
function -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
prediction -X- _ O
would -X- _ O
be -X- _ O
altered -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
operations -X- _ O
on -X- _ O
that -X- _ O
sample -X- _ O
. -X- _ O
In -X- _ O
vanilla -X- _ O
distillation -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
zas -X- _ O
the -X- _ O
gradient -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
training -X- _ O
sample -X- _ O
zand -X- _ O
the -X- _ O
validation -X- _ O
batch -X- _ O
z -X- _ O
: -X- _ O
The -X- _ O
detailed -X- _ O
derivation -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
appendix -X- _ O
A. -X- _ O
The -X- _ O
influence -X- _ O
reflects -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
knowledge -X- _ O
gained -X- _ O
from -X- _ O
a -X- _ O
particular -X- _ O
sample -X- _ O
generalizes -X- _ O
. -X- _ O
It -X- _ O
follows -X- _ O
that -X- _ O
the -X- _ O
teacher -X- _ O
should -X- _ O
focus -X- _ O
on -X- _ O
teaching -X- _ O
the -X- _ O
student -X- _ O
to -X- _ O
capture -X- _ O
training -X- _ O
samples -X- _ O
that -X- _ O
have -X- _ O
the -X- _ O
highest -X- _ O
distillation -X- _ O
influences -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
sample -X- _ O
influence -X- _ O
into -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
we -X- _ O
adjust -X- _ O
the -X- _ O
loss -X- _ O
weight -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
distillation -X- _ O
influence -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
relative -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
, -X- _ O
and -X- _ O
helps -X- _ O
to -X- _ O
control -X- _ O
how -X- _ O
much -X- _ O
each -X- _ O
sample -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
learning -X- _ O
process -X- _ O
. -X- _ O
Samples -X- _ O
that -X- _ O
are -X- _ O
deemed -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
beneficial -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
are -X- _ O
assigned -X- _ O
higher -X- _ O
weights -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
propose -X- _ O
training -X- _ O
the -X- _ O
teacher -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
: -X- _ O
where -X- _ O
w -X- _ O
= -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
including -X- _ O
the -X- _ O
influence -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
distillation -X- _ O
loss -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
tailor -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
to -X- _ O
better -X- _ O
suit -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
Algorithm -X- _ O
1 -X- _ O
LGTM -X- _ B-MethodName
Finite -X- _ O
difference -X- _ O
approximation -X- _ O
For -X- _ O
standard -X- _ O
neural -X- _ O
network -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
often -X- _ O
compute -X- _ O
a -X- _ O
consolidated -X- _ O
gradient -X- _ O
for -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
of -X- _ O
Btraining -X- _ O
samples -X- _ O
to -X- _ O
enhance -X- _ O
computational -X- _ O
efficiency -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
determining -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
, -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
per -X- _ O
- -X- _ O
sample -X- _ O
gradient -X- _ O
L -X- _ O
( -X- _ O
T -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
will -X- _ O
slow -X- _ O
down -X- _ O
the -X- _ O
training -X- _ O
by -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
B. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
a -X- _ O
naive -X- _ O
implementation -X- _ O
is -X- _ O
memory -X- _ O
intensive -X- _ O
, -X- _ O
because -X- _ O
it -X- _ O
requires -X- _ O
to -X- _ O
keep -X- _ O
a -X- _ O
copy -X- _ O
of -X- _ O
∇L -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
efficient -X- _ O
method -X- _ O
for -X- _ O
updating -X- _ O
the -X- _ O
teacher -X- _ O
with -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
by -X- _ O
utilizing -X- _ O
finite -X- _ O
difference -X- _ O
( -X- _ O
Gleich -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
technique -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
numerical -X- _ O
analysis -X- _ O
for -X- _ O
approximating -X- _ O
the -X- _ O
derivative -X- _ O
of -X- _ O
a -X- _ O
function -X- _ O
at -X- _ O
a -X- _ O
given -X- _ O
point -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
( -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
approximate -X- _ O
L -X- _ O
by -X- _ O
where -X- _ O
θ -X- _ O
= -X- _ O
θ±ϵL -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
andϵis -X- _ O
a -X- _ O
small -X- _ O
scalar -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
method -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
finite -X- _ O
difference -X- _ O
is -X- _ O
computationally -X- _ O
efficient -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
only -X- _ O
requires -X- _ O
two -X- _ O
forward -X- _ O
passes -X- _ O
for -X- _ O
θand -X- _ O
one -X- _ O
backward -X- _ O
pass -X- _ O
for -X- _ O
θfor -X- _ O
a -X- _ O
single -X- _ O
batch -X- _ O
, -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
a -X- _ O
naive -X- _ O
implementation -X- _ O
which -X- _ O
requires -X- _ O
Bforward -X- _ O
and -X- _ O
backward -X- _ O
passes -X- _ O
for -X- _ O
θand -X- _ O
one -X- _ O
backward -X- _ O
pass -X- _ O
for -X- _ O
θ -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
more -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
derivation -X- _ O
in -X- _ O
appendix -X- _ O
B. -X- _ O
Teacher -X- _ O
’s -X- _ O
auxiliary -X- _ O
loss -X- _ O
Inspired -X- _ O
by -X- _ O
( -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
self -X- _ O
- -X- _ O
evolution -X- _ O
and -X- _ O
transferability -X- _ O
of -X- _ O
the -X- _ O
teacher1993 -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
incorporate -X- _ O
the -X- _ O
loss -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
as -X- _ O
Linto -X- _ O
the -X- _ O
final -X- _ O
objective -X- _ O
: -X- _ O
where -X- _ O
αis -X- _ O
the -X- _ O
loss -X- _ O
ratio -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
allows -X- _ O
the -X- _ O
teacher -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
abilities -X- _ O
and -X- _ O
provide -X- _ O
more -X- _ O
personalized -X- _ O
guidance -X- _ O
while -X- _ O
improving -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
capability -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
algorithm -X- _ O
of -X- _ O
LGTM -X- _ B-MethodName
in -X- _ O
algorithm -X- _ O
1 -X- _ O
. -X- _ O
Relationship -X- _ O
with -X- _ O
other -X- _ O
L2 -X- _ O
T -X- _ O
methods -X- _ O
Here -X- _ O
we -X- _ O
interpret -X- _ O
current -X- _ O
learning -X- _ O
to -X- _ O
teach -X- _ O
methods -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
influence -X- _ O
function -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
online -X- _ O
distillation -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
assumed -X- _ O
that -X- _ O
all -X- _ O
training -X- _ O
samples -X- _ O
possess -X- _ O
an -X- _ O
equivalent -X- _ O
distillation -X- _ O
influence -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
reducing -X- _ O
the -X- _ O
transfer -X- _ O
difficulty -X- _ O
of -X- _ O
all -X- _ O
training -X- _ O
samples -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
key -X- _ O
differentiating -X- _ O
factor -X- _ O
between -X- _ O
meta -X- _ O
distillation -X- _ O
and -X- _ O
online -X- _ O
distillation -X- _ O
is -X- _ O
the -X- _ O
utilization -X- _ O
of -X- _ O
a -X- _ O
dynamic -X- _ O
loss -X- _ O
weight -X- _ O
. -X- _ O
We -X- _ O
interpret -X- _ O
this -X- _ O
weight -X- _ O
as -X- _ O
a -X- _ O
measure -X- _ O
of -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
batch -X- _ O
zon -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
it -X- _ O
reflects -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
gradients -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
batches -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
batch -X- _ O
zon -X- _ O
the -X- _ O
validation -X- _ O
batch -X- _ O
z -X- _ O
( -X- _ O
as -X- _ O
detailed -X- _ O
in -X- _ O
appendix -X- _ O
C -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
this -X- _ O
weight -X- _ O
functions -X- _ O
primarily -X- _ O
as -X- _ O
an -X- _ O
adaptive -X- _ O
learning -X- _ O
rate -X- _ O
, -X- _ O
adjusting -X- _ O
the -X- _ O
gradient -X- _ O
step -X- _ O
proportionally -X- _ O
to -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
similarity -X- _ O
in -X- _ O
gradients -X- _ O
. -X- _ O
We -X- _ O
illustrate -X- _ O
the -X- _ O
general -X- _ O
workflow -X- _ O
of -X- _ O
vanilla -X- _ O
distillation -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
, -X- _ O
meta -X- _ O
distillation -X- _ O
and -X- _ O
LGTM -X- _ B-MethodName
in -X- _ O
fig -X- _ O
. -X- _ O
1.5 -X- _ O
Experiments -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
describe -X- _ O
our -X- _ O
experiment -X- _ O
setup -X- _ O
including -X- _ O
datasets -X- _ O
and -X- _ O
baselines -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
5.1 -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
proposed -X- _ O
LGTM -X- _ B-MethodName
to -X- _ O
meta -X- _ O
distillation -X- _ O
to -X- _ O
gain -X- _ O
some -X- _ O
basic -X- _ O
understanding -X- _ O
of -X- _ O
how -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
feedback -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
5.2 -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
5.3 -X- _ O
we -X- _ O
compare -X- _ O
to -X- _ O
10 -X- _ O
widely -X- _ O
adopted -X- _ O
knowledge -X- _ O
distillation -X- _ O
baselines -X- _ O
and -X- _ O
show -X- _ O
consistently -X- _ O
better -X- _ O
results -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
demonstrate -X- _ O
how -X- _ O
distillation -X- _ O
influence -X- _ O
works -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
5.4 -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
ablation -X- _ O
studies -X- _ O
of -X- _ O
LGTM -X- _ B-MethodName
in -X- _ O
Sec -X- _ O
. -X- _ O
5.5 -X- _ O
. -X- _ O
5.1 -X- _ O
Experimental -X- _ O
Setup -X- _ O
Datasets -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
on -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
in -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
: -X- _ O
MRPC -X- _ B-DatasetName
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
RTE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
SST-2 -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
QNLI -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
QQP -X- _ B-DatasetName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
MRPC -X- _ B-DatasetName
and -X- _ O
QQP -X- _ B-DatasetName
, -X- _ O
we -X- _ O
report -X- _ O
both -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
And -X- _ O
for -X- _ O
other -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
Baselines -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
LGTM -X- _ B-MethodName
with -X- _ O
10 -X- _ O
baselines -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
KD -X- _ B-MethodName
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
2 -X- _ O
) -X- _ O
PKD -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
3 -X- _ O
) -X- _ O
SKD -X- _ B-MethodName
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
4 -X- _ O
) -X- _ O
DIST -X- _ B-MethodName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
5 -X- _ O
) -X- _ O
TAKD -X- _ B-MethodName
( -X- _ O
Mirzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
6 -X- _ O
) -X- _ O
RCO -X- _ B-MethodName
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
7 -X- _ O
) -X- _ O
DML -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
8 -X- _ O
) -X- _ O
ProKT -X- _ B-MethodName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
9 -X- _ O
) -X- _ O
PESF -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
( -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
10 -X- _ O
) -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Training -X- _ O
setup -X- _ O
Following -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
distill -X- _ O
BERTBase -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
a -X- _ O
6 -X- _ O
- -X- _ O
layer -X- _ O
BERT -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
baselines -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
both -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
and -X- _ O
LGTM -X- _ B-MethodName
utilize -X- _ O
feedback -X- _ O
from -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
in -X- _ O
the -X- _ O
calculation -X- _ O
of -X- _ O
the -X- _ O
distillation -X- _ O
loss.1994 -X- _ O
Detailed -X- _ O
training -X- _ O
hyperparameters -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
appendix -X- _ O
D. -X- _ O
5.2 -X- _ O
Comparison -X- _ O
with -X- _ O
Meta -X- _ O
Distillation -X- _ O
Given -X- _ O
our -X- _ O
proposed -X- _ O
LGTM -X- _ B-MethodName
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
meta -X- _ O
distillation -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
, -X- _ O
here -X- _ O
we -X- _ O
first -X- _ O
conduct -X- _ O
a -X- _ O
comparison -X- _ O
between -X- _ O
LGTM -X- _ B-MethodName
and -X- _ O
a -X- _ O
specific -X- _ O
meta -X- _ O
distillation -X- _ O
method -X- _ O
, -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
adopting -X- _ O
distillation -X- _ O
influence -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
for -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
( -X- _ O
blue -X- _ O
curve -X- _ O
) -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
validation -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
gradually -X- _ O
increases -X- _ O
in -X- _ O
later -X- _ O
iterations -X- _ O
while -X- _ O
the -X- _ O
validation -X- _ O
accuracy -X- _ B-MetricName
keeps -X- _ O
improving -X- _ O
until -X- _ O
a -X- _ O
stable -X- _ O
plateau -X- _ O
. -X- _ O
This -X- _ O
clearly -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
experiencing -X- _ O
overfitting -X- _ O
. -X- _ O
One -X- _ O
possible -X- _ O
explanation -X- _ O
is -X- _ O
that -X- _ O
excessive -X- _ O
emphasis -X- _ O
is -X- _ O
placed -X- _ O
on -X- _ O
certain -X- _ O
training -X- _ O
samples -X- _ O
that -X- _ O
generate -X- _ O
high -X- _ O
loss -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
hard -X- _ O
samples -X- _ O
or -X- _ O
outliers -X- _ O
. -X- _ O
This -X- _ O
negatively -X- _ O
impacts -X- _ O
the -X- _ O
generalization -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
overfitting -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
difference -X- _ O
between -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
and -X- _ O
our -X- _ O
LGTM -X- _ B-MethodName
( -X- _ O
orange -X- _ O
curve -X- _ O
) -X- _ O
is -X- _ O
that -X- _ O
LGTM -X- _ B-MethodName
accounts -X- _ O
for -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
sample -X- _ O
distillation -X- _ O
influence -X- _ O
while -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
treats -X- _ O
all -X- _ O
training -X- _ O
samples -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
equally -X- _ O
. -X- _ O
This -X- _ O
enables -X- _ O
the -X- _ O
filtering -X- _ O
of -X- _ O
samples -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
detrimental -X- _ O
effect -X- _ O
on -X- _ O
generalization -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
steady -X- _ O
decrease -X- _ O
of -X- _ O
validation -X- _ O
loss -X- _ O
( -X- _ O
fig -X- _ O
. -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
an -X- _ O
improved -X- _ O
validation -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
fig -X- _ O
. -X- _ O
2 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
only -X- _ O
impart -X- _ O
their -X- _ O
current -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
actively -X- _ O
seek -X- _ O
out -X- _ O
new -X- _ O
information -X- _ O
and -X- _ O
perspectives -X- _ O
to -X- _ O
improve -X- _ O
their -X- _ O
own -X- _ O
understanding -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
beseen -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
2 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
LGTM -X- _ B-MethodName
allows -X- _ O
for -X- _ O
the -X- _ O
effective -X- _ O
transfer -X- _ O
of -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
by -X- _ O
incorporating -X- _ O
the -X- _ O
teacher -X- _ O
auxiliary -X- _ O
loss -X- _ O
. -X- _ O
The -X- _ O
validation -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
keeps -X- _ O
improving -X- _ O
for -X- _ O
LGTM -X- _ B-MethodName
, -X- _ O
but -X- _ O
drops -X- _ O
quickly -X- _ O
for -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
. -X- _ O
5.3 -X- _ O
Main -X- _ O
Results -X- _ O
Here -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
table -X- _ O
1 -X- _ O
, -X- _ O
LGTM -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
10 -X- _ O
baselines -X- _ O
including -X- _ O
recent -X- _ O
strong -X- _ O
KD -X- _ O
methods -X- _ O
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
highlights -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
more -X- _ O
specific -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
those -X- _ O
rely -X- _ O
on -X- _ O
carefully -X- _ O
designed -X- _ O
training -X- _ O
pipelines -X- _ O
or -X- _ O
loss -X- _ O
functions -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
PKD -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
SKD -X- _ B-MethodName
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
DIST -X- _ B-MethodName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
PKD -X- _ B-MethodName
proposes -X- _ O
two -X- _ O
distillation -X- _ O
schemes -X- _ O
, -X- _ O
to -X- _ O
enable -X- _ O
the -X- _ O
student -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
multiple -X- _ O
intermediate -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
for -X- _ O
incremental -X- _ O
knowledge -X- _ O
extraction -X- _ O
. -X- _ O
SKD -X- _ B-MethodName
and -X- _ O
DIST -X- _ B-MethodName
both -X- _ O
modify -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
loss -X- _ O
to -X- _ O
narrow -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
LGTM -X- _ B-MethodName
also -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
teacher -X- _ O
assistant -X- _ O
models -X- _ O
as -X- _ O
TAKD -X- _ B-MethodName
( -X- _ O
Mirzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
RCO -X- _ B-MethodName
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
online -X- _ O
distillation -X- _ O
methods -X- _ O
, -X- _ O
LGTM -X- _ B-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
DML -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
ProKT -X- _ B-MethodName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
PESF -X- _ B-MethodName
- -X- _ I-MethodName
KD -X- _ I-MethodName
( -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
highlights -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
incorporating -X- _ O
student -X- _ O
’s -X- _ O
feedback -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
An -X- _ O
overemphasis -X- _ O
on -X- _ O
knowledge -X- _ O
transfer -X- _ O
from1995 -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
overfitting -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
outputs -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
reduction -X- _ O
in -X- _ O
its -X- _ O
generalization -X- _ O
abilities -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
unlike -X- _ O
meta -X- _ O
distillation -X- _ O
methods -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Meta -X- _ B-MethodName
Distill -X- _ I-MethodName
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
allows -X- _ O
for -X- _ O
computing -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
individual -X- _ O
training -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
filtering -X- _ O
out -X- _ O
samples -X- _ O
that -X- _ O
may -X- _ O
hurt -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
LGTM -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
student -X- _ O
to -X- _ O
develop -X- _ O
general -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
overall -X- _ O
task -X- _ O
while -X- _ O
alleviate -X- _ O
the -X- _ O
overfitting -X- _ O
issue -X- _ O
. -X- _ O
5.4 -X- _ O
Analysis -X- _ O
of -X- _ O
Distillation -X- _ O
Influence -X- _ O
We -X- _ O
further -X- _ O
explore -X- _ O
the -X- _ O
trend -X- _ O
of -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
samples -X- _ O
during -X- _ O
the -X- _ O
real -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
MRPC -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
two -X- _ O
representative -X- _ O
samples -X- _ O
presented -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
3 -X- _ O
to -X- _ O
visualize -X- _ O
the -X- _ O
trend -X- _ O
of -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
and -X- _ O
its -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
prediction -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
side -X- _ O
of -X- _ O
fig -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
during -X- _ O
the -X- _ O
initial -X- _ O
stages -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
both -X- _ O
the -X- _ O
teacher -X- _ O
( -X- _ O
green -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
( -X- _ O
orange -X- _ O
) -X- _ O
have -X- _ O
made -X- _ O
wrong -X- _ O
predictions -X- _ O
. -X- _ O
It -X- _ O
might -X- _ O
suggest -X- _ O
that -X- _ O
this -X- _ O
sample -X- _ O
poses -X- _ O
a -X- _ O
significant -X- _ O
challenge -X- _ O
for -X- _ O
both -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
want -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
mimic -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
teacher -X- _ O
models -X- _ O
too -X- _ O
much -X- _ O
becauseteacher -X- _ O
model -X- _ O
is -X- _ O
also -X- _ O
wrong -X- _ O
about -X- _ O
this -X- _ O
sample -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
gradually -X- _ O
adjust -X- _ O
the -X- _ O
loss -X- _ O
weight -X- _ O
to -X- _ O
negative -X- _ O
, -X- _ O
indicating -X- _ O
we -X- _ O
will -X- _ O
filter -X- _ O
out -X- _ O
this -X- _ O
misleading -X- _ O
training -X- _ O
sample -X- _ O
for -X- _ O
now -X- _ O
to -X- _ O
make -X- _ O
both -X- _ O
models -X- _ O
learn -X- _ O
faster -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
first -X- _ O
escapes -X- _ O
this -X- _ O
predicament -X- _ O
. -X- _ O
Then -X- _ O
through -X- _ O
student -X- _ O
feedback -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
also -X- _ O
learns -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
correct -X- _ O
prediction -X- _ O
. -X- _ O
Finally -X- _ O
as -X- _ O
training -X- _ O
progresses -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
observed -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
the -X- _ O
teacher -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
correctly -X- _ O
classify -X- _ O
this -X- _ O
sample -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
stabilizing -X- _ O
at -X- _ O
a -X- _ O
near -X- _ O
- -X- _ O
zero -X- _ O
value -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
another -X- _ O
example -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
3 -X- _ O
right -X- _ O
, -X- _ O
where -X- _ O
both -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
the -X- _ O
teacher -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
accurately -X- _ O
predict -X- _ O
a -X- _ O
given -X- _ O
sample -X- _ O
. -X- _ O
It -X- _ O
might -X- _ O
suggest -X- _ O
this -X- _ O
sample -X- _ O
is -X- _ O
too -X- _ O
easy -X- _ O
for -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
give -X- _ O
this -X- _ O
sample -X- _ O
a -X- _ O
high -X- _ O
positive -X- _ O
weight -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
student -X- _ O
- -X- _ O
friendly -X- _ O
decision -X- _ O
boundary -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
curriculum -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
easy -X- _ O
samples -X- _ O
to -X- _ O
hard -X- _ O
ones -X- _ O
in -X- _ O
curriculum -X- _ O
learning -X- _ O
( -X- _ O
Soviany -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
visualize -X- _ O
an -X- _ O
average -X- _ O
trend -X- _ O
of -X- _ O
distillation -X- _ O
influence -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
4 -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
64 -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
randomly -X- _ O
chosen -X- _ O
from -X- _ O
MRPC -X- _ B-DatasetName
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
is -X- _ O
usually -X- _ O
insignificant -X- _ O
in -X- _ O
the -X- _ O
beginning -X- _ O
and -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
but -X- _ O
fluctuates -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
reasonable -X- _ O
since -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
assigning -X- _ O
varying -X- _ O
weights -X- _ O
to -X- _ O
each -X- _ O
sample -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
filtering -X- _ O
difficult -X- _ O
samples -X- _ O
and -X- _ O
focusing -X- _ O
on -X- _ O
samples -X- _ O
better -X- _ O
for -X- _ O
generalization.1996 -X- _ O
5.5 -X- _ O
Ablation -X- _ O
Study -X- _ O
Given -X- _ O
limited -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
three -X- _ O
studies -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
and -X- _ O
show -X- _ O
more -X- _ O
ablation -X- _ O
studies -X- _ O
in -X- _ O
appendix -X- _ O
E. -X- _ O
Finite -X- _ O
difference -X- _ O
approximation -X- _ O
Recall -X- _ O
in -X- _ O
section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
finite -X- _ O
difference -X- _ O
approximation -X- _ O
( -X- _ O
FDA -X- _ O
) -X- _ O
for -X- _ O
estimating -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
slowness -X- _ O
of -X- _ O
computing -X- _ O
per -X- _ O
- -X- _ O
sample -X- _ O
gradients -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
table -X- _ O
3 -X- _ O
, -X- _ O
here -X- _ O
we -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
experiment -X- _ O
on -X- _ O
the -X- _ O
MRPC -X- _ B-DatasetName
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
its -X- _ O
usefulness -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
with -X- _ O
FDA -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
only -X- _ O
requires -X- _ O
11 -X- _ O
minutes -X- _ O
to -X- _ O
complete -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
naive -X- _ O
training -X- _ O
without -X- _ O
FDA -X- _ O
requires -X- _ O
117 -X- _ O
minutes -X- _ O
. -X- _ O
Such -X- _ O
a -X- _ O
significant -X- _ O
reduction -X- _ O
in -X- _ O
training -X- _ O
time -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
more -X- _ O
than -X- _ O
10×speedup -X- _ O
) -X- _ O
highlights -X- _ O
the -X- _ O
computational -X- _ O
efficiency -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
FDA -X- _ O
technique -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
assess -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
MRPC -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
observe -X- _ O
that -X- _ O
training -X- _ O
with -X- _ O
FDA -X- _ O
result -X- _ O
in -X- _ O
an -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
90.4 -X- _ B-MetricValue
, -X- _ O
while -X- _ O
training -X- _ O
without -X- _ O
FDA -X- _ B-MetricName
resulted -X- _ O
in -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
90.7 -X- _ B-MetricValue
. -X- _ O
There -X- _ O
is -X- _ O
only -X- _ O
a -X- _ O
slight -X- _ O
drop -X- _ O
in -X- _ O
performance -X- _ O
with -X- _ O
the -X- _ O
approximation -X- _ O
. -X- _ O
Distillation -X- _ O
loss -X- _ O
There -X- _ O
are -X- _ O
other -X- _ O
distillation -X- _ O
losses -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
knowledge -X- _ O
distillation -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
evaluate -X- _ O
whether -X- _ O
LGTM -X- _ B-MethodName
can -X- _ O
adapt -X- _ O
to -X- _ O
those -X- _ O
objectives -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
modified -X- _ O
loss -X- _ O
used -X- _ O
in -X- _ O
DIST -X- _ B-MethodName
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
common -X- _ O
mean -X- _ O
squared -X- _ O
error -X- _ O
( -X- _ O
MSE -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
table -X- _ O
2 -X- _ O
, -X- _ O
our -X- _ O
LGTM -X- _ O
consistently -X- _ O
beats -X- _ O
the -X- _ O
original -X- _ O
methods -X- _ O
that -X- _ O
utilize -X- _ O
these -X- _ O
distillation -X- _ O
objectives -X- _ O
, -X- _ O
which -X- _ O
validates -X- _ O
the -X- _ O
compatibility -X- _ O
of -X- _ O
LGTM -X- _ B-MethodName
to -X- _ O
different -X- _ O
distillation -X- _ O
objectives -X- _ O
. -X- _ O
Student -X- _ O
model -X- _ O
size -X- _ O
Here -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
in -X- _ O
scenarios -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
larger -X- _ O
capacity -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
knowledge -X- _ O
distillation -X- _ O
from -X- _ O
a -X- _ O
BERT -X- _ O
- -X- _ O
Base -X- _ O
model -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
a -X- _ O
4 -X- _ O
- -X- _ O
layer -X- _ O
BERT -X- _ O
model -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
table -X- _ O
4 -X- _ O
, -X- _ O
LGTM -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
other -X- _ O
baselines -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
except -X- _ O
competitive -X- _ O
results -X- _ O
on -X- _ O
SST-2 -X- _ B-DatasetName
. -X- _ O
This -X- _ O
indicates -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
which -X- _ O
suggests -X- _ O
its -X- _ O
wide -X- _ O
usage -X- _ O
in -X- _ O
various -X- _ O
knowledge -X- _ O
distillation -X- _ O
settings -X- _ O
. -X- _ O
6 -X- _ O
Related -X- _ O
Work -X- _ O
The -X- _ O
core -X- _ O
of -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
relies -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
formulate -X- _ O
and -X- _ O
transfer -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
teacher -X- _ O
to -X- _ O
student -X- _ O
. -X- _ O
Three1997 -X- _ O
key -X- _ O
aspects -X- _ O
are -X- _ O
typically -X- _ O
considered -X- _ O
: -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
from -X- _ O
which -X- _ O
knowledge -X- _ O
is -X- _ O
transferred -X- _ O
( -X- _ O
learning -X- _ O
target -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
on -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
( -X- _ O
learning -X- _ O
material -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
that -X- _ O
defines -X- _ O
the -X- _ O
learning -X- _ O
objective -X- _ O
. -X- _ O
Efforts -X- _ O
have -X- _ O
been -X- _ O
made -X- _ O
to -X- _ O
make -X- _ O
knowledge -X- _ O
distillation -X- _ O
more -X- _ O
studentfriendly -X- _ O
by -X- _ O
reducing -X- _ O
the -X- _ O
difficulties -X- _ O
in -X- _ O
these -X- _ O
aspects -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
learning -X- _ O
target -X- _ O
, -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Mirzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
introduce -X- _ O
teacher -X- _ O
assistant -X- _ O
models -X- _ O
of -X- _ O
intermediate -X- _ O
timestep -X- _ O
or -X- _ O
training -X- _ O
time -X- _ O
step -X- _ O
respectively -X- _ O
to -X- _ O
narrow -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
updating -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
jointly -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
teacher -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
state -X- _ O
. -X- _ O
Rao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
trains -X- _ O
for -X- _ O
more -X- _ O
timestep -X- _ O
to -X- _ O
smooth -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
for -X- _ O
a -X- _ O
easier -X- _ O
transfer -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
learning -X- _ O
material -X- _ O
, -X- _ O
TinyBERT -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
suggests -X- _ O
augmenting -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
more -X- _ O
diverse -X- _ O
. -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
proposes -X- _ O
training -X- _ O
the -X- _ O
student -X- _ O
with -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
easy -X- _ O
for -X- _ O
the -X- _ O
teacher -X- _ O
but -X- _ O
difficult -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
With -X- _ O
respect -X- _ O
to -X- _ O
learning -X- _ O
objective -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
common -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
probabilistic -X- _ O
prediction -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
using -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
can -X- _ O
cause -X- _ O
problems -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
soft -X- _ O
the -X- _ O
constraint -X- _ O
by -X- _ O
a -X- _ O
more -X- _ O
tolerated -X- _ O
loss -X- _ O
. -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
propose -X- _ O
using -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
performance -X- _ O
as -X- _ O
the -X- _ O
optimization -X- _ O
objective -X- _ O
for -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
teacher -X- _ O
to -X- _ O
optimize -X- _ O
its -X- _ O
knowledge -X- _ O
transfer -X- _ O
based -X- _ O
on -X- _ O
feedback -X- _ O
from -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022b -X- _ O
) -X- _ O
proposes -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
appropriate -X- _ O
knowledge -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
optimization -X- _ O
of -X- _ O
the -X- _ O
student.7 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
revisit -X- _ O
several -X- _ O
learning -X- _ O
to -X- _ O
teach -X- _ O
paradigms -X- _ O
in -X- _ O
knowledge -X- _ O
distillation -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
propose -X- _ O
distillation -X- _ O
influence -X- _ O
to -X- _ O
determine -X- _ O
how -X- _ O
distilling -X- _ O
from -X- _ O
each -X- _ O
training -X- _ O
sample -X- _ O
impacts -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
generalization -X- _ O
ability -X- _ O
. -X- _ O
By -X- _ O
visualizing -X- _ O
how -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
changes -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
a -X- _ O
simple -X- _ O
re -X- _ O
- -X- _ O
weighting -X- _ O
using -X- _ O
distillation -X- _ O
influence -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
help -X- _ O
student -X- _ O
training -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
reduce -X- _ O
overfitting -X- _ O
. -X- _ O
Built -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
distillation -X- _ O
influence -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
our -X- _ O
learning -X- _ O
to -X- _ O
teach -X- _ O
framework -X- _ O
, -X- _ O
LGTM -X- _ B-MethodName
, -X- _ O
that -X- _ O
consistently -X- _ O
outperforms -X- _ O
existing -X- _ O
knowledge -X- _ O
distillation -X- _ O
methods -X- _ O
on -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
Limitations -X- _ O
Although -X- _ O
LGTM -X- _ B-MethodName
has -X- _ O
demonstrated -X- _ O
superior -X- _ O
performance -X- _ O
in -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
knowledge -X- _ O
distillation -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
investigating -X- _ O
the -X- _ O
potential -X- _ O
benefits -X- _ O
of -X- _ O
combining -X- _ O
LGTM -X- _ B-MethodName
with -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
experiments -X- _ O
have -X- _ O
been -X- _ O
limited -X- _ O
to -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
relatively -X- _ O
simple -X- _ O
for -X- _ O
current -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
future -X- _ O
work -X- _ O
should -X- _ O
explore -X- _ O
the -X- _ O
application -X- _ O
of -X- _ O
LGTM -X- _ B-MethodName
to -X- _ O
more -X- _ O
complex -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O
Ethics -X- _ O
Statement -X- _ O
During -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
are -X- _ O
initialized -X- _ O
from -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
vulnerable -X- _ O
to -X- _ O
potential -X- _ O
ethical -X- _ O
and -X- _ O
social -X- _ O
risk -X- _ O
as -X- _ O
mentioned -X- _ O
by -X- _ O
Bommasani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Weidinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
exposed -X- _ O
to -X- _ O
similar -X- _ O
social -X- _ O
risks -X- _ O
of -X- _ O
large -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Acknowledgements -X- _ O
We -X- _ O
thank -X- _ O
Yongfei -X- _ O
Liu -X- _ O
and -X- _ O
Zhengkun -X- _ O
Zhang -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
discussion -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
comments -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Key -X- _ O
R -X- _ O
& -X- _ O
D -X- _ O
Program -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
2022YFB4701400 -X- _ O
/ -X- _ O
4701402 -X- _ O
) -X- _ O
, -X- _ O
SZSTC -X- _ O
Grant -X- _ O
( -X- _ O
JCYJ20190809172201639 -X- _ O
, -X- _ O
WDZC20200820200655001 -X- _ O
) -X- _ O
, -X- _ O
Shenzhen -X- _ O
Key -X- _ O
Laboratory -X- _ O
( -X- _ O
ZDSYS20210623092001004 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Beijing -X- _ O
Key -X- _ O
Lab -X- _ O
of -X- _ O
Networked -X- _ O
Multimedia.1998References19992000 -X- _ O
AThe -X- _ O
Derivation -X- _ O
of -X- _ O
Distillation -X- _ O
Influence -X- _ O
As -X- _ O
described -X- _ O
by -X- _ O
Pruthi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
a -X- _ O
training -X- _ O
sample -X- _ O
z= -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
on -X- _ O
a -X- _ O
test -X- _ O
samplez= -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
traced -X- _ O
by -X- _ O
examining -X- _ O
the -X- _ O
change -X- _ O
in -X- _ O
loss -X- _ O
of -X- _ O
model -X- _ O
won -X- _ O
the -X- _ O
test -X- _ O
sample -X- _ O
. -X- _ O
The -X- _ O
influence -X- _ O
function -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
total -X- _ O
reduction -X- _ O
in -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sample -X- _ O
zinduced -X- _ O
by -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
whenever -X- _ O
the -X- _ O
training -X- _ O
sample -X- _ O
zis -X- _ O
utilized -X- _ O
: -X- _ O
where -X- _ O
w -X- _ O
= -X- _ O
w−ηL -X- _ O
( -X- _ O
w -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
andηis -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
are -X- _ O
parameterized -X- _ O
by -X- _ O
wand -X- _ O
w. -X- _ O
In -X- _ O
this -X- _ O
context -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
batch -X- _ O
on -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
’s -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
computation -X- _ O
efficiency -X- _ O
, -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
samples -X- _ O
is -X- _ O
drawn -X- _ O
from -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
generalization -X- _ O
performance -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
influence -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
validation -X- _ O
sample -X- _ O
, -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
eq -X- _ O
. -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
extended -X- _ O
to -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
validation -X- _ O
samplesz -X- _ O
. -X- _ O
The -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
training -X- _ O
batch -X- _ O
zon -X- _ O
the -X- _ O
validation -X- _ O
batch -X- _ O
zis -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
where -X- _ O
θ -X- _ O
= -X- _ O
θ−ηL -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
applying -X- _ O
the -X- _ O
Taylor -X- _ O
expansion -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
approximate -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
approximate -X- _ O
the -X- _ O
I -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
The -X- _ O
contribution -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
sample -X- _ O
z= -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
batch -X- _ O
zis -X- _ O
defined -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
By -X- _ O
excluding -X- _ O
loss -X- _ O
irrelevant -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
in -X- _ O
eq -X- _ O
. -X- _ O
( -X- _ O
16 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
distillation -X- _ O
influence -X- _ O
of -X- _ O
z -X- _ O
to -X- _ O
be -X- _ O
: -X- _ O
B -X- _ O
Approximation -X- _ O
Methods -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
efficiently -X- _ O
approximate -X- _ O
this -X- _ O
gradient -X- _ O
similarity -X- _ O
using -X- _ O
a -X- _ O
Taylor -X- _ O
expansion -X- _ O
: -X- _ O
where -X- _ O
θ -X- _ O
= -X- _ O
θ±ϵL -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
) -X- _ O
andϵis -X- _ O
a -X- _ O
small -X- _ O
scalar -X- _ O
. -X- _ O
C -X- _ O
A -X- _ O
Closer -X- _ O
Look -X- _ O
at -X- _ O
Meta -X- _ O
Distillation -X- _ O
In -X- _ O
meta -X- _ O
distillation -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
can -X- _ O
be -X- _ O
derived -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
19 -X- _ O
) -X- _ O
where2001D -X- _ O
Hyperparameters -X- _ O
Hyperparameter -X- _ O
α -X- _ B-HyperparameterName
0.6 -X- _ B-HyperparameterValue
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
128 -X- _ B-HyperparameterValue
distillation -X- _ B-HyperparameterName
temperature -X- _ I-HyperparameterName
1 -X- _ B-HyperparameterValue
fine -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
tuning -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
6 -X- _ B-HyperparameterValue
student -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
1e−4,3e−5,5e−5 -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
32 -X- _ B-HyperparameterValue
For -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
and -X- _ O
meta -X- _ O
distillation -X- _ O
baselines -X- _ O
, -X- _ O
we -X- _ O
fix -X- _ O
the -X- _ O
teacher -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
at -X- _ O
3e−5 -X- _ B-HyperparameterValue
. -X- _ O
E -X- _ O
More -X- _ O
ablation -X- _ O
study -X- _ O
E.1 -X- _ O
Datasets -X- _ O
for -X- _ O
Student -X- _ O
’s -X- _ O
Feedback -X- _ O
In -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
feedback -X- _ O
from -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
provided -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
GLUE -X- _ B-DatasetName
datasets -X- _ O
directly -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
utilizing -X- _ O
feedback -X- _ O
derived -X- _ O
from -X- _ O
a -X- _ O
new -X- _ O
validation -X- _ O
set -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
separated -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
random -X- _ O
sample -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
and -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
samples -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
new -X- _ O
validation -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
respectively -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
apply -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
the -X- _ O
new -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
used -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
generalization -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
, -X- _ O
whether -X- _ O
it -X- _ O
be -X- _ O
from -X- _ O
an -X- _ O
existing -X- _ O
validation -X- _ O
set -X- _ O
or -X- _ O
a -X- _ O
newly -X- _ O
separated -X- _ O
set -X- _ O
, -X- _ O
remains -X- _ O
informative -X- _ O
in -X- _ O
both -X- _ O
cases -X- _ O
. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
reasonable -X- _ O
to -X- _ O
expect -X- _ O
that -X- _ O
the -X- _ O
feedback -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
student -X- _ O
to -X- _ O
the -X- _ O
teacher -X- _ O
would -X- _ O
not -X- _ O
exhibit -X- _ O
significant -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
sources -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
utilizing -X- _ O
feedback -X- _ O
from -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
whether -X- _ O
pre -X- _ O
- -X- _ O
existing -X- _ O
or -X- _ O
newly -X- _ O
separated -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
lead -X- _ O
to -X- _ O
significant -X- _ O
variations -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
may -X- _ O
play -X- _ O
a -X- _ O
role -X- _ O
in -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
When -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
selected -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
new -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
is -X- _ O
reduced -X- _ O
. -X- _ O
This -X- _ O
reduction -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
overfitting -X- _ O
in -X- _ O
datasets -X- _ O
of -X- _ O
small -X- _ O
or -X- _ O
medium -X- _ O
size -X- _ O
, -X- _ O
as -X- _ O
there -X- _ O
is -X- _ O
not -X- _ O
enough -X- _ O
data -X- _ O
information -X- _ O
provided -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Conversely -X- _ O
, -X- _ O
in -X- _ O
large -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
is -X- _ O
sufficient -X- _ O
to -X- _ O
encompass -X- _ O
a -X- _ O
substantial -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
information -X- _ O
, -X- _ O
thus -X- _ O
having -X- _ O
minimal -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
E.2 -X- _ O
Ratio -X- _ O
of -X- _ O
Teacher -X- _ O
’s -X- _ O
Self -X- _ O
- -X- _ O
evolution -X- _ O
A -X- _ O
student -X- _ O
- -X- _ O
friendly -X- _ O
teacher -X- _ O
should -X- _ O
strike -X- _ O
a -X- _ O
balance -X- _ O
between -X- _ O
self -X- _ O
- -X- _ O
evolution -X- _ O
and -X- _ O
knowledge -X- _ O
transfer -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
believed -X- _ O
that -X- _ O
an -X- _ O
excessive -X- _ O
focus -X- _ O
on -X- _ O
self -X- _ O
- -X- _ O
evolution -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
neglect -X- _ O
of -X- _ O
feedback -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
student -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
instruction -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
centered -X- _ O
on -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
needs -X- _ O
. -X- _ O
Conversely -X- _ O
, -X- _ O
inadequate -X- _ O
focus -X- _ O
on -X- _ O
self -X- _ O
- -X- _ O
evolution -X- _ O
may -X- _ O
prevent -X- _ O
the -X- _ O
teacher -X- _ O
from -X- _ O
improving -X- _ O
their -X- _ O
own -X- _ O
abilities -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
suboptimal -X- _ O
instruction -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
In -X- _ O
either -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
outcome -X- _ O
is -X- _ O
not -X- _ O
conducive -X- _ O
to -X- _ O
fostering -X- _ O
a -X- _ O
student -X- _ O
- -X- _ O
friendly -X- _ O
environment -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
ablate -X- _ O
on -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
self -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
evolution -X- _ I-HyperparameterName
to -X- _ O
see -X- _ O
how -X- _ O
it -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
. -X- _ O
αis -X- _ B-HyperparameterName
the -X- _ O
ratio -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
loss -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
ground -X- _ O
truth -X- _ O
in -X- _ O
eq -X- _ O
. -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
it -X- _ O
from -X- _ O
{ -X- _ O
1.0,0.8,0.6,0.4 -X- _ B-HyperparameterValue
} -X- _ O
.2002 -X- _ O
In -X- _ O
table -X- _ O
7 -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
exhibits -X- _ O
a -X- _ O
unimodal -X- _ O
distribution -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
in -X- _ O
agreement -X- _ O
with -X- _ O
our -X- _ O
proposed -X- _ O
assumption -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
self -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
evolution -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
at -X- _ O
0.6 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
student -X- _ O
is -X- _ O
optimal -X- _ O
. -X- _ O
F -X- _ O
Analysis -X- _ O
We -X- _ O
further -X- _ O
discuss -X- _ O
some -X- _ O
design -X- _ O
choices -X- _ O
of -X- _ O
current -X- _ O
methods -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
initialization -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
the -X- _ O
updating -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
entropy -X- _ O
gap -X- _ O
to -X- _ O
evaluate -X- _ O
these -X- _ O
design -X- _ O
choices -X- _ O
. -X- _ O
F.1 -X- _ O
Impact -X- _ O
of -X- _ O
the -X- _ O
Teacher -X- _ O
’s -X- _ O
initial -X- _ O
state -X- _ O
While -X- _ O
vanilla -X- _ O
distillation -X- _ O
and -X- _ O
meta -X- _ O
distillation -X- _ O
employ -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
approach -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
and -X- _ O
LGTM -X- _ B-MethodName
employ -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
stage -X- _ O
joint -X- _ O
training -X- _ O
strategy -X- _ O
for -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
difference -X- _ O
is -X- _ O
whether -X- _ O
to -X- _ O
involve -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
teacher -X- _ O
network -X- _ O
on -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
weinvestigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
network -X- _ O
’s -X- _ O
state -X- _ O
on -X- _ O
the -X- _ O
student -X- _ O
network -X- _ O
. -X- _ O
A -X- _ O
teacher -X- _ O
network -X- _ O
initialized -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
state -X- _ O
as -X- _ O
the -X- _ O
student -X- _ O
network -X- _ O
can -X- _ O
maintain -X- _ O
the -X- _ O
student -X- _ O
network -X- _ O
’s -X- _ O
progress -X- _ O
at -X- _ O
all -X- _ O
times -X- _ O
, -X- _ O
but -X- _ O
its -X- _ O
capabilities -X- _ O
may -X- _ O
be -X- _ O
relatively -X- _ O
weak -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
a -X- _ O
converged -X- _ O
teacher -X- _ O
network -X- _ O
has -X- _ O
superior -X- _ O
performance -X- _ O
but -X- _ O
also -X- _ O
a -X- _ O
larger -X- _ O
gap -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
prevent -X- _ O
the -X- _ O
student -X- _ O
network -X- _ O
from -X- _ O
gaining -X- _ O
knowledge -X- _ O
effectively -X- _ O
. -X- _ O
As -X- _ O
show -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
5 -X- _ O
, -X- _ O
a -X- _ O
lower -X- _ O
initial -X- _ O
confidence -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
leads -X- _ O
to -X- _ O
more -X- _ O
efficient -X- _ O
knowledge -X- _ O
transfer -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
initial -X- _ O
ability -X- _ O
gap -X- _ O
is -X- _ O
relatively -X- _ O
high -X- _ O
, -X- _ O
it -X- _ O
takes -X- _ O
more -X- _ O
iterations -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
to -X- _ O
catch -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
initial -X- _ O
ability -X- _ O
gap -X- _ O
is -X- _ O
lower -X- _ O
, -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
initialized -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
state -X- _ O
as -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
transfer -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
more -X- _ O
quickly -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
stages -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
focuses -X- _ O
more -X- _ O
on -X- _ O
self -X- _ O
- -X- _ O
evolution -X- _ O
than -X- _ O
knowledge -X- _ O
transfer -X- _ O
, -X- _ O
causing -X- _ O
the -X- _ O
entropy -X- _ O
gap -X- _ O
to -X- _ O
increase -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
shifts -X- _ O
its -X- _ O
focus -X- _ O
towards -X- _ O
knowledge -X- _ O
transfer -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
an -X- _ O
increasing -X- _ O
and -X- _ O
then -X- _ O
decreasing -X- _ O
trend -X- _ O
in -X- _ O
the -X- _ O
entropy -X- _ O
gap -X- _ O
. -X- _ O
F.2 -X- _ O
Prioritizing -X- _ O
the -X- _ O
Teacher -X- _ O
or -X- _ O
Student -X- _ O
Online -X- _ O
distillation -X- _ O
and -X- _ O
meta -X- _ O
distillation -X- _ O
and -X- _ O
LGTM -X- _ B-MethodName
all -X- _ O
use -X- _ O
bi -X- _ O
- -X- _ O
level -X- _ O
optimization -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
online -X- _ O
distillation -X- _ O
and -X- _ O
LGTM -X- _ B-MethodName
updates -X- _ O
the -X- _ O
teacher -X- _ O
network -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
student -X- _ O
network -X- _ O
, -X- _ O
while -X- _ O
meta -X- _ O
distillation -X- _ O
updates -X- _ O
the -X- _ O
student -X- _ O
network -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
network -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
optimal -X- _ O
order -X- _ O
for -X- _ O
updating -X- _ O
the -X- _ O
teacher -X- _ O
network -X- _ O
and -X- _ O
student -X- _ O
network -X- _ O
in -X- _ O
knowledge -X- _ O
distillation -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
fig -X- _ O
. -X- _ O
6 -X- _ O
, -X- _ O
updating -X- _ O
the -X- _ O
teacher -X- _ O
model -X- _ O
first -X- _ O
could -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
lower -X- _ O
entropy -X- _ O
gap -X- _ O
and -X- _ O
faster -X- _ O
convergence -X- _ O
speed -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
teacher -X- _ O
could -X- _ O
formulate -X- _ O
an -X- _ O
appropriate -X- _ O
‘ -X- _ O
teaching -X- _ O
plan -X- _ O
’ -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
in -X- _ O
this -X- _ O
updating -X- _ O
order -X- _ O
. -X- _ O
The -X- _ O
teacher -X- _ O
should -X- _ O
strive -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
student -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
samples -X- _ O
and -X- _ O
information -X- _ O
, -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
student -X- _ O
develop -X- _ O
a -X- _ O
deep -X- _ O
and -X- _ O
general -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
should -X- _ O
also -X- _ O
take -X- _ O
into -X- _ O
consideration -X- _ O
that -X- _ O
some -X- _ O
samples -X- _ O
may -X- _ O
be -X- _ O
difficult -X- _ O
for -X- _ O
the -X- _ O
teacher -X- _ O
itself -X- _ O
to -X- _ O
classify -X- _ O
or -X- _ O
understand -X- _ O
. -X- _ O
And -X- _ O
for -X- _ O
those -X- _ O
samples -X- _ O
, -X- _ O
a -X- _ O
lower -X- _ O
criterion -X- _ O
should -X- _ O
be -X- _ O
set -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
form -X- _ O
a -X- _ O
more -X- _ O
student -X- _ O
- -X- _ O
friendly -X- _ O
decision -X- _ O
boundary -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
’s -X- _ O
output -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
dynamic -X- _ O
learning -X- _ O
target -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
. -X- _ O
By -X- _ O
updating -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
feedback -X- _ O
in -X- _ O
advance -X- _ O
, -X- _ O
the2003teacher -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
reach -X- _ O
a -X- _ O
state -X- _ O
that -X- _ O
is -X- _ O
optimal -X- _ O
for -X- _ O
the -X- _ O
student -X- _ O
’s -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
could -X- _ O
provide -X- _ O
an -X- _ O
appropriate -X- _ O
learning -X- _ O
signal -X- _ O
. -X- _ O
Leveraging -X- _ O
this -X- _ O
updated -X- _ O
supervision -X- _ O
signal -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
could -X- _ O
make -X- _ O
up -X- _ O
for -X- _ O
the -X- _ O
ability -X- _ O
gap -X- _ O
faster -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
updating -X- _ O
orders -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
has -X- _ O
n’t -X- _ O
updated -X- _ O
yet -X- _ O
, -X- _ O
lacking -X- _ O
of -X- _ O
making -X- _ O
trade -X- _ O
- -X- _ O
offs -X- _ O
between -X- _ O
the -X- _ O
samples -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
beneficial -X- _ O
for -X- _ O
generalization -X- _ O
and -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
challenging -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
degree -X- _ O
of -X- _ O
lag -X- _ O
in -X- _ O
knowledge -X- _ O
transfer -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
larger -X- _ O
entropy -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
student -X- _ O
and -X- _ O
the -X- _ O
teacher.2004ACL -X- _ O
2023 -X- _ O
Responsible -X- _ O
NLP -X- _ O
Checklist -X- _ O
A -X- _ O
For -X- _ O
every -X- _ O
submission -X- _ O
: -X- _ O
/ -X- _ O
squareA1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
describe -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
Yes -X- _ O
. -X- _ O
Section -X- _ O
" -X- _ O
Limitations -X- _ O
" -X- _ O
/ -X- _ O
squareA2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
any -X- _ O
potential -X- _ O
risks -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
Yes -X- _ O
. -X- _ O
Section -X- _ O
" -X- _ O
Ethics -X- _ O
Statement -X- _ O
" -X- _ O
/ -X- _ O
squareA3 -X- _ O
. -X- _ O
Do -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
introduction -X- _ O
summarize -X- _ O
the -X- _ O
paper -X- _ O
’s -X- _ O
main -X- _ O
claims -X- _ O
? -X- _ O
Abstract -X- _ O
+ -X- _ O
End -X- _ O
of -X- _ O
Section -X- _ O
1 -X- _ O
: -X- _ O
Introduction -X- _ O
/ -X- _ O
squareA4 -X- _ O
. -X- _ O
Have -X- _ O
you -X- _ O
used -X- _ O
AI -X- _ O
writing -X- _ O
assistants -X- _ O
when -X- _ O
working -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
? -X- _ O
Checking -X- _ O
the -X- _ O
presentation -X- _ O
style -X- _ O
of -X- _ O
some -X- _ O
sentences -X- _ O
via -X- _ O
ChatGPT -X- _ O
. -X- _ O
Use -X- _ O
prompt -X- _ O
like -X- _ O
" -X- _ O
help -X- _ O
me -X- _ O
rephrase -X- _ O
XXX -X- _ O
" -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
sometimes -X- _ O
ChatGPT -X- _ O
will -X- _ O
generate -X- _ O
very -X- _ O
wordy -X- _ O
sentences -X- _ O
and -X- _ O
we -X- _ O
have -X- _ O
n’t -X- _ O
used -X- _ O
many -X- _ O
recommendations -X- _ O
. -X- _ O
B -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
or -X- _ O
create -X- _ O
scientiﬁc -X- _ O
artifacts -X- _ O
? -X- _ O
Section -X- _ O
5.1 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
/ -X- _ O
squareB1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
cite -X- _ O
the -X- _ O
creators -X- _ O
of -X- _ O
artifacts -X- _ O
you -X- _ O
used -X- _ O
? -X- _ O
Section -X- _ O
5.1 -X- _ O
/ -X- _ O
squareB2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
license -X- _ O
or -X- _ O
terms -X- _ O
for -X- _ O
use -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
distribution -X- _ O
of -X- _ O
any -X- _ O
artifacts -X- _ O
? -X- _ O
We -X- _ O
have -X- _ O
n’t -X- _ O
discussed -X- _ O
the -X- _ O
term -X- _ O
+ -X- _ O
license -X- _ O
explicitly -X- _ O
since -X- _ O
they -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
paper -X- _ O
and -X- _ O
other -X- _ O
papers -X- _ O
we -X- _ O
cited -X- _ O
. -X- _ O
/ -X- _ O
squareB3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
speciﬁed -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
GLUE -X- _ B-DatasetName
has -X- _ O
widely -X- _ O
been -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
research -X- _ O
community -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
writing -X- _ O
a -X- _ O
research -X- _ O
paper -X- _ O
so -X- _ O
we -X- _ O
have -X- _ O
n’t -X- _ O
used -X- _ O
spaces -X- _ O
to -X- _ O
discuss -X- _ O
the -X- _ O
intended -X- _ O
usage -X- _ O
of -X- _ O
GLUE -X- _ B-DatasetName
. -X- _ O
/ -X- _ O
squareB4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identiﬁes -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
using -X- _ O
the -X- _ O
datasets -X- _ O
from -X- _ O
GLUE -X- _ B-DatasetName
. -X- _ O
/ -X- _ O
squareB5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
provide -X- _ O
documentation -X- _ O
of -X- _ O
the -X- _ O
artifacts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
coverage -X- _ O
of -X- _ O
domains -X- _ O
, -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
linguistic -X- _ O
phenomena -X- _ O
, -X- _ O
demographic -X- _ O
groups -X- _ O
represented -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
using -X- _ O
the -X- _ O
datasets -X- _ O
from -X- _ O
GLUE -X- _ B-DatasetName
. -X- _ O
/ -X- _ O
squareB6 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
relevant -X- _ O
statistics -X- _ O
like -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
, -X- _ O
details -X- _ O
of -X- _ O
train -X- _ O
/ -X- _ O
test -X- _ O
/ -X- _ O
dev -X- _ O
splits -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
for -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
you -X- _ O
used -X- _ O
/ -X- _ O
created -X- _ O
? -X- _ O
Even -X- _ O
for -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
include -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
train -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
provide -X- _ O
necessary -X- _ O
context -X- _ O
for -X- _ O
a -X- _ O
reader -X- _ O
to -X- _ O
understand -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
small -X- _ O
differences -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
large -X- _ O
test -X- _ O
sets -X- _ O
may -X- _ O
be -X- _ O
signiﬁcant -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
small -X- _ O
test -X- _ O
sets -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
. -X- _ O
Section -X- _ O
5.12005C -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
run -X- _ O
computational -X- _ O
experiments -X- _ O
? -X- _ O
Section -X- _ O
5 -X- _ O
/ -X- _ O
squareC1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
computational -X- _ O
budget -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPU -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
infrastructure -X- _ O
used -X- _ O
? -X- _ O
Section -X- _ O
5 -X- _ O
/ -X- _ O
squareC2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
including -X- _ O
hyperparameter -X- _ O
search -X- _ O
and -X- _ O
best -X- _ O
- -X- _ O
found -X- _ O
hyperparameter -X- _ O
values -X- _ O
? -X- _ O
Section -X- _ O
5.1 -X- _ O
and -X- _ O
Appendix -X- _ O
D -X- _ O
/ -X- _ O
squareC3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
descriptive -X- _ O
statistics -X- _ O
about -X- _ O
your -X- _ O
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
error -X- _ O
bars -X- _ O
around -X- _ O
results -X- _ O
, -X- _ O
summary -X- _ O
statistics -X- _ O
from -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
it -X- _ O
transparent -X- _ O
whether -X- _ O
you -X- _ O
are -X- _ O
reporting -X- _ O
the -X- _ O
max -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
or -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
? -X- _ O
No -X- _ O
, -X- _ O
we -X- _ O
reported -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
limitation -X- _ O
to -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
submissions -X- _ O
each -X- _ O
person -X- _ O
can -X- _ O
make -X- _ O
for -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
/ -X- _ O
squareC4 -X- _ O
. -X- _ O
If -X- _ O
you -X- _ O
used -X- _ O
existing -X- _ O
packages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
preprocessing -X- _ O
, -X- _ O
for -X- _ O
normalization -X- _ O
, -X- _ O
or -X- _ O
for -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
implementation -X- _ O
, -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
parameter -X- _ O
settings -X- _ O
used -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
NLTK -X- _ O
, -X- _ O
Spacy -X- _ O
, -X- _ O
ROUGE -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
? -X- _ O
Section -X- _ O
5 -X- _ O
and -X- _ O
Appendix -X- _ O
D -X- _ O
D -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
human -X- _ O
annotators -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdworkers -X- _ O
) -X- _ O
or -X- _ O
research -X- _ O
with -X- _ O
human -X- _ O
participants -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
of -X- _ O
instructions -X- _ O
given -X- _ O
to -X- _ O
participants -X- _ O
, -X- _ O
including -X- _ O
e.g. -X- _ O
, -X- _ O
screenshots -X- _ O
, -X- _ O
disclaimers -X- _ O
of -X- _ O
any -X- _ O
risks -X- _ O
to -X- _ O
participants -X- _ O
or -X- _ O
annotators -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
you -X- _ O
recruited -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdsourcing -X- _ O
platform -X- _ O
, -X- _ O
students -X- _ O
) -X- _ O
and -X- _ O
paid -X- _ O
participants -X- _ O
, -X- _ O
and -X- _ O
discuss -X- _ O
if -X- _ O
such -X- _ O
payment -X- _ O
is -X- _ O
adequate -X- _ O
given -X- _ O
the -X- _ O
participants -X- _ O
’ -X- _ O
demographic -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
country -X- _ O
of -X- _ O
residence -X- _ O
) -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
whether -X- _ O
and -X- _ O
how -X- _ O
consent -X- _ O
was -X- _ O
obtained -X- _ O
from -X- _ O
people -X- _ O
whose -X- _ O
data -X- _ O
you -X- _ O
’re -X- _ O
using -X- _ O
/ -X- _ O
curating -X- _ O
? -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
collected -X- _ O
data -X- _ O
via -X- _ O
crowdsourcing -X- _ O
, -X- _ O
did -X- _ O
your -X- _ O
instructions -X- _ O
to -X- _ O
crowdworkers -X- _ O
explain -X- _ O
how -X- _ O
the -X- _ O
data -X- _ O
would -X- _ O
be -X- _ O
used -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD4 -X- _ O
. -X- _ O
Was -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
protocol -X- _ O
approved -X- _ O
( -X- _ O
or -X- _ O
determined -X- _ O
exempt -X- _ O
) -X- _ O
by -X- _ O
an -X- _ O
ethics -X- _ O
review -X- _ O
board -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
basic -X- _ O
demographic -X- _ O
and -X- _ O
geographic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
annotator -X- _ O
population -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank.2006 -X- _ O

2022.naacl-main.59.txt -X- _ O
Rohit -X- _ O
Sridhar -X- _ O
School -X- _ O
of -X- _ O
Interactive -X- _ O
Computing -X- _ O
Georgia -X- _ O
Institute -X- _ O
of -X- _ O
Technology -X- _ O
rsridhar37 -X- _ O
@ -X- _ O
gatech.eduDiyi -X- _ O
Yang -X- _ O
School -X- _ O
of -X- _ O
Interactive -X- _ O
Computing -X- _ O
Georgia -X- _ O
Institute -X- _ O
of -X- _ O
Technology -X- _ O
dyang888 -X- _ O
@ -X- _ O
gatech.edu -X- _ O
Abstract -X- _ O
Warning -X- _ O
: -X- _ O
This -X- _ O
paper -X- _ O
contains -X- _ O
content -X- _ O
that -X- _ O
is -X- _ O
offensive -X- _ O
and -X- _ O
may -X- _ O
be -X- _ O
upsetting -X- _ O
. -X- _ O
Biased -X- _ O
or -X- _ O
toxic -X- _ O
speech -X- _ O
can -X- _ O
be -X- _ O
harmful -X- _ O
to -X- _ O
various -X- _ O
demographic -X- _ O
groups -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
only -X- _ O
important -X- _ O
for -X- _ O
models -X- _ O
to -X- _ O
detect -X- _ O
these -X- _ O
speech -X- _ O
, -X- _ O
but -X- _ O
to -X- _ O
also -X- _ O
output -X- _ O
explanations -X- _ O
of -X- _ O
why -X- _ O
a -X- _ O
given -X- _ O
text -X- _ O
is -X- _ O
toxic -X- _ O
. -X- _ O
Previous -X- _ O
literature -X- _ O
has -X- _ O
mostly -X- _ O
focused -X- _ O
on -X- _ O
classifying -X- _ O
and -X- _ O
detecting -X- _ O
toxic -X- _ O
speech -X- _ O
, -X- _ O
and -X- _ O
existing -X- _ O
efforts -X- _ O
on -X- _ O
explaining -X- _ O
stereotypes -X- _ O
in -X- _ O
toxic -X- _ O
speech -X- _ O
mainly -X- _ O
use -X- _ O
standard -X- _ O
text -X- _ O
generation -X- _ O
approaches -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
generic -X- _ O
and -X- _ O
repetitive -X- _ O
explanations -X- _ O
. -X- _ O
Building -X- _ O
on -X- _ O
these -X- _ O
prior -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
novel -X- _ O
knowledgeinformed -X- _ B-MethodName
encoder -X- _ I-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
framework -X- _ O
to -X- _ O
utilize -X- _ O
multiple -X- _ O
knowledge -X- _ O
sources -X- _ O
to -X- _ O
generate -X- _ O
implications -X- _ O
of -X- _ O
biased -X- _ O
text -X- _ O
. -X- _ O
Experiments -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
knowledge -X- _ O
informed -X- _ O
models -X- _ O
outperform -X- _ O
prior -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
significantly -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
generate -X- _ O
detailed -X- _ O
explanations -X- _ O
of -X- _ O
stereotypes -X- _ O
in -X- _ O
toxic -X- _ O
speech -X- _ O
compared -X- _ O
to -X- _ O
baselines -X- _ O
, -X- _ O
both -X- _ O
quantitatively -X- _ O
and -X- _ O
qualitatively -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
The -X- _ O
toxic -X- _ B-TaskName
speech -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ I-TaskName
classification -X- _ I-TaskName
problem -X- _ O
has -X- _ O
seen -X- _ O
increasing -X- _ O
interest -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
only -X- _ O
important -X- _ O
for -X- _ O
AI -X- _ O
agents -X- _ O
to -X- _ O
recognize -X- _ O
and -X- _ O
classify -X- _ O
toxic -X- _ O
speech -X- _ O
, -X- _ O
but -X- _ O
to -X- _ O
also -X- _ O
explain -X- _ O
why -X- _ O
it -X- _ O
is -X- _ O
toxic -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
debiasing -X- _ O
methods -X- _ O
that -X- _ O
use -X- _ O
information -X- _ O
about -X- _ O
toxic -X- _ O
language -X- _ O
may -X- _ O
benefit -X- _ O
from -X- _ O
additional -X- _ O
information -X- _ O
given -X- _ O
by -X- _ O
detailed -X- _ O
explanations -X- _ O
of -X- _ O
toxicity -X- _ O
in -X- _ O
text -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
detailed -X- _ O
explanations -X- _ O
of -X- _ O
toxicity -X- _ O
may -X- _ O
facilitate -X- _ O
human -X- _ O
interaction -X- _ O
with -X- _ O
toxicity -X- _ B-TaskName
detection -X- _ I-TaskName
systems -X- _ O
( -X- _ O
Rosenfeld -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
can -X- _ O
also -X- _ O
help -X- _ O
humans -X- _ O
who -X- _ O
work -X- _ O
with -X- _ O
toxicity -X- _ O
classifiers -X- _ O
use -X- _ O
more -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
input -X- _ O
when -X- _ O
making -X- _ O
decisions -X- _ O
about -X- _ O
toxic -X- _ O
speech -X- _ O
. -X- _ O
To -X- _ O
elucidate -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
offensive -X- _ O
joke -X- _ O
: -X- _ O
“ -X- _ O
What -X- _ O
type -X- _ O
of -X- _ O
punch -X- _ O
do -X- _ O
you -X- _ O
use -X- _ O
against -X- _ O
a -X- _ O
kindergartener -X- _ O
? -X- _ O
A -X- _ O
sandy -X- _ O
- -X- _ O
hook -X- _ O
. -X- _ O
" -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
literal -X- _ O
text -X- _ O
is -X- _ O
not -X- _ O
toxic -X- _ O
, -X- _ O
the -X- _ O
implied -X- _ O
meaning -X- _ O
is -X- _ O
offensive -X- _ O
, -X- _ O
particularly -X- _ O
to -X- _ O
those -X- _ O
affected -X- _ O
by -X- _ O
school -X- _ O
shootings -X- _ O
. -X- _ O
An -X- _ O
AIagent -X- _ O
capable -X- _ O
of -X- _ O
generating -X- _ O
the -X- _ O
implied -X- _ O
meaning -X- _ O
could -X- _ O
thus -X- _ O
provide -X- _ O
additional -X- _ O
information -X- _ O
to -X- _ O
downstream -X- _ O
actors -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
term -X- _ O
biased -X- _ O
andtoxic -X- _ O
interchangeably -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
Existing -X- _ O
work -X- _ O
largely -X- _ O
addresses -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
detecting -X- _ B-TaskName
andclassifying -X- _ I-TaskName
toxic -X- _ I-TaskName
speech -X- _ I-TaskName
( -X- _ O
Waseem -X- _ O
and -X- _ O
Hovy -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Founta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Davidson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
earlier -X- _ O
, -X- _ O
explanations -X- _ O
of -X- _ O
toxicity -X- _ O
can -X- _ O
help -X- _ O
with -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
debiasing -X- _ O
or -X- _ O
decision -X- _ O
making -X- _ O
by -X- _ O
humans -X- _ O
, -X- _ O
thus -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
increasing -X- _ O
demand -X- _ O
for -X- _ O
explainable -X- _ O
machine -X- _ O
learning -X- _ O
classifiers -X- _ O
( -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Došilovi -X- _ O
´ -X- _ O
c -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
around -X- _ O
explainable -X- _ B-TaskName
toxicity -X- _ I-TaskName
classification -X- _ I-TaskName
introduced -X- _ O
Social -X- _ B-MethodName
Bias -X- _ I-MethodName
Frames -X- _ I-MethodName
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
formal -X- _ O
framework -X- _ O
which -X- _ O
combines -X- _ O
explanations -X- _ O
of -X- _ O
toxicity -X- _ O
along -X- _ O
with -X- _ O
toxicity -X- _ O
classifications -X- _ O
along -X- _ O
multiple -X- _ O
dimensions -X- _ O
. -X- _ O
However -X- _ O
the -X- _ O
explanations -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
generic -X- _ O
, -X- _ O
without -X- _ O
much -X- _ O
detail -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
explanations -X- _ O
may -X- _ O
focus -X- _ O
on -X- _ O
certain -X- _ O
toxic -X- _ O
components -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
but -X- _ O
ignore -X- _ O
others -X- _ O
, -X- _ O
or -X- _ O
include -X- _ O
irrelevant -X- _ O
stereotypes -X- _ O
about -X- _ O
the -X- _ O
minority -X- _ O
group -X- _ O
affected -X- _ O
. -X- _ O
To -X- _ O
fill -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
proposes -X- _ O
to -X- _ O
leverage -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
knowledge -X- _ O
to -X- _ O
provide -X- _ O
rich -X- _ O
context -X- _ O
and -X- _ O
background -X- _ O
for -X- _ O
toxicity -X- _ B-TaskName
explanation -X- _ I-TaskName
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
to -X- _ O
utilize -X- _ O
three -X- _ O
distinct -X- _ O
knowledge -X- _ O
sources -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
divides -X- _ O
knowledge -X- _ O
broadly -X- _ O
into -X- _ O
internal -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
, -X- _ O
where -X- _ O
internal -X- _ O
knowledge -X- _ O
is -X- _ O
knowledge -X- _ O
embedded -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
is -X- _ O
derived -X- _ O
from -X- _ O
sources -X- _ O
outside -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
Building -X- _ O
upon -X- _ O
these -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
expert -X- _ O
knowledge -X- _ O
that -X- _ O
comes -X- _ O
from -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
expert -X- _ O
annotations -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
and -X- _ O
explicit -X- _ O
knowledge -X- _ O
from -X- _ O
knowledge -X- _ O
graphs -X- _ O
and -X- _ O
bases -X- _ O
, -X- _ O
as -X- _ O
such -X- _ O
symbolic -X- _ O
knowledge -X- _ O
can -X- _ O
provide -X- _ O
relevant -X- _ O
information -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
text -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Mou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
knowledge -X- _ O
graphs -X- _ O
and -X- _ O
bases -X- _ O
deterministically -X- _ O
retrieve -X- _ O
and -X- _ O
restructure -X- _ O
knowledge -X- _ O
from -X- _ O
raw -X- _ O
text -X- _ O
sources -X- _ O
, -X- _ O
large -X- _ O
pretrained -X- _ O
generative -X- _ O
models -X- _ O
are811 -X- _ O
found -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
outputting -X- _ O
useful -X- _ O
knowledge -X- _ O
in -X- _ O
a -X- _ O
probabilistic -X- _ O
manner -X- _ O
, -X- _ O
complementing -X- _ O
the -X- _ O
expert -X- _ O
and -X- _ O
explicit -X- _ O
knowledge -X- _ O
( -X- _ O
Razniewski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
include -X- _ O
implicit -X- _ O
knowledge -X- _ O
models -X- _ O
which -X- _ O
source -X- _ O
knowledge -X- _ O
from -X- _ O
large -X- _ O
pretrained -X- _ O
text -X- _ O
generation -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
build -X- _ O
a -X- _ O
family -X- _ O
of -X- _ O
mixture -X- _ O
models -X- _ O
, -X- _ O
MGEN -X- _ B-MethodName
, -X- _ O
to -X- _ O
synthesize -X- _ O
knowledge -X- _ O
from -X- _ O
all -X- _ O
three -X- _ O
sources -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
To -X- _ O
sum -X- _ O
up -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
twofold -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
leverage -X- _ O
three -X- _ O
different -X- _ O
sources -X- _ O
of -X- _ O
knowledge -X- _ O
, -X- _ O
and -X- _ O
further -X- _ O
combine -X- _ O
them -X- _ O
using -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
mixture -X- _ O
models -X- _ O
to -X- _ O
explain -X- _ O
toxic -X- _ O
text -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
outperform -X- _ O
prior -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
baselines -X- _ O
and -X- _ O
generate -X- _ O
more -X- _ O
detailed -X- _ O
explanations -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
Prior -X- _ O
work -X- _ O
on -X- _ O
knowledge -X- _ O
enhanced -X- _ O
text -X- _ O
generation -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
across -X- _ O
two -X- _ O
different -X- _ O
knowledge -X- _ O
sources -X- _ O
. -X- _ O
2.1 -X- _ O
Internal -X- _ O
Knowledge -X- _ O
Internal -X- _ O
knowledge -X- _ O
includes -X- _ O
knowledge -X- _ O
that -X- _ O
is -X- _ O
available -X- _ O
within -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Latent -X- _ O
Dirichlet -X- _ O
Allocation -X- _ O
( -X- _ O
LDA -X- _ O
) -X- _ O
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
can -X- _ O
learn -X- _ O
topics -X- _ O
from -X- _ O
inputs -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
incorporated -X- _ O
into -X- _ O
text -X- _ O
generation -X- _ O
models -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Keywords -X- _ O
may -X- _ O
also -X- _ O
be -X- _ O
extracted -X- _ O
from -X- _ O
input -X- _ O
text -X- _ O
using -X- _ O
techniques -X- _ O
like -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
, -X- _ O
PMI -X- _ O
or -X- _ O
independent -X- _ O
classifiers -X- _ O
. -X- _ O
In -X- _ O
one -X- _ O
such -X- _ O
work -X- _ O
, -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
extract -X- _ O
emotion -X- _ O
oriented -X- _ O
keywords -X- _ O
using -X- _ O
an -X- _ O
independent -X- _ O
emotion -X- _ O
classifier -X- _ O
to -X- _ O
enhance -X- _ O
dialogue -X- _ O
generation -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
Mou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
use -X- _ O
PMI -X- _ O
to -X- _ O
find -X- _ O
relevant -X- _ O
keywords -X- _ O
for -X- _ O
short -X- _ O
text -X- _ O
conversation -X- _ O
. -X- _ O
Forbes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
develop -X- _ O
conceptual -X- _ O
formalisms -X- _ O
that -X- _ O
rely -X- _ O
on -X- _ O
annotations -X- _ O
about -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
generate -X- _ O
text -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
independent -X- _ O
annotations -X- _ O
on -X- _ O
input -X- _ O
to -X- _ O
enhancetext -X- _ O
generation -X- _ O
as -X- _ O
expert -X- _ O
knowledge -X- _ O
, -X- _ O
as -X- _ O
such -X- _ O
annotations -X- _ O
often -X- _ O
come -X- _ O
from -X- _ O
human -X- _ O
experts -X- _ O
. -X- _ O
2.2 -X- _ O
External -X- _ O
Knowledge -X- _ O
Knowledge -X- _ O
graphs -X- _ O
and -X- _ O
bases -X- _ O
are -X- _ O
commonly -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
use -X- _ O
knowledge -X- _ O
graph -X- _ O
embeddings -X- _ O
to -X- _ O
model -X- _ O
conversation -X- _ O
flow -X- _ O
, -X- _ O
while -X- _ O
Guan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
triples -X- _ O
extracted -X- _ O
from -X- _ O
knowledge -X- _ O
graphs -X- _ O
to -X- _ O
enhance -X- _ O
story -X- _ O
generation -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Lian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
develop -X- _ O
probabilistic -X- _ O
mechanisms -X- _ O
to -X- _ O
select -X- _ O
knowledge -X- _ O
from -X- _ O
knowledge -X- _ O
bases -X- _ O
for -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
Knowledge -X- _ O
from -X- _ O
conventional -X- _ O
sources -X- _ O
are -X- _ O
determinstically -X- _ O
created -X- _ O
, -X- _ O
in -X- _ O
that -X- _ O
they -X- _ O
simply -X- _ O
restructure -X- _ O
raw -X- _ O
text -X- _ O
and -X- _ O
store -X- _ O
them -X- _ O
in -X- _ O
a -X- _ O
knowledge -X- _ O
base -X- _ O
or -X- _ O
graph -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
as -X- _ O
explicit -X- _ O
knowledge -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
increasing -X- _ O
interest -X- _ O
in -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
large -X- _ O
pretrained -X- _ O
generative -X- _ O
models -X- _ O
as -X- _ O
a -X- _ O
source -X- _ O
of -X- _ O
knowledge -X- _ O
. -X- _ O
Heinzerling -X- _ O
and -X- _ O
Inui -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
argue -X- _ O
that -X- _ O
large -X- _ O
pretrained -X- _ O
models -X- _ O
can -X- _ O
in -X- _ O
fact -X- _ O
serve -X- _ O
as -X- _ O
knowledge -X- _ O
bases -X- _ O
, -X- _ O
while -X- _ O
Davison -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
argue -X- _ O
that -X- _ O
pretrained -X- _ O
models -X- _ O
can -X- _ O
accurately -X- _ O
assess -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
knowledge -X- _ O
mined -X- _ O
from -X- _ O
raw -X- _ O
text -X- _ O
. -X- _ O
While -X- _ O
pretrained -X- _ O
models -X- _ O
are -X- _ O
also -X- _ O
trained -X- _ O
on -X- _ O
raw -X- _ O
texts -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
knowledge -X- _ O
bases -X- _ O
and -X- _ O
graphs -X- _ O
, -X- _ O
they -X- _ O
draw -X- _ O
from -X- _ O
this -X- _ O
knowledge -X- _ O
probabilistically -X- _ O
and -X- _ O
thus -X- _ O
are -X- _ O
a -X- _ O
distinct -X- _ O
approach -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
as -X- _ O
implicit -X- _ O
knowledge -X- _ O
. -X- _ O
2.3 -X- _ O
Toxic -X- _ O
Text -X- _ O
Understanding -X- _ O
Prior -X- _ O
work -X- _ O
around -X- _ O
toxicity -X- _ O
understanding -X- _ O
mainly -X- _ O
focuses -X- _ O
on -X- _ O
detection -X- _ O
( -X- _ O
Schmidt -X- _ O
and -X- _ O
Wiegand -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Early -X- _ O
approaches -X- _ O
include -X- _ O
using -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
( -X- _ O
Waseem -X- _ O
and -X- _ O
Hovy -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Sood -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Perera -X- _ O
and -X- _ O
Fernando -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
word -X- _ O
clustering -X- _ O
( -X- _ O
Xiang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
knowledge -X- _ O
enhanced -X- _ O
approaches -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
toxicity -X- _ O
detection -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Dinakar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
use -X- _ O
ConceptNet -X- _ O
to -X- _ O
detect -X- _ O
anti -X- _ O
- -X- _ O
LGBT -X- _ O
bullying -X- _ O
. -X- _ O
The -X- _ O
use -X- _ O
of -X- _ O
meta -X- _ O
- -X- _ O
information -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
user -X- _ O
( -X- _ O
Dadvar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
has -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
useful -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
information -X- _ O
used -X- _ O
. -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
Social -X- _ O
Bias -X- _ O
Frames -X- _ O
to -X- _ O
produce -X- _ O
both -X- _ O
toxicity -X- _ O
classifications -X- _ O
and -X- _ O
explanations -X- _ O
of -X- _ O
toxicity -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
attempts -X- _ O
to -X- _ O
explain -X- _ O
toxicity -X- _ O
by -X- _ O
leveraging -X- _ O
different -X- _ O
sources -X- _ O
of -X- _ O
knowledge -X- _ O
to -X- _ O
provide -X- _ O
more -X- _ O
context -X- _ O
and -X- _ O
grounding -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
explanations -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
many -X- _ O
prior -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
synthesize -X- _ O
these -X- _ O
diverse -X- _ O
knowledge -X- _ O
sources -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
unique -X- _ O
contribution -X- _ O
from -X- _ O
each812individual -X- _ O
knowledge -X- _ O
source -X- _ O
. -X- _ O
3 -X- _ O
Knowledge -X- _ O
Enhanced -X- _ O
MG -X- _ B-MethodName
This -X- _ O
section -X- _ O
presents -X- _ O
our -X- _ O
selected -X- _ O
three -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
knowledge -X- _ O
— -X- _ O
expert -X- _ O
knowledge -X- _ O
, -X- _ O
explicit -X- _ O
knowledge -X- _ O
andimplicit -X- _ O
knowledge -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
MGmodels -X- _ B-MethodName
for -X- _ O
toxicity -X- _ O
explanation -X- _ O
. -X- _ O
3.1 -X- _ O
Expert -X- _ O
Knowledge -X- _ O
Expert -X- _ O
knowledge -X- _ O
is -X- _ O
sourced -X- _ O
from -X- _ O
annotations -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
Social -X- _ O
Bias -X- _ O
Frames -X- _ O
dataset -X- _ O
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
expert -X- _ O
knowledge -X- _ O
include -X- _ O
human -X- _ O
judgements -X- _ O
towards -X- _ O
the -X- _ O
lewdness -X- _ O
, -X- _ O
offensiveness -X- _ O
, -X- _ O
intent -X- _ O
to -X- _ O
offend -X- _ O
, -X- _ O
and -X- _ O
group -X- _ O
targeted -X- _ O
categories -X- _ O
. -X- _ O
This -X- _ O
type -X- _ O
of -X- _ O
expert -X- _ O
knowledge -X- _ O
provides -X- _ O
useful -X- _ O
insights -X- _ O
and -X- _ O
heuristics -X- _ O
for -X- _ O
the -X- _ O
toxicity -X- _ O
explanation -X- _ O
task -X- _ O
, -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
available -X- _ O
. -X- _ O
We -X- _ O
incorporate -X- _ O
expert -X- _ O
knowledge -X- _ O
into -X- _ O
the -X- _ O
generation -X- _ O
process -X- _ O
using -X- _ O
the -X- _ O
join -X- _ O
embedding -X- _ O
technique -X- _ O
( -X- _ O
Pryzant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
along -X- _ O
with -X- _ O
toxicity -X- _ B-TaskName
classification -X- _ I-TaskName
models -X- _ O
. -X- _ O
The -X- _ O
join -X- _ O
embedding -X- _ O
architecture -X- _ O
uses -X- _ O
attention -X- _ O
weights -X- _ O
from -X- _ O
the -X- _ O
toxicity -X- _ O
classifiers -X- _ O
to -X- _ O
inform -X- _ O
the -X- _ O
text -X- _ O
generation -X- _ O
model -X- _ O
about -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
relevant -X- _ O
to -X- _ O
toxicity -X- _ O
classification -X- _ O
, -X- _ O
thus -X- _ O
providing -X- _ O
a -X- _ O
heuristic -X- _ O
for -X- _ O
the -X- _ O
related -X- _ O
toxicity -X- _ B-TaskName
explanation -X- _ I-TaskName
task -X- _ O
. -X- _ O
Formal -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
architecture -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.1 -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
these -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
naming -X- _ O
convention -X- _ O
, -X- _ O
“ -X- _ O
E -X- _ O
[ -X- _ O
F -X- _ O
] -X- _ O
" -X- _ O
, -X- _ O
where -X- _ O
“ -X- _ O
[ -X- _ O
F -X- _ O
] -X- _ O
" -X- _ O
is -X- _ O
the -X- _ O
categorical -X- _ O
variable -X- _ O
we -X- _ O
use -X- _ O
for -X- _ O
the -X- _ O
join -X- _ O
embedding -X- _ O
. -X- _ O
We -X- _ O
replace -X- _ O
“ -X- _ O
[ -X- _ O
F -X- _ O
] -X- _ O
" -X- _ O
with -X- _ O
“ -X- _ O
A -X- _ O
" -X- _ O
when -X- _ O
we -X- _ O
train -X- _ O
on -X- _ O
all -X- _ O
features -X- _ O
. -X- _ O
3.2 -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
Explicit -X- _ O
knowledge -X- _ O
is -X- _ O
sourced -X- _ O
from -X- _ O
some -X- _ O
knowledge -X- _ O
base -X- _ O
or -X- _ O
graph -X- _ O
. -X- _ O
Common -X- _ O
sources -X- _ O
include -X- _ O
ConceptNET -X- _ O
, -X- _ O
DBpedia -X- _ O
, -X- _ O
WikiData -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
( -X- _ O
Auer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Vrande -X- _ O
ˇci´c -X- _ O
and -X- _ O
Krötzsch -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
opt -X- _ O
to -X- _ O
use -X- _ O
ConceptNet -X- _ O
( -X- _ O
Speer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
contains -X- _ O
commonsense -X- _ O
knowledge -X- _ O
( -X- _ O
Liu -X- _ O
and -X- _ O
Singh -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
Commonsense -X- _ O
knowledge -X- _ O
incorporates -X- _ O
everyday -X- _ O
concepts -X- _ O
, -X- _ O
especially -X- _ O
knowledge -X- _ O
regarding -X- _ O
social -X- _ O
groups -X- _ O
and -X- _ O
situations -X- _ O
. -X- _ O
Following -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
and -X- _ O
an -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
ranked -X- _ O
triples -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
and -X- _ O
keep -X- _ O
the -X- _ O
top -X- _ O
ktriples -X- _ O
per -X- _ O
post -X- _ O
where -X- _ O
we -X- _ O
vary -X- _ O
the -X- _ O
k∈ -X- _ O
{ -X- _ O
3,5,10,15,20,25 -X- _ O
} -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
both -X- _ O
concatenation -X- _ O
and -X- _ O
attention -X- _ O
based -X- _ O
methods -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
top -X- _ O
ktriples -X- _ O
, -X- _ O
but -X- _ O
settle -X- _ O
on -X- _ O
a -X- _ O
concatenation -X- _ O
based -X- _ O
approach -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
simplicity -X- _ O
and -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
performance -X- _ O
gainsfrom -X- _ O
the -X- _ O
attention -X- _ O
based -X- _ O
approach -X- _ O
. -X- _ O
Results -X- _ O
and -X- _ O
analysis -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
concatenation -X- _ O
and -X- _ O
attention -X- _ O
based -X- _ O
approaches -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
12 -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
these -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
naming -X- _ O
convention -X- _ O
, -X- _ O
“ -X- _ O
E -X- _ O
( -X- _ O
) -X- _ O
" -X- _ O
, -X- _ O
wheredenotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
triples -X- _ O
used -X- _ O
. -X- _ O
3.3 -X- _ O
Implicit -X- _ O
Knowledge -X- _ O
Implicit -X- _ O
knowledge -X- _ O
is -X- _ O
obtained -X- _ O
from -X- _ O
some -X- _ O
text -X- _ O
generator -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
large -X- _ O
pretrained -X- _ O
generative -X- _ O
model -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
such -X- _ O
as -X- _ O
Heinzerling -X- _ O
and -X- _ O
Inui -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
argue -X- _ O
that -X- _ O
large -X- _ O
pretrained -X- _ O
models -X- _ O
can -X- _ O
in -X- _ O
fact -X- _ O
serve -X- _ O
as -X- _ O
knowledge -X- _ O
bases -X- _ O
. -X- _ O
Implicit -X- _ O
knowledge -X- _ O
grants -X- _ O
models -X- _ O
a -X- _ O
probabilistic -X- _ O
view -X- _ O
of -X- _ O
external -X- _ O
raw -X- _ O
text -X- _ O
sources -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
scenario -X- _ O
or -X- _ O
input -X- _ O
, -X- _ O
since -X- _ O
generative -X- _ O
models -X- _ O
tend -X- _ O
to -X- _ O
generate -X- _ O
based -X- _ O
on -X- _ O
statistical -X- _ O
correlations -X- _ O
found -X- _ O
in -X- _ O
their -X- _ O
training -X- _ O
corpora -X- _ O
( -X- _ O
Razniewski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
use -X- _ O
implicit -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
train -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
target -X- _ O
minority -X- _ O
group -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
Following -X- _ O
Sheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
predicted -X- _ O
target -X- _ O
minority -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
input -X- _ O
post -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
prompts -X- _ O
to -X- _ O
induce -X- _ O
biased -X- _ O
prompt -X- _ O
completions -X- _ O
from -X- _ O
GPT -X- _ B-MethodName
models -X- _ O
. -X- _ O
We -X- _ O
may -X- _ O
use -X- _ O
multiple -X- _ O
prompts -X- _ O
per -X- _ O
input -X- _ O
post -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
prompt -X- _ O
completions -X- _ O
generated -X- _ O
is -X- _ O
governed -X- _ O
by -X- _ O
a -X- _ O
hyperparameter -X- _ O
, -X- _ O
k. -X- _ O
Then -X- _ O
we -X- _ O
train -X- _ O
an -X- _ O
independent -X- _ O
BART -X- _ B-MethodName
model -X- _ O
to -X- _ O
generate -X- _ O
these -X- _ O
biased -X- _ O
prompt -X- _ O
completions -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
origin -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
This -X- _ O
BART -X- _ B-MethodName
model -X- _ O
is -X- _ O
then -X- _ O
retrained -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
formal -X- _ O
description -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
these -X- _ O
models -X- _ O
with -X- _ O
“ -X- _ O
I -X- _ O
[ -X- _ O
GPT|GPT-2 -X- _ B-MethodName
] -X- _ O
( -X- _ O
) -X- _ O
" -X- _ O
, -X- _ O
where -X- _ O
“ -X- _ O
GPT -X- _ B-MethodName
" -X- _ O
and -X- _ O
“ -X- _ O
GPT-2 -X- _ B-MethodName
" -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
used -X- _ O
for -X- _ O
prompt -X- _ O
completion -X- _ O
, -X- _ O
whilecorresponds -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
biased -X- _ O
prompt -X- _ O
completions -X- _ O
generated -X- _ O
per -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
3.4 -X- _ O
MGEN -X- _ B-MethodName
Models -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
effective -X- _ O
approach -X- _ O
to -X- _ O
combine -X- _ O
all -X- _ O
three -X- _ O
knowledge -X- _ O
sources -X- _ O
as -X- _ O
input -X- _ O
for -X- _ O
ourMGEN -X- _ B-MethodName
family -X- _ O
of -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
generate -X- _ O
the -X- _ O
final -X- _ O
stereotype -X- _ O
by -X- _ O
integrating -X- _ O
complementary -X- _ O
knowledge -X- _ O
from -X- _ O
these -X- _ O
sources -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
design -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
inspiration -X- _ O
from -X- _ O
Mixture -X- _ O
of -X- _ O
Experts -X- _ O
models -X- _ O
( -X- _ O
Masoudnia -X- _ O
and -X- _ O
Ebrahimpour -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
combine -X- _ O
base -X- _ O
expert -X- _ O
model -X- _ O
outputs -X- _ O
into -X- _ O
a -X- _ O
final -X- _ O
output -X- _ O
using -X- _ O
a -X- _ O
gating -X- _ O
mechanism -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
rely -X- _ O
on -X- _ O
attention -X- _ O
mechanisms -X- _ O
over -X- _ O
the -X- _ O
knowledge -X- _ O
informed -X- _ O
model -X- _ O
outputs -X- _ O
to -X- _ O
serve -X- _ O
as -X- _ O
the -X- _ O
gating -X- _ O
mechanism -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
two -X- _ O
variants -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
variant -X- _ O
is -X- _ O
called -X- _ O
MGEN -X- _ B-MethodName
C -X- _ I-MethodName
which -X- _ O
uses -X- _ O
concatenation -X- _ O
to813 -X- _ O
combine -X- _ O
outputs -X- _ O
from -X- _ O
the -X- _ O
knowledge -X- _ O
informed -X- _ O
models -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
variant -X- _ O
is -X- _ O
called -X- _ O
MGEN -X- _ B-MethodName
M -X- _ I-MethodName
V -X- _ I-MethodName
which -X- _ O
uses -X- _ O
views -X- _ O
to -X- _ O
perform -X- _ O
self -X- _ O
attention -X- _ O
over -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
informed -X- _ O
models -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Yang -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
already -X- _ O
uses -X- _ O
self -X- _ O
attention -X- _ O
over -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
the -X- _ O
MultiView -X- _ O
architecture -X- _ O
to -X- _ O
see -X- _ O
whether -X- _ O
the -X- _ O
additional -X- _ O
self -X- _ O
attention -X- _ O
mechanisms -X- _ O
of -X- _ O
the -X- _ O
MultiView -X- _ O
model -X- _ O
causes -X- _ O
changes -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O
ForMGEN -X- _ B-MethodName
C -X- _ I-MethodName
, -X- _ O
suppose -X- _ O
we -X- _ O
have -X- _ O
k -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
each -X- _ O
trained -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
informed -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
aforementioned -X- _ O
knowledge -X- _ O
types -X- _ O
. -X- _ O
We -X- _ O
con -X- _ O
- -X- _ O
catenate -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
each -X- _ O
knowledge -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
new -X- _ O
input -X- _ O
string -X- _ O
. -X- _ O
Thus -X- _ O
if -X- _ O
each -X- _ O
model -X- _ O
Moutputs -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
the -X- _ O
following -X- _ O
concatenated -X- _ O
input -X- _ O
string -X- _ O
: -X- _ O
“ -X- _ O
s -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s··· -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s -X- _ O
" -X- _ O
. -X- _ O
Now -X- _ O
, -X- _ O
letMbe -X- _ O
a -X- _ O
standard -X- _ O
pretrained -X- _ O
BART -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
model -X- _ O
Mto -X- _ O
produce -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
using -X- _ O
“ -X- _ O
s -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s··· -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s -X- _ O
" -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
knowledge -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
Mare -X- _ O
fixed -X- _ O
when -X- _ O
training -X- _ O
M. -X- _ O
Model -X- _ O
M -X- _ O
serves -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
MGEN -X- _ B-MethodName
C -X- _ I-MethodName
model -X- _ O
. -X- _ O
MGEN -X- _ B-MethodName
M -X- _ I-MethodName
V -X- _ I-MethodName
uses -X- _ O
the -X- _ O
MultiView -X- _ O
architecture -X- _ O
proposed -X- _ O
by -X- _ O
Chen -X- _ O
and -X- _ O
Yang -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
M -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
Mare -X- _ O
treated -X- _ O
as -X- _ O
separate -X- _ O
views -X- _ O
. -X- _ O
If -X- _ O
each -X- _ O
model -X- _ O
Moutputs -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
, -X- _ O
then -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
Mwe -X- _ O
configure -X- _ O
the -X- _ O
corresponding -X- _ O
view -X- _ O
as -X- _ O
the -X- _ O
string -X- _ O
“ -X- _ O
vs -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
· -X- _ O
· -X- _ O
· -X- _ O
vsv -X- _ O
· -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s -X- _ O
" -X- _ O
, -X- _ O
where -X- _ O
v -X- _ O
, -X- _ O
v -X- _ O
, -X- _ O
andvare -X- _ O
view -X- _ O
tokens -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
vis -X- _ O
always -X- _ O
the -X- _ O
first -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
view -X- _ O
string -X- _ O
and -X- _ O
vandvsurround -X- _ O
M -X- _ O
’s -X- _ O
output -X- _ O
. -X- _ O
We -X- _ O
configure -X- _ O
ksuch -X- _ O
views -X- _ O
( -X- _ O
one -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
) -X- _ O
and -X- _ O
pass -X- _ O
each -X- _ O
into -X- _ O
the -X- _ O
BART -X- _ B-MethodName
MultiView -X- _ I-MethodName
model -X- _ O
as -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
views -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
The -X- _ O
BART -X- _ B-MethodName
MultiView -X- _ I-MethodName
model -X- _ O
is -X- _ O
then -X- _ O
trained -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
corresponding -X- _ O
output -X- _ O
stereotype -X- _ O
. -X- _ O
For -X- _ O
details -X- _ O
on -X- _ O
the -X- _ O
MultiView -X- _ O
architecture -X- _ O
, -X- _ O
please -X- _ O
see -X- _ O
Chen -X- _ O
and -X- _ O
Yang -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
3.5 -X- _ O
Training -X- _ O
We -X- _ O
utilize -X- _ O
the -X- _ O
BART -X- _ B-MethodName
encoder -X- _ O
decoder -X- _ O
framework -X- _ O
throughout -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
batch -X- _ O
gradient -X- _ O
descent -X- _ O
when -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
batch -X- _ O
Bwith -X- _ O
padded -X- _ O
input -X- _ O
sequences -X- _ O
Xof -X- _ O
length -X- _ O
Nand -X- _ O
corresponding -X- _ O
padded -X- _ O
target -X- _ O
sequences -X- _ O
Yof -X- _ O
length -X- _ O
N -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
knowledge -X- _ O
Kfrom -X- _ O
some -X- _ O
knowledge814 -X- _ O
source -X- _ O
, -X- _ O
we -X- _ O
minimize -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
: -X- _ O
L=−1 -X- _ O
|B|N· -X- _ O
/ -X- _ O
summationdisplay -X- _ O
/ -X- _ O
summationdisplaylogp -X- _ O
( -X- _ O
Y|Y -X- _ O
, -X- _ O
X -X- _ O
, -X- _ O
K -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
4 -X- _ O
Experimental -X- _ O
Setup -X- _ O
4.1 -X- _ O
Dataset -X- _ O
We -X- _ O
conduct -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
SBIC -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Implicit -X- _ B-DatasetName
Hate -X- _ O
dataset -X- _ O
( -X- _ O
ElSherief -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
SBIC -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
an -X- _ O
input -X- _ O
post -X- _ O
, -X- _ O
toxicity -X- _ O
annotations -X- _ O
and -X- _ O
free -X- _ O
text -X- _ O
annotations -X- _ O
of -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
. -X- _ O
We -X- _ O
work -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
and -X- _ O
the -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
. -X- _ O
The -X- _ O
Implicit -X- _ B-DatasetName
Hate -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
ElSherief -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
contains -X- _ O
free -X- _ O
text -X- _ O
annotations -X- _ O
of -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
. -X- _ O
Dataset -X- _ O
statistics -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
4.2 -X- _ O
Baselines -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
models -X- _ O
with -X- _ O
BART -X- _ B-MethodName
, -X- _ O
and -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
baselines -X- _ O
from -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
: -X- _ O
•GPT -X- _ B-MethodName
: -X- _ O
Following -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
GPT -X- _ B-MethodName
pretrained -X- _ O
model -X- _ O
from -X- _ O
huggingface -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
toxicity -X- _ O
classifications -X- _ O
, -X- _ O
the -X- _ O
Target -X- _ O
Minority -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Implied -X- _ O
Stereotype -X- _ O
as -X- _ O
a -X- _ O
string -X- _ O
, -X- _ O
when -X- _ O
prompted -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
•GPT-2 -X- _ B-MethodName
: -X- _ O
We -X- _ O
train -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
setting -X- _ O
as -X- _ O
the -X- _ O
GPT -X- _ B-MethodName
Baseline -X- _ O
, -X- _ O
but -X- _ O
use -X- _ O
the -X- _ O
GPT-2 -X- _ B-MethodName
pretrained -X- _ O
model -X- _ O
from -X- _ O
huggingface -X- _ O
. -X- _ O
•BART -X- _ B-MethodName
: -X- _ O
We -X- _ O
train -X- _ O
a -X- _ O
standard -X- _ O
pretrained -X- _ O
BART -X- _ B-MethodName
model -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
when -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
4.3 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
We -X- _ O
use -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
and -X- _ O
BERTScore -X- _ B-MetricName
( -X- _ O
Zhang -X- _ O
* -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
take -X- _ O
the -X- _ O
maximum -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
hypothesis -X- _ O
over -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
references -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
BERTScore -X- _ B-MetricName
since -X- _ O
it -X- _ O
looks -X- _ O
forsemantic -X- _ O
similarity -X- _ O
, -X- _ O
unlike -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
metrics -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
acknowledge -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
limitation -X- _ O
, -X- _ O
we -X- _ O
ultimately -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
human -X- _ O
evaluation -X- _ O
for -X- _ O
multiple -X- _ O
reasons -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
stereotypes -X- _ O
are -X- _ O
minimal -X- _ O
in -X- _ O
length -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
manual -X- _ B-MetricName
analyses -X- _ I-MetricName
of -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
following -X- _ O
precedent -X- _ O
set -X- _ O
by -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
minimize -X- _ O
annotator -X- _ O
exposure -X- _ O
to -X- _ O
harmful -X- _ O
content -X- _ O
. -X- _ O
4.4 -X- _ O
Results -X- _ O
on -X- _ O
SBIC -X- _ B-DatasetName
Our -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
dev -X- _ O
since -X- _ O
both -X- _ O
sets -X- _ O
of -X- _ O
results -X- _ O
track -X- _ O
similar -X- _ O
trends -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
models -X- _ O
outperform -X- _ O
all -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
AfterMGEN -X- _ B-MethodName
, -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
Implicit -X- _ O
Knowledge -X- _ O
sources -X- _ O
perform -X- _ O
best -X- _ O
. -X- _ O
These -X- _ O
are -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
, -X- _ O
in -X- _ O
turn -X- _ O
followed -X- _ O
by -X- _ O
model -X- _ O
using -X- _ O
Expert -X- _ O
Knowledge -X- _ O
. -X- _ O
Both -X- _ O
models -X- _ O
with -X- _ O
explicit -X- _ O
and -X- _ O
with -X- _ O
implicit -X- _ O
knowledge -X- _ O
outperform -X- _ O
expert -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
models -X- _ O
using -X- _ O
implicit -X- _ O
knowledge -X- _ O
tend -X- _ O
to -X- _ O
perform -X- _ O
best -X- _ O
overall -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
: -X- _ O
from -X- _ O
0.650 -X- _ B-MetricValue
to0.683 -X- _ B-MetricValue
, -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
: -X- _ O
from -X- _ O
0.624 -X- _ B-MetricValue
to0.659 -X- _ B-MetricValue
, -X- _ O
BERTScore -X- _ B-MetricName
: -X- _ O
from -X- _ O
0.759to0.800 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
likely -X- _ O
because -X- _ O
implicit -X- _ O
knowledge -X- _ O
is -X- _ O
less -X- _ O
structured -X- _ O
and -X- _ O
hence -X- _ O
easier -X- _ O
to -X- _ O
induce -X- _ O
bias -X- _ O
from -X- _ O
( -X- _ O
Petroni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
source -X- _ O
( -X- _ O
ConceptNET -X- _ O
) -X- _ O
for -X- _ O
explicit -X- _ O
knowledge -X- _ O
may -X- _ O
be -X- _ O
biased -X- _ O
( -X- _ O
Mehrabi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
retrieved -X- _ O
stereotypes -X- _ O
are -X- _ O
often -X- _ O
mixed -X- _ O
with -X- _ O
general -X- _ O
, -X- _ O
unbiased -X- _ O
facts -X- _ O
. -X- _ O
TheMGEN -X- _ B-MethodName
models -X- _ O
outperform -X- _ O
every -X- _ O
other -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
intuitive -X- _ O
sense -X- _ O
since -X- _ O
MGEN -X- _ B-MethodName
synthesizes -X- _ O
multiple -X- _ O
types -X- _ O
of -X- _ O
knowledge -X- _ O
. -X- _ O
Unexpectedly -X- _ O
, -X- _ O
MGEN -X- _ B-MethodName
M -X- _ I-MethodName
V -X- _ I-MethodName
model -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
performance -X- _ O
( -X- _ O
the -X- _ O
absolute -X- _ O
difference -X- _ O
is -X- _ O
within -X- _ O
0.002 -X- _ B-MetricValue
across -X- _ O
all -X- _ O
scores -X- _ O
) -X- _ O
over -X- _ O
MGEN -X- _ B-MethodName
C -X- _ I-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
likely -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
MultiView -X- _ O
model -X- _ O
was -X- _ O
intended -X- _ O
to -X- _ O
capture -X- _ O
metasequences -X- _ O
in -X- _ O
text -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Yang -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
in -X- _ O
our -X- _ O
setting -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
not -X- _ O
sequential -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
models -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
source -X- _ O
models -X- _ O
, -X- _ O
despite -X- _ O
their -X- _ O
input -X- _ O
being -X- _ O
sourced -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
models -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
despite -X- _ O
differing -X- _ O
performance -X- _ O
, -X- _ O
models -X- _ O
from -X- _ O
different -X- _ O
knowledge -X- _ O
sources -X- _ O
are -X- _ O
likely -X- _ O
providing -X- _ O
some -X- _ O
distinct -X- _ O
and -X- _ O
complementary -X- _ O
information -X- _ O
. -X- _ O
4.5 -X- _ O
Results -X- _ O
on -X- _ O
Implicit -X- _ B-DatasetName
Hate -X- _ I-DatasetName
Speech -X- _ I-DatasetName
Corpus -X- _ O
Results -X- _ O
on -X- _ O
the -X- _ O
implicit -X- _ B-DatasetName
hate -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
ElSherief -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
( -X- _ O
including815 -X- _ O
baselines -X- _ O
) -X- _ O
generally -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
they -X- _ O
do -X- _ O
on -X- _ O
the -X- _ O
SBIC -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
likely -X- _ O
because -X- _ O
the -X- _ O
implicit -X- _ B-DatasetName
hate -X- _ I-DatasetName
corpus -X- _ O
contains -X- _ O
one -X- _ O
reference -X- _ O
per -X- _ O
post -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
SBIC -X- _ B-DatasetName
dataset -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
Expert -X- _ O
knowledge -X- _ O
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
perform -X- _ O
slightly -X- _ O
better -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
likely -X- _ O
because -X- _ O
the -X- _ O
Expert -X- _ O
model -X- _ O
relies -X- _ O
on -X- _ O
toxicity -X- _ O
classifications -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
n’t -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
implicit -X- _ O
hate -X- _ O
corpus -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
our -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
generalized -X- _ O
to -X- _ O
text -X- _ O
generation -X- _ O
tasks -X- _ O
on -X- _ O
other -X- _ O
datasets -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
likely -X- _ O
need -X- _ O
multiple -X- _ O
reference -X- _ O
points -X- _ O
where -X- _ O
the -X- _ O
implicit -X- _ O
hate -X- _ O
corpus -X- _ O
only -X- _ O
has -X- _ O
one -X- _ O
. -X- _ O
5 -X- _ O
Error -X- _ O
Analysis -X- _ O
and -X- _ O
Ablation -X- _ O
Studies -X- _ O
We -X- _ O
perform -X- _ O
analyses -X- _ O
and -X- _ O
ablation -X- _ O
studies -X- _ O
on -X- _ O
model -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
SBIC -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
these -X- _ O
on -X- _ O
the -X- _ O
implicit -X- _ B-DatasetName
hate -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
have -X- _ O
too -X- _ O
few -X- _ O
references -X- _ O
per -X- _ O
example -X- _ O
. -X- _ O
Examples -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
and -X- _ O
challenge -X- _ O
types -X- _ O
below -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
An -X- _ O
additional -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
error -X- _ O
and -X- _ O
challenge -X- _ O
type -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
13 -X- _ O
. -X- _ O
5.1 -X- _ O
Error -X- _ O
Analysis -X- _ O
We -X- _ O
categorize -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
errors -X- _ O
made -X- _ O
by -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
sample -X- _ O
of -X- _ O
200examples -X- _ O
from -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
and -X- _ O
provide -X- _ O
the -X- _ O
distributions -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
the -X- _ O
error -X- _ O
categories -X- _ O
below -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
Non -X- _ O
- -X- _ O
Existent -X- _ O
Stereotype -X- _ O
: -X- _ O
Model -X- _ O
generates -X- _ O
a -X- _ O
stereotype -X- _ O
when -X- _ O
the -X- _ O
reference -X- _ O
stereotype -X- _ O
is -X- _ O
an -X- _ O
empty -X- _ O
string -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
Ignores -X- _ O
Stereotype -X- _ O
: -X- _ O
Model -X- _ O
does -X- _ O
not -X- _ O
generate -X- _ O
a -X- _ O
stereotype -X- _ O
when -X- _ O
the -X- _ O
reference -X- _ O
stereotype -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
empty -X- _ O
string -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
Incorrect -X- _ O
Target -X- _ O
Minority -X- _ O
: -X- _ O
Model -X- _ O
uses -X- _ O
the -X- _ O
incorrect -X- _ O
target -X- _ O
minority -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O
Incorrect -X- _ O
Stereotype -X- _ O
: -X- _ O
Model -X- _ O
uses -X- _ O
the -X- _ O
correct -X- _ O
target -X- _ O
minority -X- _ O
but -X- _ O
generates -X- _ O
an -X- _ O
incorrect -X- _ O
or -X- _ O
overly -X- _ O
general -X- _ O
stereotype.816 -X- _ O
The -X- _ O
baseline -X- _ O
GPT -X- _ B-MethodName
models -X- _ O
tend -X- _ O
to -X- _ O
make -X- _ O
more -X- _ O
errors -X- _ O
of -X- _ O
every -X- _ O
type -X- _ O
, -X- _ O
except -X- _ O
that -X- _ O
the -X- _ O
expert -X- _ O
model -X- _ O
makes -X- _ O
more -X- _ O
errors -X- _ O
of -X- _ O
type -X- _ O
4 -X- _ O
. -X- _ O
The -X- _ O
expert -X- _ O
model -X- _ O
likely -X- _ O
focuses -X- _ O
on -X- _ O
tokens -X- _ O
that -X- _ O
trigger -X- _ O
toxicity -X- _ O
classifications -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
other -X- _ O
relevant -X- _ O
tokens -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
example -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
“ -X- _ O
black -X- _ O
" -X- _ O
may -X- _ O
be -X- _ O
triggering -X- _ O
the -X- _ O
Expert -X- _ O
Model -X- _ O
, -X- _ O
causing -X- _ O
an -X- _ O
error -X- _ O
of -X- _ O
type -X- _ O
4 -X- _ O
. -X- _ O
The -X- _ O
knowledge -X- _ O
enhanced -X- _ O
models -X- _ O
rarely -X- _ O
fail -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
stereotype -X- _ O
( -X- _ O
type -X- _ O
2 -X- _ O
error -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
they -X- _ O
often -X- _ O
detect -X- _ O
non -X- _ O
existent -X- _ O
stereotypes -X- _ O
( -X- _ O
type -X- _ O
1 -X- _ O
error -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
less -X- _ O
often -X- _ O
than -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
third -X- _ O
example -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
“ -X- _ O
contraceptive -X- _ O
" -X- _ O
may -X- _ O
be -X- _ O
incorrectly -X- _ O
triggering -X- _ O
the -X- _ O
implicit -X- _ O
and -X- _ O
explicit -X- _ O
models -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
expert -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
triggered -X- _ O
. -X- _ O
5.2 -X- _ O
Challenges -X- _ O
in -X- _ O
Stereotype -X- _ O
Generation -X- _ O
We -X- _ O
categorize -X- _ O
the -X- _ O
various -X- _ O
challenges -X- _ O
faced -X- _ O
by -X- _ O
our -X- _ O
text -X- _ O
generation -X- _ O
models -X- _ O
and -X- _ O
provide -X- _ O
distributions -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
and -X- _ O
counts -X- _ O
in -X- _ O
Appendix -X- _ O
15 -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
same -X- _ O
sample -X- _ O
of -X- _ O
200examples -X- _ O
from -X- _ O
Section -X- _ O
5.1 -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
Misunderstands -X- _ O
Post -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
fundamentally -X- _ O
misunderstands -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
generates -X- _ O
an -X- _ O
irrelevant -X- _ O
stereotype -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
High -X- _ O
Sensitivity -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
highly -X- _ O
sensitive -X- _ O
to -X- _ O
trigger -X- _ O
words -X- _ O
, -X- _ O
which -X- _ O
causes -X- _ O
it -X- _ O
to -X- _ O
detect -X- _ O
non -X- _ O
- -X- _ O
existent -X- _ O
stereotypes -X- _ O
or -X- _ O
generate -X- _ O
stereotypes -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
triggers -X- _ O
alone -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
Localized -X- _ O
Generation -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
focuses -X- _ O
only -X- _ O
on -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
generates -X- _ O
stereotypes -X- _ O
based -X- _ O
on -X- _ O
those -X- _ O
parts -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
post.4 -X- _ O
. -X- _ O
Does -X- _ O
not -X- _ O
Draw -X- _ O
Connections -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
clearly -X- _ O
considers -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
post -X- _ O
, -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
draw -X- _ O
connections -X- _ O
between -X- _ O
the -X- _ O
different -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O
Misunderstands -X- _ O
Sarcasm -X- _ O
or -X- _ O
Irony -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
takes -X- _ O
a -X- _ O
more -X- _ O
literal -X- _ O
interpretation -X- _ O
of -X- _ O
a -X- _ O
sarcastic -X- _ O
or -X- _ O
ironic -X- _ O
post -X- _ O
, -X- _ O
causing -X- _ O
it -X- _ O
to -X- _ O
output -X- _ O
text -X- _ O
that -X- _ O
has -X- _ O
the -X- _ O
opposite -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
stereotype -X- _ O
. -X- _ O
6 -X- _ O
. -X- _ O
Ignores -X- _ O
Stereotype -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
generate -X- _ O
a -X- _ O
stereotype -X- _ O
despite -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
empty -X- _ O
reference -X- _ O
stereotype -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
model -X- _ O
tends -X- _ O
to -X- _ O
misunderstand -X- _ O
sarcasm -X- _ O
and -X- _ O
irony -X- _ O
at -X- _ O
a -X- _ O
slightly -X- _ O
higher -X- _ O
rate -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
knowledge -X- _ O
model -X- _ O
types -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
fourth -X- _ O
example -X- _ O
of -X- _ O
5 -X- _ O
, -X- _ O
MGEN -X- _ B-MethodName
and -X- _ O
the -X- _ O
Implicit -X- _ O
Model -X- _ O
take -X- _ O
literal -X- _ O
interpretations -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
The -X- _ O
Implicit -X- _ O
Model -X- _ O
type -X- _ O
has -X- _ O
difficulty -X- _ O
with -X- _ O
drawing -X- _ O
connections -X- _ O
over -X- _ O
the -X- _ O
input -X- _ O
( -X- _ O
challenge -X- _ O
type -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
the -X- _ O
6th -X- _ O
row -X- _ O
of -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
draw -X- _ O
a -X- _ O
connection -X- _ O
between -X- _ O
the -X- _ O
target -X- _ O
minority -X- _ O
and -X- _ O
the -X- _ O
stereotypes -X- _ O
present -X- _ O
. -X- _ O
5.3 -X- _ O
How -X- _ O
MGEN -X- _ B-MethodName
Synthesizes -X- _ O
Knowledge -X- _ O
Table -X- _ O
5 -X- _ O
provides -X- _ O
examples -X- _ O
of -X- _ O
MGEN -X- _ B-MethodName
synthesizing -X- _ O
knowledge -X- _ O
across -X- _ O
sources -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
third -X- _ O
example -X- _ O
, -X- _ O
MGEN -X- _ B-MethodName
produces -X- _ O
an -X- _ O
empty -X- _ O
string -X- _ O
even -X- _ O
though -X- _ O
two -X- _ O
of -X- _ O
the -X- _ O
more -X- _ O
reliable -X- _ O
sources -X- _ O
( -X- _ O
explicit -X- _ O
and -X- _ O
implicit -X- _ O
knowledge -X- _ O
) -X- _ O
produce -X- _ O
non -X- _ O
empty -X- _ O
strings -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
fifth -X- _ O
example -X- _ O
, -X- _ O
MGEN -X- _ B-MethodName
clearly -X- _ O
combines -X- _ O
parts -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
knowledge -X- _ O
sources -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
the -X- _ O
sixth -X- _ O
example -X- _ O
MGEN -X- _ B-MethodName
produces -X- _ O
a -X- _ O
more -X- _ O
accurate -X- _ O
stereotype -X- _ O
than -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
seems -X- _ O
thatMGEN -X- _ B-MethodName
does -X- _ O
not -X- _ O
simply -X- _ O
attempt -X- _ O
to -X- _ O
copy -X- _ O
the -X- _ O
correct -X- _ O
model -X- _ O
, -X- _ O
but -X- _ O
actually -X- _ O
possess -X- _ O
a -X- _ O
deeper -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
types -X- _ O
it -X- _ O
synthesizes -X- _ O
. -X- _ O
5.4 -X- _ O
Implicit -X- _ O
Knowledge -X- _ O
Ablation -X- _ O
Study -X- _ O
Table -X- _ O
6 -X- _ O
contains -X- _ O
results -X- _ O
of -X- _ O
ablations -X- _ O
on -X- _ O
the -X- _ O
Implicit -X- _ O
Knowledge -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
vary -X- _ O
the -X- _ O
amount -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
and -X- _ O
source -X- _ O
( -X- _ O
GPT -X- _ B-MethodName
and -X- _ O
GPT-2 -X- _ B-MethodName
) -X- _ O
of -X- _ O
implicit -X- _ O
knowledge -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
which -X- _ O
sources -X- _ O
knowledge -X- _ O
using -X- _ O
GPT -X- _ B-MethodName
only -X- _ O
outperforms -X- _ O
the -X- _ O
model -X- _ O
sourcing -X- _ O
knowledge -X- _ O
using -X- _ O
GPT-2 -X- _ B-MethodName
when -X- _ O
k= -X- _ O
3 -X- _ O
. -X- _ O
When -X- _ O
k= -X- _ O
15 -X- _ O
, -X- _ O
the -X- _ O
latter -X- _ O
model -X- _ O
sourcing -X- _ O
GPT-2 -X- _ B-MethodName
knowledge -X- _ O
outperforms -X- _ O
the -X- _ O
model -X- _ O
sourcing -X- _ O
knowledge -X- _ O
from -X- _ O
GPT -X- _ B-MethodName
. -X- _ O
It -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
GPT-2 -X- _ B-MethodName
is -X- _ O
less -X- _ O
biased -X- _ O
than -X- _ O
GPT -X- _ B-MethodName
, -X- _ O
thus -X- _ O
benefiting -X- _ O
our -X- _ O
model -X- _ O
for -X- _ O
low -X- _ O
k -X- _ O
, -X- _ O
but -X- _ O
that -X- _ O
these -X- _ O
benefits -X- _ O
decrease -X- _ O
askincreases -X- _ O
. -X- _ O
With -X- _ O
greater -X- _ O
k -X- _ O
, -X- _ O
both -X- _ O
models -X- _ O
have -X- _ O
a -X- _ O
greater -X- _ O
chance -X- _ O
of -X- _ O
exhibiting -X- _ O
bias.817 -X- _ O
5.5 -X- _ O
MGEN -X- _ B-MethodName
CONCAT -X- _ I-MethodName
Ablation -X- _ O
Study -X- _ O
In -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
ablations -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
knowledge -X- _ O
informed -X- _ O
models -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
CONCAT -X- _ I-MethodName
model -X- _ O
. -X- _ O
Let -X- _ O
kbe -X- _ B-HyperparameterName
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
knowledge -X- _ I-HyperparameterName
informed -X- _ I-HyperparameterName
models -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
variant -X- _ O
using -X- _ O
k= -X- _ B-HyperparameterName
6 -X- _ B-HyperparameterValue
models -X- _ O
performs -X- _ O
best -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
models -X- _ O
variantswithin -X- _ O
each -X- _ O
knowledge -X- _ O
type -X- _ O
only -X- _ O
vary -X- _ O
by -X- _ O
some -X- _ O
hyperparameter -X- _ O
, -X- _ O
information -X- _ O
gain -X- _ O
probably -X- _ O
saturates -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
models -X- _ O
increases -X- _ O
; -X- _ O
however -X- _ O
performance -X- _ O
decreases -X- _ O
when -X- _ O
k= -X- _ B-HyperparameterName
9 -X- _ B-HyperparameterValue
. -X- _ O
Since -X- _ O
we -X- _ O
tend -X- _ O
to -X- _ O
include -X- _ O
models -X- _ O
with -X- _ O
lower -X- _ O
performance -X- _ O
for -X- _ O
larger -X- _ O
k -X- _ B-HyperparameterName
, -X- _ O
worse -X- _ O
performing -X- _ O
models -X- _ O
are -X- _ O
likely -X- _ O
counter -X- _ O
productive -X- _ O
. -X- _ O
6 -X- _ O
Limitations -X- _ O
We -X- _ O
discuss -X- _ O
limitations -X- _ O
of -X- _ O
our -X- _ O
study -X- _ O
here -X- _ O
. -X- _ O
Per -X- _ O
the -X- _ O
discussion -X- _ O
in -X- _ O
Subsection -X- _ O
4.3 -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
human -X- _ O
evaluation -X- _ O
of -X- _ O
our -X- _ O
results -X- _ O
for -X- _ O
multiple -X- _ O
reasons -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
believe -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
limitation -X- _ O
, -X- _ O
and -X- _ O
think -X- _ O
future -X- _ O
work -X- _ O
may -X- _ O
benefit -X- _ O
from -X- _ O
some -X- _ O
form -X- _ O
of -X- _ O
human -X- _ O
evaluation -X- _ O
, -X- _ O
while -X- _ O
mitigating -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
concerns -X- _ O
mentioned -X- _ O
in -X- _ O
Subsection -X- _ O
4.3 -X- _ O
. -X- _ O
TheMGEN -X- _ B-MethodName
model -X- _ O
requires -X- _ O
significant -X- _ O
computational -X- _ O
power -X- _ O
. -X- _ O
One -X- _ O
needs -X- _ O
to -X- _ O
train -X- _ O
models -X- _ O
across -X- _ O
knowledge -X- _ O
sources -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
train -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
model -X- _ O
itself -X- _ O
. -X- _ O
Future -X- _ O
work -X- _ O
may -X- _ O
alleviate -X- _ O
this -X- _ O
burden -X- _ O
by -X- _ O
considering -X- _ O
end -X- _ O
to -X- _ O
end -X- _ O
solutions -X- _ O
, -X- _ O
or -X- _ O
more -X- _ O
efficient -X- _ O
knowledge -X- _ O
retrieval -X- _ O
techniques -X- _ O
. -X- _ O
Future -X- _ O
work -X- _ O
could -X- _ O
perform -X- _ O
an -X- _ O
“ -X- _ O
in -X- _ O
the -X- _ O
wild -X- _ O
" -X- _ O
analysis -X- _ O
, -X- _ O
produced -X- _ O
by -X- _ O
procuring -X- _ O
random -X- _ O
comments -X- _ O
from -X- _ O
the -X- _ O
internet -X- _ O
and -X- _ O
running -X- _ O
our -X- _ O
proposed -X- _ O
models -X- _ O
on -X- _ O
these -X- _ O
comments -X- _ O
, -X- _ O
to -X- _ O
determine -X- _ O
how -X- _ O
effective -X- _ O
the -X- _ O
models -X- _ O
might -X- _ O
be -X- _ O
in -X- _ O
a -X- _ O
real -X- _ O
world -X- _ O
setting -X- _ O
. -X- _ O
Further -X- _ O
ablations -X- _ O
may -X- _ O
also -X- _ O
provide -X- _ O
insight -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
our -X- _ O
implicit -X- _ O
knowledge -X- _ O
models -X- _ O
, -X- _ O
it818may -X- _ O
be -X- _ O
helpful -X- _ O
to -X- _ O
remove -X- _ O
BART -X- _ O
altogether -X- _ O
and -X- _ O
instead -X- _ O
use -X- _ O
GPT -X- _ O
for -X- _ O
predicting -X- _ O
the -X- _ O
target -X- _ O
minority -X- _ O
, -X- _ O
pretraining -X- _ O
on -X- _ O
implicit -X- _ O
knowledge -X- _ O
and -X- _ O
for -X- _ O
generating -X- _ O
the -X- _ O
final -X- _ O
stereotype -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
be -X- _ O
helpful -X- _ O
to -X- _ O
standardize -X- _ O
the -X- _ O
incorporation -X- _ O
of -X- _ O
knowledge -X- _ O
into -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
using -X- _ O
different -X- _ O
knowledge -X- _ O
types -X- _ O
may -X- _ O
be -X- _ O
directly -X- _ O
compared -X- _ O
. -X- _ O
7 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
MGto -X- _ B-MethodName
generate -X- _ O
the -X- _ O
stereotypes -X- _ O
present -X- _ O
in -X- _ O
toxic -X- _ O
social -X- _ O
media -X- _ O
posts -X- _ O
, -X- _ O
using -X- _ O
multiple -X- _ O
knowledge -X- _ O
sources -X- _ O
. -X- _ O
We -X- _ O
categorized -X- _ O
three -X- _ O
different -X- _ O
sources -X- _ O
of -X- _ O
knowledge -X- _ O
and -X- _ O
synthesize -X- _ O
the -X- _ O
sources -X- _ O
of -X- _ O
knowledge -X- _ O
using -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
models -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
knowledge -X- _ O
models -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
baselines -X- _ O
, -X- _ O
models -X- _ O
built -X- _ O
on -X- _ O
different -X- _ O
knowledge -X- _ O
types -X- _ O
vary -X- _ O
in -X- _ O
strengths -X- _ O
and -X- _ O
weaknesses -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
expert -X- _ O
model -X- _ O
suffers -X- _ O
from -X- _ O
high -X- _ O
sensitivity -X- _ O
to -X- _ O
trigger -X- _ O
words -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
implicit -X- _ O
models -X- _ O
may -X- _ O
not -X- _ O
draw -X- _ O
connections -X- _ O
over -X- _ O
complex -X- _ O
inputs -X- _ O
. -X- _ O
The -X- _ O
MGEN -X- _ B-MethodName
models -X- _ O
takes -X- _ O
this -X- _ O
into -X- _ O
account -X- _ O
and -X- _ O
minimizes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
on -X- _ O
which -X- _ O
it -X- _ O
has -X- _ O
errors -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
faces -X- _ O
challenges -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
that -X- _ O
mixture -X- _ O
and -X- _ O
ensemble -X- _ O
methods -X- _ O
as -X- _ O
simple -X- _ O
as -X- _ O
concatenation -X- _ O
can -X- _ O
leverage -X- _ O
the -X- _ O
complementary -X- _ O
nature -X- _ O
of -X- _ O
distinct -X- _ O
knowledge -X- _ O
sources -X- _ O
to -X- _ O
produce -X- _ O
high -X- _ O
quality -X- _ O
text -X- _ O
generations -X- _ O
. -X- _ O
Ethical -X- _ O
Considerations -X- _ O
Models -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
one -X- _ O
proposed -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
which -X- _ O
output -X- _ O
toxicity -X- _ O
classifications -X- _ O
of -X- _ O
text -X- _ O
or -X- _ O
speech -X- _ O
and -X- _ O
reasoning -X- _ O
behind -X- _ O
such -X- _ O
classifications -X- _ O
should -X- _ O
be -X- _ O
used -X- _ O
with -X- _ O
care -X- _ O
. -X- _ O
Considerations -X- _ O
of -X- _ O
algorithmic -X- _ O
fairness -X- _ O
should -X- _ O
be -X- _ O
taken -X- _ O
into -X- _ O
account -X- _ O
( -X- _ O
Corbett -X- _ O
- -X- _ O
Davies -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
cultural -X- _ O
differences -X- _ O
( -X- _ O
Oliva -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
racial -X- _ O
biases -X- _ O
( -X- _ O
Xia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
which -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
misclassifications -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
Care -X- _ O
should -X- _ O
be -X- _ O
taken -X- _ O
to -X- _ O
avoid -X- _ O
political -X- _ O
bias -X- _ O
in -X- _ O
training -X- _ O
datasets -X- _ O
, -X- _ O
when -X- _ O
training -X- _ O
these -X- _ O
models -X- _ O
for -X- _ O
deployment -X- _ O
purposes -X- _ O
( -X- _ O
Wich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
concerns -X- _ O
about -X- _ O
censorship -X- _ O
should -X- _ O
be -X- _ O
taken -X- _ O
seriously -X- _ O
( -X- _ O
Heins -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
References819820 -X- _ O
A -X- _ O
Formal -X- _ O
Details -X- _ O
for -X- _ O
Knowledge -X- _ O
Incorporation -X- _ O
A.1 -X- _ O
Expert -X- _ O
Knowledge -X- _ O
A.1.1 -X- _ O
Incorporating -X- _ O
Expert -X- _ O
Knowledge -X- _ O
using -X- _ O
the -X- _ O
Join -X- _ O
Embedding -X- _ O
Technique -X- _ O
Given -X- _ O
the -X- _ O
BERT -X- _ O
classifier -X- _ O
with -X- _ O
mattention -X- _ O
heads -X- _ O
, -X- _ O
an -X- _ O
input -X- _ O
with -X- _ O
length -X- _ O
n -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
with -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
pass -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ O
classifier -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
attention -X- _ O
head -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
, -X- _ O
namely -X- _ O
a -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
each -X- _ O
in -X- _ O
R. -X- _ O
We821also -X- _ O
pass -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
and -X- _ O
retrieve -X- _ O
the -X- _ O
BART -X- _ B-MethodName
encoded -X- _ O
input -X- _ O
, -X- _ O
namely -X- _ O
H∈R. -X- _ O
Let -X- _ O
v -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
vinRbe -X- _ O
trainable -X- _ O
weight -X- _ O
vectors -X- _ O
. -X- _ O
For -X- _ O
thej -X- _ O
- -X- _ O
th -X- _ O
row -X- _ O
vector -X- _ O
, -X- _ O
hofH -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
an -X- _ O
enriched -X- _ O
hidden -X- _ O
state -X- _ O
has -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
h -X- _ O
) -X- _ O
=h+ -X- _ O
/ -X- _ O
summationdisplayav -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
then -X- _ O
pass -X- _ O
the -X- _ O
enriched -X- _ O
hidden -X- _ O
state -X- _ O
through -X- _ O
the -X- _ O
BART -X- _ B-MethodName
decoder -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
output -X- _ O
stereotype -X- _ O
. -X- _ O
To -X- _ O
combine -X- _ O
knowledge -X- _ O
from -X- _ O
multiple -X- _ O
variables -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
the -X- _ O
enriched -X- _ O
hidden -X- _ O
state -X- _ O
in -X- _ O
Equation -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
over -X- _ O
each -X- _ O
variable -X- _ O
. -X- _ O
A.2 -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
A.2.1 -X- _ O
Incorporating -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
using -X- _ O
Concatenation -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
formal -X- _ O
details -X- _ O
on -X- _ O
how -X- _ O
we -X- _ O
incorporate -X- _ O
explicit -X- _ O
knowledge -X- _ O
from -X- _ O
ConceptNET -X- _ O
using -X- _ O
concatenation -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
topktriples -X- _ O
( -X- _ O
varying -X- _ O
k∈ -X- _ O
{ -X- _ O
3,5,10,15,20,25 -X- _ O
} -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
extract -X- _ O
nouns -X- _ O
, -X- _ O
verbs -X- _ O
, -X- _ O
and -X- _ O
adjectives -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
as -X- _ O
our -X- _ O
query -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
query -X- _ O
ConceptNet -X- _ O
for -X- _ O
triples -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
query -X- _ O
tokens -X- _ O
and -X- _ O
sort -X- _ O
the -X- _ O
triples -X- _ O
by -X- _ O
the -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
’s -X- _ O
IDF -X- _ O
weight -X- _ O
and -X- _ O
the -X- _ O
triple -X- _ O
’s -X- _ O
edge -X- _ O
weight -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
translate -X- _ O
the -X- _ O
triples -X- _ O
into -X- _ O
English -X- _ O
( -X- _ O
Robyn -X- _ O
Speer -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
entities -X- _ O
“ -X- _ O
car -X- _ O
" -X- _ O
and -X- _ O
“ -X- _ O
vehicle -X- _ O
" -X- _ O
are -X- _ O
connected -X- _ O
by -X- _ O
the -X- _ O
edge -X- _ O
relation -X- _ O
“ -X- _ O
IsA -X- _ O
" -X- _ O
, -X- _ O
the -X- _ O
translation -X- _ O
would -X- _ O
be -X- _ O
“ -X- _ O
Car -X- _ O
is -X- _ O
a -X- _ O
vehicle -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
concatenate -X- _ O
the -X- _ O
translations -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
new -X- _ O
input -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
let -X- _ O
the -X- _ O
input -X- _ O
be -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
and -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
be -X- _ O
the -X- _ O
sentence -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
triple -X- _ O
. -X- _ O
The -X- _ O
modified -X- _ O
input -X- _ O
is -X- _ O
then -X- _ O
“ -X- _ O
s -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
··· -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
s -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
pass -X- _ O
the -X- _ O
modified -X- _ O
to -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
which -X- _ O
generates -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
. -X- _ O
The -X- _ O
concatenation -X- _ O
based -X- _ O
approach -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
into -X- _ O
its -X- _ O
own -X- _ O
embedding -X- _ O
space -X- _ O
. -X- _ O
A.2.2 -X- _ O
Incorporating -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
using -X- _ O
Attention -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
formal -X- _ O
details -X- _ O
on -X- _ O
how -X- _ O
we -X- _ O
incorporate -X- _ O
explicit -X- _ O
knowledge -X- _ O
from -X- _ O
ConceptNET -X- _ O
using -X- _ O
attention -X- _ O
and -X- _ O
the -X- _ O
fusion -X- _ O
layer -X- _ O
described -X- _ O
in -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
an -X- _ O
alternative -X- _ O
method -X- _ O
we -X- _ O
tried -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
method -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
A.2.1 -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
accumulate -X- _ O
the -X- _ O
top -X- _ O
ktriples -X- _ O
( -X- _ O
varying -X- _ O
k∈ -X- _ O
{ -X- _ O
5,10,20 -X- _ O
} -X- _ O
) -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
post -X- _ O
, -X- _ O
using -X- _ O
themethod -X- _ O
described -X- _ O
in -X- _ O
Appendix -X- _ O
A.2.1 -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
concatenate -X- _ O
the -X- _ O
numberbatch -X- _ O
embeddings -X- _ O
( -X- _ O
each -X- _ O
of -X- _ O
dimension -X- _ O
p -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
entities -X- _ O
in -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
k -X- _ O
triples -X- _ O
vertically -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
vector -X- _ O
in -X- _ O
R. -X- _ O
We -X- _ O
then -X- _ O
horizontally -X- _ O
stack -X- _ O
the -X- _ O
concatenations -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
matrix -X- _ O
, -X- _ O
H∈R. -X- _ O
The -X- _ O
encoded -X- _ O
input -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
the -X- _ O
matrix -X- _ O
H∈R -X- _ O
, -X- _ O
where -X- _ O
nis -X- _ O
the -X- _ O
input -X- _ O
length -X- _ O
and -X- _ O
dis -X- _ O
the -X- _ O
hidden -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
knowledge -X- _ O
aware -X- _ O
attention -X- _ O
over -X- _ O
the -X- _ O
input -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Q -X- _ O
= -X- _ O
H∗W+b -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
K -X- _ O
= -X- _ O
H∗W+b -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
V -X- _ O
= -X- _ O
H∗W+b -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
H -X- _ O
= -X- _ O
softmax -X- _ O
/ -X- _ O
parenleftigQK -X- _ O
√ -X- _ O
dV -X- _ O
/ -X- _ O
parenrightig -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
where -X- _ O
W∈R -X- _ O
, -X- _ O
W -X- _ O
, -X- _ O
W∈Rand -X- _ O
b -X- _ O
, -X- _ O
b -X- _ O
, -X- _ O
b∈R. -X- _ O
The -X- _ O
knowledge -X- _ O
aware -X- _ O
matrix -X- _ O
is -X- _ O
H∈R. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
original -X- _ O
encoded -X- _ O
input -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
aware -X- _ O
matrix -X- _ O
, -X- _ O
Hand -X- _ O
perform -X- _ O
an -X- _ O
affine -X- _ O
transformation -X- _ O
: -X- _ O
H= -X- _ O
( -X- _ O
H⊕H -X- _ O
) -X- _ O
∗W+b -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
where -X- _ O
⊕denotes -X- _ O
column -X- _ O
- -X- _ O
wise -X- _ O
concatenation -X- _ O
, -X- _ O
W∈Randb∈R.H∈Ris -X- _ O
the -X- _ O
new -X- _ O
hidden -X- _ O
state -X- _ O
, -X- _ O
which -X- _ O
fuses -X- _ O
the -X- _ O
old -X- _ O
hidden -X- _ O
state -X- _ O
and -X- _ O
the -X- _ O
new -X- _ O
knowledge -X- _ O
aware -X- _ O
hidden -X- _ O
state -X- _ O
. -X- _ O
His -X- _ O
passed -X- _ O
into -X- _ O
the -X- _ O
BART -X- _ B-MethodName
decoder -X- _ O
. -X- _ O
A.3 -X- _ O
Implicit -X- _ O
Knowledge -X- _ O
A.3.1 -X- _ O
Incorporating -X- _ O
Implicit -X- _ O
Knowledge -X- _ O
using -X- _ O
GPT -X- _ B-MethodName
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
formal -X- _ O
details -X- _ O
on -X- _ O
incorporating -X- _ O
implicit -X- _ O
knowledge -X- _ O
using -X- _ O
a -X- _ O
pretrained -X- _ O
GPT -X- _ B-MethodName
models -X- _ O
. -X- _ O
LetMbe -X- _ O
a -X- _ O
BART -X- _ O
model -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
minority -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
Let -X- _ O
the -X- _ O
target -X- _ O
minority -X- _ O
string -X- _ O
predicted -X- _ O
by -X- _ O
Mbe -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
and -X- _ O
let -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
be -X- _ O
a -X- _ O
prompt -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
prompts -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
We -X- _ O
then -X- _ O
prompt -X- _ O
the -X- _ O
GPT -X- _ B-MethodName
models -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
string -X- _ O
“ -X- _ O
Thess -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
GPT -X- _ B-MethodName
models -X- _ O
complete -X- _ O
the -X- _ O
prompt -X- _ O
with -X- _ O
a -X- _ O
generated -X- _ O
string -X- _ O
, -X- _ O
“ -X- _ O
s -X- _ O
" -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
final -X- _ O
string -X- _ O
is -X- _ O
“ -X- _ O
Thesss -X- _ O
" -X- _ O
. -X- _ O
For -X- _ O
GPT -X- _ B-MethodName
generations -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
based -X- _ O
on -X- _ O
methods -X- _ O
in -X- _ O
Patrick -X- _ O
von -X- _ O
Platen -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
select -X- _ O
various -X- _ O
prompts -X- _ O
to -X- _ O
generate -X- _ O
ksentences -X- _ O
of -X- _ O
the -X- _ O
form -X- _ O
“ -X- _ O
Thesss -X- _ O
" -X- _ O
, -X- _ O
varying -X- _ O
k∈ -X- _ O
{ -X- _ O
3,15 -X- _ O
} -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
predicted822Prompt -X- _ O
were -X- _ O
known -X- _ O
for -X- _ O
were -X- _ O
described -X- _ O
as -X- _ O
were -X- _ O
regarded -X- _ O
as -X- _ O
were -X- _ O
thought -X- _ O
of -X- _ O
as -X- _ O
were -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
for -X- _ O
were -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
have -X- _ O
a -X- _ O
reputation -X- _ O
for -X- _ O
would -X- _ O
frequently -X- _ O
worked -X- _ O
as -X- _ O
have -X- _ O
a -X- _ O
job -X- _ O
as -X- _ O
have -X- _ O
a -X- _ O
part -X- _ O
- -X- _ O
time -X- _ O
job -X- _ O
as -X- _ O
earned -X- _ O
money -X- _ O
by -X- _ O
started -X- _ O
working -X- _ O
as -X- _ O
have -X- _ O
various -X- _ O
hobbies -X- _ O
such -X- _ O
as -X- _ O
would -X- _ O
regularly -X- _ O
engage -X- _ O
in -X- _ O
frequently -X- _ O
talked -X- _ O
about -X- _ O
behaved -X- _ O
as -X- _ O
though -X- _ O
liked -X- _ O
to -X- _ O
target -X- _ O
minority -X- _ O
, -X- _ O
sis -X- _ O
the -X- _ O
empty -X- _ O
string -X- _ O
and -X- _ O
no -X- _ O
sentence -X- _ O
is -X- _ O
generated -X- _ O
using -X- _ O
GPT -X- _ B-MethodName
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
paired -X- _ O
with -X- _ O
just -X- _ O
the -X- _ O
empty -X- _ O
string -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
pair -X- _ O
the -X- _ O
input -X- _ O
with -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
kgenerated -X- _ O
sentences -X- _ O
( -X- _ O
or -X- _ O
the -X- _ O
empty -X- _ O
string -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
predicted -X- _ O
target -X- _ O
minority -X- _ O
) -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
BART -X- _ B-MethodName
model -X- _ O
Mto -X- _ O
predict -X- _ O
the -X- _ O
generated -X- _ O
sentences -X- _ O
. -X- _ O
Model -X- _ O
M -X- _ O
is -X- _ O
then -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
pretrained -X- _ O
model -X- _ O
and -X- _ O
is -X- _ O
retrained -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
implied -X- _ O
stereotype -X- _ O
given -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
. -X- _ O
The -X- _ O
retrained -X- _ O
BART -X- _ B-MethodName
model -X- _ O
is -X- _ O
our -X- _ O
final -X- _ O
implied -X- _ O
stereotype -X- _ O
generator -X- _ O
. -X- _ O
B -X- _ O
Implementation -X- _ O
Details -X- _ O
B.1 -X- _ O
Implementation -X- _ O
Details -X- _ O
for -X- _ O
BART -X- _ B-MethodName
Encoder -X- _ O
Decoder -X- _ O
Models -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
BART -X- _ B-MethodName
models -X- _ O
using -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of5e−6for3epochs -X- _ B-HyperparameterValue
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
2or -X- _ B-HyperparameterValue
4 -X- _ B-HyperparameterValue
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
This -X- _ O
excludes -X- _ O
the -X- _ O
BERT -X- _ O
classifier -X- _ O
models -X- _ O
, -X- _ O
whose -X- _ O
settings -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
The -X- _ O
BART -X- _ B-MethodName
models -X- _ O
have -X- _ O
406 -X- _ O
M -X- _ O
parameters -X- _ O
and -X- _ O
all -X- _ O
training -X- _ O
is -X- _ O
done -X- _ O
on -X- _ O
an -X- _ O
Nvidia -X- _ O
TITAN -X- _ O
V -X- _ O
GPU -X- _ O
, -X- _ O
with -X- _ O
12 -X- _ O
GB -X- _ O
memory -X- _ O
, -X- _ O
a -X- _ O
boost -X- _ O
clock -X- _ O
speed -X- _ O
of -X- _ O
1455 -X- _ O
MHz -X- _ O
, -X- _ O
640Tensor -X- _ O
coresand5120 -X- _ O
CUDA -X- _ O
cores -X- _ O
. -X- _ O
Training -X- _ O
under -X- _ O
this -X- _ O
regime -X- _ O
takes -X- _ O
approximately -X- _ O
90 -X- _ O
- -X- _ O
120 -X- _ O
minutes -X- _ O
. -X- _ O
We -X- _ O
remove -X- _ O
all -X- _ O
URLs -X- _ O
, -X- _ O
“ -X- _ O
RT -X- _ O
" -X- _ O
strings -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
@ -X- _ O
" -X- _ O
mentions -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
post -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
these -X- _ O
models -X- _ O
on -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
seed -X- _ O
and -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
on -X- _ O
just -X- _ O
that -X- _ O
seed -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
had -X- _ O
limited -X- _ O
time -X- _ O
to -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
baseline -X- _ O
GPT-2 -X- _ B-MethodName
and -X- _ O
GPT -X- _ B-MethodName
models -X- _ O
are -X- _ O
trained -X- _ O
for5epochs -X- _ B-HyperparameterValue
, -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
by -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
minimal -X- _ O
preprocessing -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
before -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
and -X- _ O
only -X- _ O
remove -X- _ O
all -X- _ O
URLs -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
pass -X- _ O
batches -X- _ O
of -X- _ O
input -X- _ O
from -X- _ O
the -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
to -X- _ O
the -X- _ O
generate -X- _ O
method -X- _ O
of -X- _ O
the -X- _ O
huggingface -X- _ O
BART -X- _ B-MethodName
model -X- _ O
class -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
for -X- _ O
generation -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
of -X- _ O
10and -X- _ B-HyperparameterValue
a -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
of5.0 -X- _ B-HyperparameterValue
. -X- _ O
B.2 -X- _ O
Implementation -X- _ O
Details -X- _ O
for -X- _ O
BERT -X- _ O
Classifier -X- _ O
Models -X- _ O
We -X- _ O
train -X- _ O
base -X- _ O
BERT -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
110 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O
Training -X- _ O
takes -X- _ O
approximately -X- _ O
30 -X- _ O
- -X- _ O
40 -X- _ O
minutes -X- _ O
on -X- _ O
the -X- _ O
GPUs -X- _ O
described -X- _ O
in -X- _ O
B. -X- _ O
We -X- _ O
train -X- _ O
these -X- _ O
models -X- _ O
on -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
seed -X- _ O
, -X- _ O
as -X- _ O
results -X- _ O
did -X- _ O
not -X- _ O
vary -X- _ O
much -X- _ O
as -X- _ O
the -X- _ O
seed -X- _ O
varied -X- _ O
and -X- _ O
we -X- _ O
had -X- _ O
limited -X- _ O
time -X- _ O
to -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
Model -X- _ O
LR -X- _ B-HyperparameterName
Batch -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
Epochs -X- _ B-HyperparameterName
Offensiveness -X- _ O
5e-6 -X- _ B-HyperparameterValue
32 -X- _ B-HyperparameterValue
2 -X- _ B-HyperparameterValue
Intent -X- _ O
to -X- _ O
Offend -X- _ O
5e-7 -X- _ B-HyperparameterValue
32 -X- _ B-HyperparameterValue
1 -X- _ O
Lewdness -X- _ O
5e-6 -X- _ B-HyperparameterValue
32 -X- _ B-HyperparameterValue
1 -X- _ O
Group -X- _ O
Targeted -X- _ O
5e-6 -X- _ B-HyperparameterValue
32 -X- _ O
2 -X- _ O
BERT -X- _ O
Classifier -X- _ O
Model -X- _ O
training -X- _ O
settings -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
and -X- _ O
Table -X- _ O
10 -X- _ O
. -X- _ O
C -X- _ O
Further -X- _ O
Ablation -X- _ O
Studies -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
ablation -X- _ O
studies -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
Expert -X- _ O
Knowledge -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
models -X- _ O
. -X- _ O
C.1 -X- _ O
Expert -X- _ O
Knowledge -X- _ O
Ablation -X- _ O
Study -X- _ O
Recall -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
last -X- _ O
attention -X- _ O
layer -X- _ O
of -X- _ O
a -X- _ O
BERT -X- _ O
classifier -X- _ O
with -X- _ O
the -X- _ O
join -X- _ O
embedding -X- _ O
architecture -X- _ O
introduced -X- _ O
in -X- _ O
Pryzant -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
BART -X- _ B-MethodName
model -X- _ O
performing -X- _ O
stereotype -X- _ O
generation -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
ablation -X- _ O
studies -X- _ O
by -X- _ O
replacing -X- _ O
the -X- _ O
classifier -X- _ O
over -X- _ O
a -X- _ O
few -X- _ O
different -X- _ O
annotated -X- _ O
categories -X- _ O
, -X- _ O
namely -X- _ O
Offensiveness -X- _ O
, -X- _ O
Intent -X- _ O
to823 -X- _ O
Offend -X- _ O
, -X- _ O
Lewdness -X- _ O
, -X- _ O
and -X- _ O
Group -X- _ O
Targeted -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
classifiers -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
ablations -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
note -X- _ O
the -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
Expert -X- _ O
Knowledge -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
Group -X- _ O
Targeted -X- _ O
BERT -X- _ O
classifiers -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
single -X- _ O
classifier -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
performs -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
the -X- _ O
Expert -X- _ O
Knowledge -X- _ O
model -X- _ O
leveraging -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
classifiers -X- _ O
. -X- _ O
It -X- _ O
’s -X- _ O
likely -X- _ O
that -X- _ O
the -X- _ O
tokens -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
BERT -X- _ O
model -X- _ O
to -X- _ O
identify -X- _ O
whether -X- _ O
a -X- _ O
minority -X- _ O
group -X- _ O
is -X- _ O
targeted -X- _ O
aligns -X- _ O
closely -X- _ O
with -X- _ O
the -X- _ O
portions -X- _ O
of -X- _ O
the -X- _ O
encoded -X- _ O
input -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
stereotypes -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
intuitive -X- _ O
sense -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
posts -X- _ O
targeting -X- _ O
some -X- _ O
minority -X- _ O
group -X- _ O
likely -X- _ O
has -X- _ O
some -X- _ O
stereotype -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
The -X- _ O
same -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
said -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
categories -X- _ O
. -X- _ O
This -X- _ O
intuition -X- _ O
is -X- _ O
further -X- _ O
strengthened -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
Expert -X- _ O
Knowledge -X- _ O
model -X- _ O
using -X- _ O
all -X- _ O
the -X- _ O
classifiers -X- _ O
does -X- _ O
not -X- _ O
perform -X- _ O
much -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
Expert -X- _ O
Knowledge -X- _ O
model -X- _ O
using -X- _ O
just -X- _ O
the -X- _ O
Group -X- _ O
Targeted -X- _ O
classifier -X- _ O
. -X- _ O
Thus -X- _ O
the -X- _ O
other -X- _ O
classifiers -X- _ O
may -X- _ O
be -X- _ O
contributing -X- _ O
little -X- _ O
additional -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
stereotype -X- _ O
generation -X- _ O
task -X- _ O
. -X- _ O
C.2 -X- _ O
Explicit -X- _ O
Knowledge -X- _ O
Ablation -X- _ O
Study -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
specifically -X- _ O
discuss -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
knowledge -X- _ O
triples -X- _ O
we -X- _ O
use -X- _ O
when -X- _ O
training -X- _ O
explicit -X- _ O
knowledge -X- _ O
models -X- _ O
and -X- _ O
note -X- _ O
trends -X- _ O
in -X- _ O
the -X- _ O
BERTScore -X- _ B-MetricName
as -X- _ O
kvaries -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
in -X- _ O
Table -X- _ O
12 -X- _ O
. -X- _ O
We -X- _ O
discuss -X- _ O
an -X- _ O
additional -X- _ O
attention -X- _ O
based -X- _ O
model -X- _ O
not -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
. -X- _ O
The -X- _ O
detailed -X- _ O
methodology -X- _ O
for -X- _ O
this -X- _ O
model -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
A.2.2 -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
when -X- _ O
concatenated -X- _ O
directly -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
performance -X- _ O
increases -X- _ O
as -X- _ O
kincreases -X- _ O
up -X- _ O
to -X- _ O
a -X- _ O
point -X- _ O
and -X- _ O
then -X- _ O
starts -X- _ O
to -X- _ O
decrease -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
occurs -X- _ O
because -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
knowledge -X- _ O
initially -X- _ O
increases -X- _ O
then -X- _ O
decreases -X- _ O
as -X- _ O
kincreases -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
as -X- _ O
kincreases -X- _ O
, -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
triples -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
synonymous -X- _ O
with -X- _ O
earlier -X- _ O
triples -X- _ O
or -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
incorporating -X- _ O
knowledge -X- _ O
as -X- _ O
attention -X- _ O
tends -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
better -X- _ O
BERTScore -X- _ B-MetricName
, -X- _ O
while -X- _ O
not -X- _ O
performing -X- _ O
as -X- _ O
well -X- _ O
on -X- _ O
other -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
suspect -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
numerbatch -X- _ O
embeddings -X- _ O
capturing -X- _ O
more -X- _ O
semantic -X- _ O
meaning -X- _ O
than -X- _ O
the -X- _ O
BART -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O
The -X- _ O
numberbatch -X- _ O
embeddings -X- _ O
draw -X- _ O
from -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
sources -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
graph -X- _ O
structure -X- _ O
itself -X- _ O
and -X- _ O
they -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
benchmarks -X- _ O
measuring -X- _ O
word -X- _ O
similarity -X- _ O
. -X- _ O
D -X- _ O
Analysis -X- _ O
We -X- _ O
provide -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
of -X- _ O
stereotype -X- _ O
generation -X- _ O
, -X- _ O
comparing -X- _ O
and -X- _ O
contrasting -X- _ O
the -X- _ O
different -X- _ O
model -X- _ O
types -X- _ O
in -X- _ O
Table -X- _ O
13.824 -X- _ O
D.1 -X- _ O
Error -X- _ O
Analysis -X- _ O
Table -X- _ O
14 -X- _ O
provides -X- _ O
the -X- _ O
counts -X- _ O
for -X- _ O
the -X- _ O
Error -X- _ O
Analysis -X- _ O
. -X- _ O
Clearly -X- _ O
, -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
models -X- _ O
minimize -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
made -X- _ O
, -X- _ O
although -X- _ O
MGEN -X- _ B-MethodName
may -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
minimal -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
in -X- _ O
each -X- _ O
category -X- _ O
. -X- _ O
D.2 -X- _ O
Challenges -X- _ O
in -X- _ O
Stereotype -X- _ O
Generation -X- _ O
Table -X- _ O
15 -X- _ O
provides -X- _ O
the -X- _ O
counts -X- _ O
for -X- _ O
the -X- _ O
Challenges -X- _ O
faced -X- _ O
by -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
Clearly -X- _ O
, -X- _ O
the -X- _ O
MGEN -X- _ B-MethodName
models -X- _ O
minimize -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
challenges -X- _ O
face -X- _ O
, -X- _ O
although -X- _ O
MGEN -X- _ B-MethodName
may -X- _ O
not -X- _ O
have -X- _ O
faced -X- _ O
the -X- _ O
minimal -X- _ O
number -X- _ O
of -X- _ O
challenges -X- _ O
within -X- _ O
each -X- _ O
category.825Error -X- _ O
Type -X- _ O
GPT -X- _ B-MethodName
GPT-2 -X- _ B-MethodName
Expert -X- _ O
Explicit -X- _ O
Implicit -X- _ O
MGEN -X- _ B-MethodName
1 -X- _ O
45 -X- _ O
46 -X- _ O
37 -X- _ O
44 -X- _ O
30 -X- _ O
24 -X- _ O
2 -X- _ O
8 -X- _ O
7 -X- _ O
1 -X- _ O
0 -X- _ O
3 -X- _ O
4 -X- _ O
3 -X- _ O
13 -X- _ O
11 -X- _ O
11 -X- _ O
10 -X- _ O
10 -X- _ O
8 -X- _ O
4 -X- _ O
28 -X- _ O
37 -X- _ O
41 -X- _ O
24 -X- _ O
27 -X- _ O
27 -X- _ O
5 -X- _ O
106 -X- _ O
99 -X- _ O
110 -X- _ O
122 -X- _ O
130 -X- _ O
137 -X- _ O
Challenge -X- _ O
Type -X- _ O
GPT -X- _ O
GPT-2 -X- _ O
Expert -X- _ O
Explicit -X- _ O
Implicit -X- _ O
MGEN -X- _ O
1 -X- _ O
8 -X- _ O
6 -X- _ O
6 -X- _ O
4 -X- _ O
2 -X- _ O
4 -X- _ O
2 -X- _ O
( -X- _ O
Non -X- _ O
- -X- _ O
existent -X- _ O
Stereotypes -X- _ O
) -X- _ O
44 -X- _ O
46 -X- _ O
37 -X- _ O
44 -X- _ O
30 -X- _ O
24 -X- _ O
2 -X- _ O
( -X- _ O
Remainder -X- _ O
) -X- _ O
15 -X- _ O
9 -X- _ O
33 -X- _ O
13 -X- _ O
18 -X- _ O
11 -X- _ O
3 -X- _ O
8 -X- _ O
19 -X- _ O
10 -X- _ O
7 -X- _ O
8 -X- _ O
8 -X- _ O
4 -X- _ O
7 -X- _ O
9 -X- _ O
2 -X- _ O
5 -X- _ O
6 -X- _ O
5 -X- _ O
5 -X- _ O
4 -X- _ O
5 -X- _ O
1 -X- _ O
5 -X- _ O
3 -X- _ O
7 -X- _ O
6 -X- _ O
8 -X- _ O
7 -X- _ O
1 -X- _ O
0 -X- _ O
3 -X- _ O
4 -X- _ O
7 -X- _ O
106 -X- _ O
99 -X- _ O
110 -X- _ O
122 -X- _ O
130 -X- _ O
137826 -X- _ O

2022.emnlp-main.11.txt -X- _ O
Do -X- _ O
June -X- _ O
Min -X- _ O
, -X- _ O
Verónica -X- _ O
Pérez -X- _ O
- -X- _ O
Rosas -X- _ O
, -X- _ O
Kenneth -X- _ O
Resnicow -X- _ O
, -X- _ O
and -X- _ O
Rada -X- _ O
MihalceaDepartment -X- _ O
of -X- _ O
Electrical -X- _ O
Engineering -X- _ O
and -X- _ O
Computer -X- _ O
Science -X- _ O
, -X- _ O
School -X- _ O
of -X- _ O
Public -X- _ O
Health -X- _ O
University -X- _ O
of -X- _ O
Michigan -X- _ O
, -X- _ O
Ann -X- _ O
Arbor -X- _ O
, -X- _ O
MI -X- _ O
, -X- _ O
USA -X- _ O
{ -X- _ O
dojmin -X- _ O
, -X- _ O
vrncapr -X- _ O
, -X- _ O
kresnic -X- _ O
, -X- _ O
mihalcea -X- _ O
} -X- _ O
@ -X- _ O
umich.edu -X- _ O
Abstract -X- _ O
Reflections -X- _ O
are -X- _ O
a -X- _ O
core -X- _ O
verbal -X- _ O
skill -X- _ O
used -X- _ O
by -X- _ O
mental -X- _ O
health -X- _ O
counselors -X- _ O
to -X- _ O
express -X- _ O
understanding -X- _ O
and -X- _ O
acknowledgement -X- _ O
of -X- _ O
the -X- _ O
client -X- _ O
’s -X- _ O
experience -X- _ O
and -X- _ O
concerns -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
system -X- _ O
for -X- _ O
the -X- _ O
automatic -X- _ O
evaluation -X- _ O
of -X- _ O
counselor -X- _ O
reflections -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
takes -X- _ O
as -X- _ O
input -X- _ O
one -X- _ O
dialog -X- _ O
turn -X- _ O
containing -X- _ O
a -X- _ O
client -X- _ O
prompt -X- _ O
likely -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
reflection -X- _ O
and -X- _ O
a -X- _ O
counselor -X- _ O
response -X- _ O
to -X- _ O
it -X- _ O
, -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
numeric -X- _ O
score -X- _ O
indicating -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
reflection -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
counselor -X- _ O
. -X- _ O
We -X- _ O
compile -X- _ O
a -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
reflections -X- _ O
portraying -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
reflective -X- _ O
listening -X- _ O
skills -X- _ O
, -X- _ O
and -X- _ O
propose -X- _ O
PromptAware -X- _ B-MethodName
margIn -X- _ I-MethodName
Ranking -X- _ I-MethodName
( -X- _ O
PAIR -X- _ B-MethodName
) -X- _ O
, -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
for -X- _ O
reflection -X- _ B-TaskName
scoring -X- _ I-TaskName
that -X- _ O
contrasts -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
prompt -X- _ O
and -X- _ O
response -X- _ O
pairs -X- _ O
using -X- _ O
adhoc -X- _ O
multi -X- _ O
- -X- _ O
gap -X- _ O
and -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
margin -X- _ O
ranking -X- _ O
losses -X- _ O
. -X- _ O
Through -X- _ O
empirical -X- _ O
evaluations -X- _ O
and -X- _ O
deployment -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
in -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
educational -X- _ O
environment -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
scoring -X- _ O
model -X- _ O
outperforms -X- _ O
several -X- _ O
baselines -X- _ O
on -X- _ O
different -X- _ O
metrics -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
provide -X- _ O
useful -X- _ O
feedback -X- _ O
to -X- _ O
counseling -X- _ O
trainees -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Counselor -X- _ O
training -X- _ O
is -X- _ O
an -X- _ O
expensive -X- _ O
and -X- _ O
time -X- _ O
consuming -X- _ O
process -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
extensive -X- _ O
expert -X- _ O
supervision -X- _ O
involved -X- _ O
( -X- _ O
Bartholomew -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
Current -X- _ O
strategies -X- _ O
for -X- _ O
counselor -X- _ O
training -X- _ O
usually -X- _ O
rely -X- _ O
on -X- _ O
either -X- _ O
role -X- _ O
playing -X- _ O
or -X- _ O
monitoring -X- _ O
and -X- _ O
recording -X- _ O
live -X- _ O
video -X- _ O
interactions -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
manually -X- _ O
evaluated -X- _ O
to -X- _ O
provide -X- _ O
constructive -X- _ O
feedback -X- _ O
, -X- _ O
thus -X- _ O
limiting -X- _ O
the -X- _ O
opportunities -X- _ O
for -X- _ O
training -X- _ O
counselors -X- _ O
to -X- _ O
practice -X- _ O
and -X- _ O
receive -X- _ O
timely -X- _ O
evaluative -X- _ O
feedback -X- _ O
. -X- _ O
While -X- _ O
several -X- _ O
promising -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
automatically -X- _ O
provide -X- _ O
evaluative -X- _ O
feedback -X- _ O
to -X- _ O
counselors -X- _ O
( -X- _ O
Tanana -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
providing -X- _ O
detailed -X- _ O
feedback -X- _ O
in -X- _ O
real -X- _ O
time -X- _ O
remains -X- _ O
a -X- _ O
challenge -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
particularly -X- _ O
the -X- _ O
case -X- _ O
in -X- _ O
educational -X- _ O
settings -X- _ O
, -X- _ O
where -X- _ O
counseling -X- _ O
trainees -X- _ O
could -X- _ O
benefit -X- _ O
from -X- _ O
a -X- _ O
supportive -X- _ O
learning -X- _ O
environment -X- _ O
that -X- _ O
allows -X- _ O
them -X- _ O
to -X- _ O
make -X- _ O
mistakes -X- _ O
and -X- _ O
learnFigure -X- _ O
1 -X- _ O
: -X- _ O
Example -X- _ O
of -X- _ O
Reflective -X- _ O
and -X- _ O
Non -X- _ O
- -X- _ O
reflective -X- _ O
Counselor -X- _ O
Behaviors -X- _ O
. -X- _ O
at -X- _ O
their -X- _ O
own -X- _ O
pace -X- _ O
while -X- _ O
acquiring -X- _ O
counseling -X- _ O
skills -X- _ O
. -X- _ O
Seeking -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
need -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
scoring -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
counseling -X- _ O
trainees -X- _ O
when -X- _ O
learning -X- _ O
to -X- _ O
formulate -X- _ O
responses -X- _ O
to -X- _ O
clients -X- _ O
’ -X- _ O
statements -X- _ O
. -X- _ O
We -X- _ O
focus -X- _ O
on -X- _ O
responses -X- _ O
containing -X- _ O
counseling -X- _ O
reflections -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
understand -X- _ O
and -X- _ O
reflect -X- _ O
on -X- _ O
what -X- _ O
the -X- _ O
client -X- _ O
is -X- _ O
saying -X- _ O
. -X- _ O
Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
computational -X- _ O
model -X- _ O
for -X- _ O
scoring -X- _ O
counselor -X- _ O
reflections -X- _ O
by -X- _ O
leveraging -X- _ O
existing -X- _ O
counseling -X- _ O
behavioral -X- _ O
annotation -X- _ O
schemes -X- _ O
and -X- _ O
learningto -X- _ O
- -X- _ O
rank -X- _ O
approaches -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
developing -X- _ O
an -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
model -X- _ O
capable -X- _ O
of -X- _ O
assessing -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
verbal -X- _ O
behavior -X- _ O
observed -X- _ O
in -X- _ O
counselor -X- _ O
language -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
quality -X- _ O
and -X- _ O
efficiency -X- _ O
of -X- _ O
Motivational -X- _ O
Interviewing -X- _ O
( -X- _ O
MI -X- _ O
) -X- _ O
training -X- _ O
by -X- _ O
allowing -X- _ O
counselors -X- _ O
to -X- _ O
practice -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
their -X- _ O
reflective -X- _ O
listening -X- _ O
skills -X- _ O
, -X- _ O
and -X- _ O
providing -X- _ O
them -X- _ O
with -X- _ O
immediate -X- _ O
feedback -X- _ O
. -X- _ O
To -X- _ O
build -X- _ O
our -X- _ O
scoring -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
compile -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
of -X- _ O
counseling -X- _ O
reflections -X- _ O
using -X- _ O
expert -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
expert -X- _ O
annotations -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
pairs -X- _ O
of -X- _ O
client -X- _ O
prompts -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
situations -X- _ O
from -X- _ O
a -X- _ O
client -X- _ O
that -X- _ O
prompt -X- _ O
a -X- _ O
reflective -X- _ O
statement -X- _ O
, -X- _ O
and -X- _ O
counselor -X- _ O
responses -X- _ O
showing -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
counseling -X- _ O
skill -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
introduce -X- _ O
PAIR -X- _ B-MethodName
( -X- _ O
Prompt -X- _ B-MethodName
- -X- _ I-MethodName
Aware -X- _ I-MethodName
margIn -X- _ I-MethodName
Ranking -X- _ I-MethodName
) -X- _ O
, -X- _ O
a -X- _ O
novel -X- _ O
margin148ranking -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
that -X- _ O
can -X- _ O
output -X- _ O
a -X- _ O
continuous -X- _ O
score -X- _ O
learned -X- _ O
from -X- _ O
discrete -X- _ O
annotations -X- _ O
of -X- _ O
counseling -X- _ O
reflections -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
correct -X- _ O
ranking -X- _ O
of -X- _ O
counseling -X- _ O
responses -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
testing -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
collected -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
deploy -X- _ O
our -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
real -X- _ O
world -X- _ O
education -X- _ O
setting -X- _ O
with -X- _ O
graduate -X- _ O
counseling -X- _ O
students -X- _ O
, -X- _ O
and -X- _ O
conduct -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
evaluations -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
is -X- _ O
a -X- _ O
viable -X- _ O
alternative -X- _ O
to -X- _ O
manual -X- _ O
human -X- _ O
feedback -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
contributions -X- _ O
include -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
formulation -X- _ O
of -X- _ O
the -X- _ O
reflection -X- _ B-TaskName
scoring -X- _ I-TaskName
problem -X- _ O
and -X- _ O
a -X- _ O
counseling -X- _ O
dataset -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
A -X- _ O
novel -X- _ O
contrastive -X- _ O
learning -X- _ O
- -X- _ O
inspired -X- _ O
framework -X- _ O
PAIR -X- _ B-MethodName
( -X- _ O
Prompt -X- _ B-MethodName
- -X- _ I-MethodName
Aware -X- _ I-MethodName
margIn -X- _ I-MethodName
Ranking -X- _ I-MethodName
) -X- _ O
for -X- _ O
automatically -X- _ O
scoring -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
reflection -X- _ O
statement -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
assessments -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
annotated -X- _ O
dataset -X- _ O
and -X- _ O
through -X- _ O
in -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
wild -X- _ O
deployment -X- _ O
and -X- _ O
feedback -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
Automated -X- _ O
analysis -X- _ O
and -X- _ O
evaluation -X- _ O
of -X- _ O
verbal -X- _ O
strategies -X- _ O
used -X- _ O
in -X- _ O
mental -X- _ O
health -X- _ O
conversations -X- _ O
has -X- _ O
emerged -X- _ O
as -X- _ O
a -X- _ O
promising -X- _ O
intersection -X- _ O
of -X- _ O
psychotherapy -X- _ O
and -X- _ O
NLP -X- _ O
( -X- _ O
Althoff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Work -X- _ O
has -X- _ O
been -X- _ O
done -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
fidelity -X- _ O
of -X- _ O
treatment -X- _ O
via -X- _ O
behavioral -X- _ O
coding -X- _ O
or -X- _ O
analysis -X- _ O
of -X- _ O
counselors -X- _ O
’ -X- _ O
language -X- _ O
( -X- _ O
Pérez -X- _ O
- -X- _ O
Rosas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017b -X- _ O
; -X- _ O
Flemotomos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Ardulov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
also -X- _ O
to -X- _ O
evaluate -X- _ O
empathy -X- _ O
and -X- _ O
verbal -X- _ O
mimicry -X- _ O
expressed -X- _ O
by -X- _ O
counselors -X- _ O
( -X- _ O
Pérez -X- _ O
- -X- _ O
Rosas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a -X- _ O
; -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
dialog -X- _ O
- -X- _ O
based -X- _ O
systems -X- _ O
have -X- _ O
been -X- _ O
explored -X- _ O
to -X- _ O
assist -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
basic -X- _ O
counseling -X- _ O
skills -X- _ O
. -X- _ O
Tanana -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
developed -X- _ O
a -X- _ O
patient -X- _ O
- -X- _ O
like -X- _ O
conversational -X- _ O
agent -X- _ O
that -X- _ O
interacts -X- _ O
with -X- _ O
counselors -X- _ O
while -X- _ O
practicing -X- _ O
open -X- _ O
questions -X- _ O
and -X- _ O
reflections -X- _ O
and -X- _ O
categorizes -X- _ O
their -X- _ O
responses -X- _ O
to -X- _ O
show -X- _ O
percentages -X- _ O
of -X- _ O
questions -X- _ O
and -X- _ O
reflections -X- _ O
used -X- _ O
during -X- _ O
the -X- _ O
interaction -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
proposed -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
behavioral -X- _ O
coding -X- _ O
, -X- _ O
but -X- _ O
our -X- _ O
focus -X- _ O
is -X- _ O
on -X- _ O
detecting -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
verbal -X- _ O
behavior -X- _ O
( -X- _ O
a -X- _ O
reflection -X- _ O
) -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
identifying -X- _ O
their -X- _ O
type -X- _ O
. -X- _ O
Our -X- _ O
scoring -X- _ O
system -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
component -X- _ O
in -X- _ O
larger -X- _ O
systems -X- _ O
for -X- _ O
writing -X- _ O
or -X- _ O
rewriting -X- _ O
counselor -X- _ O
utterances -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
framework -X- _ O
in -X- _ O
( -X- _ O
Laban -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Pérez -X- _ O
- -X- _ O
Rosas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
high -X- _ O
reflection -X- _ O
frequency -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
practicing -X- _ O
reflective -X- _ O
be -X- _ O
- -X- _ O
havior -X- _ O
in -X- _ O
MI -X- _ O
. -X- _ O
3 -X- _ O
Motivational -X- _ B-DatasetName
Interviewing -X- _ I-DatasetName
Reflection -X- _ I-DatasetName
Dataset -X- _ O
To -X- _ O
build -X- _ O
our -X- _ O
reflection -X- _ O
scoring -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
compile -X- _ O
a -X- _ O
dataset -X- _ O
consisting -X- _ O
of -X- _ O
brief -X- _ O
interactions -X- _ O
between -X- _ O
counselors -X- _ O
and -X- _ O
clients -X- _ O
portraying -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
reflective -X- _ O
listening -X- _ O
skills -X- _ O
. -X- _ O
Each -X- _ O
interaction -X- _ O
is -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
includes -X- _ O
a -X- _ O
client -X- _ O
prompt -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
a -X- _ O
client -X- _ O
’s -X- _ O
statement -X- _ O
that -X- _ O
is -X- _ O
usually -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
counseling -X- _ O
trainee -X- _ O
, -X- _ O
paired -X- _ O
with -X- _ O
counseling -X- _ O
responses -X- _ O
portraying -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
reflections -X- _ O
skill -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
low -X- _ O
quality -X- _ O
, -X- _ O
medium -X- _ O
quality -X- _ O
, -X- _ O
and -X- _ O
high -X- _ O
quality -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
the -X- _ O
dataset -X- _ O
using -X- _ O
both -X- _ O
expert -X- _ O
and -X- _ O
crowd -X- _ O
- -X- _ O
sourced -X- _ O
annotators -X- _ O
and -X- _ O
also -X- _ O
leverage -X- _ O
conversational -X- _ O
data -X- _ O
from -X- _ O
an -X- _ O
MI -X- _ O
dataset -X- _ O
to -X- _ O
obtain -X- _ O
additional -X- _ O
prompt -X- _ O
- -X- _ O
response -X- _ O
pairs -X- _ O
from -X- _ O
conversations -X- _ O
snippets -X- _ O
containing -X- _ O
reflections -X- _ O
. -X- _ O
3.1 -X- _ O
Annotations -X- _ O
We -X- _ O
classify -X- _ O
reflections -X- _ O
into -X- _ O
Simple -X- _ O
Reflections -X- _ O
and -X- _ O
Complex -X- _ O
Reflections -X- _ O
based -X- _ O
on -X- _ O
standard -X- _ O
criteria -X- _ O
( -X- _ O
McMaster -X- _ O
and -X- _ O
Resnicow -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Moyers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
consider -X- _ O
a -X- _ O
third -X- _ O
category -X- _ O
of -X- _ O
responses -X- _ O
consisting -X- _ O
of -X- _ O
Non -X- _ O
Reflections -X- _ O
. -X- _ O
Simple -X- _ O
Reflection -X- _ O
( -X- _ O
SR -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
entails -X- _ O
reflecting -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
client -X- _ O
on -X- _ O
what -X- _ O
they -X- _ O
said -X- _ O
, -X- _ O
using -X- _ O
different -X- _ O
words -X- _ O
( -X- _ O
paraphrasing -X- _ O
) -X- _ O
. -X- _ O
Simple -X- _ O
reflections -X- _ O
typically -X- _ O
do -X- _ O
not -X- _ O
include -X- _ O
new -X- _ O
insights -X- _ O
or -X- _ O
inferences -X- _ O
. -X- _ O
They -X- _ O
tend -X- _ O
to -X- _ O
capture -X- _ O
what -X- _ O
was -X- _ O
just -X- _ O
said -X- _ O
more -X- _ O
than -X- _ O
what -X- _ O
lies -X- _ O
behind -X- _ O
or -X- _ O
ahead -X- _ O
of -X- _ O
the -X- _ O
client -X- _ O
statement -X- _ O
. -X- _ O
We -X- _ O
categorize -X- _ O
SRs -X- _ O
as -X- _ O
mid -X- _ O
- -X- _ O
quality -X- _ O
reflections -X- _ O
, -X- _ O
whose -X- _ O
quality -X- _ O
lies -X- _ O
between -X- _ O
that -X- _ O
of -X- _ O
complex -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
reflections -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
response -X- _ O
“ -X- _ O
You -X- _ O
believe -X- _ O
you -X- _ O
will -X- _ O
die -X- _ O
from -X- _ O
breast -X- _ O
cancer -X- _ O
, -X- _ O
just -X- _ O
like -X- _ O
your -X- _ O
mom -X- _ O
. -X- _ O
“ -X- _ O
is -X- _ O
a -X- _ O
medium -X- _ O
quality -X- _ O
reflection -X- _ O
containing -X- _ O
a -X- _ O
simple -X- _ O
reflection -X- _ O
because -X- _ O
it -X- _ O
adds -X- _ O
no -X- _ O
additional -X- _ O
meaning -X- _ O
to -X- _ O
what -X- _ O
the -X- _ O
client -X- _ O
has -X- _ O
already -X- _ O
expressed -X- _ O
. -X- _ O
Complex -X- _ O
Reflection -X- _ O
( -X- _ O
CR -X- _ O
) -X- _ O
. -X- _ O
Complex -X- _ O
reflections -X- _ O
entail -X- _ O
the -X- _ O
counselor -X- _ O
adding -X- _ O
or -X- _ O
inferring -X- _ O
something -X- _ O
new -X- _ O
from -X- _ O
the -X- _ O
client -X- _ O
statement -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
include -X- _ O
naming -X- _ O
a -X- _ O
feeling -X- _ O
or -X- _ O
emotion -X- _ O
that -X- _ O
has -X- _ O
not -X- _ O
yet -X- _ O
been -X- _ O
expressed -X- _ O
by -X- _ O
the -X- _ O
client -X- _ O
; -X- _ O
inferring -X- _ O
why -X- _ O
the -X- _ O
client -X- _ O
might -X- _ O
have -X- _ O
said -X- _ O
something -X- _ O
; -X- _ O
or -X- _ O
stating -X- _ O
where -X- _ O
they -X- _ O
are -X- _ O
headed -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
counselor -X- _ O
utterance -X- _ O
“ -X- _ O
Your -X- _ O
mother -X- _ O
’s -X- _ O
death -X- _ O
was -X- _ O
devastating -X- _ O
. -X- _ O
You -X- _ O
’re -X- _ O
worried -X- _ O
you -X- _ O
may -X- _ O
die -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
she -X- _ O
did -X- _ O
. -X- _ O
” -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
is -X- _ O
a -X- _ O
complex -X- _ O
reflection -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
high -X- _ O
quality -X- _ O
response -X- _ O
) -X- _ O
as -X- _ O
it -X- _ O
brings -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
client -X- _ O
’s -X- _ O
traumatic -X- _ O
experience -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
merely -X- _ O
rephrasing -X- _ O
what -X- _ O
was149 -X- _ O
said -X- _ O
. -X- _ O
Complex -X- _ O
reflections -X- _ O
are -X- _ O
considered -X- _ O
a -X- _ O
high -X- _ O
quality -X- _ O
MI -X- _ O
response -X- _ O
. -X- _ O
Non -X- _ O
Reflection -X- _ O
( -X- _ O
NR -X- _ O
) -X- _ O
. -X- _ O
Responses -X- _ O
that -X- _ O
include -X- _ O
unsolicited -X- _ O
advice -X- _ O
or -X- _ O
asking -X- _ O
questions -X- _ O
when -X- _ O
a -X- _ O
reflection -X- _ O
would -X- _ O
have -X- _ O
been -X- _ O
a -X- _ O
better -X- _ O
response -X- _ O
are -X- _ O
classified -X- _ O
as -X- _ O
low -X- _ O
quality -X- _ O
responses -X- _ O
. -X- _ O
3.2 -X- _ O
Prompt -X- _ O
- -X- _ O
reflection -X- _ O
Pairs -X- _ O
Using -X- _ O
Hand -X- _ O
- -X- _ O
crafted -X- _ O
Prompts -X- _ O
We -X- _ O
start -X- _ O
by -X- _ O
collecting -X- _ O
reflections -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
318 -X- _ O
manually -X- _ O
crafted -X- _ O
client -X- _ O
prompts -X- _ O
, -X- _ O
covering -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
health -X- _ O
related -X- _ O
behaviors -X- _ O
such -X- _ O
as -X- _ O
diabetes -X- _ O
, -X- _ O
weight -X- _ O
management -X- _ O
, -X- _ O
smoking -X- _ O
cessation -X- _ O
, -X- _ O
vaccination -X- _ O
, -X- _ O
or -X- _ O
alcohol -X- _ O
consumption -X- _ O
. -X- _ O
The -X- _ O
client -X- _ O
prompts -X- _ O
are -X- _ O
sourced -X- _ O
from -X- _ O
MI -X- _ O
training -X- _ O
materials -X- _ O
used -X- _ O
during -X- _ O
a -X- _ O
graduate -X- _ O
MI -X- _ O
class -X- _ O
taught -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
authors -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
our -X- _ O
annotation -X- _ O
process -X- _ O
to -X- _ O
create -X- _ O
responses -X- _ O
to -X- _ O
each -X- _ O
client -X- _ O
prompt -X- _ O
with -X- _ O
varying -X- _ O
reflection -X- _ O
quality -X- _ O
levels -X- _ O
. -X- _ O
Expert -X- _ O
Annotations -X- _ O
. -X- _ O
We -X- _ O
recruit -X- _ O
two -X- _ O
annotators -X- _ O
with -X- _ O
MI -X- _ O
expertise -X- _ O
to -X- _ O
write -X- _ O
high -X- _ O
, -X- _ O
medium -X- _ O
and -X- _ O
low -X- _ O
quality -X- _ O
reflections -X- _ O
( -X- _ O
CRs -X- _ O
, -X- _ O
SRs -X- _ O
, -X- _ O
NRs -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
prompts -X- _ O
using -X- _ O
the -X- _ O
definitions -X- _ O
for -X- _ O
each -X- _ O
type -X- _ O
of -X- _ O
reflection -X- _ O
. -X- _ O
We -X- _ O
assign -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
prompts -X- _ O
to -X- _ O
each -X- _ O
annotator -X- _ O
and -X- _ O
ask -X- _ O
them -X- _ O
to -X- _ O
write -X- _ O
two -X- _ O
complex -X- _ O
reflections -X- _ O
, -X- _ O
one -X- _ O
simple -X- _ O
reflection -X- _ O
and -X- _ O
two -X- _ O
non -X- _ O
- -X- _ O
reflections -X- _ O
for -X- _ O
each -X- _ O
client -X- _ O
prompt -X- _ O
. -X- _ O
Non -X- _ O
- -X- _ O
expert -X- _ O
Annotations -X- _ O
. -X- _ O
One -X- _ O
concern -X- _ O
with -X- _ O
only -X- _ O
using -X- _ O
expert -X- _ O
annotated -X- _ O
data -X- _ O
is -X- _ O
that -X- _ O
experts -X- _ O
might -X- _ O
struggle -X- _ O
to -X- _ O
simulate -X- _ O
MI -X- _ O
inconsistent -X- _ O
responses -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
capture -X- _ O
in -X- _ O
low -X- _ O
quality -X- _ O
( -X- _ O
NR -X- _ O
) -X- _ O
responses -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
crowdsourced -X- _ O
annotations -X- _ O
from -X- _ O
non -X- _ O
- -X- _ O
MI -X- _ O
experts -X- _ O
, -X- _ O
using -X- _ O
workers -X- _ O
from -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turk -X- _ O
. -X- _ O
Our -X- _ O
rationale -X- _ O
for -X- _ O
using -X- _ O
non -X- _ O
- -X- _ O
expert -X- _ O
annotation -X- _ O
for -X- _ O
low -X- _ O
quality -X- _ O
( -X- _ O
NR -X- _ O
) -X- _ O
reflections -X- _ O
is -X- _ O
that -X- _ O
nonexperts -X- _ O
responses -X- _ O
should -X- _ O
be -X- _ O
closer -X- _ O
to -X- _ O
inexpert -X- _ O
MI -X- _ O
practitioner -X- _ O
responses -X- _ O
that -X- _ O
we -X- _ O
expect -X- _ O
our -X- _ O
modelsto -X- _ O
encounter -X- _ O
during -X- _ O
training -X- _ O
or -X- _ O
evaluation -X- _ O
scenarios -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
this -X- _ O
strategy -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
generate -X- _ O
low -X- _ O
quality -X- _ O
reflections -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
of -X- _ O
expert -X- _ O
input -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
annotation -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
request -X- _ O
AMT -X- _ O
workers -X- _ O
to -X- _ O
provide -X- _ O
“ -X- _ O
advice -X- _ O
” -X- _ O
to -X- _ O
the -X- _ O
situation -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
client -X- _ O
prompt -X- _ O
so -X- _ O
their -X- _ O
responses -X- _ O
will -X- _ O
likely -X- _ O
contain -X- _ O
directive -X- _ O
language -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
follow -X- _ O
MI -X- _ O
guidelines -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
expert -X- _ O
observation -X- _ O
that -X- _ O
providing -X- _ O
unsolicited -X- _ O
advice -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
behavior -X- _ O
while -X- _ O
trainees -X- _ O
are -X- _ O
still -X- _ O
learning -X- _ O
to -X- _ O
craft -X- _ O
reflections -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
responses -X- _ O
, -X- _ O
we -X- _ O
request -X- _ O
three -X- _ O
responses -X- _ O
per -X- _ O
prompt -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
response -X- _ O
is -X- _ O
annotated -X- _ O
by -X- _ O
a -X- _ O
unique -X- _ O
AMT -X- _ O
worker -X- _ O
. -X- _ O
We -X- _ O
manually -X- _ O
verify -X- _ O
the -X- _ O
responses -X- _ O
and -X- _ O
reject -X- _ O
those -X- _ O
that -X- _ O
fail -X- _ O
to -X- _ O
follow -X- _ O
the -X- _ O
provided -X- _ O
guidelines -X- _ O
. -X- _ O
Our -X- _ O
final -X- _ O
set -X- _ O
of -X- _ O
prompt -X- _ O
- -X- _ O
reflection -X- _ O
pairs -X- _ O
using -X- _ O
the -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
prompts -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
complex -X- _ O
reflections -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
reflection -X- _ O
, -X- _ O
and -X- _ O
five -X- _ O
non -X- _ O
reflections -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
318 -X- _ O
client -X- _ O
prompts -X- _ O
. -X- _ O
This -X- _ O
results -X- _ O
in -X- _ O
2,544 -X- _ O
prompt -X- _ O
- -X- _ O
response -X- _ O
pairwise -X- _ O
examples -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
for -X- _ O
each -X- _ O
type -X- _ O
of -X- _ O
reflection -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
3.3 -X- _ O
Prompt -X- _ O
- -X- _ O
reflection -X- _ O
Pairs -X- _ O
from -X- _ O
Counseling -X- _ O
Conversations -X- _ O
We -X- _ O
also -X- _ O
obtain -X- _ O
prompt -X- _ O
- -X- _ O
reflection -X- _ O
pairs -X- _ O
from -X- _ O
an -X- _ O
existing -X- _ O
counseling -X- _ O
dataset -X- _ O
by -X- _ O
Pérez -X- _ O
- -X- _ O
Rosas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
containing -X- _ O
annotations -X- _ O
for -X- _ O
2690 -X- _ O
simple -X- _ O
reflections -X- _ O
and -X- _ O
2876 -X- _ O
complex -X- _ O
reflections -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
dataset -X- _ O
annotations -X- _ O
to -X- _ O
select -X- _ O
conversation -X- _ O
snippets -X- _ O
leading -X- _ O
to -X- _ O
counseling -X- _ O
reflections -X- _ O
. -X- _ O
To -X- _ O
build -X- _ O
client -X- _ O
prompt -X- _ O
- -X- _ O
reflection -X- _ O
pairs -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
previous -X- _ O
utterance -X- _ O
by -X- _ O
the -X- _ O
client -X- _ O
as -X- _ O
the -X- _ O
prompt -X- _ O
and -X- _ O
collect -X- _ O
responses -X- _ O
that -X- _ O
are -X- _ O
labeled -X- _ O
as -X- _ O
complex -X- _ O
and -X- _ O
simple -X- _ O
reflections -X- _ O
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
resulting -X- _ O
dataset -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
this -X- _ O
dataset -X- _ O
for -X- _ O
additional -X- _ O
validation -X- _ O
and -X- _ O
sampling -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
matching -X- _ O
responses -X- _ O
for -X- _ O
our -X- _ O
learning -X- _ O
objectives -X- _ O
in -X- _ O
Section -X- _ O
4.150 -X- _ O
4Prompt -X- _ B-MethodName
- -X- _ I-MethodName
Aware -X- _ I-MethodName
margIn -X- _ I-MethodName
Ranking -X- _ I-MethodName
( -X- _ O
PAIR -X- _ B-MethodName
) -X- _ O
Our -X- _ O
reflection -X- _ B-TaskName
scoring -X- _ I-TaskName
task -X- _ O
consists -X- _ O
of -X- _ O
assigning -X- _ O
a -X- _ O
reflection -X- _ O
quality -X- _ O
score -X- _ O
sbetween -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
to -X- _ O
a -X- _ O
interaction -X- _ O
pair -X- _ O
containing -X- _ O
a -X- _ O
client -X- _ O
prompt -X- _ O
pand -X- _ O
a -X- _ O
candidate -X- _ O
reflection -X- _ O
by -X- _ O
a -X- _ O
counselor -X- _ O
r. -X- _ O
While -X- _ O
this -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
regression -X- _ O
, -X- _ O
obtaining -X- _ O
ground -X- _ O
truth -X- _ O
labels -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
noisy -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
expert -X- _ O
annotators -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
formulate -X- _ O
the -X- _ O
scoring -X- _ O
problem -X- _ O
as -X- _ O
a -X- _ O
learning -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
rank -X- _ I-TaskName
task -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
labels -X- _ O
are -X- _ O
pairwise -X- _ O
relevance -X- _ O
levels -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
reflection -X- _ O
, -X- _ O
i.e -X- _ O
, -X- _ O
NR -X- _ O
, -X- _ O
SR -X- _ O
and -X- _ O
CR -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
develop -X- _ O
a -X- _ O
scoring -X- _ O
framework -X- _ O
inspired -X- _ O
by -X- _ O
contrastive -X- _ O
and -X- _ O
metric -X- _ O
learning -X- _ O
strategies -X- _ O
, -X- _ O
where -X- _ O
binary -X- _ O
contrastive -X- _ O
estimations -X- _ O
are -X- _ O
computed -X- _ O
between -X- _ O
examples -X- _ O
for -X- _ O
consecutive -X- _ O
reflection -X- _ O
quality -X- _ O
levels -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
combines -X- _ O
two -X- _ O
metric -X- _ O
- -X- _ O
learning -X- _ O
based -X- _ O
objectives -X- _ O
that -X- _ O
enforce -X- _ O
the -X- _ O
correct -X- _ O
ranking -X- _ O
along -X- _ O
with -X- _ O
prompt -X- _ O
relevance -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
model -X- _ O
backbone -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
transformerbased -X- _ O
encoder -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
our -X- _ O
learning -X- _ O
objectives -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
neural -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
recurrent -X- _ O
neural -X- _ O
networks -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
RoBERTa -X- _ O
variant -X- _ O
of -X- _ O
the -X- _ O
transformerbased -X- _ O
encoder -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
a -X- _ O
simple -X- _ O
cross -X- _ O
encoder -X- _ O
that -X- _ O
takes -X- _ O
the -X- _ O
concatenated -X- _ O
sequence -X- _ O
of -X- _ O
a -X- _ O
prompt -X- _ O
and -X- _ O
a -X- _ O
response -X- _ O
pair -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
Since -X- _ O
this -X- _ O
design -X- _ O
choice -X- _ O
allows -X- _ O
to -X- _ O
directly -X- _ O
model -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
prompt -X- _ O
and -X- _ O
response -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
classify -X- _ O
our -X- _ O
main -X- _ O
model -X- _ O
as -X- _ O
a -X- _ O
cross -X- _ O
encoder -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
characterization -X- _ O
of -X- _ O
encoder -X- _ O
provided -X- _ O
by -X- _ O
Humeau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
level -X- _ O
Margin -X- _ O
Ranking -X- _ O
Objective -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
a -X- _ O
margin -X- _ O
ranking -X- _ O
loss -X- _ O
term -X- _ O
to -X- _ O
ensure -X- _ O
a -X- _ O
distance -X- _ O
gap -X- _ O
between -X- _ O
quality -X- _ O
levels -X- _ O
of -X- _ O
reflections -X- _ O
taking -X- _ O
inspiration -X- _ O
from -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
ranking -X- _ O
objective -X- _ O
uses -X- _ O
a -X- _ O
margin -X- _ O
parameter -X- _ O
µor2µ -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
examples -X- _ O
being -X- _ O
compared -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
term -X- _ O
, -X- _ O
where -X- _ O
µcorresponds -X- _ O
to -X- _ O
the -X- _ O
“ -X- _ O
gap -X- _ O
” -X- _ O
in -X- _ O
scores -X- _ O
between -X- _ O
each -X- _ O
neighboring -X- _ O
quality -X- _ O
level -X- _ O
pair -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
µwhen -X- _ O
the -X- _ O
quality -X- _ O
gap -X- _ O
is -X- _ O
within -X- _ O
one -X- _ O
level -X- _ O
i.e -X- _ O
, -X- _ O
distinguishing -X- _ O
between -X- _ O
medium -X- _ O
qualityand -X- _ O
high -X- _ O
quality -X- _ O
pairs -X- _ O
( -X- _ O
SR -X- _ O
, -X- _ O
CR -X- _ O
) -X- _ O
or -X- _ O
low -X- _ O
quality -X- _ O
and -X- _ O
medium -X- _ O
quality -X- _ O
pairs -X- _ O
( -X- _ O
NR -X- _ O
, -X- _ O
SR -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
2µwhen -X- _ O
the -X- _ O
gap -X- _ O
is -X- _ O
within -X- _ O
two -X- _ O
levels -X- _ O
i.e -X- _ O
, -X- _ O
low -X- _ O
quality -X- _ O
and -X- _ O
high -X- _ O
quality -X- _ O
pairs -X- _ O
( -X- _ O
NR -X- _ O
, -X- _ O
CR -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
loss -X- _ O
is -X- _ O
calculated -X- _ O
using -X- _ O
the -X- _ O
equation -X- _ O
below -X- _ O
, -X- _ O
where -X- _ O
pis -X- _ O
the -X- _ O
client -X- _ O
prompt -X- _ O
andr -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
rrespectively -X- _ O
denote -X- _ O
CR -X- _ O
, -X- _ O
SR -X- _ O
, -X- _ O
and -X- _ O
NR -X- _ O
responses -X- _ O
to -X- _ O
p. -X- _ O
L -X- _ O
= -X- _ O
max -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
µ− -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
−s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
+ -X- _ O
max -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
µ− -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
−s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
+ -X- _ O
max -X- _ O
{ -X- _ O
0,2∗µ− -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
−s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
Prompt -X- _ O
- -X- _ O
Aware -X- _ O
Margin -X- _ O
Ranking -X- _ O
Objective -X- _ O
. -X- _ O
In -X- _ O
preliminary -X- _ O
experiments -X- _ O
using -X- _ O
Lwe -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
tended -X- _ O
to -X- _ O
ignore -X- _ O
the -X- _ O
client -X- _ O
prompt -X- _ O
when -X- _ O
making -X- _ O
predictions -X- _ O
. -X- _ O
This -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
incorrect -X- _ O
scoring -X- _ O
for -X- _ O
cases -X- _ O
where -X- _ O
responses -X- _ O
are -X- _ O
not -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
client -X- _ O
prompt -X- _ O
but -X- _ O
do -X- _ O
follow -X- _ O
MI -X- _ O
style -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
objective -X- _ O
to -X- _ O
penalize -X- _ O
the -X- _ O
model -X- _ O
against -X- _ O
this -X- _ O
scenario -X- _ O
. -X- _ O
To -X- _ O
provide -X- _ O
examples -X- _ O
of -X- _ O
such -X- _ O
cases -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
an -X- _ O
additional -X- _ O
set -X- _ O
of -X- _ O
pairs -X- _ O
by -X- _ O
sampling -X- _ O
CR -X- _ O
and -X- _ O
SR -X- _ O
responses -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
m -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
batch -X- _ O
and -X- _ O
matching -X- _ O
them -X- _ O
with -X- _ O
random -X- _ O
prompts -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
( -X- _ O
p -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
condition -X- _ O
that -X- _ O
the -X- _ O
matched -X- _ O
prompts -X- _ O
must -X- _ O
be -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
pairs -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
treat -X- _ O
the -X- _ O
constructed -X- _ O
pairs -X- _ O
of -X- _ O
prompt -X- _ O
and -X- _ O
mismatched -X- _ O
responses -X- _ O
as -X- _ O
low -X- _ O
- -X- _ O
quality -X- _ O
examples -X- _ O
( -X- _ O
NR -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
formulate -X- _ O
the -X- _ O
following -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
ranking -X- _ O
objective -X- _ O
, -X- _ O
where -X- _ O
r -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
µ -X- _ O
, -X- _ O
and2µare -X- _ O
defined -X- _ O
as -X- _ O
in -X- _ O
L -X- _ O
, -X- _ O
while -X- _ O
m -X- _ O
, -X- _ O
m -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
mismatched -X- _ O
responses -X- _ O
. -X- _ O
L -X- _ O
= -X- _ O
max -X- _ O
{ -X- _ O
0,2∗µ− -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
−s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
m -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
+ -X- _ O
max -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
µ− -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
−s -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
m -X- _ O
) -X- _ O
) -X- _ O
} -X- _ O
Our -X- _ O
scoring -X- _ O
function -X- _ O
is -X- _ O
the -X- _ O
transformer -X- _ O
encoder -X- _ O
model -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
pooling -X- _ O
layer -X- _ O
and -X- _ O
a -X- _ O
sigmoid -X- _ O
activation -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
final -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
LandL -X- _ O
objectives -X- _ O
with -X- _ O
equal -X- _ O
weights -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
L+L151 -X- _ O
5 -X- _ O
Experiments -X- _ O
5.1 -X- _ O
Experimental -X- _ O
Setup -X- _ O
For -X- _ O
all -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
including -X- _ O
baselines -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Roberta -X- _ O
architecture -X- _ O
from -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
initialize -X- _ O
our -X- _ O
models -X- _ O
with -X- _ O
pretrained -X- _ O
weights -X- _ O
mental -X- _ O
- -X- _ O
roberta -X- _ O
- -X- _ O
base -X- _ O
from -X- _ O
( -X- _ O
Ji -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
choice -X- _ O
of -X- _ O
pretrained -X- _ O
weights -X- _ O
is -X- _ O
motivated -X- _ O
by -X- _ O
our -X- _ O
domain -X- _ O
being -X- _ O
similar -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
corpus -X- _ O
used -X- _ O
for -X- _ O
mental -X- _ O
- -X- _ O
roberta -X- _ O
- -X- _ O
base -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
mental -X- _ O
- -X- _ O
health -X- _ O
topic -X- _ O
posts -X- _ O
from -X- _ O
Reddit -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
counsel -X- _ O
- -X- _ O
seeking -X- _ O
posts -X- _ O
are -X- _ O
paired -X- _ O
with -X- _ O
responding -X- _ O
comments -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
preliminary -X- _ O
experiments -X- _ O
using -X- _ O
the -X- _ O
pretrained -X- _ O
weights -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
they -X- _ O
improve -X- _ O
overall -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
our -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
PyTorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Huggingface -X- _ O
Transformers -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
packages -X- _ O
. -X- _ O
For -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ B-HyperparameterName
with -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
, -X- _ O
a -X- _ O
constant -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
samples -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
apply -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ O
of -X- _ O
0.1 -X- _ B-HyperparameterValue
to -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
To -X- _ O
fit -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
into -X- _ O
our -X- _ O
computing -X- _ O
device -X- _ O
in -X- _ O
an -X- _ O
efficient -X- _ O
manner -X- _ O
, -X- _ O
we -X- _ O
subsample -X- _ O
each -X- _ O
data -X- _ O
row -X- _ O
into -X- _ O
a -X- _ O
smaller -X- _ O
row -X- _ O
. -X- _ O
That -X- _ O
is -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
prompt -X- _ O
- -X- _ O
tuple -X- _ O
with -X- _ O
one -X- _ O
prompt -X- _ O
and -X- _ O
eight -X- _ O
responses -X- _ O
( -X- _ O
2 -X- _ O
/ -X- _ O
1 -X- _ O
/ -X- _ O
5 -X- _ O
CR -X- _ O
/ -X- _ O
SR -X- _ O
/ -X- _ O
NR -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
20 -X- _ O
sub -X- _ O
- -X- _ O
tuples -X- _ O
with -X- _ O
one -X- _ O
prompt -X- _ O
and -X- _ O
four -X- _ O
responses -X- _ O
, -X- _ O
composed -X- _ O
of -X- _ O
1 -X- _ O
CR -X- _ O
, -X- _ O
1 -X- _ O
SR -X- _ O
and -X- _ O
2 -X- _ O
NR -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
manner -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
pairwise -X- _ O
data -X- _ O
is -X- _ O
318 -X- _ O
* -X- _ O
20 -X- _ O
= -X- _ O
6360 -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
for -X- _ O
two -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
on -X- _ O
one -X- _ O
NVIDIA -X- _ O
GeForce -X- _ O
RTX -X- _ O
2080 -X- _ O
Ti -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
( -X- _ O
using -X- _ O
gradient -X- _ O
accumulation -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
aside -X- _ O
20 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
our -X- _ O
data -X- _ O
as -X- _ O
our -X- _ O
test -X- _ B-HyperparameterName
set -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
main -X- _ O
performance -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
, -X- _ O
Pearsonand -X- _ B-MetricName
Spearman -X- _ B-MetricName
, -X- _ O
and -X- _ O
Kendall -X- _ O
’s -X- _ O
Tau -X- _ B-MetricName
correlation -X- _ B-MetricName
coeficient -X- _ I-MetricName
. -X- _ O
We -X- _ O
compute -X- _ O
the -X- _ O
Pearson -X- _ O
and -X- _ O
Spearman -X- _ O
correlations -X- _ O
between -X- _ O
the -X- _ O
model -X- _ O
- -X- _ O
predicted -X- _ O
scores -X- _ O
and -X- _ O
the -X- _ O
discrete -X- _ O
label -X- _ O
mapped -X- _ O
to -X- _ O
an -X- _ O
integer -X- _ O
level -X- _ O
corresponding -X- _ O
to -X- _ O
their -X- _ O
order -X- _ O
. -X- _ O
For -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
and -X- _ O
Kendall -X- _ O
’s -X- _ O
Tau -X- _ B-MetricName
, -X- _ O
given -X- _ O
a -X- _ O
client -X- _ O
prompt -X- _ O
, -X- _ O
counselor -X- _ O
responses -X- _ O
with -X- _ O
varying -X- _ O
levels -X- _ O
of -X- _ O
reflection -X- _ O
quality -X- _ O
are -X- _ O
considered -X- _ O
rankings -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
true -X- _ O
and -X- _ O
predicted -X- _ O
reflection -X- _ O
levels -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
true -X- _ O
and -X- _ O
predicted -X- _ O
rankings -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
mentioned -X- _ O
metrics -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
prompt -X- _ O
and -X- _ O
response -X- _ O
pairs -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
match -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
response -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
coherent -X- _ O
reply -X- _ O
to -X- _ O
the -X- _ O
prompt -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
each -X- _ O
prompt -X- _ O
- -X- _ O
response -X- _ O
tuple -X- _ O
with -X- _ O
a -X- _ O
kresponse -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
prompt -X- _ O
tuple -X- _ O
. -X- _ O
The -X- _ O
ground -X- _ O
truth -X- _ O
judgement -X- _ O
for -X- _ O
the -X- _ O
randomly -X- _ O
matched -X- _ O
responses -X- _ O
are -X- _ O
NR -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
judgement -X- _ O
the -X- _ O
responses -X- _ O
received -X- _ O
. -X- _ O
5.2 -X- _ O
Reflection -X- _ O
Scorer -X- _ O
Models -X- _ O
Using -X- _ O
the -X- _ O
PAIR -X- _ B-MethodName
model -X- _ O
as -X- _ O
our -X- _ O
architecture -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
different -X- _ O
versions -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
level -X- _ O
ranking -X- _ O
and -X- _ O
promptaware -X- _ O
objectives -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
models -X- _ O
with -X- _ O
or -X- _ O
without -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
objective -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O
5.3 -X- _ O
Baselines -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
baselines -X- _ O
that -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
transformer -X- _ O
encoder -X- _ O
architecture -X- _ O
and -X- _ O
pretrained -X- _ O
weights -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
a -X- _ O
classifier -X- _ O
and -X- _ O
a -X- _ O
regressor -X- _ O
using -X- _ O
linear -X- _ O
heads -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
encoders -X- _ O
. -X- _ O
Naive -X- _ B-MethodName
Classifier -X- _ I-MethodName
. -X- _ O
Given -X- _ O
a -X- _ O
prompt -X- _ O
and -X- _ O
a -X- _ O
response -X- _ O
, -X- _ O
it -X- _ O
outputs -X- _ O
a -X- _ O
discrete -X- _ O
label -X- _ O
for -X- _ O
the -X- _ O
reflection -X- _ O
quality152 -X- _ O
of -X- _ O
the -X- _ O
responses -X- _ O
i.e. -X- _ O
, -X- _ O
NR -X- _ O
, -X- _ O
CR -X- _ O
or -X- _ O
NR -X- _ O
. -X- _ O
The -X- _ O
classification -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
standard -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
against -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
discrete -X- _ O
reflection -X- _ O
quality -X- _ O
labels -X- _ O
included -X- _ O
in -X- _ O
our -X- _ O
annotated -X- _ O
dataset -X- _ O
. -X- _ O
Naive -X- _ B-MethodName
Regressor -X- _ I-MethodName
. -X- _ O
Given -X- _ O
a -X- _ O
prompt -X- _ O
and -X- _ O
a -X- _ O
response -X- _ O
, -X- _ O
it -X- _ O
outputs -X- _ O
a -X- _ O
scalar -X- _ O
score -X- _ O
( -X- _ O
between -X- _ O
[ -X- _ O
0,1 -X- _ O
] -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
reflection -X- _ O
quality -X- _ O
level -X- _ O
of -X- _ O
the -X- _ O
response -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
standard -X- _ O
mean -X- _ O
squared -X- _ O
error -X- _ O
loss -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
convert -X- _ O
discrete -X- _ O
labels -X- _ O
into -X- _ O
continuous -X- _ O
scores -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
mapping -X- _ O
: -X- _ O
{ -X- _ O
CR -X- _ O
: -X- _ O
1.0 -X- _ O
, -X- _ O
SR -X- _ O
: -X- _ O
0.5 -X- _ O
, -X- _ O
NR -X- _ O
: -X- _ O
0.0 -X- _ O
} -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
versions -X- _ O
of -X- _ O
the -X- _ O
baselines -X- _ O
that -X- _ O
are -X- _ O
additionally -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
loss -X- _ O
term -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
original -X- _ O
losses -X- _ O
. -X- _ O
As -X- _ O
in -X- _ O
our -X- _ O
cross -X- _ O
- -X- _ O
encoder -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
negative -X- _ O
examples -X- _ O
by -X- _ O
switching -X- _ O
the -X- _ O
client -X- _ O
context -X- _ O
and -X- _ O
labeling -X- _ O
it -X- _ O
as -X- _ O
NR -X- _ O
. -X- _ O
6 -X- _ O
Results -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
evaluation -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
scorer -X- _ O
models -X- _ O
and -X- _ O
baselines -X- _ O
on -X- _ O
the -X- _ O
set -X- _ O
- -X- _ O
aside -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
while -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
experiment -X- _ O
results -X- _ O
over -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
augmented -X- _ O
with -X- _ O
randomly -X- _ O
- -X- _ O
matched -X- _ O
responses -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
tables -X- _ O
, -X- _ O
PAIR -X- _ B-MethodName
refers -X- _ O
to -X- _ O
our -X- _ O
main -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
our -X- _ O
objectives -X- _ O
, -X- _ O
while -X- _ O
* -X- _ O
indicate -X- _ O
that -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
objective -X- _ O
for -X- _ O
ablation -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
leave -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
level -X- _ O
margin -X- _ O
ranking -X- _ O
objective -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
Tables -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
results -X- _ O
are -X- _ O
identical -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
even -X- _ O
after -X- _ O
randomly -X- _ O
matched -X- _ O
responses -X- _ O
are -X- _ O
added -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
correctly -X- _ O
identify -X- _ O
response -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
reflection -X- _ O
level -X- _ O
( -X- _ O
complex -X- _ O
reflection -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
for -X- _ O
the -X- _ O
naive -X- _ O
classifier -X- _ O
models -X- _ O
Spearman -X- _ B-MetricName
correla -X- _ O
- -X- _ O
tion -X- _ O
scores -X- _ O
higher -X- _ O
than -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ O
, -X- _ O
likely -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ O
measures -X- _ O
monotonic -X- _ O
relationships -X- _ O
and -X- _ O
the -X- _ O
naive -X- _ B-MethodName
classifier -X- _ I-MethodName
predictions -X- _ O
contain -X- _ O
frequent -X- _ O
ties -X- _ O
, -X- _ O
since -X- _ O
unlike -X- _ O
other -X- _ O
models -X- _ O
the -X- _ O
classifier -X- _ O
outputs -X- _ O
discrete -X- _ O
integers -X- _ O
. -X- _ O
Baseline -X- _ O
Comparison -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
against -X- _ O
several -X- _ O
baselines -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
tested -X- _ O
against -X- _ O
data -X- _ O
without -X- _ O
randomly -X- _ O
matched -X- _ O
responses -X- _ O
( -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
baseline -X- _ O
models -X- _ O
( -X- _ O
Naive -X- _ B-MethodName
Classifier -X- _ I-MethodName
, -X- _ O
Naive -X- _ B-MethodName
Regressor -X- _ I-MethodName
) -X- _ O
perform -X- _ O
similarly -X- _ O
to -X- _ O
PAIR -X- _ B-MethodName
* -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
level -X- _ O
objective -X- _ O
but -X- _ O
not -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
objective -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
PAIR -X- _ B-MethodName
* -X- _ O
model -X- _ O
scores -X- _ O
highest -X- _ O
of -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
and -X- _ O
Kendall -X- _ O
’s -X- _ O
Tau -X- _ B-MetricName
, -X- _ O
its -X- _ O
Pearson -X- _ B-MetricName
and -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ B-MetricName
coefficients -X- _ I-MetricName
are -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
naive -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
more -X- _ O
evidence -X- _ O
in -X- _ O
favor -X- _ O
of -X- _ O
PAIR -X- _ B-MethodName
. -X- _ O
Comparing -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
models -X- _ O
( -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
models -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
PAIR -X- _ B-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
both -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
objectives -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
Naive -X- _ B-MethodName
Regressor -X- _ I-MethodName
model -X- _ O
. -X- _ O
When -X- _ O
comparing -X- _ O
the -X- _ O
Naive -X- _ B-MethodName
Classifier -X- _ I-MethodName
and -X- _ O
the -X- _ O
PAIR -X- _ B-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
Naive -X- _ B-MethodName
Classifier -X- _ I-MethodName
models -X- _ O
are -X- _ O
better -X- _ O
for -X- _ O
the -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
metric -X- _ O
. -X- _ O
We -X- _ O
remark -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
, -X- _ O
since -X- _ O
they -X- _ O
represent -X- _ O
different -X- _ O
frameworks -X- _ O
of -X- _ O
prediction -X- _ O
and -X- _ O
feedback -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
in -X- _ O
a -X- _ O
setting -X- _ O
where -X- _ O
a -X- _ O
continuous -X- _ O
score -X- _ O
is -X- _ O
desired -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
preferable -X- _ O
to -X- _ O
the -X- _ O
classifier -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
provide -X- _ O
a -X- _ O
more -X- _ O
detailed -X- _ O
feedback -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
better -X- _ O
convey -X- _ O
the -X- _ O
implicit -X- _ O
preference -X- _ O
ranking -X- _ O
of -X- _ O
different -X- _ O
responses -X- _ O
, -X- _ O
as -X- _ O
evidenced -X- _ O
by -X- _ O
its -X- _ O
higher -X- _ O
Kendall -X- _ O
’s -X- _ O
Tau -X- _ B-MetricName
score.1537 -X- _ O
Ablation -X- _ O
Study -X- _ O
We -X- _ O
study -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
learning -X- _ O
objective -X- _ O
by -X- _ O
conducting -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
ablation -X- _ O
experiments -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
scorer -X- _ O
models -X- _ O
and -X- _ O
baselines -X- _ O
with -X- _ O
or -X- _ O
without -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
learning -X- _ O
objective -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
when -X- _ O
we -X- _ O
tested -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
test -X- _ O
cases -X- _ O
where -X- _ O
all -X- _ O
prompt -X- _ O
- -X- _ O
response -X- _ O
pairs -X- _ O
were -X- _ O
matched -X- _ O
pairs -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
response -X- _ O
was -X- _ O
in -X- _ O
response -X- _ O
to -X- _ O
the -X- _ O
matched -X- _ O
prompt -X- _ O
) -X- _ O
, -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
models -X- _ O
perform -X- _ O
worse -X- _ O
in -X- _ O
all -X- _ O
metrics -X- _ O
than -X- _ O
their -X- _ O
* -X- _ O
counterparts -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
using -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
during -X- _ O
training -X- _ O
leads -X- _ O
to -X- _ O
performance -X- _ O
losses -X- _ O
when -X- _ O
tested -X- _ O
on -X- _ O
data -X- _ O
without -X- _ O
randomly -X- _ O
matched -X- _ O
responses -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
performance -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
reflection -X- _ O
scoring -X- _ O
and -X- _ O
incoherence -X- _ O
detection -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
test -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
augmented -X- _ O
with -X- _ O
randomly -X- _ O
- -X- _ O
matched -X- _ O
negative -X- _ O
responses -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
loss -X- _ O
leads -X- _ O
to -X- _ O
improved -X- _ O
performance -X- _ O
on -X- _ O
data -X- _ O
that -X- _ O
includes -X- _ O
random -X- _ O
responses -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
models -X- _ O
perform -X- _ O
consistently -X- _ O
better -X- _ O
than -X- _ O
their -X- _ O
counterparts -X- _ O
on -X- _ O
all -X- _ O
metrics -X- _ O
except -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
. -X- _ O
This -X- _ O
result -X- _ O
is -X- _ O
expected -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
loss -X- _ O
was -X- _ O
specifically -X- _ O
designed -X- _ O
to -X- _ O
prevent -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
ignoring -X- _ O
prompts -X- _ O
when -X- _ O
predicting -X- _ O
reflection -X- _ O
levels -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
our -X- _ O
objective -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
addressing -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
critical -X- _ O
point -X- _ O
of -X- _ O
failure -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
the -X- _ O
assumption -X- _ O
of -X- _ O
coherent -X- _ O
or -X- _ O
relevant -X- _ O
user -X- _ O
input -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
guaranteed -X- _ O
. -X- _ O
8 -X- _ O
User -X- _ O
Study -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
testing -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
annotated -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
deploy -X- _ O
our -X- _ O
final -X- _ O
model -X- _ O
( -X- _ O
PAIR -X- _ B-MethodName
) -X- _ O
in -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
education -X- _ O
setting -X- _ O
– -X- _ O
a -X- _ O
graduate -X- _ O
- -X- _ O
level -X- _ O
MI -X- _ O
training -X- _ O
course -X- _ O
taught -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
collaborated -X- _ O
with -X- _ O
MI -X- _ O
experts -X- _ O
at -X- _ O
the -X- _ O
University -X- _ O
of -X- _ O
Michigan -X- _ O
School -X- _ O
of -X- _ O
Public -X- _ O
Health -X- _ O
and -X- _ O
implemented -X- _ O
a -X- _ O
web -X- _ O
application -X- _ O
for -X- _ O
a -X- _ O
graduate -X- _ O
- -X- _ O
level -X- _ O
MI -X- _ O
training -X- _ O
course -X- _ O
. -X- _ O
We -X- _ O
develop -X- _ O
and -X- _ O
evaluate -X- _ O
a -X- _ O
web -X- _ O
based -X- _ O
application -X- _ O
that -X- _ O
uses -X- _ O
the -X- _ O
PAIR -X- _ B-MethodName
model -X- _ O
to -X- _ O
provide -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
scoring -X- _ O
feedback -X- _ O
to -X- _ O
students -X- _ O
while -X- _ O
learning -X- _ O
to -X- _ O
create -X- _ O
reflective -X- _ O
responses -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
client -X- _ O
prompt -X- _ O
. -X- _ O
We -X- _ O
plan -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
system -X- _ O
website -X- _ O
available -X- _ O
for -X- _ O
demonstration -X- _ O
. -X- _ O
System -X- _ O
Implementation -X- _ O
. -X- _ O
The -X- _ O
web -X- _ O
platform -X- _ O
is -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
shows -X- _ O
a -X- _ O
client -X- _ O
prompt -X- _ O
to -X- _ O
the -X- _ O
counseling -X- _ O
trainee -X- _ O
and -X- _ O
ask -X- _ O
them -X- _ O
to -X- _ O
write -X- _ O
a -X- _ O
reflective -X- _ O
response -X- _ O
for -X- _ O
the -X- _ O
situation -X- _ O
depicted -X- _ O
in -X- _ O
the -X- _ O
prompt -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
shows -X- _ O
five -X- _ O
prompts -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
trainee -X- _ O
only -X- _ O
needs -X- _ O
to -X- _ O
provide -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
response -X- _ O
to -X- _ O
receive -X- _ O
feedback -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
trainee -X- _ O
has -X- _ O
provided -X- _ O
their -X- _ O
response -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
system -X- _ O
shows -X- _ O
detailed -X- _ O
feedback -X- _ O
for -X- _ O
each -X- _ O
response -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
numerical -X- _ O
score -X- _ O
ranging -X- _ O
between -X- _ O
0 -X- _ O
- -X- _ O
1 -X- _ O
and -X- _ O
two -X- _ O
examples -X- _ O
of -X- _ O
high -X- _ O
quality -X- _ O
( -X- _ O
CR -X- _ O
) -X- _ O
reflections -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
prompt -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
is -X- _ O
implemented -X- _ O
as -X- _ O
a -X- _ O
web -X- _ O
server -X- _ O
using -X- _ O
Nginx -X- _ O
, -X- _ O
Gunicorn -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Flaskweb -X- _ O
framework -X- _ O
and -X- _ O
is -X- _ O
run -X- _ O
on -X- _ O
a -X- _ O
secure -X- _ O
machine -X- _ O
. -X- _ O
The -X- _ O
system -X- _ O
takes -X- _ O
less -X- _ O
than -X- _ O
one -X- _ O
second -X- _ O
to -X- _ O
run -X- _ O
the -X- _ O
PAIR -X- _ O
model -X- _ O
for -X- _ O
˜30 -X- _ O
prompt -X- _ O
and -X- _ O
response -X- _ O
pairs -X- _ O
and -X- _ O
provide -X- _ O
feedback -X- _ O
. -X- _ O
Participants -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
a -X- _ O
user -X- _ O
study -X- _ O
with -X- _ O
30 -X- _ O
students -X- _ O
enrolled -X- _ O
in -X- _ O
the -X- _ O
MI -X- _ O
training -X- _ O
class -X- _ O
. -X- _ O
The -X- _ O
students -X- _ O
used -X- _ O
our -X- _ O
system -X- _ O
to -X- _ O
complete -X- _ O
three -X- _ O
assignments -X- _ O
that -X- _ O
required -X- _ O
them -X- _ O
to -X- _ O
practice -X- _ O
their -X- _ O
reflective -X- _ O
skills -X- _ O
. -X- _ O
Over -X- _ O
the -X- _ O
course -X- _ O
of -X- _ O
four -X- _ O
weeks -X- _ O
between -X- _ O
January -X- _ O
- -X- _ O
February -X- _ O
2022 -X- _ O
, -X- _ O
they -X- _ O
completed -X- _ O
three -X- _ O
assignments -X- _ O
, -X- _ O
each -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
client -X- _ O
prompts -X- _ O
designed -X- _ O
by -X- _ O
the -X- _ O
course -X- _ O
instructor -X- _ O
. -X- _ O
Before -X- _ O
using -X- _ O
the -X- _ O
system -X- _ O
, -X- _ O
participants -X- _ O
were -X- _ O
directed -X- _ O
to -X- _ O
a -X- _ O
page -X- _ O
where -X- _ O
they -X- _ O
read -X- _ O
the -X- _ O
consent -X- _ O
form -X- _ O
. -X- _ O
If -X- _ O
they -X- _ O
agreed -X- _ O
to -X- _ O
participate -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
directed -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
system -X- _ O
view -X- _ O
showing -X- _ O
the -X- _ O
different -X- _ O
prompts -X- _ O
to -X- _ O
be -X- _ O
answered -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
assignment -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
assignment -X- _ O
, -X- _ O
the -X- _ O
participant -X- _ O
was -X- _ O
presented -X- _ O
with -X- _ O
about -X- _ O
20 -X- _ O
client -X- _ O
prompts -X- _ O
, -X- _ O
to -X- _ O
which -X- _ O
they -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
write -X- _ O
a -X- _ O
reflective -X- _ O
response -X- _ O
to -X- _ O
the -X- _ O
situation -X- _ O
being -X- _ O
described -X- _ O
by -X- _ O
the -X- _ O
client -X- _ O
. -X- _ O
Participants -X- _ O
completed -X- _ O
their -X- _ O
assignments -X- _ O
at -X- _ O
their -X- _ O
own -X- _ O
pace -X- _ O
as -X- _ O
the -X- _ O
system -X- _ O
allowed -X- _ O
them -X- _ O
to -X- _ O
save -X- _ O
and -X- _ O
retrieve -X- _ O
their -X- _ O
work -X- _ O
at -X- _ O
any -X- _ O
time -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
participant -X- _ O
submitted -X- _ O
their -X- _ O
responses -X- _ O
, -X- _ O
the -X- _ O
web -X- _ O
application -X- _ O
ran -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
server -X- _ O
and -X- _ O
provided -X- _ O
detailed -X- _ O
feedback -X- _ O
to -X- _ O
each -X- _ O
response -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
two -X- _ O
ground -X- _ O
truth -X- _ O
high -X- _ O
quality -X- _ O
reflections -X- _ O
for -X- _ O
each -X- _ O
prompt -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
predicted -X- _ O
score -X- _ O
. -X- _ O
Participants -X- _ O
were -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
on -X- _ O
completion -X- _ O
/ -X- _ O
non -X- _ O
completion -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
assignment -X- _ O
. -X- _ O
After -X- _ O
completing -X- _ O
each -X- _ O
assignment -X- _ O
, -X- _ O
participants -X- _ O
took -X- _ O
a -X- _ O
survey -X- _ O
regarding -X- _ O
the -X- _ O
system -X- _ O
accuracy -X- _ O
and -X- _ O
usability -X- _ O
and -X- _ O
optional -X- _ O
qualitative -X- _ O
feedback -X- _ O
. -X- _ O
A -X- _ O
screenshot -X- _ O
of -X- _ O
our -X- _ O
web -X- _ O
interface -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
8.1 -X- _ O
Evaluation -X- _ O
with -X- _ O
User -X- _ O
- -X- _ O
generated -X- _ O
Responses -X- _ O
The -X- _ O
student -X- _ O
submissions -X- _ O
are -X- _ O
new -X- _ O
data -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
useful -X- _ O
to -X- _ O
further -X- _ O
train -X- _ O
or -X- _ O
evaluate -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
We154 -X- _ O
annotate -X- _ O
the -X- _ O
submissions -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
a -X- _ O
student -X- _ O
instructor -X- _ O
, -X- _ O
who -X- _ O
reviewed -X- _ O
each -X- _ O
submitted -X- _ O
response -X- _ O
alongside -X- _ O
the -X- _ O
original -X- _ O
prompt -X- _ O
and -X- _ O
annotated -X- _ O
it -X- _ O
with -X- _ O
a -X- _ O
discrete -X- _ O
reflection -X- _ O
level -X- _ O
judgement -X- _ O
. -X- _ O
Given -X- _ O
this -X- _ O
new -X- _ O
annotated -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
correlation -X- _ B-MetricName
metrics -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
convert -X- _ O
a -X- _ O
model -X- _ O
predicted -X- _ O
score -X- _ O
into -X- _ O
a -X- _ O
discrete -X- _ O
judgement -X- _ O
using -X- _ O
the -X- _ O
mapping -X- _ O
: -X- _ O
{ -X- _ O
CR -X- _ O
: -X- _ O
[ -X- _ O
0.7,1.0 -X- _ O
] -X- _ O
, -X- _ O
SR -X- _ O
: -X- _ O
[ -X- _ O
0.3,0.7 -X- _ O
] -X- _ O
, -X- _ O
NR -X- _ O
: -X- _ O
[ -X- _ O
0.0,0.3 -X- _ O
] -X- _ O
} -X- _ O
. -X- _ O
This -X- _ O
mapping -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
our -X- _ O
and -X- _ O
experts -X- _ O
’ -X- _ O
observation -X- _ O
on -X- _ O
score -X- _ O
distribution -X- _ O
over -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
responses -X- _ O
. -X- _ O
As -X- _ O
indicated -X- _ O
by -X- _ O
the -X- _ O
confusion -X- _ O
matrix -X- _ O
and -X- _ O
accuracies -X- _ B-MetricName
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
does -X- _ O
best -X- _ O
on -X- _ O
correctly -X- _ O
identifying -X- _ O
CRs -X- _ O
, -X- _ O
while -X- _ O
performing -X- _ O
less -X- _ O
well -X- _ O
on -X- _ O
SRs -X- _ O
and -X- _ O
NRs -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
ground -X- _ O
truth -X- _ O
labels -X- _ O
shows -X- _ O
, -X- _ O
identifying -X- _ O
and -X- _ O
encouraging -X- _ O
reflective -X- _ O
listening -X- _ O
is -X- _ O
a -X- _ O
priority -X- _ O
of -X- _ O
this -X- _ O
class -X- _ O
, -X- _ O
and -X- _ O
hence -X- _ O
the -X- _ O
low -X- _ O
false -X- _ B-MetricName
positive -X- _ I-MetricName
rate -X- _ I-MetricName
shown -X- _ O
by -X- _ O
the -X- _ O
system -X- _ O
is -X- _ O
aligned -X- _ O
with -X- _ O
this -X- _ O
design -X- _ O
objective -X- _ O
. -X- _ O
8.2 -X- _ O
Usability -X- _ O
Evaluation -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
a -X- _ O
usability -X- _ O
study -X- _ O
to -X- _ O
test -X- _ O
how -X- _ O
well -X- _ O
our -X- _ O
model -X- _ O
does -X- _ O
in -X- _ O
a -X- _ O
real -X- _ O
setting -X- _ O
. -X- _ O
Usability -X- _ O
Survey -X- _ O
Result -X- _ O
. -X- _ O
To -X- _ O
collect -X- _ O
and -X- _ O
measure -X- _ O
user -X- _ O
experience -X- _ O
and -X- _ O
satisfaction -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
a -X- _ O
5 -X- _ O
- -X- _ O
point -X- _ O
Likert -X- _ O
questionnaire -X- _ O
on -X- _ O
the -X- _ O
perceived -X- _ O
accuracy -X- _ O
and -X- _ O
usability -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
9 -X- _ O
questions -X- _ O
covering -X- _ O
model -X- _ O
error -X- _ O
and -X- _ O
systemusability -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
user -X- _ O
responses -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
received -X- _ O
positive -X- _ O
assessment -X- _ O
on -X- _ O
average -X- _ O
for -X- _ O
both -X- _ O
accessibility -X- _ O
and -X- _ O
performance -X- _ O
questions -X- _ O
. -X- _ O
Qualitative -X- _ O
Feedback -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
asked -X- _ O
users -X- _ O
to -X- _ O
submit -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
text -X- _ O
feedbacks -X- _ O
after -X- _ O
submitting -X- _ O
the -X- _ O
assignment -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
submitted -X- _ O
comments -X- _ O
, -X- _ O
positive -X- _ O
answers -X- _ O
focus -X- _ O
on -X- _ O
how -X- _ O
the -X- _ O
application -X- _ O
allowed -X- _ O
them -X- _ O
to -X- _ O
have -X- _ O
more -X- _ O
practice -X- _ O
and -X- _ O
build -X- _ O
up -X- _ O
confidence -X- _ O
, -X- _ O
while -X- _ O
negative -X- _ O
feedback -X- _ O
is -X- _ O
usually -X- _ O
concerned -X- _ O
with -X- _ O
the -X- _ O
functionality -X- _ O
aspects -X- _ O
such -X- _ O
as -X- _ O
saving -X- _ O
and -X- _ O
loading -X- _ O
their -X- _ O
work -X- _ O
. -X- _ O
9 -X- _ O
Ethics -X- _ O
Statement -X- _ O
Privacy -X- _ O
and -X- _ O
Data -X- _ O
Protection -X- _ O
. -X- _ O
We -X- _ O
ensure -X- _ O
that -X- _ O
users -X- _ O
of -X- _ O
our -X- _ O
systems -X- _ O
are -X- _ O
informed -X- _ O
of -X- _ O
our -X- _ O
data -X- _ O
collection -X- _ O
practices -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
data -X- _ O
cleaning -X- _ O
and -X- _ O
anonymization -X- _ O
to -X- _ O
remove -X- _ O
any -X- _ O
personal -X- _ O
or -X- _ O
sensitive -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
collected -X- _ O
data -X- _ O
. -X- _ O
Bias -X- _ O
and -X- _ O
Impact -X- _ O
of -X- _ O
the -X- _ O
Model -X- _ O
Since -X- _ O
our -X- _ O
model -X- _ O
provides -X- _ O
feedback -X- _ O
to -X- _ O
human -X- _ O
behavior -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
risk -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
may -X- _ O
have -X- _ O
negative -X- _ O
consequences -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
biases -X- _ O
or -X- _ O
artifacts -X- _ O
contained -X- _ O
in -X- _ O
expert -X- _ O
annotation -X- _ O
can -X- _ O
be -X- _ O
encoded -X- _ O
in -X- _ O
such -X- _ O
models -X- _ O
and -X- _ O
may -X- _ O
exert -X- _ O
influence -X- _ O
on -X- _ O
students -X- _ O
who -X- _ O
are -X- _ O
trying -X- _ O
to -X- _ O
mimic -X- _ O
or -X- _ O
learn -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
have -X- _ O
not -X- _ O
detected -X- _ O
any -X- _ O
such -X- _ O
examples -X- _ O
or -X- _ O
trends -X- _ O
during -X- _ O
the -X- _ O
model -X- _ O
testing -X- _ O
and -X- _ O
deployment -X- _ O
, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
further -X- _ O
study -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
10 -X- _ O
Limitations -X- _ O
Our -X- _ O
work -X- _ O
has -X- _ O
several -X- _ O
limitations -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
address -X- _ O
in -X- _ O
our -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
finetuned -X- _ O
using -X- _ O
only -X- _ O
synthetic -X- _ O
data -X- _ O
, -X- _ O
annotated -X- _ O
by -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
experts -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
prede-155fined -X- _ O
collection -X- _ O
of -X- _ O
simulated -X- _ O
client -X- _ O
prompts -X- _ O
. -X- _ O
We -X- _ O
included -X- _ O
real -X- _ O
counseling -X- _ O
data -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
through -X- _ O
pretraining -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
supervised -X- _ O
training -X- _ O
or -X- _ O
downstream -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
wild -X- _ O
through -X- _ O
system -X- _ O
deployment -X- _ O
and -X- _ O
user -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
to -X- _ O
further -X- _ O
understand -X- _ O
and -X- _ O
bridge -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
models -X- _ O
trained -X- _ O
using -X- _ O
observed -X- _ O
data -X- _ O
and -X- _ O
models -X- _ O
trained -X- _ O
using -X- _ O
synthetic -X- _ O
data -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
rely -X- _ O
on -X- _ O
linguistic -X- _ O
and -X- _ O
reflection -X- _ O
style -X- _ O
to -X- _ O
score -X- _ O
reflections -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
account -X- _ O
for -X- _ O
conversational -X- _ O
aspects -X- _ O
such -X- _ O
as -X- _ O
empathy -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
considered -X- _ O
an -X- _ O
important -X- _ O
counseling -X- _ O
strategy -X- _ O
while -X- _ O
generating -X- _ O
reflections -X- _ O
. -X- _ O
In -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
preliminary -X- _ O
experiments -X- _ O
where -X- _ O
we -X- _ O
compared -X- _ O
our -X- _ O
reflection -X- _ O
scores -X- _ O
and -X- _ O
empathy -X- _ O
levels -X- _ O
computed -X- _ O
by -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
’s -X- _ O
empathy -X- _ O
model -X- _ O
( -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
emotional -X- _ O
reactions -X- _ O
to -X- _ O
mental -X- _ O
health -X- _ O
posts -X- _ O
tend -X- _ O
to -X- _ O
have -X- _ O
low -X- _ O
reflection -X- _ O
levels -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
counseling -X- _ O
reflection -X- _ O
is -X- _ O
related -X- _ O
but -X- _ O
not -X- _ O
identical -X- _ O
to -X- _ O
empathy -X- _ O
in -X- _ O
counseling -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
reflection -X- _ O
scoring -X- _ O
system -X- _ O
proposed -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
mainly -X- _ O
provides -X- _ O
numerical -X- _ O
scoring -X- _ O
feedback -X- _ O
to -X- _ O
trainees -X- _ O
along -X- _ O
with -X- _ O
good -X- _ O
reflection -X- _ O
feedback -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
designed -X- _ O
by -X- _ O
the -X- _ O
course -X- _ O
instructor -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
working -X- _ O
on -X- _ O
expanding -X- _ O
the -X- _ O
system -X- _ O
to -X- _ O
include -X- _ O
models -X- _ O
for -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
feedback -X- _ O
, -X- _ O
beyond -X- _ O
mere -X- _ O
reflection -X- _ O
level -X- _ O
scoring -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
by -X- _ O
exploring -X- _ O
generative -X- _ O
models -X- _ O
to -X- _ O
automatically -X- _ O
create -X- _ O
counselor -X- _ O
responses -X- _ O
, -X- _ O
reference -X- _ O
responses -X- _ O
can -X- _ O
be -X- _ O
provided -X- _ O
for -X- _ O
students -X- _ O
, -X- _ O
even -X- _ O
when -X- _ O
annotated -X- _ O
ground -X- _ O
truth -X- _ O
is -X- _ O
unavailable -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
rewriting -X- _ O
models -X- _ O
can -X- _ O
provide -X- _ O
more -X- _ O
valuable -X- _ O
feedback -X- _ O
by -X- _ O
presenting -X- _ O
improved -X- _ O
versions -X- _ O
of -X- _ O
students -X- _ O
’ -X- _ O
own -X- _ O
responses -X- _ O
. -X- _ O
11 -X- _ O
Conclusion -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
reflection -X- _ O
scoring -X- _ O
and -X- _ O
developed -X- _ O
a -X- _ O
prompt -X- _ O
- -X- _ O
aware -X- _ O
margin -X- _ O
ranking -X- _ O
approach -X- _ O
, -X- _ O
PAIR -X- _ B-MethodName
, -X- _ O
to -X- _ O
tackle -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
predict -X- _ O
continuous -X- _ O
scores -X- _ O
from -X- _ O
discrete -X- _ O
label -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
outperforms -X- _ O
simple -X- _ O
baselines -X- _ O
on -X- _ O
several -X- _ O
metrics -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
showed -X- _ O
its -X- _ O
deployment -X- _ O
in -X- _ O
an -X- _ O
educational -X- _ O
setting -X- _ O
with -X- _ O
real -X- _ O
students -X- _ O
and -X- _ O
instructors -X- _ O
. -X- _ O
We -X- _ O
plan -X- _ O
to -X- _ O
extend -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
incorporate -X- _ O
diverse -X- _ O
information -X- _ O
that -X- _ O
can -X- _ O
assist -X- _ O
counselors -X- _ O
in -X- _ O
understanding -X- _ O
their -X- _ O
clients -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
dialog -X- _ O
context -X- _ O
, -X- _ O
client -X- _ O
background -X- _ O
, -X- _ O
or -X- _ O
medical -X- _ O
knowledge -X- _ O
. -X- _ O
We -X- _ O
make -X- _ O
our -X- _ O
data -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
lit.eecs.umich.edu -X- _ O
/ -X- _ O
downloads -X- _ O
. -X- _ O
html -X- _ O
# -X- _ O
PAIR -X- _ O
. -X- _ O
Acknowledgements -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
express -X- _ O
gratitude -X- _ O
toward -X- _ O
researchers -X- _ O
and -X- _ O
students -X- _ O
from -X- _ O
the -X- _ O
University -X- _ O
of -X- _ O
Michigan -X- _ O
School -X- _ O
of -X- _ O
Public -X- _ O
Health -X- _ O
, -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
feedback -X- _ O
and -X- _ O
participation -X- _ O
in -X- _ O
this -X- _ O
project -X- _ O
. -X- _ O
This -X- _ O
material -X- _ O
is -X- _ O
based -X- _ O
in -X- _ O
part -X- _ O
upon -X- _ O
work -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Precision -X- _ O
Health -X- _ O
initiative -X- _ O
at -X- _ O
the -X- _ O
University -X- _ O
of -X- _ O
Michigan -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
John -X- _ O
Templeton -X- _ O
Foundation -X- _ O
( -X- _ O
grant -X- _ O
# -X- _ O
61156 -X- _ O
) -X- _ O
. -X- _ O
Any -X- _ O
opinions -X- _ O
, -X- _ O
findings -X- _ O
, -X- _ O
and -X- _ O
conclusions -X- _ O
or -X- _ O
recommendations -X- _ O
expressed -X- _ O
in -X- _ O
this -X- _ O
material -X- _ O
are -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
necessarily -X- _ O
reflect -X- _ O
the -X- _ O
views -X- _ O
of -X- _ O
the -X- _ O
Precision -X- _ O
Health -X- _ O
initiative -X- _ O
or -X- _ O
the -X- _ O
John -X- _ O
Templeton -X- _ O
Foundation -X- _ O
. -X- _ O
References156157A -X- _ O
Additional -X- _ O
Information -X- _ O
of -X- _ O
Our -X- _ O
User -X- _ O
Study -X- _ O
A.1 -X- _ O
Obtaining -X- _ O
Consent -X- _ O
from -X- _ O
Participants -X- _ O
Before -X- _ O
they -X- _ O
could -X- _ O
access -X- _ O
the -X- _ O
assignments -X- _ O
, -X- _ O
participants -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
read -X- _ O
and -X- _ O
sign -X- _ O
an -X- _ O
informed -X- _ O
consent -X- _ O
form -X- _ O
, -X- _ O
which -X- _ O
informs -X- _ O
that -X- _ O
their -X- _ O
submissions -X- _ O
will -X- _ O
be -X- _ O
securely -X- _ O
stored -X- _ O
and -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
academic -X- _ O
research -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
some -X- _ O
participants -X- _ O
were -X- _ O
not -X- _ O
comfortable -X- _ O
doing -X- _ O
this -X- _ O
assignment -X- _ O
, -X- _ O
they -X- _ O
could -X- _ O
choose -X- _ O
from -X- _ O
alternatives -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
class -X- _ O
instructor -X- _ O
, -X- _ O
but -X- _ O
no -X- _ O
one -X- _ O
opted -X- _ O
to -X- _ O
do -X- _ O
so -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
. -X- _ O
A.2 -X- _ O
Data -X- _ O
Anonymization -X- _ O
and -X- _ O
Protection -X- _ O
To -X- _ O
ensure -X- _ O
that -X- _ O
user -X- _ O
data -X- _ O
is -X- _ O
securely -X- _ O
stored -X- _ O
without -X- _ O
compromising -X- _ O
privacy -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
ask -X- _ O
8 -X- _ O
- -X- _ O
digit -X- _ O
student -X- _ O
IDs -X- _ O
for -X- _ O
assignment -X- _ O
submission -X- _ O
, -X- _ O
which -X- _ O
then -X- _ O
are -X- _ O
mapped -X- _ O
to -X- _ O
unrelated -X- _ O
hash -X- _ O
strings -X- _ O
for -X- _ O
storage -X- _ O
in -X- _ O
a -X- _ O
secure -X- _ O
server -X- _ O
. -X- _ O
A.3 -X- _ O
Web -X- _ O
Interface158 -X- _ O

2022.acl-long.480.txt -X- _ O
Javier -X- _ O
Iranzo -X- _ O
- -X- _ O
Sánchez -X- _ O
and -X- _ O
Jorge -X- _ O
Civera -X- _ O
and -X- _ O
Alfons -X- _ O
Juan -X- _ O
Machine -X- _ O
Learning -X- _ O
and -X- _ O
Language -X- _ O
Processing -X- _ O
Group -X- _ O
Valencian -X- _ O
Research -X- _ O
Institute -X- _ O
for -X- _ O
Artiﬁcial -X- _ O
Intelligence -X- _ O
Universitat -X- _ O
Politècnica -X- _ O
de -X- _ O
València -X- _ O
Camí -X- _ O
de -X- _ O
Vera -X- _ O
s -X- _ O
/ -X- _ O
n -X- _ O
, -X- _ O
46022 -X- _ O
València -X- _ O
, -X- _ O
Spain -X- _ O
{ -X- _ O
jairsan -X- _ O
, -X- _ O
jorcisai -X- _ O
, -X- _ O
ajuanci -X- _ O
} -X- _ O
@ -X- _ O
vrain.upv.es -X- _ O
Abstract -X- _ O
Simultaneous -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
incrementally -X- _ O
translating -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
before -X- _ O
it -X- _ O
is -X- _ O
fully -X- _ O
available -X- _ O
. -X- _ O
Currently -X- _ O
, -X- _ O
simultaneous -X- _ B-TaskName
translation -X- _ I-TaskName
is -X- _ O
carried -X- _ O
out -X- _ O
by -X- _ O
translating -X- _ O
each -X- _ O
sentence -X- _ O
independently -X- _ O
of -X- _ O
the -X- _ O
previously -X- _ O
translated -X- _ O
text -X- _ O
. -X- _ O
More -X- _ O
generally -X- _ O
, -X- _ O
Streaming -X- _ B-TaskName
MT -X- _ I-TaskName
can -X- _ O
be -X- _ O
understood -X- _ O
as -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
Simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
to -X- _ O
the -X- _ O
incremental -X- _ O
translation -X- _ O
of -X- _ O
a -X- _ O
continuous -X- _ O
input -X- _ O
text -X- _ O
stream -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
simultaneous -X- _ O
sentencelevel -X- _ O
MT -X- _ B-TaskName
system -X- _ O
is -X- _ O
extended -X- _ O
to -X- _ O
the -X- _ O
streaming -X- _ O
setup -X- _ O
by -X- _ O
leveraging -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
. -X- _ O
Extensive -X- _ O
empirical -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
on -X- _ O
IWSLT -X- _ B-DatasetName
Translation -X- _ O
Tasks -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
leveraging -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
leads -X- _ O
to -X- _ O
signiﬁcant -X- _ O
quality -X- _ O
gains -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
system -X- _ O
proves -X- _ O
to -X- _ O
compare -X- _ O
favorably -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
systems -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Simultaneous -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
( -X- _ O
MT -X- _ B-TaskName
) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
incrementally -X- _ O
translating -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
before -X- _ O
it -X- _ O
is -X- _ O
fully -X- _ O
available -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
can -X- _ O
be -X- _ O
naturally -X- _ O
understood -X- _ O
in -X- _ O
the -X- _ O
scenario -X- _ O
of -X- _ O
translating -X- _ O
a -X- _ O
text -X- _ O
stream -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
an -X- _ O
upstream -X- _ O
Automatic -X- _ O
Speech -X- _ O
Recognition -X- _ O
( -X- _ O
ASR -X- _ O
) -X- _ O
process -X- _ O
. -X- _ O
This -X- _ O
setup -X- _ O
deﬁnes -X- _ O
a -X- _ O
simultaneous -X- _ O
Speech -X- _ O
Translation -X- _ O
( -X- _ O
ST -X- _ O
) -X- _ O
scenario -X- _ O
that -X- _ O
is -X- _ O
gaining -X- _ O
momentum -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
vast -X- _ O
number -X- _ O
of -X- _ O
industry -X- _ O
applications -X- _ O
that -X- _ O
could -X- _ O
be -X- _ O
exploited -X- _ O
based -X- _ O
on -X- _ O
this -X- _ O
technology -X- _ O
, -X- _ O
from -X- _ O
person -X- _ O
- -X- _ O
toperson -X- _ O
communication -X- _ O
to -X- _ O
subtitling -X- _ O
of -X- _ O
audiovisual -X- _ O
content -X- _ O
, -X- _ O
just -X- _ O
to -X- _ O
mention -X- _ O
two -X- _ O
main -X- _ O
applications -X- _ O
. -X- _ O
These -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
streaming -X- _ O
applications -X- _ O
motivate -X- _ O
us -X- _ O
to -X- _ O
move -X- _ O
from -X- _ O
simultaneous -X- _ O
to -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
, -X- _ O
understanding -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
as -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
simultaneously -X- _ O
translating -X- _ O
a -X- _ O
potentially -X- _ O
unbounded -X- _ O
and -X- _ O
unsegmented -X- _ O
text -X- _ O
stream -X- _ O
. -X- _ O
Streaming -X- _ B-TaskName
MT -X- _ I-TaskName
poses -X- _ O
two -X- _ O
main -X- _ O
additional -X- _ O
challenges -X- _ O
over -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
MT -X- _ B-TaskName
system -X- _ O
must -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
beyond -X- _ O
the -X- _ O
sentence -X- _ O
level -X- _ O
both -X- _ O
at -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
thesystem -X- _ O
must -X- _ O
work -X- _ O
under -X- _ O
latency -X- _ O
constraints -X- _ O
over -X- _ O
the -X- _ O
entire -X- _ O
stream -X- _ O
. -X- _ O
With -X- _ O
regard -X- _ O
to -X- _ O
exploiting -X- _ O
streaming -X- _ O
history -X- _ O
, -X- _ O
or -X- _ O
more -X- _ O
generally -X- _ O
sentence -X- _ O
context -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
mentioning -X- _ O
the -X- _ O
signiﬁcant -X- _ O
amount -X- _ O
of -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
ofﬂine -X- _ O
MT -X- _ B-TaskName
at -X- _ O
sentence -X- _ O
level -X- _ O
( -X- _ O
Tiedemann -X- _ O
and -X- _ O
Scherrer -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
document -X- _ O
level -X- _ O
( -X- _ O
Scherrer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Maruf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
related -X- _ O
areas -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
modelling -X- _ O
( -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
has -X- _ O
proved -X- _ O
to -X- _ O
lead -X- _ O
to -X- _ O
quality -X- _ O
gains -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
more -X- _ O
robust -X- _ O
ST -X- _ O
systems -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
by -X- _ O
taking -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
across -X- _ O
sentence -X- _ O
boundaries -X- _ O
using -X- _ O
a -X- _ O
data -X- _ O
augmentation -X- _ O
strategy -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
preﬁx -X- _ O
training -X- _ O
methods -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
Niehues -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
data -X- _ O
augmentation -X- _ O
strategy -X- _ O
was -X- _ O
suspected -X- _ O
to -X- _ O
boost -X- _ O
re -X- _ O
- -X- _ O
translation -X- _ O
performance -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
conventional -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
( -X- _ O
Arivazhagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
notable -X- _ O
exception -X- _ O
of -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
sentences -X- _ O
in -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
are -X- _ O
still -X- _ O
translated -X- _ O
independently -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
ignoring -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
. -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
model -X- _ O
with -X- _ O
a -X- _ O
Transformer -X- _ O
architecture -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
Adaptive -X- _ O
Computation -X- _ O
Time -X- _ O
method -X- _ O
with -X- _ O
a -X- _ O
monotonic -X- _ O
encoderdecoder -X- _ O
attention -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
successfully -X- _ O
uses -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
and -X- _ O
a -X- _ O
relative -X- _ O
attention -X- _ O
mechanism -X- _ O
inspired -X- _ O
by -X- _ O
Transformer -X- _ O
- -X- _ O
XL -X- _ O
( -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
an -X- _ O
MT -X- _ B-TaskName
model -X- _ O
that -X- _ O
sequentially -X- _ O
translates -X- _ O
the -X- _ O
input -X- _ O
stream -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
a -X- _ O
segmentation -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
interpret -X- _ O
the -X- _ O
latency -X- _ O
of -X- _ O
their -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
model -X- _ O
because -X- _ O
the -X- _ O
authors -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
current -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
latency -X- _ O
measures -X- _ O
, -X- _ O
Average -X- _ O
Proportion -X- _ O
( -X- _ O
AP -X- _ O
) -X- _ O
( -X- _ O
Cho -X- _ O
and -X- _ O
Esipova -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Average -X- _ O
Lagging -X- _ O
( -X- _ O
AL -X- _ O
) -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Differentiable -X- _ O
Average -X- _ O
Lagging -X- _ O
( -X- _ O
DAL -X- _ O
) -X- _ O
( -X- _ O
Cherry -X- _ O
and -X- _ O
Foster -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
perform6972well -X- _ O
on -X- _ O
a -X- _ O
streaming -X- _ O
setup -X- _ O
. -X- _ O
This -X- _ O
fact -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
second -X- _ O
challenge -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
system -X- _ O
must -X- _ O
work -X- _ O
under -X- _ O
latency -X- _ O
constraints -X- _ O
over -X- _ O
the -X- _ O
entire -X- _ O
stream -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
current -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
latency -X- _ O
measures -X- _ O
do -X- _ O
not -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
appropriately -X- _ O
gauge -X- _ O
the -X- _ O
latency -X- _ O
of -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
( -X- _ O
Iranzo -X- _ O
- -X- _ O
Sánchez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
recently -X- _ O
proposed -X- _ O
a -X- _ O
stream -X- _ O
- -X- _ O
level -X- _ O
adaptation -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
latency -X- _ O
measures -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
conventional -X- _ O
re -X- _ O
- -X- _ O
segmentation -X- _ O
approach -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
ST -X- _ O
output -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
translation -X- _ O
quality -X- _ O
( -X- _ O
Matusov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
the -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
model -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
unidirectional -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
and -X- _ O
training -X- _ O
along -X- _ O
multiple -X- _ O
wait- -X- _ O
kpaths -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Elbayad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
is -X- _ O
evolved -X- _ O
into -X- _ O
a -X- _ O
streamingready -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
model -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
this -X- _ O
, -X- _ O
model -X- _ O
training -X- _ O
is -X- _ O
performed -X- _ O
following -X- _ O
a -X- _ O
sentenceboundary -X- _ O
sliding -X- _ O
- -X- _ O
window -X- _ O
strategy -X- _ O
over -X- _ O
the -X- _ O
parallel -X- _ O
stream -X- _ O
that -X- _ O
exploits -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
preﬁx -X- _ O
training -X- _ O
, -X- _ O
while -X- _ O
inference -X- _ O
is -X- _ O
carried -X- _ O
out -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
forward -X- _ O
pass -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
stream -X- _ O
that -X- _ O
is -X- _ O
segmented -X- _ O
by -X- _ O
a -X- _ O
Direct -X- _ O
Segmentation -X- _ O
( -X- _ O
DS -X- _ O
) -X- _ O
model -X- _ O
( -X- _ O
Iranzo -X- _ O
- -X- _ O
Sánchez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
a -X- _ O
reﬁnement -X- _ O
of -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
that -X- _ O
takes -X- _ O
advantage -X- _ O
of -X- _ O
longer -X- _ O
context -X- _ O
for -X- _ O
encoding -X- _ O
the -X- _ O
initial -X- _ O
positions -X- _ O
of -X- _ O
the -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
process -X- _ O
is -X- _ O
proposed -X- _ O
. -X- _ O
This -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
is -X- _ O
thoroughly -X- _ O
assessed -X- _ O
on -X- _ O
IWSLT -X- _ B-DatasetName
translation -X- _ O
tasks -X- _ O
to -X- _ O
show -X- _ O
how -X- _ O
leveraging -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
provides -X- _ O
systematic -X- _ O
and -X- _ O
signiﬁcant -X- _ O
BLEU -X- _ B-MetricName
improvements -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
while -X- _ O
reported -X- _ O
stream -X- _ O
- -X- _ O
adapted -X- _ O
latency -X- _ O
measures -X- _ O
are -X- _ O
fully -X- _ O
consistent -X- _ O
and -X- _ O
interpretable -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
favourably -X- _ O
compares -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
translation -X- _ O
quality -X- _ O
and -X- _ O
latency -X- _ O
to -X- _ O
the -X- _ O
latest -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
( -X- _ O
Ansari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
is -X- _ O
organized -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
Next -X- _ O
section -X- _ O
provides -X- _ O
a -X- _ O
formal -X- _ O
framework -X- _ O
for -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
to -X- _ O
accommodate -X- _ O
streaming -X- _ O
history -X- _ O
in -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O
Section -X- _ O
3 -X- _ O
presents -X- _ O
the -X- _ O
streaming -X- _ O
experimental -X- _ O
setup -X- _ O
whose -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
and -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
conclusions -X- _ O
and -X- _ O
future -X- _ O
work -X- _ O
are -X- _ O
drawn -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
2 -X- _ O
Streaming -X- _ B-TaskName
MT -X- _ I-TaskName
In -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
, -X- _ O
the -X- _ O
source -X- _ O
stream -X- _ O
Xto -X- _ O
be -X- _ O
translated -X- _ O
intoYcomes -X- _ O
as -X- _ O
an -X- _ O
unsegmented -X- _ O
and -X- _ O
unbounded -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
decoding -X- _ O
process -X- _ O
usually -X- _ O
takes -X- _ O
the -X- _ O
greedy -X- _ O
decision -X- _ O
of -X- _ O
which -X- _ O
token -X- _ O
appears -X- _ O
next -X- _ O
at -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
ofthe -X- _ O
translation -X- _ O
being -X- _ O
generated -X- _ O
^Y -X- _ O
= -X- _ O
argmaxp -X- _ O
y -X- _ O
X -X- _ O
; -X- _ O
Y -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
whereG -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
global -X- _ O
delay -X- _ O
function -X- _ O
that -X- _ O
tells -X- _ O
us -X- _ O
the -X- _ O
last -X- _ O
position -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
stream -X- _ O
that -X- _ O
was -X- _ O
available -X- _ O
when -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
target -X- _ O
token -X- _ O
was -X- _ O
output -X- _ O
, -X- _ O
and -X- _ O
Yis -X- _ O
the -X- _ O
target -X- _ O
vocabulary -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
entire -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
streams -X- _ O
can -X- _ O
be -X- _ O
prohibitive -X- _ O
from -X- _ O
a -X- _ O
computational -X- _ O
viewpoint -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
can -X- _ O
be -X- _ O
conditioned -X- _ O
to -X- _ O
the -X- _ O
lastH -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
stream -X- _ O
as -X- _ O
^Y -X- _ O
= -X- _ O
argmaxp -X- _ O
y -X- _ O
X -X- _ O
; -X- _ O
Y -X- _ O
: -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Nevertheless -X- _ O
, -X- _ O
for -X- _ O
practical -X- _ O
purposes -X- _ O
, -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
sentence -X- _ O
segmentation -X- _ O
is -X- _ O
usually -X- _ O
introduced -X- _ O
to -X- _ O
explicitly -X- _ O
indicate -X- _ O
a -X- _ O
monotonic -X- _ O
alignment -X- _ O
between -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
in -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O
Let -X- _ O
us -X- _ O
consider -X- _ O
for -X- _ O
this -X- _ O
purpose -X- _ O
the -X- _ O
random -X- _ O
variables -X- _ O
aandbfor -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
segmentation -X- _ O
of -X- _ O
the -X- _ O
stream -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Variables -X- _ O
aandbcan -X- _ O
be -X- _ O
understood -X- _ O
as -X- _ O
two -X- _ O
vectors -X- _ O
of -X- _ O
equal -X- _ O
length -X- _ O
denoting -X- _ O
that -X- _ O
then -X- _ O
- -X- _ O
th -X- _ O
source -X- _ O
sentence -X- _ O
starts -X- _ O
at -X- _ O
position -X- _ O
a -X- _ O
, -X- _ O
while -X- _ O
then -X- _ O
- -X- _ O
th -X- _ O
target -X- _ O
sentence -X- _ O
does -X- _ O
so -X- _ O
at -X- _ O
position -X- _ O
b. -X- _ O
In -X- _ O
the -X- _ O
next -X- _ O
sections -X- _ O
, -X- _ O
we -X- _ O
reformulate -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
more -X- _ O
general -X- _ O
framework -X- _ O
of -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O
This -X- _ O
reformulation -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
consider -X- _ O
opportunities -X- _ O
for -X- _ O
improvement -X- _ O
of -X- _ O
previous -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
models -X- _ O
. -X- _ O
2.1 -X- _ O
Simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
with -X- _ O
streaming -X- _ O
history -X- _ O
In -X- _ O
the -X- _ O
conventional -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
setup -X- _ O
, -X- _ O
the -X- _ O
aforementioned -X- _ O
variables -X- _ O
aandbare -X- _ O
uncovered -X- _ O
at -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
streaming -X- _ O
MT -X- _ O
aandbare -X- _ O
considered -X- _ O
hidden -X- _ O
variables -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
that -X- _ O
may -X- _ O
be -X- _ O
uncovered -X- _ O
by -X- _ O
a -X- _ O
segmentation -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
in -X- _ O
conventional -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
the -X- _ O
history -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
sentence -X- _ O
being -X- _ O
translated -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
we -X- _ O
could -X- _ O
exploit -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
history -X- _ O
could -X- _ O
potentially -X- _ O
span -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
previous -X- _ O
tokens -X- _ O
before -X- _ O
the -X- _ O
current -X- _ O
sentence -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
the -X- _ O
global -X- _ O
delay -X- _ O
function -X- _ O
G -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
introduced -X- _ O
above -X- _ O
would -X- _ O
replace -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
delay -X- _ O
function -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
noticed -X- _ O
that -X- _ O
we -X- _ O
could -X- _ O
express -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
asG -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
awithbi -X- _ O
< -X- _ O
b. -X- _ O
Delay -X- _ O
functions -X- _ O
are -X- _ O
deﬁned -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
being -X- _ O
applied -X- _ O
. -X- _ O
This -X- _ O
policy -X- _ O
decides -X- _ O
what -X- _ O
action -X- _ O
to -X- _ O
take -X- _ O
at -X- _ O
each -X- _ O
timestep -X- _ O
, -X- _ O
whether -X- _ O
to -X- _ O
read6973a -X- _ O
token -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
or -X- _ O
to -X- _ O
write -X- _ O
a -X- _ O
target -X- _ O
token -X- _ O
. -X- _ O
Policies -X- _ O
can -X- _ O
be -X- _ O
either -X- _ O
ﬁxed -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Dalvi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
depending -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
timestep -X- _ O
, -X- _ O
or -X- _ O
adaptive -X- _ O
( -X- _ O
Arivazhagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
being -X- _ O
also -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
available -X- _ O
input -X- _ O
source -X- _ O
words -X- _ O
. -X- _ O
Among -X- _ O
those -X- _ O
ﬁxed -X- _ O
policies -X- _ O
, -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
wait -X- _ O
- -X- _ O
k -X- _ O
policy -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
with -X- _ O
the -X- _ O
simple -X- _ O
local -X- _ O
delay -X- _ O
function -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
k+i1 -X- _ O
: -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
This -X- _ O
policy -X- _ O
initially -X- _ O
reads -X- _ O
ksource -X- _ O
tokens -X- _ O
without -X- _ O
writing -X- _ O
a -X- _ O
target -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
outputs -X- _ O
a -X- _ O
target -X- _ O
token -X- _ O
every -X- _ O
time -X- _ O
a -X- _ O
source -X- _ O
token -X- _ O
is -X- _ O
read -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
true -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
the -X- _ O
ratio -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentence -X- _ O
lengths -X- _ O
is -X- _ O
one -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
general -X- _ O
case -X- _ O
, -X- _ O
a -X- _ O
catch -X- _ O
- -X- _ O
up -X- _ O
factor -X- _ O
computed -X- _ O
as -X- _ O
the -X- _ O
inverse -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
- -X- _ O
target -X- _ O
length -X- _ O
ratio -X- _ O
deﬁnes -X- _ O
how -X- _ O
many -X- _ O
target -X- _ O
tokens -X- _ O
are -X- _ O
written -X- _ O
for -X- _ O
every -X- _ O
read -X- _ O
token -X- _ O
, -X- _ O
that -X- _ O
generalises -X- _ O
Eq -X- _ O
. -X- _ O
3 -X- _ O
as -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
k+i1 -X- _ O
: -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
The -X- _ O
wait -X- _ O
- -X- _ O
kpolicy -X- _ O
can -X- _ O
be -X- _ O
reformulated -X- _ O
in -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
so -X- _ O
that -X- _ O
the -X- _ O
wait- -X- _ O
kbehaviour -X- _ O
is -X- _ O
carried -X- _ O
out -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
as -X- _ O
G -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
k+ib -X- _ O
+ -X- _ O
a1 -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
wherebi -X- _ O
< -X- _ O
b. -X- _ O
In -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
, -X- _ O
we -X- _ O
could -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
by -X- _ O
learning -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
stated -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
2 -X- _ O
, -X- _ O
whenever -X- _ O
streaming -X- _ O
samples -X- _ O
would -X- _ O
be -X- _ O
available -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
training -X- _ O
such -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
arbitrarily -X- _ O
long -X- _ O
streaming -X- _ O
samples -X- _ O
poses -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
challenges -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
addressed -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
necessary -X- _ O
to -X- _ O
carefully -X- _ O
deﬁne -X- _ O
G -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
and -X- _ O
H -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
functions -X- _ O
so -X- _ O
that -X- _ O
, -X- _ O
at -X- _ O
each -X- _ O
timestep -X- _ O
, -X- _ O
the -X- _ O
available -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
streams -X- _ O
are -X- _ O
perfectly -X- _ O
aligned -X- _ O
. -X- _ O
Given -X- _ O
that -X- _ O
the -X- _ O
source -X- _ O
- -X- _ O
target -X- _ O
length -X- _ O
ratio -X- _ O
may -X- _ O
vary -X- _ O
over -X- _ O
the -X- _ O
stream -X- _ O
, -X- _ O
if -X- _ O
one -X- _ O
uses -X- _ O
a -X- _ O
wait- -X- _ O
kpolicy -X- _ O
with -X- _ O
a -X- _ O
ﬁxed -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
signiﬁcant -X- _ O
chance -X- _ O
that -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
are -X- _ O
misaligned -X- _ O
at -X- _ O
some -X- _ O
points -X- _ O
over -X- _ O
the -X- _ O
stream -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
every -X- _ O
target -X- _ O
token -X- _ O
can -X- _ O
potentially -X- _ O
have -X- _ O
a -X- _ O
differentG -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
andH -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
representation -X- _ O
and -X- _ O
contribution -X- _ O
to -X- _ O
the -X- _ O
loss -X- _ O
would -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
recomputed -X- _ O
for -X- _ O
each -X- _ O
target -X- _ O
token -X- _ O
at -X- _ O
a -X- _ O
signiﬁcant -X- _ O
computational -X- _ O
expense -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
current -X- _ O
MT -X- _ B-TaskName
architectures -X- _ O
and -X- _ O
training -X- _ O
procedures -X- _ O
have -X- _ O
evolved -X- _ O
conditioned -X- _ O
by -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
sentence -X- _ O
- -X- _ O
levelparallel -X- _ O
corpora -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
so -X- _ O
they -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
parallel -X- _ O
streams -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
the -X- _ O
aforementioned -X- _ O
challenges -X- _ O
in -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
, -X- _ O
a -X- _ O
compromise -X- _ O
practical -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
uncover -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentence -X- _ O
segmentations -X- _ O
. -X- _ O
At -X- _ O
training -X- _ O
time -X- _ O
, -X- _ O
parallel -X- _ O
samples -X- _ O
are -X- _ O
extracted -X- _ O
by -X- _ O
a -X- _ O
sentence -X- _ O
- -X- _ O
boundary -X- _ O
sliding -X- _ O
window -X- _ O
spanning -X- _ O
over -X- _ O
several -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
stream -X- _ O
that -X- _ O
shifts -X- _ O
to -X- _ O
the -X- _ O
right -X- _ O
one -X- _ O
sentence -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
each -X- _ O
sentence -X- _ O
pair -X- _ O
is -X- _ O
concatenated -X- _ O
with -X- _ O
its -X- _ O
corresponding -X- _ O
streaming -X- _ O
history -X- _ O
that -X- _ O
includes -X- _ O
previous -X- _ O
sentence -X- _ O
pairs -X- _ O
simulating -X- _ O
long -X- _ O
- -X- _ O
span -X- _ O
preﬁx -X- _ O
training -X- _ O
. -X- _ O
Doing -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
ensure -X- _ O
that -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
streams -X- _ O
are -X- _ O
properly -X- _ O
aligned -X- _ O
at -X- _ O
all -X- _ O
times -X- _ O
, -X- _ O
and -X- _ O
training -X- _ O
can -X- _ O
be -X- _ O
efﬁciently -X- _ O
carried -X- _ O
out -X- _ O
by -X- _ O
considering -X- _ O
a -X- _ O
limited -X- _ O
history -X- _ O
. -X- _ O
The -X- _ O
inference -X- _ O
process -X- _ O
is -X- _ O
performed -X- _ O
in -X- _ O
a -X- _ O
purely -X- _ O
streaming -X- _ O
fashion -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
forward -X- _ O
pass -X- _ O
as -X- _ O
deﬁned -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
2 -X- _ O
with -X- _ O
H -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
being -X- _ O
consistently -X- _ O
deﬁned -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
training -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
spans -X- _ O
over -X- _ O
previous -X- _ O
sentences -X- _ O
already -X- _ O
translated -X- _ O
. -X- _ O
2.2 -X- _ O
Partial -X- _ O
Bidirectional -X- _ O
Encoder -X- _ O
In -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
, -X- _ O
the -X- _ O
conventional -X- _ O
Transformerbased -X- _ O
bidirectional -X- _ O
encoder -X- _ O
representation -X- _ O
( -X- _ O
of -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
) -X- _ O
of -X- _ O
a -X- _ O
source -X- _ O
token -X- _ O
at -X- _ O
any -X- _ O
position -X- _ O
jis -X- _ O
constrained -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
n -X- _ O
- -X- _ O
th -X- _ O
sentence -X- _ O
e -X- _ O
= -X- _ O
Enc -X- _ O
e -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
whereajG -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
decoder -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
previous -X- _ O
target -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
encoding -X- _ O
of -X- _ O
those -X- _ O
source -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
each -X- _ O
timestep -X- _ O
s -X- _ O
= -X- _ O
Dec -X- _ O
s -X- _ O
; -X- _ O
e -X- _ O
: -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
representations -X- _ O
for -X- _ O
positions -X- _ O
jandi -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
could -X- _ O
be -X- _ O
computed -X- _ O
taking -X- _ O
advantage -X- _ O
of -X- _ O
subsequent -X- _ O
positions -X- _ O
to -X- _ O
positionjup -X- _ O
to -X- _ O
position -X- _ O
G -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
, -X- _ O
this -X- _ O
means -X- _ O
that -X- _ O
this -X- _ O
bidirectional -X- _ O
encoding -X- _ O
- -X- _ O
decoding -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
has -X- _ O
to -X- _ O
be -X- _ O
computed -X- _ O
for -X- _ O
every -X- _ O
timestep -X- _ O
, -X- _ O
taking -X- _ O
up -X- _ O
to -X- _ O
jyjtimes -X- _ O
longer -X- _ O
than -X- _ O
the -X- _ O
conventional -X- _ O
Transformer -X- _ O
model -X- _ O
. -X- _ O
To -X- _ O
alleviate -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
( -X- _ O
Elbayad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
proposes -X- _ O
a -X- _ O
wait- -X- _ O
ksimultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
model -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
modiﬁcation -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ O
architecture -X- _ O
that -X- _ O
uses -X- _ O
unidirectional -X- _ O
encoders -X- _ O
and -X- _ O
multiple -X- _ O
values -X- _ O
of -X- _ O
kat -X- _ O
training -X- _ O
time -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the6974model -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
limited -X- _ O
- -X- _ O
input -X- _ O
restriction -X- _ O
of -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
unidirectional -X- _ O
encoder -X- _ O
can -X- _ O
be -X- _ O
stated -X- _ O
as -X- _ O
e -X- _ O
= -X- _ O
Enc -X- _ O
e -X- _ O
; -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
restrictive -X- _ O
than -X- _ O
that -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
6 -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
consequently -X- _ O
conditions -X- _ O
the -X- _ O
decoder -X- _ O
representation -X- _ O
, -X- _ O
sinceG -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
7 -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
speciﬁc -X- _ O
kvalue -X- _ O
employed -X- _ O
at -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
just -X- _ O
requires -X- _ O
a -X- _ O
single -X- _ O
forward -X- _ O
pass -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
additional -X- _ O
computational -X- _ O
cost -X- _ O
compared -X- _ O
with -X- _ O
a -X- _ O
conventional -X- _ O
Transformer -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
all -X- _ O
possible -X- _ O
input -X- _ O
tokens -X- _ O
for -X- _ O
different -X- _ O
values -X- _ O
ofk -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
the -X- _ O
encoding -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
input -X- _ O
token -X- _ O
will -X- _ O
not -X- _ O
consider -X- _ O
those -X- _ O
tokens -X- _ O
beyond -X- _ O
the -X- _ O
j -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
including -X- _ O
them -X- _ O
into -X- _ O
the -X- _ O
encoding -X- _ O
process -X- _ O
does -X- _ O
not -X- _ O
prevent -X- _ O
us -X- _ O
from -X- _ O
performing -X- _ O
a -X- _ O
single -X- _ O
forward -X- _ O
pass -X- _ O
. -X- _ O
A -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
the -X- _ O
unidirectional -X- _ O
and -X- _ O
bidirectional -X- _ O
encoders -X- _ O
is -X- _ O
what -X- _ O
we -X- _ O
have -X- _ O
dubbed -X- _ O
Partial -X- _ B-MethodName
Bidirectional -X- _ I-MethodName
Encoder -X- _ I-MethodName
( -X- _ O
PBE -X- _ B-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
modiﬁes -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
to -X- _ O
allow -X- _ O
the -X- _ O
ﬁrst -X- _ O
k1source -X- _ O
positions -X- _ O
to -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
succeeding -X- _ O
tokens -X- _ O
according -X- _ O
to -X- _ O
e -X- _ O
= -X- _ O
Enc -X- _ O
e -X- _ O
: -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
PBE -X- _ B-MethodName
allows -X- _ O
for -X- _ O
a -X- _ O
longer -X- _ O
context -X- _ O
when -X- _ O
encoding -X- _ O
the -X- _ O
initial -X- _ O
positions -X- _ O
and -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
Eq -X- _ O
. -X- _ O
7 -X- _ O
. -X- _ O
At -X- _ O
training -X- _ O
time -X- _ O
a -X- _ O
single -X- _ O
forward -X- _ O
pass -X- _ O
of -X- _ O
the -X- _ O
encoderdecoder -X- _ O
is -X- _ O
still -X- _ O
possible -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
no -X- _ O
additional -X- _ O
training -X- _ O
cost -X- _ O
is -X- _ O
incurred -X- _ O
. -X- _ O
At -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
fall -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
bidirectional -X- _ O
encoder -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
a -X- _ O
graphical -X- _ O
comparison -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
in -X- _ O
j= -X- _ O
3 -X- _ O
across -X- _ O
the -X- _ O
bidirectional -X- _ O
( -X- _ O
left -X- _ O
) -X- _ O
, -X- _ O
unidirectional -X- _ O
( -X- _ O
center -X- _ O
) -X- _ O
and -X- _ O
PBE -X- _ B-MethodName
( -X- _ O
right -X- _ O
) -X- _ O
encoders -X- _ O
with -X- _ O
k= -X- _ O
4 -X- _ O
for -X- _ O
two -X- _ O
consecutive -X- _ O
timestepsi= -X- _ O
1 -X- _ O
withG -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
4 -X- _ O
( -X- _ O
top -X- _ O
) -X- _ O
andi= -X- _ O
2 -X- _ O
withG -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
5 -X- _ O
( -X- _ O
bottom -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
observed -X- _ O
, -X- _ O
PBE -X- _ B-MethodName
can -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
additional -X- _ O
positions -X- _ O
from -X- _ O
j+ -X- _ O
1 -X- _ O
up -X- _ O
tokwith -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
streaming -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
bidirectional -X- _ O
encoderdecoder -X- _ O
of -X- _ O
Eqs -X- _ O
. -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
are -X- _ O
not -X- _ O
necessarily -X- _ O
constrained -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
sentence -X- _ O
and -X- _ O
could -X- _ O
exploit -X- _ O
a -X- _ O
streaming -X- _ O
history -X- _ O
of -X- _ O
H -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
tokens -X- _ O
e -X- _ O
= -X- _ O
Enc -X- _ O
e -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
s -X- _ O
= -X- _ O
Dec -X- _ O
s -X- _ O
; -X- _ O
e -X- _ O
: -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
Likewise -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
PBE -X- _ B-MethodName
with -X- _ O
streaming -X- _ O
history -X- _ O
states -X- _ O
as -X- _ O
follows -X- _ O
e -X- _ O
= -X- _ O
Enc -X- _ O
e -X- _ O
: -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
3 -X- _ O
Experimental -X- _ O
setup -X- _ O
A -X- _ O
series -X- _ O
of -X- _ O
comparative -X- _ O
experiments -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
translation -X- _ O
quality -X- _ O
and -X- _ O
latency -X- _ O
have -X- _ O
been -X- _ O
carried -X- _ O
out -X- _ O
using -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
IWSLT -X- _ B-DatasetName
2020 -X- _ I-DatasetName
Evaluation -X- _ I-DatasetName
Campaign -X- _ I-DatasetName
( -X- _ O
Ansari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
both -X- _ O
German -X- _ O
! -X- _ O
English -X- _ O
and -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
streaming -X- _ O
condition -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
is -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
2010 -X- _ O
dev -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
2010 -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
comparison -X- _ O
with -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Under -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
words -X- _ O
were -X- _ O
lowercased -X- _ O
and -X- _ O
punctuation -X- _ O
was -X- _ O
removed -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
simulate -X- _ O
a -X- _ O
basic -X- _ O
upstream -X- _ O
ASR -X- _ O
system -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
a -X- _ O
second -X- _ O
nonstreaming -X- _ O
setting -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
direction -X- _ O
to -X- _ O
compare -X- _ O
our -X- _ O
system -X- _ O
with -X- _ O
top -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theline -X- _ O
sentence -X- _ O
- -X- _ O
based -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
participating -X- _ O
in -X- _ O
the -X- _ O
IWSLT -X- _ B-DatasetName
2020 -X- _ I-DatasetName
Simultaneous -X- _ B-TaskName
Translation -X- _ I-TaskName
Task -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
summarizes -X- _ O
the -X- _ O
basic -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
IWSLT -X- _ B-DatasetName
corpora -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
the -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
. -X- _ O
Corpora -X- _ O
for -X- _ O
which -X- _ O
document -X- _ O
information -X- _ O
is -X- _ O
readily -X- _ O
available -X- _ O
are -X- _ O
processed -X- _ O
for -X- _ O
training -X- _ O
using -X- _ O
the -X- _ O
sliding -X- _ O
window -X- _ O
technique -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
training -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
prepend -X- _ O
previous -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
added -X- _ O
one -X- _ O
by -X- _ O
one -X- _ O
until -X- _ O
a -X- _ O
thresholdhof -X- _ O
history -X- _ O
tokens -X- _ O
is -X- _ O
reached -X- _ O
. -X- _ O
Sentence -X- _ O
boundaries -X- _ O
are -X- _ O
deﬁned -X- _ O
on -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
special -X- _ O
tokens -X- _ O
( -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
, -X- _ O
< -X- _ O
CONT -X- _ O
> -X- _ O
, -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
, -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
) -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Junczys -X- _ O
- -X- _ O
Dowmunt -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Byte -X- _ O
Pair -X- _ O
Encoding -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
with -X- _ O
40 -X- _ O
K -X- _ O
merge -X- _ O
operations -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
after -X- _ O
preprocessing -X- _ O
. -X- _ O
Our -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
is -X- _ O
evaluated -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
latency -X- _ O
and -X- _ O
translation -X- _ O
quality -X- _ O
with -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O
Traditionally -X- _ O
, -X- _ O
latency -X- _ O
evaluation -X- _ O
in -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
has -X- _ O
been -X- _ O
carried -X- _ O
out -X- _ O
using6975 -X- _ O
AP -X- _ O
, -X- _ O
AL -X- _ O
and -X- _ O
DAL -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
measures -X- _ O
have -X- _ O
been -X- _ O
devised -X- _ O
for -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
latency -X- _ O
of -X- _ O
every -X- _ O
sentence -X- _ O
is -X- _ O
computed -X- _ O
independently -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
as -X- _ O
mentioned -X- _ O
before -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ O
a -X- _ O
streaming -X- _ O
setup -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
revert -X- _ O
to -X- _ O
the -X- _ O
stream -X- _ O
- -X- _ O
based -X- _ O
adaptation -X- _ O
of -X- _ O
these -X- _ O
measures -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
Iranzo -X- _ O
- -X- _ O
Sánchez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
unless -X- _ O
stated -X- _ O
otherwise -X- _ O
. -X- _ O
Latency -X- _ O
measures -X- _ O
for -X- _ O
a -X- _ O
sentence -X- _ O
pair -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
cost -X- _ O
function -X- _ O
C -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
normalization -X- _ O
termZ -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
L -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
Z -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
XC -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O
where -X- _ O
C -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
8 -X- _ O
> -X- _ O
< -X- _ O
> -X- _ O
: -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
AP -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
AL -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
DAL -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O
and -X- _ O
Z -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
8 -X- _ O
> -X- _ O
< -X- _ O
> -X- _ O
: -X- _ O
jxjjyj -X- _ O
AP -X- _ O
argminiAL -X- _ O
jyj -X- _ O
DAL -X- _ O
( -X- _ O
15 -X- _ O
) -X- _ O
Latency -X- _ O
measures -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
in -X- _ O
a -X- _ O
streaming -X- _ O
manner -X- _ O
by -X- _ O
considering -X- _ O
a -X- _ O
global -X- _ O
delay -X- _ O
function -X- _ O
G -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
mapped -X- _ O
into -X- _ O
a -X- _ O
relative -X- _ O
delay -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
oracle -X- _ O
delay -X- _ O
. -X- _ O
For -X- _ O
thei -X- _ O
- -X- _ O
th -X- _ O
target -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
th -X- _ O
sentence -X- _ O
, -X- _ O
the -X- _ O
associated -X- _ O
relative -X- _ O
delay -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
global -X- _ O
delay -X- _ O
function -X- _ O
as -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
= -X- _ O
G -X- _ O
( -X- _ O
i+b -X- _ O
) -X- _ O
a -X- _ O
. -X- _ O
So -X- _ O
, -X- _ O
the -X- _ O
stream -X- _ O
- -X- _ O
adapted -X- _ O
cost -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
latencymeasures -X- _ O
is -X- _ O
deﬁned -X- _ O
as -X- _ O
C -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
8 -X- _ O
> -X- _ O
< -X- _ O
> -X- _ O
: -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
AP -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
AL -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
DAL -X- _ O
( -X- _ O
16 -X- _ O
) -X- _ O
withg -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
deﬁned -X- _ O
as -X- _ O
max8 -X- _ O
> -X- _ O
< -X- _ O
> -X- _ O
: -X- _ O
g -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
( -X- _ O
g -X- _ O
( -X- _ O
jxj -X- _ O
) -X- _ O
+ -X- _ O
i= -X- _ O
1 -X- _ O
g -X- _ O
( -X- _ O
i1 -X- _ O
) -X- _ O
+ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
( -X- _ O
17 -X- _ O
) -X- _ O
This -X- _ O
deﬁnition -X- _ O
assumes -X- _ O
that -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentence -X- _ O
segmentation -X- _ O
of -X- _ O
the -X- _ O
stream -X- _ O
are -X- _ O
uncovered -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
the -X- _ O
case -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
match -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
translations -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
sentence -X- _ O
boundaries -X- _ O
can -X- _ O
be -X- _ O
obtained -X- _ O
by -X- _ O
re -X- _ O
- -X- _ O
segmenting -X- _ O
the -X- _ O
system -X- _ O
hypothesis -X- _ O
following -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
procedure -X- _ O
applied -X- _ O
to -X- _ O
compute -X- _ O
translation -X- _ O
quality -X- _ O
in -X- _ O
ST -X- _ O
evaluation -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
MWER -X- _ O
segmenter -X- _ O
( -X- _ O
Matusov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
sentence -X- _ O
boundaries -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
translations -X- _ O
. -X- _ O
Our -X- _ O
streaming -X- _ O
MT -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
trained -X- _ O
following -X- _ O
the -X- _ O
conventional -X- _ O
Transformer -X- _ O
BASE -X- _ O
( -X- _ O
German -X- _ O
$ -X- _ O
English -X- _ O
streaming -X- _ O
MT -X- _ O
) -X- _ O
and -X- _ O
BIG -X- _ O
( -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
simultaneous -X- _ O
MT -X- _ O
) -X- _ O
conﬁgurations -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
in -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
after -X- _ O
training -X- _ O
is -X- _ O
ﬁnished -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
ﬁnetuned -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
MuSTC -X- _ O
( -X- _ O
Di -X- _ O
Gangi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
model -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
assumes -X- _ O
that -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
the -X- _ O
source -X- _ O
stream -X- _ O
has -X- _ O
been -X- _ O
segmented -X- _ O
into -X- _ O
sentences -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
we -X- _ O
opt -X- _ O
for -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
DS -X- _ O
model -X- _ O
( -X- _ O
Iranzo -X- _ O
- -X- _ O
Sánchez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
sliding -X- _ O
- -X- _ O
window -X- _ O
segmenter -X- _ O
that -X- _ O
moves -X- _ O
over -X- _ O
the -X- _ O
source -X- _ O
stream -X- _ O
taking -X- _ O
a -X- _ O
split -X- _ O
decision -X- _ O
at -X- _ O
each6976token -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
local -X- _ O
- -X- _ O
context -X- _ O
window -X- _ O
that -X- _ O
extends -X- _ O
to -X- _ O
both -X- _ O
past -X- _ O
and -X- _ O
future -X- _ O
tokens -X- _ O
. -X- _ O
This -X- _ O
segmenter -X- _ O
is -X- _ O
streaming -X- _ O
- -X- _ O
ready -X- _ O
and -X- _ O
obtains -X- _ O
superior -X- _ O
translation -X- _ O
quality -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
segmenters -X- _ O
( -X- _ O
Stolcke -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
future -X- _ O
window -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
DS -X- _ O
segmenter -X- _ O
conditions -X- _ O
the -X- _ O
latency -X- _ O
of -X- _ O
the -X- _ O
streaming -X- _ O
MT -X- _ B-TaskName
system -X- _ O
, -X- _ O
this -X- _ O
length -X- _ O
was -X- _ O
adjusted -X- _ O
to -X- _ O
ﬁnd -X- _ O
a -X- _ O
tradeoff -X- _ O
between -X- _ O
latency -X- _ O
and -X- _ O
translation -X- _ O
quality -X- _ O
. -X- _ O
The -X- _ O
DS -X- _ O
segmenter -X- _ O
was -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
TED -X- _ O
corpus -X- _ O
( -X- _ O
Cettolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
Evaluation -X- _ O
Figure -X- _ O
2 -X- _ O
reports -X- _ O
the -X- _ O
evolution -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
on -X- _ O
the -X- _ O
German -X- _ O
- -X- _ O
English -X- _ O
IWSLT -X- _ B-DatasetName
2010 -X- _ I-DatasetName
dev -X- _ O
set -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
thekvalue -X- _ O
in -X- _ O
the -X- _ O
wait- -X- _ O
kpolicy -X- _ O
for -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
streaming -X- _ O
history -X- _ O
lengths -X- _ O
( -X- _ O
h -X- _ O
= -X- _ O
f0 -X- _ O
; -X- _ O
20 -X- _ O
; -X- _ O
40 -X- _ O
; -X- _ O
60 -X- _ O
; -X- _ O
80 -X- _ O
g -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
3 -X- _ O
encoders -X- _ O
introduced -X- _ O
previously -X- _ O
. -X- _ O
History -X- _ O
lengths -X- _ O
were -X- _ O
selected -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
sentence -X- _ O
length -X- _ O
is -X- _ O
20 -X- _ O
tokens -X- _ O
. -X- _ O
A -X- _ O
history -X- _ O
length -X- _ O
of -X- _ O
zero -X- _ O
( -X- _ O
h= -X- _ O
0 -X- _ O
) -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
conventional -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
model -X- _ O
. -X- _ O
The -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
for -X- _ O
the -X- _ O
ofﬂine -X- _ O
MT -X- _ B-TaskName
systems -X- _ O
with -X- _ O
a -X- _ O
bidirectional -X- _ O
encoder -X- _ O
are -X- _ O
also -X- _ O
reported -X- _ O
using -X- _ O
horizontal -X- _ O
lines -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
serve -X- _ O
as -X- _ O
reference -X- _ O
values -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
ofﬂine -X- _ O
results -X- _ O
for -X- _ O
h= -X- _ O
0and -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
history -X- _ O
conﬁguration -X- _ O
, -X- _ O
h= -X- _ O
60 -X- _ O
. -X- _ O
All -X- _ O
systems -X- _ O
used -X- _ O
the -X- _ O
reference -X- _ O
segmentation -X- _ O
during -X- _ O
decoding -X- _ O
. -X- _ O
As -X- _ O
observed -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
of -X- _ O
the -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
leveraging -X- _ O
on -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
( -X- _ O
h -X- _ O
> -X- _ O
0 -X- _ O
) -X- _ O
are -X- _ O
systematically -X- _ O
and -X- _ O
notably -X- _ O
higher -X- _ O
than -X- _ O
those -X- _ O
of -X- _ O
conventional -X- _ O
sentence -X- _ O
- -X- _ O
based -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
( -X- _ O
h= -X- _ O
0 -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
wait- -X- _ O
kvalues -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
increases -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
also -X- _ O
do -X- _ O
reaching -X- _ O
what -X- _ O
it -X- _ O
seems -X- _ O
the -X- _ O
optimal -X- _ O
history -X- _ O
length -X- _ O
at -X- _ O
h= -X- _ O
60 -X- _ O
and -X- _ O
slightly -X- _ O
degrading -X- _ O
at -X- _ O
h= -X- _ O
80 -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
when -X- _ O
replacing -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
by -X- _ O
the -X- _ O
PBE -X- _ O
, -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
improve -X- _ O
as -X- _ O
the -X- _ O
wait -X- _ O
- -X- _ O
kvalue -X- _ O
increases -X- _ O
, -X- _ O
since -X- _ O
PBE -X- _ O
has -X- _ O
additional -X- _ O
access -X- _ O
to -X- _ O
those -X- _ O
tokens -X- _ O
from -X- _ O
j+ -X- _ O
1up -X- _ O
to -X- _ O
k. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
for -X- _ O
k= -X- _ O
32 -X- _ O
andh= -X- _ O
60 -X- _ O
, -X- _ O
PBE -X- _ O
is -X- _ O
0:7BLEU -X- _ B-MetricValue
points -X- _ O
above -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
how -X- _ O
using -X- _ O
an -X- _ O
encoder -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
fully -X- _ O
bidirectional -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
creates -X- _ O
a -X- _ O
performance -X- _ O
gap -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
ofﬂine -X- _ O
bidirectional -X- _ O
model -X- _ O
when -X- _ O
carrying -X- _ O
out -X- _ O
inference -X- _ O
in -X- _ O
an -X- _ O
ofﬂine -X- _ O
manner -X- _ O
( -X- _ O
k32 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
also -X- _ O
observed -X- _ O
how -X- _ O
the -X- _ O
PBE -X- _ O
model -X- _ O
is -X- _ O
better -X- _ O
prepared -X- _ O
for -X- _ O
this -X- _ O
scenario -X- _ O
and -X- _ O
shows -X- _ O
a -X- _ O
smaller -X- _ O
gap -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
keep -X- _ O
in -X- _ O
mind -X- _ O
that -X- _ O
although -X- _ O
both -X- _ O
ofﬂine -X- _ O
and -X- _ O
PBE -X- _ O
models -X- _ O
behave -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
during -X- _ O
inference -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
enough -X- _ O
k -X- _ O
, -X- _ O
during -X- _ O
training -X- _ O
time -X- _ O
the -X- _ O
PBE -X- _ O
model -X- _ O
, -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
multi- -X- _ O
kwith -X- _ O
krandomly -X- _ O
sampled -X- _ O
for -X- _ O
each -X- _ O
batch -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
optimized -X- _ O
jointly -X- _ O
for -X- _ O
low -X- _ O
, -X- _ O
medium -X- _ O
and -X- _ O
high -X- _ O
latencies -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
the -X- _ O
bidirectional -X- _ O
encoder -X- _ O
shows -X- _ O
poor -X- _ O
performance -X- _ O
for -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
. -X- _ O
This -X- _ O
can -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
the -X- _ O
training -X- _ O
condition -X- _ O
( -X- _ O
whole -X- _ O
source -X- _ O
available -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
inference -X- _ O
condition -X- _ O
( -X- _ O
only -X- _ O
a -X- _ O
preﬁx -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
is -X- _ O
available -X- _ O
for -X- _ O
k -X- _ O
< -X- _ O
32 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
( -X- _ O
Elbayad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Keep -X- _ O
in -X- _ O
mind -X- _ O
that -X- _ O
this -X- _ O
bidirectional -X- _ O
model -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
ofﬂine -X- _ O
one -X- _ O
because -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
subject -X- _ O
to -X- _ O
the -X- _ O
constraints -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
7 -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
reported -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
with -X- _ O
h= -X- _ O
60 -X- _ O
and -X- _ O
PBE -X- _ O
was -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
German -X- _ O
- -X- _ O
English -X- _ O
experiments -X- _ O
. -X- _ O
Following -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
’s -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
lowercased -X- _ O
and -X- _ O
concatenated -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
stream -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
latency -X- _ O
of -X- _ O
the -X- _ O
pipeline -X- _ O
deﬁned -X- _ O
by -X- _ O
the -X- _ O
segmenter -X- _ O
followed -X- _ O
by -X- _ O
MT -X- _ B-TaskName
system -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
not -X- _ O
only -X- _ O
the -X- _ O
latency -X- _ O
of -X- _ O
the -X- _ O
MT -X- _ B-TaskName
system -X- _ O
but -X- _ O
also -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
segmenter -X- _ O
. -X- _ O
Thankfully -X- _ O
this -X- _ O
is -X- _ O
straightforward -X- _ O
to -X- _ O
do -X- _ O
in -X- _ O
our -X- _ O
pipeline -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
segmenter -X- _ O
with -X- _ O
a6977 -X- _ O
future -X- _ O
window -X- _ O
of -X- _ O
length -X- _ O
wmodiﬁes -X- _ O
the -X- _ O
pipeline -X- _ O
policy -X- _ O
so -X- _ O
that -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
the -X- _ O
stream -X- _ O
, -X- _ O
wREAD -X- _ O
actions -X- _ O
are -X- _ O
carried -X- _ O
out -X- _ O
to -X- _ O
ﬁll -X- _ O
up -X- _ O
the -X- _ O
future -X- _ O
window -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
every -X- _ O
time -X- _ O
the -X- _ O
MT -X- _ B-TaskName
system -X- _ O
carries -X- _ O
out -X- _ O
a -X- _ O
READ -X- _ O
action -X- _ O
, -X- _ O
it -X- _ O
receives -X- _ O
one -X- _ O
token -X- _ O
from -X- _ O
the -X- _ O
segmenter -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
integration -X- _ O
of -X- _ O
the -X- _ O
segmenter -X- _ O
into -X- _ O
the -X- _ O
pipeline -X- _ O
is -X- _ O
transparent -X- _ O
from -X- _ O
a -X- _ O
latency -X- _ O
viewpoint -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
versus -X- _ O
streamadapted -X- _ O
AL -X- _ O
and -X- _ O
DAL -X- _ O
( -X- _ O
sscale -X- _ O
= -X- _ O
0.85 -X- _ O
) -X- _ O
ﬁgures -X- _ O
reported -X- _ O
with -X- _ O
segmenters -X- _ O
of -X- _ O
future -X- _ O
window -X- _ O
length -X- _ O
w -X- _ O
= -X- _ O
f0 -X- _ O
; -X- _ O
1 -X- _ O
; -X- _ O
2 -X- _ O
; -X- _ O
3 -X- _ O
; -X- _ O
4gfor -X- _ O
a -X- _ O
streaming -X- _ O
evaluation -X- _ O
on -X- _ O
the -X- _ O
IWSLT -X- _ B-DatasetName
2010 -X- _ I-DatasetName
test -X- _ O
set -X- _ O
. -X- _ O
Points -X- _ O
over -X- _ O
each -X- _ O
curve -X- _ O
correspond -X- _ O
to -X- _ O
k -X- _ O
= -X- _ O
f1 -X- _ O
; -X- _ O
2 -X- _ O
; -X- _ O
4 -X- _ O
; -X- _ O
8 -X- _ O
; -X- _ O
16gvalues -X- _ O
of -X- _ O
the -X- _ O
wait -X- _ O
- -X- _ O
kpolicy -X- _ O
used -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
Results -X- _ O
for -X- _ O
a -X- _ O
w= -X- _ O
0oracle -X- _ O
are -X- _ O
also -X- _ O
shown -X- _ O
as -X- _ O
an -X- _ O
upper -X- _ O
- -X- _ O
bound -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
, -X- _ O
stream -X- _ O
- -X- _ O
adapted -X- _ O
AL -X- _ O
and -X- _ O
DAL -X- _ O
ﬁgures -X- _ O
achieved -X- _ O
by -X- _ O
our -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
are -X- _ O
reasonable -X- _ O
, -X- _ O
lagging -X- _ O
2 -X- _ O
- -X- _ O
10 -X- _ O
tokens -X- _ O
behind -X- _ O
the -X- _ O
speaker -X- _ O
for -X- _ O
nearly -X- _ O
maximum -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
with -X- _ O
a -X- _ O
best -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
29.5 -X- _ B-MetricValue
points -X- _ O
. -X- _ O
The -X- _ O
same -X- _ O
happens -X- _ O
with -X- _ O
AP -X- _ O
ﬁgures -X- _ O
ranging -X- _ O
from -X- _ O
0.6 -X- _ O
for -X- _ O
w= -X- _ O
0to -X- _ O
1.3 -X- _ O
forw= -X- _ O
4 -X- _ O
. -X- _ O
These -X- _ O
ﬁgures -X- _ O
highlight -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
tying -X- _ O
together -X- _ O
our -X- _ O
translation -X- _ O
policy -X- _ O
with -X- _ O
the -X- _ O
sentence -X- _ O
segmentation -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
DS -X- _ O
model -X- _ O
. -X- _ O
Every -X- _ O
timethe -X- _ O
DS -X- _ O
model -X- _ O
emits -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
sentence -X- _ O
event -X- _ O
, -X- _ O
the -X- _ O
MT -X- _ B-TaskName
model -X- _ O
is -X- _ O
forced -X- _ O
to -X- _ O
catch -X- _ O
- -X- _ O
up -X- _ O
and -X- _ O
translate -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
MT -X- _ B-TaskName
model -X- _ O
never -X- _ O
strays -X- _ O
too -X- _ O
far -X- _ O
from -X- _ O
the -X- _ O
speaker -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
source -X- _ O
- -X- _ O
target -X- _ O
length -X- _ O
ratio -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
deﬁned -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
streaming -X- _ O
translation -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
reverse -X- _ O
direction -X- _ O
( -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
) -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
proposed -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
( -X- _ O
STR -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
) -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
= -X- _ O
0:3ACT -X- _ B-MethodName
system -X- _ O
( -X- _ O
Schneider -X- _ O
and -X- _ O
Waibel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
and -X- _ O
stream -X- _ O
- -X- _ O
adapted -X- _ O
latency -X- _ O
measures -X- _ O
on -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Stream -X- _ O
- -X- _ O
level -X- _ O
AL -X- _ O
and -X- _ O
DAL -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
ACT -X- _ O
models -X- _ O
lags -X- _ O
around -X- _ O
100 -X- _ O
tokens -X- _ O
behind -X- _ O
the -X- _ O
speaker -X- _ O
. -X- _ O
Although -X- _ O
both -X- _ O
MT -X- _ O
systems -X- _ O
achieve -X- _ O
similar -X- _ O
translation -X- _ O
quality -X- _ O
levels -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
so -X- _ O
at -X- _ O
signiﬁcantly -X- _ O
different -X- _ O
latencies -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
ACT -X- _ B-MethodName
model -X- _ O
Model -X- _ O
BLEU -X- _ B-MetricName
AP -X- _ O
AL -X- _ O
DAL -X- _ O
ACT -X- _ O
30.3 -X- _ O
10.3 -X- _ O
100.1 -X- _ O
101.8 -X- _ O
STR -X- _ O
- -X- _ O
MT -X- _ O
29.5 -X- _ O
1.2 -X- _ O
11.2 -X- _ O
17.86978lacks -X- _ O
a -X- _ O
catch -X- _ O
- -X- _ O
up -X- _ O
mechanism -X- _ O
to -X- _ O
synchronize -X- _ O
and -X- _ O
keep -X- _ O
the -X- _ O
pace -X- _ O
of -X- _ O
the -X- _ O
speaker -X- _ O
. -X- _ O
The -X- _ O
STR -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
model -X- _ O
is -X- _ O
now -X- _ O
compared -X- _ O
on -X- _ O
the -X- _ O
English -X- _ O
- -X- _ O
German -X- _ O
IWSLT -X- _ B-DatasetName
2020 -X- _ I-DatasetName
simultaneous -X- _ O
textto -X- _ O
- -X- _ O
text -X- _ O
track -X- _ O
( -X- _ O
Ansari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
other -X- _ O
participants -X- _ O
: -X- _ O
RWTH -X- _ B-MethodName
( -X- _ O
Bahar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
KIT -X- _ B-MethodName
( -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
ON -X- _ B-MethodName
- -X- _ I-MethodName
TRAC -X- _ I-MethodName
( -X- _ O
Elbayad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
comparison -X- _ O
is -X- _ O
carried -X- _ O
out -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
assess -X- _ O
whether -X- _ O
the -X- _ O
proposed -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
highly -X- _ O
optimized -X- _ O
systems -X- _ O
for -X- _ O
a -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
task -X- _ O
. -X- _ O
Given -X- _ O
that -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
this -X- _ O
track -X- _ O
remains -X- _ O
blind -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
results -X- _ O
reported -X- _ O
on -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
corpus -X- _ O
as -X- _ O
a -X- _ O
reference -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
evaluate -X- _ O
all -X- _ O
systems -X- _ O
under -X- _ O
the -X- _ O
same -X- _ O
conditions -X- _ O
, -X- _ O
the -X- _ O
reference -X- _ O
segmentation -X- _ O
of -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
corpus -X- _ O
is -X- _ O
used -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
DS -X- _ O
model -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
given -X- _ O
that -X- _ O
all -X- _ O
other -X- _ O
participants -X- _ O
translate -X- _ O
each -X- _ O
sentence -X- _ O
independently -X- _ O
, -X- _ O
the -X- _ O
conventional -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
AL -X- _ O
latency -X- _ O
measure -X- _ O
is -X- _ O
reported -X- _ O
. -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
versus -X- _ O
AL -X- _ O
measured -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
detokenized -X- _ O
tokens -X- _ O
. -X- _ O
As -X- _ O
deﬁned -X- _ O
in -X- _ O
the -X- _ O
IWSLT -X- _ B-DatasetName
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
track -X- _ O
, -X- _ O
three -X- _ O
AL -X- _ O
regimes -X- _ O
, -X- _ O
low -X- _ O
( -X- _ O
AL3 -X- _ O
) -X- _ O
, -X- _ O
medium -X- _ O
( -X- _ O
3 -X- _ O
< -X- _ O
AL6 -X- _ O
) -X- _ O
and -X- _ O
high -X- _ O
( -X- _ O
6 -X- _ O
< -X- _ O
AL15 -X- _ O
) -X- _ O
were -X- _ O
considered -X- _ O
. -X- _ O
ON -X- _ B-MethodName
- -X- _ I-MethodName
TRAC -X- _ I-MethodName
and -X- _ O
our -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
exhibit -X- _ O
a -X- _ O
similar -X- _ O
progression -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
expected -X- _ O
given -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
both -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
multi- -X- _ O
kapproach -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
consistently -X- _ O
outperforms -X- _ O
the -X- _ O
ON -X- _ B-MethodName
- -X- _ I-MethodName
TRAC -X- _ I-MethodName
system -X- _ O
by -X- _ O
1 -X- _ B-MetricValue
- -X- _ I-MetricValue
2 -X- _ I-MetricValue
BLEU -X- _ B-MetricName
. -X- _ O
This -X- _ O
conﬁrms -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
utilizing -X- _ O
streaming -X- _ O
history -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
signiﬁcantly -X- _ O
improve -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
how -X- _ O
the -X- _ O
proposed -X- _ O
PBE -X- _ O
model -X- _ O
can -X- _ O
take -X- _ O
better -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
history -X- _ O
. -X- _ O
RWTH -X- _ B-MethodName
and -X- _ O
KIT -X- _ B-MethodName
systems -X- _ O
are -X- _ O
closer -X- _ O
in -X- _ O
translation -X- _ O
quality -X- _ O
to -X- _ O
our -X- _ O
proposal -X- _ O
than -X- _ O
ON -X- _ B-MethodName
- -X- _ I-MethodName
TRAC -X- _ I-MethodName
, -X- _ O
for -X- _ O
AL -X- _ O
between -X- _ O
5 -X- _ O
and -X- _ O
7 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
systems -X- _ O
do -X- _ O
not -X- _ O
show -X- _ O
a -X- _ O
ﬂexible -X- _ O
latency -X- _ O
policy -X- _ O
and -X- _ O
are -X- _ O
not -X- _ O
comparable -X- _ O
to -X- _ O
our -X- _ O
system -X- _ O
at -X- _ O
other -X- _ O
regimes -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
for -X- _ O
that -X- _ O
to -X- _ O
be -X- _ O
possible -X- _ O
, -X- _ O
these -X- _ O
systems -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
re -X- _ O
- -X- _ O
trained -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
our -X- _ O
system -X- _ O
in -X- _ O
which -X- _ O
latency -X- _ O
is -X- _ O
adjusted -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
5 -X- _ O
Conclusions -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
a -X- _ O
formalization -X- _ O
of -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
as -X- _ O
a -X- _ O
generalization -X- _ O
of -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
has -X- _ O
been -X- _ O
proposed -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
deﬁne -X- _ O
a -X- _ O
theoretical -X- _ O
framework -X- _ O
in -X- _ O
which -X- _ O
our -X- _ O
two -X- _ O
contributions -X- _ O
have -X- _ O
been -X- _ O
made -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
successfully -X- _ O
leverage -X- _ O
streaming -X- _ O
history -X- _ O
across -X- _ O
sentence -X- _ O
boundaries -X- _ O
for -X- _ O
a -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
based -X- _ O
on -X- _ O
multiple -X- _ O
wait -X- _ O
- -X- _ O
k -X- _ O
paths -X- _ O
that -X- _ O
allows -X- _ O
our -X- _ O
system -X- _ O
to -X- _ O
greatly -X- _ O
improve -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
baseline -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
our -X- _ O
PBE -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
longer -X- _ O
context -X- _ O
information -X- _ O
than -X- _ O
its -X- _ O
unidirectional -X- _ O
counterpart -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
same -X- _ O
training -X- _ O
efﬁciency -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
MT -X- _ B-TaskName
system -X- _ O
has -X- _ O
been -X- _ O
evaluated -X- _ O
under -X- _ O
a -X- _ O
realistic -X- _ O
streaming -X- _ O
setting -X- _ O
being -X- _ O
able -X- _ O
to -X- _ O
reach -X- _ O
similar -X- _ O
translation -X- _ O
quality -X- _ O
than -X- _ O
a -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
segmentation -X- _ O
- -X- _ O
free -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
system -X- _ O
at -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
its -X- _ O
latency -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
competitive -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
simultaneous -X- _ B-TaskName
MT -X- _ I-TaskName
systems -X- _ O
optimized -X- _ O
for -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
translation -X- _ O
, -X- _ O
obtaining -X- _ O
excellent -X- _ O
results -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
latency -X- _ O
levels -X- _ O
, -X- _ O
thanks -X- _ O
to -X- _ O
its -X- _ O
ﬂexible -X- _ O
inference -X- _ O
policy -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
additional -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
procedures -X- _ O
that -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
streaming -X- _ O
history -X- _ O
in -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
are -X- _ O
still -X- _ O
open -X- _ O
for -X- _ O
research -X- _ O
. -X- _ O
One -X- _ O
important -X- _ O
avenue -X- _ O
of -X- _ O
improvement -X- _ O
is -X- _ O
to -X- _ O
devise -X- _ O
more -X- _ O
robust -X- _ O
training -X- _ O
methods -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
simultaneous -X- _ O
models -X- _ O
can -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
their -X- _ O
ofﬂine -X- _ O
counterparts -X- _ O
when -X- _ O
carrying -X- _ O
out -X- _ O
inference -X- _ O
at6979higher -X- _ O
latencies -X- _ O
. -X- _ O
The -X- _ O
segmentation -X- _ O
model -X- _ O
, -X- _ O
though -X- _ O
proved -X- _ O
useful -X- _ O
in -X- _ O
a -X- _ O
streaming -X- _ O
setup -X- _ O
, -X- _ O
adds -X- _ O
complexity -X- _ O
and -X- _ O
can -X- _ O
greatly -X- _ O
affect -X- _ O
translation -X- _ O
quality -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
segmentation -X- _ O
- -X- _ O
free -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
models -X- _ O
is -X- _ O
another -X- _ O
interesting -X- _ O
research -X- _ O
topic -X- _ O
. -X- _ O
Acknowledgements -X- _ O
The -X- _ O
research -X- _ O
leading -X- _ O
to -X- _ O
these -X- _ O
results -X- _ O
has -X- _ O
received -X- _ O
funding -X- _ O
from -X- _ O
the -X- _ O
European -X- _ O
Union -X- _ O
’s -X- _ O
Horizon -X- _ O
2020 -X- _ O
research -X- _ O
and -X- _ O
innovation -X- _ O
programme -X- _ O
under -X- _ O
grant -X- _ O
agreements -X- _ O
no -X- _ O
. -X- _ O
761758 -X- _ O
( -X- _ O
X5Gon -X- _ O
) -X- _ O
and -X- _ O
952215 -X- _ O
( -X- _ O
TAILOR -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Erasmus+ -X- _ O
Education -X- _ O
programme -X- _ O
under -X- _ O
grant -X- _ O
agreement -X- _ O
no -X- _ O
. -X- _ O
20226 -X- _ O
- -X- _ O
093604 -X- _ O
- -X- _ O
SCH -X- _ O
( -X- _ O
EXPERT -X- _ O
) -X- _ O
; -X- _ O
the -X- _ O
Government -X- _ O
of -X- _ O
Spain -X- _ O
’s -X- _ O
grant -X- _ O
RTI2018 -X- _ O
- -X- _ O
094879 -X- _ O
- -X- _ O
B -X- _ O
- -X- _ O
I00 -X- _ O
( -X- _ O
Multisub -X- _ O
) -X- _ O
funded -X- _ O
by -X- _ O
MCIN -X- _ O
/ -X- _ O
AEI -X- _ O
/ -X- _ O
10.13039 -X- _ O
/ -X- _ O
501100011033 -X- _ O
& -X- _ O
“ -X- _ O
ERDF -X- _ O
A -X- _ O
way -X- _ O
of -X- _ O
making -X- _ O
Europe -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
FPU -X- _ O
scholarships -X- _ O
FPU18 -X- _ O
/ -X- _ O
04135 -X- _ O
; -X- _ O
and -X- _ O
the -X- _ O
Generalitat -X- _ O
Valenciana -X- _ O
’s -X- _ O
research -X- _ O
project -X- _ O
Classroom -X- _ O
Activity -X- _ O
Recognition -X- _ O
( -X- _ O
ref -X- _ O
. -X- _ O
PROMETEO -X- _ O
/ -X- _ O
2019 -X- _ O
/ -X- _ O
111 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
gratefully -X- _ O
acknowledge -X- _ O
the -X- _ O
computer -X- _ O
resources -X- _ O
at -X- _ O
Artemisa -X- _ O
, -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
European -X- _ O
Union -X- _ O
ERDF -X- _ O
and -X- _ O
Comunitat -X- _ O
Valenciana -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
technical -X- _ O
support -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
Instituto -X- _ O
de -X- _ O
Física -X- _ O
Corpuscular -X- _ O
, -X- _ O
IFIC -X- _ O
( -X- _ O
CSIC -X- _ O
- -X- _ O
UV -X- _ O
) -X- _ O
. -X- _ O
References6980 -X- _ O
A -X- _ O
Extended -X- _ O
Streaming -X- _ O
Translation -X- _ O
Results -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
a -X- _ O
close -X- _ O
- -X- _ O
up -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
German -X- _ O
- -X- _ O
English -X- _ O
IWSLT -X- _ B-DatasetName
2010 -X- _ I-DatasetName
dev -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
how -X- _ O
the -X- _ O
PBE -X- _ B-MethodName
models -X- _ O
obtain -X- _ O
consistent -X- _ O
quality -X- _ O
improvements -X- _ O
over -X- _ O
their -X- _ O
unidirectional -X- _ O
counterparts -X- _ O
. -X- _ O
Apart -X- _ O
from -X- _ O
the -X- _ O
previously -X- _ O
reported -X- _ O
German -X- _ O
! -X- _ O
English -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
results -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
also -X- _ O
conducted -X- _ O
experiments -X- _ O
in -X- _ O
the -X- _ O
reverse -X- _ O
direction -X- _ O
, -X- _ O
English -X- _ O
! -X- _ O
German -X- _ O
. -X- _ O
These -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
to -X- _ O
previous -X- _ O
experiments -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
streaming -X- _ O
history -X- _ O
allowing -X- _ O
our -X- _ O
systems -X- _ O
to -X- _ O
obtain -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
based -X- _ O
baseline -X- _ O
. -X- _ O
Unlike -X- _ O
the -X- _ O
previous -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
optimum -X- _ O
history -X- _ O
size -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
ish= -X- _ O
40 -X- _ O
instead -X- _ O
ofh= -X- _ O
60 -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
enable -X- _ O
streaming -X- _ O
translation -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
h= -X- _ O
40 -X- _ O
systems -X- _ O
has -X- _ O
been -X- _ O
combined -X- _ O
with -X- _ O
a -X- _ O
German -X- _ O
DS -X- _ O
system -X- _ O
. -X- _ O
Similarly -X- _ O
to -X- _ O
previous -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
conducted -X- _ O
tests -X- _ O
using -X- _ O
different -X- _ O
values -X- _ O
of -X- _ O
wandkin -X- _ O
order -X- _ O
to -X- _ O
balance -X- _ O
the6981 -X- _ O
latency -X- _ O
- -X- _ O
quality -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
streaming -X- _ O
condition -X- _ O
, -X- _ O
the -X- _ O
wait- -X- _ O
kpolicy -X- _ O
and -X- _ O
DS -X- _ O
model -X- _ O
allow -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
follow -X- _ O
closely -X- _ O
the -X- _ O
speaker -X- _ O
while -X- _ O
achieving -X- _ O
good -X- _ O
quality -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
latency -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
adjusted -X- _ O
between -X- _ O
4 -X- _ O
and -X- _ O
15 -X- _ O
tokens -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
requirements -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
diminishing -X- _ O
returns -X- _ O
when -X- _ O
increasing -X- _ O
the -X- _ O
latency -X- _ O
above -X- _ O
6 -X- _ O
- -X- _ O
7 -X- _ O
tokens -X- _ O
, -X- _ O
as -X- _ O
only -X- _ O
marginal -X- _ O
gains -X- _ O
in -X- _ O
quality -X- _ O
are -X- _ O
obtained -X- _ O
. -X- _ O
B -X- _ O
Efﬁciency -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
models -X- _ O
During -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
unidirectional -X- _ O
and -X- _ O
PBE -X- _ B-MethodName
encoders -X- _ O
, -X- _ O
the -X- _ O
constraints -X- _ O
imposed -X- _ O
by -X- _ O
Eqs -X- _ O
. -X- _ O
8 -X- _ O
and -X- _ O
9 -X- _ O
are -X- _ O
efﬁciently -X- _ O
implemented -X- _ O
by -X- _ O
full -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
bidirectional -X- _ O
encoder -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
attention -X- _ O
mask -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
to -X- _ O
only -X- _ O
attend -X- _ O
those -X- _ O
tokens -X- _ O
fulﬁlling -X- _ O
the -X- _ O
constraints -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
mask -X- _ O
sets -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
tokens -X- _ O
to -X- _ O
1 -X- _ O
before -X- _ O
application -X- _ O
of -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
softmax -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
mechanism -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
standard -X- _ O
Transformer -X- _ O
decoder -X- _ O
to -X- _ O
prevent -X- _ O
the -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
decoder -X- _ O
from -X- _ O
accessing -X- _ O
future -X- _ O
information -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
three -X- _ O
encoder -X- _ O
types -X- _ O
have -X- _ O
an -X- _ O
identical -X- _ O
computational -X- _ O
behavior -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
not -X- _ O
aware -X- _ O
of -X- _ O
alternative -X- _ O
GPU -X- _ O
- -X- _ O
based -X- _ O
acceleration -X- _ O
techniques -X- _ O
to -X- _ O
speed -X- _ O
up -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
. -X- _ O
If -X- _ O
so -X- _ O
, -X- _ O
this -X- _ O
could -X- _ O
be -X- _ O
also -X- _ O
applicable -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
standard -X- _ O
Transformer -X- _ O
decoder -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
has -X- _ O
some -X- _ O
advantages -X- _ O
. -X- _ O
Given -X- _ O
that -X- _ O
the -X- _ O
unidirectional -X- _ O
encoder -X- _ O
is -X- _ O
incremental -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
the -X- _ O
encodings -X- _ O
of -X- _ O
old -X- _ O
tokens -X- _ O
do -X- _ O
not -X- _ O
change -X- _ O
when -X- _ O
a -X- _ O
new -X- _ O
token -X- _ O
becomes -X- _ O
available -X- _ O
, -X- _ O
the -X- _ O
process -X- _ O
can -X- _ O
be -X- _ O
sped -X- _ O
up -X- _ O
by -X- _ O
only -X- _ O
computing -X- _ O
the -X- _ O
encoding -X- _ O
of -X- _ O
the -X- _ O
newly -X- _ O
available -X- _ O
token -X- _ O
. -X- _ O
Although -X- _ O
encoder -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
still -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
computed -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
vector -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
query -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
full -X- _ O
matrix -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
inference -X- _ O
statistics -X- _ O
for -X- _ O
the -X- _ O
different -X- _ O
components -X- _ O
of -X- _ O
the -X- _ O
En -X- _ O
! -X- _ O
De -X- _ O
Transformer -X- _ O
Big -X- _ O
with -X- _ O
h=60 -X- _ O
. -X- _ O
Two -X- _ O
setups -X- _ O
have -X- _ O
been -X- _ O
tested -X- _ O
: -X- _ O
CPU -X- _ O
- -X- _ O
only -X- _ O
inference -X- _ O
, -X- _ O
and -X- _ O
GPU -X- _ O
inference -X- _ O
. -X- _ O
Results -X- _ O
were -X- _ O
obtained -X- _ O
on -X- _ O
an -X- _ O
Intel -X- _ O
i9 -X- _ O
- -X- _ O
7920X -X- _ O
machine -X- _ O
with -X- _ O
an -X- _ O
NVIDIA -X- _ O
GTX -X- _ O
2080Ti -X- _ O
. -X- _ O
The -X- _ O
unidirectional -X- _ O
encoder -X- _ O
is -X- _ O
four -X- _ O
times -X- _ O
faster -X- _ O
than -X- _ O
the -X- _ O
bidirectional -X- _ O
encoder -X- _ O
when -X- _ O
run -X- _ O
on -X- _ O
a -X- _ O
CPU -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
both -X- _ O
encoders -X- _ O
perform -X- _ O
the -X- _ O
same -X- _ O
when -X- _ O
run -X- _ O
on -X- _ O
a -X- _ O
GPU -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
scenario -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
no -X- _ O
latency -X- _ O
reduction -X- _ O
is -X- _ O
gained6982 -X- _ O
Component -X- _ O
CPU -X- _ O
GPU -X- _ O
Unidir -X- _ O
. -X- _ O
Encoder -X- _ O
0.034s -X- _ O
0.002s -X- _ O
Bidir -X- _ O
. -X- _ O
Encoder -X- _ O
0.138s -X- _ O
0.002s -X- _ O
Decoder -X- _ O
0.242s -X- _ O
0.004s -X- _ O
by -X- _ O
not -X- _ O
re -X- _ O
- -X- _ O
encoding -X- _ O
previous -X- _ O
tokens -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
GPU -X- _ O
paralellization -X- _ O
capability -X- _ O
. -X- _ O
When -X- _ O
run -X- _ O
on -X- _ O
a -X- _ O
GPU -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
works -X- _ O
seamlessly -X- _ O
under -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
constraints -X- _ O
. -X- _ O
C -X- _ O
MT -X- _ O
System -X- _ O
conﬁguration -X- _ O
The -X- _ O
multi -X- _ O
- -X- _ O
ksystems -X- _ O
have -X- _ O
been -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
ofﬁcial -X- _ O
implementation -X- _ O
( -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
elbayadm -X- _ O
/ -X- _ O
attn2d -X- _ O
) -X- _ O
. -X- _ O
Models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
0.5 -X- _ O
M -X- _ O
steps -X- _ O
on -X- _ O
a -X- _ O
machine -X- _ O
with -X- _ O
4 -X- _ O
2080Ti -X- _ O
GPUs -X- _ O
. -X- _ O
Total -X- _ O
training -X- _ O
time -X- _ O
was -X- _ O
40h -X- _ O
for -X- _ O
BASE -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
60h -X- _ O
for -X- _ O
BIG -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
command -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
them:6983 -X- _ O
with -X- _ O
ARCH -X- _ O
= -X- _ O
waitk_transformer_base -X- _ O
; -X- _ O
TOK=4000 -X- _ O
for -X- _ O
the -X- _ O
BASE -X- _ O
conﬁguration -X- _ O
, -X- _ O
and -X- _ O
ARCH -X- _ O
= -X- _ O
waitk_transformer_big -X- _ O
; -X- _ O
TOK=2000 -X- _ O
for -X- _ O
the -X- _ O
BIG -X- _ O
one -X- _ O
. -X- _ O
For -X- _ O
ﬁnetuning -X- _ O
, -X- _ O
we -X- _ O
change -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
-- -X- _ O
lr -X- _ O
- -X- _ O
scheduler -X- _ O
fixed -X- _ O
\ -X- _ O
-- -X- _ O
lr -X- _ O
4.47169e-05 -X- _ O
\ -X- _ O
For -X- _ O
the -X- _ O
streaming -X- _ O
translation -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
lowercased -X- _ O
and -X- _ O
all -X- _ O
punctuation -X- _ O
signs -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
simultaneous -X- _ O
scenario -X- _ O
( -X- _ O
IWSLT -X- _ B-DatasetName
2020 -X- _ I-DatasetName
simultaneous -X- _ O
text- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
truecased -X- _ O
and -X- _ O
tokenized -X- _ O
using -X- _ O
Moses -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
language -X- _ O
identiﬁcation -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
using -X- _ O
langid -X- _ O
( -X- _ O
Lui -X- _ O
and -X- _ O
Baldwin -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
and -X- _ O
discard -X- _ O
those -X- _ O
sentences -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
tagged -X- _ O
with -X- _ O
the -X- _ O
wrong -X- _ O
language -X- _ O
. -X- _ O
SentencePiece -X- _ O
( -X- _ O
Kudo -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
BPE -X- _ O
units -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
whitespace -X- _ O
as -X- _ O
a -X- _ O
sufﬁx -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
know -X- _ O
when -X- _ O
an -X- _ O
entire -X- _ O
target -X- _ O
word -X- _ O
has -X- _ O
been -X- _ O
written -X- _ O
during -X- _ O
decoding -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
samples -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
streaming -X- _ B-TaskName
MT -X- _ I-TaskName
models -X- _ O
, -X- _ O
a -X- _ O
sliding -X- _ O
window -X- _ O
that -X- _ O
moves -X- _ O
over -X- _ O
whole -X- _ O
sentences -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
extract -X- _ O
consistent -X- _ O
source -X- _ O
- -X- _ O
target -X- _ O
samples -X- _ O
. -X- _ O
Figure -X- _ O
8 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
corpus -X- _ O
construction -X- _ O
using -X- _ O
h= -X- _ O
5 -X- _ O
. -X- _ O
The -X- _ O
generated -X- _ O
streaming -X- _ O
data -X- _ O
is -X- _ O
upsampled -X- _ O
to -X- _ O
keep -X- _ O
a -X- _ O
1 -X- _ O
- -X- _ O
to-3 -X- _ O
ratio -X- _ O
with -X- _ O
the -X- _ O
regular -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
data -X- _ O
. -X- _ O
D -X- _ O
Segmenter -X- _ O
System -X- _ O
conﬁguration -X- _ O
The -X- _ O
Direct -X- _ O
Segmentation -X- _ O
system -X- _ O
has -X- _ O
been -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
ofﬁcial -X- _ O
implementation -X- _ O
( -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
jairsan -X- _ O
/ -X- _ O
Speech_Translation_Segmenter -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
command -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
segmenter -X- _ O
system -X- _ O
: -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
conﬁgurations -X- _ O
: -X- _ O
( -X- _ O
len=11 -X- _ O
; -X- _ O
window=0 -X- _ O
) -X- _ O
( -X- _ O
len=12 -X- _ O
; -X- _ O
window=1 -X- _ O
) -X- _ O
( -X- _ O
len=13 -X- _ O
; -X- _ O
window=2 -X- _ O
) -X- _ O
( -X- _ O
len=14 -X- _ O
, -X- _ O
window=3 -X- _ O
) -X- _ O
( -X- _ O
len=15 -X- _ O
, -X- _ O
window=4 -X- _ O
) -X- _ O
6984Sentece -X- _ O
pair -X- _ O
Source -X- _ O
Target -X- _ O
1 -X- _ O
xxyy -X- _ O
2 -X- _ O
xxxyy -X- _ O
3 -X- _ O
xxxyyy -X- _ O
4 -X- _ O
xxyy -X- _ O
Sentence -X- _ O
pair -X- _ O
Source -X- _ O
1 -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
xx -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
2 -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
xx -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
xxx -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
3 -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
xx -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
xxx -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
xxx -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
4 -X- _ O
< -X- _ O
CONT -X- _ O
> -X- _ O
xxx -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
xx -X- _ O
< -X- _ O
END -X- _ O
> -X- _ O
Sentence -X- _ O
pair -X- _ O
Target -X- _ O
1 -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
yy -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
2 -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
yy -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
yy -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
3 -X- _ O
< -X- _ O
DOC -X- _ O
> -X- _ O
yy -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
yy -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
yyy -X- _ O
< -X- _ O
BRK -X- _ O
> -X- _ O
4 -X- _ O
< -X- _ O
CONT -X- _ O
> -X- _ O
yyy -X- _ O
< -X- _ O
SEP -X- _ O
> -X- _ O
yy -X- _ O
< -X- _ O
END -X- _ O
> -X- _ O
6985 -X- _ O

