-DOCSTART- -X- O
Summary -X- _ SUMMARY
: -X- _ SUMMARY
AdapLeR -X- _ SUMMARY
is -X- _ SUMMARY
a -X- _ SUMMARY
novel -X- _ SUMMARY
method -X- _ SUMMARY
that -X- _ SUMMARY
reduces -X- _ SUMMARY
the -X- _ SUMMARY
computational -X- _ SUMMARY
cost -X- _ SUMMARY
of -X- _ SUMMARY
BERT -X- _ SUMMARY
models -X- _ SUMMARY
during -X- _ SUMMARY
inference -X- _ SUMMARY
while -X- _ SUMMARY
minimizing -X- _ SUMMARY
the -X- _ SUMMARY
loss -X- _ SUMMARY
in -X- _ SUMMARY
downstream -X- _ SUMMARY
performance -X- _ SUMMARY
. -X- _ SUMMARY
It -X- _ SUMMARY
dynamically -X- _ SUMMARY
eliminates -X- _ SUMMARY
less -X- _ SUMMARY
contributing -X- _ SUMMARY
tokens -X- _ SUMMARY
through -X- _ SUMMARY
layers -X- _ SUMMARY
to -X- _ SUMMARY
reduce -X- _ SUMMARY
the -X- _ SUMMARY
length -X- _ SUMMARY
and -X- _ SUMMARY
computational -X- _ SUMMARY
cost -X- _ SUMMARY
. -X- _ SUMMARY
A -X- _ SUMMARY
Contribution -X- _ SUMMARY
Predictor -X- _ SUMMARY
( -X- _ SUMMARY
CP -X- _ SUMMARY
) -X- _ SUMMARY
is -X- _ SUMMARY
trained -X- _ SUMMARY
for -X- _ SUMMARY
each -X- _ SUMMARY
layer -X- _ SUMMARY
to -X- _ SUMMARY
estimate -X- _ SUMMARY
token -X- _ SUMMARY
contribution -X- _ SUMMARY
using -X- _ SUMMARY
saliency -X- _ SUMMARY
scores -X- _ SUMMARY
. -X- _ SUMMARY
Experiments -X- _ SUMMARY
on -X- _ SUMMARY
diverse -X- _ SUMMARY
classification -X- _ SUMMARY
tasks -X- _ SUMMARY
show -X- _ SUMMARY
speedups -X- _ SUMMARY
of -X- _ SUMMARY
up -X- _ SUMMARY
to -X- _ SUMMARY
22x -X- _ SUMMARY
during -X- _ SUMMARY
inference -X- _ SUMMARY
without -X- _ SUMMARY
sacrificing -X- _ SUMMARY
performance -X- _ SUMMARY
. -X- _ SUMMARY
AdapLeR -X- _ SUMMARY
also -X- _ SUMMARY
outperforms -X- _ SUMMARY
other -X- _ SUMMARY
strategies -X- _ SUMMARY
for -X- _ SUMMARY
selecting -X- _ SUMMARY
important -X- _ SUMMARY
tokens -X- _ SUMMARY
, -X- _ SUMMARY
such -X- _ SUMMARY
as -X- _ SUMMARY
saliency -X- _ SUMMARY
and -X- _ SUMMARY
attention -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
method -X- _ SUMMARY
is -X- _ SUMMARY
evaluated -X- _ SUMMARY
on -X- _ SUMMARY
multiple -X- _ SUMMARY
datasets -X- _ SUMMARY
, -X- _ SUMMARY
including -X- _ SUMMARY
SST-2 -X- _ SUMMARY
, -X- _ SUMMARY
IMDB -X- _ SUMMARY
, -X- _ SUMMARY
MRPC -X- _ SUMMARY
, -X- _ SUMMARY
AG -X- _ SUMMARY
’s -X- _ SUMMARY
News -X- _ SUMMARY
, -X- _ SUMMARY
DBpedia -X- _ SUMMARY
, -X- _ SUMMARY
MNLI -X- _ SUMMARY
, -X- _ SUMMARY
QNLI -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
HateXplain -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
achieves -X- _ SUMMARY
significant -X- _ SUMMARY
improvements -X- _ SUMMARY
in -X- _ SUMMARY
both -X- _ SUMMARY
speed -X- _ SUMMARY
and -X- _ SUMMARY
accuracy -X- _ SUMMARY
. -X- _ SUMMARY
AdapLeR -X- _ SUMMARY
provides -X- _ SUMMARY
a -X- _ SUMMARY
more -X- _ SUMMARY
efficient -X- _ SUMMARY
approach -X- _ SUMMARY
for -X- _ SUMMARY
BERT -X- _ SUMMARY
models -X- _ SUMMARY
, -X- _ SUMMARY
making -X- _ SUMMARY
them -X- _ SUMMARY
more -X- _ SUMMARY
viable -X- _ SUMMARY
in -X- _ SUMMARY
resource -X- _ SUMMARY
- -X- _ SUMMARY
limited -X- _ SUMMARY
settings -X- _ SUMMARY
. -X- _ SUMMARY
Code -X- _ SUMMARY
for -X- _ SUMMARY
AdapLeR -X- _ SUMMARY
is -X- _ SUMMARY
available -X- _ SUMMARY
on -X- _ SUMMARY
GitHub -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.1.txt -X- _ O
Ali -X- _ O
ModarressiHosein -X- _ O
MohebbiMohammad -X- _ O
Taher -X- _ O
PilehvarIran -X- _ O
University -X- _ O
of -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
, -X- _ O
IranCognitive -X- _ O
Science -X- _ O
and -X- _ O
AI -X- _ O
, -X- _ O
Tilburg -X- _ O
University -X- _ O
, -X- _ O
NetherlandsTehran -X- _ O
Institute -X- _ O
for -X- _ O
Advanced -X- _ O
Studies -X- _ O
, -X- _ O
Khatam -X- _ O
University -X- _ O
, -X- _ O
Iran -X- _ O
m_modarressi -X- _ O
@ -X- _ O
comp.iust.ac.ir -X- _ O
h.mohebbi -X- _ O
@ -X- _ O
uvt.nl -X- _ O
mp792 -X- _ O
@ -X- _ O
cam.ac.uk -X- _ O
Abstract -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
shown -X- _ O
stel- -X- _ O
lar -X- _ O
performance -X- _ O
in -X- _ O
various -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
But -X- _ O
, -X- _ O
this -X- _ O
usually -X- _ O
comes -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
high -X- _ O
latency -X- _ O
and -X- _ O
computation -X- _ O
, -X- _ O
hindering -X- _ O
their -X- _ O
us- -X- _ O
age -X- _ O
in -X- _ O
resource -X- _ O
- -X- _ O
limited -X- _ O
settings -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
approach -X- _ O
for -X- _ O
reducing -X- _ O
the -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
minimal -X- _ O
loss -X- _ O
in -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
dy- -X- _ O
namically -X- _ O
eliminates -X- _ O
less -X- _ O
contributing -X- _ O
tokens -X- _ O
through -X- _ O
layers -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
shorter -X- _ O
lengths -X- _ O
and -X- _ O
consequently -X- _ O
lower -X- _ O
computational -X- _ O
cost -X- _ O
. -X- _ O
To -X- _ O
determine -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
rep- -X- _ O
resentation -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
for -X- _ O
each -X- _ O
layer -X- _ O
using -X- _ O
a -X- _ O
gradient -X- _ O
- -X- _ O
based -X- _ O
saliency -X- _ O
method -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
on -X- _ O
several -X- _ O
diverse -X- _ O
classification -X- _ O
tasks -X- _ O
show -X- _ O
speedups -X- _ O
up -X- _ O
to -X- _ O
22x -X- _ O
during -X- _ O
inference -X- _ O
time -X- _ O
without -X- _ O
much -X- _ O
sacrifice -X- _ O
in -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
validate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
tokens -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
using -X- _ O
hu- -X- _ O
man -X- _ O
annotations -X- _ O
in -X- _ O
the -X- _ O
ERASER -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
to -X- _ O
other -X- _ O
widely -X- _ O
used -X- _ O
strategies -X- _ O
for -X- _ O
selecting -X- _ O
important -X- _ O
tokens -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
saliency -X- _ O
andattention -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
has -X- _ O
a -X- _ O
sig- -X- _ O
nificantly -X- _ O
lower -X- _ O
false -X- _ O
positive -X- _ O
rate -X- _ O
in -X- _ O
generat- -X- _ O
ing -X- _ O
rationales -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
freely -X- _ O
available -X- _ O
athttps -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
amodaresi -X- _ O
/ -X- _ O
AdapLeR -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
While -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
ex- -X- _ O
hibit -X- _ O
remarkable -X- _ O
performances -X- _ O
on -X- _ O
various -X- _ O
NLP -X- _ O
benchmarks -X- _ O
, -X- _ O
their -X- _ O
excessive -X- _ O
computational -X- _ O
costs -X- _ O
and -X- _ O
high -X- _ O
inference -X- _ O
latency -X- _ O
have -X- _ O
limited -X- _ O
their -X- _ O
us- -X- _ O
age -X- _ O
in -X- _ O
resource -X- _ O
- -X- _ O
limited -X- _ O
settings -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
regard -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
various -X- _ O
attempts -X- _ O
at -X- _ O
improving -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
knowledge -X- _ O
distilation -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
quantization -X- _ O
( -X- _ O
Gong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Tambe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
weightpruning -X- _ O
( -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Michel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
progressive -X- _ O
module -X- _ O
replacing -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
pro- -X- _ O
viding -X- _ O
significant -X- _ O
reduction -X- _ O
in -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
these -X- _ O
techniques -X- _ O
are -X- _ O
generally -X- _ O
static -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
they -X- _ O
dedicate -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
computation -X- _ O
to -X- _ O
all -X- _ O
inputs -X- _ O
, -X- _ O
irrespective -X- _ O
of -X- _ O
their -X- _ O
difficulty -X- _ O
. -X- _ O
A -X- _ O
number -X- _ O
of -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
also -X- _ O
proposed -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
efficiency -X- _ O
enhancement -X- _ O
sensitive -X- _ O
to -X- _ O
inputs -X- _ O
. -X- _ O
Early -X- _ O
exit -X- _ O
mechanism -X- _ O
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Liao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Eyza- -X- _ O
guirre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
commonly -X- _ O
used -X- _ O
method -X- _ O
in -X- _ O
which -X- _ O
each -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
coupled -X- _ O
with -X- _ O
an -X- _ O
intermediate -X- _ O
classifier -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
la- -X- _ O
bel -X- _ O
. -X- _ O
At -X- _ O
inference -X- _ O
, -X- _ O
a -X- _ O
halting -X- _ O
condition -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
model -X- _ O
allows -X- _ O
an -X- _ O
example -X- _ O
to -X- _ O
exit -X- _ O
without -X- _ O
passing -X- _ O
through -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
Vari- -X- _ O
ous -X- _ O
halting -X- _ O
conditions -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
includ- -X- _ O
ing -X- _ O
Shannon -X- _ O
’s -X- _ O
entropy -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
softmax -X- _ O
outputs -X- _ O
with -X- _ O
temperature -X- _ O
calibra- -X- _ O
tion -X- _ O
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
confidence -X- _ O
predictors -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
agree- -X- _ O
ments -X- _ O
between -X- _ O
predictions -X- _ O
of -X- _ O
intermediate -X- _ O
classi- -X- _ O
fiers -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
these -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
techniques -X- _ O
com- -X- _ O
press -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
depth -X- _ O
perspective -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
involved -X- _ O
encoder -X- _ O
layers -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
view -X- _ O
compression -X- _ O
from -X- _ O
the -X- _ O
width -X- _ O
perspective -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
reducing -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
hidden -X- _ O
states -X- _ O
. -X- _ O
( -X- _ O
Ethayarajh -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Klafka -X- _ O
and -X- _ O
Ettinger -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
particularly -X- _ O
promising -X- _ O
as -X- _ O
recent -X- _ O
analytical -X- _ O
studies -X- _ O
showed -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
redundant -X- _ O
encoded -X- _ O
information -X- _ O
in -X- _ O
token -X- _ O
representations -X- _ O
( -X- _ O
Klafka -X- _ O
and -X- _ O
Ettinger -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ethayarajh -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Among -X- _ O
these -X- _ O
redundancies -X- _ O
, -X- _ O
some -X- _ O
tokens -X- _ O
carry -X- _ O
more -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
than -X- _ O
others -X- _ O
( -X- _ O
Mohebbi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
only -X- _ O
these -X- _ O
tokens -X- _ O
could -X- _ O
be -X- _ O
con- -X- _ O
sidered -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
pruning -X- _ O
, -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
pruning -X- _ O
does -X- _ O
not1come -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
reducing -X- _ O
model -X- _ O
’s -X- _ O
capacity -X- _ O
in -X- _ O
complex -X- _ O
reasoning -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
such -X- _ O
techniques -X- _ O
which -X- _ O
reduces -X- _ O
inference -X- _ O
time -X- _ O
by -X- _ O
eliminating -X- _ O
redundant -X- _ O
token -X- _ O
representa- -X- _ O
tions -X- _ O
through -X- _ O
layers -X- _ O
based -X- _ O
on -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O
Several -X- _ O
studies -X- _ O
have -X- _ O
followed -X- _ O
( -X- _ O
Kim -X- _ O
and -X- _ O
Cho -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
usually -X- _ O
optimize -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
elimination -X- _ O
configuration -X- _ O
across -X- _ O
the -X- _ O
entire -X- _ O
dataset -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
static -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
addi- -X- _ O
tion -X- _ O
, -X- _ O
their -X- _ O
token -X- _ O
selection -X- _ O
strategies -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
attention -X- _ O
weights -X- _ O
which -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
suboptimal -X- _ O
solution -X- _ O
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
Adap -X- _ B-MethodName
tiveLength -X- _ I-MethodName
Reduction -X- _ I-MethodName
( -X- _ O
AdapLeR -X- _ B-MethodName
) -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
relying -X- _ O
on -X- _ O
at- -X- _ O
tention -X- _ O
weights -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
trains -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
Contri- -X- _ B-MethodName
bution -X- _ I-MethodName
Predictors -X- _ I-MethodName
( -X- _ O
CP -X- _ O
) -X- _ O
to -X- _ O
estimate -X- _ O
tokens -X- _ O
’ -X- _ O
saliency -X- _ O
scores -X- _ O
at -X- _ O
inference -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
choice -X- _ O
re- -X- _ O
sults -X- _ O
in -X- _ O
more -X- _ O
reliable -X- _ O
scores -X- _ O
than -X- _ O
attention -X- _ O
weights -X- _ O
in -X- _ O
measuring -X- _ O
tokens -X- _ O
’ -X- _ O
contributions -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
re- -X- _ O
lated -X- _ O
study -X- _ O
to -X- _ O
ours -X- _ O
is -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
which -X- _ O
leverages -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
develop -X- _ O
an -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
token -X- _ O
selection -X- _ O
policy -X- _ O
network -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
pointed -X- _ O
out -X- _ O
by -X- _ O
the -X- _ O
authors -X- _ O
, -X- _ O
the -X- _ O
prob- -X- _ O
lem -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
for -X- _ O
RL -X- _ O
to -X- _ O
solve -X- _ O
. -X- _ O
To -X- _ O
mitigate -X- _ O
this -X- _ O
, -X- _ O
they -X- _ O
resorted -X- _ O
to -X- _ O
extra -X- _ O
heuristics -X- _ O
such -X- _ O
as -X- _ O
imitation -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
Hussein -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
for -X- _ O
warming -X- _ O
up -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
net- -X- _ O
work -X- _ O
, -X- _ O
action -X- _ O
sampling -X- _ O
for -X- _ O
limiting -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
and -X- _ O
knowledge -X- _ B-TaskName
distillation -X- _ I-TaskName
for -X- _ O
transferring -X- _ O
knowl- -X- _ O
edge -X- _ O
from -X- _ O
the -X- _ O
intact -X- _ O
backbone -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
these -X- _ O
steps -X- _ O
significantly -X- _ O
increase -X- _ O
the -X- _ O
train- -X- _ O
ing -X- _ O
cost -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
they -X- _ O
only -X- _ O
perform -X- _ O
token -X- _ O
selection -X- _ O
at -X- _ O
two -X- _ O
layers -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
but -X- _ O
effective -X- _ O
method -X- _ O
to -X- _ O
gradually -X- _ O
eliminate -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
throughout -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
using -X- _ O
a -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
which -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
adaptable -X- _ O
to -X- _ O
various -X- _ O
inputs -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
- -X- _ O
wise -X- _ O
mode -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
worth -X- _ O
noting -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
our -X- _ O
ap- -X- _ O
proach -X- _ O
above -X- _ O
studies -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
operations -X- _ O
for -X- _ O
identifying -X- _ O
the -X- _ O
k -X- _ O
most -X- _ O
important -X- _ O
tokens -X- _ O
during -X- _ O
training -X- _ O
or -X- _ O
inference -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
expensive -X- _ O
with- -X- _ O
out -X- _ O
a -X- _ O
specific -X- _ O
hardware -X- _ O
architecture -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
threefold -X- _ O
: -X- _ O
•We -X- _ O
couple -X- _ O
a -X- _ O
simple -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
( -X- _ O
CP -X- _ O
) -X- _ O
with -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
estimate -X- _ O
tokens -X- _ O
’ -X- _ O
contribution -X- _ O
scores -X- _ O
to -X- _ O
eliminate -X- _ O
redun- -X- _ O
dant -X- _ O
representations -X- _ O
. -X- _ O
•Instead -X- _ O
of -X- _ O
an -X- _ O
instant -X- _ O
token -X- _ O
removal -X- _ O
, -X- _ O
we -X- _ O
grad- -X- _ O
ually -X- _ O
mask -X- _ O
out -X- _ O
less -X- _ O
contributing -X- _ O
token -X- _ O
repre -X- _ O
- -X- _ O
sentations -X- _ O
by -X- _ O
employing -X- _ O
a -X- _ O
novel -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
. -X- _ O
•We -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
token -X- _ O
selection -X- _ O
strategy -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
widely -X- _ O
used -X- _ O
strategies -X- _ O
by -X- _ O
using -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
2 -X- _ O
Background -X- _ O
2.1 -X- _ O
Self -X- _ O
- -X- _ O
attention -X- _ O
Weights -X- _ O
Self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
a -X- _ O
core -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
Trans- -X- _ O
formers -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
which -X- _ O
looks -X- _ O
for -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
different -X- _ O
positions -X- _ O
of -X- _ O
a -X- _ O
sin- -X- _ O
gle -X- _ O
sequence -X- _ O
of -X- _ O
token -X- _ O
representations -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
to -X- _ O
build -X- _ O
contextualized -X- _ O
representations -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
each -X- _ O
input -X- _ O
vector -X- _ O
xis -X- _ O
multiplied -X- _ O
by -X- _ O
the -X- _ O
corre- -X- _ O
sponding -X- _ O
trainable -X- _ O
matrices -X- _ O
Q -X- _ O
, -X- _ O
K -X- _ O
, -X- _ O
andVto -X- _ O
respec- -X- _ O
tively -X- _ O
produce -X- _ O
query -X- _ O
( -X- _ O
q -X- _ O
) -X- _ O
, -X- _ O
key -X- _ O
( -X- _ O
k -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
value -X- _ O
( -X- _ O
v -X- _ O
) -X- _ O
vectors -X- _ O
. -X- _ O
To -X- _ O
construct -X- _ O
the -X- _ O
output -X- _ O
representation -X- _ O
z -X- _ O
, -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
weights -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
the -X- _ O
dot -X- _ O
product -X- _ O
of -X- _ O
qwith -X- _ O
every -X- _ O
kin -X- _ O
all -X- _ O
time -X- _ O
steps -X- _ O
. -X- _ O
Before -X- _ O
applying -X- _ O
a -X- _ O
softmax -X- _ O
function -X- _ O
, -X- _ O
these -X- _ O
values -X- _ O
are -X- _ O
divided -X- _ O
by -X- _ O
a -X- _ O
scaling -X- _ O
factor -X- _ O
and -X- _ O
then -X- _ O
added -X- _ O
to -X- _ O
an -X- _ O
attention -X- _ O
mask -X- _ O
vector -X- _ O
m -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
zero -X- _ O
for -X- _ O
positions -X- _ O
we -X- _ O
wish -X- _ O
to -X- _ O
attend -X- _ O
and -X- _ O
−∞ -X- _ O
( -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
−10000 -X- _ O
) -X- _ O
for -X- _ O
padded -X- _ O
tokens -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Mathematically -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
attention -X- _ O
head -X- _ O
, -X- _ O
the -X- _ O
weight -X- _ O
attention -X- _ O
from -X- _ O
token -X- _ O
xto -X- _ O
token -X- _ O
xin -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
sequence -X- _ O
can -X- _ O
be -X- _ O
written -X- _ O
as -X- _ O
: -X- _ O
α= -X- _ O
softmax -X- _ O
qk√ -X- _ O
d+m -X- _ O
! -X- _ O
∈R -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
time -X- _ O
complexity -X- _ O
for -X- _ O
this -X- _ O
is -X- _ O
O -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
given -X- _ O
the -X- _ O
dot -X- _ O
product -X- _ O
qk -X- _ O
, -X- _ O
where -X- _ O
nis -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O
This -X- _ O
impedes -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
based -X- _ O
models -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
. -X- _ O
While -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
white -X- _ O
- -X- _ O
box -X- _ O
components -X- _ O
in -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
relying -X- _ O
on -X- _ O
raw -X- _ O
attention -X- _ O
weights -X- _ O
as -X- _ O
an -X- _ O
explanation -X- _ O
could -X- _ O
be -X- _ O
misleading -X- _ O
given -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
necessarily -X- _ O
re- -X- _ O
sponsible -X- _ O
for -X- _ O
determining -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
classifier -X- _ O
’s -X- _ O
decision -X- _ O
( -X- _ O
Jain -X- _ O
and -X- _ O
Wal- -X- _ O
lace -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Serrano -X- _ O
and -X- _ O
Smith -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Abnar -X- _ O
and -X- _ O
Zuidema -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
raw -X- _ O
attentions -X- _ O
are -X- _ O
being -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
local -X- _ O
mixture -X- _ O
of -X- _ O
information -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
and -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
global -X- _ O
perspective -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
flow -X- _ O
through -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
( -X- _ O
Pascual -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
2.2 -X- _ O
Gradient -X- _ O
- -X- _ O
based -X- _ O
Saliency -X- _ O
Scores -X- _ O
Gradient -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
provide -X- _ O
alternatives -X- _ O
to -X- _ O
at- -X- _ O
tention -X- _ O
weights -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
a2 -X- _ O
specific -X- _ O
input -X- _ O
feature -X- _ O
. -X- _ O
Despite -X- _ O
having -X- _ O
been -X- _ O
widely -X- _ O
utilized -X- _ O
in -X- _ O
other -X- _ O
fields -X- _ O
earlier -X- _ O
( -X- _ O
Ancona -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Simonyan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Sundararajan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Smilkov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
only -X- _ O
recently -X- _ O
be- -X- _ O
come -X- _ O
popular -X- _ O
in -X- _ O
NLP -X- _ B-TaskName
studies -X- _ O
( -X- _ O
Bastings -X- _ O
and -X- _ O
Fil- -X- _ O
ippova -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Yuan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
methods -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
computing -X- _ O
the -X- _ O
first- -X- _ O
order -X- _ O
derivative -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
logit -X- _ O
yw.r.t -X- _ O
. -X- _ O
the -X- _ O
input -X- _ O
embedding -X- _ O
h -X- _ O
( -X- _ O
initial -X- _ O
hidden -X- _ O
states -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
ccould -X- _ O
be -X- _ O
true -X- _ O
class -X- _ O
label -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
impor- -X- _ O
tant -X- _ O
input -X- _ O
features -X- _ O
or -X- _ O
the -X- _ O
predicted -X- _ O
class -X- _ O
to -X- _ O
interpret -X- _ O
model -X- _ O
’s -X- _ O
behavior -X- _ O
. -X- _ O
After -X- _ O
taking -X- _ O
the -X- _ O
norm -X- _ O
of -X- _ O
output -X- _ O
derivatives -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
sensitivity -X- _ O
( -X- _ O
Ancona -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
changes -X- _ O
in -X- _ O
model -X- _ O
’s -X- _ O
output -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
changes -X- _ O
in -X- _ O
specific -X- _ O
input -X- _ O
dimensions -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
by -X- _ O
multiplying -X- _ O
gradients -X- _ O
with -X- _ O
input -X- _ O
fea- -X- _ O
tures -X- _ O
, -X- _ O
we -X- _ O
arrive -X- _ O
at -X- _ O
gradient -X- _ O
×input -X- _ O
( -X- _ O
Bastings -X- _ O
and -X- _ O
Filippova -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
saliency -X- _ O
, -X- _ O
which -X- _ O
also -X- _ O
considers -X- _ O
the -X- _ O
direction -X- _ O
of -X- _ O
input -X- _ O
vectors -X- _ O
to -X- _ O
de- -X- _ O
termine -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
tokens -X- _ O
. -X- _ O
Since -X- _ O
these -X- _ O
scores -X- _ O
are -X- _ O
computed -X- _ O
for -X- _ O
each -X- _ O
dimension -X- _ O
of -X- _ O
embed- -X- _ O
ding -X- _ O
vectors -X- _ O
, -X- _ O
an -X- _ O
aggregation -X- _ O
method -X- _ O
such -X- _ O
as -X- _ O
L2 -X- _ O
norm -X- _ O
or -X- _ O
mean -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
produce -X- _ O
one -X- _ O
score -X- _ O
per -X- _ O
input -X- _ O
token -X- _ O
( -X- _ O
Atanasova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
: -X- _ O
S=∥∂y -X- _ O
∂h⊙h∥ -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
3 -X- _ O
Methodology -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
relies -X- _ O
on -X- _ O
drop- -X- _ O
ping -X- _ O
low -X- _ O
contributing -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
and -X- _ O
passing -X- _ O
only -X- _ O
the -X- _ O
more -X- _ O
important -X- _ O
ones -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
one -X- _ O
important -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
im- -X- _ O
portance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
saliency -X- _ O
scores -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
recently -X- _ O
shownas -X- _ O
a -X- _ O
reliable -X- _ O
criterion -X- _ O
in -X- _ O
measuring -X- _ O
token -X- _ O
’s -X- _ O
con- -X- _ O
tributions -X- _ O
( -X- _ O
Bastings -X- _ O
and -X- _ O
Filippova -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Pascual -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
5.1 -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
a -X- _ O
series -X- _ O
quantitative -X- _ O
analyses -X- _ O
that -X- _ O
supports -X- _ O
this -X- _ O
choice -X- _ O
. -X- _ O
In -X- _ O
what -X- _ O
follows -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
describe -X- _ O
how -X- _ O
we -X- _ O
estimate -X- _ O
saliency -X- _ O
scores -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
using -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
Contribution -X- _ B-MethodName
Predictors -X- _ I-MethodName
( -X- _ O
CPs -X- _ O
) -X- _ O
and -X- _ O
then -X- _ O
elab- -X- _ O
orate -X- _ O
on -X- _ O
how -X- _ O
we -X- _ O
leverage -X- _ O
these -X- _ O
predictors -X- _ O
during -X- _ O
inference -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
training -X- _ O
( -X- _ O
Section -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O
3.1 -X- _ O
Contribution -X- _ B-MethodName
Predictor -X- _ I-MethodName
Computing -X- _ O
gradients -X- _ O
during -X- _ O
inference -X- _ O
is -X- _ O
problem- -X- _ O
atic -X- _ O
as -X- _ O
backpropagation -X- _ O
computation -X- _ O
prolongs -X- _ O
in- -X- _ O
ference -X- _ O
time -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
contrary -X- _ O
to -X- _ O
our -X- _ O
main -X- _ O
goal -X- _ O
. -X- _ O
To -X- _ O
circumvent -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
add -X- _ O
a -X- _ O
CP -X- _ B-MethodName
after -X- _ O
each -X- _ O
layer -X- _ O
ℓin -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
estimate -X- _ O
contribution -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
representation -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
then -X- _ O
decides -X- _ O
on -X- _ O
the -X- _ O
tokens -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
layer -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
. -X- _ O
CP -X- _ B-MethodName
com- -X- _ O
putesfor -X- _ O
each -X- _ O
token -X- _ O
using -X- _ O
an -X- _ O
MLP -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
, -X- _ O
despite -X- _ O
being -X- _ O
limited -X- _ O
in -X- _ O
learning -X- _ O
capacity -X- _ O
, -X- _ O
the -X- _ O
MLP -X- _ O
is -X- _ O
sufficient -X- _ O
for -X- _ O
estimating -X- _ O
scores -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
gen- -X- _ O
eralized -X- _ O
and -X- _ O
relevant -X- _ O
than -X- _ O
vanilla -X- _ O
saliency -X- _ O
values -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
present -X- _ O
a -X- _ O
quantitative -X- _ O
analysis -X- _ O
on -X- _ O
this -X- _ O
topic -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
3.2 -X- _ O
Model -X- _ O
Inference -X- _ O
Most -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
models -X- _ O
consist -X- _ O
of -X- _ O
Lencoder -X- _ O
layers -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
sequence -X- _ O
of -X- _ O
ntokens -X- _ O
is -X- _ O
usually -X- _ O
passed -X- _ O
through -X- _ O
an -X- _ O
embedding -X- _ O
layer -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
initial -X- _ O
hidden -X- _ O
states -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
h. -X- _ O
Each -X- _ O
encoder -X- _ O
layer -X- _ O
then -X- _ O
produces -X- _ O
the -X- _ O
next -X- _ O
hidden -X- _ O
states -X- _ O
using -X- _ O
the3ones -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
layer -X- _ O
: -X- _ O
h -X- _ O
= -X- _ O
Encoder -X- _ O
( -X- _ O
h -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
In -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
eliminate -X- _ O
less -X- _ O
contribut- -X- _ O
ing -X- _ O
token -X- _ O
representations -X- _ O
before -X- _ O
delivering -X- _ O
hidden -X- _ O
states -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
encoder -X- _ O
. -X- _ O
Tokens -X- _ O
are -X- _ O
selected -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
contribution -X- _ O
scoresobtained -X- _ O
from -X- _ O
the -X- _ O
CP -X- _ B-MethodName
of -X- _ O
the -X- _ O
corresponding -X- _ O
layer -X- _ O
ℓ. -X- _ O
As -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
these -X- _ O
scores -X- _ O
is -X- _ O
equal -X- _ O
to -X- _ O
one -X- _ O
, -X- _ O
a -X- _ O
uniform -X- _ O
level -X- _ O
indicates -X- _ O
that -X- _ O
all -X- _ O
tokens -X- _ O
contribute -X- _ O
equally -X- _ O
to -X- _ O
the -X- _ O
prediction -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
retained -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
lower -X- _ O
- -X- _ O
scoring -X- _ O
tokens -X- _ O
could -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
unnecessary -X- _ O
tokens -X- _ O
if -X- _ O
the -X- _ O
contribution -X- _ O
scores -X- _ O
are -X- _ O
concentrated -X- _ O
only -X- _ O
on -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O
Given -X- _ O
that -X- _ O
the -X- _ O
final -X- _ O
classification -X- _ O
head -X- _ O
uses -X- _ O
the -X- _ O
last -X- _ O
hid- -X- _ O
den -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
preserve -X- _ O
this -X- _ O
token -X- _ O
’s -X- _ O
representation -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
Despite -X- _ O
pre- -X- _ O
serving -X- _ O
this -X- _ O
, -X- _ O
other -X- _ O
tokens -X- _ O
might -X- _ O
be -X- _ O
removed -X- _ O
from -X- _ O
a -X- _ O
layer -X- _ O
when -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
has -X- _ O
a -X- _ O
significantly -X- _ O
high -X- _ O
esti- -X- _ O
mated -X- _ O
contribution -X- _ O
score -X- _ O
than -X- _ O
others -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
intuition -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
cutoff -X- _ O
threshold -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
uniform -X- _ O
level -X- _ O
as -X- _ O
: -X- _ O
δ -X- _ O
= -X- _ O
η· -X- _ O
/ -X- _ O
with0 -X- _ O
< -X- _ O
η≤1to -X- _ O
distinguish -X- _ O
important -X- _ O
tokens -X- _ O
. -X- _ O
Tokens -X- _ O
are -X- _ O
consid- -X- _ O
ered -X- _ O
important -X- _ O
if -X- _ O
their -X- _ O
contribution -X- _ O
score -X- _ O
exceeds -X- _ O
δ -X- _ O
( -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
value -X- _ O
equal -X- _ O
or -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
uniform -X- _ O
score -X- _ O
) -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
a -X- _ O
larger -X- _ O
ηprovides -X- _ O
a -X- _ O
higher -X- _ O
δ -X- _ O
cutoff -X- _ O
level -X- _ O
, -X- _ O
thereby -X- _ O
dropping -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
, -X- _ O
hence -X- _ O
, -X- _ O
yielding -X- _ O
more -X- _ O
speedup -X- _ O
. -X- _ O
The -X- _ O
value -X- _ O
ofηdetermines -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
we -X- _ O
can -X- _ O
rely -X- _ O
on -X- _ O
CP -X- _ O
’s -X- _ O
estimations -X- _ O
. -X- _ O
In -X- _ O
case -X- _ O
the -X- _ O
estimations -X- _ O
of -X- _ O
CP -X- _ O
are -X- _ O
deemed -X- _ O
to -X- _ O
be -X- _ O
inaccurate -X- _ O
, -X- _ O
its -X- _ O
impact -X- _ O
can -X- _ O
be -X- _ O
reduced -X- _ O
by -X- _ O
lowering -X- _ O
η -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
each -X- _ O
layer -X- _ O
’s -X- _ O
η -X- _ O
using -X- _ O
an -X- _ O
auxiliary -X- _ O
training -X- _ O
objective -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
cutoff -X- _ O
value -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
speedup -X- _ O
- -X- _ O
performance -X- _ O
tradeoff -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
since -X- _ O
each -X- _ O
input -X- _ O
instance -X- _ O
has -X- _ O
a -X- _ O
different -X- _ O
computational -X- _ O
path -X- _ O
during -X- _ O
token -X- _ O
removal -X- _ O
process -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
should -X- _ O
be -X- _ O
equal -X- _ O
to -X- _ O
one -X- _ O
( -X- _ O
single -X- _ O
instance -X- _ O
usage -X- _ O
) -X- _ O
, -X- _ O
similarly -X- _ O
to -X- _ O
other -X- _ O
dynamic -X- _ O
approaches -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Eyzaguirre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
3.3 -X- _ O
Model -X- _ O
Training -X- _ O
Training -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
phases -X- _ O
: -X- _ O
initial -X- _ O
fine- -X- _ O
tuning -X- _ O
, -X- _ O
saliency -X- _ O
extraction -X- _ O
, -X- _ O
and -X- _ O
adaptive -X- _ O
length -X- _ O
re- -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
) -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
extract -X- _ O
the -X- _ O
saliencies -X- _ O
of -X- _ O
three -X- _ O
top -X- _ O
- -X- _ O
perfroming -X- _ O
checkpoints -X- _ O
from -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
and -X- _ O
com- -X- _ O
pute -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
them -X- _ O
to -X- _ O
mitigate -X- _ O
potential -X- _ O
in- -X- _ O
consistencies -X- _ O
in -X- _ O
saliency -X- _ O
scores -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Section -X- _ O
2.2 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
us- -X- _ O
ing -X- _ O
an -X- _ O
adaptive -X- _ O
length -X- _ O
reduction -X- _ O
procedure -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
phase -X- _ O
, -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
function -X- _ O
gradually -X- _ O
fades -X- _ O
out -X- _ O
the -X- _ O
representations -X- _ O
throughout -X- _ O
the -X- _ O
training -X- _ O
pro- -X- _ O
cess -X- _ O
. -X- _ O
Each -X- _ O
CP -X- _ B-MethodName
is -X- _ O
jointly -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
saliencies -X- _ O
extracted -X- _ O
in -X- _ O
the -X- _ O
pre- -X- _ O
vious -X- _ O
phase -X- _ O
alongside -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
define -X- _ O
a -X- _ O
speedup -X- _ O
tuning -X- _ O
objective -X- _ O
to -X- _ O
deter- -X- _ O
mine -X- _ O
the -X- _ O
thresholds -X- _ O
( -X- _ O
via -X- _ O
tuning -X- _ O
η -X- _ O
) -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
performance -X- _ O
- -X- _ O
speedup -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
, -X- _ O
we -X- _ O
elaborate -X- _ O
on -X- _ O
the -X- _ O
procedure -X- _ O
. -X- _ O
Soft -X- _ B-MethodName
- -X- _ I-MethodName
removal -X- _ I-MethodName
function -X- _ I-MethodName
. -X- _ O
During -X- _ O
training -X- _ O
, -X- _ O
if -X- _ O
to- -X- _ O
kens -X- _ O
are -X- _ O
immediately -X- _ O
dropped -X- _ O
similarly -X- _ O
to -X- _ O
the -X- _ O
in- -X- _ O
ference -X- _ O
mode -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
dropping -X- _ O
tokens -X- _ O
can- -X- _ O
not -X- _ O
be -X- _ O
captured -X- _ O
using -X- _ O
a -X- _ O
gradient -X- _ O
backpropagation -X- _ O
procedure -X- _ O
. -X- _ O
Using -X- _ O
batch -X- _ O
- -X- _ O
wise -X- _ O
training -X- _ O
in -X- _ O
this -X- _ O
sce- -X- _ O
nario -X- _ O
will -X- _ O
also -X- _ O
be -X- _ O
problematic -X- _ O
as -X- _ O
the -X- _ O
structure -X- _ O
will -X- _ O
vary -X- _ O
with -X- _ O
each -X- _ O
example -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
padding -X- _ O
mechanism -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
models -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
proce- -X- _ O
dure -X- _ O
that -X- _ O
gradually -X- _ O
masks -X- _ O
out -X- _ O
less -X- _ O
contributing -X- _ O
to- -X- _ O
ken -X- _ O
representations -X- _ O
. -X- _ O
In -X- _ O
each -X- _ O
layer -X- _ O
, -X- _ O
after -X- _ O
predicting -X- _ O
contribution -X- _ O
scores -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
instantly -X- _ O
removing -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
accumulate -X- _ O
a -X- _ O
nega- -X- _ O
tive -X- _ O
mask -X- _ O
to -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
vector -X- _ O
Musing -X- _ O
a -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
: -X- _ O
m -X- _ O
( -X- _ O
˜S -X- _ O
) -X- _ O
= -X- _ O
 -X- _ O
 -X- _ O
λ -X- _ O
( -X- _ O
˜S−δ -X- _ O
) -X- _ O
−β -X- _ O
λ˜S -X- _ O
< -X- _ O
δ -X- _ O
( -X- _ O
˜S−1 -X- _ O
) -X- _ O
β -X- _ O
( -X- _ O
1−δ -X- _ O
) -X- _ O
λ˜S≥δ -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
This -X- _ O
function -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
main -X- _ O
zones -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
term -X- _ O
, -X- _ O
the -X- _ O
less -X- _ O
important -X- _ O
tokens -X- _ O
with -X- _ O
scores -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
threshold -X- _ O
( -X- _ O
δ -X- _ B-HyperparameterName
) -X- _ O
are -X- _ O
assigned -X- _ O
higher -X- _ O
negative -X- _ O
masking -X- _ O
as -X- _ O
they -X- _ O
get -X- _ O
more -X- _ O
distant4from -X- _ O
δ -X- _ O
. -X- _ O
The -X- _ O
slope -X- _ O
is -X- _ O
determined -X- _ O
by -X- _ O
λ= -X- _ B-HyperparameterName
/ -X- _ O
, -X- _ O
where -X- _ O
λis -X- _ O
a -X- _ O
hyperparameter -X- _ O
that -X- _ O
is -X- _ O
increased -X- _ O
ex- -X- _ O
ponentially -X- _ O
after -X- _ O
each -X- _ O
epoch -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
λ←10×λaf- -X- _ B-HyperparameterName
ter -X- _ O
finishing -X- _ O
each -X- _ O
epoch -X- _ O
) -X- _ O
. -X- _ O
Increasing -X- _ O
λmakes -X- _ B-HyperparameterName
the -X- _ O
soft -X- _ O
- -X- _ O
removal -X- _ O
function -X- _ O
stronger -X- _ O
and -X- _ O
more -X- _ O
decisive -X- _ O
in -X- _ O
masking -X- _ O
the -X- _ O
representations -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
under- -X- _ O
going -X- _ O
zero -X- _ O
gradients -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
0 -X- _ O
< -X- _ O
β -X- _ B-HyperparameterName
< -X- _ O
0.1to -X- _ O
construct -X- _ O
a -X- _ O
small -X- _ O
negative -X- _ O
slope -X- _ O
( -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
well -X- _ O
known -X- _ O
Leaky -X- _ O
- -X- _ O
ReLU -X- _ O
of -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2013 -X- _ O
) -X- _ O
for -X- _ O
those -X- _ O
tokens -X- _ O
with -X- _ O
higher -X- _ O
contribut- -X- _ O
ing -X- _ O
scores -X- _ O
than -X- _ O
δthreshold -X- _ O
. -X- _ O
Consider -X- _ O
a -X- _ O
scenario -X- _ O
in -X- _ O
which -X- _ O
ηsharply -X- _ B-HyperparameterName
drops -X- _ O
, -X- _ O
causing -X- _ O
most -X- _ O
ofget -X- _ O
over -X- _ O
theδthreshold -X- _ B-HyperparameterName
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
zero -X- _ O
value -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
term -X- _ O
of -X- _ O
Equation -X- _ O
4 -X- _ O
, -X- _ O
which -X- _ O
facilitates -X- _ O
optimizing -X- _ O
η -X- _ B-HyperparameterName
. -X- _ O
Training -X- _ O
the -X- _ O
Contribution -X- _ O
Predictors -X- _ O
. -X- _ O
The -X- _ O
CPs -X- _ O
are -X- _ O
trained -X- _ O
by -X- _ O
an -X- _ O
additional -X- _ O
term -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
KL -X- _ O
- -X- _ O
divergenceof -X- _ O
each -X- _ O
layer -X- _ O
’s -X- _ O
CP -X- _ B-MethodName
output -X- _ O
with -X- _ O
the -X- _ O
extracted -X- _ O
saliencies -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
a -X- _ O
minimization -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
loss -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
L+γL -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Where -X- _ O
γis -X- _ O
a -X- _ O
hyperparameter -X- _ O
which -X- _ O
that -X- _ O
specifies -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
emphasis -X- _ O
on -X- _ O
the -X- _ O
CP -X- _ B-MethodName
training -X- _ O
loss -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
X -X- _ O
( -X- _ O
L−ℓ -X- _ O
) -X- _ O
D -X- _ O
( -X- _ O
ˆS||˜S -X- _ O
) -X- _ O
= -X- _ O
X -X- _ O
( -X- _ O
L−ℓ -X- _ O
) -X- _ O
XˆSlog -X- _ O
( -X- _ O
ˆS -X- _ O
˜S -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Since -X- _ O
Sis -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
embeddings -X- _ O
, -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
usually -X- _ O
shows -X- _ O
a -X- _ O
low -X- _ O
amount -X- _ O
of -X- _ O
con- -X- _ O
tribution -X- _ O
due -X- _ O
to -X- _ O
not -X- _ O
having -X- _ O
any -X- _ O
contextualism -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
for -X- _ O
classification -X- _ O
, -X- _ O
this -X- _ O
token -X- _ O
acts -X- _ O
as -X- _ O
a -X- _ O
pooler -X- _ O
and -X- _ O
gathers -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
can -X- _ O
potentially -X- _ O
have -X- _ O
more -X- _ O
contribution -X- _ O
as -X- _ O
it -X- _ O
passes -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
amplify -X- _ O
the -X- _ O
contribution -X- _ O
score -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
renormalize -X- _ O
the -X- _ O
distribution -X- _ O
( -X- _ O
ˆS -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
trainable -X- _ O
parameter -X- _ O
θ -X- _ O
: -X- _ O
ˆS -X- _ O
= -X- _ O
θS1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
+ -X- _ O
S1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
θS+PS -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
By -X- _ O
this -X- _ O
procedure -X- _ O
, -X- _ O
the -X- _ O
next -X- _ O
objective -X- _ O
( -X- _ O
discussed -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
paragraph -X- _ O
) -X- _ O
will -X- _ O
have -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
tuning -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
pooling -X- _ O
, -X- _ O
consequently -X- _ O
con- -X- _ O
trolling -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
speedup -X- _ O
. -X- _ O
Larger -X- _ O
θpush -X- _ O
theCPs -X- _ B-MethodName
to -X- _ O
shift -X- _ O
the -X- _ O
contribution -X- _ O
towards -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
to- -X- _ O
ken -X- _ O
to -X- _ O
gather -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
and -X- _ O
avoids -X- _ O
carrying -X- _ O
redundant -X- _ O
tokens -X- _ O
through -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Speedup -X- _ O
Tuning -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
speedup -X- _ O
tuning -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
classification -X- _ O
task -X- _ O
with -X- _ O
a -X- _ O
length -X- _ O
loss -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
expected -X- _ O
number -X- _ O
of -X- _ O
unmasked -X- _ O
token -X- _ O
representa- -X- _ O
tions -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
Considering -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
positive -X- _ O
and -X- _ O
continuous -X- _ O
attention -X- _ O
mask -X- _ O
M -X- _ O
, -X- _ O
the -X- _ O
length -X- _ O
loss -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
layer -X- _ O
would -X- _ O
be -X- _ O
the -X- _ O
summation -X- _ O
over -X- _ O
the -X- _ O
exponential -X- _ O
of -X- _ O
the -X- _ O
mask -X- _ O
val- -X- _ O
uesexp -X- _ O
( -X- _ O
m -X- _ O
) -X- _ O
to -X- _ O
map -X- _ O
the -X- _ O
masking -X- _ O
range -X- _ O
[ -X- _ O
−∞,0 -X- _ O
] -X- _ O
to -X- _ O
a -X- _ O
[ -X- _ O
0 -X- _ O
( -X- _ O
fully -X- _ O
masked -X- _ O
/ -X- _ O
removed -X- _ O
) -X- _ O
, -X- _ O
1 -X- _ O
( -X- _ O
fully -X- _ O
retained -X- _ O
) -X- _ O
] -X- _ O
bound -X- _ O
. -X- _ O
L -X- _ O
= -X- _ O
L+ϕL -X- _ O
L -X- _ O
= -X- _ O
XXexp -X- _ O
( -X- _ O
m -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
Equation -X- _ O
8 -X- _ O
demonstrates -X- _ O
how -X- _ O
the -X- _ O
length -X- _ O
loss -X- _ O
is -X- _ O
computed -X- _ O
inside -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
how -X- _ O
it -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
classification -X- _ O
loss -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
a -X- _ O
separate -X- _ O
optimization -X- _ O
process -X- _ O
which -X- _ O
tunes -X- _ O
ηandθto -X- _ O
adjust -X- _ O
the -X- _ O
thresholds -X- _ O
and -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
poolingalongside -X- _ O
with -X- _ O
the -X- _ O
CP -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
that -X- _ O
this -X- _ O
objective -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
sep- -X- _ O
arate -X- _ O
problem -X- _ O
instead -X- _ O
of -X- _ O
merging -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
pre- -X- _ O
vious -X- _ O
one -X- _ O
, -X- _ O
is -X- _ O
because -X- _ O
in -X- _ O
the -X- _ O
latter -X- _ O
case -X- _ O
the -X- _ O
CPs -X- _ O
could -X- _ O
be -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
length -X- _ O
loss -X- _ O
and -X- _ O
try -X- _ O
to -X- _ O
manipulate -X- _ O
the -X- _ O
contribution -X- _ O
scores -X- _ O
for -X- _ O
some -X- _ O
tokens -X- _ O
regardless -X- _ O
of -X- _ O
their -X- _ O
real -X- _ O
influence -X- _ O
. -X- _ O
So -X- _ O
in -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
task -X- _ O
and -X- _ O
make -X- _ O
it -X- _ O
explainable -X- _ O
with -X- _ O
the -X- _ O
CPs -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
secondary -X- _ O
objec- -X- _ O
tive -X- _ O
builds -X- _ O
the -X- _ O
speedup -X- _ O
using -X- _ O
tuning -X- _ O
the -X- _ O
threshold -X- _ O
levels -X- _ O
and -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
pooling -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O
4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Datasets -X- _ O
To -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
AdapLeR -X- _ B-MethodName
on -X- _ O
infer- -X- _ O
ence -X- _ O
speedup -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
eight -X- _ O
various -X- _ O
text -X- _ O
classi- -X- _ O
fication -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
incorporate -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
utilized -X- _ O
SST-2 -X- _ B-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
and -X- _ O
IMDB -X- _ B-DatasetName
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
for -X- _ O
sentiment -X- _ B-TaskName
, -X- _ O
MRPC -X- _ B-DatasetName
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
for -X- _ O
paraphrase -X- _ B-TaskName
, -X- _ O
AG -X- _ B-DatasetName
’s -X- _ I-DatasetName
News -X- _ I-DatasetName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
topic -X- _ B-TaskName
classification -X- _ I-TaskName
, -X- _ O
DBpedia -X- _ B-DatasetName
( -X- _ O
Lehmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
for -X- _ O
knowledge -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
MNLI -X- _ B-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
NLI,5 -X- _ B-TaskName
QNLI -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
for -X- _ O
question -X- _ B-TaskName
answer- -X- _ I-TaskName
ing -X- _ I-TaskName
, -X- _ O
and -X- _ O
HateXplain -X- _ B-DatasetName
( -X- _ O
Mathew -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
hate -X- _ B-TaskName
speech -X- _ I-TaskName
. -X- _ O
Evaluations -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
split -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
For -X- _ O
those -X- _ O
datasets -X- _ O
that -X- _ O
are -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
Benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
test -X- _ O
results -X- _ O
were -X- _ O
acquired -X- _ O
by -X- _ O
submitting -X- _ O
the -X- _ O
test -X- _ O
predictions -X- _ O
to -X- _ O
the -X- _ O
evaluation -X- _ O
server -X- _ O
. -X- _ O
4.2 -X- _ O
Experimental -X- _ O
Setup -X- _ O
As -X- _ O
our -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
pre- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
AdapLeR. -X- _ B-MethodName
We -X- _ O
also -X- _ O
compare -X- _ O
against -X- _ O
three -X- _ O
other -X- _ O
approaches -X- _ O
: -X- _ O
DistilBERT -X- _ B-MethodName
( -X- _ O
uncased -X- _ O
) -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
static -X- _ O
compression -X- _ O
method -X- _ O
, -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
as -X- _ O
two -X- _ O
strong -X- _ O
length -X- _ O
reduction -X- _ O
methods -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Sec -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
provided -X- _ O
implemen- -X- _ O
tations -X- _ O
and -X- _ O
suggested -X- _ O
hyperparametersto -X- _ O
train -X- _ O
these -X- _ O
baselines -X- _ O
. -X- _ O
To -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
same -X- _ O
hyperparameters -X- _ O
over -X- _ O
all -X- _ O
tasks -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
D -X- _ O
for -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
backbone -X- _ O
model -X- _ O
and -X- _ O
our -X- _ O
model -X- _ O
implementation -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Hug- -X- _ O
gingFace -X- _ O
’s -X- _ O
Transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Trainings -X- _ O
and -X- _ O
evaluations -X- _ O
were -X- _ O
conducted -X- _ O
on -X- _ O
a -X- _ O
dual -X- _ O
2080Ti -X- _ O
11 -X- _ O
GB -X- _ O
GPU -X- _ O
machine -X- _ O
with -X- _ O
multiple -X- _ O
runs -X- _ O
. -X- _ O
Hyperparameter -X- _ O
Selection -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
intro- -X- _ O
duced -X- _ O
four -X- _ O
hyperparameters -X- _ O
( -X- _ O
γ -X- _ B-HyperparameterName
, -X- _ O
ϕ -X- _ B-HyperparameterName
, -X- _ O
λ -X- _ B-HyperparameterName
, -X- _ O
β -X- _ B-HyperparameterName
) -X- _ O
which -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
Among -X- _ O
these -X- _ O
, -X- _ O
ϕ -X- _ O
andγare -X- _ O
the -X- _ O
primary -X- _ O
terms -X- _ O
that -X- _ O
have -X- _ O
considerable -X- _ O
effects -X- _ O
on -X- _ O
AdapLeR -X- _ B-MethodName
’s -X- _ O
downstream -X- _ O
performance -X- _ O
and -X- _ O
speedup -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
our -X- _ O
approach -X- _ O
comparable -X- _ O
to -X- _ O
existing -X- _ O
techniques -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
which -X- _ O
usually -X- _ O
have -X- _ O
two -X- _ O
or -X- _ O
three -X- _ O
hyperpa- -X- _ O
rameters -X- _ O
adjusted -X- _ O
per -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
grid -X- _ O
search -X- _ O
tofind -X- _ O
the -X- _ O
optimal -X- _ O
values -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
terms -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
other -X- _ O
hyperparameters -X- _ O
constant -X- _ O
over -X- _ O
all -X- _ O
datasets -X- _ O
. -X- _ O
Hyperparamter -X- _ O
selection -X- _ O
is -X- _ O
further -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
D. -X- _ O
FLOPs -X- _ O
Computation -X- _ O
. -X- _ O
We -X- _ O
followed -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
measured -X- _ O
com- -X- _ O
putational -X- _ O
complexity -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
FLOPs -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
floating -X- _ O
- -X- _ O
point -X- _ O
operations -X- _ O
( -X- _ O
FLOPs -X- _ O
) -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
inference -X- _ O
procedure -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
assess -X- _ O
models -X- _ O
’ -X- _ O
speedups -X- _ O
independently -X- _ O
of -X- _ O
their -X- _ O
op- -X- _ O
erating -X- _ O
environment -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CPU -X- _ O
/ -X- _ O
GPU -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
total -X- _ O
FLOPs -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
summation -X- _ O
of -X- _ O
the -X- _ O
measured -X- _ O
FLOPs -X- _ O
over -X- _ O
all -X- _ O
test -X- _ O
examples -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
’s -X- _ O
speedup -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
total -X- _ O
FLOPs -X- _ O
measured -X- _ O
on -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
our -X- _ O
baseline -X- _ O
) -X- _ O
divided -X- _ O
by -X- _ O
the -X- _ O
corresponding -X- _ O
model -X- _ O
’s -X- _ O
total -X- _ O
FLOPs -X- _ O
. -X- _ O
To -X- _ O
have -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
computed -X- _ O
FLOPs -X- _ O
for -X- _ O
PoWER- -X- _ B-MethodName
BERT -X- _ I-MethodName
in -X- _ O
a -X- _ O
single -X- _ O
instance -X- _ O
mode -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
Sec- -X- _ O
tion -X- _ O
C. -X- _ O
4.3 -X- _ O
Results -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
performance -X- _ O
and -X- _ O
speedup -X- _ O
for -X- _ O
AdapLeR -X- _ O
and -X- _ O
other -X- _ O
comparison -X- _ O
models -X- _ O
across -X- _ O
eight -X- _ O
different -X- _ O
datasets -X- _ O
. -X- _ O
While -X- _ O
preserving -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
performance -X- _ O
, -X- _ O
AdapLeR -X- _ B-MethodName
outperforms -X- _ O
other -X- _ O
techniques -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
speedup -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
( -X- _ O
ranging -X- _ O
from -X- _ O
+0.2x -X- _ O
to -X- _ O
+7.4x -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
in -X- _ O
each -X- _ O
dataset -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
noteworthy -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
also -X- _ O
reveal -X- _ O
some -X- _ O
form -X- _ O
of -X- _ O
dependency -X- _ O
on -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
. -X- _ O
Some -X- _ O
tasks -X- _ O
may -X- _ O
need -X- _ O
less -X- _ O
amount -X- _ O
of -X- _ O
contextualism -X- _ O
dur- -X- _ O
ing -X- _ O
inference -X- _ O
and -X- _ O
could -X- _ O
be -X- _ O
classified -X- _ O
by -X- _ O
using -X- _ O
only -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
input -X- _ O
tokens -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
AG -X- _ B-DatasetName
’s -X- _ I-DatasetName
News -X- _ I-DatasetName
, -X- _ O
the -X- _ O
topic -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
might -X- _ O
be -X- _ O
identifiable -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
soccer -X- _ O
→Topic -X- _ O
: -X- _ O
Sports -X- _ O
, -X- _ O
see -X- _ O
Figure -X- _ O
6 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
for -X- _ O
an -X- _ O
example -X- _ O
) -X- _ O
. -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
adopts -X- _ O
attention -X- _ O
weights -X- _ O
in -X- _ O
its -X- _ O
to- -X- _ O
ken -X- _ O
selection -X- _ O
which -X- _ O
requires -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
layer -X- _ O
of -X- _ O
computation -X- _ O
to -X- _ O
be -X- _ O
determined -X- _ O
, -X- _ O
and -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
ap-6 -X- _ O
plies -X- _ O
token -X- _ O
elimination -X- _ O
only -X- _ O
in -X- _ O
two -X- _ O
layers -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
training -X- _ O
search -X- _ O
space -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
proce- -X- _ O
dure -X- _ O
performs -X- _ O
token -X- _ O
elimination -X- _ O
for -X- _ O
all -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
enabling -X- _ O
a -X- _ O
more -X- _ O
effective -X- _ O
removal -X- _ O
of -X- _ O
re- -X- _ O
dundant -X- _ O
tokens -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
TR -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
lack -X- _ O
any -X- _ O
speedup -X- _ O
gains -X- _ O
for -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
QNLI -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
and -X- _ O
MRPC -X- _ B-DatasetName
which -X- _ O
need -X- _ O
a -X- _ O
higher -X- _ O
degree -X- _ O
of -X- _ O
contextualism -X- _ O
dur- -X- _ O
ing -X- _ O
inference -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
AdapLeR -X- _ B-MethodName
can -X- _ O
offer -X- _ O
some -X- _ O
speedups -X- _ O
even -X- _ O
for -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O
Speedup -X- _ O
- -X- _ O
Performance -X- _ O
Tradeoff -X- _ O
. -X- _ O
To -X- _ O
provide -X- _ O
a -X- _ O
closer -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
efficiency -X- _ O
of -X- _ O
AdapLeR -X- _ O
in -X- _ O
com- -X- _ O
parison -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
length -X- _ O
re- -X- _ O
duction -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
illustrate -X- _ O
speedup -X- _ O
- -X- _ O
accuracy -X- _ O
curves -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
these -X- _ O
curves -X- _ O
for -X- _ O
two -X- _ O
tasks -X- _ O
in -X- _ O
which -X- _ O
other -X- _ O
length -X- _ O
reduction -X- _ O
methods -X- _ O
show -X- _ O
comparable -X- _ O
speedups -X- _ O
to -X- _ O
AdapLeR. -X- _ O
For -X- _ O
each -X- _ O
curve -X- _ O
, -X- _ O
the -X- _ O
points -X- _ O
were -X- _ O
obtained -X- _ O
by -X- _ O
tuning -X- _ O
the -X- _ O
most -X- _ O
influential -X- _ O
hyperparameters -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
model -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
, -X- _ O
AdapLeR -X- _ O
significantly -X- _ O
out- -X- _ O
performs -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
approaches -X- _ O
in -X- _ O
all -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O
An -X- _ O
interesting -X- _ O
observation -X- _ O
here -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
curves -X- _ O
for -X- _ O
TR -X- _ O
- -X- _ O
BERT -X- _ O
and -X- _ O
AdapLeR -X- _ O
are -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O
This -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
procedure -X- _ O
employed -X- _ O
by -X- _ O
the -X- _ O
for- -X- _ O
mer -X- _ O
two -X- _ O
methods -X- _ O
for -X- _ O
determining -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
reduced -X- _ O
tokens -X- _ O
( -X- _ O
whereas -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
adopts -X- _ O
a -X- _ O
fixed -X- _ O
retention -X- _ O
configuration -X- _ O
in -X- _ O
token -X- _ O
elimination -X- _ O
) -X- _ O
. -X- _ O
5 -X- _ O
Analysis -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
to -X- _ O
support -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
saliency -X- _ O
scores -X- _ O
as -X- _ O
a -X- _ O
super- -X- _ O
vision -X- _ O
in -X- _ O
measuring -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
token -X- _ O
rep- -X- _ O
resentations -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
behavior -X- _ O
of -X- _ O
Contribution -X- _ B-MethodName
Predictors -X- _ I-MethodName
in -X- _ O
identifying -X- _ O
the -X- _ O
most -X- _ O
im- -X- _ O
portant -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
AdapLeR. -X- _ O
5.1 -X- _ O
Rationale -X- _ O
as -X- _ O
an -X- _ O
Upper -X- _ O
Bound -X- _ O
A -X- _ O
natural -X- _ O
question -X- _ O
that -X- _ O
arises -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
token -X- _ O
pruning -X- _ O
is -X- _ O
that -X- _ O
of -X- _ O
importance -X- _ O
measure -X- _ O
: -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
appropriate -X- _ O
criterion -X- _ O
for -X- _ O
assessing -X- _ O
the -X- _ O
relative -X- _ O
importance -X- _ O
of -X- _ O
tokens -X- _ O
within -X- _ O
a -X- _ O
sentence -X- _ O
? -X- _ O
We -X- _ O
resort -X- _ O
to -X- _ O
human -X- _ O
rationale -X- _ O
as -X- _ O
a -X- _ O
reliable -X- _ O
up- -X- _ O
per -X- _ O
bound -X- _ O
for -X- _ O
measuring -X- _ O
token -X- _ O
importance -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
ERASER -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
DeY- -X- _ O
oung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
multiple -X- _ O
tasks -X- _ O
for -X- _ O
which -X- _ O
important -X- _ O
spans -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
have -X- _ O
been -X- _ O
highlighted -X- _ O
as -X- _ O
supporting -X- _ O
evidence -X- _ O
( -X- _ O
aka -X- _ O
“ -X- _ O
ra- -X- _ O
tionale -X- _ O
” -X- _ O
) -X- _ O
by -X- _ O
human -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
benchmark -X- _ O
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
two -X- _ O
diverse -X- _ O
classifica- -X- _ O
tion -X- _ O
tasks -X- _ O
: -X- _ O
Movie -X- _ O
reviews -X- _ O
( -X- _ O
Zaidan -X- _ O
and -X- _ O
Eisner -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
MultiRC -X- _ O
( -X- _ O
Khashabi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
former -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
sentiment -X- _ O
of -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
Whereas -X- _ O
the -X- _ O
latter -X- _ O
contains -X- _ O
a -X- _ O
pas- -X- _ O
sage -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
multiple -X- _ O
candidate -X- _ O
answers -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
cast -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
task -X- _ O
of -X- _ O
passage -X- _ O
/ -X- _ O
question -X- _ O
/ -X- _ O
answer -X- _ O
triplets -X- _ O
in -X- _ O
the -X- _ O
ERASER -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
human -X- _ O
ratio- -X- _ O
nales -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ B-MethodName
based -X- _ O
on -X- _ O
the -X- _ O
rationales -X- _ O
only -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
by -X- _ O
excluding -X- _ O
those -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
highlighted -X- _ O
as -X- _ O
being -X- _ O
important -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
Ta- -X- _ O
ble -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
rows -X- _ O
show -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
with -X- _ O
full -X- _ O
input -X- _ O
and -X- _ O
with -X- _ O
hu- -X- _ O
man -X- _ O
rationales -X- _ O
only -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
merely7 -X- _ O
on -X- _ O
rationales -X- _ O
not -X- _ O
only -X- _ O
yields -X- _ O
less -X- _ O
computation -X- _ O
cost -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
better -X- _ O
performance -X- _ O
when -X- _ O
com- -X- _ O
pared -X- _ O
with -X- _ O
the -X- _ O
full -X- _ O
input -X- _ O
setting -X- _ O
. -X- _ O
Obviously -X- _ O
, -X- _ O
human -X- _ O
annotations -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
for -X- _ O
a -X- _ O
whole -X- _ O
range -X- _ O
of -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
this -X- _ O
criterion -X- _ O
is -X- _ O
infeasible -X- _ O
in -X- _ O
practice -X- _ O
and -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
an -X- _ O
upper -X- _ O
bound -X- _ O
for -X- _ O
evaluating -X- _ O
different -X- _ O
strategies -X- _ O
in -X- _ O
measuring -X- _ O
token -X- _ O
importance -X- _ O
. -X- _ O
5.2 -X- _ O
Saliency -X- _ O
vs. -X- _ O
Attention -X- _ O
We -X- _ O
investigated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
saliency -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
weights -X- _ O
as -X- _ O
two -X- _ O
commonly -X- _ O
used -X- _ O
strate- -X- _ O
gies -X- _ O
for -X- _ O
measuring -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
compute -X- _ O
these -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
all -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
obtained -X- _ O
saliency -X- _ O
scores -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
embedding -X- _ O
layer -X- _ O
. -X- _ O
This -X- _ O
brings -X- _ O
about -X- _ O
two -X- _ O
ad- -X- _ O
vantages -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
representations -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
are -X- _ O
non -X- _ O
- -X- _ O
contextualized -X- _ O
, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
mea- -X- _ O
sure -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
independently -X- _ O
from -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
the -X- _ O
backpropagation -X- _ O
of -X- _ O
gradients -X- _ O
through -X- _ O
layers -X- _ O
to -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
provides -X- _ O
us -X- _ O
with -X- _ O
aggregated -X- _ O
values -X- _ O
for -X- _ O
the -X- _ O
relative -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
aggregated -X- _ O
the -X- _ O
self- -X- _ O
attention -X- _ O
weights -X- _ O
across -X- _ O
all -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
processed -X- _ O
variant -X- _ O
of -X- _ O
attentions -X- _ O
called -X- _ O
attention -X- _ O
rollout -X- _ O
( -X- _ O
Abnar -X- _ O
and -X- _ O
Zuidema -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
pop- -X- _ O
ular -X- _ O
technique -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
attention -X- _ O
weight -X- _ O
matrix -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
is -X- _ O
multiplied -X- _ O
with -X- _ O
the -X- _ O
preceding -X- _ O
ones -X- _ O
to -X- _ O
form -X- _ O
aggregated -X- _ O
attention -X- _ O
values -X- _ O
. -X- _ O
To -X- _ O
assign -X- _ O
an -X- _ O
importance -X- _ O
score -X- _ O
to -X- _ O
each -X- _ O
token -X- _ O
, -X- _ O
we -X- _ O
examined -X- _ O
two -X- _ O
different -X- _ O
interpretation -X- _ O
of -X- _ O
attention -X- _ O
weights -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
strategy -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
adopted -X- _ O
by -X- _ O
PoWER -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
which -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
we -X- _ O
accumulate -X- _ O
attention -X- _ O
values -X- _ O
fromother -X- _ O
tokens -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
measured -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
attends -X- _ O
to -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
sen- -X- _ O
tence -X- _ O
, -X- _ O
a -X- _ O
strategy -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
interpretability -X- _ O
studies -X- _ O
around -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Abnar -X- _ O
and -X- _ O
Zuidema -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Chrysostomou -X- _ O
and -X- _ O
Aletras -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Jain -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
ksalient -X- _ O
and -X- _ O
attended -X- _ O
words -X- _ O
, -X- _ O
with -X- _ O
kbeing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
annotated -X- _ O
as -X- _ O
rationales -X- _ O
. -X- _ O
Results -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
show -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
salient -X- _ O
tokens -X- _ O
outperforms -X- _ O
that -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
attended -X- _ O
tokens -X- _ O
. -X- _ O
This -X- _ O
denotes -X- _ O
that -X- _ O
saliency -X- _ O
is -X- _ O
a -X- _ O
better -X- _ O
indicator -X- _ O
for -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
tokens -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
recent -X- _ O
length -X- _ O
reduction -X- _ O
techniques -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kim -X- _ O
and -X- _ O
Cho -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
mostly -X- _ O
adopted -X- _ O
attention -X- _ O
weights -X- _ O
as -X- _ O
their -X- _ O
criterion -X- _ O
for -X- _ O
selecting -X- _ O
important -X- _ O
tokens -X- _ O
. -X- _ O
Computing -X- _ O
these -X- _ O
weights -X- _ O
is -X- _ O
convenient -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
already -X- _ O
computed -X- _ O
during -X- _ O
the -X- _ O
forward -X- _ O
pass -X- _ O
, -X- _ O
whereas -X- _ O
computing -X- _ O
saliency -X- _ O
requires -X- _ O
an -X- _ O
additional -X- _ O
backpropagation -X- _ O
step -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
saliency -X- _ O
scores -X- _ O
are -X- _ O
easily -X- _ O
estimated -X- _ O
within -X- _ O
infer- -X- _ O
ence -X- _ O
time -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
CPs -X- _ O
. -X- _ O
5.3 -X- _ O
Contribution -X- _ O
Predictor -X- _ O
Evaluation -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
validate -X- _ O
our -X- _ O
Contribution -X- _ O
Predic- -X- _ O
tors -X- _ O
in -X- _ O
selecting -X- _ O
the -X- _ O
most -X- _ O
contributed -X- _ O
tokens -X- _ O
. -X- _ O
Fig- -X- _ O
ure -X- _ O
4 -X- _ O
illustrates -X- _ O
two -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
QNLI -X- _ B-DatasetName
datasets -X- _ O
in -X- _ O
which -X- _ O
CPs -X- _ B-MethodName
identify -X- _ O
and -X- _ O
gradually -X- _ O
drop -X- _ O
the -X- _ O
irrelevant -X- _ O
tokens -X- _ O
through -X- _ O
layers -X- _ O
, -X- _ O
finally -X- _ O
focusing -X- _ O
mostly -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
token -X- _ O
rep- -X- _ O
resentations -X- _ O
; -X- _ O
pedestrian -X- _ O
( -X- _ O
adjective -X- _ O
) -X- _ O
in -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
tesla -X- _ O
coil -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
part -X- _ O
of -X- _ O
QNLI -X- _ B-DatasetName
( -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
highly -X- _ O
aligned -X- _ O
with -X- _ O
human -X- _ O
rationale -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
AdapLeR -X- _ B-MethodName
’s -X- _ I-MethodName
CPs -X- _ I-MethodName
can -X- _ O
preserve -X- _ O
rationales -X- _ O
without -X- _ O
requiring -X- _ O
direct -X- _ O
human -X- _ O
annotations -X- _ O
in -X- _ O
an -X- _ O
unsuper-8 -X- _ O
vised -X- _ O
manner -X- _ O
we -X- _ O
carried -X- _ O
out -X- _ O
the -X- _ O
following -X- _ O
exper- -X- _ O
iment -X- _ O
. -X- _ O
To -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
trained -X- _ O
CPs -X- _ B-MethodName
in -X- _ O
predicting -X- _ O
human -X- _ O
rationales -X- _ O
we -X- _ O
computed -X- _ O
the -X- _ O
output -X- _ O
scores -X- _ O
of -X- _ O
CPs -X- _ B-MethodName
in -X- _ O
AdapLeR -X- _ B-MethodName
for -X- _ O
each -X- _ O
to- -X- _ O
ken -X- _ O
representation -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
Movie -X- _ O
Review -X- _ O
dataset -X- _ O
and -X- _ O
computed -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
raw -X- _ O
attention -X- _ O
, -X- _ O
attention -X- _ O
roll- -X- _ O
out -X- _ O
, -X- _ O
and -X- _ O
saliency -X- _ O
scores -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
represen- -X- _ O
tation -X- _ O
. -X- _ O
Since -X- _ O
human -X- _ O
rationales -X- _ O
are -X- _ O
annotated -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
level -X- _ O
, -X- _ O
we -X- _ O
sum -X- _ O
the -X- _ O
scores -X- _ O
across -X- _ O
tokens -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
arrive -X- _ O
at -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
importance -X- _ O
scores -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
these -X- _ O
soft -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
uniform -X- _ O
- -X- _ O
level -X- _ O
threshold -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
/ -X- _ O
) -X- _ O
to -X- _ O
reach -X- _ O
a -X- _ O
binary -X- _ O
score -X- _ O
indicating -X- _ O
tokens -X- _ O
selected -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
. -X- _ O
As -X- _ O
for -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
Average -X- _ B-MetricName
Precision -X- _ I-MetricName
( -X- _ O
AP -X- _ B-MetricName
) -X- _ O
and -X- _ O
False -X- _ B-MetricName
Positive -X- _ I-MetricName
Rate -X- _ I-MetricName
( -X- _ O
FPR -X- _ B-MetricName
) -X- _ O
metrics -X- _ O
by -X- _ O
com- -X- _ O
paring -X- _ O
the -X- _ O
remaining -X- _ O
tokens -X- _ O
to -X- _ O
the -X- _ O
human -X- _ O
rationale -X- _ O
annotations -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
metric -X- _ O
measures -X- _ O
whether -X- _ O
the -X- _ O
model -X- _ O
assigns -X- _ O
higher -X- _ O
continuous -X- _ O
scores -X- _ O
to -X- _ O
those -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
annotated -X- _ O
by -X- _ O
humans -X- _ O
as -X- _ O
rationales -X- _ O
. -X- _ O
Whereas -X- _ O
, -X- _ O
the -X- _ O
intuition -X- _ O
behind -X- _ O
the -X- _ O
second -X- _ O
metric -X- _ O
is -X- _ O
how -X- _ O
many -X- _ O
irrelevant -X- _ O
tokens -X- _ O
are -X- _ O
selected -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
passed -X- _ O
to -X- _ O
subsequent -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
soft -X- _ O
scores -X- _ O
for -X- _ O
computing -X- _ O
AP -X- _ B-MetricName
and -X- _ O
binary -X- _ O
scores -X- _ O
for -X- _ O
computing -X- _ O
FPR -X- _ B-MetricName
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
agreement -X- _ O
between -X- _ O
human -X- _ O
rationales -X- _ O
and -X- _ O
the -X- _ O
selected -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
widely -X- _ O
used -X- _ O
strategies -X- _ O
for -X- _ O
selecting -X- _ O
important -X- _ O
tokens -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
salinecy -X- _ O
and -X- _ O
attention -X- _ O
, -X- _ O
our -X- _ O
CPs -X- _ B-MethodName
have -X- _ O
signifi- -X- _ O
cantly -X- _ O
less -X- _ O
false -X- _ O
positive -X- _ O
rate -X- _ O
in -X- _ O
preserving -X- _ O
ratio -X- _ O
- -X- _ O
nales -X- _ O
through -X- _ O
layers -X- _ O
. -X- _ O
Despite -X- _ O
having -X- _ O
similar -X- _ O
FPRs -X- _ B-MetricName
at -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
, -X- _ O
CP -X- _ B-MethodName
is -X- _ O
preferable -X- _ O
to -X- _ O
attention -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
better -X- _ O
identify -X- _ O
rationales -X- _ O
at -X- _ O
the -X- _ O
earlier -X- _ O
layers -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
token -X- _ O
representations -X- _ O
when -X- _ O
building -X- _ O
the -X- _ O
final -X- _ O
one -X- _ O
. -X- _ O
This -X- _ O
in -X- _ O
turn -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
performance -X- _ O
, -X- _ O
as -X- _ O
was -X- _ O
also -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
experiment -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
curve -X- _ O
of -X- _ O
mAP -X- _ B-MetricName
for -X- _ O
saliency -X- _ O
is -X- _ O
consistently -X- _ O
higher -X- _ O
than -X- _ O
other -X- _ O
strategies -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
alignment -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
which -X- _ O
supports -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
saliency -X- _ O
as -X- _ O
a -X- _ O
measure -X- _ O
for -X- _ O
token -X- _ O
importance -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
that -X- _ O
attempts -X- _ O
at -X- _ O
guiding -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
human- -X- _ O
like -X- _ O
reasoning -X- _ O
by -X- _ O
training -X- _ O
rationale -X- _ O
generation -X- _ O
si- -X- _ O
multaneously -X- _ O
with -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
that -X- _ O
requires -X- _ O
hu- -X- _ O
man -X- _ O
annotation -X- _ O
( -X- _ O
Atanasova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
by -X- _ O
- -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
contribution -X- _ O
estimation -X- _ O
process -X- _ O
, -X- _ O
our -X- _ O
trained -X- _ O
CPs -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
these -X- _ O
rationales -X- _ O
at -X- _ O
inference -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
human -X- _ O
- -X- _ O
generated -X- _ O
annotations -X- _ O
. -X- _ O
6 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
AdapLeR -X- _ B-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
method -X- _ O
that -X- _ O
accelerates -X- _ O
inference -X- _ O
by -X- _ O
dynamically -X- _ O
identifying -X- _ O
and -X- _ O
dropping -X- _ O
less -X- _ O
contributing -X- _ O
token -X- _ O
representations -X- _ O
through -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
mod- -X- _ O
els -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
AdapLeR -X- _ O
accomplishes -X- _ O
this -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
Contribution -X- _ B-MethodName
Predictors -X- _ I-MethodName
based -X- _ O
on -X- _ O
saliencies -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
model -X- _ O
and -X- _ O
applying -X- _ O
a -X- _ O
gradual -X- _ O
masking -X- _ O
technique -X- _ O
to -X- _ O
simulate -X- _ O
input -X- _ O
- -X- _ O
adaptive -X- _ O
token -X- _ O
removal -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
Em- -X- _ O
pirical -X- _ O
results -X- _ O
on -X- _ O
eight -X- _ O
diverse -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
show -X- _ O
considerable -X- _ O
improvements -X- _ O
over -X- _ O
exist- -X- _ O
ing -X- _ O
methods -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
demonstrated -X- _ O
that -X- _ O
contribution -X- _ O
predictors -X- _ O
generate -X- _ O
rationales -X- _ O
that -X- _ O
are -X- _ O
highly -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
those -X- _ O
manually -X- _ O
specified -X- _ O
by -X- _ O
humans -X- _ O
. -X- _ O
As -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
apply -X- _ O
our -X- _ O
technique -X- _ O
to -X- _ O
more -X- _ O
tasks -X- _ O
and -X- _ O
see -X- _ O
whether -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
those -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
all -X- _ O
token -X- _ O
rep- -X- _ O
resentations -X- _ O
to -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
combining -X- _ O
our -X- _ O
width -X- _ O
- -X- _ O
based -X- _ O
strategy -X- _ O
with -X- _ O
a -X- _ O
depth- -X- _ O
based -X- _ O
one -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
early -X- _ O
exiting -X- _ O
) -X- _ O
might -X- _ O
potentially -X- _ O
yield -X- _ O
greater -X- _ O
efficiency -X- _ O
, -X- _ O
something -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
pur- -X- _ O
sue -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Broader -X- _ O
Impact -X- _ O
Using -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
use -X- _ O
fewer -X- _ O
FLOPs -X- _ O
, -X- _ O
reducing -X- _ O
energy -X- _ O
use -X- _ O
and -X- _ O
carbon -X- _ O
emissions -X- _ O
( -X- _ O
Schwartz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
.9References101112 -X- _ O
A -X- _ O
Inclusive -X- _ O
KL -X- _ O
Loss -X- _ O
Consideration -X- _ O
We -X- _ O
opted -X- _ O
for -X- _ O
an -X- _ O
inclusive -X- _ O
KL -X- _ O
loss -X- _ O
since -X- _ O
CPs -X- _ O
should -X- _ O
be -X- _ O
trained -X- _ O
to -X- _ O
cover -X- _ O
all -X- _ O
tokens -X- _ O
considered -X- _ O
important -X- _ O
by -X- _ O
saliency -X- _ O
and -X- _ O
not -X- _ O
to -X- _ O
be -X- _ O
mode -X- _ O
seeking -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
cover- -X- _ O
ing -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
high -X- _ O
contributing -X- _ O
tokens -X- _ O
considered -X- _ O
by -X- _ O
the -X- _ O
saliency -X- _ O
scores -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
Suppose -X- _ O
an -X- _ O
exclusive -X- _ O
KL -X- _ O
is -X- _ O
selected -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
limited -X- _ O
learning -X- _ O
capacity -X- _ O
of -X- _ O
the -X- _ O
CP -X- _ B-MethodName
and -X- _ O
miscalculation -X- _ O
possibility -X- _ O
from -X- _ O
the -X- _ O
saliency -X- _ O
, -X- _ O
the -X- _ O
CP -X- _ B-MethodName
may -X- _ O
be -X- _ O
trained -X- _ O
to -X- _ O
maximize -X- _ O
its -X- _ O
contribution -X- _ O
on -X- _ O
noninformative -X- _ O
tokens -X- _ O
. -X- _ O
While -X- _ O
in -X- _ O
an -X- _ O
inclusive -X- _ O
setting -X- _ O
, -X- _ O
it -X- _ O
trains -X- _ O
to -X- _ O
extend -X- _ O
its -X- _ O
coverage -X- _ O
over -X- _ O
all -X- _ O
high -X- _ O
- -X- _ O
saliency -X- _ O
tokens -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
initial -X- _ O
research -X- _ O
indicated -X- _ O
that -X- _ O
using -X- _ O
a -X- _ O
symmetric -X- _ O
loss -X- _ O
( -X- _ O
e.g. -X- _ O
Jensen -X- _ O
- -X- _ O
Shannon -X- _ O
di- -X- _ O
vergence -X- _ O
) -X- _ O
would -X- _ O
produce -X- _ O
similar -X- _ O
results -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
significantly -X- _ O
longer -X- _ O
convergence -X- _ O
time -X- _ O
. -X- _ O
B -X- _ O
Optimization -X- _ O
of -X- _ O
θ -X- _ O
In -X- _ O
Section -X- _ O
3.3 -X- _ O
, -X- _ O
we -X- _ O
introduced -X- _ O
θas -X- _ O
a -X- _ O
trainable -X- _ O
pa- -X- _ O
rameter -X- _ O
that -X- _ O
increases -X- _ O
the -X- _ O
saliency -X- _ O
score -X- _ O
of -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
deduce -X- _ O
from -X- _ O
Equations -X- _ O
6 -X- _ O
and -X- _ O
7 -X- _ O
that -X- _ O
this -X- _ O
pa- -X- _ O
rameter -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
computational -X- _ O
DAG -X- _ O
and -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
derivative -X- _ O
of -X- _ O
˜S -X- _ O
w.r.t -X- _ O
. -X- _ O
θto -X- _ O
train -X- _ O
this -X- _ O
parameter -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
first -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
˜Sis -X- _ O
a -X- _ O
close -X- _ O
estimate -X- _ O
of -X- _ O
ˆS -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
CPs -X- _ O
’ -X- _ O
training -X- _ O
objective -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
dummy -X- _ O
variable -X- _ O
θ -X- _ O
— -X- _ O
that -X- _ O
is -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
computational -X- _ O
graph -X- _ O
and -X- _ O
is -X- _ O
always -X- _ O
equal -X- _ O
to -X- _ O
1 -X- _ O
— -X- _ O
we -X- _ O
reformulate -X- _ O
˜S -X- _ O
: -X- _ O
ˆS≈˜S -X- _ O
= -X- _ O
θ˜S1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
+ -X- _ O
˜S1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
θ˜S+P˜S -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
This -X- _ O
reformulation -X- _ O
is -X- _ O
valid -X- _ O
due -X- _ O
to -X- _ O
θ= -X- _ O
1 -X- _ O
andP˜S= -X- _ O
1 -X- _ O
. -X- _ O
Now -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
partial -X- _ O
deriva- -X- _ O
tive -X- _ O
w.r.t -X- _ O
. -X- _ O
θwhich -X- _ O
is -X- _ O
the -X- _ O
gradient -X- _ O
that -X- _ O
is -X- _ O
computed -X- _ O
in -X- _ O
the -X- _ O
backpropagation -X- _ O
: -X- _ O
∂˜S -X- _ O
∂θ=˜S -X- _ O
( -X- _ O
P˜S1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
−˜S1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
) -X- _ O
( -X- _ O
θ˜S+P˜S -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
By -X- _ O
knowing -X- _ O
that -X- _ O
θ= -X- _ O
1 -X- _ O
: -X- _ O
∂˜S -X- _ O
∂θ=˜S -X- _ O
( -X- _ O
( -X- _ O
1−˜S -X- _ O
) -X- _ O
1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
−˜S1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
Now -X- _ O
using -X- _ O
our -X- _ O
initial -X- _ O
assumption -X- _ O
( -X- _ O
ˆS≈˜S -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
substitute -X- _ O
˜Swith -X- _ O
ˆSbased -X- _ O
on -X- _ O
Equation -X- _ O
7 -X- _ O
: -X- _ O
∂˜S -X- _ O
∂θ=ˆS -X- _ O
( -X- _ O
( -X- _ O
1−ˆS -X- _ O
) -X- _ O
1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
−ˆS1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
) -X- _ O
= -X- _ O
θS -X- _ O
( -X- _ O
PS1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
−S1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
) -X- _ O
( -X- _ O
θS+PS -X- _ O
) -X- _ O
( -X- _ O
12 -X- _ O
) -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
of -X- _ O
ˆSw.r.t -X- _ O
. -X- _ O
θis -X- _ O
as -X- _ O
follows -X- _ O
( -X- _ O
cf -X- _ O
. -X- _ O
Equation -X- _ O
7 -X- _ O
) -X- _ O
: -X- _ O
∂ˆS -X- _ O
∂θ -X- _ O
= -X- _ O
S -X- _ O
( -X- _ O
PS1 -X- _ O
[ -X- _ O
i= -X- _ O
1 -X- _ O
] -X- _ O
−S1 -X- _ O
[ -X- _ O
i -X- _ O
> -X- _ O
1 -X- _ O
] -X- _ O
) -X- _ O
( -X- _ O
θS+PS -X- _ O
) -X- _ O
( -X- _ O
13 -X- _ O
) -X- _ O
By -X- _ O
comparing -X- _ O
Equations -X- _ O
12 -X- _ O
and -X- _ O
13 -X- _ O
, -X- _ O
these -X- _ O
deriva- -X- _ O
tives -X- _ O
are -X- _ O
related -X- _ O
with -X- _ O
a -X- _ O
term -X- _ O
of -X- _ O
θ -X- _ O
: -X- _ O
∂ˆS -X- _ O
∂θ≈∂˜S -X- _ O
∂θ=1 -X- _ O
θ∂˜S -X- _ O
∂θ -X- _ O
( -X- _ O
14 -X- _ O
) -X- _ O
13Therefore -X- _ O
, -X- _ O
during -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
compute -X- _ O
the -X- _ O
gradient -X- _ O
w.r.t -X- _ O
. -X- _ O
the -X- _ O
dummy -X- _ O
variable -X- _ O
θand -X- _ O
then -X- _ O
divide -X- _ O
it -X- _ O
by -X- _ O
θ -X- _ O
. -X- _ O
C -X- _ O
Evaluating -X- _ O
PoWER -X- _ O
- -X- _ O
BERT -X- _ O
in -X- _ O
Single -X- _ O
Instance -X- _ O
Mode -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
static -X- _ O
structure -X- _ O
of -X- _ O
PoWER -X- _ O
- -X- _ O
BERT -X- _ O
, -X- _ O
the -X- _ O
speedup -X- _ O
ratios -X- _ O
reported -X- _ O
in -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
wall -X- _ O
time -X- _ O
acceleration -X- _ O
with -X- _ O
batch -X- _ O
- -X- _ O
wise -X- _ O
inference -X- _ O
procedure -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
some -X- _ O
inputs -X- _ O
might -X- _ O
need -X- _ O
extra -X- _ O
padding -X- _ O
to -X- _ O
make -X- _ O
all -X- _ O
inputs -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
token -X- _ O
length -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
our -X- _ O
ap- -X- _ O
proach -X- _ O
and -X- _ O
other -X- _ O
dynamic -X- _ O
approaches -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
single -X- _ O
instance -X- _ O
inference -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
procedure -X- _ O
in- -X- _ O
puts -X- _ O
are -X- _ O
fed -X- _ O
without -X- _ O
being -X- _ O
padded -X- _ O
. -X- _ O
To -X- _ O
even -X- _ O
out -X- _ O
this -X- _ O
discrepancy -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
single -X- _ O
instance -X- _ O
flops -X- _ O
computation -X- _ O
on -X- _ O
the -X- _ O
PoWER -X- _ O
- -X- _ O
BERT -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
computational -X- _ O
cost -X- _ O
for -X- _ O
all -X- _ O
input -X- _ O
lengths -X- _ O
that -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
dataset -X- _ O
. -X- _ O
Some -X- _ O
in- -X- _ O
stnaces -X- _ O
may -X- _ O
have -X- _ O
shorter -X- _ O
input -X- _ O
length -X- _ O
than -X- _ O
some -X- _ O
values -X- _ O
in -X- _ O
the -X- _ O
resulting -X- _ O
retention -X- _ O
configuration -X- _ O
( -X- _ O
num- -X- _ O
ber -X- _ O
of -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
retained -X- _ O
in -X- _ O
each -X- _ O
layer -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
update -X- _ O
the -X- _ O
retention -X- _ O
con- -X- _ O
figuration -X- _ O
by -X- _ O
selecting -X- _ O
the -X- _ O
minimum -X- _ O
between -X- _ O
the -X- _ O
input -X- _ O
length -X- _ O
and -X- _ O
each -X- _ O
layers -X- _ O
’ -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
re- -X- _ O
tained -X- _ O
, -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
new -X- _ O
retention -X- _ O
configuration -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
length -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
retention -X- _ O
con- -X- _ O
figuration -X- _ O
trained -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
task -X- _ O
be -X- _ O
( -X- _ O
153 -X- _ O
, -X- _ O
125 -X- _ O
, -X- _ O
111 -X- _ O
, -X- _ O
105 -X- _ O
, -X- _ O
85 -X- _ O
, -X- _ O
80 -X- _ O
, -X- _ O
72 -X- _ O
, -X- _ O
48 -X- _ O
, -X- _ O
35 -X- _ O
, -X- _ O
27 -X- _ O
, -X- _ O
22 -X- _ O
, -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
an -X- _ O
input -X- _ O
with -X- _ O
75 -X- _ O
tokens -X- _ O
length -X- _ O
, -X- _ O
the -X- _ O
new -X- _ O
configuration -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
speedup -X- _ O
computation -X- _ O
will -X- _ O
be -X- _ O
: -X- _ O
( -X- _ O
75 -X- _ O
, -X- _ O
75 -X- _ O
, -X- _ O
75 -X- _ O
, -X- _ O
75 -X- _ O
, -X- _ O
75 -X- _ O
, -X- _ O
75 -X- _ O
, -X- _ O
72 -X- _ O
, -X- _ O
48 -X- _ O
, -X- _ O
35 -X- _ O
, -X- _ O
27 -X- _ O
, -X- _ O
22 -X- _ O
, -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
D -X- _ O
AdapLeR -X- _ O
Training -X- _ O
Hyperparameters -X- _ O
For -X- _ O
the -X- _ O
initial -X- _ O
step -X- _ O
of -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
hyperparameters -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
training -X- _ O
with -X- _ O
length -X- _ O
reduction -X- _ O
, -X- _ O
we -X- _ O
employed -X- _ O
an -X- _ O
AdamW -X- _ O
optimizer -X- _ O
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
weight -X- _ O
decay -X- _ O
rate -X- _ O
of -X- _ O
0.1 -X- _ O
, -X- _ O
warmup -X- _ O
proportion -X- _ O
6 -X- _ O
% -X- _ O
of -X- _ O
total -X- _ O
training -X- _ O
steps -X- _ O
and -X- _ O
a -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
decay -X- _ O
which -X- _ O
reaches -X- _ O
to -X- _ O
zero -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
adaptive -X- _ O
length -X- _ O
reduction -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
with -X- _ O
two -X- _ O
differences -X- _ O
: -X- _ O
Since -X- _ O
MRPC -X- _ O
and -X- _ O
CoLA -X- _ O
have -X- _ O
small -X- _ O
training -X- _ O
sets -X- _ O
, -X- _ O
to -X- _ O
prolong -X- _ O
the -X- _ O
gradual -X- _ O
soft- -X- _ O
removal -X- _ O
process -X- _ O
, -X- _ O
we -X- _ O
increased -X- _ O
the -X- _ O
training -X- _ O
duration -X- _ O
to -X- _ O
10 -X- _ O
epochs -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
to -X- _ O
3e-5 -X- _ O
. -X- _ O
Other -X- _ O
hyperparameters -X- _ O
are -X- _ O
stated -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
To -X- _ O
set -X- _ O
a -X- _ O
trend -X- _ O
for -X- _ O
λ -X- _ O
, -X- _ O
it -X- _ O
needs -X- _ O
to -X- _ O
start -X- _ O
from -X- _ O
a -X- _ O
small -X- _ O
but -X- _ O
effective -X- _ O
value -X- _ O
( -X- _ O
10 -X- _ O
< -X- _ O
λ -X- _ O
< -X- _ O
100 -X- _ O
) -X- _ O
and -X- _ O
grow -X- _ O
exponentially -X- _ O
per -X- _ O
each -X- _ O
epoch -X- _ O
to -X- _ O
reach -X- _ O
an -X- _ O
ex- -X- _ O
tremely -X- _ O
high -X- _ O
amount -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
to -X- _ O
mimic -X- _ O
a -X- _ O
hard -X- _ O
removal -X- _ O
function -X- _ O
( -X- _ O
1e+5 -X- _ O
< -X- _ O
λ -X- _ O
) -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
datasets -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
epochs -X- _ O
have -X- _ O
similar -X- _ O
λtrends -X- _ O
. -X- _ O
E -X- _ O
Statistics -X- _ O
of -X- _ O
Datasets -X- _ O
F -X- _ O
Additional -X- _ O
Qualitative -X- _ O
Examples1415 -X- _ O

This -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
focuses -X- _ SUMMARY
on -X- _ SUMMARY
evaluating -X- _ SUMMARY
the -X- _ SUMMARY
faithfulness -X- _ SUMMARY
of -X- _ SUMMARY
abstractive -X- _ SUMMARY
summarization -X- _ SUMMARY
systems -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
propose -X- _ SUMMARY
a -X- _ SUMMARY
framework -X- _ SUMMARY
for -X- _ SUMMARY
evaluating -X- _ SUMMARY
the -X- _ SUMMARY
effective -X- _ SUMMARY
faithfulness -X- _ SUMMARY
of -X- _ SUMMARY
summarization -X- _ SUMMARY
systems -X- _ SUMMARY
by -X- _ SUMMARY
generating -X- _ SUMMARY
a -X- _ SUMMARY
trade -X- _ SUMMARY
- -X- _ SUMMARY
off -X- _ SUMMARY
curve -X- _ SUMMARY
between -X- _ SUMMARY
faithfulness -X- _ SUMMARY
and -X- _ SUMMARY
abstractiveness -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
recent -X- _ SUMMARY
methods -X- _ SUMMARY
for -X- _ SUMMARY
improving -X- _ SUMMARY
faithfulness -X- _ SUMMARY
mainly -X- _ SUMMARY
rely -X- _ SUMMARY
on -X- _ SUMMARY
increased -X- _ SUMMARY
extractiveness -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
then -X- _ SUMMARY
propose -X- _ SUMMARY
a -X- _ SUMMARY
system -X- _ SUMMARY
that -X- _ SUMMARY
can -X- _ SUMMARY
select -X- _ SUMMARY
the -X- _ SUMMARY
most -X- _ SUMMARY
abstractive -X- _ SUMMARY
and -X- _ SUMMARY
faithful -X- _ SUMMARY
summary -X- _ SUMMARY
from -X- _ SUMMARY
a -X- _ SUMMARY
set -X- _ SUMMARY
of -X- _ SUMMARY
candidate -X- _ SUMMARY
summaries -X- _ SUMMARY
. -X- _ SUMMARY
This -X- _ SUMMARY
system -X- _ SUMMARY
outperforms -X- _ SUMMARY
the -X- _ SUMMARY
baseline -X- _ SUMMARY
system -X- _ SUMMARY
in -X- _ SUMMARY
terms -X- _ SUMMARY
of -X- _ SUMMARY
both -X- _ SUMMARY
abstractiveness -X- _ SUMMARY
and -X- _ SUMMARY
faithfulness -X- _ SUMMARY
on -X- _ SUMMARY
two -X- _ SUMMARY
datasets -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
also -X- _ SUMMARY
introduce -X- _ SUMMARY
a -X- _ SUMMARY
selector -X- _ SUMMARY
model -X- _ SUMMARY
that -X- _ SUMMARY
achieves -X- _ SUMMARY
better -X- _ SUMMARY
effective -X- _ SUMMARY
faithfulness -X- _ SUMMARY
than -X- _ SUMMARY
the -X- _ SUMMARY
baseline -X- _ SUMMARY
model -X- _ SUMMARY
and -X- _ SUMMARY
other -X- _ SUMMARY
existing -X- _ SUMMARY
methods -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
study -X- _ SUMMARY
is -X- _ SUMMARY
conducted -X- _ SUMMARY
on -X- _ SUMMARY
two -X- _ SUMMARY
English -X- _ SUMMARY
abstractive -X- _ SUMMARY
summarization -X- _ SUMMARY
datasets -X- _ SUMMARY
, -X- _ SUMMARY
Gigaword -X- _ SUMMARY
and -X- _ SUMMARY
Wikihow -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
to -X- _ SUMMARY
evaluate -X- _ SUMMARY
faithfulness -X- _ SUMMARY
include -X- _ SUMMARY
coverage -X- _ SUMMARY
and -X- _ SUMMARY
density -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
results -X- _ SUMMARY
show -X- _ SUMMARY
a -X- _ SUMMARY
positive -X- _ SUMMARY
correlation -X- _ SUMMARY
between -X- _ SUMMARY
extractiveness -X- _ SUMMARY
and -X- _ SUMMARY
faithfulness -X- _ SUMMARY
scores -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
concludes -X- _ SUMMARY
by -X- _ SUMMARY
discussing -X- _ SUMMARY
the -X- _ SUMMARY
implications -X- _ SUMMARY
and -X- _ SUMMARY
limitations -X- _ SUMMARY
of -X- _ SUMMARY
the -X- _ SUMMARY
study -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.100.txt -X- _ O
Faisal -X- _ O
LadhakEsin -X- _ O
DurmusHe -X- _ O
HeClaire -X- _ O
CardieKathleen -X- _ O
McKeownColumbia -X- _ O
UniversityStanford -X- _ O
UniversityNew -X- _ O
York -X- _ O
UniversityCornell -X- _ O
University -X- _ O
Abstract -X- _ O
Despite -X- _ O
recent -X- _ O
progress -X- _ O
in -X- _ O
abstractive -X- _ B-TaskName
summa- -X- _ I-TaskName
rization -X- _ I-TaskName
, -X- _ O
systems -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
faithfulness -X- _ O
errors -X- _ O
. -X- _ O
While -X- _ O
prior -X- _ O
work -X- _ O
has -X- _ O
proposed -X- _ O
models -X- _ O
that -X- _ O
improve -X- _ O
faithfulness -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
whether -X- _ O
the -X- _ O
improvement -X- _ O
comes -X- _ O
from -X- _ O
an -X- _ O
increased -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
outputs -X- _ O
as -X- _ O
one -X- _ O
naive -X- _ O
way -X- _ O
to -X- _ O
improve -X- _ O
faithfulness -X- _ O
is -X- _ O
to -X- _ O
make -X- _ O
summarization -X- _ O
models -X- _ O
more -X- _ O
extrac- -X- _ O
tive -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
framework -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
effective -X- _ O
faithfulness -X- _ O
of -X- _ O
summa- -X- _ O
rization -X- _ O
systems -X- _ O
, -X- _ O
by -X- _ O
generating -X- _ O
a -X- _ O
faithfulness- -X- _ B-HyperparameterValue
abstractiveness -X- _ B-HyperparameterValue
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
that -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
control -X- _ O
at -X- _ O
different -X- _ O
operating -X- _ O
points -X- _ O
on -X- _ O
the -X- _ O
ab- -X- _ O
stractiveness -X- _ O
spectrum -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
baseline -X- _ O
system -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
recently -X- _ O
proposed -X- _ O
methods -X- _ O
for -X- _ O
improving -X- _ O
faithfulness -X- _ B-HyperparameterValue
, -X- _ O
fail -X- _ O
to -X- _ O
con- -X- _ O
sistently -X- _ O
improve -X- _ O
over -X- _ O
the -X- _ O
control -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
abstractiveness -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
learn -X- _ O
a -X- _ O
selector -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
most -X- _ O
faithful -X- _ O
and -X- _ O
ab- -X- _ O
stractive -X- _ O
summary -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
document -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
system -X- _ O
can -X- _ O
attain -X- _ O
higher -X- _ O
faith- -X- _ B-MetricName
fulness -X- _ I-MetricName
scores -X- _ O
in -X- _ O
human -X- _ O
evaluations -X- _ O
while -X- _ O
be- -X- _ O
ing -X- _ O
more -X- _ O
abstractive -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
system -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
better -X- _ O
faithfulness- -X- _ B-MetricName
abstractiveness -X- _ B-MetricName
trade -X- _ O
- -X- _ O
off -X- _ O
than -X- _ O
the -X- _ O
control -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
abstractiveness -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Generating -X- _ O
abstractive -X- _ O
summaries -X- _ O
of -X- _ O
documents -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
long -X- _ O
- -X- _ O
standing -X- _ O
goal -X- _ O
of -X- _ O
summarization -X- _ B-TaskName
. -X- _ O
While -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
tremendous -X- _ O
progress -X- _ O
towards -X- _ O
this -X- _ O
goal -X- _ O
( -X- _ O
Kry -X- _ O
´ -X- _ O
sci´nski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
systems -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
faithful- -X- _ B-MetricName
ness -X- _ I-MetricName
errors -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
generating -X- _ O
informa- -X- _ O
tion -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
an -X- _ O
increased -X- _ O
research -X- _ O
in -X- _ O
faithfulness -X- _ B-MetricName
evalua- -X- _ O
tion -X- _ O
of -X- _ O
summarization -X- _ O
systems -X- _ O
( -X- _ O
Falke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Durmus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
aswell -X- _ O
as -X- _ O
methods -X- _ O
to -X- _ O
improve -X- _ O
faithfulness -X- _ O
of -X- _ O
gen- -X- _ O
erated -X- _ O
summaries -X- _ O
( -X- _ O
Kang -X- _ O
and -X- _ O
Hashimoto -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
one -X- _ O
straightfor- -X- _ O
ward -X- _ O
way -X- _ O
of -X- _ O
improving -X- _ O
faithfulness -X- _ O
of -X- _ O
generated -X- _ O
summaries -X- _ O
is -X- _ O
to -X- _ O
copy -X- _ O
a -X- _ O
larger -X- _ O
amount -X- _ O
of -X- _ O
content -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
( -X- _ O
i.e. -X- _ O
more -X- _ O
extraction -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
any -X- _ O
methods -X- _ O
that -X- _ O
increase -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
extractive- -X- _ O
ness -X- _ O
, -X- _ O
whether -X- _ O
intentionally -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
would -X- _ O
improve -X- _ O
faithfulness -X- _ B-MetricName
. -X- _ O
Without -X- _ O
reported -X- _ O
extractiveness -X- _ B-MetricName
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
whether -X- _ O
prior -X- _ O
improvements -X- _ O
mainly -X- _ O
arise -X- _ O
from -X- _ O
increased -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
progress -X- _ O
in -X- _ O
abstractive -X- _ O
summariza- -X- _ O
tion -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
tease -X- _ O
apart -X- _ O
faithfulness -X- _ B-MetricName
im- -X- _ O
provements -X- _ O
due -X- _ O
to -X- _ O
increased -X- _ O
extractiveness -X- _ B-MetricName
versus -X- _ O
improvements -X- _ O
due -X- _ O
to -X- _ O
improved -X- _ O
abstraction -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
tease -X- _ O
this -X- _ O
apart -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
frame- -X- _ O
work -X- _ O
for -X- _ O
evaluating -X- _ O
progress -X- _ O
in -X- _ O
faithfulness -X- _ B-MetricName
, -X- _ O
by -X- _ O
con- -X- _ O
sidering -X- _ O
the -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
, -X- _ O
i.e. -X- _ O
the -X- _ O
improve- -X- _ O
ment -X- _ O
in -X- _ O
faithfulness -X- _ B-MetricName
over -X- _ O
a -X- _ O
baseline -X- _ O
system -X- _ O
( -X- _ O
con- -X- _ O
trol -X- _ O
) -X- _ O
operating -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
training -X- _ O
examples -X- _ O
into -X- _ O
dif- -X- _ O
ferent -X- _ O
groups -X- _ O
by -X- _ O
the -X- _ O
extractiveness -X- _ B-MetricName
of -X- _ O
the -X- _ O
summary -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
control -X- _ O
models -X- _ O
on -X- _ O
each -X- _ O
group -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
corresponds -X- _ O
to -X- _ O
a -X- _ O
speciﬁc -X- _ O
tradeoff -X- _ O
between -X- _ O
abstractiveness -X- _ B-MetricName
and -X- _ O
faithfulness -X- _ B-MetricName
, -X- _ O
forming -X- _ O
atrade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
indicating -X- _ O
how -X- _ O
much -X- _ O
faithfulness -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
solely -X- _ O
by -X- _ O
increasing -X- _ O
extractive- -X- _ O
ness -X- _ O
. -X- _ O
Systems -X- _ O
that -X- _ O
improve -X- _ O
effective -X- _ O
faithfulness -X- _ O
should -X- _ O
lie -X- _ O
above -X- _ O
this -X- _ O
curve -X- _ O
. -X- _ O
Using -X- _ O
this -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
im- -X- _ O
proved -X- _ O
faithfulness -X- _ B-MetricName
of -X- _ O
recently -X- _ O
proposed -X- _ O
methods -X- _ O
comes -X- _ O
mainly -X- _ O
from -X- _ O
an -X- _ O
increased -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
We -X- _ O
then -X- _ O
conduct -X- _ O
further -X- _ O
analysis -X- _ O
to -X- _ O
explore -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
system -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
both -X- _ O
more -X- _ O
abstractive -X- _ O
and -X- _ O
more -X- _ O
faithful -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
sys- -X- _ O
tem -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
a -X- _ O
selector -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
human- -X- _ O
annotated -X- _ O
data -X- _ O
that -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
output -X- _ O
summaries -X- _ O
with -X- _ O
varying -X- _ O
levels -X- _ O
of -X- _ O
extractiveness -X- _ O
, -X- _ O
picks -X- _ O
the -X- _ O
most -X- _ O
abstractive -X- _ O
output -X- _ O
that -X- _ O
is -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
system -X- _ O
is -X- _ O
both -X- _ O
more -X- _ O
abstractive -X- _ O
and -X- _ O
more -X- _ O
faithful -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that1410 -X- _ O
our -X- _ O
system -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
effective -X- _ O
faithful- -X- _ B-MetricName
ness -X- _ I-MetricName
, -X- _ O
achieving -X- _ O
a -X- _ O
better -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
than -X- _ O
the -X- _ O
control -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
point -X- _ O
on -X- _ O
the -X- _ O
abstractiveness -X- _ O
spectrum -X- _ O
. -X- _ O
To -X- _ O
summarize -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1.We -X- _ O
present -X- _ O
a -X- _ O
framework -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
progress -X- _ O
in -X- _ O
improving -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
of -X- _ O
models -X- _ O
considering -X- _ O
the -X- _ O
control -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ O
. -X- _ O
2.We -X- _ O
illustrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
considering -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
by -X- _ O
showing -X- _ O
that -X- _ O
recently -X- _ O
proposed -X- _ O
methods -X- _ O
for -X- _ O
improving -X- _ O
faithfulness -X- _ B-MetricName
are -X- _ O
able -X- _ O
to -X- _ O
attain -X- _ O
higher -X- _ O
faithfulness -X- _ B-MetricName
scores -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
consistently -X- _ O
im- -X- _ O
prove -X- _ O
over -X- _ O
the -X- _ O
control -X- _ O
curve -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
their -X- _ O
improvements -X- _ O
come -X- _ O
from -X- _ O
gener- -X- _ O
ating -X- _ O
more -X- _ O
extractive -X- _ O
outputs -X- _ O
, -X- _ O
on -X- _ O
average -X- _ O
. -X- _ O
3.We -X- _ O
propose -X- _ O
a -X- _ O
selector -X- _ O
that -X- _ O
picks -X- _ O
the -X- _ O
most -X- _ O
abstractive -X- _ O
and -X- _ O
faithful -X- _ O
summary -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
possible -X- _ O
summaries -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
method -X- _ O
gets -X- _ O
higher -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
com- -X- _ O
pared -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
methods -X- _ O
. -X- _ O
2 -X- _ O
Dataset -X- _ O
We -X- _ O
conduct -X- _ O
our -X- _ O
study -X- _ O
on -X- _ O
two -X- _ O
English -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
datasets -X- _ O
, -X- _ O
one -X- _ O
from -X- _ O
the -X- _ O
news -X- _ O
domain -X- _ O
, -X- _ O
and -X- _ O
one -X- _ O
from -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
news -X- _ O
domain -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
news -X- _ O
do- -X- _ O
main -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
decided -X- _ O
against -X- _ O
using -X- _ O
the -X- _ O
popular -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
Dailymail -X- _ I-DatasetName
dataset -X- _ O
since -X- _ O
its -X- _ O
reference -X- _ O
sum- -X- _ O
maries -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
very -X- _ O
extractive -X- _ O
( -X- _ O
Kedzie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Bommasani -X- _ O
and -X- _ O
Cardie -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
a -X- _ O
poor -X- _ O
choice -X- _ O
for -X- _ O
studying -X- _ O
faithfulness -X- _ B-MetricName
in -X- _ O
abstrac- -X- _ O
tive -X- _ O
summarization -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
decided -X- _ O
against -X- _ O
using -X- _ O
XSum -X- _ B-DatasetName
, -X- _ O
another -X- _ O
popular -X- _ O
news -X- _ B-TaskName
summa- -X- _ I-TaskName
rization -X- _ I-TaskName
dataset -X- _ O
, -X- _ O
since -X- _ O
almost -X- _ O
77 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
ref- -X- _ O
erence -X- _ O
summaries -X- _ O
contain -X- _ O
hallucinations -X- _ O
( -X- _ O
Maynez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
Gigaword -X- _ B-DatasetName
and -X- _ O
Wikihow -X- _ B-DatasetName
, -X- _ O
which -X- _ O
are -X- _ O
datasets -X- _ O
with -X- _ O
substantial -X- _ O
ab- -X- _ O
straction -X- _ O
without -X- _ O
as -X- _ O
much -X- _ O
hallucination -X- _ O
problems -X- _ O
as -X- _ O
XSum -X- _ B-DatasetName
. -X- _ O
Gigaword -X- _ B-DatasetName
reference -X- _ O
summaries -X- _ O
have -X- _ O
substantially -X- _ O
less -X- _ O
hallucinations -X- _ O
than -X- _ O
XSum -X- _ B-DatasetName
( -X- _ O
Kang -X- _ O
and -X- _ O
Hashimoto -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
WikiHow -X- _ B-DatasetName
summaries -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
of -X- _ O
a -X- _ O
higher -X- _ O
quality -X- _ O
since -X- _ O
they -X- _ O
are -X- _ O
written -X- _ O
and -X- _ O
curated -X- _ O
by -X- _ O
humans -X- _ O
( -X- _ O
Koupaee -X- _ O
and -X- _ O
Wang -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ladhak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Wikihow -X- _ B-DatasetName
( -X- _ O
Koupaee -X- _ O
and -X- _ O
Wang -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
how -X- _ O
- -X- _ O
to -X- _ O
articles -X- _ O
covering -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
topics -X- _ O
, -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
wikihow.com -X- _ O
website -X- _ O
. -X- _ O
Each -X- _ O
article -X- _ O
contains -X- _ O
several -X- _ O
paragraphs -X- _ O
detailing -X- _ O
step -X- _ O
by -X- _ O
step -X- _ O
instructions -X- _ O
for -X- _ O
a -X- _ O
procedural -X- _ O
task -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
about -X- _ O
12 -X- _ O
M -X- _ O
such -X- _ O
paragraphs -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
paired -X- _ O
with -X- _ O
a -X- _ O
one -X- _ O
sentence -X- _ O
summary -X- _ O
. -X- _ O
Gigaword -X- _ B-DatasetName
( -X- _ O
Rush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
headline -X- _ O
gener- -X- _ O
ation -X- _ O
dataset -X- _ O
that -X- _ O
contains -X- _ O
around -X- _ O
4 -X- _ O
M -X- _ O
examples,1411extracted -X- _ O
from -X- _ O
news -X- _ O
articles -X- _ O
that -X- _ O
were -X- _ O
collected -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
Gigaword -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Graff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
tasked -X- _ O
with -X- _ O
generating -X- _ O
the -X- _ O
headline -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
given -X- _ O
the -X- _ O
ﬁrst -X- _ O
sentence -X- _ O
. -X- _ O
2.1 -X- _ O
Dataset -X- _ O
Extractiveness -X- _ B-MetricName
We -X- _ O
follow -X- _ O
the -X- _ O
process -X- _ O
detailed -X- _ O
by -X- _ O
Grusky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
extractive -X- _ O
fragment -X- _ O
coverage -X- _ O
and -X- _ O
extractive -X- _ O
fragment -X- _ O
density -X- _ O
as -X- _ O
the -X- _ O
measures -X- _ O
of -X- _ O
ex- -X- _ B-MetricName
tractiveness -X- _ I-MetricName
of -X- _ O
a -X- _ O
given -X- _ O
summary -X- _ O
. -X- _ O
Henceforth -X- _ O
we -X- _ O
will -X- _ O
refer -X- _ O
to -X- _ O
these -X- _ O
as -X- _ O
coverage -X- _ B-MetricName
and -X- _ O
density -X- _ B-MetricName
respec- -X- _ O
tively -X- _ O
. -X- _ O
Coverage -X- _ B-MetricName
is -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
summary -X- _ O
that -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
Density -X- _ B-MetricName
is -X- _ O
the -X- _ O
average -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
spans -X- _ O
copied -X- _ O
from -X- _ O
the -X- _ O
document -X- _ O
that -X- _ O
are -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
A -X- _ O
summary -X- _ O
that -X- _ O
copies -X- _ O
larger -X- _ O
chunks -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
will -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
density -X- _ B-MetricName
. -X- _ O
3 -X- _ O
Analysis -X- _ O
on -X- _ O
Metrics -X- _ O
of -X- _ O
Faithfulness -X- _ O
Recent -X- _ O
studies -X- _ O
of -X- _ O
faithfulness -X- _ B-MetricName
evaluation -X- _ O
have -X- _ O
pro- -X- _ O
posed -X- _ O
model -X- _ O
- -X- _ O
based -X- _ O
automated -X- _ O
metrics -X- _ O
to -X- _ O
detect -X- _ O
whether -X- _ O
a -X- _ O
given -X- _ O
summary -X- _ O
is -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Falke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
Entail- -X- _ O
ment -X- _ O
) -X- _ O
have -X- _ O
studied -X- _ O
using -X- _ O
pretrained -X- _ O
entailment -X- _ O
based -X- _ O
methods -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
gen- -X- _ O
erated -X- _ O
output -X- _ O
being -X- _ O
entailed -X- _ O
by -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
( -X- _ O
FactCC -X- _ O
) -X- _ O
augment -X- _ O
hallu- -X- _ O
cinated -X- _ O
summaries -X- _ O
by -X- _ O
applying -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
trans- -X- _ O
formations -X- _ O
to -X- _ O
the -X- _ O
document -X- _ O
sentences -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
model -X- _ O
to -X- _ O
classify -X- _ O
whether -X- _ O
the -X- _ O
gener- -X- _ O
ated -X- _ O
output -X- _ O
is -X- _ O
faithful -X- _ O
. -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
DAE -X- _ O
) -X- _ O
have -X- _ O
collected -X- _ O
ﬁne -X- _ O
- -X- _ O
grained -X- _ O
annotations -X- _ O
to -X- _ O
study -X- _ O
word- -X- _ O
, -X- _ O
dependency- -X- _ O
and -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
faith- -X- _ B-TaskName
fulness -X- _ I-TaskName
and -X- _ O
use -X- _ O
these -X- _ O
annotations -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
factual- -X- _ O
ity -X- _ O
detection -X- _ O
model -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
av- -X- _ O
erage -X- _ O
coverage -X- _ B-MetricName
of -X- _ O
the -X- _ O
generated -X- _ O
outputs -X- _ O
( -X- _ O
extrac- -X- _ B-MetricName
tiveness -X- _ I-MetricName
) -X- _ O
vs. -X- _ O
average -X- _ B-MetricName
metric -X- _ I-MetricName
scores -X- _ I-MetricName
( -X- _ O
faithfulness -X- _ B-MetricName
) -X- _ O
assigned -X- _ O
to -X- _ O
various -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
mod- -X- _ O
els -X- _ O
trained -X- _ O
on -X- _ O
Gigaword -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
positive -X- _ O
correlation -X- _ O
between -X- _ O
extractiveness -X- _ B-MetricName
and -X- _ O
faithfulness -X- _ B-MetricName
scores -X- _ O
, -X- _ O
as -X- _ O
models -X- _ O
whose -X- _ O
generated -X- _ O
summaries -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
average -X- _ B-MetricName
coverage -X- _ I-MetricName
tend -X- _ O
to -X- _ O
also -X- _ O
get -X- _ O
higher -X- _ O
scores -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
metrics -X- _ O
. -X- _ O
This -X- _ O
correlation -X- _ O
between -X- _ O
exractiveness -X- _ B-MetricName
and -X- _ O
faithfulness -X- _ B-MetricName
makes -X- _ O
it -X- _ O
unclear -X- _ O
whether -X- _ O
a -X- _ O
model -X- _ O
gets -X- _ O
higher -X- _ O
factuality -X- _ O
scores -X- _ O
simply -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
extractive -X- _ O
or -X- _ O
it -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
generating -X- _ O
faith- -X- _ O
ful -X- _ O
summaries -X- _ O
at -X- _ O
the -X- _ O
original -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
This -X- _ O
highlights -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
accounting -X- _ O
for -X- _ O
extrac- -X- _ B-MetricName
tiveness -X- _ I-MetricName
in -X- _ O
order -X- _ O
to -X- _ O
compare -X- _ O
faithfulness -X- _ B-MetricName
across -X- _ O
different -X- _ O
abstractive -X- _ O
summarization -X- _ O
systems -X- _ O
. -X- _ O
4 -X- _ O
Evaluating -X- _ O
Effective -X- _ B-MetricName
Faithfulness -X- _ I-MetricName
Given -X- _ O
that -X- _ O
extractiveness -X- _ B-MetricName
is -X- _ O
confounded -X- _ O
with -X- _ O
faith- -X- _ B-MetricName
fulness -X- _ I-MetricName
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
framework -X- _ O
for -X- _ O
evaluating -X- _ O
effective -X- _ O
faithfulness -X- _ O
, -X- _ O
which -X- _ O
takes -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
extractiveness -X- _ O
of -X- _ O
a -X- _ O
system -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
do -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
need -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
a -X- _ O
system -X- _ O
operating -X- _ O
at -X- _ O
a -X- _ O
given -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
We -X- _ O
call -X- _ O
this -X- _ O
the -X- _ O
Faithfulness -X- _ B-MetricName
- -X- _ O
Abstractiveness -X- _ B-MetricName
Tradeoff -X- _ O
and -X- _ O
we -X- _ O
describe -X- _ O
it -X- _ O
further -X- _ O
in -X- _ O
§ -X- _ O
4.1 -X- _ O
. -X- _ O
The -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
of -X- _ O
a -X- _ O
system -X- _ O
is -X- _ O
then -X- _ O
simply -X- _ O
the -X- _ O
relative -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
system -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
system -X- _ O
operating -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
average -X- _ B-MetricName
extractiveness -X- _ I-MetricName
according -X- _ O
to -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
. -X- _ O
4.1 -X- _ O
Faithfulness -X- _ B-MetricName
- -X- _ O
Abstractiveness -X- _ B-MetricName
Tradeoff -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
a -X- _ O
pro- -X- _ O
posed -X- _ O
system -X- _ O
for -X- _ O
improving -X- _ O
faithfulness -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
its -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
We -X- _ O
ﬁnetune -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BART -X- _ B-MethodName
models -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
extractiveness -X- _ B-MetricName
, -X- _ O
without -X- _ O
any -X- _ O
explicit -X- _ O
recourse -X- _ O
for -X- _ O
improving -X- _ O
faithfulness -X- _ B-MetricName
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
these -X- _ O
systems -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
faithfulness- -X- _ B-MetricName
abstractiveness -X- _ B-MetricName
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
that -X- _ O
can -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
control -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
of -X- _ O
summarization -X- _ O
systems -X- _ O
. -X- _ O
Models -X- _ O
that -X- _ O
improve -X- _ O
effec- -X- _ O
tive -X- _ O
faithfulness -X- _ B-MetricName
should -X- _ O
lie -X- _ O
above -X- _ O
the -X- _ O
faithfulness- -X- _ B-MetricName
abstractiveness -X- _ B-MetricName
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
sub -X- _ O
- -X- _ O
sample -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
into -X- _ O
extractiveness -X- _ B-MetricName
quartiles -X- _ O
by -X- _ O
computing -X- _ O
the -X- _ O
cov- -X- _ O
erage -X- _ O
of -X- _ O
the -X- _ O
references -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
BART -X- _ B-MethodName
on -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
quartiles -X- _ O
to -X- _ O
obtain -X- _ O
quartile -X- _ O
models -X- _ O
with -X- _ O
varying -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
ﬁne- -X- _ O
tune -X- _ O
BART -X- _ B-MethodName
on -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
We -X- _ O
collect -X- _ O
faithfulness -X- _ B-MetricName
annotations -X- _ O
for -X- _ O
sum- -X- _ O
maries -X- _ O
generated -X- _ O
by -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
random -X- _ O
sample -X- _ O
of -X- _ O
200articles -X- _ O
. -X- _ O
We -X- _ O
collect -X- _ O
three -X- _ O
annotations -X- _ O
per -X- _ O
example -X- _ O
on -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turk -X- _ O
asking -X- _ O
whether -X- _ O
an -X- _ O
output -X- _ O
is -X- _ O
faithful -X- _ O
or -X- _ O
unfaith- -X- _ O
ful -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
compute -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
annotators -X- _ O
that -X- _ O
selects -X- _ O
" -X- _ O
faithful -X- _ O
" -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
this -X- _ O
as -X- _ O
the -X- _ O
faithfulness1412Article -X- _ O
Once -X- _ O
you -X- _ O
decide -X- _ O
what -X- _ O
to -X- _ O
outsource -X- _ O
, -X- _ O
look -X- _ O
for -X- _ O
the -X- _ O
right -X- _ O
contractors -X- _ O
. -X- _ O
Start -X- _ O
by -X- _ O
asking -X- _ O
for -X- _ O
refer- -X- _ O
rals -X- _ O
from -X- _ O
your -X- _ O
own -X- _ O
professional -X- _ O
network -X- _ O
. -X- _ O
Talk -X- _ O
to -X- _ O
other -X- _ O
business -X- _ O
owners -X- _ O
and -X- _ O
professionals -X- _ O
about -X- _ O
how -X- _ O
and -X- _ O
where -X- _ O
they -X- _ O
outsource -X- _ O
. -X- _ O
You -X- _ O
can -X- _ O
also -X- _ O
check -X- _ O
professional -X- _ O
associations -X- _ O
or -X- _ O
trade -X- _ O
groups -X- _ O
ﬁeld -X- _ O
in -X- _ O
which -X- _ O
you -X- _ O
are -X- _ O
trying -X- _ O
to -X- _ O
outsource -X- _ O
work -X- _ O
. -X- _ O
Use -X- _ O
other -X- _ O
social -X- _ O
media -X- _ O
platforms -X- _ O
such -X- _ O
as -X- _ O
Facebook -X- _ O
or -X- _ O
Twitter -X- _ O
to -X- _ O
advertise -X- _ O
what -X- _ O
you -X- _ O
are -X- _ O
looking -X- _ O
for -X- _ O
. -X- _ O
Alternately -X- _ O
, -X- _ O
you -X- _ O
can -X- _ O
connect -X- _ O
with -X- _ O
contractors -X- _ O
and -X- _ O
freelancers -X- _ O
on -X- _ O
sites -X- _ O
such -X- _ O
as -X- _ O
eLance -X- _ O
, -X- _ O
Guru -X- _ O
and -X- _ O
oDesk -X- _ O
. -X- _ O
These -X- _ O
websites -X- _ O
allow -X- _ O
business -X- _ O
owners -X- _ O
to -X- _ O
place -X- _ O
an -X- _ O
ad -X- _ O
that -X- _ O
describes -X- _ O
what -X- _ O
kind -X- _ O
of -X- _ O
work -X- _ O
they -X- _ O
need -X- _ O
to -X- _ O
have -X- _ O
done -X- _ O
, -X- _ O
and -X- _ O
contractors -X- _ O
respond -X- _ O
with -X- _ O
their -X- _ O
qualiﬁcations -X- _ O
and -X- _ O
rates -X- _ O
. -X- _ O
[ -X- _ O
TRUNCATED -X- _ O
] -X- _ O
... -X- _ O
Baseline -X- _ O
Search -X- _ O
for -X- _ O
contractors -X- _ O
and -X- _ O
freelancers -X- _ O
to -X- _ O
outsource -X- _ O
the -X- _ O
work -X- _ O
. -X- _ O
Q1 -X- _ O
Conduct -X- _ O
an -X- _ O
initial -X- _ O
search -X- _ O
for -X- _ O
qualiﬁed -X- _ O
contractors -X- _ O
and -X- _ O
freelancers -X- _ O
. -X- _ O
Q2 -X- _ O
Search -X- _ O
for -X- _ O
qualiﬁed -X- _ O
contractors -X- _ O
and -X- _ O
freelancers -X- _ O
to -X- _ O
work -X- _ O
on -X- _ O
your -X- _ O
project -X- _ O
. -X- _ O
Q3 -X- _ O
Search -X- _ O
for -X- _ O
contractors -X- _ O
and -X- _ O
freelancers -X- _ O
to -X- _ O
do -X- _ O
the -X- _ O
work -X- _ O
. -X- _ O
Q4 -X- _ O
Look -X- _ O
for -X- _ O
contractors -X- _ O
and -X- _ O
freelancers -X- _ O
to -X- _ O
bid -X- _ O
on -X- _ O
the -X- _ O
work -X- _ O
. -X- _ O
Dataset -X- _ O
Model -X- _ B-MetricName
Coverage -X- _ I-MetricName
Faithfulness -X- _ B-MetricName
GigawordBaseline -X- _ B-DatasetName
76.12 -X- _ B-MetricValue
83.33 -X- _ B-MetricValue
Q1 -X- _ O
50.25 -X- _ B-MetricValue
71.83 -X- _ B-MetricValue
Q2 -X- _ O
60.57 -X- _ B-MetricValue
79.50 -X- _ B-MetricValue
Q3 -X- _ O
73.64 -X- _ B-MetricValue
86.67 -X- _ B-MetricValue
Q4 -X- _ O
86.94 -X- _ B-MetricValue
89.17 -X- _ B-MetricValue
WikihowBaseline -X- _ B-DatasetName
88.28 -X- _ O
82.52 -X- _ O
Q1 -X- _ O
81.34 -X- _ O
67.82 -X- _ O
Q2 -X- _ O
85.34 -X- _ O
76.21 -X- _ O
Q3 -X- _ O
87.59 -X- _ O
80.35 -X- _ O
Q4 -X- _ O
90.19 -X- _ O
91.08 -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
coverage -X- _ O
and -X- _ O
faithfulness -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
baseline -X- _ O
and -X- _ O
the -X- _ O
quartile -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
Q1 -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
abstractive -X- _ O
and -X- _ O
Q4 -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
extractive -X- _ O
quartile -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
mod- -X- _ O
els -X- _ O
that -X- _ O
are -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
more -X- _ O
extractive -X- _ O
quartiles -X- _ O
produce -X- _ O
outputs -X- _ O
with -X- _ O
signiﬁcantly -X- _ O
higher -X- _ O
coverage -X- _ B-MetricName
and -X- _ O
faithfulness -X- _ B-MetricName
scores -X- _ O
. -X- _ O
The -X- _ O
baseline -X- _ O
model -X- _ O
gen- -X- _ O
erates -X- _ O
relatively -X- _ O
extractive -X- _ O
outputs -X- _ O
with -X- _ O
coverage -X- _ O
closest -X- _ O
to -X- _ O
Q3 -X- _ O
on -X- _ O
both -X- _ O
Gigaword -X- _ B-DatasetName
and -X- _ O
Wikihow -X- _ B-DatasetName
. -X- _ O
Fur- -X- _ O
thermore -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
higher -X- _ O
coverage -X- _ B-MetricName
than -X- _ O
the -X- _ O
model -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
Q3 -X- _ O
but -X- _ O
it -X- _ O
has -X- _ O
lower -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ I-MetricName
for -X- _ O
Gigaword -X- _ B-DatasetName
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
article -X- _ O
from -X- _ O
the -X- _ O
Wikihow -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
corresponding -X- _ O
output -X- _ O
summaries -X- _ O
gener- -X- _ O
ated -X- _ O
by -X- _ O
the -X- _ O
baseline -X- _ O
and -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
quartile -X- _ O
mod- -X- _ O
els -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
summaries -X- _ O
are -X- _ O
very -X- _ O
similar -X- _ O
in -X- _ O
meaning -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
gener- -X- _ O
ated -X- _ O
by -X- _ O
the -X- _ O
Q1 -X- _ O
model -X- _ O
includes -X- _ O
a -X- _ O
higher -X- _ O
number -X- _ O
of -X- _ O
novel -X- _ O
words -X- _ O
( -X- _ O
i.e. -X- _ O
lower -X- _ O
coverage -X- _ O
) -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
while -X- _ O
staying -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
Conversely -X- _ O
, -X- _ O
Q4 -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
coverage -X- _ O
of -X- _ O
1 -X- _ O
in -X- _ O
this -X- _ O
example -X- _ O
; -X- _ O
all -X- _ O
the -X- _ O
words -X- _ O
generated -X- _ O
by -X- _ O
this -X- _ O
model -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
the -X- _ O
Q1 -X- _ O
model -X- _ O
generates -X- _ O
outputs -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
abstractive -X- _ O
and -X- _ O
less -X- _ O
faithful -X- _ O
while -X- _ O
Q4 -X- _ O
generates -X- _ O
outputs -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
extractive -X- _ O
and -X- _ O
more -X- _ O
faithful -X- _ O
. -X- _ O
5 -X- _ O
Mitigating -X- _ O
the -X- _ O
Trade -X- _ O
- -X- _ O
off -X- _ O
5.1 -X- _ O
Oracle -X- _ O
Experiments -X- _ O
We -X- _ O
ﬁrst -X- _ O
aim -X- _ O
to -X- _ O
understand -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
mitigate -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
- -X- _ O
abstractiveness -X- _ B-MetricName
tradeoff -X- _ O
by -X- _ O
designing -X- _ O
several -X- _ O
oracle -X- _ O
experiments -X- _ O
where -X- _ O
we -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
human -X- _ O
judgments -X- _ O
. -X- _ O
baseline -X- _ O
+ -X- _ O
faithfulness -X- _ B-MetricName
( -X- _ O
bf -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
faithful -X- _ O
( -X- _ O
i.e. -X- _ O
at -X- _ O
least -X- _ O
two -X- _ O
out -X- _ O
of -X- _ O
three -X- _ O
annotators -X- _ O
agree -X- _ O
that -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
faithful -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
baseline -X- _ O
output -X- _ O
is -X- _ O
not -X- _ O
faithful -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
the -X- _ O
quartile -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
extractive -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
to -X- _ O
see -X- _ O
whether -X- _ O
we -X- _ O
can -X- _ O
have -X- _ O
a -X- _ O
similar -X- _ O
coverage -X- _ O
as -X- _ O
the -X- _ O
baseline -X- _ O
but -X- _ O
preserve -X- _ O
faithfulness -X- _ B-MetricName
. -X- _ O
baseline -X- _ O
+ -X- _ O
faithfulness -X- _ B-MetricName
- -X- _ O
extractiveness -X- _ B-MetricName
( -X- _ O
bfe -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
oracle -X- _ O
system -X- _ O
behaves -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
one -X- _ O
de- -X- _ O
scribed -X- _ O
above -X- _ O
when -X- _ O
the -X- _ O
baseline -X- _ O
output -X- _ O
is -X- _ O
unfaith- -X- _ O
ful -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
always -X- _ O
selecting -X- _ O
the -X- _ O
base-1413Dataset -X- _ O
Cov -X- _ O
. -X- _ O
Faithfulness -X- _ B-MetricName
GigawordBaseline -X- _ B-DatasetName
76.12 -X- _ B-MetricValue
83.33 -X- _ B-MetricValue
bf -X- _ B-MetricName
77.74 -X- _ B-MetricValue
89.57 -X- _ B-MetricValue
bfe -X- _ B-MetricName
61.87 -X- _ B-MetricValue
90.67 -X- _ B-MetricValue
qfe -X- _ B-MetricName
63.55 -X- _ B-MetricValue
98.00 -X- _ B-MetricValue
WikihowBaseline -X- _ B-DatasetName
82.52 -X- _ B-MetricValue
88.28 -X- _ B-MetricValue
bf -X- _ B-MetricName
83.95 -X- _ B-MetricValue
92.20 -X- _ B-MetricValue
bfe -X- _ B-MetricName
70.52 -X- _ B-MetricValue
91.32 -X- _ B-MetricValue
qfe -X- _ B-MetricName
72.58 -X- _ B-MetricValue
98.61 -X- _ B-MetricValue
line -X- _ O
output -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
faithful -X- _ O
, -X- _ O
we -X- _ O
pick -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
the -X- _ O
quartile -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
more -X- _ O
abstractive -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
whenever -X- _ O
it -X- _ O
is -X- _ O
also -X- _ O
faithful -X- _ O
ac- -X- _ O
cording -X- _ O
to -X- _ O
human -X- _ O
judgement -X- _ O
. -X- _ O
quartile -X- _ O
+ -X- _ O
faithfulness -X- _ B-MetricName
- -X- _ O
extractiveness -X- _ B-MetricName
( -X- _ O
qfe -X- _ O
) -X- _ O
. -X- _ O
Amongst -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
all -X- _ O
four -X- _ O
quartile -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
pick -X- _ O
the -X- _ O
most -X- _ O
faithful -X- _ O
output -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
level -X- _ O
of -X- _ O
abstractiveness -X- _ O
to -X- _ O
understand -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
generate -X- _ O
abstractive -X- _ O
output -X- _ O
while -X- _ O
re- -X- _ O
maining -X- _ O
faithful -X- _ O
. -X- _ O
Analysis -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
coverage -X- _ O
and -X- _ O
faith- -X- _ B-MetricName
fulness -X- _ I-MetricName
of -X- _ O
the -X- _ O
baseline -X- _ O
and -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
oracles -X- _ O
for -X- _ O
Gigaword -X- _ O
and -X- _ O
Wikihow -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
faithful -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
at -X- _ O
a -X- _ O
similar -X- _ O
level -X- _ O
of -X- _ O
abstractiveness -X- _ B-MetricName
( -X- _ O
bf -X- _ B-MetricName
) -X- _ O
. -X- _ O
Further- -X- _ O
more -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
be -X- _ O
more -X- _ O
abstractive -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
while -X- _ O
being -X- _ O
more -X- _ O
faithful -X- _ O
( -X- _ O
bfe -X- _ B-MetricName
) -X- _ O
. -X- _ O
Selecting -X- _ O
the -X- _ O
most -X- _ O
faithful -X- _ O
and -X- _ O
abstractive -X- _ O
output -X- _ O
from -X- _ O
the -X- _ O
quartile -X- _ O
models -X- _ O
achieves -X- _ O
a -X- _ O
really -X- _ O
high -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ O
( -X- _ O
98 -X- _ O
% -X- _ O
) -X- _ O
while -X- _ O
having -X- _ O
signiﬁcantly -X- _ O
less -X- _ O
coverage -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
This -X- _ O
oracle -X- _ O
analysis -X- _ O
suggests -X- _ O
that -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
build -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
mit- -X- _ O
igate -X- _ O
the -X- _ O
faithfulness -X- _ O
- -X- _ O
abstractiveness -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
by -X- _ O
controlling -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ O
. -X- _ O
Given -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
explore -X- _ O
whether -X- _ O
we -X- _ O
can -X- _ O
learn -X- _ O
a -X- _ O
selector -X- _ O
that -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
doing -X- _ O
this -X- _ O
selection -X- _ O
automatically -X- _ O
to -X- _ O
mitigate -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
- -X- _ O
abstractiveness -X- _ B-MetricName
trade- -X- _ O
off -X- _ O
. -X- _ O
5.2 -X- _ O
Loss -X- _ O
Truncation -X- _ O
Kang -X- _ O
and -X- _ O
Hashimoto -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
adaptively -X- _ O
remove -X- _ O
high -X- _ O
loss -X- _ O
examples -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
distinguishability -X- _ O
of -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
. -X- _ O
They -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
samples -X- _ O
generated -X- _ O
by -X- _ O
this -X- _ O
Loss -X- _ O
Truncation -X- _ O
model -X- _ O
achieves -X- _ O
higher -X- _ O
factuality -X- _ O
ratings -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
methods -X- _ O
. -X- _ O
We -X- _ O
study -X- _ O
this -X- _ O
method -X- _ O
tounderstand -X- _ O
where -X- _ O
it -X- _ O
lies -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
faithfulness- -X- _ B-MetricName
abstractiveness -X- _ B-MetricName
trade -X- _ O
- -X- _ O
off -X- _ O
and -X- _ O
whether -X- _ O
it -X- _ O
can -X- _ O
achieve -X- _ O
a -X- _ O
improved -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
over -X- _ O
the -X- _ O
control -X- _ O
. -X- _ O
5.3 -X- _ O
Dependency -X- _ O
Arc -X- _ O
Entailment -X- _ O
( -X- _ O
DAE -X- _ O
) -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
proposed -X- _ O
a -X- _ O
factual- -X- _ O
ity -X- _ O
evaluation -X- _ O
metric -X- _ O
( -X- _ O
DAE -X- _ B-MetricName
) -X- _ O
that -X- _ O
evaluates -X- _ O
whether -X- _ O
each -X- _ O
dependency -X- _ O
arc -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
output -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
They -X- _ O
show -X- _ O
that -X- _ O
their -X- _ O
proposed -X- _ O
metric -X- _ O
works -X- _ O
better -X- _ O
than -X- _ O
existing -X- _ O
factu- -X- _ O
ality -X- _ O
metrics -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
being -X- _ O
able -X- _ O
to -X- _ O
localize -X- _ O
the -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
output -X- _ O
that -X- _ O
are -X- _ O
non -X- _ O
- -X- _ O
factual -X- _ O
. -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
DAE -X- _ B-MetricName
’s -X- _ O
ability -X- _ O
to -X- _ O
localize -X- _ O
factuality -X- _ O
errors -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
sum- -X- _ O
marization -X- _ O
model -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
tokens -X- _ O
that -X- _ O
is -X- _ O
deemed -X- _ O
factual -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
DAE -X- _ B-MetricName
metric -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
their -X- _ O
methodology -X- _ O
to -X- _ O
train -X- _ O
summariza- -X- _ O
tion -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
assess -X- _ O
them -X- _ O
using -X- _ O
our -X- _ O
evaluation -X- _ O
framework -X- _ O
. -X- _ O
5.4 -X- _ O
Selector -X- _ B-MethodName
Model -X- _ I-MethodName
We -X- _ O
aim -X- _ O
to -X- _ O
understand -X- _ O
whether -X- _ O
we -X- _ O
can -X- _ O
build -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
achieves -X- _ O
a -X- _ O
better -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
than -X- _ O
Loss -X- _ O
Truncation -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
selector -X- _ O
that -X- _ O
can -X- _ O
identify -X- _ O
the -X- _ O
most -X- _ O
abstractive -X- _ O
but -X- _ O
faithful -X- _ O
output -X- _ O
to -X- _ O
improve -X- _ O
this -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
. -X- _ O
We -X- _ O
ﬁrst -X- _ O
generate -X- _ O
four -X- _ O
possible -X- _ O
candidate -X- _ O
summaries -X- _ O
using -X- _ O
the -X- _ O
quartile -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
in -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
results -X- _ O
in -X- _ O
outputs -X- _ O
with -X- _ O
varying -X- _ O
levels -X- _ O
of -X- _ O
extractive- -X- _ O
ness -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
selector -X- _ O
, -X- _ O
we -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
FactCC -X- _ B-MethodName
model -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
we -X- _ O
collected -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
, -X- _ O
using -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
validation -X- _ O
, -X- _ O
to -X- _ O
assign -X- _ O
faithfulness -X- _ B-MetricName
scores -X- _ O
to -X- _ O
the -X- _ O
gen- -X- _ O
erated -X- _ O
summaries -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
folds -X- _ O
) -X- _ O
.In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
learn -X- _ O
a -X- _ O
threshold -X- _ O
for -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ O
that -X- _ O
maximizes -X- _ O
the -X- _ O
area -X- _ O
under -X- _ O
the -X- _ O
ROC -X- _ O
curve -X- _ O
( -X- _ O
Selector- -X- _ O
ROC -X- _ O
) -X- _ O
( -X- _ O
also -X- _ O
using -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
validation -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
example -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
fold -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
abstractive -X- _ O
candidate -X- _ O
( -X- _ O
amongst -X- _ O
the -X- _ O
four -X- _ O
possible -X- _ O
candidates -X- _ O
from -X- _ O
the -X- _ O
quartile -X- _ O
models -X- _ O
) -X- _ O
that -X- _ O
is -X- _ O
con- -X- _ O
sidered -X- _ O
faithful -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
ﬁntuned -X- _ O
FactCC -X- _ O
model -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ O
is -X- _ O
above -X- _ O
the -X- _ O
tuned -X- _ O
threshold -X- _ O
) -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
maximizing -X- _ O
for -X- _ O
the -X- _ O
area -X- _ O
under -X- _ O
the -X- _ O
ROC -X- _ O
curve -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
tune -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
thresh- -X- _ O
old -X- _ O
to -X- _ O
maximize -X- _ O
Fscores -X- _ O
( -X- _ O
Selector -X- _ O
- -X- _ O
F -X- _ O
) -X- _ O
. -X- _ O
Using -X- _ O
Fscore -X- _ B-MetricName
with -X- _ O
< -X- _ O
1allows -X- _ O
us -X- _ O
to -X- _ O
assign -X- _ O
a -X- _ O
higher -X- _ O
weight -X- _ O
to -X- _ O
the -X- _ O
precision -X- _ O
of -X- _ O
our -X- _ O
selector -X- _ O
which -X- _ O
would -X- _ O
result -X- _ O
in -X- _ O
outputs -X- _ O
with -X- _ O
higher -X- _ O
coverage -X- _ O
and -X- _ O
faithful- -X- _ O
ness.1414Gigaword -X- _ B-DatasetName
Wikihow -X- _ B-DatasetName
Coverage -X- _ B-MetricName
Faitfulness -X- _ B-MetricName
Coverage -X- _ B-MetricName
Faithfulness -X- _ B-MetricName
Baseline -X- _ O
76.12 -X- _ B-MetricValue
83.33 -X- _ B-MetricValue
82.76 -X- _ B-MetricValue
86.94 -X- _ B-MetricValue
Loss -X- _ B-MetricName
Truncation -X- _ I-MetricName
79.55 -X- _ B-MetricValue
87.17 -X- _ B-MetricValue
84.93 -X- _ B-MetricValue
87.84 -X- _ B-MetricValue
DAE -X- _ B-MetricName
78.23 -X- _ B-MetricValue
86.33 -X- _ B-MetricValue
84.15 -X- _ B-MetricValue
88.83 -X- _ B-MetricValue
Selector -X- _ O
- -X- _ O
ROC -X- _ B-MetricName
( -X- _ O
Ours -X- _ O
) -X- _ O
64.58 -X- _ B-MetricValue
84.17 -X- _ B-MetricValue
78.67 -X- _ B-MetricValue
87.84 -X- _ B-MetricValue
Selector -X- _ O
- -X- _ O
F -X- _ B-MetricName
( -X- _ I-MetricName
Ours -X- _ O
) -X- _ O
0.5 -X- _ B-MetricValue
54.77 -X- _ B-MetricValue
76.83 -X- _ B-MetricValue
64.24 -X- _ B-MetricValue
79.82 -X- _ B-MetricValue
0.4 -X- _ B-MetricValue
59.79 -X- _ B-MetricValue
81.67 -X- _ B-MetricValue
67.81 -X- _ B-MetricValue
81.71 -X- _ B-MetricValue
0.3 -X- _ B-MetricValue
60.72 -X- _ B-MetricValue
82.00 -X- _ B-MetricValue
68.53 -X- _ B-MetricValue
83.15 -X- _ B-MetricValue
0.2 -X- _ B-MetricValue
68.38 -X- _ B-MetricValue
86.00 -X- _ B-MetricValue
78.67 -X- _ B-MetricValue
87.84 -X- _ B-MetricValue
0.1 -X- _ B-MetricValue
79.92 -X- _ B-MetricValue
88.00 -X- _ B-MetricValue
84.72 -X- _ B-MetricValue
89.19 -X- _ B-MetricValue
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
FactCC -X- _ B-MethodName
is -X- _ O
important -X- _ O
since -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
FactCC -X- _ B-MethodName
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
dataset -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
transfer -X- _ O
well -X- _ O
to -X- _ O
our -X- _ O
setttings -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
ﬁndings -X- _ O
of -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
5.5 -X- _ O
Results -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
coverage -X- _ O
and -X- _ O
faithfulness -X- _ O
re- -X- _ O
sults -X- _ O
for -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
Loss -X- _ O
Truncation -X- _ O
, -X- _ O
DAE -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
selectors -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
as -X- _ O
we -X- _ O
use -X- _ O
smaller -X- _ O
values -X- _ O
for -X- _ O
for -X- _ O
Selector -X- _ O
- -X- _ O
F -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
more -X- _ O
extrac- -X- _ O
tive -X- _ O
and -X- _ O
more -X- _ O
faithful -X- _ O
outputs -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
between -X- _ O
faithfulness -X- _ B-MetricName
and -X- _ O
abstrac- -X- _ B-MetricName
tiveness -X- _ I-MetricName
. -X- _ O
Moreover -X- _ O
, -X- _ O
with -X- _ O
both -X- _ O
Selector -X- _ B-MethodName
- -X- _ I-MethodName
ROC -X- _ I-MethodName
and -X- _ O
Selector -X- _ B-MethodName
- -X- _ I-MethodName
F -X- _ I-MethodName
, -X- _ O
we -X- _ O
produce -X- _ O
output -X- _ O
with -X- _ O
less -X- _ O
cover- -X- _ B-MetricName
age -X- _ I-MetricName
but -X- _ O
higher -X- _ O
faithfulness -X- _ B-MetricName
scores -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
For -X- _ O
Wikihow -X- _ B-DatasetName
, -X- _ O
Selector -X- _ B-MethodName
- -X- _ I-MethodName
ROC -X- _ I-MethodName
produces -X- _ O
outputs -X- _ O
with -X- _ O
lower -X- _ O
coverage -X- _ O
but -X- _ O
similar -X- _ O
faithfulness -X- _ O
scores -X- _ O
to -X- _ O
Loss -X- _ O
Truncation -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
further -X- _ O
obtain -X- _ O
a -X- _ O
higher -X- _ O
faithfulness -X- _ O
score -X- _ O
at -X- _ O
a -X- _ O
similar -X- _ O
coverage -X- _ O
level -X- _ O
as -X- _ O
DAE -X- _ B-MethodName
and -X- _ O
Loss -X- _ B-MethodName
truncation -X- _ I-MethodName
with -X- _ I-MethodName
Selector -X- _ I-MethodName
- -X- _ O
Fwith -X- _ O
= -X- _ O
0:1 -X- _ O
. -X- _ O
For -X- _ O
Gigaword -X- _ B-DatasetName
, -X- _ O
Select -X- _ B-MethodName
- -X- _ I-MethodName
ROC -X- _ I-MethodName
produces -X- _ O
output -X- _ O
with -X- _ O
signiﬁcantly -X- _ O
lower -X- _ O
coverage -X- _ O
than -X- _ O
Loss -X- _ B-MethodName
Truncation -X- _ I-MethodName
and -X- _ O
DAE -X- _ B-MetricName
. -X- _ O
Selector -X- _ B-MethodName
- -X- _ I-MethodName
Fproduces -X- _ I-MethodName
output -X- _ O
with -X- _ O
similar -X- _ O
coverage -X- _ O
to -X- _ O
Loss -X- _ B-MethodName
Truncation -X- _ I-MethodName
with -X- _ O
a -X- _ O
higher -X- _ O
faithfulness -X- _ B-MetricName
score -X- _ O
( -X- _ O
= -X- _ O
0:1 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
understand -X- _ O
whether -X- _ O
models -X- _ O
im- -X- _ O
prove -X- _ O
faithfulness -X- _ O
by -X- _ O
simply -X- _ O
being -X- _ O
more -X- _ O
extractive -X- _ O
or -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
improve -X- _ O
effective -X- _ O
faithfulness -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
understand -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
whether -X- _ O
the -X- _ O
models -X- _ O
get -X- _ O
improvement -X- _ O
in -X- _ O
faithfulness -X- _ B-MetricName
over -X- _ O
the -X- _ O
control -X- _ O
operating -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
In -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
plot -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
- -X- _ O
abstractiveness -X- _ B-MetricName
curve -X- _ O
with -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
and -X- _ O
abstractiveness -X- _ B-MetricName
ofthe -X- _ O
quartile -X- _ O
models -X- _ O
. -X- _ O
If -X- _ O
a -X- _ O
model -X- _ O
lies -X- _ O
above -X- _ O
this -X- _ O
curve -X- _ O
, -X- _ O
it -X- _ O
improves -X- _ O
the -X- _ O
effective -X- _ O
faithfulness -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
below -X- _ O
this -X- _ O
curve -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
improve -X- _ O
theeffective -X- _ O
faithfulness -X- _ O
and -X- _ O
it -X- _ O
has -X- _ O
a -X- _ O
worse -X- _ O
trade- -X- _ O
off -X- _ O
than -X- _ O
the -X- _ O
control -X- _ O
operating -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ B-MetricName
. -X- _ O
For -X- _ O
both -X- _ O
Gigaword -X- _ O
and -X- _ O
Wikihow -X- _ O
, -X- _ O
Selector -X- _ O
- -X- _ O
ROC -X- _ O
lies -X- _ O
above -X- _ O
the -X- _ O
curve -X- _ O
improving -X- _ O
this -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
. -X- _ O
How- -X- _ O
ever -X- _ O
, -X- _ O
both -X- _ O
the -X- _ O
baseline -X- _ O
and -X- _ O
Loss -X- _ B-MethodName
Truncation -X- _ I-MethodName
models -X- _ O
get -X- _ O
worse -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
than -X- _ O
the -X- _ O
control -X- _ O
operating -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
extractiveness -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
several -X- _ O
models -X- _ O
that -X- _ O
lie -X- _ O
above -X- _ O
the -X- _ O
curve -X- _ O
for -X- _ O
both -X- _ O
Gigaword -X- _ O
and -X- _ O
Wikihow -X- _ O
using -X- _ O
Selector- -X- _ O
F. -X- _ O
The -X- _ O
selector -X- _ B-MethodName
approach -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
get -X- _ O
bet- -X- _ O
tereffective -X- _ O
faithfulness -X- _ B-MetricName
at -X- _ O
different -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
abstractiveness -X- _ B-MetricName
- -X- _ O
extractiveness -X- _ B-MetricName
spectrum -X- _ O
. -X- _ O
The -X- _ O
DAE -X- _ B-MethodName
based -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
improve -X- _ O
effective -X- _ O
faithful- -X- _ O
ness -X- _ O
on -X- _ O
the -X- _ O
Wikihow -X- _ O
dataset -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
on -X- _ O
the -X- _ O
Giga- -X- _ O
word -X- _ O
dataset -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
not -X- _ O
consistent -X- _ O
across -X- _ O
datasets -X- _ O
. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
ex- -X- _ O
ample -X- _ O
summaries -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
Loss -X- _ O
Truncation -X- _ O
, -X- _ O
DAE -X- _ O
and -X- _ O
the -X- _ O
Selector -X- _ O
- -X- _ O
ROC -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
selector -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
summaries -X- _ O
that -X- _ O
are -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
article -X- _ O
while -X- _ O
having -X- _ O
more -X- _ O
novel -X- _ O
words -X- _ O
and -X- _ O
phrases -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
summaries -X- _ O
. -X- _ O
6 -X- _ O
Related -X- _ O
Work -X- _ O
There -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
recent -X- _ O
work -X- _ O
in -X- _ O
abstractive -X- _ O
summarization -X- _ O
showing -X- _ O
that -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sys- -X- _ O
tems -X- _ O
suffer -X- _ O
from -X- _ O
generating -X- _ O
inconsistent -X- _ O
informa- -X- _ O
tion -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
despite -X- _ O
their -X- _ O
improved -X- _ O
success -X- _ O
in -X- _ O
producing -X- _ O
ﬂuent -X- _ O
summaries1415 -X- _ O
( -X- _ O
Falke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lux -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wilber -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
word -X- _ O
- -X- _ O
overlap -X- _ O
based -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
ROUGE -X- _ O
have -X- _ O
low -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
of -X- _ O
faithfulness -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
signiﬁcant -X- _ O
effort -X- _ O
to -X- _ O
develop -X- _ O
automated -X- _ O
metrics -X- _ O
that -X- _ O
can -X- _ O
detect -X- _ O
such -X- _ O
errors -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Gabriel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Pagnoni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Falke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Maynez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
proposed -X- _ O
to -X- _ O
assess -X- _ O
faithfulness -X- _ O
using -X- _ O
entailment -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
faithful -X- _ O
summary -X- _ O
should -X- _ O
be -X- _ O
as- -X- _ O
signed -X- _ O
a -X- _ O
high -X- _ O
entailment -X- _ O
score -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
article -X- _ O
. -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
presented -X- _ O
FactCC -X- _ O
, -X- _ O
a -X- _ O
weakly -X- _ O
- -X- _ O
supervised -X- _ O
BERT -X- _ O
- -X- _ O
based -X- _ O
entail- -X- _ O
ment -X- _ O
model -X- _ O
, -X- _ O
by -X- _ O
augmenting -X- _ O
the -X- _ O
dataset -X- _ O
with -X- _ O
artiﬁ- -X- _ O
cial -X- _ O
faithfulness -X- _ B-MetricName
errors -X- _ O
. -X- _ O
Durmus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
based -X- _ O
evaluation -X- _ O
frameworks -X- _ O
by -X- _ O
automatically -X- _ O
gen- -X- _ O
erating -X- _ O
questions -X- _ O
from -X- _ O
the -X- _ O
generated -X- _ O
summary -X- _ O
, -X- _ O
and -X- _ O
comparing -X- _ O
the -X- _ O
corresponding -X- _ O
answers -X- _ O
from -X- _ O
both -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
summary -X- _ O
in -X- _ O
order -X- _ O
assess -X- _ O
information -X- _ O
consistency -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
sev -X- _ O
- -X- _ O
eral -X- _ O
benchmarks -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
strengths -X- _ O
and -X- _ O
weaknesses -X- _ O
of -X- _ O
these -X- _ O
evaluation -X- _ O
metric -X- _ O
( -X- _ O
Gabriel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Pagnoni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
Previous -X- _ O
studies -X- _ O
in -X- _ O
faithfulness -X- _ O
evaluation -X- _ O
, -X- _ O
how- -X- _ O
ever -X- _ O
, -X- _ O
has -X- _ O
not -X- _ O
accounted -X- _ O
for -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
extractive- -X- _ O
ness -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
summaries -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
the -X- _ O
extractiveness -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
is -X- _ O
correlated -X- _ O
with -X- _ O
the -X- _ O
faithfulness -X- _ O
scores -X- _ O
assigned -X- _ O
by -X- _ O
these -X- _ O
au- -X- _ O
tomated -X- _ O
metrics -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
whether -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
higher -X- _ O
scores -X- _ O
are -X- _ O
better -X- _ O
at -X- _ O
abstrac- -X- _ O
tion -X- _ O
, -X- _ O
or -X- _ O
extract -X- _ O
more -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
that -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
this -X- _ O
confound- -X- _ O
ing -X- _ O
factor -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
real -X- _ O
progress -X- _ O
in -X- _ O
building -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
better -X- _ O
at -X- _ O
abstraction -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
concurrent -X- _ O
work -X- _ O
that -X- _ O
also -X- _ O
argues -X- _ O
for -X- _ O
accounting -X- _ O
for -X- _ O
extractiveness -X- _ O
in -X- _ O
assessing -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
models -X- _ O
( -X- _ O
Dreyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
how- -X- _ O
ever -X- _ O
, -X- _ O
unlike -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
propose -X- _ O
any -X- _ O
mitigation -X- _ O
for -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
- -X- _ O
abstractiveness -X- _ B-MetricName
trade -X- _ O
- -X- _ O
off -X- _ O
. -X- _ O
Improving -X- _ O
faithfulness -X- _ O
of -X- _ O
summarization -X- _ O
sys- -X- _ O
tems -X- _ O
is -X- _ O
essential -X- _ O
for -X- _ O
deploying -X- _ O
these -X- _ O
systems -X- _ O
in -X- _ O
real-1416Article -X- _ O
If -X- _ O
applicable -X- _ O
, -X- _ O
the -X- _ O
description -X- _ O
of -X- _ O
any -X- _ O
people -X- _ O
who -X- _ O
take -X- _ O
part -X- _ O
in -X- _ O
your -X- _ O
study -X- _ O
should -X- _ O
be -X- _ O
extremely -X- _ O
thorough -X- _ O
. -X- _ O
Each -X- _ O
person -X- _ O
should -X- _ O
be -X- _ O
identiﬁable -X- _ O
within -X- _ O
the -X- _ O
research -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
how -X- _ O
people -X- _ O
join -X- _ O
and -X- _ O
leave -X- _ O
the -X- _ O
study -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
. -X- _ O
If -X- _ O
people -X- _ O
were -X- _ O
selected -X- _ O
at -X- _ O
random -X- _ O
, -X- _ O
or -X- _ O
if -X- _ O
they -X- _ O
were -X- _ O
family -X- _ O
members -X- _ O
, -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
the -X- _ O
study -X- _ O
. -X- _ O
Be -X- _ O
sure -X- _ O
to -X- _ O
consider -X- _ O
various -X- _ O
ethical -X- _ O
concerns -X- _ O
( -X- _ O
e.g. -X- _ O
risk -X- _ O
and -X- _ O
consent -X- _ O
of -X- _ O
participants -X- _ O
) -X- _ O
if -X- _ O
people -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
your -X- _ O
research -X- _ O
. -X- _ O
BaselineDescribe -X- _ O
who -X- _ O
is -X- _ O
involved -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
. -X- _ O
DAEIdentify -X- _ B-MethodName
the -X- _ O
people -X- _ O
who -X- _ O
take -X- _ O
part -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
. -X- _ O
Loss -X- _ B-MethodName
TruncationDescribe -X- _ I-MethodName
people -X- _ O
who -X- _ O
take -X- _ O
part -X- _ O
in -X- _ O
your -X- _ O
study -X- _ O
. -X- _ O
Selector -X- _ B-MethodName
- -X- _ I-MethodName
ROC -X- _ I-MethodName
( -X- _ O
Ours -X- _ O
) -X- _ O
Describe -X- _ O
all -X- _ O
participants -X- _ O
thoroughly -X- _ O
and -X- _ O
with -X- _ O
care -X- _ O
. -X- _ O
Article -X- _ O
Because -X- _ O
diarrhea -X- _ O
frequently -X- _ O
causes -X- _ O
dehydration -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
crucial -X- _ O
that -X- _ O
patients -X- _ O
with -X- _ O
IBD -X- _ O
remain -X- _ O
hydrated -X- _ O
. -X- _ O
Drink -X- _ O
at -X- _ O
least -X- _ O
8 -X- _ O
glasses -X- _ O
of -X- _ O
water -X- _ O
every -X- _ O
day -X- _ O
( -X- _ O
or -X- _ O
64 -X- _ O
oz -X- _ O
) -X- _ O
. -X- _ O
Foods -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
high -X- _ O
water -X- _ O
content -X- _ O
( -X- _ O
like -X- _ O
watermelon -X- _ O
) -X- _ O
can -X- _ O
also -X- _ O
count -X- _ O
toward -X- _ O
this -X- _ O
minimum -X- _ O
. -X- _ O
If -X- _ O
you -X- _ O
have -X- _ O
a -X- _ O
severe -X- _ O
attack -X- _ O
of -X- _ O
diarrhea -X- _ O
, -X- _ O
you -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
lose -X- _ O
electrolytes -X- _ O
. -X- _ O
In -X- _ O
these -X- _ O
cases -X- _ O
, -X- _ O
you -X- _ O
might -X- _ O
need -X- _ O
to -X- _ O
consume -X- _ O
beverages -X- _ O
such -X- _ O
as -X- _ O
Pedialyte -X- _ O
or -X- _ O
Gatorade -X- _ O
to -X- _ O
help -X- _ O
replenish -X- _ O
them -X- _ O
[ -X- _ O
TRUNCATED -X- _ O
] -X- _ O
... -X- _ O
Baseline -X- _ O
Drink -X- _ O
plenty -X- _ O
of -X- _ O
water -X- _ O
to -X- _ O
stay -X- _ O
hydrated -X- _ O
. -X- _ O
Loss -X- _ O
Truncation -X- _ O
Drink -X- _ O
plenty -X- _ O
of -X- _ O
water -X- _ O
. -X- _ O
DAE -X- _ O
Drink -X- _ O
plenty -X- _ O
of -X- _ O
water -X- _ O
to -X- _ O
stay -X- _ O
hydrated -X- _ O
. -X- _ O
Selector -X- _ O
- -X- _ O
ROC -X- _ O
( -X- _ O
Ours -X- _ O
) -X- _ O
Drink -X- _ O
plenty -X- _ O
of -X- _ O
ﬂuids -X- _ O
to -X- _ O
stay -X- _ O
hydrated -X- _ O
. -X- _ O
world -X- _ O
scenarios -X- _ O
, -X- _ O
as -X- _ O
such -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
studied -X- _ O
methods -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
abstractive -X- _ O
summarization -X- _ O
systems -X- _ O
( -X- _ O
Matsumaru -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
train -X- _ O
summarization -X- _ O
systems -X- _ O
by -X- _ O
modifying -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
summary -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
consid- -X- _ O
ered -X- _ O
faithful -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
factuality -X- _ O
detection -X- _ O
model -X- _ O
. -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
speciﬁcally -X- _ O
target -X- _ O
hallu- -X- _ O
cination -X- _ O
of -X- _ O
quantities -X- _ O
in -X- _ O
generated -X- _ O
summaries -X- _ O
, -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
veriﬁcation -X- _ O
model -X- _ O
that -X- _ O
they -X- _ O
use -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
rank -X- _ O
summaries -X- _ O
such -X- _ O
that -X- _ O
summaries -X- _ O
containing -X- _ O
quanti- -X- _ O
ties -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
are -X- _ O
up -X- _ O
- -X- _ O
ranked -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
methods -X- _ O
have -X- _ O
shown -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
compared -X- _ O
baselines -X- _ O
, -X- _ O
unlike -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
measure -X- _ O
the -X- _ O
effective -X- _ O
faithfulness -X- _ O
taking -X- _ O
ex- -X- _ O
tractiveness -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
outputs -X- _ O
into -X- _ O
account -X- _ O
. -X- _ O
7 -X- _ O
Implications -X- _ O
and -X- _ O
Limitations -X- _ O
Recent -X- _ O
studies -X- _ O
that -X- _ O
propose -X- _ O
methods -X- _ O
to -X- _ O
improve -X- _ O
faithfulness -X- _ B-MetricName
evaluate -X- _ O
progress -X- _ O
by -X- _ O
conducting -X- _ O
hu- -X- _ O
man -X- _ O
evaluation -X- _ O
on -X- _ O
generated -X- _ O
summaries -X- _ O
and -X- _ O
checkwhether -X- _ O
the -X- _ O
faithfulness -X- _ O
scores -X- _ O
are -X- _ O
higher -X- _ O
for -X- _ O
their -X- _ O
proposed -X- _ O
system -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
their -X- _ O
baselines -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
strong -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
extractiveness -X- _ B-MetricName
and -X- _ O
faithfulness -X- _ B-MetricName
of -X- _ O
generated -X- _ O
out- -X- _ O
puts -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
more -X- _ O
extractive -X- _ O
outputs -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
faithful -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
simply -X- _ O
disregard -X- _ O
extractiveness -X- _ O
in -X- _ O
faithfulness -X- _ B-MetricName
evaluation -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
that -X- _ O
we -X- _ O
should -X- _ O
instead -X- _ O
be -X- _ O
measur- -X- _ O
ingeffective -X- _ O
faithfulness -X- _ B-MetricName
and -X- _ O
introduce -X- _ O
a -X- _ O
frame- -X- _ O
work -X- _ O
that -X- _ O
takes -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
faithfulness- -X- _ B-MetricName
abstractiveness -X- _ B-MetricName
trade -X- _ O
- -X- _ O
off -X- _ O
curve -X- _ O
that -X- _ O
is -X- _ O
generated -X- _ O
by -X- _ O
training -X- _ O
control -X- _ O
models -X- _ O
at -X- _ O
different -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
abstractiveness -X- _ B-MetricName
spectrum -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
measuring -X- _ O
effective -X- _ O
faithfulness -X- _ O
by -X- _ O
showing -X- _ O
that -X- _ O
recently -X- _ O
proposed -X- _ O
methods -X- _ O
that -X- _ O
im- -X- _ O
prove -X- _ O
faithfulness -X- _ B-MetricName
over -X- _ O
the -X- _ O
baseline -X- _ O
fails -X- _ O
to -X- _ O
consis- -X- _ O
tently -X- _ O
improve -X- _ O
over -X- _ O
a -X- _ O
simple -X- _ O
control -X- _ O
operating -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
abstractiveness -X- _ B-MetricName
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
measuring -X- _ O
effective -X- _ O
faithfulness -X- _ B-MetricName
is -X- _ O
important -X- _ O
since -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
build -X- _ O
abstractive -X- _ O
, -X- _ O
faithful -X- _ O
summarization -X- _ O
systems -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
objective -X- _ O
was -X- _ O
to -X- _ O
optimize -X- _ O
for -X- _ O
faithfulness -X- _ O
alone -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
do -X- _ O
so -X- _ O
by -X- _ O
simply -X- _ O
building -X- _ O
more -X- _ O
extractive -X- _ O
systems -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Q4 -X- _ O
model -X- _ O
we -X- _ O
trained -X- _ O
above -X- _ O
) -X- _ O
.1417Limitations -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
this -X- _ O
method -X- _ O
relies -X- _ O
on -X- _ O
some -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
extractiveness -X- _ B-MetricName
of -X- _ O
reference -X- _ O
summaries -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
rely -X- _ O
on -X- _ O
sub -X- _ O
- -X- _ O
sampling -X- _ O
to -X- _ O
train -X- _ O
models -X- _ O
for -X- _ O
the -X- _ O
control -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
effec- -X- _ O
tive -X- _ O
for -X- _ O
datasets -X- _ O
with -X- _ O
very -X- _ O
little -X- _ O
variation -X- _ O
in -X- _ O
the -X- _ O
ex- -X- _ O
tractiveness -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
summaries -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
signiﬁcantly -X- _ O
more -X- _ O
faithfulness -X- _ O
problems -X- _ O
for -X- _ O
datasets -X- _ O
with -X- _ O
higher -X- _ O
diversity -X- _ O
of -X- _ O
ab- -X- _ B-MetricName
stractiveness -X- _ I-MetricName
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
faithfulness -X- _ O
- -X- _ O
abstractiveness -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
for -X- _ O
such -X- _ O
datasets -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
8 -X- _ O
Acknowledgements -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
partly -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Ofﬁce -X- _ O
of -X- _ O
the -X- _ O
Director -X- _ O
of -X- _ O
National -X- _ O
Intelligence -X- _ O
( -X- _ O
ODNI -X- _ O
) -X- _ O
, -X- _ O
In- -X- _ O
telligence -X- _ O
Advanced -X- _ O
Research -X- _ O
Projects -X- _ O
Activity -X- _ O
( -X- _ O
IARPA -X- _ O
) -X- _ O
, -X- _ O
via -X- _ O
contract -X- _ O
# -X- _ O
FA8650 -X- _ O
- -X- _ O
17 -X- _ O
- -X- _ O
C-9117 -X- _ O
, -X- _ O
Sam- -X- _ O
sung -X- _ O
Advanced -X- _ O
Institute -X- _ O
of -X- _ O
Technology -X- _ O
( -X- _ O
Next -X- _ O
Gen- -X- _ O
eration -X- _ O
Deep -X- _ O
Learning -X- _ O
: -X- _ O
From -X- _ O
Pattern -X- _ O
Recognition -X- _ O
to -X- _ O
AI -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
collaborative -X- _ O
grant -X- _ O
from -X- _ O
Amazon -X- _ O
to -X- _ O
the -X- _ O
Columbia -X- _ O
Center -X- _ O
for -X- _ O
Artiﬁcial -X- _ O
Intelligence -X- _ O
entitled -X- _ O
“ -X- _ O
Extremely -X- _ O
Abstractive -X- _ B-MetricName
Summarization -X- _ O
” -X- _ O
. -X- _ O
The -X- _ O
views -X- _ O
and -X- _ O
conclusions -X- _ O
contained -X- _ O
herein -X- _ O
are -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
and -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
necessarily -X- _ O
representing -X- _ O
the -X- _ O
ofﬁcial -X- _ O
policies -X- _ O
, -X- _ O
ei- -X- _ O
ther -X- _ O
expressed -X- _ O
or -X- _ O
implied -X- _ O
, -X- _ O
of -X- _ O
the -X- _ O
funding -X- _ O
agencies -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
and -X- _ O
the -X- _ O
Stanford -X- _ O
NLP -X- _ O
group -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
feedback -X- _ O
. -X- _ O
References14181419A -X- _ O
Data -X- _ O
Statistics -X- _ O
Number -X- _ O
of -X- _ O
examples -X- _ O
, -X- _ O
source -X- _ O
article -X- _ O
length -X- _ O
and -X- _ O
tar- -X- _ O
get -X- _ O
summary -X- _ O
length -X- _ O
for -X- _ O
each -X- _ O
quartile -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
To -X- _ O
create -X- _ O
the -X- _ O
quartiles -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
compute -X- _ O
the -X- _ O
extractiveness -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
training -X- _ O
example -X- _ O
x -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
25th -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
50th -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
75th -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
percentile -X- _ O
of -X- _ O
the -X- _ O
extrac- -X- _ O
tiveness -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
quartiles -X- _ O
are -X- _ O
then -X- _ O
created -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
q1 -X- _ O
= -X- _ O
fxjeag -X- _ O
q2 -X- _ O
= -X- _ O
fxja -X- _ O
< -X- _ O
ebg -X- _ O
q3 -X- _ O
= -X- _ O
fxjb -X- _ O
< -X- _ O
ecg -X- _ O
q4 -X- _ O
= -X- _ O
fxje -X- _ O
> -X- _ O
cg -X- _ O
Note -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
for -X- _ O
there -X- _ O
to -X- _ O
be -X- _ O
several -X- _ O
points -X- _ O
at -X- _ O
the -X- _ O
boundary -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
there -X- _ O
are -X- _ O
unequal -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
each -X- _ O
quartile -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
For -X- _ O
Gigaword -X- _ O
, -X- _ O
the -X- _ O
article -X- _ O
and -X- _ O
summary -X- _ O
lengths -X- _ O
are -X- _ O
very -X- _ O
similar -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
quartiles -X- _ O
. -X- _ O
For -X- _ O
Wikihow -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
article -X- _ O
length -X- _ O
is -X- _ O
longer -X- _ O
and -X- _ O
summary -X- _ O
length -X- _ O
is -X- _ O
shorter -X- _ O
for -X- _ O
more -X- _ O
extractive -X- _ O
quartiles -X- _ O
. -X- _ O
B -X- _ O
Human -X- _ O
Annotation -X- _ O
Details -X- _ O
We -X- _ O
follow -X- _ O
a -X- _ O
similar -X- _ O
procedure -X- _ O
as -X- _ O
the -X- _ O
prior -X- _ O
work -X- _ O
to -X- _ O
collect -X- _ O
human -X- _ O
evaluations -X- _ O
for -X- _ O
faithfulness -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
summaries -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
and -X- _ O
generated -X- _ O
summaries -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
annotators -X- _ O
to -X- _ O
judge -X- _ O
whether -X- _ O
the -X- _ O
generated -X- _ O
sum- -X- _ O
mary -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
article -X- _ O
if -X- _ O
all -X- _ O
the -X- _ O
information -X- _ O
ex- -X- _ O
pressed -X- _ O
by -X- _ O
the -X- _ O
output -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
inferred -X- _ O
from -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
We -X- _ O
ask -X- _ O
annotators -X- _ O
to -X- _ O
ignore -X- _ O
minor -X- _ O
gram- -X- _ O
matical -X- _ O
errors -X- _ O
and -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
information -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
summaries -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
from -X- _ O
our -X- _ O
human -X- _ O
evaluation -X- _ O
. -X- _ O
Computing -X- _ O
faithfulness -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
200output -X- _ O
summaries -X- _ O
per -X- _ O
system -X- _ O
and -X- _ O
each -X- _ O
output -X- _ O
is -X- _ O
evaluated -X- _ O
by -X- _ O
3annotators -X- _ O
. -X- _ O
We -X- _ O
restricted -X- _ O
the -X- _ O
study -X- _ O
to -X- _ O
the -X- _ O
annotators -X- _ O
with -X- _ O
a -X- _ O
high -X- _ O
acceptance -X- _ O
rate -X- _ O
( -X- _ O
98 -X- _ O
% -X- _ O
) -X- _ O
and -X- _ O
at -X- _ O
least -X- _ O
500 -X- _ O
HITs -X- _ O
to -X- _ O
ensure -X- _ O
annotation -X- _ O
quality -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Durmus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
take -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
annotators -X- _ O
who -X- _ O
judge -X- _ O
the -X- _ O
summary -X- _ O
as -X- _ O
faithful -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
faithfulness -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
summary -X- _ O
. -X- _ O
To -X- _ O
get -X- _ O
the -X- _ O
faithfulness -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
average -X- _ O
the -X- _ O
summary -X- _ O
scores -X- _ O
across -X- _ O
all200samples.1420Dataset -X- _ O
Quartile -X- _ O
# -X- _ O
Examples -X- _ O
Article -X- _ O
Length -X- _ O
Summary -X- _ O
Length -X- _ O
GigawordQ1 -X- _ B-DatasetName
985,931 -X- _ O
30.58 -X- _ O
8.03 -X- _ O
Q2 -X- _ O
961,970 -X- _ O
32.02 -X- _ O
8.32 -X- _ O
Q3 -X- _ O
952,833 -X- _ O
31.77 -X- _ O
8.41 -X- _ O
Q4 -X- _ O
903,223 -X- _ O
31.05 -X- _ O
8.17 -X- _ O
WikihowQ1 -X- _ O
328,470 -X- _ O
50.73 -X- _ O
7.63 -X- _ O
Q2 -X- _ O
221,452 -X- _ O
75.69 -X- _ O
7.40 -X- _ O
Q3 -X- _ O
206,558 -X- _ O
85.44 -X- _ O
5.96 -X- _ O
Q4 -X- _ O
243,837 -X- _ O
92.09 -X- _ O
5.49 -X- _ O
C -X- _ O
Model -X- _ O
details -X- _ O
For -X- _ O
all -X- _ O
summarization -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
ﬁnetune -X- _ O
BART -X- _ O
( -X- _ O
406 -X- _ O
M -X- _ O
parameters -X- _ O
) -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Nvidia -X- _ O
A-100 -X- _ O
GPU -X- _ O
. -X- _ O
Each -X- _ O
model -X- _ O
takes -X- _ O
roughly -X- _ O
3hours -X- _ O
to -X- _ O
train -X- _ O
to -X- _ O
con- -X- _ O
vergence -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
selector -X- _ O
, -X- _ O
we -X- _ O
ﬁnetune -X- _ O
FactCC -X- _ O
, -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Nvidia -X- _ O
A-100 -X- _ O
GPU -X- _ O
, -X- _ O
using -X- _ O
10 -X- _ O
- -X- _ O
Fold -X- _ O
cross -X- _ O
validation -X- _ O
. -X- _ O
Finetuning -X- _ O
for -X- _ O
the -X- _ O
entire -X- _ O
cross -X- _ O
valida- -X- _ O
tion -X- _ O
procedure -X- _ O
takes -X- _ O
roughly -X- _ O
15minutes -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
all -X- _ O
artifacts -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
terms -X- _ O
indicated -X- _ O
in -X- _ O
their -X- _ O
respective -X- _ O
licenses.1421 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
explores -X- _ SUMMARY
language -X- _ SUMMARY
evolution -X- _ SUMMARY
, -X- _ SUMMARY
focusing -X- _ SUMMARY
on -X- _ SUMMARY
slang -X- _ SUMMARY
and -X- _ SUMMARY
its -X- _ SUMMARY
semantic -X- _ SUMMARY
change -X- _ SUMMARY
and -X- _ SUMMARY
frequency -X- _ SUMMARY
shift -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
propose -X- _ SUMMARY
a -X- _ SUMMARY
causal -X- _ SUMMARY
framework -X- _ SUMMARY
to -X- _ SUMMARY
analyze -X- _ SUMMARY
the -X- _ SUMMARY
dynamics -X- _ SUMMARY
of -X- _ SUMMARY
slang -X- _ SUMMARY
words -X- _ SUMMARY
compared -X- _ SUMMARY
to -X- _ SUMMARY
standard -X- _ SUMMARY
language -X- _ SUMMARY
words -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
use -X- _ SUMMARY
causal -X- _ SUMMARY
discovery -X- _ SUMMARY
and -X- _ SUMMARY
inference -X- _ SUMMARY
techniques -X- _ SUMMARY
to -X- _ SUMMARY
model -X- _ SUMMARY
the -X- _ SUMMARY
interactions -X- _ SUMMARY
between -X- _ SUMMARY
word -X- _ SUMMARY
type -X- _ SUMMARY
( -X- _ SUMMARY
slang -X- _ SUMMARY
/ -X- _ SUMMARY
nonslang -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
semantic -X- _ SUMMARY
change -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
frequency -X- _ SUMMARY
shift -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
analysis -X- _ SUMMARY
reveals -X- _ SUMMARY
that -X- _ SUMMARY
slang -X- _ SUMMARY
words -X- _ SUMMARY
undergo -X- _ SUMMARY
slower -X- _ SUMMARY
semantic -X- _ SUMMARY
change -X- _ SUMMARY
but -X- _ SUMMARY
show -X- _ SUMMARY
larger -X- _ SUMMARY
frequency -X- _ SUMMARY
shifts -X- _ SUMMARY
over -X- _ SUMMARY
time -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
study -X- _ SUMMARY
confirms -X- _ SUMMARY
a -X- _ SUMMARY
direct -X- _ SUMMARY
causal -X- _ SUMMARY
effect -X- _ SUMMARY
of -X- _ SUMMARY
word -X- _ SUMMARY
type -X- _ SUMMARY
on -X- _ SUMMARY
semantic -X- _ SUMMARY
change -X- _ SUMMARY
and -X- _ SUMMARY
frequency -X- _ SUMMARY
shift -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
findings -X- _ SUMMARY
also -X- _ SUMMARY
shed -X- _ SUMMARY
light -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
relationship -X- _ SUMMARY
between -X- _ SUMMARY
word -X- _ SUMMARY
polysemy -X- _ SUMMARY
and -X- _ SUMMARY
frequency -X- _ SUMMARY
, -X- _ SUMMARY
supporting -X- _ SUMMARY
the -X- _ SUMMARY
S -X- _ SUMMARY
- -X- _ SUMMARY
curve -X- _ SUMMARY
theory -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
study -X- _ SUMMARY
contributes -X- _ SUMMARY
to -X- _ SUMMARY
the -X- _ SUMMARY
understanding -X- _ SUMMARY
of -X- _ SUMMARY
language -X- _ SUMMARY
change -X- _ SUMMARY
dynamics -X- _ SUMMARY
and -X- _ SUMMARY
provides -X- _ SUMMARY
insights -X- _ SUMMARY
about -X- _ SUMMARY
the -X- _ SUMMARY
distinctive -X- _ SUMMARY
properties -X- _ SUMMARY
of -X- _ SUMMARY
slang -X- _ SUMMARY
words -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
is -X- _ SUMMARY
based -X- _ SUMMARY
on -X- _ SUMMARY
a -X- _ SUMMARY
curated -X- _ SUMMARY
Twitter -X- _ SUMMARY
dataset -X- _ SUMMARY
from -X- _ SUMMARY
2010 -X- _ SUMMARY
and -X- _ SUMMARY
2020 -X- _ SUMMARY
and -X- _ SUMMARY
employs -X- _ SUMMARY
causal -X- _ SUMMARY
analysis -X- _ SUMMARY
methods -X- _ SUMMARY
to -X- _ SUMMARY
uncover -X- _ SUMMARY
causal -X- _ SUMMARY
relationships -X- _ SUMMARY
in -X- _ SUMMARY
language -X- _ SUMMARY
evolution -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.101.txt -X- _ O
Daphna -X- _ O
KeidarAndreas -X- _ O
OpedalZhijing -X- _ O
JinMrinmaya -X- _ O
SachanETH -X- _ O
Zürich -X- _ O
, -X- _ O
Max -X- _ O
Planck -X- _ O
Institute -X- _ O
for -X- _ O
Intelligent -X- _ O
Systems -X- _ O
, -X- _ O
Tübingen -X- _ O
, -X- _ O
Germany -X- _ O
dkeidar -X- _ O
@ -X- _ O
ethz.ch -X- _ O
, -X- _ O
andreas.opedal -X- _ O
@ -X- _ O
inf.ethz.ch -X- _ O
, -X- _ O
zjin -X- _ O
@ -X- _ O
tue.mpg.de -X- _ O
, -X- _ O
mrinmaya.sachan -X- _ O
@ -X- _ O
inf.ethz.ch -X- _ O
Abstract -X- _ O
Languages -X- _ O
are -X- _ O
continuously -X- _ O
undergoing -X- _ O
changes -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
mechanisms -X- _ O
that -X- _ O
underlie -X- _ O
these -X- _ O
changes -X- _ O
are -X- _ O
still -X- _ O
a -X- _ O
matter -X- _ O
of -X- _ O
debate -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
approach -X- _ O
language -X- _ B-TaskName
evolution -X- _ I-TaskName
through -X- _ O
the -X- _ O
lens -X- _ O
of -X- _ O
causality -X- _ B-MethodName
in -X- _ O
order -X- _ O
to -X- _ O
model -X- _ O
not -X- _ O
only -X- _ O
how -X- _ O
various -X- _ O
distributional -X- _ O
factors -X- _ O
associate -X- _ O
with -X- _ O
language -X- _ O
change -X- _ O
, -X- _ O
but -X- _ O
how -X- _ O
they -X- _ O
causally -X- _ O
affect -X- _ O
it -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
slang -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
informal -X- _ O
language -X- _ O
that -X- _ O
is -X- _ O
typically -X- _ O
restricted -X- _ O
to -X- _ O
a -X- _ O
speciﬁc -X- _ O
group -X- _ O
or -X- _ O
social -X- _ O
setting -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
compare -X- _ O
them -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
standard -X- _ O
, -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
With -X- _ O
causal -X- _ B-TaskName
discovery -X- _ I-TaskName
and -X- _ O
causal -X- _ B-TaskName
inference -X- _ I-TaskName
techniques -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
effect -X- _ O
that -X- _ O
word -X- _ O
type -X- _ O
( -X- _ O
slang -X- _ O
/ -X- _ O
nonslang -X- _ O
) -X- _ O
has -X- _ O
on -X- _ O
both -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
its -X- _ O
relationship -X- _ O
to -X- _ O
frequency -X- _ O
, -X- _ O
polysemy -X- _ O
and -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
provides -X- _ O
some -X- _ O
new -X- _ O
insights -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
language -X- _ O
change -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
slang -X- _ O
words -X- _ O
undergo -X- _ O
less -X- _ O
semantic -X- _ O
change -X- _ O
but -X- _ O
tend -X- _ O
to -X- _ O
have -X- _ O
larger -X- _ O
frequency -X- _ O
shifts -X- _ O
over -X- _ O
time -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Language -X- _ O
is -X- _ O
a -X- _ O
continuously -X- _ O
evolving -X- _ O
system -X- _ O
, -X- _ O
con- -X- _ O
stantly -X- _ O
resculptured -X- _ O
by -X- _ O
its -X- _ O
speakers -X- _ O
. -X- _ O
The -X- _ O
forces -X- _ O
that -X- _ O
drive -X- _ O
this -X- _ O
evolution -X- _ O
are -X- _ O
many -X- _ O
, -X- _ O
ranging -X- _ O
from -X- _ O
pho- -X- _ O
netic -X- _ O
convenience -X- _ O
to -X- _ O
sociocultural -X- _ O
changes -X- _ O
( -X- _ O
Blank -X- _ O
, -X- _ O
1999 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
meanings -X- _ O
of -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
frequencies -X- _ O
in -X- _ O
which -X- _ O
they -X- _ O
are -X- _ O
used -X- _ O
are -X- _ O
not -X- _ O
static -X- _ O
, -X- _ O
but -X- _ O
rather -X- _ O
evolve -X- _ O
over -X- _ O
time -X- _ O
. -X- _ O
Several -X- _ O
pre- -X- _ O
vious -X- _ O
works -X- _ O
, -X- _ O
in -X- _ O
both -X- _ O
historical -X- _ O
and -X- _ O
computational -X- _ O
linguistics -X- _ O
, -X- _ O
have -X- _ O
described -X- _ O
diachronic -X- _ O
mechanisms -X- _ O
, -X- _ O
often -X- _ O
suggesting -X- _ O
causal -X- _ O
relationships -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
i.e. -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
, -X- _ O
has -X- _ O
both -X- _ O
been -X- _ O
suggested -X- _ O
to -X- _ O
cause -X- _ O
( -X- _ O
Wilkins -X- _ O
, -X- _ O
1993 -X- _ O
; -X- _ O
Hopper -X- _ O
and -X- _ O
Traugott -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
and -X- _ O
be -X- _ O
caused -X- _ O
by -X- _ O
( -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
polysemy -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
partFigure -X- _ O
1 -X- _ O
: -X- _ O
We -X- _ O
observe -X- _ O
very -X- _ O
different -X- _ O
change -X- _ O
dynamics -X- _ O
for -X- _ O
the -X- _ O
slang -X- _ O
word -X- _ O
“ -X- _ O
duckface -X- _ O
” -X- _ O
and -X- _ O
the -X- _ O
nonslang -X- _ O
word -X- _ O
“ -X- _ O
inclusive -X- _ O
. -X- _ O
” -X- _ O
“ -X- _ O
Inclusive -X- _ O
” -X- _ O
has -X- _ O
acquired -X- _ O
a -X- _ O
new -X- _ O
meaning -X- _ O
, -X- _ O
reﬂected -X- _ O
in -X- _ O
a -X- _ O
high -X- _ O
semantic -X- _ O
change -X- _ O
score -X- _ O
of -X- _ O
0:77as -X- _ O
measured -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
“ -X- _ O
Duckface -X- _ O
” -X- _ O
undergoes -X- _ O
little -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
scored -X- _ O
0:39by -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
while -X- _ O
its -X- _ O
usage -X- _ O
frequency -X- _ O
varies -X- _ O
greatly -X- _ O
. -X- _ O
of -X- _ O
speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
implied -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
causal -X- _ O
factor -X- _ O
behind -X- _ O
semantic -X- _ O
change -X- _ O
( -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
these -X- _ O
studies -X- _ O
perform -X- _ O
a -X- _ O
causal -X- _ O
analysis -X- _ O
to -X- _ O
verify -X- _ O
these -X- _ O
claims -X- _ O
. -X- _ O
Causality -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
not -X- _ O
only -X- _ O
infer -X- _ O
causal -X- _ O
ef- -X- _ O
fects -X- _ O
between -X- _ O
pairs -X- _ O
of -X- _ O
variables -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
model -X- _ O
their -X- _ O
interactions -X- _ O
with -X- _ O
other -X- _ O
related -X- _ O
factors -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
linguistic -X- _ O
evolution -X- _ O
of -X- _ O
slang -X- _ O
, -X- _ O
deﬁned -X- _ O
as -X- _ O
colloquial -X- _ O
and -X- _ O
informal -X- _ O
lan- -X- _ O
guage -X- _ O
commonly -X- _ O
associated -X- _ O
with -X- _ O
particular -X- _ O
groups -X- _ O
( -X- _ O
González -X- _ O
, -X- _ O
1998 -X- _ O
; -X- _ O
Bembe -X- _ O
and -X- _ O
Beukes -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
causal -X- _ O
framework -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
change -X- _ O
dynamics -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
standard -X- _ O
lan- -X- _ O
guage -X- _ O
. -X- _ O
More -X- _ O
speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
changes -X- _ O
in -X- _ O
frequency -X- _ O
, -X- _ O
i.e. -X- _ O
,1422frequency -X- _ O
shift -X- _ O
, -X- _ O
over -X- _ O
time -X- _ O
between -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
standard -X- _ O
, -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
learn -X- _ O
a -X- _ O
causal -X- _ B-MethodName
graphical -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
Spirtes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
to -X- _ O
assess -X- _ O
how -X- _ O
these -X- _ O
variables -X- _ O
interact -X- _ O
with -X- _ O
other -X- _ O
factors -X- _ O
they -X- _ O
have -X- _ O
been -X- _ O
previously -X- _ O
found -X- _ O
to -X- _ O
correlate -X- _ O
with -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
fre- -X- _ O
quency -X- _ O
, -X- _ O
polysemy -X- _ O
andpart -X- _ O
of -X- _ O
speech -X- _ O
( -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Having -X- _ O
discov- -X- _ O
ered -X- _ O
a -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
proceed -X- _ O
to -X- _ O
use -X- _ O
do -X- _ O
- -X- _ O
calculus -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
causal -X- _ O
effects -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
type -X- _ O
( -X- _ O
slang -X- _ O
/ -X- _ O
nonslang -X- _ O
) -X- _ O
on -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
. -X- _ O
Semantic -X- _ O
change -X- _ O
is -X- _ O
measured -X- _ O
using -X- _ O
the -X- _ O
average -X- _ B-MetricName
pairwise -X- _ I-MetricName
distance -X- _ I-MetricName
( -X- _ O
APD -X- _ B-MetricName
) -X- _ O
( -X- _ O
Sagi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Giu- -X- _ O
lianelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
between -X- _ O
time -X- _ O
- -X- _ O
separated -X- _ O
con- -X- _ O
textualized -X- _ O
representations -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
obtained -X- _ O
from -X- _ O
a -X- _ O
Twitter -X- _ O
corpus -X- _ O
via -X- _ O
a -X- _ O
bi -X- _ B-MethodName
- -X- _ I-MethodName
directional -X- _ I-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
builds -X- _ O
on -X- _ O
re- -X- _ O
cent -X- _ O
semantic -X- _ O
change -X- _ O
literature -X- _ O
( -X- _ O
Schlechtweg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
novel -X- _ O
additions -X- _ O
of -X- _ O
dimensionality -X- _ O
re- -X- _ O
duction -X- _ O
and -X- _ O
a -X- _ O
combined -X- _ O
distance -X- _ O
function -X- _ O
. -X- _ O
By -X- _ O
deploying -X- _ O
a -X- _ O
causal -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
establish -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
not -X- _ O
just -X- _ O
an -X- _ O
association -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
direct -X- _ O
effect -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
type -X- _ O
on -X- _ O
its -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
being -X- _ O
slang -X- _ O
causes -X- _ O
it -X- _ O
to -X- _ O
undergo -X- _ O
slower -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
more -X- _ O
rapid -X- _ O
decreases -X- _ O
in -X- _ O
frequency -X- _ O
. -X- _ O
To -X- _ O
illustrate -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
slang -X- _ O
word -X- _ O
“ -X- _ O
duckface -X- _ O
” -X- _ O
and -X- _ O
the -X- _ O
nonslang -X- _ O
word -X- _ O
“ -X- _ O
in- -X- _ O
clusive -X- _ O
” -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
Duckface -X- _ O
is -X- _ O
a -X- _ O
face -X- _ O
pose -X- _ O
commonly -X- _ O
made -X- _ O
for -X- _ O
photos -X- _ O
( -X- _ O
Miller -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
early -X- _ O
2010s -X- _ O
, -X- _ O
and -X- _ O
while -X- _ O
it -X- _ O
has -X- _ O
largely -X- _ O
de- -X- _ O
creased -X- _ O
in -X- _ O
frequency -X- _ O
since -X- _ O
, -X- _ O
its -X- _ O
meaning -X- _ O
has -X- _ O
not -X- _ O
changed -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
nonslang -X- _ O
word -X- _ O
“ -X- _ O
inclu- -X- _ O
sive -X- _ O
” -X- _ O
has -X- _ O
developed -X- _ O
a -X- _ O
new -X- _ O
usage -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
Merriam -X- _ O
- -X- _ O
Webster -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
was -X- _ O
given -X- _ O
a -X- _ O
high -X- _ O
se- -X- _ O
mantic -X- _ O
change -X- _ O
score -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
also -X- _ O
sheds -X- _ O
light -X- _ O
on -X- _ O
a -X- _ O
couple -X- _ O
of -X- _ O
pre- -X- _ O
vious -X- _ O
ﬁndings -X- _ O
in -X- _ O
the -X- _ O
diachronic -X- _ O
linguistics -X- _ O
litera- -X- _ O
ture -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
support -X- _ O
for -X- _ O
the -X- _ O
S -X- _ O
- -X- _ O
curve -X- _ O
theory -X- _ O
( -X- _ O
Kroch -X- _ O
, -X- _ O
1989 -X- _ O
) -X- _ O
, -X- _ O
showing -X- _ O
a -X- _ O
causal -X- _ O
effect -X- _ O
from -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
pol- -X- _ O
ysemy -X- _ O
to -X- _ O
its -X- _ O
frequency -X- _ O
. -X- _ O
This -X- _ O
relationship -X- _ O
is -X- _ O
ev- -X- _ O
ident -X- _ O
in -X- _ O
the -X- _ O
increase -X- _ O
in -X- _ O
frequency -X- _ O
that -X- _ O
the -X- _ O
word -X- _ O
“ -X- _ O
inclusive -X- _ O
” -X- _ O
displays -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
after -X- _ O
it -X- _ O
develops -X- _ O
a -X- _ O
new -X- _ O
meaning -X- _ O
( -X- _ O
Merriam -X- _ O
- -X- _ O
Webster -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
How- -X- _ O
ever -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
ﬁnd -X- _ O
causal -X- _ O
links -X- _ O
to -X- _ O
semantic -X- _ O
change -X- _ O
from -X- _ O
fre- -X- _ O
quency -X- _ O
, -X- _ O
polysemy -X- _ O
, -X- _ O
or -X- _ O
POS -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
sug- -X- _ O
gested -X- _ O
in -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
three- -X- _ O
fold -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
we -X- _ O
formalize -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
change -X- _ O
dy- -X- _ O
namics -X- _ O
in -X- _ O
language -X- _ O
with -X- _ O
a -X- _ O
causal -X- _ O
framework -X- _ O
; -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
semantic -X- _ O
change -X- _ O
metric -X- _ O
that -X- _ O
builds -X- _ O
upon -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
we -X- _ O
discover -X- _ O
interesting -X- _ O
insights -X- _ O
about -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
semantic -X- _ O
change -X- _ O
– -X- _ O
e.g. -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
the -X- _ O
change -X- _ O
dynamics -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
are -X- _ O
different -X- _ O
from -X- _ O
those -X- _ O
of -X- _ O
nonslang -X- _ O
words -X- _ O
, -X- _ O
with -X- _ O
slang -X- _ O
words -X- _ O
exhibiting -X- _ O
both -X- _ O
more -X- _ O
rapid -X- _ O
frequency -X- _ O
ﬂuctuations -X- _ O
and -X- _ O
less -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
2.1 -X- _ O
Semantic -X- _ O
Change -X- _ O
A -X- _ O
typical -X- _ O
method -X- _ O
for -X- _ O
measuring -X- _ O
semantic -X- _ O
change -X- _ O
is -X- _ O
by -X- _ O
comparing -X- _ O
word -X- _ O
representations -X- _ O
across -X- _ O
time -X- _ O
periods -X- _ O
( -X- _ O
Gulordava -X- _ O
and -X- _ O
Baroni -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Jatowt -X- _ O
and -X- _ O
Duh -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Kulkarni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Eger -X- _ O
and -X- _ O
Mehler -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Schlechtweg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
this -X- _ O
approach -X- _ O
, -X- _ O
previous -X- _ O
research -X- _ O
has -X- _ O
proposed -X- _ O
laws -X- _ O
relating -X- _ O
semantic -X- _ O
change -X- _ O
to -X- _ O
other -X- _ O
linguistic -X- _ O
properties -X- _ O
( -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Xu -X- _ O
and -X- _ O
Kemp -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
ﬁnd -X- _ O
that -X- _ O
verbs -X- _ O
change -X- _ O
faster -X- _ O
than -X- _ O
nouns -X- _ O
, -X- _ O
whereas -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
discover -X- _ O
that -X- _ O
polysemous -X- _ O
words -X- _ O
change -X- _ O
at -X- _ O
a -X- _ O
faster -X- _ O
rate -X- _ O
, -X- _ O
while -X- _ O
frequent -X- _ O
words -X- _ O
change -X- _ O
slower -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
some -X- _ O
of -X- _ O
these -X- _ O
results -X- _ O
has -X- _ O
been -X- _ O
questioned -X- _ O
via -X- _ O
case -X- _ O
- -X- _ O
control -X- _ O
matching -X- _ O
( -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
highlighting -X- _ O
the -X- _ O
inﬂuence -X- _ O
of -X- _ O
word -X- _ O
frequency -X- _ O
on -X- _ O
the -X- _ O
represen- -X- _ O
tations -X- _ O
and -X- _ O
thus -X- _ O
on -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
metric -X- _ O
( -X- _ O
Hellrich -X- _ O
and -X- _ O
Hahn -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
analyses -X- _ O
can -X- _ O
in- -X- _ O
deed -X- _ O
give -X- _ O
stronger -X- _ O
evidence -X- _ O
for -X- _ O
causal -X- _ O
effects -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
methodologically -X- _ O
different -X- _ O
ap- -X- _ O
proach -X- _ O
, -X- _ O
considering -X- _ O
observational -X- _ O
data -X- _ O
alone -X- _ O
for -X- _ O
our -X- _ O
causal -X- _ O
analysis -X- _ O
. -X- _ O
The -X- _ O
aforementioned -X- _ O
works -X- _ O
rely -X- _ O
on -X- _ O
ﬁxed -X- _ O
word -X- _ O
representations -X- _ O
, -X- _ O
whereas -X- _ O
more -X- _ O
recent -X- _ O
approaches -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Giulianelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
pro- -X- _ O
posed -X- _ O
semantic -X- _ O
change -X- _ O
measures -X- _ O
based -X- _ O
on -X- _ O
con- -X- _ O
textualized -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
ﬂexibly -X- _ O
capture -X- _ O
con- -X- _ O
textual -X- _ O
nuances -X- _ O
in -X- _ O
word -X- _ O
meaning -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
further -X- _ O
stream -X- _ O
of -X- _ O
work -X- _ O
on -X- _ O
semantic -X- _ B-TaskName
change -X- _ I-TaskName
detection -X- _ I-TaskName
with -X- _ O
contextualized -X- _ O
embeddings -X- _ O
( -X- _ O
Mar- -X- _ O
tinc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kutuzov -X- _ O
and -X- _ O
Giulianelli -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Schlechtweg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Montariol -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Kutuzov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Laicher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
upon -X- _ O
this -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
and -X- _ O
extend -X- _ O
them -X- _ O
using -X- _ O
principal -X- _ B-MethodName
component -X- _ I-MethodName
analysis -X- _ I-MethodName
( -X- _ O
PCA -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
combi- -X- _ O
nation -X- _ O
of -X- _ O
distance -X- _ O
metrics.14232.2 -X- _ O
Characterization -X- _ O
and -X- _ O
Properties -X- _ O
of -X- _ O
Slang -X- _ O
Slang -X- _ O
is -X- _ O
an -X- _ O
informal -X- _ O
, -X- _ O
unconventional -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
, -X- _ O
often -X- _ O
used -X- _ O
in -X- _ O
connection -X- _ O
to -X- _ O
a -X- _ O
certain -X- _ O
setting -X- _ O
or -X- _ O
societal -X- _ O
trend -X- _ O
( -X- _ O
Dumas -X- _ O
and -X- _ O
Lighter -X- _ O
, -X- _ O
1978 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
reﬂect -X- _ O
and -X- _ O
establish -X- _ O
a -X- _ O
sense -X- _ O
of -X- _ O
belonging -X- _ O
to -X- _ O
a -X- _ O
group -X- _ O
( -X- _ O
González -X- _ O
, -X- _ O
1998 -X- _ O
; -X- _ O
Bembe -X- _ O
and -X- _ O
Beukes -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Carter -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
or -X- _ O
to -X- _ O
a -X- _ O
generation -X- _ O
( -X- _ O
Citera -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Earl -X- _ O
, -X- _ O
1972 -X- _ O
; -X- _ O
Barbieri -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
Mattiello -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
highlights -X- _ O
the -X- _ O
role -X- _ O
slang -X- _ O
plays -X- _ O
in -X- _ O
enriching -X- _ O
the -X- _ O
language -X- _ O
with -X- _ O
neologisms -X- _ O
, -X- _ O
and -X- _ O
claims -X- _ O
that -X- _ O
it -X- _ O
follows -X- _ O
unique -X- _ O
word -X- _ O
formation -X- _ O
pro- -X- _ O
cesses -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
this -X- _ O
, -X- _ O
Kulkarni -X- _ O
and -X- _ O
Wang -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
model -X- _ O
for -X- _ O
emulating -X- _ O
the -X- _ O
gen- -X- _ O
eration -X- _ O
process -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
that -X- _ O
Mattiello -X- _ O
( -X- _ O
2005 -X- _ O
) -X- _ O
describes -X- _ O
. -X- _ O
Others -X- _ O
have -X- _ O
described -X- _ O
the -X- _ O
ephemeral- -X- _ O
ity -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
( -X- _ O
González -X- _ O
, -X- _ O
1998 -X- _ O
; -X- _ O
Carter -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
although -X- _ O
this -X- _ O
property -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
previously -X- _ O
ver- -X- _ O
iﬁed -X- _ O
by -X- _ O
computational -X- _ O
approaches -X- _ O
. -X- _ O
3 -X- _ O
Causal -X- _ B-MethodName
Methodology -X- _ I-MethodName
for -X- _ O
Change -X- _ O
Dynamics -X- _ O
Examining -X- _ O
change -X- _ O
dynamics -X- _ O
through -X- _ O
a -X- _ O
causal -X- _ O
lens -X- _ O
helps -X- _ O
determine -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
direct -X- _ O
causal -X- _ O
ef- -X- _ O
fects -X- _ O
, -X- _ O
by -X- _ O
modeling -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
vari- -X- _ O
ables -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
conclude -X- _ O
whether -X- _ O
word -X- _ O
type -X- _ O
directly -X- _ O
inﬂuences -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
or -X- _ O
rather -X- _ O
inﬂuences -X- _ O
polysemy -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
turn -X- _ O
causes -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
give -X- _ O
a -X- _ O
short -X- _ O
overview -X- _ O
of -X- _ O
relevant -X- _ O
work -X- _ O
on -X- _ O
causality -X- _ O
, -X- _ O
before -X- _ O
presenting -X- _ O
how -X- _ O
we -X- _ O
apply -X- _ O
these -X- _ O
concepts -X- _ O
to -X- _ O
word -X- _ O
change -X- _ O
dynamics -X- _ O
. -X- _ O
3.1 -X- _ O
Overview -X- _ O
of -X- _ O
Causal -X- _ B-MetricValue
Discovery -X- _ I-MetricValue
and -X- _ O
Causal -X- _ B-MetricValue
Inference -X- _ I-MetricValue
A -X- _ O
common -X- _ O
framework -X- _ O
for -X- _ O
causal -X- _ B-MetricValue
reasoning -X- _ I-MetricValue
is -X- _ O
through -X- _ O
causal -X- _ B-MethodName
directed -X- _ I-MethodName
acyclic -X- _ I-MethodName
graphs -X- _ I-MethodName
( -X- _ O
DAGs -X- _ O
) -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
causal -X- _ B-MethodName
DAG -X- _ I-MethodName
consists -X- _ O
of -X- _ O
a -X- _ O
pair -X- _ O
( -X- _ O
G -X- _ O
; -X- _ O
P -X- _ O
) -X- _ O
whereG= -X- _ O
( -X- _ O
V -X- _ O
; -X- _ O
E -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
DAG -X- _ O
and -X- _ O
Pis -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
variables -X- _ O
. -X- _ O
Each -X- _ O
variable -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
node -X- _ O
v2V -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
graph -X- _ O
’s -X- _ O
edges -X- _ O
e2Ereﬂect -X- _ O
causal -X- _ O
relationships -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
main -X- _ O
tasks -X- _ O
in -X- _ O
causality -X- _ O
. -X- _ O
Causal -X- _ O
dis- -X- _ O
covery -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
uncovering -X- _ O
the -X- _ O
causal -X- _ B-MethodName
DAG -X- _ I-MethodName
that -X- _ O
explains -X- _ O
observed -X- _ O
data -X- _ O
. -X- _ O
Assuming -X- _ O
a -X- _ O
causal -X- _ B-MethodName
DAG -X- _ I-MethodName
, -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
causal -X- _ O
inference -X- _ O
then -X- _ O
concerns -X- _ O
determining -X- _ O
the -X- _ O
effect -X- _ O
that -X- _ O
intervening -X- _ O
on -X- _ O
a -X- _ O
vari- -X- _ O
able -X- _ O
, -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
treatment -X- _ O
, -X- _ O
will -X- _ O
have -X- _ O
on -X- _ O
another -X- _ O
variable -X- _ O
, -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
outcome -X- _ O
. -X- _ O
The -X- _ O
causal -X- _ O
DAG -X- _ O
is -X- _ O
often -X- _ O
inferred -X- _ O
from -X- _ O
domain -X- _ O
knowledge -X- _ O
or -X- _ O
intuition -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
cases -X- _ O
where -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
safely -X- _ O
assume -X- _ O
a -X- _ O
known -X- _ O
causal -X- _ O
struc -X- _ O
- -X- _ O
ture -X- _ O
, -X- _ O
causal -X- _ O
discovery -X- _ O
methods -X- _ O
come -X- _ O
in -X- _ O
useful -X- _ O
. -X- _ O
Constraint -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Spirtes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
form -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
categories -X- _ O
of -X- _ O
causal -X- _ O
discov- -X- _ O
ery -X- _ O
techniques -X- _ O
. -X- _ O
These -X- _ O
methods -X- _ O
use -X- _ O
conditional -X- _ O
independence -X- _ O
tests -X- _ O
between -X- _ O
variables -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
uncover -X- _ O
the -X- _ O
causal -X- _ O
structure -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
they -X- _ O
rely -X- _ O
on -X- _ O
two -X- _ O
main -X- _ O
assumptions -X- _ O
: -X- _ O
that -X- _ O
the -X- _ O
graph -X- _ O
fulﬁlls -X- _ O
the -X- _ O
global -X- _ O
Markov -X- _ O
property -X- _ O
and -X- _ O
the -X- _ O
faithfulness -X- _ O
assumption -X- _ O
. -X- _ O
Together -X- _ O
they -X- _ O
state -X- _ O
that -X- _ O
we -X- _ O
observe -X- _ O
conditional -X- _ O
independence -X- _ O
relations -X- _ O
between -X- _ O
two -X- _ O
variables -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
if -X- _ O
and -X- _ O
only -X- _ O
if -X- _ O
these -X- _ O
two -X- _ O
variables -X- _ O
are -X- _ O
d -X- _ O
- -X- _ O
separated -X- _ O
( -X- _ O
Geiger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1990 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
graphical -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
D.1 -X- _ O
. -X- _ O
Causal -X- _ O
inference -X- _ O
is -X- _ O
commonly -X- _ O
approached -X- _ O
with -X- _ O
do -X- _ O
- -X- _ O
calculus -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
the -X- _ O
interven- -X- _ O
tion -X- _ O
distribution -X- _ O
P -X- _ O
( -X- _ O
Yjdo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
distri- -X- _ O
bution -X- _ O
of -X- _ O
the -X- _ O
outcome -X- _ O
Yconditioned -X- _ O
on -X- _ O
an -X- _ O
inter- -X- _ O
ventiondo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
which -X- _ O
forces -X- _ O
the -X- _ O
treatment -X- _ O
variableXto -X- _ O
take -X- _ O
on -X- _ O
the -X- _ O
value -X- _ O
x. -X- _ O
Note -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
in -X- _ O
general -X- _ O
not -X- _ O
necessarily -X- _ O
equal -X- _ O
to -X- _ O
P -X- _ O
( -X- _ O
YjX -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
equal -X- _ O
, -X- _ O
we -X- _ O
say -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
con- -X- _ O
founding -X- _ O
. -X- _ O
Confounding -X- _ O
occurs -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
third -X- _ O
variableZ -X- _ O
, -X- _ O
which -X- _ O
causes -X- _ O
both -X- _ O
the -X- _ O
treatment -X- _ O
Xand -X- _ O
the -X- _ O
outcome -X- _ O
Y. -X- _ O
We -X- _ O
say -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
causal -X- _ O
effect -X- _ O
of -X- _ O
XonYif -X- _ O
there -X- _ O
existxandxsuch -X- _ O
that -X- _ O
P -X- _ O
( -X- _ O
Yjdo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
6 -X- _ O
= -X- _ O
P -X- _ O
( -X- _ O
Yjdo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
One -X- _ O
way -X- _ O
to -X- _ O
quantify -X- _ O
the -X- _ O
causal -X- _ O
effect -X- _ O
is -X- _ O
with -X- _ O
the -X- _ O
average -X- _ O
causal -X- _ O
effect -X- _ O
( -X- _ O
ACE -X- _ O
) -X- _ O
: -X- _ O
E -X- _ O
[ -X- _ O
Yjdo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
] -X- _ O
E -X- _ O
[ -X- _ O
Yjdo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
] -X- _ O
: -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
To -X- _ O
estimate -X- _ O
the -X- _ O
causal -X- _ O
effect -X- _ O
using -X- _ O
observational -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
rewrite -X- _ O
the -X- _ O
intervention -X- _ O
distribu- -X- _ O
tion -X- _ O
using -X- _ O
only -X- _ O
conditional -X- _ O
distributions -X- _ O
. -X- _ O
Assuming -X- _ O
a -X- _ O
causal -X- _ B-MethodName
DAG -X- _ I-MethodName
, -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
done -X- _ O
with -X- _ O
the -X- _ O
truncated -X- _ O
factorization -X- _ O
formula -X- _ O
( -X- _ O
Pearl -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
Xjdo -X- _ O
( -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
= -X- _ O
YP -X- _ O
( -X- _ O
XjX -X- _ O
) -X- _ O
1 -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
forWV -X- _ O
, -X- _ O
withXbeing -X- _ O
the -X- _ O
variables -X- _ O
in -X- _ O
P -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
nodes -X- _ O
in -X- _ O
W.14243.2 -X- _ O
Causality -X- _ O
for -X- _ O
Change -X- _ O
Dynamics -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
estimate -X- _ O
the -X- _ O
direct -X- _ O
causal -X- _ O
effect -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
type -X- _ O
on -X- _ O
its -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
dynamics -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
establish -X- _ O
that -X- _ O
such -X- _ O
an -X- _ O
effect -X- _ O
exists -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
know -X- _ O
which -X- _ O
variables -X- _ O
to -X- _ O
control -X- _ O
for -X- _ O
, -X- _ O
we -X- _ O
turn -X- _ O
to -X- _ O
causal -X- _ O
discovery -X- _ O
algorithms -X- _ O
. -X- _ O
The -X- _ O
variables -X- _ O
in -X- _ O
our -X- _ O
causal -X- _ O
graph -X- _ O
additionally -X- _ O
include -X- _ O
frequency -X- _ O
, -X- _ O
polysemy -X- _ O
and -X- _ O
POS -X- _ O
. -X- _ O
For -X- _ O
learning -X- _ O
the -X- _ O
causal -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
constraint -X- _ O
- -X- _ O
based -X- _ O
PC -X- _ B-MethodName
- -X- _ I-MethodName
stable -X- _ I-MethodName
algorithm -X- _ I-MethodName
( -X- _ O
Colombo -X- _ O
and -X- _ O
Maathuis -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
order -X- _ O
- -X- _ O
independent -X- _ O
vari- -X- _ O
ant -X- _ O
of -X- _ O
the -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
PC -X- _ O
algorithm -X- _ O
( -X- _ O
Spirtes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
discussed -X- _ O
in -X- _ O
Appendix -X- _ O
D.1 -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
learn- -X- _ O
ing -X- _ O
a -X- _ O
mixed -X- _ B-MethodName
graphical -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
Lauritzen -X- _ O
, -X- _ O
1996 -X- _ O
; -X- _ O
Lee -X- _ O
and -X- _ O
Hastie -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
both -X- _ O
continuous -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
frequency -X- _ O
) -X- _ O
and -X- _ O
categorical -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
type -X- _ O
) -X- _ O
vari- -X- _ O
ables -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
reason -X- _ O
we -X- _ O
opt -X- _ O
for -X- _ O
constraint -X- _ O
- -X- _ O
based -X- _ O
algorithms -X- _ O
, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
tailor -X- _ O
the -X- _ O
conditional -X- _ O
independence -X- _ O
tests -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
various -X- _ O
data -X- _ O
types -X- _ O
. -X- _ O
Having -X- _ O
learned -X- _ O
the -X- _ O
causal -X- _ O
graph -X- _ O
( -X- _ O
Section -X- _ O
6.2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
proceed -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
ACE -X- _ B-MetricName
of -X- _ O
word -X- _ O
type -X- _ O
on -X- _ O
both -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
using -X- _ O
do -X- _ O
- -X- _ O
calculus -X- _ O
( -X- _ O
Section -X- _ O
6.3 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
Slang -X- _ O
and -X- _ O
Nonslang -X- _ O
Word -X- _ O
Selection -X- _ O
We -X- _ O
select -X- _ O
100 -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
100 -X- _ O
nonslang -X- _ O
words -X- _ O
for -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
E. -X- _ O
In -X- _ O
the -X- _ O
trade- -X- _ O
off -X- _ O
between -X- _ O
statistical -X- _ O
signiﬁcance -X- _ O
and -X- _ O
time -X- _ O
spent -X- _ O
on -X- _ O
computation -X- _ O
and -X- _ O
data -X- _ O
collection -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
200 -X- _ O
words -X- _ O
was -X- _ O
enough -X- _ O
to -X- _ O
get -X- _ O
highly -X- _ O
sig- -X- _ O
niﬁcant -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
slang -X- _ O
words -X- _ O
are -X- _ O
randomly -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
Online -X- _ B-DatasetName
Slang -X- _ I-DatasetName
Dictionary -X- _ I-DatasetName
, -X- _ O
which -X- _ O
provides -X- _ O
well -X- _ O
- -X- _ O
maintained -X- _ O
and -X- _ O
curated -X- _ O
slang -X- _ O
word -X- _ O
deﬁnitions -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
4,828 -X- _ O
featured -X- _ O
slang -X- _ O
words -X- _ O
as -X- _ O
of -X- _ O
June -X- _ O
2021 -X- _ O
. -X- _ O
We -X- _ O
limit -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
our -X- _ O
study -X- _ O
to -X- _ O
only -X- _ O
encompass -X- _ O
single -X- _ O
- -X- _ O
word -X- _ O
expressions -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
so -X- _ O
doing -X- _ O
we -X- _ O
ﬁlter -X- _ O
out -X- _ O
2,169 -X- _ O
multi -X- _ O
- -X- _ O
word -X- _ O
expressions -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
clean -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
delete -X- _ O
words -X- _ O
with -X- _ O
only -X- _ O
one -X- _ O
character -X- _ O
and -X- _ O
acronyms -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
we -X- _ O
limit -X- _ O
the -X- _ O
causal -X- _ O
analysis -X- _ O
to -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
exclusively -X- _ O
either -X- _ O
slang -X- _ O
or -X- _ O
nonslang -X- _ O
, -X- _ O
excluding -X- _ O
“ -X- _ O
hybrid -X- _ O
” -X- _ O
words -X- _ O
with -X- _ O
both -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
mean- -X- _ O
ings -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
“ -X- _ O
kosher -X- _ O
” -X- _ O
or -X- _ O
“ -X- _ O
tool -X- _ O
. -X- _ O
” -X- _ O
Including -X- _ O
words -X- _ O
of -X- _ O
this -X- _ O
type -X- _ O
would -X- _ O
have -X- _ O
interfered -X- _ O
with -X- _ O
the -X- _ O
causal -X- _ O
analysis -X- _ O
by -X- _ O
creating -X- _ O
a -X- _ O
hardcoded -X- _ O
dependency -X- _ O
be- -X- _ O
tween -X- _ O
word -X- _ O
type -X- _ O
and -X- _ O
polysemy -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
words -X- _ O
by -X- _ O
deﬁnition -X- _ O
are -X- _ O
polysemous -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
however -X- _ O
per- -X- _ O
form -X- _ O
a -X- _ O
separate -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
hybrid -X- _ O
words -X- _ O
in -X- _ O
Appendix -X- _ O
C.For -X- _ O
the -X- _ O
reference -X- _ O
set -X- _ O
of -X- _ O
standard -X- _ O
, -X- _ O
nonslang -X- _ O
, -X- _ O
words -X- _ O
we -X- _ O
sample -X- _ O
100 -X- _ O
words -X- _ O
uniformly -X- _ O
at -X- _ O
random -X- _ O
from -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
all -X- _ O
English -X- _ O
words -X- _ O
, -X- _ O
supplied -X- _ O
by -X- _ O
the -X- _ O
wordfreq -X- _ O
library -X- _ O
in -X- _ O
Python -X- _ O
( -X- _ O
Speer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
5 -X- _ O
Data -X- _ O
Collection -X- _ O
We -X- _ O
curate -X- _ O
a -X- _ O
Twitter -X- _ O
dataset -X- _ O
from -X- _ O
the -X- _ O
years -X- _ O
2010 -X- _ O
and -X- _ O
2020 -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
select -X- _ O
as -X- _ O
our -X- _ O
periods -X- _ O
of -X- _ O
reference -X- _ O
, -X- _ O
and -X- _ O
collect -X- _ O
the -X- _ O
following -X- _ O
variables -X- _ O
: -X- _ O
•Word -X- _ O
type -X- _ O
: -X- _ O
Whether -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
slang -X- _ O
or -X- _ O
not -X- _ O
•Word -X- _ O
frequency -X- _ O
: -X- _ O
The -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
tweets -X- _ O
containing -X- _ O
the -X- _ O
word -X- _ O
per -X- _ O
day -X- _ O
in -X- _ O
2010 -X- _ O
and -X- _ O
2020 -X- _ O
( -X- _ O
Section -X- _ O
5.2 -X- _ O
) -X- _ O
•Frequency -X- _ O
Shift -X- _ O
: -X- _ O
The -X- _ O
relative -X- _ O
difference -X- _ O
in -X- _ O
fre- -X- _ O
quency -X- _ O
the -X- _ O
word -X- _ O
has -X- _ O
undergone -X- _ O
between -X- _ O
2010 -X- _ O
and -X- _ O
2020 -X- _ O
( -X- _ O
Section -X- _ O
5.3 -X- _ O
) -X- _ O
•Polysemy -X- _ O
: -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
senses -X- _ O
a -X- _ O
word -X- _ O
has -X- _ O
( -X- _ O
Section -X- _ O
5.4 -X- _ O
) -X- _ O
•Part -X- _ O
of -X- _ O
speech -X- _ O
: -X- _ O
A -X- _ O
binary -X- _ O
variable -X- _ O
for -X- _ O
each -X- _ O
POS -X- _ O
tag -X- _ O
( -X- _ O
Section -X- _ O
5.5 -X- _ O
) -X- _ O
•Semantic -X- _ O
change -X- _ O
: -X- _ O
The -X- _ O
semantic -X- _ O
change -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
from -X- _ O
2010 -X- _ O
to -X- _ O
2020 -X- _ O
( -X- _ O
Section -X- _ O
5.6 -X- _ O
) -X- _ O
5.1 -X- _ O
Twitter -X- _ B-DatasetName
Dataset -X- _ I-DatasetName
As -X- _ O
a -X- _ O
social -X- _ O
media -X- _ O
platform -X- _ O
, -X- _ O
Twitter -X- _ O
data -X- _ O
is -X- _ O
rich -X- _ O
in -X- _ O
both -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
Twitter -X- _ B-DatasetName
dataset -X- _ I-DatasetName
we -X- _ O
curated -X- _ O
comprises -X- _ O
170,135 -X- _ O
tweets -X- _ O
from -X- _ O
2010 -X- _ O
and -X- _ O
2020 -X- _ O
that -X- _ O
contain -X- _ O
our -X- _ O
selected -X- _ O
words -X- _ O
. -X- _ O
Sampling -X- _ O
tweets -X- _ O
from -X- _ O
two -X- _ O
separate -X- _ O
time -X- _ O
periods -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
examine -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
over -X- _ O
a -X- _ O
10 -X- _ O
- -X- _ O
year -X- _ O
gap -X- _ O
. -X- _ O
For -X- _ O
every -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
word -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
time -X- _ O
periods -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
200- -X- _ O
500 -X- _ O
random -X- _ O
tweets -X- _ O
that -X- _ O
contain -X- _ O
the -X- _ O
word -X- _ O
and -X- _ O
were -X- _ O
posted -X- _ O
during -X- _ O
the -X- _ O
corresponding -X- _ O
year -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
each -X- _ O
tweet -X- _ O
’s -X- _ O
text -X- _ O
, -X- _ O
tweet -X- _ O
ID -X- _ O
, -X- _ O
and -X- _ O
date -X- _ O
it -X- _ O
was -X- _ O
posted -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
processing -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
all -X- _ O
URLs -X- _ O
and -X- _ O
hashtags -X- _ O
from -X- _ O
the -X- _ O
tweets -X- _ O
. -X- _ O
To -X- _ O
protect -X- _ O
user -X- _ O
privacy -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
replace -X- _ O
all -X- _ O
user -X- _ O
name -X- _ O
handles -X- _ O
with -X- _ O
the -X- _ O
word -X- _ O
“ -X- _ O
user -X- _ O
. -X- _ O
” -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
346 -X- _ O
tweets -X- _ O
per -X- _ O
slang -X- _ O
word -X- _ O
and -X- _ O
293 -X- _ O
tweets -X- _ O
per -X- _ O
nonslang -X- _ O
word -X- _ O
. -X- _ O
5.2 -X- _ O
Word -X- _ O
Frequency -X- _ O
We -X- _ O
approximate -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
frequency -X- _ O
by -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
times -X- _ O
it -X- _ O
is -X- _ O
tweeted -X- _ O
within -X- _ O
24 -X- _ O
hours -X- _ O
. -X- _ O
This -X- _ O
average -X- _ O
is -X- _ O
calculated -X- _ O
in -X- _ O
practice -X- _ O
over -X- _ O
40 -X- _ O
randomly -X- _ O
sampled -X- _ O
24 -X- _ O
hour -X- _ O
time -X- _ O
frames -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
year -X- _ O
, -X- _ O
in -X- _ O
each -X- _ O
of -X- _ O
which -X- _ O
we -X- _ O
retrieve -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tweets -X- _ O
con- -X- _ O
taining -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O
The -X- _ O
frequencies -X- _ O
are -X- _ O
calculated -X- _ O
separately -X- _ O
for -X- _ O
2010 -X- _ O
and -X- _ O
2020 -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
growing1425 -X- _ O
popularity -X- _ O
of -X- _ O
social -X- _ O
media -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tweets -X- _ O
has -X- _ O
signiﬁcantly -X- _ O
increased -X- _ O
over -X- _ O
the -X- _ O
decade -X- _ O
. -X- _ O
There- -X- _ O
fore -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
counts -X- _ O
from -X- _ O
2020 -X- _ O
by -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
6:4 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
ratio -X- _ O
between -X- _ O
the -X- _ O
average -X- _ O
word -X- _ O
counts -X- _ O
in -X- _ O
both -X- _ O
years -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
frequencies -X- _ O
from -X- _ O
both -X- _ O
years -X- _ O
are -X- _ O
then -X- _ O
averaged -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
frequency -X- _ O
variable -X- _ O
for -X- _ O
the -X- _ O
causal -X- _ O
analysis -X- _ O
. -X- _ O
5.3 -X- _ O
Frequency -X- _ O
Shift -X- _ O
We -X- _ O
are -X- _ O
now -X- _ O
interested -X- _ O
in -X- _ O
analyzing -X- _ O
the -X- _ O
dynamics -X- _ O
of -X- _ O
frequency -X- _ O
shifts -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
relative -X- _ O
change -X- _ O
in -X- _ O
frequency -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
word -X- _ O
wwe -X- _ O
take -X- _ O
FreqShift -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
= -X- _ O
logx -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
x -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
, -X- _ O
x -X- _ O
( -X- _ O
w -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
frequency -X- _ O
of -X- _ O
word -X- _ O
win -X- _ O
yeark -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
only -X- _ O
metric -X- _ O
for -X- _ O
rela- -X- _ O
tive -X- _ O
change -X- _ O
that -X- _ O
is -X- _ O
symmetric -X- _ O
, -X- _ O
additive -X- _ O
, -X- _ O
and -X- _ O
normed -X- _ O
( -X- _ O
Tornqvist -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1985 -X- _ O
) -X- _ O
. -X- _ O
Importantly -X- _ O
, -X- _ O
this -X- _ O
measure -X- _ O
symmetrically -X- _ O
reﬂects -X- _ O
both -X- _ O
increases -X- _ O
and -X- _ O
decreases -X- _ O
in -X- _ O
relative -X- _ O
frequency -X- _ O
. -X- _ O
The -X- _ O
mean -X- _ O
relative -X- _ O
changes -X- _ O
in -X- _ O
frequency -X- _ O
were0:486 -X- _ O
( -X- _ O
1:644 -X- _ O
) -X- _ O
for -X- _ O
slang -X- _ O
words -X- _ O
and0:533 -X- _ O
( -X- _ O
1:070 -X- _ O
) -X- _ O
for -X- _ O
nonslang -X- _ O
words -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
positive -X- _ O
score -X- _ O
corresponds -X- _ O
to -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
fre- -X- _ O
quency -X- _ O
. -X- _ O
As -X- _ O
evident -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
not -X- _ O
only -X- _ O
did -X- _ O
more -X- _ O
slang -X- _ O
words -X- _ O
exhibit -X- _ O
a -X- _ O
decrease -X- _ O
in -X- _ O
frequency -X- _ O
than -X- _ O
nonslang -X- _ O
ones -X- _ O
, -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
showed -X- _ O
the -X- _ O
highest -X- _ O
frequency -X- _ O
increase -X- _ O
are -X- _ O
also -X- _ O
slang -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
examine -X- _ O
the -X- _ O
absolute -X- _ O
value -X- _ O
of -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
change -X- _ O
, -X- _ O
may -X- _ O
it -X- _ O
be -X- _ O
a -X- _ O
de- -X- _ O
crease -X- _ O
or -X- _ O
an -X- _ O
increase -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
, -X- _ O
as -X- _ O
expected -X- _ O
, -X- _ O
slang -X- _ O
words -X- _ O
have -X- _ O
signiﬁcantly -X- _ O
higher -X- _ O
changes -X- _ O
in -X- _ O
frequency -X- _ O
than -X- _ O
nonslang -X- _ O
words -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:05 -X- _ O
) -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O
5.4 -X- _ O
Polysemy -X- _ O
We -X- _ O
deﬁne -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
polysemy -X- _ O
score -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
distinct -X- _ O
senses -X- _ O
it -X- _ O
has -X- _ O
. -X- _ O
For -X- _ O
nonslang -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
senses -X- _ O
the -X- _ O
word -X- _ O
has -X- _ O
in -X- _ O
Merriam -X- _ O
Webster -X- _ O
and -X- _ O
for -X- _ O
slang -X- _ O
words -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
deﬁnitions -X- _ O
on -X- _ O
the -X- _ O
Online -X- _ O
Slang -X- _ O
Dictionary -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
separate -X- _ O
resources -X- _ O
as -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
no -X- _ O
dictio- -X- _ O
nary -X- _ O
encapsulates -X- _ O
both -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
mean -X- _ O
polysemy -X- _ O
scores -X- _ O
are -X- _ O
( -X- _ O
2:0742:595 -X- _ O
) -X- _ O
for -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
( -X- _ O
3:0792:780 -X- _ O
) -X- _ O
for -X- _ O
nonslang -X- _ O
words -X- _ O
with -X- _ O
a -X- _ O
signiﬁcant -X- _ O
difference -X- _ O
in -X- _ O
distribution -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:05 -X- _ O
) -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
permutation -X- _ O
test -X- _ O
, -X- _ O
im- -X- _ O
plying -X- _ O
that -X- _ O
the -X- _ O
latter -X- _ O
are -X- _ O
used -X- _ O
with -X- _ O
a -X- _ O
larger -X- _ O
variety -X- _ O
of -X- _ O
meanings -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
slang -X- _ O
senses -X- _ O
of -X- _ O
the -X- _ O
hybrid -X- _ O
words -X- _ O
exhibit -X- _ O
a -X- _ O
distribution -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
slang -X- _ O
words -X- _ O
( -X- _ O
Appendix -X- _ O
C -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
polyse- -X- _ O
mous -X- _ O
words -X- _ O
tend -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
word -X- _ O
frequency -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
– -X- _ O
the -X- _ O
log -X- _ O
transform -X- _ O
of -X- _ O
frequency -X- _ O
and -X- _ O
polysemy -X- _ O
display -X- _ O
a -X- _ O
highly -X- _ O
signiﬁcant -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001 -X- _ O
) -X- _ O
linear -X- _ O
correlation -X- _ O
coefﬁcient -X- _ O
of -X- _ O
0:350 -X- _ O
. -X- _ O
5.5 -X- _ O
Part -X- _ O
of -X- _ O
Speech -X- _ O
For -X- _ O
each -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
retrieve -X- _ O
four -X- _ O
binary -X- _ O
variables -X- _ O
, -X- _ O
in- -X- _ O
dicating -X- _ O
whether -X- _ O
a -X- _ O
word -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
noun -X- _ O
, -X- _ O
verb -X- _ O
, -X- _ O
adverb -X- _ O
or -X- _ O
adjective -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
the -X- _ O
four -X- _ O
major -X- _ O
POS -X- _ O
tags -X- _ O
observed -X- _ O
in -X- _ O
our -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
calculate -X- _ O
these -X- _ O
variables -X- _ O
we -X- _ O
run -X- _ O
the -X- _ O
NLTK -X- _ B-MethodName
POS -X- _ I-MethodName
tagger -X- _ I-MethodName
( -X- _ O
Loper -X- _ O
and -X- _ O
Bird -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
tweets -X- _ O
, -X- _ O
and -X- _ O
collect -X- _ O
the -X- _ O
distribu- -X- _ O
tion -X- _ O
of -X- _ O
POS -X- _ O
tags -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
may -X- _ O
have -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
POS -X- _ O
tag -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
in -X- _ O
which -X- _ O
it -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
the -X- _ O
binary -X- _ O
variables -X- _ O
is -X- _ O
then -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
1 -X- _ O
if -X- _ O
the -X- _ O
word -X- _ O
had -X- _ O
the -X- _ O
corresponding -X- _ O
POS -X- _ O
tag -X- _ O
in -X- _ O
at -X- _ O
least -X- _ O
5 -X- _ O
% -X- _ O
of -X- _ O
its -X- _ O
tweets -X- _ O
and -X- _ O
0 -X- _ O
otherwise -X- _ O
. -X- _ O
5.6 -X- _ O
Semantic -X- _ O
Change -X- _ O
Score -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
explain -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
how -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
start -X- _ O
by -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
a -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
slang -X- _ O
- -X- _ O
dense -X- _ O
corpus -X- _ O
( -X- _ O
Section -X- _ O
5.6.1 -X- _ O
) -X- _ O
, -X- _ O
after -X- _ O
which -X- _ O
we -X- _ O
survey -X- _ O
the -X- _ O
literature -X- _ O
and -X- _ O
propose -X- _ O
metrics -X- _ O
( -X- _ O
Sec- -X- _ O
tion -X- _ O
5.6.2 -X- _ O
) -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
to -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
experimentation -X- _ O
study -X- _ O
to -X- _ O
ﬁnd -X- _ O
the -X- _ O
most -X- _ O
suitable -X- _ O
one -X- _ O
( -X- _ O
Section -X- _ O
5.6.3 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
this -X- _ O
metric -X- _ O
to -X- _ O
our1426sets -X- _ O
of -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
on -X- _ O
the -X- _ O
Twitter -X- _ O
data -X- _ O
( -X- _ O
Section -X- _ O
5.6.4 -X- _ O
) -X- _ O
. -X- _ O
5.6.1 -X- _ O
Obtaining -X- _ O
Contextualized -X- _ O
Representations -X- _ O
We -X- _ O
familiarize -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
contexts -X- _ O
in -X- _ O
which -X- _ O
they -X- _ O
are -X- _ O
used -X- _ O
by -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
mod- -X- _ O
eling -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
purpose -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
web -X- _ O
- -X- _ O
scraped -X- _ O
dataset -X- _ O
from -X- _ O
the -X- _ O
Urban -X- _ O
Dictionary -X- _ O
, -X- _ O
previously -X- _ O
col- -X- _ O
lected -X- _ O
by -X- _ O
Wilson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
After -X- _ O
preprocessing -X- _ O
and -X- _ O
subsampling -X- _ O
, -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.1 -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
left -X- _ O
with -X- _ O
a -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
200 -X- _ O
; -X- _ O
000slang -X- _ O
- -X- _ O
dense -X- _ O
text -X- _ O
sequences -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
language -X- _ O
model -X- _ O
we -X- _ O
select -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Beyond -X- _ O
performance -X- _ O
gains -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
this -X- _ O
model -X- _ O
since -X- _ O
it -X- _ O
allows -X- _ O
for -X- _ O
more -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O
We -X- _ O
reason -X- _ O
, -X- _ O
that -X- _ O
this -X- _ O
could -X- _ O
be -X- _ O
use- -X- _ O
ful -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
since -X- _ O
potentially -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
units -X- _ O
used -X- _ O
in -X- _ O
these -X- _ O
words -X- _ O
would -X- _ O
not -X- _ O
have -X- _ O
been -X- _ O
recognized -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
We -X- _ O
choose -X- _ O
the -X- _ O
smaller -X- _ O
125 -X- _ O
M -X- _ O
parameter -X- _ O
base -X- _ O
version -X- _ O
for -X- _ O
computa- -X- _ O
tional -X- _ O
reasons -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
different -X- _ O
learning -X- _ O
rates -X- _ O
. -X- _ O
The -X- _ O
lowest -X- _ O
loss -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
was -X- _ O
found -X- _ O
with -X- _ O
= -X- _ O
10 -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
proceed -X- _ O
with -X- _ O
for -X- _ O
scoring -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
on -X- _ O
training -X- _ O
conﬁgurations -X- _ O
, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.2 -X- _ O
. -X- _ O
5.6.2 -X- _ O
Quantifying -X- _ O
Semantic -X- _ O
Change -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
select -X- _ O
a -X- _ O
change -X- _ O
detection -X- _ O
metric -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
SemEval-2020 -X- _ O
Task -X- _ O
1 -X- _ O
on -X- _ O
Unsupervised -X- _ O
Lexical -X- _ O
Semantic -X- _ B-TaskName
Change -X- _ I-TaskName
Detec- -X- _ I-TaskName
tion -X- _ I-TaskName
( -X- _ O
Schlechtweg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
task -X- _ O
provides -X- _ O
the -X- _ O
ﬁrst -X- _ O
standard -X- _ O
evaluation -X- _ O
framework -X- _ O
for -X- _ O
seman- -X- _ O
tic -X- _ O
change -X- _ O
detection -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
labeled -X- _ O
dataset -X- _ O
for -X- _ O
four -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
restrict -X- _ O
ourselves -X- _ O
to -X- _ O
English -X- _ O
and -X- _ O
focus -X- _ O
on -X- _ O
subtask -X- _ O
2 -X- _ O
, -X- _ O
which -X- _ O
concerns -X- _ O
ranking -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
37target -X- _ O
words -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
semantic -X- _ O
change -X- _ O
between -X- _ O
two -X- _ O
time -X- _ O
peri- -X- _ O
ods -X- _ O
. -X- _ O
The -X- _ O
ranking -X- _ O
is -X- _ O
evaluated -X- _ O
using -X- _ O
Spearman -X- _ O
’s -X- _ O
rank -X- _ O
- -X- _ O
order -X- _ O
correlation -X- _ O
coefﬁcient -X- _ O
.Our -X- _ O
space -X- _ O
of -X- _ O
conﬁgurations -X- _ O
includes -X- _ O
layer -X- _ O
representations -X- _ O
, -X- _ O
di- -X- _ O
mensionality -X- _ O
reduction -X- _ O
techniques -X- _ O
and -X- _ O
semantic -X- _ O
change -X- _ O
metrics -X- _ O
. -X- _ O
Layer -X- _ O
Representations -X- _ O
: -X- _ O
Previous -X- _ O
work -X- _ O
( -X- _ O
Etha- -X- _ O
yarajh -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
embeddings -X- _ O
re- -X- _ O
trieved -X- _ O
from -X- _ O
bi -X- _ O
- -X- _ O
directional -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
notisotropic -X- _ O
, -X- _ O
but -X- _ O
are -X- _ O
rather -X- _ O
concentrated -X- _ O
around -X- _ O
a -X- _ O
high- -X- _ O
dimensional -X- _ O
cone -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
isotropy -X- _ O
may -X- _ O
vary -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
layer -X- _ O
from -X- _ O
which -X- _ O
the -X- _ O
rep- -X- _ O
resentations -X- _ O
are -X- _ O
retrieved -X- _ O
( -X- _ O
Ethayarajh -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
us -X- _ O
to -X- _ O
experiment -X- _ O
with -X- _ O
representations -X- _ O
from -X- _ O
different -X- _ O
layers -X- _ O
in -X- _ O
our -X- _ O
ﬁne- -X- _ O
tuned -X- _ O
RoBERTa -X- _ O
model -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
taking -X- _ O
only -X- _ O
the -X- _ O
ﬁrst -X- _ O
layer -X- _ O
, -X- _ O
only -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
or -X- _ O
summing -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
Dimensionality -X- _ O
Reduction -X- _ O
: -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
only -X- _ O
one -X- _ O
previous -X- _ O
semantic -X- _ O
change -X- _ O
detection -X- _ O
approach -X- _ O
( -X- _ O
Rother -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
incor- -X- _ O
porated -X- _ O
dimensionality -X- _ O
reduction -X- _ O
, -X- _ O
more -X- _ O
speciﬁcally -X- _ O
UMAP -X- _ B-MethodName
( -X- _ O
McInnes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
Euclidean -X- _ O
distances -X- _ O
in -X- _ O
the -X- _ O
UMAP -X- _ B-MethodName
- -X- _ O
reduced -X- _ O
space -X- _ O
are -X- _ O
very -X- _ O
sen- -X- _ O
sitive -X- _ O
to -X- _ O
hyperparameters -X- _ O
and -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
retain -X- _ O
an -X- _ O
interpretable -X- _ O
notion -X- _ O
of -X- _ O
absolute -X- _ O
distances -X- _ O
, -X- _ O
it -X- _ O
might -X- _ O
be -X- _ O
unsuitable -X- _ O
for -X- _ O
pure -X- _ O
distance -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
like -X- _ O
APD -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
therefore -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
PCA -X- _ B-MethodName
. -X- _ O
Metrics -X- _ O
for -X- _ O
Semantic -X- _ O
Change -X- _ O
: -X- _ O
Given -X- _ O
represen- -X- _ O
tationsX -X- _ O
= -X- _ O
fx -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
xgfor -X- _ O
a -X- _ O
particular -X- _ O
word -X- _ O
in -X- _ O
time -X- _ O
period -X- _ O
t -X- _ O
, -X- _ O
we -X- _ O
deﬁne -X- _ O
the -X- _ O
average -X- _ B-MetricName
pairwise -X- _ I-MetricName
distance -X- _ I-MetricName
( -X- _ O
APD -X- _ B-MetricName
) -X- _ O
between -X- _ O
two -X- _ O
periods -X- _ O
as -X- _ O
APD -X- _ O
( -X- _ O
X -X- _ O
; -X- _ O
X -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
nnXd -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
for -X- _ O
some -X- _ O
distance -X- _ O
metric -X- _ O
d -X- _ O
( -X- _ O
; -X- _ O
) -X- _ O
, -X- _ O
wheren -X- _ O
; -X- _ O
nare -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
in -X- _ O
each -X- _ O
time -X- _ O
period -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
Euclidean -X- _ B-MetricName
distance -X- _ I-MetricName
d -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
cosine -X- _ B-MetricName
distance -X- _ I-MetricName
d -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
and -X- _ O
Manhattan -X- _ B-MetricName
dis- -X- _ I-MetricName
tanced -X- _ I-MetricName
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
combined -X- _ O
metric -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
d -X- _ O
( -X- _ O
; -X- _ O
) -X- _ O
2 -X- _ O
[ -X- _ O
0 -X- _ O
; -X- _ O
1 -X- _ O
] -X- _ O
and -X- _ O
d -X- _ O
( -X- _ O
; -X- _ O
) -X- _ O
2 -X- _ O
[ -X- _ O
0 -X- _ O
; -X- _ O
2 -X- _ O
] -X- _ O
. -X- _ O
Further -X- _ O
note -X- _ O
that -X- _ O
jjxxjjjjxjj+jjxjj -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Normalizing -X- _ O
both -X- _ O
metrics -X- _ O
for -X- _ O
a -X- _ O
support -X- _ O
in -X- _ O
[ -X- _ O
0 -X- _ O
; -X- _ O
1 -X- _ O
] -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
a -X- _ O
combined -X- _ O
metric -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
unit -X- _ O
support -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
following -X- _ O
average -X- _ O
: -X- _ O
d -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
0:5d -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
p -X- _ O
jjxjj+jjxjj -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
+ -X- _ O
d -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
4 -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
this -X- _ O
provides -X- _ O
a -X- _ O
more -X- _ O
complete -X- _ O
met- -X- _ O
ric -X- _ O
, -X- _ O
capturing -X- _ O
both -X- _ O
absolute -X- _ O
distance -X- _ O
and -X- _ O
the -X- _ O
angle -X- _ O
between -X- _ O
vectors -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
APD -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
distribution -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
B.1 -X- _ O
) -X- _ O
.1427Reduction -X- _ O
h -X- _ O
APD -X- _ B-MetricName
Score -X- _ I-MetricName
PCA -X- _ B-MethodName
100dandd0:489 -X- _ O
PCA -X- _ B-MethodName
100d -X- _ O
0:464 -X- _ O
PCA -X- _ B-MethodName
100d -X- _ O
0:298 -X- _ O
None -X- _ O
768dandd -X- _ O
0:345 -X- _ O
5.6.3 -X- _ O
Evaluating -X- _ O
the -X- _ O
Semantic -X- _ O
Change -X- _ O
Scores -X- _ O
We -X- _ O
ﬁrst -X- _ O
compare -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
layer -X- _ O
representations -X- _ O
for -X- _ O
different -X- _ O
APD -X- _ B-MetricName
metrics -X- _ O
, -X- _ O
and -X- _ O
note -X- _ O
that -X- _ O
summing -X- _ O
all -X- _ O
layer -X- _ O
representations -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
. -X- _ O
Consequentially -X- _ O
, -X- _ O
we -X- _ O
pro- -X- _ O
ceed -X- _ O
with -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
experiments -X- _ O
using -X- _ O
only -X- _ O
these -X- _ O
representations -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
PCA -X- _ B-MethodName
and -X- _ O
UMAP -X- _ B-MethodName
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
projecting -X- _ O
the -X- _ O
representations -X- _ O
down -X- _ O
toh2 -X- _ O
f2 -X- _ B-HyperparameterValue
; -X- _ O
5 -X- _ B-HyperparameterValue
; -X- _ O
10 -X- _ B-HyperparameterValue
; -X- _ O
20 -X- _ B-HyperparameterValue
; -X- _ O
50 -X- _ B-HyperparameterValue
; -X- _ O
100gdimensions -X- _ B-HyperparameterValue
. -X- _ O
These -X- _ O
combinations -X- _ O
are -X- _ O
tested -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
APD -X- _ B-MetricName
metrics -X- _ O
as -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
5.6.2 -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
distribution -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
described -X- _ O
in -X- _ O
Ap- -X- _ O
pendix -X- _ O
B. -X- _ O
The -X- _ O
latter -X- _ O
do -X- _ O
not -X- _ O
however -X- _ O
in -X- _ O
general -X- _ O
display -X- _ O
signiﬁcant -X- _ O
correlations -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
scores -X- _ O
result- -X- _ O
ing -X- _ O
from -X- _ O
the -X- _ O
APD -X- _ B-MetricName
conﬁgurations -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
high- -X- _ O
lighting -X- _ O
our -X- _ O
ﬁnding -X- _ O
that -X- _ O
both -X- _ O
PCA -X- _ B-MethodName
dimensionality -X- _ O
reduction -X- _ O
and -X- _ O
using -X- _ O
a -X- _ O
combined -X- _ O
metric -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
More -X- _ O
results -X- _ O
and -X- _ O
comparisons -X- _ O
to -X- _ O
baselines -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
B.3 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
combined -X- _ O
metric -X- _ O
consis- -X- _ O
tently -X- _ O
outperforms -X- _ O
both -X- _ O
danddacross -X- _ O
values -X- _ O
ofhfor -X- _ O
PCA -X- _ B-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
UMAP -X- _ B-MethodName
projec- -X- _ O
tions -X- _ O
perform -X- _ O
poorly -X- _ O
with -X- _ O
the -X- _ O
APD -X- _ B-MetricName
metrics -X- _ O
and -X- _ O
that -X- _ O
projecting -X- _ O
down -X- _ O
to -X- _ O
50 -X- _ O
- -X- _ O
100 -X- _ O
dimensions -X- _ O
seems -X- _ O
to -X- _ O
be -X- _ O
optimal -X- _ O
, -X- _ O
which -X- _ O
maintains -X- _ O
70 -X- _ O
- -X- _ O
85 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
vari- -X- _ O
ance -X- _ O
as -X- _ O
we -X- _ O
illustrate -X- _ O
in -X- _ O
Appendix -X- _ O
B.2 -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
both -X- _ O
norm -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
danddperform -X- _ O
worse -X- _ O
with -X- _ O
dimensionality -X- _ O
reduction -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
ﬁnal -X- _ O
metric -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
conﬁguration -X- _ O
on -X- _ O
SemEval -X- _ B-DatasetName
, -X- _ O
with -X- _ O
PCA -X- _ O
h= -X- _ B-HyperparameterName
100 -X- _ B-MetricName
and -X- _ O
the -X- _ O
combined -X- _ O
metric -X- _ O
, -X- _ O
as -X- _ O
seen -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
5.6.4 -X- _ O
Semantic -X- _ O
Change -X- _ O
Scores -X- _ O
for -X- _ O
Slang -X- _ O
and -X- _ O
Nonslang -X- _ O
Words -X- _ O
on -X- _ O
the -X- _ O
Twitter -X- _ B-DatasetName
Dataset -X- _ I-DatasetName
We -X- _ O
obtain -X- _ O
semantic -X- _ O
change -X- _ O
scores -X- _ O
using -X- _ O
the -X- _ O
Twitter -X- _ O
dataset -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
seman- -X- _ O
tic -X- _ O
change -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
exclude -X- _ O
words -X- _ O
that -X- _ O
have -X- _ O
less -X- _ O
than -X- _ O
150 -X- _ O
tweets -X- _ O
in -X- _ O
each -X- _ O
time -X- _ O
period -X- _ O
within -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
leaves -X- _ O
us -X- _ O
with -X- _ O
80 -X- _ O
slang -X- _ O
and -X- _ O
81 -X- _ O
non- -X- _ O
slang -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
normalize -X- _ O
the -X- _ O
scores -X- _ O
accord- -X- _ O
ing -X- _ O
to -X- _ O
the -X- _ O
sample -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
semantic -X- _ O
change -X- _ O
scores -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
mean -X- _ O
semantic -X- _ B-MetricName
change -X- _ I-MetricName
scores -X- _ I-MetricName
are -X- _ O
0:564 -X- _ B-MetricValue
( -X- _ O
0:114 -X- _ O
) -X- _ O
for -X- _ O
slang -X- _ O
words -X- _ O
and0:648 -X- _ B-MetricValue
( -X- _ O
0:084 -X- _ O
) -X- _ O
for -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
dif- -X- _ O
ference -X- _ O
in -X- _ O
semantic -X- _ O
change -X- _ O
score -X- _ O
distributions -X- _ O
is -X- _ O
signiﬁcant -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001 -X- _ O
) -X- _ O
via -X- _ O
a -X- _ O
permutation -X- _ O
test -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
semantic -X- _ O
change -X- _ O
score -X- _ O
of -X- _ O
1 -X- _ O
is -X- _ O
“ -X- _ O
anticlockwise -X- _ O
, -X- _ O
” -X- _ O
and -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
score -X- _ O
of -X- _ O
0is -X- _ O
“ -X- _ O
whadja -X- _ O
. -X- _ O
” -X- _ O
6 -X- _ O
Causal -X- _ O
Analysis -X- _ O
6.1 -X- _ O
Preparation -X- _ O
for -X- _ O
Causal -X- _ O
Discovery -X- _ O
PC -X- _ O
- -X- _ O
stable -X- _ O
is -X- _ O
constraint -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
thus -X- _ O
makes -X- _ O
use -X- _ O
of -X- _ O
conditional -X- _ O
independence -X- _ O
tests -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
continuous -X- _ O
Gaussian -X- _ O
variables -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
perform -X- _ O
partial -X- _ O
correlation -X- _ O
tests -X- _ O
to -X- _ O
assess -X- _ O
conditional -X- _ O
inde- -X- _ O
pendence -X- _ O
, -X- _ O
since -X- _ O
zero -X- _ O
partial -X- _ O
correlation -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
conditional -X- _ O
independence -X- _ O
( -X- _ O
Baba -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
word -X- _ O
frequency -X- _ O
has -X- _ O
been -X- _ O
sug- -X- _ O
gested -X- _ O
to -X- _ O
follow -X- _ O
a -X- _ O
lognormal -X- _ O
distribution -X- _ O
( -X- _ O
Baayen -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
log -X- _ O
transform -X- _ O
of -X- _ O
it -X- _ O
. -X- _ O
The -X- _ O
continu- -X- _ O
ous -X- _ O
variables -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
frequency -X- _ O
change -X- _ O
andlog -X- _ O
- -X- _ O
frequency -X- _ O
are -X- _ O
then -X- _ O
all -X- _ O
assumed -X- _ O
to -X- _ O
be -X- _ O
ap- -X- _ O
proximated -X- _ O
well -X- _ O
by -X- _ O
a -X- _ O
Gaussian -X- _ O
distribution -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
conﬁrmed -X- _ O
by -X- _ O
diagnostic -X- _ O
density -X- _ O
and -X- _ O
Q -X- _ O
- -X- _ O
Q -X- _ O
plots -X- _ O
( -X- _ O
displayed -X- _ O
in -X- _ O
Appendix -X- _ O
D.2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
categorize -X- _ O
the -X- _ O
discrete -X- _ O
polysemy -X- _ O
variable -X- _ O
, -X- _ O
experimenting -X- _ O
with -X- _ O
nine -X- _ O
different -X- _ O
plausible -X- _ O
cate- -X- _ O
gorizations -X- _ O
for -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
robustness -X- _ O
of -X- _ O
the -X- _ O
re- -X- _ O
sults -X- _ O
. -X- _ O
Word -X- _ O
type -X- _ O
and -X- _ O
POS -X- _ O
are -X- _ O
categorical -X- _ O
in -X- _ O
na- -X- _ O
ture -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
categorical -X- _ O
variables -X- _ O
and -X- _ O
for -X- _ O
mixes -X- _ O
of -X- _ O
categorical -X- _ O
and -X- _ O
continuous -X- _ O
variables -X- _ O
, -X- _ O
we -X- _ O
per- -X- _ O
form -X- _ O
chi -X- _ O
- -X- _ O
squared -X- _ O
mutual -X- _ O
information -X- _ O
based -X- _ O
tests1428 -X- _ O
( -X- _ O
Edwards -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
approximate -X- _ O
null -X- _ O
distri- -X- _ O
bution -X- _ O
of -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
is -X- _ O
chi -X- _ O
- -X- _ O
squared -X- _ O
( -X- _ O
Brillinger -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
conditional -X- _ O
indepen- -X- _ O
dence -X- _ O
tests -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
signiﬁcance -X- _ O
levels -X- _ O
2f0:01 -X- _ O
; -X- _ O
0:03 -X- _ O
; -X- _ O
0:05 -X- _ O
g. -X- _ O
6.2 -X- _ O
Resulting -X- _ O
Causal -X- _ O
Structure -X- _ O
In -X- _ O
Figure -X- _ O
4 -X- _ O
we -X- _ O
see -X- _ O
the -X- _ O
result -X- _ O
from -X- _ O
the -X- _ O
above -X- _ O
ap- -X- _ O
proach -X- _ O
, -X- _ O
with -X- _ O
dashed -X- _ O
lines -X- _ O
representing -X- _ O
edges -X- _ O
that -X- _ O
were -X- _ O
apparent -X- _ O
in -X- _ O
most -X- _ O
but -X- _ O
not -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
conﬁgura- -X- _ O
tions -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
D.3 -X- _ O
for -X- _ O
a -X- _ O
sensitivity -X- _ O
analysis -X- _ O
. -X- _ O
We -X- _ O
ﬁrst -X- _ O
observe -X- _ O
that -X- _ O
word -X- _ O
type -X- _ O
has -X- _ O
a -X- _ O
direct -X- _ O
causal -X- _ O
effect -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
score -X- _ O
and -X- _ O
the -X- _ O
frequency -X- _ O
shift -X- _ O
, -X- _ O
without -X- _ O
any -X- _ O
confounding -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
variables -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
a -X- _ O
direct -X- _ O
in- -X- _ O
ﬂuence -X- _ O
of -X- _ O
word -X- _ O
polysemy -X- _ O
on -X- _ O
frequency -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
POS -X- _ O
categories -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
all -X- _ O
gathered -X- _ O
in -X- _ O
one -X- _ O
node -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
have -X- _ O
a -X- _ O
causal -X- _ O
link -X- _ O
to -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
variables -X- _ O
. -X- _ O
We -X- _ O
additionally -X- _ O
observe -X- _ O
a -X- _ O
dependency -X- _ O
between -X- _ O
word -X- _ O
type -X- _ O
and -X- _ O
polysemy -X- _ O
. -X- _ O
This -X- _ O
edge -X- _ O
could -X- _ O
not -X- _ O
be -X- _ O
oriented -X- _ O
by -X- _ O
the -X- _ O
PC -X- _ O
- -X- _ O
stable -X- _ O
algorithm -X- _ O
, -X- _ O
however -X- _ O
we -X- _ O
manually -X- _ O
orient -X- _ O
it -X- _ O
as -X- _ O
outgoing -X- _ O
from -X- _ O
type -X- _ O
and -X- _ O
ingoing -X- _ O
to -X- _ O
pol- -X- _ O
ysemy -X- _ O
, -X- _ O
since -X- _ O
an -X- _ O
intervention -X- _ O
on -X- _ O
type -X- _ O
should -X- _ O
have -X- _ O
a -X- _ O
causal -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
word -X- _ O
senses -X- _ O
and -X- _ O
not -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
interesting -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
polysemy -X- _ O
does -X- _ O
not -X- _ O
seem -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
causal -X- _ O
effect -X- _ O
on -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
Its -X- _ O
association -X- _ O
with -X- _ O
semantic -X- _ O
change -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:05 -X- _ O
, -X- _ O
rejecting -X- _ O
the -X- _ O
null -X- _ O
hypothesis -X- _ O
of -X- _ O
independence -X- _ O
between -X- _ O
polysemy -X- _ O
and -X- _ O
semantic -X- _ O
change -X- _ O
) -X- _ O
is -X- _ O
instead -X- _ O
confounded -X- _ O
by -X- _ O
word -X- _ O
type -X- _ O
. -X- _ O
6.3 -X- _ O
Causal -X- _ O
Effects -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
of -X- _ O
no -X- _ O
confounders -X- _ O
, -X- _ O
evaluating -X- _ O
the -X- _ O
ACE -X- _ O
of -X- _ O
word -X- _ O
type -X- _ O
on -X- _ O
semantic -X- _ O
change -X- _ O
is -X- _ O
straight- -X- _ O
forward -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
reduces -X- _ O
to -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
theconditional -X- _ O
expectations -X- _ O
: -X- _ O
E -X- _ O
[ -X- _ O
Sjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
nonslang -X- _ O
) -X- _ O
] -X- _ O
E -X- _ O
[ -X- _ O
Sjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
slang -X- _ O
) -X- _ O
] -X- _ O
= -X- _ O
= -X- _ O
E -X- _ O
[ -X- _ O
SjT -X- _ O
= -X- _ O
nonslang -X- _ O
] -X- _ O
E -X- _ O
[ -X- _ O
SjT -X- _ O
= -X- _ O
slang -X- _ O
] -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
See -X- _ O
Appendix -X- _ O
D.4 -X- _ O
for -X- _ O
a -X- _ O
derivation -X- _ O
. -X- _ O
The -X- _ O
case -X- _ O
of -X- _ O
frequency -X- _ O
shift -X- _ O
is -X- _ O
analogous -X- _ O
. -X- _ O
We -X- _ O
estimate -X- _ O
the -X- _ O
expectations -X- _ O
by -X- _ O
the -X- _ O
sample -X- _ O
means -X- _ O
on -X- _ O
the -X- _ O
normalized -X- _ O
values -X- _ O
and -X- _ O
get -X- _ O
an -X- _ O
average -X- _ B-MetricName
causal -X- _ I-MetricName
effect -X- _ I-MetricName
of -X- _ O
0:084 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
highly -X- _ O
signiﬁ- -X- _ O
ca -X- _ O
nt -X- _ O
value -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
observed -X- _ O
changes -X- _ O
in -X- _ O
relative -X- _ O
frequency -X- _ O
, -X- _ O
calculated -X- _ O
according -X- _ O
to -X- _ O
Eq -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
an -X- _ O
average -X- _ O
causal -X- _ O
ef- -X- _ O
fect -X- _ O
of -X- _ O
1:017 -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001via -X- _ O
a -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
) -X- _ O
. -X- _ O
7 -X- _ O
Discussion -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
dynamics -X- _ O
of -X- _ O
frequency -X- _ O
shift -X- _ O
and -X- _ O
se- -X- _ O
mantic -X- _ O
change -X- _ O
in -X- _ O
slang -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
them -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
shows -X- _ O
that -X- _ O
slang -X- _ O
words -X- _ O
change -X- _ O
slower -X- _ O
in -X- _ O
semantic -X- _ O
mean- -X- _ O
ing -X- _ O
, -X- _ O
but -X- _ O
adhere -X- _ O
to -X- _ O
more -X- _ O
rapid -X- _ O
frequency -X- _ O
ﬂuctu- -X- _ O
ations -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
greatly -X- _ O
decrease -X- _ O
in -X- _ O
frequency -X- _ O
. -X- _ O
Our -X- _ O
study -X- _ O
is -X- _ O
the -X- _ O
ﬁrst -X- _ O
computational -X- _ O
approach -X- _ O
to -X- _ O
conﬁrm -X- _ O
this -X- _ O
property -X- _ O
in -X- _ O
slang -X- _ O
words -X- _ O
( -X- _ O
González -X- _ O
, -X- _ O
1998 -X- _ O
; -X- _ O
Carter -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
a -X- _ O
causal -X- _ O
ef- -X- _ O
fect -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
mediated -X- _ O
through -X- _ O
another -X- _ O
variable -X- _ O
or -X- _ O
subject -X- _ O
to -X- _ O
confounders -X- _ O
, -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
data -X- _ O
with -X- _ O
a -X- _ O
causal -X- _ O
DAG -X- _ O
, -X- _ O
by -X- _ O
also -X- _ O
considering -X- _ O
the -X- _ O
potential -X- _ O
inter- -X- _ O
acting -X- _ O
variables -X- _ O
polysemy -X- _ O
, -X- _ O
frequency -X- _ O
and -X- _ O
POS -X- _ O
. -X- _ O
We -X- _ O
discover -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
inﬂuence -X- _ O
of -X- _ O
confounders -X- _ O
, -X- _ O
nor -X- _ O
are -X- _ O
there -X- _ O
mediators -X- _ O
between -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
type -X- _ O
and -X- _ O
its -X- _ O
semantic -X- _ O
change -X- _ O
or -X- _ O
its -X- _ O
frequency -X- _ O
shift -X- _ O
, -X- _ O
which -X- _ O
conﬁrms -X- _ O
a -X- _ O
direct -X- _ O
causal -X- _ O
effect -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
if -X- _ O
we -X- _ O
could -X- _ O
intervene -X- _ O
on -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
type -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
by -X- _ O
setting -X- _ O
it -X- _ O
to -X- _ O
be -X- _ O
slang -X- _ O
instead -X- _ O
of -X- _ O
nonslang -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
its -X- _ O
change -X- _ O
dynamics -X- _ O
to -X- _ O
differ -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
those -X- _ O
of -X- _ O
Du- -X- _ O
bossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
found -X- _ O
that -X- _ O
neither1429the -X- _ O
law -X- _ O
relating -X- _ O
semantic -X- _ O
change -X- _ O
to -X- _ O
frequency -X- _ O
, -X- _ O
pol- -X- _ O
ysemy -X- _ O
( -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
nor -X- _ O
prototypicality -X- _ O
( -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
were -X- _ O
found -X- _ O
to -X- _ O
be -X- _ O
as -X- _ O
strong -X- _ O
as -X- _ O
previously -X- _ O
thought -X- _ O
after -X- _ O
a -X- _ O
case -X- _ O
- -X- _ O
control -X- _ O
study -X- _ O
using -X- _ O
a -X- _ O
scenario -X- _ O
without -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
directed -X- _ O
path -X- _ O
from -X- _ O
polysemy -X- _ O
or -X- _ O
frequency -X- _ O
to -X- _ O
semantic -X- _ O
change -X- _ O
in -X- _ O
our -X- _ O
causal -X- _ O
graph -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
are -X- _ O
both -X- _ O
inﬂuenced -X- _ O
by -X- _ O
word -X- _ O
type -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
for -X- _ O
future -X- _ O
research -X- _ O
to -X- _ O
explore -X- _ O
whether -X- _ O
other -X- _ O
word -X- _ O
categorizations -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
related -X- _ O
to -X- _ O
speciﬁc -X- _ O
domains -X- _ O
, -X- _ O
languages -X- _ O
or -X- _ O
phonetic -X- _ O
aspects -X- _ O
, -X- _ O
sustain -X- _ O
this -X- _ O
result -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
our -X- _ O
analysis -X- _ O
does -X- _ O
not -X- _ O
support -X- _ O
the -X- _ O
claim -X- _ O
that -X- _ O
POS -X- _ O
could -X- _ O
underlie -X- _ O
semantic -X- _ O
change -X- _ O
( -X- _ O
Dubossarsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
however -X- _ O
that -X- _ O
as -X- _ O
our -X- _ O
vocabulary -X- _ O
contains -X- _ O
50 -X- _ O
% -X- _ O
slang -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
need -X- _ O
not -X- _ O
be -X- _ O
consistent -X- _ O
with -X- _ O
results -X- _ O
obtained -X- _ O
with -X- _ O
a -X- _ O
word -X- _ O
sample -X- _ O
drawn -X- _ O
from -X- _ O
standard -X- _ O
language -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
causal -X- _ O
structure -X- _ O
we -X- _ O
discover -X- _ O
thatword -X- _ O
polysemy -X- _ O
has -X- _ O
a -X- _ O
direct -X- _ O
effect -X- _ O
on -X- _ O
word -X- _ O
frequency -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
previous -X- _ O
linguis- -X- _ O
tic -X- _ O
studies -X- _ O
showing -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
frequency -X- _ O
grows -X- _ O
in -X- _ O
an -X- _ O
S -X- _ O
- -X- _ O
shaped -X- _ O
curve -X- _ O
when -X- _ O
it -X- _ O
acquires -X- _ O
new -X- _ O
mean- -X- _ O
ings -X- _ O
( -X- _ O
Kroch -X- _ O
, -X- _ O
1989 -X- _ O
; -X- _ O
Feltgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
known -X- _ O
positive -X- _ O
correlation -X- _ O
between -X- _ O
polysemy -X- _ O
and -X- _ O
frequency -X- _ O
( -X- _ O
Lee -X- _ O
, -X- _ O
1990 -X- _ O
; -X- _ O
Casas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
emphasize -X- _ O
that -X- _ O
this -X- _ O
relationship -X- _ O
is -X- _ O
not -X- _ O
merely -X- _ O
an -X- _ O
ar- -X- _ O
tifact -X- _ O
of -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
being -X- _ O
affected -X- _ O
by -X- _ O
frequency -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
since -X- _ O
our -X- _ O
polysemy -X- _ O
score -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
word -X- _ O
representa- -X- _ O
tions -X- _ O
as -X- _ O
in -X- _ O
Hamilton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
is -X- _ O
however -X- _ O
not -X- _ O
without -X- _ O
drawbacks -X- _ O
– -X- _ O
the -X- _ O
polysemy -X- _ O
variable -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
dictionaries -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
subjective -X- _ O
in -X- _ O
their -X- _ O
assignments -X- _ O
of -X- _ O
word -X- _ O
senses -X- _ O
. -X- _ O
Our -X- _ O
study -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
the -X- _ O
dy- -X- _ O
namics -X- _ O
of -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
is -X- _ O
limited -X- _ O
by -X- _ O
mainly -X- _ O
considering -X- _ O
distributional -X- _ O
factors -X- _ O
. -X- _ O
Linguists -X- _ O
have -X- _ O
suggested -X- _ O
that -X- _ O
sociocultural -X- _ O
, -X- _ O
psychological -X- _ O
and -X- _ O
po- -X- _ O
litical -X- _ O
factors -X- _ O
may -X- _ O
drive -X- _ O
word -X- _ O
change -X- _ O
dynamics -X- _ O
( -X- _ O
Blank -X- _ O
, -X- _ O
1999 -X- _ O
; -X- _ O
Bochkarev -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
slang -X- _ O
words -X- _ O
are -X- _ O
not -X- _ O
an -X- _ O
exception -X- _ O
. -X- _ O
Although -X- _ O
challenging -X- _ O
to -X- _ O
measure -X- _ O
, -X- _ O
the -X- _ O
inﬂuence -X- _ O
of -X- _ O
such -X- _ O
factors -X- _ O
on -X- _ O
slang -X- _ O
compared -X- _ O
to -X- _ O
nonslang -X- _ O
words -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
examine -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
conclusion -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
a -X- _ O
causal -X- _ O
analysis -X- _ O
as -X- _ O
we -X- _ O
have -X- _ O
presented -X- _ O
here -X- _ O
provides -X- _ O
a -X- _ O
useful -X- _ O
tool -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
underlying -X- _ O
mechanisms -X- _ O
of -X- _ O
language -X- _ O
. -X- _ O
Complementing -X- _ O
the -X- _ O
recent -X- _ O
emergence -X- _ O
of -X- _ O
research -X- _ O
combining -X- _ O
causal -X- _ O
inference -X- _ O
and -X- _ O
NLP -X- _ O
( -X- _ O
Feder -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
tools -X- _ O
from -X- _ O
causality -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
beneﬁcial -X- _ O
for -X- _ O
gaining -X- _ O
new -X- _ O
insights -X- _ O
in -X- _ O
diachronic -X- _ O
linguistics.8 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
analyzed -X- _ O
the -X- _ O
diachronic -X- _ O
mechanisms -X- _ O
of -X- _ O
slang -X- _ O
language -X- _ O
with -X- _ O
a -X- _ O
causal -X- _ O
methodology -X- _ O
. -X- _ O
This -X- _ O
allowed -X- _ O
us -X- _ O
to -X- _ O
establish -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
’s -X- _ O
type -X- _ O
has -X- _ O
a -X- _ O
direct -X- _ O
effect -X- _ O
on -X- _ O
its -X- _ O
semantic -X- _ O
change -X- _ O
and -X- _ O
frequency -X- _ O
shift -X- _ O
, -X- _ O
without -X- _ O
mediating -X- _ O
ef- -X- _ O
fects -X- _ O
from -X- _ O
other -X- _ O
distributional -X- _ O
factors -X- _ O
. -X- _ O
Acknowledgments -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Steven -X- _ O
R. -X- _ O
Wilson -X- _ O
for -X- _ O
provid- -X- _ O
ing -X- _ O
us -X- _ O
with -X- _ O
the -X- _ O
Urban -X- _ O
Dictionary -X- _ O
data -X- _ O
and -X- _ O
Walter -X- _ O
Rader -X- _ O
for -X- _ O
providing -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
curated -X- _ O
set -X- _ O
of -X- _ O
slang -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
Online -X- _ O
Slang -X- _ O
Dictionary -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
Twitter -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
thankful -X- _ O
to -X- _ O
have -X- _ O
been -X- _ O
able -X- _ O
to -X- _ O
get -X- _ O
access -X- _ O
to -X- _ O
Twitter -X- _ O
’s -X- _ O
Academic -X- _ O
Research -X- _ O
Track -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
gratefully -X- _ O
acknowledge -X- _ O
feedback -X- _ O
and -X- _ O
helpful -X- _ O
comments -X- _ O
from -X- _ O
Mario -X- _ O
Giulianelli -X- _ O
, -X- _ O
Yifan -X- _ O
Hou -X- _ O
, -X- _ O
Bernhard -X- _ O
Schölkopf -X- _ O
and -X- _ O
three -X- _ O
anonymous -X- _ O
reviewers -X- _ O
. -X- _ O
This -X- _ O
material -X- _ O
is -X- _ O
based -X- _ O
in -X- _ O
part -X- _ O
upon -X- _ O
works -X- _ O
sup- -X- _ O
ported -X- _ O
by -X- _ O
the -X- _ O
John -X- _ O
Templeton -X- _ O
Foundation -X- _ O
( -X- _ O
grant -X- _ O
# -X- _ O
61156 -X- _ O
) -X- _ O
; -X- _ O
by -X- _ O
a -X- _ O
Responsible -X- _ O
AI -X- _ O
grant -X- _ O
by -X- _ O
the -X- _ O
Hasler- -X- _ O
stiftung -X- _ O
; -X- _ O
by -X- _ O
an -X- _ O
ETH -X- _ O
Grant -X- _ O
( -X- _ O
ETH-19 -X- _ O
21 -X- _ O
- -X- _ O
1 -X- _ O
) -X- _ O
; -X- _ O
by -X- _ O
the -X- _ O
German -X- _ O
Federal -X- _ O
Ministry -X- _ O
of -X- _ O
Education -X- _ O
and -X- _ O
Research -X- _ O
( -X- _ O
BMBF -X- _ O
) -X- _ O
: -X- _ O
Tübingen -X- _ O
AI -X- _ O
Center -X- _ O
, -X- _ O
FKZ -X- _ O
: -X- _ O
01IS18039B -X- _ O
; -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
Machine -X- _ O
Learning -X- _ O
Clus- -X- _ O
ter -X- _ O
of -X- _ O
Excellence -X- _ O
, -X- _ O
EXC -X- _ O
number -X- _ O
2064 -X- _ O
/ -X- _ O
1 -X- _ O
– -X- _ O
Project -X- _ O
number -X- _ O
390727645 -X- _ O
. -X- _ O
Ethical -X- _ O
Considerations -X- _ O
Our -X- _ O
dataset -X- _ O
is -X- _ O
composed -X- _ O
solely -X- _ O
of -X- _ O
English -X- _ O
text -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
our -X- _ O
analysis -X- _ O
applies -X- _ O
uniquely -X- _ O
to -X- _ O
the -X- _ O
English -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
results -X- _ O
may -X- _ O
differ -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
curated -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
170 -X- _ O
; -X- _ O
135tweets -X- _ O
. -X- _ O
We -X- _ O
emphasize -X- _ O
that -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
protect -X- _ O
the -X- _ O
anonymity -X- _ O
of -X- _ O
users -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
all -X- _ O
author -X- _ O
IDs -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
replace -X- _ O
all -X- _ O
usernames -X- _ O
with -X- _ O
the -X- _ O
general -X- _ O
token -X- _ O
“ -X- _ O
user -X- _ O
. -X- _ O
” -X- _ O
In -X- _ O
the -X- _ O
Urban -X- _ O
Dictionary -X- _ O
dataset -X- _ O
we -X- _ O
received -X- _ O
from -X- _ O
Wilson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
similarly -X- _ O
remove -X- _ O
the -X- _ O
author -X- _ O
IDs -X- _ O
and -X- _ O
only -X- _ O
consider -X- _ O
the -X- _ O
entry -X- _ O
text -X- _ O
. -X- _ O
References1430143114321433 -X- _ O
A -X- _ O
Appendix -X- _ O
– -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
with -X- _ O
Urban -X- _ O
Dictionary -X- _ O
data -X- _ O
A.1 -X- _ O
Preprocessing -X- _ O
The -X- _ O
full -X- _ O
Urban -X- _ O
Dictionary -X- _ O
data -X- _ O
contains -X- _ O
3 -X- _ O
; -X- _ O
534 -X- _ O
; -X- _ O
966 -X- _ O
word -X- _ O
deﬁnitions -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
dataset -X- _ O
provided -X- _ O
by -X- _ O
Wil- -X- _ O
son -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
each -X- _ O
entry -X- _ O
contains -X- _ O
a -X- _ O
deﬁnition -X- _ O
, -X- _ O
examples -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
word -X- _ O
occurs -X- _ O
, -X- _ O
number -X- _ O
of -X- _ O
up- -X- _ O
votes -X- _ O
& -X- _ O
downvotes -X- _ O
from -X- _ O
website -X- _ O
visitors -X- _ O
, -X- _ O
username -X- _ O
of -X- _ O
the -X- _ O
submitter -X- _ O
and -X- _ O
a -X- _ O
timestamp -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
crowd -X- _ O
- -X- _ O
sourced -X- _ O
, -X- _ O
many -X- _ O
of -X- _ O
these -X- _ O
entries -X- _ O
are -X- _ O
noisy -X- _ O
and -X- _ O
of -X- _ O
low -X- _ O
quality -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
ﬁlter -X- _ O
the -X- _ O
lower -X- _ O
quality -X- _ O
deﬁnitions -X- _ O
out -X- _ O
before -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
RoBERTa -X- _ O
. -X- _ O
Af- -X- _ O
ter -X- _ O
performing -X- _ O
data -X- _ O
exploration -X- _ O
, -X- _ O
we -X- _ O
came -X- _ O
up -X- _ O
with -X- _ O
two -X- _ O
criteria -X- _ O
that -X- _ O
we -X- _ O
found -X- _ O
the -X- _ O
most -X- _ O
indicative -X- _ O
of -X- _ O
a -X- _ O
deﬁnition -X- _ O
’s -X- _ O
quality -X- _ O
: -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
upvotes -X- _ O
it -X- _ O
got -X- _ O
, -X- _ O
and -X- _ O
its -X- _ O
upvote -X- _ O
/ -X- _ O
downvote -X- _ O
ratio -X- _ O
. -X- _ O
The -X- _ O
distribution -X- _ O
of -X- _ O
upvotes -X- _ O
, -X- _ O
downvotes -X- _ O
and -X- _ O
the -X- _ O
upvote -X- _ O
/ -X- _ O
downvote -X- _ O
ratios -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
below -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
submissions -X- _ O
to -X- _ O
Urban -X- _ O
Dictionary -X- _ O
is -X- _ O
relatively -X- _ O
well -X- _ O
- -X- _ O
spread -X- _ O
, -X- _ O
see -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
This -X- _ O
implies -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
a -X- _ O
strong -X- _ O
bias -X- _ O
to- -X- _ O
wards -X- _ O
more -X- _ O
recently -X- _ O
popularized -X- _ O
slang -X- _ O
terms -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
have -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
time -X- _ O
span -X- _ O
of -X- _ O
interest -X- _ O
; -X- _ O
20102020 -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
the -X- _ O
entries -X- _ O
having -X- _ O
more -X- _ O
than -X- _ O
20up- -X- _ O
votes -X- _ O
and -X- _ O
an -X- _ O
upvote -X- _ O
/ -X- _ O
downvote -X- _ O
ratio -X- _ O
of -X- _ O
at -X- _ O
least -X- _ O
2 -X- _ O
. -X- _ O
This -X- _ O
leaves -X- _ O
us -X- _ O
with -X- _ O
488 -X- _ O
; -X- _ O
010Urban -X- _ O
Dictionary -X- _ O
en- -X- _ O
tries -X- _ O
, -X- _ O
out -X- _ O
of -X- _ O
which -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
100 -X- _ O
; -X- _ O
000 -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
computation -X- _ O
time -X- _ O
in -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
both -X- _ O
the -X- _ O
deﬁnitions -X- _ O
and -X- _ O
the -X- _ O
word -X- _ O
usage -X- _ O
examples -X- _ O
for -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
producing -X- _ O
a -X- _ O
ﬁnal -X- _ O
dataset -X- _ O
of -X- _ O
200 -X- _ O
; -X- _ O
000sequences -X- _ O
. -X- _ O
A.2 -X- _ O
Training -X- _ O
We -X- _ O
randomly -X- _ O
split -X- _ O
the -X- _ O
data -X- _ O
into -X- _ O
80 -X- _ O
% -X- _ O
train -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
test -X- _ O
, -X- _ O
before -X- _ O
training -X- _ O
for -X- _ O
10epochs -X- _ O
with -X- _ O
an -X- _ O
early -X- _ O
stopping -X- _ O
with -X- _ O
patience -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
batch -X- _ O
size -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
1 -X- _ O
in -X- _ O
the -X- _ O
interest -X- _ O
of -X- _ O
memory -X- _ O
constraints -X- _ O
. -X- _ O
Following1434 -X- _ O
the -X- _ O
setup -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
as -X- _ O
explained -X- _ O
in -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
= -X- _ O
10 -X- _ O
; -X- _ O
= -X- _ O
0:9 -X- _ O
& -X- _ O
= -X- _ O
0:98and -X- _ O
a -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
decay -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
since -X- _ O
the -X- _ O
initial- -X- _ O
ized -X- _ O
parameters -X- _ O
should -X- _ O
provide -X- _ O
a -X- _ O
solution -X- _ O
which -X- _ O
is -X- _ O
already -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
optimum -X- _ O
when -X- _ O
evaluating -X- _ O
on -X- _ O
our -X- _ O
dataset -X- _ O
( -X- _ O
our -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
being -X- _ O
the -X- _ O
very -X- _ O
same -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
as -X- _ O
RoBERTa -X- _ O
has -X- _ O
already -X- _ O
been -X- _ O
trained -X- _ O
on -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
should -X- _ O
be -X- _ O
smaller -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
picking -X- _ O
the -X- _ O
learning -X- _ O
rate -X- _ O
= -X- _ O
610as -X- _ O
was -X- _ O
done -X- _ O
by -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
2 -X- _ O
f10 -X- _ O
; -X- _ O
10 -X- _ O
; -X- _ O
10 -X- _ O
; -X- _ O
10 -X- _ O
g. -X- _ O
Training -X- _ O
was -X- _ O
done -X- _ O
using -X- _ O
an -X- _ O
NVIDIA -X- _ O
GeForce -X- _ O
GTX -X- _ O
1080 -X- _ O
8 -X- _ O
GB -X- _ O
GPU -X- _ O
and -X- _ O
took -X- _ O
around -X- _ O
1 -X- _ O
to -X- _ O
1.5 -X- _ O
days -X- _ O
per -X- _ O
model -X- _ O
. -X- _ O
B -X- _ O
Appendix -X- _ O
– -X- _ O
Experiments -X- _ O
on -X- _ O
SemEval-2020 -X- _ O
B.1 -X- _ O
Distribution -X- _ O
- -X- _ O
based -X- _ O
Metrics -X- _ O
Method -X- _ O
: -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
distance -X- _ O
- -X- _ O
based -X- _ O
APD -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
two -X- _ O
distribution -X- _ O
- -X- _ O
based -X- _ O
ones -X- _ O
, -X- _ O
namely -X- _ O
entropy -X- _ O
difference -X- _ O
( -X- _ O
ED -X- _ O
) -X- _ O
& -X- _ O
Jensen- -X- _ O
Shannon -X- _ O
Divergence -X- _ O
( -X- _ O
JSD -X- _ O
) -X- _ O
( -X- _ O
Giulianelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
a -X- _ O
categorical -X- _ O
distribution -X- _ O
over -X- _ O
a -X- _ O
set -X- _ O
ofKword -X- _ O
senses -X- _ O
for -X- _ O
word -X- _ O
wand -X- _ O
time -X- _ O
period -X- _ O
t. -X- _ O
The -X- _ O
word -X- _ O
sense -X- _ O
sof -X- _ O
an -X- _ O
occurrence -X- _ O
iis -X- _ O
then -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O
sCat -X- _ O
( -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
) -X- _ O
= -X- _ O
: -X- _ O
P -X- _ O
Given -X- _ O
two -X- _ O
time -X- _ O
periods -X- _ O
of -X- _ O
word -X- _ O
sense -X- _ O
distributions -X- _ O
, -X- _ O
we -X- _ O
deﬁne -X- _ O
the -X- _ O
ED -X- _ O
metric -X- _ O
as -X- _ O
jH -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
H -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
j -X- _ O
with -X- _ O
entropy -X- _ O
H -X- _ O
( -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
JSD -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
: -X- _ O
1 -X- _ O
2KL -X- _ O
( -X- _ O
PjjM -X- _ O
) -X- _ O
+1 -X- _ O
2KL -X- _ O
( -X- _ O
PjjM -X- _ O
) -X- _ O
withM -X- _ O
= -X- _ O
andKL -X- _ O
( -X- _ O
jj -X- _ O
) -X- _ O
being -X- _ O
the -X- _ O
KL- -X- _ O
divergence -X- _ O
. -X- _ O
We -X- _ O
obtain -X- _ O
the -X- _ O
word -X- _ O
sense -X- _ O
distributions -X- _ O
via -X- _ O
a -X- _ O
clus- -X- _ O
tering -X- _ O
of -X- _ O
the -X- _ O
representations -X- _ O
from -X- _ O
both -X- _ O
time -X- _ O
periods -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
K -X- _ O
- -X- _ O
Means -X- _ O
and -X- _ O
Gaussian -X- _ O
Mix- -X- _ O
ture -X- _ O
Models -X- _ O
( -X- _ O
GMMs -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
latter -X- _ O
proposed -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
ﬁnd -X- _ O
more -X- _ O
general -X- _ O
cluster -X- _ O
shapes -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
experiment -X- _ O
brieﬂy -X- _ O
with -X- _ O
Afﬁnity -X- _ O
Propagation -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
previous -X- _ O
semantic -X- _ O
change -X- _ O
detection -X- _ O
work -X- _ O
( -X- _ O
Martinc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kutuzov -X- _ O
and -X- _ O
Giulianelli -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Montariol -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
How- -X- _ O
ever -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
it -X- _ O
to -X- _ O
be -X- _ O
ill -X- _ O
- -X- _ O
suited -X- _ O
for -X- _ O
our -X- _ O
purposes -X- _ O
since -X- _ O
it -X- _ O
results -X- _ O
in -X- _ O
an -X- _ O
excessive -X- _ O
amount -X- _ O
of -X- _ O
clusters -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
how -X- _ O
a -X- _ O
human -X- _ O
would -X- _ O
classify -X- _ O
word -X- _ O
senses -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
K -X- _ O
- -X- _ O
means -X- _ O
and -X- _ O
GMM -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
selecting -X- _ O
the -X- _ O
optimal -X- _ O
K2 -X- _ O
[ -X- _ O
1 -X- _ O
; -X- _ O
10 -X- _ O
] -X- _ O
through -X- _ O
two -X- _ O
different -X- _ O
procedures -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
one -X- _ O
is -X- _ O
a -X- _ O
slight -X- _ O
ex- -X- _ O
tension -X- _ O
of -X- _ O
the -X- _ O
method -X- _ O
from -X- _ O
Giulianelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
– -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
Kwhich -X- _ O
optimizes -X- _ O
the -X- _ O
silhouette -X- _ O
score -X- _ O
( -X- _ O
Rousseeuw -X- _ O
, -X- _ O
1987 -X- _ O
) -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
different -X- _ O
ini- -X- _ O
tializations -X- _ O
. -X- _ O
Their -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
single -X- _ O
cluster -X- _ O
case -X- _ O
however -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
extend -X- _ O
it -X- _ O
by -X- _ O
settingK= -X- _ O
1 -X- _ O
when -X- _ O
the -X- _ O
best -X- _ O
silhouette -X- _ O
score -X- _ O
is -X- _ O
below -X- _ O
a -X- _ O
threshold -X- _ O
of -X- _ O
0:1 -X- _ O
. -X- _ O
ForK -X- _ O
- -X- _ O
Means -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
experiment -X- _ O
with -X- _ O
an -X- _ O
automatic -X- _ O
elbow -X- _ O
methodfor1435 -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
squared -X- _ O
distances -X- _ O
to -X- _ O
the -X- _ O
cluster -X- _ O
cen- -X- _ O
troids -X- _ O
, -X- _ O
which -X- _ O
decreases -X- _ O
monotonically -X- _ O
with -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
clusters -X- _ O
. -X- _ O
We -X- _ O
again -X- _ O
select -X- _ O
the -X- _ O
cluster -X- _ O
assignments -X- _ O
with -X- _ O
the -X- _ O
largest -X- _ O
silhouette -X- _ O
score -X- _ O
for -X- _ O
multiple -X- _ O
random -X- _ O
initalizations -X- _ O
. -X- _ O
For -X- _ O
GMM -X- _ O
, -X- _ O
we -X- _ O
fur- -X- _ O
ther -X- _ O
experiment -X- _ O
with -X- _ O
taking -X- _ O
the -X- _ O
model -X- _ O
which -X- _ O
corre- -X- _ O
sponds -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
Bayesian -X- _ O
Information -X- _ O
Criterion -X- _ O
( -X- _ O
Schwarz -X- _ O
, -X- _ O
1978 -X- _ O
) -X- _ O
. -X- _ O
Clustering -X- _ O
examples -X- _ O
: -X- _ O
In -X- _ O
Figure -X- _ O
7 -X- _ O
we -X- _ O
see -X- _ O
three -X- _ O
clusters -X- _ O
found -X- _ O
for -X- _ O
“ -X- _ O
gag -X- _ O
. -X- _ O
” -X- _ O
They -X- _ O
do -X- _ O
not -X- _ O
seem -X- _ O
to -X- _ O
correspond -X- _ O
to -X- _ O
word -X- _ O
senses -X- _ O
however -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
from -X- _ O
the -X- _ O
ﬁrst -X- _ O
cluster -X- _ O
is -X- _ O
“ -X- _ O
user -X- _ O
i -X- _ O
need -X- _ O
a -X- _ O
pic -X- _ O
of -X- _ O
you -X- _ O
begging -X- _ O
if -X- _ O
i -X- _ O
’ -X- _ O
m -X- _ O
boiling -X- _ O
these -X- _ O
because -X- _ O
boiled -X- _ O
eggs -X- _ O
make -X- _ O
me -X- _ O
gag -X- _ O
. -X- _ O
: -X- _ O
d -X- _ O
, -X- _ O
” -X- _ O
an -X- _ O
example -X- _ O
from -X- _ O
the -X- _ O
second -X- _ O
cluster -X- _ O
is -X- _ O
“ -X- _ O
lmao -X- _ O
rt -X- _ O
user -X- _ O
user -X- _ O
user -X- _ O
so -X- _ O
i -X- _ O
tried -X- _ O
that -X- _ O
tuna -X- _ O
with -X- _ O
cheese -X- _ O
and -X- _ O
my -X- _ O
gag -X- _ O
reﬂexes -X- _ O
were -X- _ O
in -X- _ O
full -X- _ O
affect -X- _ O
! -X- _ O
” -X- _ O
and -X- _ O
an -X- _ O
example -X- _ O
from -X- _ O
the -X- _ O
third -X- _ O
cluster -X- _ O
is -X- _ O
“ -X- _ O
gag -X- _ O
me -X- _ O
with -X- _ O
a -X- _ O
spoon -X- _ O
” -X- _ O
– -X- _ O
all -X- _ O
seemingly -X- _ O
referring -X- _ O
to -X- _ O
the -X- _ O
sensation -X- _ O
of -X- _ O
being -X- _ O
about -X- _ O
to -X- _ O
vomit -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
another -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
8 -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
“ -X- _ O
gnarly -X- _ O
, -X- _ O
” -X- _ O
this -X- _ O
time -X- _ O
reduced -X- _ O
to -X- _ O
2dimensions -X- _ O
using -X- _ O
UMAP -X- _ O
. -X- _ O
Gnarly -X- _ O
has -X- _ O
three -X- _ O
meanings -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
Online -X- _ O
Slang -X- _ O
Dictionary -X- _ O
: -X- _ O
It -X- _ O
can -X- _ O
either -X- _ O
mean -X- _ O
very -X- _ O
good -X- _ O
/ -X- _ O
excellent -X- _ O
/ -X- _ O
cool -X- _ O
, -X- _ O
gross -X- _ O
/ -X- _ O
disgusting -X- _ O
or -X- _ O
painful -X- _ O
/ -X- _ O
dangerous -X- _ O
. -X- _ O
These -X- _ O
three -X- _ O
word -X- _ O
senses -X- _ O
are -X- _ O
not -X- _ O
separated -X- _ O
by -X- _ O
UMAP -X- _ O
and -X- _ O
GMM -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
both -X- _ O
“ -X- _ O
its -X- _ O
a -X- _ O
good -X- _ O
thing -X- _ O
one -X- _ O
of -X- _ O
my -X- _ O
roomies -X- _ O
is -X- _ O
a -X- _ O
dude -X- _ O
, -X- _ O
who -X- _ O
else -X- _ O
would -X- _ O
kill -X- _ O
gnarly -X- _ O
spiders -X- _ O
in -X- _ O
my -X- _ O
room -X- _ O
when -X- _ O
i -X- _ O
start -X- _ O
to -X- _ O
hyperventilate -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
rt -X- _ O
user -X- _ O
bro -X- _ O
my -X- _ O
wreck -X- _ O
on -X- _ O
the -X- _ O
scooter -X- _ O
was -X- _ O
so -X- _ O
gnarly -X- _ O
like -X- _ O
it -X- _ O
was -X- _ O
fun -X- _ O
i -X- _ O
love -X- _ O
shit -X- _ O
like -X- _ O
that -X- _ O
. -X- _ O
i -X- _ O
wish -X- _ O
i -X- _ O
could -X- _ O
’ve -X- _ O
been -X- _ O
on -X- _ O
jackass -X- _ O
” -X- _ O
are -X- _ O
put -X- _ O
in -X- _ O
the -X- _ O
ﬁrst -X- _ O
cluster -X- _ O
. -X- _ O
B.2 -X- _ O
Variance -X- _ O
Explained -X- _ O
by -X- _ O
PCA -X- _ O
components -X- _ O
Consider -X- _ O
Figure -X- _ O
9 -X- _ O
for -X- _ O
example -X- _ O
plots -X- _ O
of -X- _ O
how -X- _ O
much -X- _ O
variance -X- _ O
is -X- _ O
preserved -X- _ O
with -X- _ O
PCA -X- _ O
on -X- _ O
the -X- _ O
contextual- -X- _ O
ized -X- _ O
representations -X- _ O
. -X- _ O
Baseline -X- _ O
Score -X- _ O
Combined -X- _ O
APD -X- _ O
PCA100 -X- _ O
0:489 -X- _ O
Kutuzov -X- _ O
and -X- _ O
Giulianelli -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0:605 -X- _ O
Kaiser -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0:461 -X- _ O
Rother -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
0:440 -X- _ O
B.3 -X- _ O
Results -X- _ O
We -X- _ O
further -X- _ O
present -X- _ O
more -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
experimen- -X- _ O
tation -X- _ O
on -X- _ O
the -X- _ O
SemEval-2020 -X- _ O
Task -X- _ O
1 -X- _ O
Subtask -X- _ O
2 -X- _ O
. -X- _ O
All -X- _ O
tables -X- _ O
show -X- _ O
the -X- _ O
Spearman -X- _ O
’s -X- _ O
rank -X- _ O
- -X- _ O
order -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
change -X- _ O
metrics -X- _ O
and -X- _ O
the -X- _ O
ground -X- _ O
truths -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
2 -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
best -X- _ O
performing -X- _ O
setup -X- _ O
to -X- _ O
the -X- _ O
three -X- _ O
best -X- _ O
performing -X- _ O
previous -X- _ O
approaches -X- _ O
on -X- _ O
SemEval-2020 -X- _ O
Task -X- _ O
1 -X- _ O
Subtask -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
only -X- _ O
Kutuzov -X- _ O
and -X- _ O
Giulianelli -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
display -X- _ O
a -X- _ O
higher -X- _ O
score -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
be -X- _ O
partially -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
they -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
their -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
SemEval -X- _ O
test -X- _ O
corpora -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
do -X- _ O
this -X- _ O
since -X- _ O
our -X- _ O
main -X- _ O
goal -X- _ O
is -X- _ O
not -X- _ O
to -X- _ O
beat -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
the -X- _ O
shared -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
rather -X- _ O
to -X- _ O
ﬁnd -X- _ O
a -X- _ O
good -X- _ O
enough -X- _ O
model -X- _ O
to -X- _ O
detect -X- _ O
semantic -X- _ O
change -X- _ O
in -X- _ O
slang -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
comparing -X- _ O
the -X- _ O
layer -X- _ O
representations -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
side -X- _ O
observation -X- _ O
we -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
less -X- _ O
isotropic -X- _ O
ﬁrst -X- _ O
layer -X- _ O
rep- -X- _ O
resentations -X- _ O
seem -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
more -X- _ O
isotropic -X- _ O
last -X- _ O
layer -X- _ O
representations -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
comparison -X- _ O
across -X- _ O
differ- -X- _ O
ent -X- _ O
layer -X- _ O
representations -X- _ O
for -X- _ O
both -X- _ O
APD -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
distribution -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
give -X- _ O
signiﬁcant -X- _ O
results -X- _ O
, -X- _ O
even -X- _ O
when -X- _ O
used -X- _ O
with -X- _ O
dimensionality -X- _ O
reduc- -X- _ O
tion -X- _ O
techniques -X- _ O
. -X- _ O
While -X- _ O
a -X- _ O
few -X- _ O
of -X- _ O
them -X- _ O
do -X- _ O
have -X- _ O
a1436 -X- _ O
slight -X- _ O
positive -X- _ O
correlation -X- _ O
, -X- _ O
we -X- _ O
omit -X- _ O
this -X- _ O
approach -X- _ O
altogether -X- _ O
. -X- _ O
The -X- _ O
APD -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
show -X- _ O
a -X- _ O
high -X- _ O
correlation -X- _ O
for -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
conﬁgurations -X- _ O
, -X- _ O
providing -X- _ O
an -X- _ O
indication -X- _ O
of -X- _ O
the -X- _ O
APD -X- _ O
’s -X- _ O
robustness -X- _ O
in -X- _ O
detecting -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
a -X- _ O
selection -X- _ O
of -X- _ O
these -X- _ O
in -X- _ O
Table -X- _ O
6.dAPDdAPD -X- _ O
First -X- _ O
layer -X- _ O
0:22 -X- _ O
0:234 -X- _ O
Last -X- _ O
layer -X- _ O
0:07 -X- _ O
0:2 -X- _ O
Sum -X- _ O
of -X- _ O
all -X- _ O
layers -X- _ O
0:3360:332 -X- _ O
Reps -X- _ O
Cluster -X- _ B-MetricName
Metric -X- _ I-MetricName
Score -X- _ I-MetricName
p -X- _ O
First -X- _ B-MetricName
- -X- _ I-MetricName
APD -X- _ I-MetricName
d -X- _ O
0:22 -X- _ B-MetricValue
0:19 -X- _ B-MetricValue
First -X- _ B-MetricName
- -X- _ I-MetricName
APD -X- _ I-MetricName
d -X- _ O
0:23 -X- _ B-MetricValue
0:16 -X- _ B-MetricValue
First -X- _ B-MetricName
K -X- _ I-MetricName
- -X- _ I-MetricName
Means -X- _ I-MetricName
ED -X- _ I-MetricName
0:08 -X- _ B-MetricValue
0:64 -X- _ B-MetricValue
First -X- _ B-MetricName
K -X- _ I-MetricName
- -X- _ I-MetricName
Means -X- _ I-MetricName
JSD -X- _ B-MetricName
0:06 -X- _ B-MetricValue
0:73 -X- _ B-MetricValue
First -X- _ B-MetricName
GMM -X- _ I-MetricName
ED -X- _ O
0:05 -X- _ B-MetricValue
0:76 -X- _ B-MetricValue
First -X- _ B-MetricName
GMM -X- _ I-MetricName
JSD -X- _ O
0:07 -X- _ B-MetricValue
0:67 -X- _ B-MetricValue
Last -X- _ B-MetricName
- -X- _ I-MetricName
APD -X- _ I-MetricName
d -X- _ O
0:01 -X- _ B-MetricValue
0:97 -X- _ B-MetricValue
Last -X- _ B-MetricName
- -X- _ I-MetricName
APD -X- _ I-MetricName
d -X- _ O
0:20 -X- _ B-MetricValue
0:24 -X- _ B-MetricValue
Last -X- _ B-MetricName
K -X- _ I-MetricName
- -X- _ I-MetricName
Means -X- _ I-MetricName
ED -X- _ O
0:00 -X- _ B-MetricValue
0:96 -X- _ B-MetricValue
Last -X- _ O
K -X- _ B-MetricName
- -X- _ I-MetricName
Means -X- _ I-MetricName
JSD -X- _ O
0:20 -X- _ B-MetricValue
0:23 -X- _ B-MetricValue
Last -X- _ O
GMM -X- _ O
ED -X- _ O
0:07 -X- _ B-MetricValue
0:70 -X- _ B-MetricValue
Last -X- _ O
GMM -X- _ O
JSD -X- _ O
0:10 -X- _ B-MetricValue
0:57 -X- _ B-MetricValue
All -X- _ O
- -X- _ O
APD -X- _ O
d -X- _ O
0:34 -X- _ B-MetricValue
0:04 -X- _ B-MetricValue
All -X- _ O
- -X- _ O
APD -X- _ O
d -X- _ O
0:33 -X- _ B-MetricValue
0:05 -X- _ B-MetricValue
All -X- _ O
K -X- _ O
- -X- _ O
Means -X- _ O
ED -X- _ O
0:03 -X- _ B-MetricValue
0:85 -X- _ B-MetricValue
All -X- _ B-MetricName
K -X- _ I-MetricName
- -X- _ I-MetricName
Means -X- _ I-MetricName
JSD -X- _ O
0:09 -X- _ B-MetricValue
0:60 -X- _ B-MetricValue
All -X- _ O
GMM -X- _ O
ED -X- _ O
0:13 -X- _ B-MetricValue
0:43 -X- _ B-MetricValue
All -X- _ B-MetricName
GMM -X- _ I-MetricName
JSD -X- _ O
0:00 -X- _ B-MetricValue
0:99 -X- _ B-MetricValue
C -X- _ O
Appendix -X- _ O
– -X- _ O
Hybrid -X- _ O
Words -X- _ O
We -X- _ O
deﬁne -X- _ O
hybrid -X- _ O
words -X- _ O
as -X- _ O
words -X- _ O
that -X- _ O
have -X- _ O
both -X- _ O
a -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
meaning -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
occurring -X- _ O
in -X- _ O
both -X- _ O
Online -X- _ O
Slang -X- _ O
Dictionary -X- _ O
( -X- _ O
OSD -X- _ O
) -X- _ O
and -X- _ O
Merriam -X- _ O
Webster -X- _ O
( -X- _ O
MW -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
polysemy -X- _ O
, -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
frequency -X- _ O
shift -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
absolute -X- _ O
frequency -X- _ O
change -X- _ O
patterns -X- _ O
of -X- _ O
hybrid -X- _ O
words -X- _ O
to -X- _ O
slang -X- _ O
and -X- _ O
nonslangs -X- _ O
. -X- _ O
Polysemy -X- _ O
is -X- _ O
collected -X- _ O
for -X- _ O
hybrid -X- _ O
words -X- _ O
from -X- _ O
OSD -X- _ O
and -X- _ O
MW -X- _ O
separately -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
MW -X- _ O
dictio- -X- _ O
nary -X- _ O
may -X- _ O
also -X- _ O
contain -X- _ O
slang -X- _ O
meanings -X- _ O
, -X- _ O
we -X- _ O
ﬁlter -X- _ O
out -X- _ O
deﬁnitions -X- _ O
labeled -X- _ O
as -X- _ O
slang -X- _ O
, -X- _ O
informal -X- _ O
orvul- -X- _ O
garfrom -X- _ O
these -X- _ O
scores -X- _ O
. -X- _ O
The -X- _ O
mean -X- _ O
polysemy -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
slang -X- _ O
words -X- _ O
are -X- _ O
( -X- _ O
2:0742:568 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
mean -X- _ O
OSD -X- _ O
polysemy -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
hybrid -X- _ O
words -X- _ O
are -X- _ O
( -X- _ O
2:5802:178 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
signiﬁcant -X- _ O
differ- -X- _ O
ence -X- _ O
( -X- _ O
p -X- _ O
> -X- _ O
0:05 -X- _ O
) -X- _ O
in -X- _ O
distribution -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
per- -X- _ O
mutation -X- _ O
test -X- _ O
. -X- _ O
This -X- _ O
tells -X- _ O
us -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
not -X- _ O
skewing1437APD -X- _ O
Score -X- _ O
p -X- _ O
d -X- _ O
0:336 -X- _ O
0:042 -X- _ O
d -X- _ O
0:332 -X- _ O
0:045 -X- _ O
d -X- _ O
0:409 -X- _ O
0:012 -X- _ O
dandd -X- _ O
0:345 -X- _ O
0:037 -X- _ O
d -X- _ O
; -X- _ O
dandd0:398 -X- _ O
0:015 -X- _ O
Dim -X- _ O
APD -X- _ O
Score -X- _ O
p -X- _ O
PCA2 -X- _ O
d0:153 -X- _ O
0:367 -X- _ O
UMAP2 -X- _ O
d0:136 -X- _ O
0:424 -X- _ O
PCA5 -X- _ O
d -X- _ O
0:209 -X- _ O
0:215 -X- _ O
PCA5 -X- _ O
dandd -X- _ O
0:268 -X- _ O
0:109 -X- _ O
UMAP5 -X- _ O
d -X- _ O
; -X- _ O
dandd0:146 -X- _ O
0:39 -X- _ O
PCA20 -X- _ O
dandd -X- _ O
0:42 -X- _ O
0:010 -X- _ O
PCA50 -X- _ O
d -X- _ O
0:26 -X- _ O
0:121 -X- _ O
PCA50 -X- _ O
d -X- _ O
0:394 -X- _ O
0:016 -X- _ O
PCA50 -X- _ O
dandd -X- _ O
0:478 -X- _ O
0:003 -X- _ O
PCA50d -X- _ O
; -X- _ O
dandd0:344 -X- _ O
0:037 -X- _ O
UMAP50 -X- _ O
d0:158 -X- _ O
0:35 -X- _ O
PCA100 -X- _ O
d -X- _ O
0:297 -X- _ O
0:074 -X- _ O
PCA100 -X- _ O
dandd -X- _ O
0:489 -X- _ O
0:002 -X- _ O
UMAP100 -X- _ O
d0:133 -X- _ O
0:433 -X- _ O
the -X- _ O
polysemy -X- _ O
score -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
slang -X- _ O
words -X- _ O
by -X- _ O
excluding -X- _ O
hybrid -X- _ O
words -X- _ O
. -X- _ O
As -X- _ O
for -X- _ O
the -X- _ O
nonslang -X- _ O
meanings -X- _ O
of -X- _ O
the -X- _ O
hybrid -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
a -X- _ O
mean -X- _ O
polysemy -X- _ O
score -X- _ O
of -X- _ O
( -X- _ O
6:880 -X- _ O
6:080 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
signiﬁcantly -X- _ O
different -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001 -X- _ O
) -X- _ O
from -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
nonslang -X- _ O
words -X- _ O
( -X- _ O
3:0792:780 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
observation -X- _ O
, -X- _ O
implying -X- _ O
that -X- _ O
had -X- _ O
we -X- _ O
included -X- _ O
nonslang -X- _ O
words -X- _ O
with -X- _ O
hybrid -X- _ O
mean- -X- _ O
ing -X- _ O
in -X- _ O
our -X- _ O
nonslang -X- _ O
words -X- _ O
sample -X- _ O
, -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
polysemy -X- _ O
between -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
would -X- _ O
have -X- _ O
been -X- _ O
larger -X- _ O
. -X- _ O
Some -X- _ O
example -X- _ O
words -X- _ O
from -X- _ O
this -X- _ O
category -X- _ O
with -X- _ O
high -X- _ O
MW -X- _ O
polysemy -X- _ O
scores -X- _ O
in- -X- _ O
clude -X- _ O
“ -X- _ O
split -X- _ O
, -X- _ O
” -X- _ O
“ -X- _ O
down -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
walk -X- _ O
. -X- _ O
” -X- _ O
For -X- _ O
the -X- _ O
relative -X- _ O
frequency -X- _ O
changes -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
as -X- _ O
histograms -X- _ O
in -X- _ O
Figure -X- _ O
10 -X- _ O
. -X- _ O
The -X- _ O
fre- -X- _ O
quency -X- _ O
changes -X- _ O
in -X- _ O
hybrid -X- _ O
words -X- _ O
seem -X- _ O
to -X- _ O
fall -X- _ O
be- -X- _ O
tween -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
slang -X- _ O
words -X- _ O
and -X- _ O
the -X- _ O
nonslang -X- _ O
words -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
of0:154and0:608respectively -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
absolute -X- _ O
relative -X- _ O
fre- -X- _ O
quency -X- _ O
changes -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
5.3 -X- _ O
across -X- _ O
slang -X- _ O
, -X- _ O
nonslang -X- _ O
and -X- _ O
hybrid -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
histograms -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
11 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
, -X- _ O
respec- -X- _ O
tively -X- _ O
, -X- _ O
a -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
1:246 -X- _ O
& -X- _ O
1:180for -X- _ O
the -X- _ O
slang -X- _ O
words -X- _ O
, -X- _ O
0:950 -X- _ O
& -X- _ O
0:724for -X- _ O
the -X- _ O
nonslang -X- _ O
words -X- _ O
and -X- _ O
0:482 -X- _ O
& -X- _ O
0:402for -X- _ O
the -X- _ O
hybrid -X- _ O
words -X- _ O
. -X- _ O
The -X- _ O
difference -X- _ O
in -X- _ O
mean -X- _ O
is -X- _ O
signiﬁcant -X- _ O
be- -X- _ O
tween -X- _ O
the -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:05 -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
slang -X- _ O
words -X- _ O
have -X- _ O
undergone -X- _ O
a -X- _ O
larger -X- _ O
absolute -X- _ O
change -X- _ O
in -X- _ O
frequency -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
a -X- _ O
highly -X- _ O
signiﬁcant -X- _ O
difference -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
the -X- _ O
hybrid -X- _ O
words -X- _ O
compared -X- _ O
to -X- _ O
both -X- _ O
the -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
word -X- _ O
means -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
normalized -X- _ O
semantic -X- _ O
change -X- _ O
scores -X- _ O
between -X- _ O
the -X- _ O
slang -X- _ O
, -X- _ O
nonslang -X- _ O
and -X- _ O
hybrid -X- _ O
words -X- _ O
. -X- _ O
Histograms -X- _ O
over -X- _ O
the -X- _ O
semantic -X- _ O
change -X- _ O
scores -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
12 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
dis-1438 -X- _ O
tribution -X- _ O
over -X- _ O
hybrid -X- _ O
change -X- _ O
scores -X- _ O
seem -X- _ O
again -X- _ O
to -X- _ O
be -X- _ O
centered -X- _ O
between -X- _ O
the -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
dis- -X- _ O
tributions -X- _ O
, -X- _ O
with -X- _ O
mean -X- _ O
0:6210:073 -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
a -X- _ O
permutation -X- _ O
text -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
signiﬁcant -X- _ O
differ- -X- _ O
ence -X- _ O
in -X- _ O
semantic -X- _ O
change -X- _ O
both -X- _ O
between -X- _ O
hybrid -X- _ O
and -X- _ O
slang -X- _ O
words -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:001 -X- _ O
) -X- _ O
and -X- _ O
between -X- _ O
hybrid -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
( -X- _ O
p -X- _ O
< -X- _ O
0:05 -X- _ O
) -X- _ O
.D -X- _ O
Appendix -X- _ O
– -X- _ O
Causal -X- _ O
Analysis -X- _ O
D.1 -X- _ O
Preliminary -X- _ O
on -X- _ O
Constraint -X- _ O
- -X- _ O
based -X- _ O
Causal -X- _ O
Discovery -X- _ O
Assumptions -X- _ O
The -X- _ O
constraint -X- _ O
- -X- _ O
based -X- _ O
causal -X- _ O
dis- -X- _ O
covery -X- _ O
algorithms -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
two -X- _ O
main -X- _ O
as- -X- _ O
sumptions -X- _ O
, -X- _ O
namely -X- _ O
the -X- _ O
global -X- _ O
Markov -X- _ O
assump- -X- _ O
tion -X- _ O
and -X- _ O
the -X- _ O
faithfulness -X- _ O
assumption -X- _ O
. -X- _ O
The -X- _ O
global -X- _ O
Markov -X- _ O
property -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
holds -X- _ O
if -X- _ O
all -X- _ O
d- -X- _ O
separations -X- _ O
( -X- _ O
deﬁned -X- _ O
below -X- _ O
) -X- _ O
encoded -X- _ O
in -X- _ O
the -X- _ O
causal -X- _ O
graph -X- _ O
imply -X- _ O
conditional -X- _ O
independencies -X- _ O
in -X- _ O
the -X- _ O
dis- -X- _ O
tribution -X- _ O
over -X- _ O
the -X- _ O
variables -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
. -X- _ O
More -X- _ O
formally -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
graph -X- _ O
G= -X- _ O
( -X- _ O
V -X- _ O
; -X- _ O
E -X- _ O
) -X- _ O
and -X- _ O
distri- -X- _ O
bution -X- _ O
Pover -X- _ O
the -X- _ O
variables -X- _ O
Xit -X- _ O
holds -X- _ O
that -X- _ O
for -X- _ O
any -X- _ O
disjoint -X- _ O
subsets -X- _ O
A -X- _ O
; -X- _ O
B -X- _ O
andCofV -X- _ O
X -X- _ O
? -X- _ O
XjX -X- _ O
; -X- _ O
inG -X- _ O
) -X- _ O
X -X- _ O
? -X- _ O
? -X- _ O
XjX -X- _ O
; -X- _ O
inP -X- _ O
The -X- _ O
faithfulness -X- _ O
assumption -X- _ O
states -X- _ O
the -X- _ O
converse -X- _ O
of -X- _ O
the -X- _ O
global -X- _ O
Markov -X- _ O
assumption -X- _ O
: -X- _ O
All -X- _ O
conditional -X- _ O
independencies -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
are -X- _ O
encoded -X- _ O
by -X- _ O
d -X- _ O
- -X- _ O
separations -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
. -X- _ O
d -X- _ O
- -X- _ O
separation -X- _ O
Two -X- _ O
nodesA -X- _ O
; -X- _ O
B2Vare -X- _ O
said -X- _ O
to -X- _ O
bed -X- _ O
- -X- _ O
separated -X- _ O
( -X- _ O
Geiger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1990 -X- _ O
) -X- _ O
, -X- _ O
by -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
nodesZVif -X- _ O
for -X- _ O
all -X- _ O
paths -X- _ O
between -X- _ O
AandB -X- _ O
, -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
holds -X- _ O
: -X- _ O
•The -X- _ O
path -X- _ O
contains -X- _ O
a -X- _ O
directed -X- _ O
chain -X- _ O
A -X- _ O
! -X- _ O
C -X- _ O
! -X- _ O
B -X- _ O
or -X- _ O
A -X- _ O
C -X- _ O
Bsuch -X- _ O
thatC2Z -X- _ O
•The -X- _ O
path -X- _ O
contains -X- _ O
a -X- _ O
fork -X- _ O
A -X- _ O
C -X- _ O
! -X- _ O
B -X- _ O
such -X- _ O
thatC2Z -X- _ O
•The -X- _ O
path -X- _ O
contains -X- _ O
a -X- _ O
collider -X- _ O
A -X- _ O
! -X- _ O
C -X- _ O
B -X- _ O
such -X- _ O
that -X- _ O
C -X- _ O
= -X- _ O
2Z -X- _ O
orC=2Z8C2desc -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
( -X- _ O
i.e -X- _ O
. -X- _ O
, -X- _ O
neither -X- _ O
C -X- _ O
nor -X- _ O
any -X- _ O
of -X- _ O
its -X- _ O
descendants -X- _ O
is -X- _ O
in -X- _ O
Z -X- _ O
) -X- _ O
We -X- _ O
would -X- _ O
then -X- _ O
denote -X- _ O
X -X- _ O
? -X- _ O
XjX. -X- _ O
Markov -X- _ O
Equivalence -X- _ O
Constraint -X- _ O
- -X- _ O
based -X- _ O
algo- -X- _ O
rithms -X- _ O
use -X- _ O
conditional -X- _ O
independence -X- _ O
tests -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
identify -X- _ O
a -X- _ O
Markov -X- _ O
equivalence -X- _ O
class -X- _ O
of -X- _ O
DAGs -X- _ O
. -X- _ O
Two -X- _ O
DAGs -X- _ O
are -X- _ O
deﬁned -X- _ O
to -X- _ O
be -X- _ O
Markov -X- _ O
equivalent -X- _ O
if -X- _ O
they -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
skeleton -X- _ O
( -X- _ O
edges -X- _ O
omitting -X- _ O
di- -X- _ O
rection -X- _ O
) -X- _ O
and -X- _ O
v -X- _ O
- -X- _ O
structures -X- _ O
. -X- _ O
The -X- _ O
three -X- _ O
vertices -X- _ O
A -X- _ O
; -X- _ O
B -X- _ O
andCform -X- _ O
a -X- _ O
v -X- _ O
- -X- _ O
structure -X- _ O
if -X- _ O
A -X- _ O
! -X- _ O
B -X- _ O
CandA -X- _ O
andCare -X- _ O
not -X- _ O
directly -X- _ O
connected -X- _ O
by -X- _ O
an -X- _ O
edge -X- _ O
. -X- _ O
Alter- -X- _ O
natively -X- _ O
, -X- _ O
two -X- _ O
DAGs -X- _ O
are -X- _ O
Markov -X- _ O
equivalent -X- _ O
if -X- _ O
they -X- _ O
describe -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
d -X- _ O
- -X- _ O
separation -X- _ O
relationships -X- _ O
. -X- _ O
A -X- _ O
Markov -X- _ O
equivalence -X- _ O
class -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
Markov -X- _ O
equivalent -X- _ O
DAGs.1439 -X- _ O
PC -X- _ O
Algorithm -X- _ O
One -X- _ O
common -X- _ O
constraint -X- _ O
- -X- _ O
based -X- _ O
al- -X- _ O
gorithm -X- _ O
is -X- _ O
the -X- _ O
PC -X- _ O
algorithm -X- _ O
( -X- _ O
Spirtes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
. -X- _ O
Starting -X- _ O
with -X- _ O
a -X- _ O
full -X- _ O
DAG -X- _ O
, -X- _ O
it -X- _ O
eliminates -X- _ O
an -X- _ O
edge -X- _ O
be- -X- _ O
tween -X- _ O
adjacent -X- _ O
vertices -X- _ O
iandjifXandXare -X- _ O
conditionally -X- _ O
independent -X- _ O
given -X- _ O
some -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
remaining -X- _ O
variables -X- _ O
. -X- _ O
This -X- _ O
process -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
conditional -X- _ O
independence -X- _ O
tests -X- _ O
, -X- _ O
is -X- _ O
conducted -X- _ O
iteratively -X- _ O
starting -X- _ O
from -X- _ O
a -X- _ O
conditioning -X- _ O
set -X- _ O
of -X- _ O
size -X- _ O
k= -X- _ O
0 -X- _ O
tok -X- _ O
= -X- _ O
jVj2 -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
global -X- _ O
Markov -X- _ O
and -X- _ O
faithfulness -X- _ O
assumptions -X- _ O
, -X- _ O
the -X- _ O
PC -X- _ O
algo- -X- _ O
rithm -X- _ O
also -X- _ O
assumes -X- _ O
causal -X- _ O
sufﬁciency -X- _ O
, -X- _ O
namely -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
unobserved -X- _ O
confounders -X- _ O
. -X- _ O
With -X- _ O
these -X- _ O
assumptions -X- _ O
satisﬁed -X- _ O
and -X- _ O
access -X- _ O
to -X- _ O
correct -X- _ O
condi- -X- _ O
tional -X- _ O
independence -X- _ O
relations -X- _ O
, -X- _ O
the -X- _ O
PC -X- _ O
algorithm -X- _ O
is -X- _ O
guaranteed -X- _ O
to -X- _ O
be -X- _ O
sound -X- _ O
, -X- _ O
complete -X- _ O
and -X- _ O
uniformly -X- _ O
consistent -X- _ O
( -X- _ O
Kalisch -X- _ O
and -X- _ O
Bühlmann -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
PC -X- _ O
- -X- _ O
stable -X- _ O
PC -X- _ O
- -X- _ O
stable -X- _ O
is -X- _ O
an -X- _ O
order -X- _ O
- -X- _ O
independent -X- _ O
ex- -X- _ O
tension -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
guarantees -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
( -X- _ O
Colombo -X- _ O
and -X- _ O
Maathuis -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
D.2 -X- _ O
Diagnostic -X- _ O
Plots -X- _ O
In -X- _ O
Figure -X- _ O
13 -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
density -X- _ O
and -X- _ O
Q -X- _ O
- -X- _ O
Q -X- _ O
plots -X- _ O
for -X- _ O
semantic -X- _ O
change -X- _ O
score -X- _ O
, -X- _ O
log -X- _ O
of -X- _ O
word -X- _ O
frequency -X- _ O
and -X- _ O
log -X- _ O
of -X- _ O
frequency -X- _ O
change -X- _ O
. -X- _ O
D.3 -X- _ O
Sensitivity -X- _ O
Analysis -X- _ O
on -X- _ O
Polysemy -X- _ O
Polysemy -X- _ O
is -X- _ O
a -X- _ O
discrete -X- _ O
variable -X- _ O
which -X- _ O
we -X- _ O
treat -X- _ O
as -X- _ O
an -X- _ O
ordered -X- _ O
factor -X- _ O
in -X- _ O
the -X- _ O
analysis -X- _ O
by -X- _ O
splitting -X- _ O
it -X- _ O
into -X- _ O
categories -X- _ O
. -X- _ O
Since -X- _ O
polysmey -X- _ O
can -X- _ O
be -X- _ O
plausibly -X- _ O
cat- -X- _ O
egorized -X- _ O
in -X- _ O
different -X- _ O
ways -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
9 -X- _ O
different -X- _ O
categorizations -X- _ O
of -X- _ O
it -X- _ O
and -X- _ O
examine -X- _ O
the -X- _ O
sta- -X- _ O
bility -X- _ O
of -X- _ O
the -X- _ O
resulting -X- _ O
graphs -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
categoriza- -X- _ O
tion -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
PC -X- _ O
- -X- _ O
stable -X- _ O
with -X- _ O
the -X- _ O
three -X- _ O
signiﬁcance -X- _ O
levels -X- _ O
2 -X- _ O
f0:05 -X- _ O
; -X- _ O
0:03 -X- _ O
; -X- _ O
0:01 -X- _ O
g. -X- _ O
In -X- _ O
Figure -X- _ O
14 -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
sensitivity -X- _ O
analysis -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
edges -X- _ O
between -X- _ O
word -X- _ O
type -X- _ O
and -X- _ O
polysemy -X- _ O
, -X- _ O
from -X- _ O
word -X- _ O
type -X- _ O
to -X- _ O
frequency -X- _ O
change -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
edge -X- _ O
from -X- _ O
polysemy -X- _ O
to -X- _ O
frequency -X- _ O
, -X- _ O
are -X- _ O
apparent -X- _ O
in -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
conﬁgurations -X- _ O
. -X- _ O
The -X- _ O
edge -X- _ O
from -X- _ O
word -X- _ O
type -X- _ O
to -X- _ O
semantic -X- _ O
change -X- _ O
is -X- _ O
apparent -X- _ O
in -X- _ O
21 -X- _ O
/ -X- _ O
27 -X- _ O
( -X- _ O
77.8 -X- _ O
% -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
conﬁgurations -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
a -X- _ O
few -X- _ O
edges -X- _ O
very -X- _ O
rarely -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
label -X- _ O
them -X- _ O
as -X- _ O
noise -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
take -X- _ O
them -X- _ O
into -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
causal -X- _ O
analy- -X- _ O
sis -X- _ O
. -X- _ O
These -X- _ O
consist -X- _ O
of -X- _ O
an -X- _ O
edge -X- _ O
from -X- _ O
the -X- _ O
POS -X- _ O
Noun -X- _ O
to -X- _ O
semantic -X- _ O
change -X- _ O
in -X- _ O
3 -X- _ O
/ -X- _ O
27 -X- _ O
( -X- _ O
11.1 -X- _ O
% -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
conﬁg- -X- _ O
urations -X- _ O
, -X- _ O
and -X- _ O
edges -X- _ O
from -X- _ O
polysemy -X- _ O
to -X- _ O
frequency -X- _ O
shift -X- _ O
and -X- _ O
from -X- _ O
polysemy -X- _ O
to -X- _ O
semantic -X- _ O
change -X- _ O
each -X- _ O
apparent -X- _ O
in -X- _ O
1 -X- _ O
/ -X- _ O
27 -X- _ O
( -X- _ O
3.7 -X- _ O
% -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
conﬁgurations -X- _ O
. -X- _ O
By -X- _ O
inferring -X- _ O
the -X- _ O
causal -X- _ O
graph -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
cate- -X- _ O
gorizations -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
up -X- _ O
for -X- _ O
the -X- _ O
possible -X- _ O
noise -X- _ O
in -X- _ O
the -X- _ O
polysemy -X- _ O
variable -X- _ O
and -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
graph -X- _ O
is -X- _ O
not -X- _ O
sensitive -X- _ O
to -X- _ O
small -X- _ O
variations -X- _ O
in -X- _ O
the -X- _ O
words -X- _ O
’ -X- _ O
polysemy -X- _ O
scores -X- _ O
. -X- _ O
D.4 -X- _ O
Causal -X- _ O
Inference -X- _ O
Given -X- _ O
the -X- _ O
causal -X- _ O
DAG -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
the -X- _ O
ex- -X- _ O
pression -X- _ O
for -X- _ O
the -X- _ O
average -X- _ O
causal -X- _ O
effect -X- _ O
of -X- _ O
word -X- _ O
type -X- _ O
on -X- _ O
semantic -X- _ O
change -X- _ O
. -X- _ O
Deﬁne -X- _ O
the -X- _ O
following -X- _ O
random -X- _ O
variables -X- _ O
: -X- _ O
T -X- _ O
= -X- _ O
word -X- _ O
type -X- _ O
, -X- _ O
X -X- _ O
= -X- _ O
polysemy -X- _ O
, -X- _ O
Y= -X- _ O
frequency -X- _ O
, -X- _ O
Z -X- _ O
= -X- _ O
frequency -X- _ O
shift -X- _ O
and -X- _ O
S -X- _ O
= -X- _ O
semantic -X- _ O
change -X- _ O
, -X- _ O
with -X- _ O
respective -X- _ O
probability -X- _ O
mass -X- _ O
functions -X- _ O
P -X- _ O
& -X- _ O
Pand -X- _ O
probability -X- _ O
density -X- _ O
functions -X- _ O
f -X- _ O
, -X- _ O
f -X- _ O
& -X- _ O
f. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
possible -X- _ O
values -X- _ O
for -X- _ O
Tlie -X- _ O
in1440fslang -X- _ O
; -X- _ O
nonslangg -X- _ O
. -X- _ O
By -X- _ O
the -X- _ O
truncated -X- _ O
factorization -X- _ O
for -X- _ O
the -X- _ O
connected -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
causal -X- _ O
DAG -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
excluding -X- _ O
POS -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
that -X- _ O
P -X- _ O
( -X- _ O
s -X- _ O
; -X- _ O
t -X- _ O
; -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
; -X- _ O
zjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
yjx -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
zjt -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
1 -X- _ O
Marginalizing -X- _ O
over -X- _ O
T -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
P -X- _ O
( -X- _ O
s -X- _ O
; -X- _ O
x -X- _ O
; -X- _ O
y -X- _ O
; -X- _ O
zjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
yjx -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
zjt -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
Next -X- _ O
, -X- _ O
marginalize -X- _ O
over -X- _ O
the -X- _ O
continuous -X- _ O
random -X- _ O
vari- -X- _ O
ablesYandZto -X- _ O
get -X- _ O
P -X- _ O
( -X- _ O
s -X- _ O
; -X- _ O
xjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
ZZf -X- _ O
( -X- _ O
yjx -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
zjt -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
dzdy -X- _ O
= -X- _ O
Zf -X- _ O
( -X- _ O
yjx -X- _ O
) -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
Zf -X- _ O
( -X- _ O
zjt -X- _ O
) -X- _ O
dz -X- _ O
| -X- _ O
{ -X- _ O
z -X- _ O
} -X- _ O
dy= -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
Zf -X- _ O
( -X- _ O
yjx -X- _ O
) -X- _ O
dy -X- _ O
| -X- _ O
{ -X- _ O
z -X- _ O
} -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
Finally -X- _ O
P -X- _ O
( -X- _ O
sjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
Xf -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
xjt -X- _ O
) -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
sjt -X- _ O
) -X- _ O
Taking -X- _ O
the -X- _ O
expectation -X- _ O
, -X- _ O
we -X- _ O
get -X- _ O
E -X- _ O
[ -X- _ O
Sjdo -X- _ O
( -X- _ O
T -X- _ O
= -X- _ O
t -X- _ O
) -X- _ O
] -X- _ O
= -X- _ O
E -X- _ O
[ -X- _ O
Sjt -X- _ O
] -X- _ O
E -X- _ O
Appendix -X- _ O
– -X- _ O
Selected -X- _ O
Words -X- _ O
In -X- _ O
Appendix -X- _ O
E -X- _ O
we -X- _ O
list -X- _ O
all -X- _ O
the -X- _ O
slang -X- _ O
and -X- _ O
nonslang -X- _ O
words -X- _ O
used -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
. -X- _ O
Slang -X- _ O
Nonslang -X- _ O
Hybrid -X- _ O
a -X- _ O
- -X- _ O
list -X- _ O
admitting -X- _ O
annihilated -X- _ O
badass -X- _ O
adulterous -X- _ O
balling -X- _ O
blankie -X- _ O
agenda -X- _ O
bastard -X- _ O
bling -X- _ O
allotted -X- _ O
beef -X- _ O
blowjob -X- _ O
anticlockwise -X- _ O
bloody -X- _ O
blumpkin -X- _ O
avoiders -X- _ O
bomb -X- _ O
bonehead -X- _ O
awesome -X- _ O
book -X- _ O
bro -X- _ O
banzai -X- _ O
bookmark -X- _ O
bromance -X- _ O
bright -X- _ O
booty -X- _ O
bumfuck -X- _ O
butane -X- _ O
bounce -X- _ O
bupkis -X- _ O
calorie -X- _ O
bowl -X- _ O
chillax -X- _ O
chug -X- _ O
brains -X- _ O
chones -X- _ O
committeeman -X- _ O
candle -X- _ O
colitas -X- _ O
competencies -X- _ O
chicken -X- _ O
compo -X- _ O
contenders -X- _ O
classic -X- _ O
conniption -X- _ O
conventionally -X- _ O
crock -X- _ O
crappy -X- _ O
copyediting -X- _ O
decompress -X- _ O
dang -X- _ O
deathblow -X- _ O
dim -X- _ O
dis -X- _ O
decomposition -X- _ O
dirt -X- _ O
dogg -X- _ O
despoil -X- _ O
dose -X- _ O
duckface -X- _ O
didot -X- _ O
down -X- _ O
dudette -X- _ O
doubleheader -X- _ O
egg -X- _ O
fanboy -X- _ O
echo -X- _ O
eye -X- _ O
fap -X- _ O
enhancements -X- _ O
fat -X- _ O
gangsta -X- _ O
epilator -X- _ O
fence -X- _ O
glitterati -X- _ O
estimated -X- _ O
ﬁre -X- _ O
gorp -X- _ O
ﬁddled -X- _ O
ﬂuffer -X- _ O
gotsta -X- _ O
galavant -X- _ O
foxy -X- _ O
gunt -X- _ O
glutton -X- _ O
freckle -X- _ O
hasbian -X- _ O
greeting -X- _ O
fruitcake -X- _ O
horribad -X- _ O
grisly -X- _ O
gag -X- _ O
jabroni -X- _ O
groans -X- _ O
ghost -X- _ O
jalopy -X- _ O
haircut -X- _ O
gig -X- _ O
jerkwad -X- _ O
heaviest -X- _ O
gnarly -X- _ O
lame -X- _ O
- -X- _ O
o -X- _ O
humblest -X- _ O
god -X- _ O
lem -X- _ O
me -X- _ O
ignites -X- _ O
gridlock -X- _ O
lowkey -X- _ O
inclusive -X- _ O
grip -X- _ O
mcdreamy -X- _ O
intimidator -X- _ O
grub -X- _ O
meme -X- _ O
jugglers -X- _ O
gumby -X- _ O
mosey -X- _ O
jute -X- _ O
hanger -X- _ O
motherfucking -X- _ O
lawlessness -X- _ O
head -X- _ O
mozzie -X- _ O
legalist -X- _ O
hell -X- _ O
netizen -X- _ O
milepost -X- _ O
hitter -X- _ O
nuker -X- _ O
mistreatment -X- _ O
item -X- _ O
pedo -X- _ O
moldovan -X- _ O
jammed -X- _ O
peeps -X- _ O
morphology -X- _ O
jill -X- _ O
plastered -X- _ O
mushroom -X- _ O
jock -X- _ O
poopy -X- _ O
nonskid -X- _ O
kick -X- _ O
preemie -X- _ O
outlawing -X- _ O
kosher -X- _ O
pregos -X- _ O
pantsuit -X- _ O
locks -X- _ O
prettyful -X- _ O
peppy -X- _ O
mad -X- _ O
rapey -X- _ O
performative -X- _ O
mine1441Slang -X- _ O
Nonslang -X- _ O
Hybrid -X- _ O
rehab -X- _ O
postural -X- _ O
money -X- _ O
relly -X- _ O
protocol -X- _ O
move -X- _ O
rooﬁe -X- _ O
repentant -X- _ O
mule -X- _ O
roshambo -X- _ O
rump -X- _ O
pecker -X- _ O
sesh -X- _ O
sabertooth -X- _ O
peckish -X- _ O
shart -X- _ O
sailor -X- _ O
peeper -X- _ O
shiesty -X- _ O
scallywag -X- _ O
pig -X- _ O
shtick -X- _ O
scheme -X- _ O
pinch -X- _ O
sicc -X- _ O
sculptured -X- _ O
plums -X- _ O
sinse -X- _ O
scummiest -X- _ O
postal -X- _ O
skeevy -X- _ O
shield -X- _ O
rad -X- _ O
skyrocket -X- _ O
shylock -X- _ O
ratchet -X- _ O
slore -X- _ O
snug -X- _ O
roadkill -X- _ O
snitch -X- _ O
squall -X- _ O
sausage -X- _ O
soused -X- _ O
steeple -X- _ O
scissor -X- _ O
spam -X- _ O
strap -X- _ O
scoot -X- _ O
spec -X- _ O
superabundance -X- _ O
scream -X- _ O
spec -X- _ O
- -X- _ O
ops -X- _ O
sympathizer -X- _ O
screaming -X- _ O
sucky -X- _ O
telogen -X- _ O
smoked -X- _ O
tenner -X- _ O
terriﬁes -X- _ O
sneak -X- _ O
thingamabob -X- _ O
they -X- _ O
split -X- _ O
trisexual -X- _ O
trampolining -X- _ O
squawk -X- _ O
tweeker -X- _ O
underpainting -X- _ O
stat -X- _ O
twit -X- _ O
underrated -X- _ O
stew -X- _ O
whadja -X- _ O
unicorn -X- _ O
streak -X- _ O
workaround -X- _ O
unlike -X- _ O
styling -X- _ O
wut -X- _ O
unmatched -X- _ O
swap -X- _ O
zooted -X- _ O
upgrade -X- _ O
thick -X- _ O
vanadium -X- _ O
thirsty -X- _ O
threads -X- _ O
tool -X- _ O
toots -X- _ O
tweaker -X- _ O
walk -X- _ O
walkie -X- _ O
whippet -X- _ O
windy -X- _ O
wrecked -X- _ O
zombie -X- _ O
zounds1442 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
analyzes -X- _ SUMMARY
reference -X- _ SUMMARY
- -X- _ SUMMARY
free -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
for -X- _ SUMMARY
natural -X- _ SUMMARY
language -X- _ SUMMARY
generation -X- _ SUMMARY
( -X- _ SUMMARY
NLG -X- _ SUMMARY
) -X- _ SUMMARY
systems -X- _ SUMMARY
, -X- _ SUMMARY
specifically -X- _ SUMMARY
for -X- _ SUMMARY
text -X- _ SUMMARY
summarization -X- _ SUMMARY
and -X- _ SUMMARY
dialog -X- _ SUMMARY
generation -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
find -X- _ SUMMARY
that -X- _ SUMMARY
these -X- _ SUMMARY
metrics -X- _ SUMMARY
may -X- _ SUMMARY
rely -X- _ SUMMARY
on -X- _ SUMMARY
spurious -X- _ SUMMARY
correlations -X- _ SUMMARY
with -X- _ SUMMARY
measures -X- _ SUMMARY
like -X- _ SUMMARY
word -X- _ SUMMARY
overlap -X- _ SUMMARY
and -X- _ SUMMARY
length -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
demonstrate -X- _ SUMMARY
that -X- _ SUMMARY
these -X- _ SUMMARY
errors -X- _ SUMMARY
can -X- _ SUMMARY
be -X- _ SUMMARY
mitigated -X- _ SUMMARY
by -X- _ SUMMARY
explicitly -X- _ SUMMARY
designing -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
to -X- _ SUMMARY
avoid -X- _ SUMMARY
spurious -X- _ SUMMARY
features -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
evaluate -X- _ SUMMARY
recently -X- _ SUMMARY
proposed -X- _ SUMMARY
metrics -X- _ SUMMARY
, -X- _ SUMMARY
such -X- _ SUMMARY
as -X- _ SUMMARY
FactCC -X- _ SUMMARY
and -X- _ SUMMARY
DAE -X- _ SUMMARY
, -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
tasks -X- _ SUMMARY
of -X- _ SUMMARY
text -X- _ SUMMARY
summarization -X- _ SUMMARY
and -X- _ SUMMARY
dialog -X- _ SUMMARY
generation -X- _ SUMMARY
, -X- _ SUMMARY
comparing -X- _ SUMMARY
them -X- _ SUMMARY
to -X- _ SUMMARY
spurious -X- _ SUMMARY
correlates -X- _ SUMMARY
like -X- _ SUMMARY
word -X- _ SUMMARY
overlap -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
also -X- _ SUMMARY
propose -X- _ SUMMARY
an -X- _ SUMMARY
adversarially -X- _ SUMMARY
trained -X- _ SUMMARY
metric -X- _ SUMMARY
that -X- _ SUMMARY
achieves -X- _ SUMMARY
improved -X- _ SUMMARY
performance -X- _ SUMMARY
in -X- _ SUMMARY
ranking -X- _ SUMMARY
abstractive -X- _ SUMMARY
and -X- _ SUMMARY
faithful -X- _ SUMMARY
systems -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
emphasizes -X- _ SUMMARY
the -X- _ SUMMARY
importance -X- _ SUMMARY
of -X- _ SUMMARY
analyzing -X- _ SUMMARY
these -X- _ SUMMARY
metrics -X- _ SUMMARY
across -X- _ SUMMARY
different -X- _ SUMMARY
distributions -X- _ SUMMARY
of -X- _ SUMMARY
systems -X- _ SUMMARY
and -X- _ SUMMARY
suggests -X- _ SUMMARY
future -X- _ SUMMARY
work -X- _ SUMMARY
to -X- _ SUMMARY
ensure -X- _ SUMMARY
robustness -X- _ SUMMARY
and -X- _ SUMMARY
better -X- _ SUMMARY
understanding -X- _ SUMMARY
of -X- _ SUMMARY
the -X- _ SUMMARY
metrics -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
dataset -X- _ SUMMARY
used -X- _ SUMMARY
for -X- _ SUMMARY
evaluation -X- _ SUMMARY
includes -X- _ SUMMARY
datasets -X- _ SUMMARY
like -X- _ SUMMARY
CNN -X- _ SUMMARY
/ -X- _ SUMMARY
DM -X- _ SUMMARY
, -X- _ SUMMARY
PersonaChat -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
DailyDialog -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.102.txt -X- _ O
Esin -X- _ O
DurmusFaisal -X- _ O
LadhakTatsunori -X- _ O
HashimotoStanford -X- _ O
UniversityColumbia -X- _ O
University -X- _ O
esindurmus -X- _ O
@ -X- _ O
cs.stanford.edu -X- _ O
faisal -X- _ O
@ -X- _ O
cs.columbia.edu -X- _ O
thashim -X- _ O
@ -X- _ O
stanford.edu -X- _ O
Abstract -X- _ O
Model -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
as -X- _ O
a -X- _ O
fast -X- _ O
and -X- _ O
cost -X- _ O
- -X- _ O
effective -X- _ O
approach -X- _ O
to -X- _ O
evaluate -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Genera- -X- _ I-TaskName
tion -X- _ I-TaskName
( -X- _ O
NLG -X- _ B-TaskName
) -X- _ O
systems -X- _ O
. -X- _ O
Despite -X- _ O
promising -X- _ O
recent -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
evidence -X- _ O
that -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
summarization -X- _ B-TaskName
and -X- _ O
di- -X- _ B-TaskName
alog -X- _ I-TaskName
generation -X- _ I-TaskName
may -X- _ O
be -X- _ O
relying -X- _ O
on -X- _ O
spurious -X- _ O
correlations -X- _ O
with -X- _ O
measures -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
over- -X- _ O
lap -X- _ O
, -X- _ O
perplexity -X- _ B-MetricName
, -X- _ O
and -X- _ O
length -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
observe -X- _ O
that -X- _ O
for -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
, -X- _ O
these -X- _ O
metrics -X- _ O
have -X- _ O
high -X- _ O
error -X- _ O
rates -X- _ O
when -X- _ O
ranking -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
systems -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
that -X- _ O
these -X- _ O
errors -X- _ O
can -X- _ O
be -X- _ O
mitigated -X- _ O
by -X- _ O
explicitly -X- _ O
designing -X- _ O
evaluation -X- _ O
metrics -X- _ O
to -X- _ O
avoid -X- _ O
spurious -X- _ O
features -X- _ O
in -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evalu- -X- _ O
ation -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Building -X- _ O
reliable -X- _ O
automated -X- _ O
evaluation -X- _ O
metrics -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
factor -X- _ O
for -X- _ O
quick -X- _ O
development -X- _ O
of -X- _ O
better -X- _ O
NLG -X- _ B-TaskName
systems -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
has -X- _ O
proposed -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
judge -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
generated -X- _ O
outputs -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
human -X- _ O
ref- -X- _ O
erences -X- _ O
( -X- _ O
Celikyilmaz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Many -X- _ O
of -X- _ O
these -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluations -X- _ O
achieve -X- _ O
remarkably -X- _ O
high -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
evaluations -X- _ O
, -X- _ O
raising -X- _ O
hopes -X- _ O
that -X- _ O
they -X- _ O
may -X- _ O
soon -X- _ O
become -X- _ O
a -X- _ O
viable -X- _ O
alternative -X- _ O
to -X- _ O
expensive -X- _ O
human -X- _ O
evaluations -X- _ O
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sinha -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Phy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
simply -X- _ O
looking -X- _ O
at -X- _ O
correlation -X- _ O
with -X- _ O
hu- -X- _ O
man -X- _ O
scores -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
sufficient -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
efficacy -X- _ O
and -X- _ O
robustness -X- _ O
of -X- _ O
an -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
recently -X- _ O
proposed -X- _ O
reference- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
text -X- _ B-TaskName
summarization -X- _ I-TaskName
and -X- _ O
dialog -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
achieve -X- _ O
similar -X- _ O
levels -X- _ O
of -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgment -X- _ O
, -X- _ O
using -X- _ O
simple -X- _ O
spurious -X- _ O
correlates -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
overlap -X- _ O
, -X- _ O
length -X- _ O
, -X- _ O
and -X- _ O
perplexity -X- _ B-MetricName
. -X- _ O
Further- -X- _ O
more -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
learned -X- _ O
metrics -X- _ O
have -X- _ O
a -X- _ O
rela -X- _ O
- -X- _ O
tively -X- _ O
high -X- _ O
correlation -X- _ O
with -X- _ O
the -X- _ O
spurious -X- _ O
correlates -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
human -X- _ O
scores -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
these -X- _ O
metrics -X- _ O
may -X- _ O
rely -X- _ O
heavily -X- _ O
on -X- _ O
spurious -X- _ O
correla- -X- _ O
tions -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
potential -X- _ O
explanation -X- _ O
for -X- _ O
the -X- _ O
robustness -X- _ O
issues -X- _ O
that -X- _ O
are -X- _ O
observed -X- _ O
in -X- _ O
recent -X- _ O
work -X- _ O
, -X- _ O
despite -X- _ O
the -X- _ O
seemingly -X- _ O
high -X- _ O
reported -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
judgements -X- _ O
( -X- _ O
Gabriel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Yeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
analyze -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
faithfulness -X- _ B-MetricName
evaluation -X- _ O
metrics -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
reliance -X- _ O
on -X- _ O
spurious -X- _ O
correlations -X- _ O
leads -X- _ O
to -X- _ O
errors -X- _ O
in -X- _ O
model -X- _ O
se- -X- _ O
lection -X- _ O
and -X- _ O
development -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
word -X- _ O
overlap -X- _ O
, -X- _ O
a -X- _ O
spurious -X- _ O
correlate -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
does -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
recently -X- _ O
proposed -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
at -X- _ O
system -X- _ O
- -X- _ O
level -X- _ O
ranking -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
rankings -X- _ O
amongst -X- _ O
systems -X- _ O
that -X- _ O
are -X- _ O
relatively -X- _ O
abstractive -X- _ O
and -X- _ O
faithful -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
these -X- _ O
learned -X- _ O
metrics -X- _ O
perform -X- _ O
significantly -X- _ O
worse -X- _ O
for -X- _ O
these -X- _ O
systems -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
word -X- _ O
- -X- _ O
overlap -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
good -X- _ O
measure -X- _ O
for -X- _ O
ranking -X- _ O
these -X- _ O
systems -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
their -X- _ O
faithfulness -X- _ O
since -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
systems -X- _ O
have -X- _ O
similarly -X- _ O
low -X- _ O
word -X- _ O
overlap -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
we -X- _ O
need -X- _ O
metrics -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
overly -X- _ O
reliant -X- _ O
on -X- _ O
word -X- _ O
overlap -X- _ O
in -X- _ O
their -X- _ O
faithfulness -X- _ B-MetricName
prediction -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
whether -X- _ O
a -X- _ O
simple -X- _ O
mitigation -X- _ O
strategy -X- _ O
of -X- _ O
adversarially -X- _ O
training -X- _ O
a -X- _ O
faithfulness -X- _ B-MetricName
eval- -X- _ O
uation -X- _ O
metric -X- _ O
to -X- _ O
avoid -X- _ O
spurious -X- _ O
correlates -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
more -X- _ O
robust -X- _ O
metric -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
our -X- _ O
adversari- -X- _ O
ally -X- _ O
trained -X- _ O
metric -X- _ O
performs -X- _ O
well -X- _ O
at -X- _ O
overall -X- _ O
pairwise -X- _ O
ranking -X- _ O
while -X- _ O
having -X- _ O
a -X- _ O
significantly -X- _ O
lower -X- _ O
corre- -X- _ O
lation -X- _ O
with -X- _ O
the -X- _ O
spurious -X- _ O
correlate -X- _ O
of -X- _ O
word -X- _ O
- -X- _ O
overlap -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
metric -X- _ O
has -X- _ O
improved -X- _ O
performance -X- _ O
in -X- _ O
ranking -X- _ O
between -X- _ O
abstrac- -X- _ O
tive -X- _ O
and -X- _ O
faithful -X- _ O
systems -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
failure -X- _ O
mode -X- _ O
for -X- _ O
existing -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
faithfulness -X- _ B-MetricName
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
2 -X- _ O
Reference -X- _ O
- -X- _ O
free -X- _ O
Evaluation -X- _ O
of -X- _ O
Text -X- _ O
Generation -X- _ O
We -X- _ O
begin -X- _ O
by -X- _ O
defining -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
eval- -X- _ O
uation -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
andsystems-1443level -X- _ O
evaluation -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metric -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
F -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
that -X- _ O
can -X- _ O
assign -X- _ O
a -X- _ O
quality -X- _ B-MetricName
score -X- _ I-MetricName
to -X- _ O
an -X- _ O
output -X- _ O
sequence -X- _ O
yfor -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
sequence -X- _ O
x. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metric -X- _ O
F -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
to -X- _ O
assign -X- _ O
high -X- _ O
scores -X- _ O
to -X- _ O
desirable -X- _ O
out- -X- _ O
putsyfor -X- _ O
some -X- _ O
attribute -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
faithfulness -X- _ B-MetricName
of -X- _ O
a -X- _ O
summary -X- _ O
. -X- _ O
Measuring -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
this -X- _ O
met- -X- _ O
ric -X- _ O
is -X- _ O
challenging -X- _ O
, -X- _ O
and -X- _ O
prior -X- _ O
work -X- _ O
has -X- _ O
relied -X- _ O
upon -X- _ O
correlation -X- _ O
to -X- _ O
human -X- _ O
judgments -X- _ O
H -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
Example -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
: -X- _ O
A -X- _ O
number -X- _ O
of -X- _ O
exist- -X- _ O
ing -X- _ O
reference -X- _ O
free -X- _ O
evaluations -X- _ O
rely -X- _ O
upon -X- _ O
a -X- _ O
procedure -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
human -X- _ O
correlations -X- _ O
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Phy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sinha -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
a -X- _ O
met- -X- _ O
ric -X- _ O
by -X- _ O
computing -X- _ O
a -X- _ O
Pearson -X- _ O
or -X- _ O
Spearman -X- _ O
correla- -X- _ O
tioncorr -X- _ O
( -X- _ O
H -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
F -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
) -X- _ O
over -X- _ O
some -X- _ O
sampled -X- _ O
evaluation -X- _ O
data -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
System -X- _ O
- -X- _ O
level -X- _ O
evaluation -X- _ O
: -X- _ O
An -X- _ O
alternative -X- _ O
ap- -X- _ O
proach -X- _ O
to -X- _ O
evaluation -X- _ O
is -X- _ O
systems -X- _ O
- -X- _ O
level -X- _ O
rankings -X- _ O
( -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kocmi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
define -X- _ O
as -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
identify -X- _ O
which -X- _ O
model -X- _ O
is -X- _ O
better -X- _ O
amongst -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
models -X- _ O
M.Fis -X- _ O
evaluated -X- _ O
via -X- _ O
its -X- _ O
accuracy -X- _ O
in -X- _ O
matching -X- _ O
human -X- _ O
evaluation -X- _ O
H -X- _ O
on -X- _ O
all -X- _ O
pairs -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
m -X- _ O
) -X- _ O
∈M×Mwhere -X- _ O
m̸=m -X- _ O
. -X- _ O
The -X- _ O
definitions -X- _ O
of -X- _ O
example -X- _ O
and -X- _ O
system -X- _ O
level -X- _ O
cor- -X- _ O
relations -X- _ O
suggest -X- _ O
that -X- _ O
evaluations -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
may -X- _ O
have -X- _ O
a -X- _ O
strong -X- _ O
dependence -X- _ O
on -X- _ O
the -X- _ O
example -X- _ O
and -X- _ O
systems -X- _ O
distributions -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
andM. -X- _ O
As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
consider -X- _ O
an -X- _ O
evaluation -X- _ O
for -X- _ O
dialogue -X- _ O
re- -X- _ O
sponse -X- _ O
quality -X- _ O
. -X- _ O
Building -X- _ O
a -X- _ O
truly -X- _ O
accurate -X- _ O
predictor -X- _ O
for -X- _ O
dialogue -X- _ O
response -X- _ O
quality -X- _ O
is -X- _ O
challenging -X- _ O
, -X- _ O
but -X- _ O
if -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
consists -X- _ O
of -X- _ O
all -X- _ O
either -X- _ O
professionally -X- _ O
writ- -X- _ O
ten -X- _ O
examples -X- _ O
or -X- _ O
ungrammatical -X- _ O
nonsense -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
grammar -X- _ O
checker -X- _ O
would -X- _ O
perform -X- _ O
exceedingly -X- _ O
well -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
an -X- _ O
instance -X- _ O
of -X- _ O
what -X- _ O
is -X- _ O
called -X- _ O
a -X- _ O
spuri- -X- _ O
ous -X- _ O
correlate -X- _ O
. -X- _ O
More -X- _ O
formally -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
this -X- _ O
as -X- _ O
some -X- _ O
attribute -X- _ O
S -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
correlated -X- _ O
with -X- _ O
H -X- _ O
inp -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
correlated -X- _ O
with -X- _ O
Hfor -X- _ O
a -X- _ O
care- -X- _ O
fully -X- _ O
constructed -X- _ O
test -X- _ O
distribution -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
say -X- _ O
that -X- _ O
Fisspuriously -X- _ O
correlated -X- _ O
withSif -X- _ O
: -X- _ O
1.Fand -X- _ O
Hare -X- _ O
highly -X- _ O
correlated -X- _ O
under -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
but -X- _ O
not -X- _ O
under -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
2.Fremains -X- _ O
correlated -X- _ O
with -X- _ O
Sunder -X- _ O
p -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
Example -X- _ O
- -X- _ O
level -X- _ O
Analysis -X- _ O
of -X- _ O
Learned -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
Spearman -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
judgements -X- _ O
for -X- _ O
reference- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
forsummarization -X- _ O
and -X- _ O
dialog -X- _ O
generation -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
metrics -X- _ O
to -X- _ O
spurious -X- _ O
correlates -X- _ O
such -X- _ O
as -X- _ O
word- -X- _ O
overlap -X- _ O
, -X- _ O
length -X- _ O
and -X- _ O
perplexity -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
under- -X- _ O
stand -X- _ O
whether -X- _ O
the -X- _ O
metrics -X- _ O
can -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
these -X- _ O
simple -X- _ O
measures -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
measure -X- _ O
to -X- _ O
what -X- _ O
ex- -X- _ O
tent -X- _ O
the -X- _ O
proposed -X- _ O
metrics -X- _ O
are -X- _ O
correlated -X- _ O
with -X- _ O
these -X- _ O
spurious -X- _ O
measures -X- _ O
. -X- _ O
3.1 -X- _ O
Faithfulness -X- _ B-MetricName
Evaluation -X- _ O
in -X- _ O
Text -X- _ B-TaskName
Summarization -X- _ I-TaskName
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
text -X- _ O
summarization -X- _ O
models -X- _ O
are -X- _ O
ca- -X- _ O
pable -X- _ O
of -X- _ O
producing -X- _ O
fluent -X- _ O
summaries -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
suffer -X- _ O
from -X- _ O
generating -X- _ O
information -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
consistent -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
unfaithful -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
showed -X- _ O
that -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
are -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
such -X- _ O
consistency -X- _ O
errors -X- _ O
( -X- _ O
Falke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
motivated -X- _ O
researchers -X- _ O
to -X- _ O
build -X- _ O
evaluation -X- _ O
met- -X- _ O
rics -X- _ O
to -X- _ O
capture -X- _ O
these -X- _ O
faithfulness -X- _ O
issues -X- _ O
since -X- _ O
col- -X- _ O
lecting -X- _ O
human -X- _ O
evaluations -X- _ O
for -X- _ O
faithfulness -X- _ O
is -X- _ O
ex- -X- _ O
pensive -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Durmus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
recently -X- _ O
proposed -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
faithfulness -X- _ B-MetricName
evaluation -X- _ O
metrics -X- _ O
and -X- _ O
compare -X- _ O
their -X- _ O
performance -X- _ O
against -X- _ O
the -X- _ O
spurious -X- _ B-MetricName
cor- -X- _ I-MetricName
relate -X- _ I-MetricName
of -X- _ I-MetricName
word -X- _ I-MetricName
overlap -X- _ I-MetricName
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
learned -X- _ O
metrics -X- _ O
and -X- _ O
word -X- _ O
overlap -X- _ O
to -X- _ O
understand -X- _ O
to -X- _ O
what -X- _ O
extent -X- _ O
these -X- _ O
metrics -X- _ O
rely -X- _ O
on -X- _ O
spurious -X- _ O
correlations -X- _ O
. -X- _ O
We -X- _ O
focus -X- _ O
on -X- _ O
learned -X- _ O
entailment -X- _ B-MetricName
- -X- _ I-MetricName
based -X- _ I-MetricName
faithfulness -X- _ I-MetricName
evaluation -X- _ I-MetricName
metrics -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
high -X- _ O
performance -X- _ O
in -X- _ O
identifying -X- _ O
faithfulness -X- _ O
issues -X- _ O
( -X- _ O
Pagnoni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
partic- -X- _ O
ular -X- _ O
we -X- _ O
evaluate -X- _ O
FactCC -X- _ B-MethodName
( -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
DAE -X- _ B-MethodName
( -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
achieve -X- _ O
higher -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
corre- -X- _ O
lations -X- _ O
with -X- _ O
human -X- _ O
judgements -X- _ O
than -X- _ O
existing -X- _ O
faith- -X- _ B-MetricName
fulness -X- _ I-MetricName
evaluation -X- _ I-MetricName
metrics -X- _ I-MetricName
( -X- _ O
Pagnoni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
FactCC -X- _ B-MethodName
. -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
an -X- _ O
entailment -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
where -X- _ O
they -X- _ O
train -X- _ O
a -X- _ O
BERT- -X- _ B-MethodName
based -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
or -X- _ O
not -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
entails -X- _ O
a -X- _ O
summary -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
, -X- _ O
they -X- _ O
generate -X- _ O
synthetic -X- _ O
training -X- _ O
data -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
transformations -X- _ O
to -X- _ O
source -X- _ O
article -X- _ O
sentences -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
get -X- _ O
article -X- _ O
, -X- _ O
summary -X- _ O
pairs -X- _ O
. -X- _ O
They -X- _ O
evaluate -X- _ O
their -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
report -X- _ O
a -X- _ O
high -X- _ O
accuracy -X- _ O
on -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
comparisons -X- _ O
on -X- _ O
a -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
DAE -X- _ B-MethodName
. -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
collected -X- _ O
human -X- _ O
annotations -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
arc -X- _ O
- -X- _ O
level -X- _ O
to -X- _ O
study -X- _ O
faithfulness -X- _ O
at -X- _ O
a -X- _ O
finer -X- _ O
granularity -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
trained1444 -X- _ O
Metric -X- _ O
Human -X- _ O
Density -X- _ O
FactCC -X- _ B-MethodName
0.36 -X- _ O
0.59 -X- _ O
DAE -X- _ B-MethodName
0.38 -X- _ O
0.76 -X- _ O
a -X- _ O
dependency -X- _ O
arc -X- _ O
entailment -X- _ O
model -X- _ O
for -X- _ O
faithfulness -X- _ B-TaskName
detection -X- _ I-TaskName
( -X- _ O
Goyal -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
test -X- _ O
set -X- _ O
as -X- _ O
Kryscinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
report -X- _ O
improved -X- _ O
results -X- _ O
over -X- _ O
FactCC -X- _ B-MethodName
. -X- _ O
We -X- _ O
look -X- _ O
at -X- _ O
how -X- _ O
these -X- _ O
learned -X- _ O
, -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
met- -X- _ O
rics -X- _ O
compare -X- _ O
with -X- _ O
word -X- _ O
overlap -X- _ O
– -X- _ O
a -X- _ O
simple -X- _ O
spurious -X- _ O
correlate -X- _ O
. -X- _ O
One -X- _ O
simple -X- _ O
measure -X- _ O
of -X- _ O
whether -X- _ O
a -X- _ O
gener- -X- _ O
ated -X- _ O
summary -X- _ O
is -X- _ O
faithful -X- _ O
is -X- _ O
to -X- _ O
look -X- _ O
at -X- _ O
its -X- _ O
word -X- _ O
over- -X- _ O
lap -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
; -X- _ O
summaries -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
word -X- _ O
overlap -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
faithful -X- _ O
( -X- _ O
Ladhak -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
measure -X- _ O
of -X- _ O
faithfulness -X- _ B-MetricName
is -X- _ O
spurious -X- _ O
because -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
distinguish -X- _ O
between -X- _ O
faithful -X- _ O
and -X- _ O
unfaithful -X- _ O
summaries -X- _ O
that -X- _ O
have -X- _ O
similar -X- _ O
word -X- _ O
overlap -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
two -X- _ O
metrics -X- _ O
of -X- _ O
word -X- _ O
- -X- _ O
overlap -X- _ O
following -X- _ O
Grusky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
: -X- _ O
coverage -X- _ O
anddensity -X- _ O
.Coverage -X- _ O
measures -X- _ O
the -X- _ O
per- -X- _ O
centage -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
that -X- _ O
are -X- _ O
also -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
Density -X- _ O
instead -X- _ O
looks -X- _ O
at -X- _ O
the -X- _ O
average -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
segments -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
that -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
Results -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
faithfulness -X- _ B-MetricName
hu- -X- _ O
man -X- _ O
annotations -X- _ O
collected -X- _ O
by -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
for16summarization -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
analysis -X- _ O
. -X- _ O
Fig- -X- _ O
ure -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
factuality -X- _ O
metrics -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
spurious -X- _ O
correlates -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
den -X- _ O
- -X- _ O
sityhas -X- _ O
a -X- _ O
similar -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
as -X- _ O
DAE -X- _ B-MethodName
, -X- _ O
and -X- _ O
is -X- _ O
significanltybetter -X- _ O
than -X- _ O
FactCC -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
is -X- _ O
alarming -X- _ O
because -X- _ O
density -X- _ O
is -X- _ O
a -X- _ O
spurious -X- _ O
correlate -X- _ O
, -X- _ O
yet -X- _ O
it -X- _ O
can -X- _ O
achieve -X- _ O
similar -X- _ O
performance -X- _ O
as -X- _ O
the -X- _ O
metrics -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
trained -X- _ O
for -X- _ O
faithfulness -X- _ O
evaluation -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
see -X- _ O
that -X- _ O
both -X- _ O
FactCC -X- _ B-MethodName
and -X- _ O
DAE -X- _ B-MethodName
have -X- _ O
a -X- _ O
significantly -X- _ O
higher -X- _ O
correlation -X- _ O
with -X- _ O
density -X- _ O
than -X- _ O
they -X- _ O
do -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
these -X- _ O
metrics -X- _ O
may -X- _ O
rely -X- _ O
upon -X- _ O
spurious -X- _ O
correlations -X- _ O
and -X- _ O
are -X- _ O
not -X- _ O
yet -X- _ O
capturing -X- _ O
a -X- _ O
deeper -X- _ O
understanding -X- _ O
of -X- _ O
faithfulness -X- _ O
. -X- _ O
3.2 -X- _ O
Learned -X- _ O
Metrics -X- _ O
for -X- _ O
Dialog -X- _ O
Generation -X- _ O
Dialog -X- _ O
generation -X- _ O
systems -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
gen- -X- _ O
erate -X- _ O
a -X- _ O
response -X- _ O
given -X- _ O
the -X- _ O
dialog -X- _ O
context -X- _ O
. -X- _ O
The -X- _ O
ability -X- _ O
to -X- _ O
automatically -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
response -X- _ O
is -X- _ O
essential -X- _ O
for -X- _ O
building -X- _ O
dialogue -X- _ O
systems -X- _ O
. -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
referenced -X- _ O
- -X- _ O
based -X- _ O
eval- -X- _ O
uation -X- _ O
metrics -X- _ O
do -X- _ O
not -X- _ O
correlate -X- _ O
well -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
of -X- _ O
response -X- _ O
quality -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
an -X- _ O
increased -X- _ O
interest -X- _ O
in -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
met- -X- _ O
rics -X- _ O
for -X- _ O
evaluating -X- _ O
dialogue -X- _ O
response -X- _ O
quality -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
our -X- _ O
analysis -X- _ O
in -X- _ O
§ -X- _ O
3.1 -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
look -X- _ O
at -X- _ O
recently -X- _ O
proposed -X- _ O
metrics -X- _ O
for -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
eval- -X- _ O
uation -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
spurious -X- _ O
correlates -X- _ O
for -X- _ O
dialog -X- _ O
response -X- _ O
quality -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
them -X- _ O
against -X- _ O
human -X- _ O
judgments -X- _ O
. -X- _ O
DialogRPT -X- _ B-MethodName
. -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
finetune -X- _ O
GPT-2 -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
human -X- _ O
feedback -X- _ O
( -X- _ O
replies -X- _ O
, -X- _ O
upvotes -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
in -X- _ O
Reddit -X- _ O
threads -X- _ O
and -X- _ O
com- -X- _ O
bine -X- _ O
these -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
composite -X- _ O
score -X- _ O
for -X- _ O
response -X- _ O
quality -X- _ O
. -X- _ O
They -X- _ O
evaluate -X- _ O
their -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
Reddit -X- _ O
data -X- _ O
that -X- _ O
they -X- _ O
collected -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
their -X- _ O
method -X- _ O
achieves -X- _ O
higher -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
agreement -X- _ O
with -X- _ O
hu- -X- _ O
man -X- _ O
judgments -X- _ O
than -X- _ O
baseline -X- _ O
metrics -X- _ O
. -X- _ O
MAUDE -X- _ B-MethodName
. -X- _ O
Sinha -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
encodes -X- _ O
each -X- _ O
utterance -X- _ O
in -X- _ O
the -X- _ O
dialog -X- _ O
context -X- _ O
using -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
and -X- _ O
leverages -X- _ O
the -X- _ O
temporal -X- _ O
transitions -X- _ O
between -X- _ O
them -X- _ O
to -X- _ O
score -X- _ O
a -X- _ O
response -X- _ O
. -X- _ O
They -X- _ O
add -X- _ O
noise -X- _ O
to -X- _ O
existing -X- _ O
dialog -X- _ O
re- -X- _ O
sponses -X- _ O
to -X- _ O
create -X- _ O
negative -X- _ O
examples -X- _ O
and -X- _ O
train -X- _ O
their -X- _ O
system -X- _ O
to -X- _ O
distinguish -X- _ O
them -X- _ O
from -X- _ O
valid -X- _ O
responses -X- _ O
using -X- _ O
noise -X- _ B-MethodName
contrastive -X- _ I-MethodName
estimation -X- _ I-MethodName
( -X- _ O
NCE -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
evaluate -X- _ O
their -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
PersonaChat -X- _ B-DatasetName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
dataset -X- _ O
and -X- _ O
report -X- _ O
improved -X- _ O
example- -X- _ O
level -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
with -X- _ O
human -X- _ O
judgments -X- _ O
compared -X- _ O
to -X- _ O
existing -X- _ O
baseline -X- _ O
metrics.1445 -X- _ O
Human -X- _ O
Perplexity -X- _ B-MetricName
Length -X- _ O
PPL+Len -X- _ B-MetricName
PersonaChatDialogRPT -X- _ B-DatasetName
-0.033 -X- _ B-MetricValue
-0.017 -X- _ B-MetricValue
0.086 -X- _ B-MetricValue
0.068 -X- _ B-MetricValue
Maude -X- _ B-MethodName
0.303 -X- _ B-MetricValue
0.373 -X- _ B-MetricValue
-0.089 -X- _ B-MetricValue
0.137 -X- _ B-MetricValue
USL -X- _ B-MethodName
- -X- _ O
H -X- _ O
0.496 -X- _ B-MetricValue
0.092 -X- _ B-MetricValue
0.506 -X- _ B-MetricValue
0.469 -X- _ B-MetricValue
TopicalChatDialogRPT -X- _ B-MethodName
0.117 -X- _ B-MetricValue
-0.011 -X- _ B-MetricValue
0.272 -X- _ B-MetricValue
0.276 -X- _ B-MetricValue
Maude -X- _ B-MethodName
0.135 -X- _ B-MetricValue
0.243 -X- _ B-MetricValue
-0.191 -X- _ B-MetricValue
-0.148 -X- _ B-MetricValue
USL -X- _ B-MethodName
- -X- _ O
H -X- _ O
0.318 -X- _ B-MetricValue
0.037 -X- _ B-MetricValue
0.359 -X- _ B-MetricValue
0.355 -X- _ B-MetricValue
DailyDialogDialogRPT -X- _ B-DatasetName
0.025 -X- _ B-MetricValue
-0.182 -X- _ B-MetricValue
0.359 -X- _ B-MetricValue
0.270 -X- _ B-MetricValue
Maude -X- _ B-MethodName
-0.074 -X- _ B-MetricValue
-0.076 -X- _ B-MetricValue
0.102 -X- _ B-MetricValue
0.033 -X- _ B-MetricValue
USL -X- _ B-MethodName
- -X- _ O
H -X- _ O
0.094 -X- _ B-MetricValue
0.048 -X- _ B-MetricValue
-0.208 -X- _ B-MetricValue
-0.236 -X- _ B-MetricValue
USL -X- _ B-MethodName
- -X- _ O
H. -X- _ O
Phy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
decompose -X- _ O
response -X- _ O
quality -X- _ O
into -X- _ O
three -X- _ O
aspects -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
score -X- _ O
a -X- _ O
response -X- _ O
along -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
aspects -X- _ O
. -X- _ O
They -X- _ O
then -X- _ O
combine -X- _ O
the -X- _ O
scores -X- _ O
hierarchically -X- _ O
into -X- _ O
one -X- _ O
compos- -X- _ O
ite -X- _ O
score -X- _ O
for -X- _ O
response -X- _ O
quality -X- _ O
. -X- _ O
They -X- _ O
evaluate -X- _ O
their -X- _ O
metric -X- _ O
on -X- _ O
the -X- _ O
DailyDialog -X- _ B-DatasetName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
dataset -X- _ O
and -X- _ O
report -X- _ O
significantly -X- _ O
higher -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
corre- -X- _ O
lations -X- _ O
than -X- _ O
previous -X- _ O
baseline -X- _ O
metrics -X- _ O
. -X- _ O
MNLI+Adv -X- _ O
. -X- _ O
Dziri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
introduce -X- _ O
an -X- _ O
entailment -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
that -X- _ O
evaluates -X- _ O
the -X- _ O
ground- -X- _ O
edness -X- _ O
of -X- _ O
a -X- _ O
dialog -X- _ O
response -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
whether -X- _ O
the -X- _ O
gener- -X- _ O
ated -X- _ O
response -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
provided -X- _ O
external -X- _ O
context -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
a -X- _ O
Wikipedia -X- _ O
article -X- _ O
. -X- _ O
They -X- _ O
trained -X- _ O
their -X- _ O
metric -X- _ O
on -X- _ O
automatically -X- _ O
generated -X- _ O
adversarial -X- _ O
data -X- _ O
by -X- _ O
applying -X- _ O
perturba- -X- _ O
tions -X- _ O
to -X- _ O
the -X- _ O
evidence -X- _ O
. -X- _ O
They -X- _ O
further -X- _ O
collect -X- _ O
human -X- _ O
annotations -X- _ O
for -X- _ O
the -X- _ O
various -X- _ O
aspects -X- _ O
of -X- _ O
dialog -X- _ O
gen- -X- _ O
eration -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
entailment -X- _ O
, -X- _ O
genericness -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
their -X- _ O
method -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
in -X- _ O
accu- -X- _ O
rately -X- _ O
categorizing -X- _ O
the -X- _ O
generations -X- _ O
than -X- _ O
existingentailment -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
assess -X- _ O
these -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
two -X- _ O
spurious -X- _ O
correlates -X- _ O
for -X- _ O
dialog -X- _ O
quality -X- _ O
– -X- _ O
perplexity -X- _ O
and -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
output -X- _ O
– -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
simple -X- _ O
com- -X- _ O
bination -X- _ O
of -X- _ O
two -X- _ O
measures -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
perplexity -X- _ O
using -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
GPT-2 -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
Rad- -X- _ O
ford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Perplexity -X- _ B-MetricName
( -X- _ O
PPL -X- _ O
) -X- _ O
and -X- _ O
length -X- _ O
are -X- _ O
spurious -X- _ O
correlates -X- _ O
since -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
dialog -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
have -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
and -X- _ O
low -X- _ O
- -X- _ O
quality -X- _ O
responses -X- _ O
with -X- _ O
similar -X- _ O
perplexities -X- _ O
/ -X- _ O
lengths -X- _ O
. -X- _ O
For -X- _ O
groundedness -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
word -X- _ O
overlap -X- _ O
measures -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
did -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
, -X- _ O
i.e. -X- _ O
, -X- _ O
density -X- _ B-MetricName
andcoverage -X- _ B-MetricName
, -X- _ O
and -X- _ O
we -X- _ O
measure -X- _ O
overlap -X- _ O
between -X- _ O
the -X- _ O
response -X- _ O
and -X- _ O
the -X- _ O
provided -X- _ O
external -X- _ O
evidence -X- _ O
. -X- _ O
Results -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
metricsfor -X- _ O
response -X- _ O
qual- -X- _ O
ity -X- _ O
estimation -X- _ O
on -X- _ O
three -X- _ O
popular -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
dialog -X- _ O
datasets -X- _ O
– -X- _ O
DailyDialog -X- _ B-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
dialogs1446about -X- _ O
everyday -X- _ O
topics -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
TopicalChat -X- _ B-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
dialogs -X- _ O
conditioned -X- _ O
on -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
8 -X- _ O
broad -X- _ O
topics -X- _ O
( -X- _ O
Gopalakrishnan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Per- -X- _ B-DatasetName
sonaChat -X- _ I-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
dialogs -X- _ O
conditioned -X- _ O
on -X- _ O
personas -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
metric -X- _ O
for -X- _ O
response -X- _ O
groundedness -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
human -X- _ O
annota- -X- _ O
tions -X- _ O
collected -X- _ O
by -X- _ O
Dziri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
on -X- _ O
Wizard -X- _ B-DatasetName
of -X- _ I-DatasetName
Wikipedia -X- _ I-DatasetName
( -X- _ O
Dinan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
dataset -X- _ O
that -X- _ O
consists -X- _ O
of -X- _ O
dialogues -X- _ O
conditioned -X- _ O
on -X- _ O
information -X- _ O
from -X- _ O
Wikipedia -X- _ O
articles -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
their -X- _ O
entailment -X- _ O
annotations -X- _ O
, -X- _ O
where -X- _ O
human -X- _ O
annotators -X- _ O
judge -X- _ O
whether -X- _ O
or -X- _ O
not -X- _ O
the -X- _ O
external -X- _ O
evidence -X- _ O
entails -X- _ O
a -X- _ O
generated -X- _ O
response -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
correlations -X- _ O
with -X- _ O
the -X- _ O
human -X- _ O
scores -X- _ O
and -X- _ O
the -X- _ O
spurious -X- _ O
correlates -X- _ O
for -X- _ O
the -X- _ O
dialog -X- _ O
generation -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
DialyDialog -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
perplexity -X- _ O
achieves -X- _ O
a -X- _ O
similar -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
as -X- _ O
USL -X- _ B-MethodName
- -X- _ O
H. -X- _ O
In -X- _ O
TopicalChat -X- _ B-DatasetName
, -X- _ O
perplexity -X- _ O
or -X- _ O
length -X- _ O
alone -X- _ O
does -X- _ O
not -X- _ O
beat -X- _ O
out -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
learned -X- _ O
metrics -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
combining -X- _ O
the -X- _ O
two -X- _ O
measures -X- _ O
achieves -X- _ O
a -X- _ O
significantly -X- _ O
better -X- _ O
correlation -X- _ O
with -X- _ O
humans -X- _ O
than -X- _ O
learned -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
PersonaChat -X- _ B-DatasetName
, -X- _ O
USL -X- _ B-MethodName
- -X- _ O
H -X- _ O
achieves -X- _ O
the -X- _ O
highest -X- _ O
correlation -X- _ O
with -X- _ O
hu- -X- _ O
man -X- _ O
judgment -X- _ O
, -X- _ O
though -X- _ O
the -X- _ O
combined -X- _ O
PPL+Len -X- _ B-MetricValue
score -X- _ I-MetricValue
is -X- _ O
close -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
USL -X- _ O
- -X- _ O
H -X- _ O
is -X- _ O
more -X- _ O
consistent -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
and -X- _ O
achieves -X- _ O
significantly -X- _ O
higher -X- _ O
correlations -X- _ O
with -X- _ O
hu- -X- _ O
man -X- _ O
scores -X- _ O
than -X- _ O
MAUDE -X- _ O
and -X- _ O
DialogRPT -X- _ O
for -X- _ O
Per- -X- _ O
sonaChat -X- _ O
and -X- _ O
TopicalChat -X- _ B-DatasetName
. -X- _ O
We -X- _ O
further -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
correlation -X- _ O
with -X- _ O
the -X- _ O
spurious -X- _ O
correlates -X- _ O
than -X- _ O
the -X- _ O
human -X- _ O
scores -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
again -X- _ O
suggests -X- _ O
that -X- _ O
these -X- _ O
learned -X- _ O
metrics -X- _ O
may -X- _ O
be -X- _ O
relying -X- _ O
upon -X- _ O
spurious -X- _ O
correlations -X- _ O
. -X- _ O
Metric -X- _ O
Human -X- _ B-MetricName
Coverage -X- _ I-MetricName
Density -X- _ B-MetricName
USL -X- _ B-MethodName
- -X- _ O
H -X- _ O
0.298 -X- _ B-MetricValue
0.467 -X- _ B-MetricValue
0.515 -X- _ B-MetricValue
MNLI+Adv -X- _ B-MethodName
0.373 -X- _ B-MetricValue
0.451 -X- _ B-MetricValue
0.514 -X- _ B-MetricValue
For -X- _ O
groundedness -X- _ B-MetricName
evaluation -X- _ O
, -X- _ O
both -X- _ O
coverage -X- _ B-MetricName
anddensity -X- _ B-MetricName
achieve -X- _ O
significantly -X- _ O
higher -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
than -X- _ O
MNLI+Ad -X- _ O
and -X- _ O
USL -X- _ O
- -X- _ O
H. -X- _ O
Furthermore -X- _ O
, -X- _ O
MNLI+Ad -X- _ O
and -X- _ O
USL -X- _ O
- -X- _ O
H -X- _ O
get -X- _ O
a -X- _ O
higher -X- _ O
correlation -X- _ O
with -X- _ O
these -X- _ O
spurious -X- _ O
correlates -X- _ O
than -X- _ O
hu- -X- _ O
man -X- _ O
scores -X- _ O
( -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
relatively -X- _ O
high -X- _ O
correlations -X- _ O
on -X- _ O
their -X- _ O
orig- -X- _ O
inal -X- _ O
datasets -X- _ O
, -X- _ O
these -X- _ O
metrics -X- _ O
seem -X- _ O
to -X- _ O
perform -X- _ O
sim- -X- _ O
ilarly -X- _ O
to -X- _ O
simple -X- _ O
spurious -X- _ O
correlations -X- _ O
on -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ O
effec- -X- _ O
tiveness -X- _ O
of -X- _ O
these -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
suggest -X- _ O
that -X- _ O
future -X- _ O
research -X- _ O
includes -X- _ O
compar- -X- _ O
isons -X- _ O
to -X- _ O
potential -X- _ O
spurious -X- _ O
correlates -X- _ O
and -X- _ O
that -X- _ O
re- -X- _ O
search -X- _ O
communities -X- _ O
come -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
potential -X- _ O
standard -X- _ O
spurious -X- _ O
correlates -X- _ O
. -X- _ O
4 -X- _ O
Learned -X- _ O
Metrics -X- _ O
in -X- _ O
System -X- _ O
- -X- _ O
level -X- _ O
Evaluation -X- _ O
4.1 -X- _ O
Pairwise -X- _ O
Ranking -X- _ O
of -X- _ O
Systems -X- _ O
Our -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
analysis -X- _ O
demonstrates -X- _ O
that -X- _ O
re- -X- _ O
cently -X- _ O
proposed -X- _ O
learned -X- _ O
evaluation -X- _ O
metrics -X- _ O
achieve -X- _ O
worse -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
than -X- _ O
spurious -X- _ O
correlates -X- _ O
for -X- _ O
almost -X- _ O
all -X- _ O
the -X- _ O
settings -X- _ O
. -X- _ O
Since -X- _ O
an -X- _ O
im- -X- _ O
portant -X- _ O
goal -X- _ O
of -X- _ O
building -X- _ O
these -X- _ O
metrics -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
rank -X- _ O
arbitrary -X- _ O
systems -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
whether -X- _ O
these -X- _ O
concerns -X- _ O
we -X- _ O
observe -X- _ O
at -X- _ O
the -X- _ O
example -X- _ O
level -X- _ O
manifest -X- _ O
into -X- _ O
harms -X- _ O
at -X- _ O
the -X- _ O
system -X- _ O
level -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
ranking -X- _ O
systems -X- _ O
incorrectly -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
study -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
large -X- _ O
collection -X- _ O
of -X- _ O
human -X- _ O
evaluation -X- _ O
data -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
systems -X- _ O
. -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
recently -X- _ O
released -X- _ O
human -X- _ O
evaluations -X- _ O
for -X- _ O
faithfulness -X- _ O
across -X- _ O
16summarization -X- _ O
systems -X- _ O
on -X- _ O
CNN -X- _ B-DatasetName
/ -X- _ I-DatasetName
DM -X- _ I-DatasetName
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
system -X- _ O
- -X- _ O
level -X- _ O
rankings -X- _ O
of -X- _ O
faithfulness -X- _ O
for -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
measure -X- _ O
pairwise -X- _ O
ranking -X- _ O
accuracy -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
systems -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4.We -X- _ O
find -X- _ O
that -X- _ O
system -X- _ O
- -X- _ O
level -X- _ O
rankings -X- _ O
suffer -X- _ O
from -X- _ O
a -X- _ O
similar -X- _ O
issue -X- _ O
as -X- _ O
the -X- _ O
example -X- _ O
level -X- _ O
correlations -X- _ O
: -X- _ O
density -X- _ O
and -X- _ O
cover-1447 -X- _ O
All -X- _ O
Pairs -X- _ O
Within -X- _ O
AF -X- _ O
Coverage -X- _ B-MetricName
56.54 -X- _ B-MetricValue
26.60 -X- _ B-MetricValue
Density -X- _ B-MetricName
81.01 -X- _ B-MetricValue
40.45 -X- _ B-MetricValue
FactCC -X- _ B-MethodName
78.87 -X- _ B-MetricValue
38.26 -X- _ B-MetricValue
DAE -X- _ B-MethodName
80.39 -X- _ B-MetricValue
37.88 -X- _ B-MetricValue
age -X- _ O
appear -X- _ O
as -X- _ O
spurious -X- _ O
correlations -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
observation -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
finer -X- _ O
- -X- _ O
grained -X- _ O
anal- -X- _ O
ysis -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
these -X- _ O
factuality -X- _ O
metrics -X- _ O
fail -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
subset -X- _ O
of -X- _ O
model -X- _ O
comparisons -X- _ O
: -X- _ O
abstractive -X- _ O
but -X- _ O
faithful -X- _ O
summarization -X- _ O
system -X- _ O
( -X- _ O
AF -X- _ O
) -X- _ O
– -X- _ O
where -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
abstractive -X- _ O
sum- -X- _ O
marization -X- _ O
systems -X- _ O
fall -X- _ O
. -X- _ O
4.2 -X- _ O
Results -X- _ O
Both -X- _ O
faithfulness -X- _ O
metrics -X- _ O
perform -X- _ O
relatively -X- _ O
well -X- _ O
when -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
pairwise -X- _ O
ranking -X- _ O
accuracy -X- _ O
across -X- _ O
all -X- _ O
pairs -X- _ O
of -X- _ O
models -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
areunable -X- _ O
to -X- _ O
improve -X- _ O
over -X- _ O
density -X- _ O
, -X- _ O
which -X- _ O
achieves -X- _ O
the -X- _ O
highest -X- _ O
overall -X- _ O
accuracy -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
ranking -X- _ O
within -X- _ O
the -X- _ O
abstractive -X- _ O
faithful -X- _ O
group -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
density -X- _ O
is -X- _ O
no -X- _ O
longer -X- _ O
a -X- _ O
good -X- _ O
measure -X- _ O
for -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
a -X- _ O
system -X- _ O
since -X- _ O
these -X- _ O
systems -X- _ O
are -X- _ O
relatively -X- _ O
close -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
density -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
learned -X- _ O
metrics -X- _ O
drops -X- _ O
significantly -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
expected -X- _ O
result -X- _ O
since -X- _ O
our -X- _ O
analysis -X- _ O
in -X- _ O
§ -X- _ O
3.1 -X- _ O
showed -X- _ O
that -X- _ O
both -X- _ O
FactCC -X- _ B-MethodName
and -X- _ O
DAE -X- _ B-MethodName
are -X- _ O
spuriously -X- _ O
corre- -X- _ O
lated -X- _ O
with -X- _ O
density -X- _ O
. -X- _ O
We -X- _ O
claim -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
- -X- _ O
level -X- _ O
analysis -X- _ O
is -X- _ O
further -X- _ O
evidence -X- _ O
that -X- _ O
these -X- _ O
metrics -X- _ O
may -X- _ O
be -X- _ O
relying -X- _ O
heavily -X- _ O
on -X- _ O
simple -X- _ O
spurious -X- _ O
measures -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
overlap -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
per- -X- _ O
forming -X- _ O
analyses -X- _ O
across -X- _ O
different -X- _ O
distributions -X- _ O
of -X- _ O
systems -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
were -X- _ O
looking -X- _ O
at -X- _ O
just -X- _ O
the -X- _ O
overall -X- _ O
rank- -X- _ O
ing -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
conclude -X- _ O
that -X- _ O
DAE -X- _ B-MethodName
and -X- _ O
FactCC -X- _ B-MethodName
correctly -X- _ O
measure -X- _ O
faithfulness -X- _ B-MetricName
. -X- _ O
However -X- _ O
, -X- _ O
on -X- _ O
closer -X- _ O
examination -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
both -X- _ O
metrics -X- _ O
perform -X- _ O
relatively -X- _ O
poorly -X- _ O
in -X- _ O
ranking -X- _ O
AF -X- _ O
systems -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
arguably -X- _ O
the -X- _ O
most -X- _ O
crucial -X- _ O
group -X- _ O
since -X- _ O
most -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
systems -X- _ O
operate -X- _ O
in -X- _ O
this -X- _ O
regime -X- _ O
, -X- _ O
and -X- _ O
there -X- _ O
is -X- _ O
substantial -X- _ O
interest -X- _ O
in -X- _ O
building -X- _ O
abstractive -X- _ O
and -X- _ O
faithful -X- _ O
summarization -X- _ O
systems.1448 -X- _ O
All -X- _ O
Pairs -X- _ O
Within -X- _ O
AF -X- _ O
FactCC -X- _ B-MethodName
- -X- _ O
Electra -X- _ O
77.85 -X- _ B-MetricValue
27.70 -X- _ B-MetricValue
FactCC -X- _ B-MethodName
78.87 -X- _ B-MetricValue
38.26 -X- _ B-MetricValue
DAE -X- _ B-MethodName
80.39 -X- _ B-MetricValue
37.88 -X- _ B-MetricValue
Adversarial -X- _ B-MethodName
85.27 -X- _ B-MetricValue
59.20 -X- _ B-MetricValue
5 -X- _ O
Adversarial -X- _ O
Model -X- _ O
In -X- _ O
our -X- _ O
earlier -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
learned -X- _ O
metrics -X- _ O
have -X- _ O
higher -X- _ O
correlation -X- _ O
with -X- _ O
spu- -X- _ O
rious -X- _ O
correlates -X- _ O
than -X- _ O
human -X- _ O
judgment -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
saw -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
- -X- _ O
level -X- _ O
analysis -X- _ O
that -X- _ O
learned -X- _ O
met- -X- _ O
rics -X- _ O
for -X- _ O
faithfulness -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
outperform -X- _ O
den- -X- _ O
sity -X- _ O
. -X- _ O
One -X- _ O
natural -X- _ O
question -X- _ O
that -X- _ O
follows -X- _ O
is -X- _ O
whether -X- _ O
we -X- _ O
can -X- _ O
build -X- _ O
metrics -X- _ O
that -X- _ O
do -X- _ O
well -X- _ O
at -X- _ O
the -X- _ O
systems -X- _ O
level -X- _ O
by -X- _ O
learning -X- _ O
representations -X- _ O
that -X- _ O
rely -X- _ O
less -X- _ O
on -X- _ O
spurious -X- _ O
correlates -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
do -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
an -X- _ O
entailment -X- _ O
based -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
synthetically -X- _ O
generated -X- _ O
data -X- _ O
from -X- _ O
FactCC -X- _ O
in -X- _ O
an -X- _ O
adversarial -X- _ O
setup -X- _ O
similar -X- _ O
to -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
augments -X- _ O
the -X- _ O
standard -X- _ O
faithfulness -X- _ O
predictor -X- _ O
with -X- _ O
a -X- _ O
density -X- _ O
predictor -X- _ O
that -X- _ O
tries -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
density -X- _ O
of -X- _ O
the -X- _ O
sum -X- _ O
- -X- _ O
mary -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
internal -X- _ O
representation -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
this -X- _ O
density -X- _ O
predictor -X- _ O
as -X- _ O
an -X- _ O
adversary -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
faithfulness -X- _ O
while -X- _ O
ensuring -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
predict -X- _ O
density -X- _ O
using -X- _ O
this -X- _ O
same -X- _ O
rep- -X- _ O
resentation -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
this -X- _ O
, -X- _ O
the -X- _ O
gradients -X- _ O
from -X- _ O
the -X- _ O
density -X- _ O
predictor -X- _ O
are -X- _ O
reversed -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
harder -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
density -X- _ O
from -X- _ O
the -X- _ O
encoder -X- _ O
’s -X- _ O
rep- -X- _ O
resentation -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
makes -X- _ O
the -X- _ O
faithfulness -X- _ O
predic- -X- _ O
tions -X- _ O
less -X- _ O
reliant -X- _ O
on -X- _ O
density -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
architecture -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
We -X- _ O
initialize -X- _ O
the -X- _ O
parameter -X- _ O
λto0and -X- _ O
gradually -X- _ O
increase -X- _ O
it -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
schedule -X- _ O
detailed -X- _ O
in -X- _ O
Ganin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Electra -X- _ O
model -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
chose -X- _ O
Electra -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
in -X- _ O
DAE -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
original -X- _ O
FactCC -X- _ B-MethodName
metric -X- _ O
was -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
also -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
our -X- _ O
own -X- _ O
version -X- _ O
of -X- _ O
FactCC -X- _ O
on -X- _ O
Electra -X- _ O
( -X- _ O
FactCC -X- _ O
- -X- _ O
Electra -X- _ O
) -X- _ O
as -X- _ O
an -X- _ O
ablation -X- _ O
. -X- _ O
Our -X- _ O
ad- -X- _ O
versarially -X- _ O
trained -X- _ O
model -X- _ O
is -X- _ O
essentially -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
FactCC -X- _ B-MethodName
- -X- _ I-MethodName
Electra -X- _ I-MethodName
, -X- _ O
but -X- _ O
with -X- _ O
an -X- _ O
additional -X- _ O
adversarial -X- _ O
head -X- _ O
for -X- _ O
predicting -X- _ O
density -X- _ O
. -X- _ O
Results -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
FactCC -X- _ B-MethodName
- -X- _ O
Electra -X- _ O
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
FactCC -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
findings -X- _ O
in -X- _ O
Goyal -X- _ O
and -X- _ O
Dur- -X- _ O
rett -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
adversarially -X- _ O
trained -X- _ O
metric -X- _ O
has -X- _ O
a -X- _ O
significantly -X- _ O
lower -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
correlation -X- _ O
with -X- _ O
density -X- _ B-MetricName
( -X- _ O
27.71 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
, -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
FactCC -X- _ B-MethodName
( -X- _ O
59.10 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
1449and -X- _ O
DAE -X- _ B-MethodName
( -X- _ O
76.37 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
adversarial -X- _ O
modelcan -X- _ O
achieve -X- _ O
a -X- _ O
significantly -X- _ O
better -X- _ O
perfor- -X- _ O
mance -X- _ O
than -X- _ O
existing -X- _ O
learned -X- _ O
evaluation -X- _ O
metrics -X- _ O
in -X- _ O
ranking -X- _ O
systems -X- _ O
within -X- _ O
the -X- _ O
abstractive -X- _ O
faithful -X- _ O
( -X- _ O
AF -X- _ O
) -X- _ O
group -X- _ O
( -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
learn -X- _ O
effective -X- _ O
metrics -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
overly -X- _ O
reliant -X- _ O
on -X- _ O
spurious -X- _ O
correlates -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
our -X- _ O
metric -X- _ O
is -X- _ O
also -X- _ O
effective -X- _ O
in -X- _ O
overall -X- _ O
pairwise -X- _ O
ranking -X- _ O
of -X- _ O
the -X- _ O
systems -X- _ O
achieving -X- _ O
85.27 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
. -X- _ O
6 -X- _ O
Related -X- _ O
Work -X- _ O
Most -X- _ O
existing -X- _ O
work -X- _ O
on -X- _ O
assessing -X- _ O
the -X- _ O
evaluation -X- _ O
methodology -X- _ O
of -X- _ O
evaluation -X- _ O
metrics -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
evaluation -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
take -X- _ O
a -X- _ O
critical -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
correlations -X- _ O
to -X- _ O
measure -X- _ O
reference- -X- _ O
based -X- _ O
evaluation -X- _ O
metrics -X- _ O
in -X- _ O
Machine -X- _ O
Translation -X- _ O
. -X- _ O
They -X- _ O
show -X- _ O
that -X- _ O
evaluating -X- _ O
these -X- _ O
metrics -X- _ O
using -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
correlations -X- _ O
can -X- _ O
be -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
outliers -X- _ O
which -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
false -X- _ O
con- -X- _ O
clusions -X- _ O
about -X- _ O
a -X- _ O
metric -X- _ O
’s -X- _ O
efficacy -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
Kocmi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
proper -X- _ O
assessment -X- _ O
of -X- _ O
evaluation -X- _ O
metrics -X- _ O
is -X- _ O
crucial -X- _ O
as -X- _ O
uninformed -X- _ O
use -X- _ O
of -X- _ O
automated -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
BLEU -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
bad -X- _ O
deployment -X- _ O
decisions -X- _ O
. -X- _ O
Caglayan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
automated -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
eval- -X- _ O
uation -X- _ O
metrics -X- _ O
have -X- _ O
robustness -X- _ O
issues -X- _ O
which -X- _ O
can -X- _ O
cause -X- _ O
them -X- _ O
to -X- _ O
score -X- _ O
generated -X- _ O
outputs -X- _ O
higher -X- _ O
than -X- _ O
human -X- _ O
written -X- _ O
outputs -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
Bhandari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
has -X- _ O
studied -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
reference- -X- _ O
based -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
text -X- _ O
summarization -X- _ O
, -X- _ O
comparing -X- _ O
these -X- _ O
metrics -X- _ O
across -X- _ O
different -X- _ O
datasets -X- _ O
and -X- _ O
application -X- _ O
scenarios -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
focuses -X- _ O
on -X- _ O
analyzing -X- _ O
learned -X- _ O
, -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
eval- -X- _ O
uation -X- _ O
metrics -X- _ O
in -X- _ O
summarization -X- _ O
and -X- _ O
dialog -X- _ O
gener- -X- _ O
ation -X- _ O
, -X- _ O
accounting -X- _ O
for -X- _ O
potential -X- _ O
spurious -X- _ O
correlates -X- _ O
for -X- _ O
these -X- _ O
evaluation -X- _ O
tasks -X- _ O
. -X- _ O
There -X- _ O
has -X- _ O
been -X- _ O
some -X- _ O
recent -X- _ O
work -X- _ O
comparing -X- _ O
existing -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
for -X- _ O
text -X- _ O
summarization -X- _ O
and -X- _ O
dialog -X- _ O
generation -X- _ O
. -X- _ O
Pagnoni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
measured -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
exist- -X- _ O
ing -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
faithfulness -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
summarization -X- _ O
on -X- _ O
two -X- _ O
different -X- _ O
summariza- -X- _ O
tion -X- _ O
datasets -X- _ O
relying -X- _ O
on -X- _ O
example -X- _ O
- -X- _ O
level -X- _ O
correlations -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
Gehrmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
evaluated -X- _ O
automated -X- _ O
metrics -X- _ O
of -X- _ O
text -X- _ O
summarization -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
datasets -X- _ O
. -X- _ O
Gabriel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
proposed -X- _ O
a -X- _ O
meta -X- _ O
- -X- _ O
evaluation -X- _ O
framework -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
looking -X- _ O
at -X- _ O
certain -X- _ O
aspects -X- _ O
ofthese -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
robustness -X- _ O
, -X- _ O
sensitivity -X- _ O
, -X- _ O
high -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
scores -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
, -X- _ O
and -X- _ O
measured -X- _ O
existing -X- _ O
evaluation -X- _ O
metrics -X- _ O
across -X- _ O
these -X- _ O
aspects -X- _ O
. -X- _ O
Yeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
perform -X- _ O
a -X- _ O
comprehensive -X- _ O
study -X- _ O
of -X- _ O
existing -X- _ O
dialog -X- _ O
generation -X- _ O
metrics -X- _ O
across -X- _ O
several -X- _ O
different -X- _ O
datasets -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
metrics -X- _ O
varies -X- _ O
widely -X- _ O
across -X- _ O
datasets -X- _ O
. -X- _ O
Gabriel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Yeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
most -X- _ O
related -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
since -X- _ O
they -X- _ O
study -X- _ O
robust- -X- _ O
ness -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
looking -X- _ O
at -X- _ O
their -X- _ O
performance -X- _ O
across -X- _ O
different -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
explicitly -X- _ O
study -X- _ O
spurious -X- _ O
correlations -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
these -X- _ O
may -X- _ O
potentially -X- _ O
be -X- _ O
contributing -X- _ O
to -X- _ O
the -X- _ O
robust- -X- _ O
ness -X- _ O
issues -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
present -X- _ O
initial -X- _ O
promising -X- _ O
results -X- _ O
suggesting -X- _ O
that -X- _ O
controlling -X- _ O
for -X- _ O
these -X- _ O
spuri- -X- _ O
ous -X- _ O
correlates -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
more -X- _ O
robust -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
7 -X- _ O
Conclusion -X- _ O
In -X- _ O
conclusion -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
for -X- _ O
summarization -X- _ O
and -X- _ O
dialog -X- _ O
generation -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
simply -X- _ O
looking -X- _ O
at -X- _ O
overall -X- _ O
example- -X- _ O
level -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgment -X- _ O
paints -X- _ O
an -X- _ O
incomplete -X- _ O
picture -X- _ O
of -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
a -X- _ O
metric -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
do -X- _ O
better -X- _ O
than -X- _ O
simple -X- _ O
spurious -X- _ O
correlates -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
this -X- _ O
trend -X- _ O
carries -X- _ O
over -X- _ O
in -X- _ O
system- -X- _ O
level -X- _ O
ranking -X- _ O
for -X- _ O
summarization -X- _ O
systems -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
spurious -X- _ O
correlate -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
performs -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
existing -X- _ O
learned -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
despite -X- _ O
the -X- _ O
relatively -X- _ O
high -X- _ O
overall -X- _ O
system -X- _ O
- -X- _ O
level -X- _ O
ranking -X- _ O
performance -X- _ O
, -X- _ O
the -X- _ O
learned -X- _ O
metrics -X- _ O
are -X- _ O
not -X- _ O
robust -X- _ O
to -X- _ O
distribution -X- _ O
shifts -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
they -X- _ O
fail -X- _ O
to -X- _ O
properly -X- _ O
rank -X- _ O
abstractive -X- _ O
and -X- _ O
( -X- _ O
relatively -X- _ O
) -X- _ O
faithful -X- _ O
systems -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
where -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
operates -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
faithfulness -X- _ O
metric -X- _ O
that -X- _ O
scores -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
a -X- _ O
summary -X- _ O
without -X- _ O
relying -X- _ O
on -X- _ O
the -X- _ O
spurious -X- _ O
overlap -X- _ O
correlate -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
metric -X- _ O
is -X- _ O
more -X- _ O
robust -X- _ O
across -X- _ O
distribution -X- _ O
shifts -X- _ O
and -X- _ O
does -X- _ O
better -X- _ O
at -X- _ O
ranking -X- _ O
abstractive -X- _ O
, -X- _ O
faithful -X- _ O
summarization -X- _ O
systems -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
that -X- _ O
future -X- _ O
work -X- _ O
in -X- _ O
designing -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
evaluation -X- _ O
metrics -X- _ O
should -X- _ O
be -X- _ O
mindful -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
evaluation -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
par- -X- _ O
ticular -X- _ O
, -X- _ O
metrics -X- _ O
should -X- _ O
be -X- _ O
assessed -X- _ O
across -X- _ O
different -X- _ O
distributions -X- _ O
of -X- _ O
systems -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
test -X- _ O
for -X- _ O
robust- -X- _ O
ness -X- _ O
and -X- _ O
failure -X- _ O
modes -X- _ O
. -X- _ O
Simple -X- _ O
spurious -X- _ O
correlates -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
tool -X- _ O
to -X- _ O
indicate -X- _ O
potential -X- _ O
overes- -X- _ O
timates -X- _ O
of -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
proposed -X- _ O
metrics -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
collecting -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
human -X- _ O
evaluation -X- _ O
datasets -X- _ O
across -X- _ O
a -X- _ O
wide1450range -X- _ O
of -X- _ O
systems -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
enable -X- _ O
more -X- _ O
comprehensive -X- _ O
analyses -X- _ O
of -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O
8 -X- _ O
Acknowledgements -X- _ O
ED -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
SAIL -X- _ O
Postdoc -X- _ O
Fellowship -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
and -X- _ O
the -X- _ O
Stanford -X- _ O
NLP -X- _ O
group -X- _ O
for -X- _ O
their -X- _ O
invaluable -X- _ O
feedback -X- _ O
. -X- _ O
References145114521453A -X- _ O
Text -X- _ O
Summarization -X- _ O
Models -X- _ O
Model -X- _ O
Name -X- _ O
Paper -X- _ O
M0 -X- _ O
Lead-3 -X- _ O
baseline -X- _ O
M1 -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M2 -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M5 -X- _ O
Wu -X- _ O
and -X- _ O
Hu -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M8 -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
M9 -X- _ O
Chen -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M10 -X- _ O
Gehrmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M11 -X- _ O
Kry -X- _ O
´ -X- _ O
sci´nski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M12 -X- _ O
Hsu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M13 -X- _ O
Pasunuru -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M14 -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M15 -X- _ O
Jiang -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
M17 -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
M20 -X- _ O
Ziegler -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
M22 -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
M23 -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
1454 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
proposes -X- _ SUMMARY
a -X- _ SUMMARY
method -X- _ SUMMARY
called -X- _ SUMMARY
Speech -X- _ SUMMARY
and -X- _ SUMMARY
Text -X- _ SUMMARY
joint -X- _ SUMMARY
Pre -X- _ SUMMARY
- -X- _ SUMMARY
Training -X- _ SUMMARY
( -X- _ SUMMARY
STPT -X- _ SUMMARY
) -X- _ SUMMARY
for -X- _ SUMMARY
speech -X- _ SUMMARY
translation -X- _ SUMMARY
and -X- _ SUMMARY
recognition -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
method -X- _ SUMMARY
incorporates -X- _ SUMMARY
four -X- _ SUMMARY
subtasks -X- _ SUMMARY
: -X- _ SUMMARY
( -X- _ SUMMARY
1 -X- _ SUMMARY
) -X- _ SUMMARY
self -X- _ SUMMARY
- -X- _ SUMMARY
supervised -X- _ SUMMARY
text -X- _ SUMMARY
to -X- _ SUMMARY
text -X- _ SUMMARY
( -X- _ SUMMARY
T2 -X- _ SUMMARY
T -X- _ SUMMARY
) -X- _ SUMMARY
subtask -X- _ SUMMARY
, -X- _ SUMMARY
( -X- _ SUMMARY
2 -X- _ SUMMARY
) -X- _ SUMMARY
self -X- _ SUMMARY
- -X- _ SUMMARY
supervised -X- _ SUMMARY
speech -X- _ SUMMARY
learning -X- _ SUMMARY
( -X- _ SUMMARY
SSL -X- _ SUMMARY
) -X- _ SUMMARY
subtask -X- _ SUMMARY
, -X- _ SUMMARY
( -X- _ SUMMARY
3 -X- _ SUMMARY
) -X- _ SUMMARY
supervised -X- _ SUMMARY
speech -X- _ SUMMARY
to -X- _ SUMMARY
phoneme -X- _ SUMMARY
classification -X- _ SUMMARY
( -X- _ SUMMARY
S2P -X- _ SUMMARY
) -X- _ SUMMARY
subtask -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
( -X- _ SUMMARY
4 -X- _ SUMMARY
) -X- _ SUMMARY
supervised -X- _ SUMMARY
AED -X- _ SUMMARY
- -X- _ SUMMARY
based -X- _ SUMMARY
speech -X- _ SUMMARY
to -X- _ SUMMARY
text -X- _ SUMMARY
( -X- _ SUMMARY
S2 -X- _ SUMMARY
T -X- _ SUMMARY
) -X- _ SUMMARY
subtask -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
effectively -X- _ SUMMARY
fuses -X- _ SUMMARY
speech -X- _ SUMMARY
and -X- _ SUMMARY
text -X- _ SUMMARY
information -X- _ SUMMARY
into -X- _ SUMMARY
one -X- _ SUMMARY
model -X- _ SUMMARY
, -X- _ SUMMARY
achieving -X- _ SUMMARY
1.7 -X- _ SUMMARY
to -X- _ SUMMARY
2.3 -X- _ SUMMARY
BLEU -X- _ SUMMARY
improvement -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
MST -X- _ SUMMARY
- -X- _ SUMMARY
C -X- _ SUMMARY
speech -X- _ SUMMARY
translation -X- _ SUMMARY
dataset -X- _ SUMMARY
and -X- _ SUMMARY
comparable -X- _ SUMMARY
Word -X- _ SUMMARY
Error -X- _ SUMMARY
Rates -X- _ SUMMARY
( -X- _ SUMMARY
WERs -X- _ SUMMARY
) -X- _ SUMMARY
to -X- _ SUMMARY
wav2vec -X- _ SUMMARY
2.0 -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
L -X- _ SUMMARY
speech -X- _ SUMMARY
recognition -X- _ SUMMARY
task -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
pre -X- _ SUMMARY
- -X- _ SUMMARY
training -X- _ SUMMARY
configuration -X- _ SUMMARY
is -X- _ SUMMARY
adapted -X- _ SUMMARY
depending -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
downstream -X- _ SUMMARY
task -X- _ SUMMARY
( -X- _ SUMMARY
ASR -X- _ SUMMARY
or -X- _ SUMMARY
ST -X- _ SUMMARY
) -X- _ SUMMARY
to -X- _ SUMMARY
minimize -X- _ SUMMARY
subtask -X- _ SUMMARY
interference -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
experiments -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
more -X- _ SUMMARY
supervised -X- _ SUMMARY
speech -X- _ SUMMARY
data -X- _ SUMMARY
in -X- _ SUMMARY
the -X- _ SUMMARY
pre -X- _ SUMMARY
- -X- _ SUMMARY
training -X- _ SUMMARY
stage -X- _ SUMMARY
leads -X- _ SUMMARY
to -X- _ SUMMARY
smaller -X- _ SUMMARY
WER -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
study -X- _ SUMMARY
also -X- _ SUMMARY
compares -X- _ SUMMARY
the -X- _ SUMMARY
effectiveness -X- _ SUMMARY
of -X- _ SUMMARY
using -X- _ SUMMARY
masked -X- _ SUMMARY
KL -X- _ SUMMARY
divergence -X- _ SUMMARY
loss -X- _ SUMMARY
in -X- _ SUMMARY
SSL -X- _ SUMMARY
subtask -X- _ SUMMARY
compared -X- _ SUMMARY
to -X- _ SUMMARY
contrastive -X- _ SUMMARY
loss -X- _ SUMMARY
. -X- _ SUMMARY
Ablation -X- _ SUMMARY
studies -X- _ SUMMARY
demonstrate -X- _ SUMMARY
the -X- _ SUMMARY
importance -X- _ SUMMARY
of -X- _ SUMMARY
each -X- _ SUMMARY
sub -X- _ SUMMARY
- -X- _ SUMMARY
task -X- _ SUMMARY
in -X- _ SUMMARY
the -X- _ SUMMARY
pre -X- _ SUMMARY
- -X- _ SUMMARY
training -X- _ SUMMARY
process -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.105.txt -X- _ O
Yun -X- _ O
Tang -X- _ O
, -X- _ O
Hongyu -X- _ O
Gong -X- _ O
, -X- _ O
Ning -X- _ O
Dong -X- _ O
, -X- _ O
Changhan -X- _ O
Wang -X- _ O
, -X- _ O
Wei -X- _ O
- -X- _ O
Ning -X- _ O
Hsu -X- _ O
, -X- _ O
Jiatao -X- _ O
Gu -X- _ O
, -X- _ O
Alexei -X- _ O
Baevski -X- _ O
, -X- _ O
Xian -X- _ O
Li -X- _ O
, -X- _ O
Abdelrahman -X- _ O
Mohamed -X- _ O
, -X- _ O
Michael -X- _ O
Auli -X- _ O
, -X- _ O
Juan -X- _ O
Pino -X- _ O
Meta -X- _ O
AI -X- _ O
fyuntang -X- _ O
, -X- _ O
hygong -X- _ O
, -X- _ O
dnn -X- _ O
, -X- _ O
changhan -X- _ O
, -X- _ O
wnhsu -X- _ O
, -X- _ O
jgu -X- _ O
, -X- _ O
abaevski -X- _ O
, -X- _ O
xianl -X- _ O
, -X- _ O
abdo -X- _ O
, -X- _ O
michaelauli -X- _ O
, -X- _ O
juancarabina -X- _ O
g -X- _ O
@ -X- _ O
fb.com -X- _ O
Abstract -X- _ O
We -X- _ O
describe -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
jointly -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
in -X- _ O
an -X- _ O
encoder -X- _ B-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
mod- -X- _ I-MethodName
eling -X- _ I-MethodName
framework -X- _ O
for -X- _ O
speech -X- _ B-TaskName
translation -X- _ I-TaskName
and -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O
The -X- _ O
proposed -X- _ O
method -X- _ O
incor- -X- _ O
porates -X- _ O
four -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
and -X- _ O
supervised -X- _ O
subtasks -X- _ O
for -X- _ O
cross -X- _ B-TaskName
modality -X- _ I-TaskName
learning -X- _ I-TaskName
. -X- _ O
A -X- _ O
self -X- _ B-TaskName
- -X- _ I-TaskName
supervised -X- _ I-TaskName
speech -X- _ I-TaskName
subtask -X- _ O
leverages -X- _ O
un- -X- _ O
labelled -X- _ O
speech -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
( -X- _ B-TaskName
self- -X- _ I-TaskName
) -X- _ I-TaskName
supervised -X- _ I-TaskName
text -X- _ I-TaskName
to -X- _ I-TaskName
text -X- _ I-TaskName
subtask -X- _ O
makes -X- _ O
use -X- _ O
of -X- _ O
abundant -X- _ O
text -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Two -X- _ O
auxiliary -X- _ O
supervised -X- _ O
speech -X- _ O
tasks -X- _ O
are -X- _ O
included -X- _ O
to -X- _ O
unify -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
modeling -X- _ O
space -X- _ O
. -X- _ O
Our -X- _ O
contribution -X- _ O
lies -X- _ O
in -X- _ O
in- -X- _ O
tegrating -X- _ O
linguistic -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
corpus -X- _ O
into -X- _ O
the -X- _ O
speech -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Detailed -X- _ O
analysis -X- _ O
reveals -X- _ O
learning -X- _ O
interference -X- _ O
among -X- _ O
subtasks -X- _ O
. -X- _ O
Two -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
conﬁgurations -X- _ O
for -X- _ O
speech -X- _ O
translation -X- _ O
and -X- _ O
recognition -X- _ O
, -X- _ O
respec- -X- _ O
tively -X- _ O
, -X- _ O
are -X- _ O
presented -X- _ O
to -X- _ O
alleviate -X- _ O
subtask -X- _ O
inter- -X- _ O
ference -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
show -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
can -X- _ O
effectively -X- _ O
fuse -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
in- -X- _ O
formation -X- _ O
into -X- _ O
one -X- _ O
model -X- _ O
. -X- _ O
It -X- _ O
achieves -X- _ O
between -X- _ O
1.7 -X- _ B-MetricValue
and -X- _ O
2.3 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
improvement -X- _ O
above -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
on -X- _ O
the -X- _ O
MST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
speech -X- _ I-DatasetName
transla- -X- _ I-DatasetName
tion -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
comparable -X- _ O
WERs -X- _ B-MetricValue
to -X- _ O
wav2vec -X- _ B-MethodName
2.0 -X- _ I-MethodName
on -X- _ O
the -X- _ O
L -X- _ B-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
task -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
can -X- _ O
learn -X- _ O
universal -X- _ O
feature -X- _ O
represen- -X- _ O
tations -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
training -X- _ O
corpus -X- _ O
and -X- _ O
is -X- _ O
beneﬁ- -X- _ O
cial -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
with -X- _ O
limited -X- _ O
amounts -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
van -X- _ O
den -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Zoph -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
advancement -X- _ O
of -X- _ O
computational -X- _ O
power -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
approaches -X- _ O
, -X- _ O
large -X- _ O
volumes -X- _ O
of -X- _ O
unlabeled -X- _ O
data -X- _ O
may -X- _ O
now -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Methods -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
BART -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
and -X- _ O
wav2vec2.0 -X- _ B-MethodName
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
emerged -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
many -X- _ O
speech -X- _ O
and -X- _ O
natural -X- _ O
lan- -X- _ O
guage -X- _ O
processing -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
aforementioned -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
focus -X- _ O
on -X- _ O
learning -X- _ O
feature -X- _ O
representation -X- _ O
either -X- _ O
from -X- _ O
text -X- _ O
or -X- _ O
speech -X- _ O
. -X- _ O
Many -X- _ O
speech -X- _ O
applications -X- _ O
combine -X- _ O
in- -X- _ O
formation -X- _ O
learnt -X- _ O
from -X- _ O
both -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
corpora -X- _ O
to -X- _ O
achieve -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
speech -X- _ O
process- -X- _ O
ing -X- _ O
, -X- _ O
transcribed -X- _ O
speech -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
generally -X- _ O
very -X- _ O
scarce -X- _ O
for -X- _ O
many -X- _ O
languages -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
difﬁcult -X- _ O
to -X- _ O
build -X- _ O
robust -X- _ O
linguistic -X- _ O
knowledge -X- _ O
representation -X- _ O
solely -X- _ O
based -X- _ O
on -X- _ O
labeled -X- _ O
speech -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Jia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
gen- -X- _ O
erate -X- _ O
synthetic -X- _ O
data -X- _ O
from -X- _ O
text -X- _ O
to -X- _ O
augment -X- _ O
speech -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
demonstrate -X- _ O
that -X- _ O
models -X- _ O
initialized -X- _ O
with -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
wav2vec2.0 -X- _ B-MethodName
and -X- _ O
mBART -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
modules -X- _ O
are -X- _ O
competi- -X- _ O
tive -X- _ O
for -X- _ O
the -X- _ O
multilingual -X- _ O
speech -X- _ O
to -X- _ O
text -X- _ O
translation -X- _ O
task -X- _ O
. -X- _ O
Chuang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
to -X- _ O
concatenate -X- _ O
the -X- _ O
acoustic -X- _ O
model -X- _ O
and -X- _ O
BERT -X- _ O
model -X- _ O
for -X- _ O
speech -X- _ B-TaskName
Q -X- _ I-TaskName
& -X- _ I-TaskName
A. -X- _ I-TaskName
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
align -X- _ O
speech -X- _ O
utterance -X- _ O
representation -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
text -X- _ O
sentence -X- _ O
representation -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
both -X- _ O
representations -X- _ O
are -X- _ O
generated -X- _ O
from -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
for -X- _ O
speech -X- _ O
understanding -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
speech -X- _ O
to -X- _ O
text -X- _ O
tasks -X- _ O
using -X- _ O
the -X- _ O
Attention -X- _ B-MethodName
based -X- _ I-MethodName
Encoder -X- _ I-MethodName
- -X- _ I-MethodName
Decoder -X- _ I-MethodName
( -X- _ O
AED -X- _ O
) -X- _ O
framework -X- _ O
. -X- _ O
In -X- _ O
particu- -X- _ O
lar -X- _ O
, -X- _ O
we -X- _ O
seek -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
whether -X- _ O
the -X- _ O
integration -X- _ O
of -X- _ O
data -X- _ O
from -X- _ O
different -X- _ O
modalities -X- _ O
is -X- _ O
ben- -X- _ O
eﬁcial -X- _ O
for -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O
To -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Speech -X- _ B-TaskName
and -X- _ I-TaskName
Text -X- _ I-TaskName
joint -X- _ I-TaskName
Pre- -X- _ I-TaskName
Training -X- _ I-TaskName
( -X- _ O
STPT -X- _ B-TaskName
) -X- _ O
, -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
framework -X- _ O
to -X- _ O
combine -X- _ O
different -X- _ O
modalities -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O
A -X- _ O
self -X- _ B-TaskName
- -X- _ I-TaskName
supervised -X- _ I-TaskName
speech -X- _ I-TaskName
subtask -X- _ O
and -X- _ O
a -X- _ O
( -X- _ B-TaskName
self- -X- _ I-TaskName
) -X- _ I-TaskName
supervised -X- _ I-TaskName
text -X- _ I-TaskName
to -X- _ I-TaskName
text -X- _ I-TaskName
subtask -X- _ I-TaskName
dominate -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
computation -X- _ O
to -X- _ O
leverage -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
unlabelled -X- _ O
speech -X- _ O
data -X- _ O
and -X- _ O
abundant -X- _ O
text -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O
Two -X- _ O
auxiliary -X- _ O
supervised -X- _ O
speech -X- _ O
subtasks -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
unify -X- _ O
dif- -X- _ O
ferent -X- _ O
modalities -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
modeling -X- _ O
space -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
method -X- _ O
fuses -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
speech -X- _ O
training -X- _ O
corpus -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
effectively -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
down-1488stream -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
speech -X- _ B-TaskName
to -X- _ I-TaskName
text -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
ST -X- _ O
) -X- _ O
and -X- _ O
automatic -X- _ B-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
ASR -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
con- -X- _ O
tributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1.We -X- _ O
propose -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
framework -X- _ O
to -X- _ O
learn -X- _ O
four -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
subtasks -X- _ O
in -X- _ O
one -X- _ O
model -X- _ O
and -X- _ O
successfully -X- _ O
integrate -X- _ O
linguistic -X- _ O
in- -X- _ O
formation -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
corpus -X- _ O
into -X- _ O
the -X- _ O
speech -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
2.We -X- _ O
conduct -X- _ O
detailed -X- _ O
analyses -X- _ O
on -X- _ O
the -X- _ O
proposed -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
reveal -X- _ O
the -X- _ O
interfer- -X- _ O
ence -X- _ O
among -X- _ O
different -X- _ O
subtasks -X- _ O
. -X- _ O
3.Two -X- _ O
joint -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
conﬁgurations -X- _ O
are -X- _ O
pro- -X- _ O
posed -X- _ O
to -X- _ O
alleviate -X- _ O
learning -X- _ O
interference -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
ST -X- _ B-TaskName
respectively -X- _ O
. -X- _ O
4.State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
are -X- _ O
achieved -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
obtain -X- _ O
at -X- _ O
least -X- _ O
1.7 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
improvement -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
MST -X- _ O
- -X- _ O
C -X- _ O
ST -X- _ O
system -X- _ O
reported -X- _ O
and -X- _ O
comparable -X- _ O
WERs -X- _ O
as -X- _ O
wav2vec -X- _ O
2.0 -X- _ O
in -X- _ O
the -X- _ O
L -X- _ O
ASR -X- _ O
task -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
work -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
Self -X- _ O
- -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
usu- -X- _ O
ally -X- _ O
optimized -X- _ O
with -X- _ O
two -X- _ O
different -X- _ O
criteria -X- _ O
: -X- _ O
con- -X- _ O
trastive -X- _ O
loss -X- _ O
( -X- _ O
van -X- _ O
den -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Chung -X- _ O
and -X- _ O
Glass -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
and -X- _ O
masked -X- _ O
prediction -X- _ O
loss -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Contrastive -X- _ O
loss -X- _ O
focuses -X- _ O
on -X- _ O
distinguishing -X- _ O
the -X- _ O
positive -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
negative -X- _ O
ones -X- _ O
given -X- _ O
the -X- _ O
reference -X- _ O
sam- -X- _ O
ple -X- _ O
and -X- _ O
it -X- _ O
has -X- _ O
achieved -X- _ O
great -X- _ O
success -X- _ O
for -X- _ O
speech -X- _ B-TaskName
recognition -X- _ I-TaskName
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Masked -X- _ O
predic- -X- _ O
tion -X- _ O
loss -X- _ O
has -X- _ O
been -X- _ O
ﬁrst -X- _ O
studied -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
tasks -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
with -X- _ O
subsequent -X- _ O
application -X- _ O
to -X- _ O
speech -X- _ B-TaskName
pro- -X- _ I-TaskName
cessing -X- _ I-TaskName
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Hsu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021a -X- _ O
) -X- _ O
combine -X- _ O
contrastive -X- _ O
loss -X- _ O
and -X- _ O
masked -X- _ O
prediction -X- _ O
loss -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
good -X- _ O
perfor- -X- _ O
mance -X- _ O
for -X- _ O
the -X- _ O
downstream -X- _ O
ASR -X- _ B-TaskName
task -X- _ O
. -X- _ O
The -X- _ O
opti- -X- _ O
mization -X- _ O
of -X- _ O
our -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
speech -X- _ O
task -X- _ O
is -X- _ O
more -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
prediction -X- _ O
loss -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
hard -X- _ O
discretized -X- _ O
label -X- _ O
for -X- _ O
the -X- _ O
masked -X- _ O
frames -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
error -X- _ O
prone -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
KL -X- _ O
divergence -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
distribution -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
same -X- _ O
feature -X- _ O
frames -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
masking -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
subsection -X- _ O
3.2 -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O
Self -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
or -X- _ O
iterative -X- _ O
pseudo -X- _ O
labelling -X- _ O
) -X- _ O
: -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
another -X- _ O
widely -X- _ O
used -X- _ O
approach -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
unlabelled -X- _ O
speech -X- _ O
data -X- _ O
to -X- _ O
im- -X- _ O
prove -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
performance -X- _ O
( -X- _ O
Kahn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Xuet -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Pino -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
; -X- _ O
Xiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
seed -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
usually -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
supervised -X- _ O
speech -X- _ O
train- -X- _ O
ing -X- _ O
data -X- _ O
, -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
generate -X- _ O
pseudo -X- _ O
labels -X- _ O
for -X- _ O
the -X- _ O
unlabelled -X- _ O
speech -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
speech -X- _ O
data -X- _ O
with -X- _ O
pseudo -X- _ O
labels -X- _ O
is -X- _ O
augmented -X- _ O
into -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
to -X- _ O
build -X- _ O
another -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
outperform -X- _ O
the -X- _ O
seed -X- _ O
model -X- _ O
due -X- _ O
to -X- _ O
more -X- _ O
train- -X- _ O
ing -X- _ O
data -X- _ O
exposure -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
small -X- _ O
amounts -X- _ O
of -X- _ O
supervised -X- _ O
data -X- _ O
to -X- _ O
unify -X- _ O
the -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
modeling -X- _ O
space -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
self -X- _ B-TaskName
- -X- _ I-TaskName
supervised -X- _ I-TaskName
speech -X- _ I-TaskName
training -X- _ I-TaskName
in -X- _ O
this -X- _ O
work -X- _ O
avoids -X- _ O
making -X- _ O
hard -X- _ O
predictions -X- _ O
and -X- _ O
uses -X- _ O
KL -X- _ O
divergence -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
mutual -X- _ O
information -X- _ O
between -X- _ O
masked -X- _ O
span -X- _ O
and -X- _ O
observed -X- _ O
feature -X- _ O
frames -X- _ O
. -X- _ O
Multi -X- _ B-TaskName
- -X- _ I-TaskName
task -X- _ I-TaskName
learning -X- _ I-TaskName
: -X- _ O
Due -X- _ O
to -X- _ O
data -X- _ O
scarcity -X- _ O
, -X- _ O
multi- -X- _ O
task -X- _ O
learning -X- _ O
is -X- _ O
widely -X- _ O
adopted -X- _ O
to -X- _ O
leverage -X- _ O
parallel -X- _ O
text -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
ST -X- _ B-TaskName
( -X- _ O
Weiss -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Anasta- -X- _ O
sopoulos -X- _ O
and -X- _ O
Chiang -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Those -X- _ O
methods -X- _ O
primarily -X- _ O
use -X- _ O
super- -X- _ O
vised -X- _ O
speech -X- _ O
data -X- _ O
sets -X- _ O
during -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
task -X- _ I-TaskName
learning -X- _ I-TaskName
, -X- _ O
whereas -X- _ O
our -X- _ O
method -X- _ O
can -X- _ O
leverage -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
unlabeled -X- _ O
speech -X- _ O
data -X- _ O
during -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
even -X- _ O
further -X- _ O
. -X- _ O
A -X- _ O
concurrent -X- _ O
work -X- _ O
from -X- _ O
Ao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
also -X- _ O
proposes -X- _ O
to -X- _ O
jointly -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
text -X- _ B-TaskName
to -X- _ I-TaskName
speech -X- _ I-TaskName
application -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
fully -X- _ O
unsupervised -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
focuses -X- _ O
on -X- _ O
taking -X- _ O
advan- -X- _ O
tage -X- _ O
of -X- _ O
the -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
joint -X- _ O
speech -X- _ O
text -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
demon- -X- _ O
strate -X- _ O
the -X- _ O
efﬁcacy -X- _ O
of -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
in -X- _ O
pre- -X- _ O
training -X- _ O
. -X- _ O
Another -X- _ O
concurrent -X- _ O
work -X- _ O
is -X- _ O
from -X- _ O
Bapna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
focuses -X- _ O
on -X- _ O
speech -X- _ O
encoder -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
using -X- _ O
both -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
emphasizes -X- _ O
the -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
frame- -X- _ O
work -X- _ O
and -X- _ O
training -X- _ O
both -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O
3 -X- _ O
Method -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
are -X- _ O
the -X- _ O
two -X- _ O
main -X- _ O
downstream -X- _ O
tasks -X- _ O
for -X- _ O
the -X- _ O
proposed -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
depicts -X- _ O
our -X- _ O
joint -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
framework -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
four -X- _ O
subtasks -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
( -X- _ B-TaskName
Self- -X- _ I-TaskName
) -X- _ I-TaskName
supervised -X- _ I-TaskName
Text -X- _ I-TaskName
to -X- _ I-TaskName
Text -X- _ I-TaskName
subtask -X- _ O
( -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
) -X- _ O
2.Self -X- _ B-TaskName
- -X- _ I-TaskName
supervised -X- _ I-TaskName
Speech -X- _ I-TaskName
Learning -X- _ I-TaskName
subtask -X- _ O
( -X- _ O
SSL -X- _ B-TaskName
) -X- _ O
1489 -X- _ O
3.Supervised -X- _ B-TaskName
Speech -X- _ I-TaskName
to -X- _ I-TaskName
Phoneme -X- _ I-TaskName
classiﬁcation -X- _ I-TaskName
subtask -X- _ O
( -X- _ O
S2P -X- _ B-TaskName
) -X- _ O
4.Supervised -X- _ B-TaskName
AED -X- _ I-TaskName
based -X- _ I-TaskName
Speech -X- _ I-TaskName
to -X- _ I-TaskName
Text -X- _ I-TaskName
sub- -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
ST -X- _ B-TaskName
or -X- _ O
ASR -X- _ B-TaskName
( -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
) -X- _ O
The -X- _ O
choice -X- _ O
of -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
ASR -X- _ B-TaskName
, -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
is -X- _ O
a -X- _ O
denoising -X- _ B-TaskName
autoencoder -X- _ I-TaskName
task -X- _ O
( -X- _ O
BART -X- _ B-MethodName
) -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
while -X- _ O
ST -X- _ B-TaskName
utilizes -X- _ O
a -X- _ O
text -X- _ O
based -X- _ O
neural -X- _ O
ma- -X- _ O
chine -X- _ O
translation -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
is -X- _ O
a -X- _ O
self- -X- _ B-TaskName
supervised -X- _ I-TaskName
speech -X- _ I-TaskName
learning -X- _ I-TaskName
task -X- _ O
to -X- _ O
leverage -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
unlabelled -X- _ O
speech -X- _ O
data -X- _ O
optimized -X- _ O
by -X- _ O
the -X- _ O
masked -X- _ O
prediction -X- _ O
loss -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
two -X- _ O
supervised -X- _ O
speech -X- _ O
tasks -X- _ O
( -X- _ O
S2P -X- _ B-TaskName
and -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
) -X- _ O
unify -X- _ O
two -X- _ O
modalities -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
, -X- _ O
into -X- _ O
one -X- _ O
modeling -X- _ O
space -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
the -X- _ O
subtasks -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
are -X- _ O
complementary -X- _ O
, -X- _ O
while -X- _ O
sub- -X- _ O
task -X- _ O
interference -X- _ O
is -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
ST -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
at -X- _ O
some -X- _ O
encoder -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
two -X- _ O
different -X- _ O
conﬁgurations -X- _ O
: -X- _ O
fully -X- _ B-MethodName
shared -X- _ I-MethodName
encoder -X- _ I-MethodName
( -X- _ O
FSE -X- _ B-MethodName
) -X- _ O
( -X- _ O
Fig- -X- _ O
ure -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
partially -X- _ B-MethodName
shared -X- _ I-MethodName
encoder -X- _ I-MethodName
( -X- _ O
PSE -X- _ B-MethodName
) -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
ST -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
FSE -X- _ B-MethodName
conﬁguration -X- _ O
aims -X- _ O
to -X- _ O
en- -X- _ O
courage -X- _ O
information -X- _ O
sharing -X- _ O
between -X- _ O
different -X- _ O
sub- -X- _ O
tasks -X- _ O
while -X- _ O
the -X- _ O
PSE -X- _ B-MethodName
conﬁguration -X- _ O
tries -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
information -X- _ O
sharing -X- _ O
between -X- _ O
encoder -X- _ O
only -X- _ O
sub- -X- _ O
tasks -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
SSL -X- _ B-TaskName
and -X- _ O
S2P -X- _ B-TaskName
, -X- _ O
and -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
AED -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
subtask -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
and -X- _ O
S2T. -X- _ B-TaskName
More -X- _ O
sub- -X- _ O
task -X- _ O
interference -X- _ O
analysis -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
subsec- -X- _ O
tion -X- _ O
5.2 -X- _ O
. -X- _ O
We -X- _ O
describe -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
each -X- _ O
subtask -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
subsections.3.1 -X- _ O
( -X- _ O
Self- -X- _ O
) -X- _ O
supervised -X- _ O
text -X- _ O
to -X- _ O
text -X- _ O
subtask -X- _ O
In -X- _ O
the -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
ST -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
a -X- _ O
text -X- _ O
generator -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
encoder -X- _ O
outputs -X- _ O
. -X- _ O
Large -X- _ O
amounts -X- _ O
of -X- _ O
training -X- _ O
sam- -X- _ O
ples -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
cover -X- _ O
different -X- _ O
linguistic -X- _ O
as- -X- _ O
pects -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
Abundant -X- _ O
text -X- _ O
is -X- _ O
an -X- _ O
ideal -X- _ O
supplement -X- _ O
to -X- _ O
the -X- _ O
limited -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
corpus -X- _ O
. -X- _ O
Assume -X- _ O
the -X- _ O
target -X- _ O
text -X- _ O
sequence -X- _ O
is -X- _ O
Y= -X- _ O
( -X- _ O
y -X- _ O
; -X- _ O
y -X- _ O
; -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
its -X- _ O
corresponding -X- _ O
corrupted -X- _ O
version -X- _ O
, -X- _ O
X -X- _ O
= -X- _ O
N -X- _ O
( -X- _ O
Y -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
x -X- _ O
; -X- _ O
; -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
created -X- _ O
by -X- _ O
masking -X- _ O
or -X- _ O
replacing -X- _ O
token -X- _ O
spans -X- _ O
inY -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
is -X- _ O
ST -X- _ O
, -X- _ O
Xis -X- _ O
the -X- _ O
correspond- -X- _ O
ing -X- _ O
source -X- _ O
token -X- _ O
sequence -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
optimized -X- _ O
by -X- _ O
maximizing -X- _ O
cross -X- _ O
entropy -X- _ O
L=Xlogp -X- _ O
( -X- _ O
yjy -X- _ O
; -X- _ O
X -X- _ O
) -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
In -X- _ O
this -X- _ O
subtask -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
convert -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
into -X- _ O
the -X- _ O
corresponding -X- _ O
pronunciation -X- _ O
form -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
phoneme -X- _ O
sequence -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
easier -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
encoder -X- _ O
outputs -X- _ O
from -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
purple -X- _ O
and -X- _ O
black -X- _ O
lines -X- _ O
in -X- _ O
Fig- -X- _ O
ure -X- _ O
1 -X- _ O
describe -X- _ O
the -X- _ O
data -X- _ O
ﬂow -X- _ O
in -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
. -X- _ O
3.2 -X- _ O
Self -X- _ O
- -X- _ O
supervised -X- _ O
speech -X- _ O
subtask -X- _ O
The -X- _ O
SSL -X- _ O
subtask -X- _ O
aims -X- _ O
to -X- _ O
leverage -X- _ O
vast -X- _ O
amounts -X- _ O
of -X- _ O
unlabelled -X- _ O
speech -X- _ O
data -X- _ O
and -X- _ O
learn -X- _ O
general -X- _ O
speech -X- _ O
representations -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
conﬁguration -X- _ O
follows -X- _ O
wav2vec2.0 -X- _ O
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
speech -X- _ O
model -X- _ O
includes -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
a1490context -X- _ O
encoder -X- _ O
. -X- _ O
The -X- _ O
context -X- _ O
encoder -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
If -X- _ O
ASR -X- _ B-TaskName
is -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
context -X- _ O
encoder -X- _ O
includes -X- _ O
one -X- _ O
extra -X- _ O
shared -X- _ O
encoder -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
different -X- _ O
frame- -X- _ O
works -X- _ O
for -X- _ O
the -X- _ O
ST -X- _ B-TaskName
and -X- _ O
ASR -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
to -X- _ O
reduce -X- _ O
interference -X- _ O
among -X- _ O
subtasks -X- _ O
. -X- _ O
The -X- _ O
detailed -X- _ O
subtask -X- _ O
interference -X- _ O
is -X- _ O
discussed -X- _ O
in -X- _ O
subsection -X- _ O
5.2 -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
masked -X- _ O
KL -X- _ O
divergence -X- _ O
loss -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
two- -X- _ O
pass -X- _ O
computation -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
speech -X- _ O
input -X- _ O
S= -X- _ O
( -X- _ O
s -X- _ O
; -X- _ O
s -X- _ O
; -X- _ O
; -X- _ O
s -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
context -X- _ O
encoder -X- _ O
outputs -X- _ O
are -X- _ O
Z= -X- _ O
( -X- _ O
z -X- _ O
; -X- _ O
z -X- _ O
; -X- _ O
; -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
O= -X- _ O
( -X- _ O
o -X- _ O
; -X- _ O
o -X- _ O
; -X- _ O
; -X- _ O
o -X- _ O
) -X- _ O
respectively -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
speech -X- _ O
input -X- _ O
is -X- _ O
down -X- _ O
- -X- _ O
sampled -X- _ O
by -X- _ O
the -X- _ O
feature -X- _ O
ex- -X- _ O
tractor -X- _ O
and -X- _ O
T -X- _ O
> -X- _ O
T. -X- _ O
In -X- _ O
the -X- _ O
ﬁrst -X- _ O
pass -X- _ O
, -X- _ O
the -X- _ O
out- -X- _ O
putOis -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
phoneme -X- _ O
embedding -X- _ O
E= -X- _ O
( -X- _ O
e -X- _ O
; -X- _ O
e -X- _ O
; -X- _ O
; -X- _ O
e -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
from -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
sub- -X- _ O
task -X- _ O
described -X- _ O
in -X- _ O
subsection -X- _ O
3.1 -X- _ O
. -X- _ O
Iis -X- _ O
the -X- _ O
phoneme -X- _ O
vocabulary -X- _ O
size -X- _ O
. -X- _ O
The -X- _ O
predicted -X- _ O
phoneme -X- _ O
distribu- -X- _ O
tionp -X- _ O
( -X- _ O
oje -X- _ O
) -X- _ O
is -X- _ O
deﬁned -X- _ O
as -X- _ O
p -X- _ O
( -X- _ O
oje -X- _ O
) -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
oe -X- _ O
) -X- _ O
Pexp -X- _ O
( -X- _ O
oe -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
pass -X- _ O
, -X- _ O
speech -X- _ O
feature -X- _ O
spans -X- _ O
^ZZ -X- _ O
are -X- _ O
selected -X- _ O
and -X- _ O
corrupted -X- _ O
as -X- _ O
wav2vec2.0 -X- _ B-MethodName
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
^Ois -X- _ O
the -X- _ O
corresponding -X- _ O
context -X- _ O
en- -X- _ O
coder -X- _ O
output -X- _ O
from -X- _ O
^Z. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
corrupted -X- _ O
p -X- _ O
( -X- _ O
^oje -X- _ O
) -X- _ O
being -X- _ O
similar -X- _ O
as -X- _ O
p -X- _ O
( -X- _ O
oje -X- _ O
) -X- _ O
by -X- _ O
minimizing -X- _ O
KL -X- _ O
divergence -X- _ O
. -X- _ O
L=XXp -X- _ O
( -X- _ O
oje -X- _ O
) -X- _ O
logp -X- _ O
( -X- _ O
^oje -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
oje -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
masked -X- _ O
prediction -X- _ O
loss -X- _ O
, -X- _ O
in- -X- _ O
stead -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
hard -X- _ O
discretized -X- _ O
label -X- _ O
for -X- _ O
the -X- _ O
masked -X- _ O
frames -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
soft -X- _ O
label -X- _ O
prediction -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
predicted -X- _ O
phoneme -X- _ O
distribution -X- _ O
from -X- _ O
the -X- _ O
ﬁrst -X- _ O
pass -X- _ O
, -X- _ O
to -X- _ O
learn -X- _ O
speech -X- _ O
representation -X- _ O
and -X- _ O
avoid -X- _ O
the -X- _ O
hard -X- _ O
prediction -X- _ O
errors -X- _ O
. -X- _ O
3.3 -X- _ O
Supervised -X- _ O
speech -X- _ O
to -X- _ O
phoneme -X- _ O
classiﬁcation -X- _ O
The -X- _ O
S2P -X- _ B-TaskName
subtask -X- _ O
is -X- _ O
employed -X- _ O
to -X- _ O
unify -X- _ O
the -X- _ O
self- -X- _ O
supervised -X- _ O
trained -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
models -X- _ O
. -X- _ O
It -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
subtask -X- _ O
, -X- _ O
a -X- _ O
transcribed -X- _ O
ASR -X- _ B-DatasetName
data -X- _ O
set -X- _ O
is -X- _ O
used -X- _ O
and -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
frame -X- _ O
level -X- _ O
phoneme -X- _ O
labels -X- _ O
. -X- _ O
A -X- _ O
HMM -X- _ B-MethodName
- -X- _ I-MethodName
GMM -X- _ I-MethodName
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
transcribed -X- _ O
dataset -X- _ O
using -X- _ O
Kaldi -X- _ O
( -X- _ O
Povey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
frame- -X- _ O
level -X- _ O
labels -X- _ O
with -X- _ O
forced -X- _ O
- -X- _ O
alignment -X- _ O
. -X- _ O
The -X- _ O
phoneme -X- _ O
classiﬁcation -X- _ O
task -X- _ O
is -X- _ O
optimized -X- _ O
with -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
, -X- _ O
L=Xlogp -X- _ O
( -X- _ O
oje -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
wherea -X- _ O
( -X- _ O
j -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
phoneme -X- _ O
label -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
encoder -X- _ O
output -X- _ O
o. -X- _ O
The -X- _ O
data -X- _ O
ﬂow -X- _ O
in -X- _ O
the -X- _ O
S2P -X- _ B-TaskName
subtask -X- _ O
is -X- _ O
depicted -X- _ O
with -X- _ O
steelblue -X- _ O
lines -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
3.4 -X- _ O
Supervised -X- _ B-MethodName
AED -X- _ I-MethodName
based -X- _ O
speech -X- _ O
to -X- _ O
text -X- _ O
subtask -X- _ O
Besides -X- _ O
the -X- _ O
S2P -X- _ B-TaskName
subtask -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
the -X- _ O
potential -X- _ O
downstream -X- _ O
AED -X- _ B-TaskName
based -X- _ O
task -X- _ O
, -X- _ O
i.e. -X- _ O
ASR -X- _ B-TaskName
or -X- _ O
ST -X- _ B-TaskName
, -X- _ O
as -X- _ O
another -X- _ O
aux- -X- _ O
iliary -X- _ O
subtask -X- _ O
during -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O
In -X- _ O
many -X- _ O
speech -X- _ O
translation -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
MuST- -X- _ B-DatasetName
C -X- _ I-DatasetName
( -X- _ O
Gangi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
CoV -X- _ B-DatasetName
oST -X- _ I-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
both -X- _ O
speech -X- _ O
transcription -X- _ O
and -X- _ O
trans- -X- _ O
lation -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
speech -X- _ O
transcription -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
S2P -X- _ B-TaskName
subtask -X- _ O
while -X- _ O
the -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
can -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
translation -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
hope -X- _ O
this -X- _ O
auxiliary -X- _ O
task -X- _ O
would -X- _ O
make -X- _ O
the -X- _ O
transition -X- _ O
from -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
to -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
smooth -X- _ O
and -X- _ O
result -X- _ O
in -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
components -X- _ O
involved -X- _ O
during -X- _ O
optimization -X- _ O
are -X- _ O
con- -X- _ O
nected -X- _ O
with -X- _ O
blue -X- _ O
lines -X- _ O
in -X- _ O
encoder -X- _ O
and -X- _ O
black -X- _ O
lines -X- _ O
in -X- _ O
decoder -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
cross -X- _ O
entropy -X- _ O
criterion -X- _ O
, -X- _ O
L=Xlogp -X- _ O
( -X- _ O
yjy -X- _ O
; -X- _ O
O -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
whereOis -X- _ O
the -X- _ O
input -X- _ O
speech -X- _ O
and -X- _ O
Y= -X- _ O
( -X- _ O
y -X- _ O
; -X- _ O
; -X- _ O
y -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
target -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
overall -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
loss -X- _ O
is -X- _ O
deﬁned -X- _ O
as -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
four -X- _ O
losses -X- _ O
discussed -X- _ O
above -X- _ O
L -X- _ O
= -X- _ O
L+ -X- _ O
L+ -X- _ O
L+ -X- _ O
L -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
where -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
task -X- _ O
weights -X- _ O
for -X- _ O
the -X- _ O
SSL -X- _ B-TaskName
, -X- _ O
S2P -X- _ B-TaskName
and -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtasks -X- _ O
respectively -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
shared -X- _ O
encoder -X- _ O
in- -X- _ O
puts -X- _ O
come -X- _ O
from -X- _ O
two -X- _ O
sources -X- _ O
, -X- _ O
either -X- _ O
from -X- _ O
speech -X- _ O
encoder -X- _ O
outputs -X- _ O
in -X- _ O
the -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
or -X- _ O
phoneme -X- _ O
embeddings -X- _ O
in -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
. -X- _ O
The -X- _ O
shared -X- _ O
en- -X- _ O
coder -X- _ O
inputs -X- _ O
might -X- _ O
be -X- _ O
in -X- _ O
different -X- _ O
numerical -X- _ O
scales -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
stabilize -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
training -X- _ O
, -X- _ O
a -X- _ O
Lay- -X- _ B-MethodName
erNorm -X- _ I-MethodName
( -X- _ O
Ba -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
shared -X- _ O
encoder -X- _ O
inputs -X- _ O
and -X- _ O
places -X- _ O
those -X- _ O
inputs -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
numerical -X- _ O
scale -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1.14914 -X- _ O
Experimental -X- _ O
setting -X- _ O
In -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
train -X- _ O
modules -X- _ O
with -X- _ O
the -X- _ O
T2 -X- _ O
T -X- _ O
subtask -X- _ O
until -X- _ O
they -X- _ O
are -X- _ O
converged -X- _ O
. -X- _ O
It -X- _ O
helps -X- _ O
to -X- _ O
stabilize -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
achieve -X- _ O
a -X- _ O
better -X- _ O
result -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
is -X- _ O
jointly -X- _ O
optimized -X- _ O
with -X- _ O
all -X- _ O
subtasks -X- _ O
mentioned -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
is -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
optimizing -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
and -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtasks -X- _ O
. -X- _ O
Two -X- _ O
encoder -X- _ O
- -X- _ O
only -X- _ O
subtasks -X- _ O
( -X- _ O
SSL -X- _ B-TaskName
and -X- _ O
S2P -X- _ B-TaskName
) -X- _ O
are -X- _ O
dropped -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
learnt -X- _ O
good -X- _ O
speech -X- _ O
representa- -X- _ O
tion -X- _ O
from -X- _ O
the -X- _ O
unlabeled -X- _ O
speech -X- _ O
data -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Two -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
ST -X- _ B-TaskName
, -X- _ O
are -X- _ O
ex- -X- _ O
amined -X- _ O
. -X- _ O
The -X- _ O
ASR -X- _ O
system -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
four -X- _ O
L -X- _ O
( -X- _ O
Panayotov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
evaluation -X- _ O
sets -X- _ O
: -X- _ O
dev -X- _ O
- -X- _ O
clean -X- _ O
, -X- _ O
dev -X- _ O
- -X- _ O
other -X- _ O
, -X- _ O
test -X- _ O
- -X- _ O
clean -X- _ O
and -X- _ O
test -X- _ O
- -X- _ O
other -X- _ O
. -X- _ O
WER -X- _ B-MetricName
is -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O
ST -X- _ B-TaskName
mod- -X- _ O
els -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
two -X- _ O
translation -X- _ O
directions -X- _ O
: -X- _ O
English -X- _ O
- -X- _ O
Spanish -X- _ O
( -X- _ O
EN -X- _ O
- -X- _ O
ES -X- _ O
) -X- _ O
and -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
( -X- _ O
EN- -X- _ O
FR -X- _ O
) -X- _ O
. -X- _ O
Case -X- _ O
- -X- _ O
sensitive -X- _ O
detokenized -X- _ O
( -X- _ O
Post -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
reported -X- _ O
on -X- _ O
the -X- _ O
tst -X- _ B-DatasetName
- -X- _ I-DatasetName
COMMON -X- _ I-DatasetName
testset -X- _ O
from -X- _ O
MST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
( -X- _ O
Gangi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
ST -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
60k -X- _ O
hours -X- _ O
of -X- _ O
unlabelled -X- _ O
English -X- _ O
speech -X- _ O
data -X- _ O
from -X- _ O
Libri- -X- _ B-DatasetName
light -X- _ I-DatasetName
( -X- _ O
Kahn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
self- -X- _ O
supervised -X- _ O
speech -X- _ O
task -X- _ O
if -X- _ O
not -X- _ O
speciﬁcally -X- _ O
men- -X- _ O
tioned -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
the -X- _ O
same -X- _ O
labelled -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
supervised -X- _ O
learning -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
L -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
MST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
for -X- _ O
ST -X- _ B-TaskName
. -X- _ O
For -X- _ O
ASR -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
L- -X- _ B-DatasetName
language -X- _ I-DatasetName
model -X- _ I-DatasetName
( -X- _ O
LM -X- _ O
) -X- _ O
training -X- _ O
dataset -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
monolingual -X- _ B-MethodName
BART -X- _ I-MethodName
model -X- _ O
. -X- _ O
For -X- _ O
ST -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
parallel -X- _ O
training -X- _ O
corpus -X- _ O
from -X- _ O
WMT -X- _ B-DatasetName
. -X- _ O
More -X- _ O
details -X- _ O
about -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
could -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
4.1 -X- _ O
Model -X- _ O
conﬁguration -X- _ O
The -X- _ O
model -X- _ O
takes -X- _ O
raw -X- _ O
speech -X- _ O
audio -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
The -X- _ O
feature -X- _ O
encoder -X- _ O
contains -X- _ O
seven -X- _ O
blocks -X- _ O
and -X- _ O
the -X- _ O
tem- -X- _ O
poral -X- _ O
convolutions -X- _ O
in -X- _ O
each -X- _ O
block -X- _ O
have -X- _ O
512 -X- _ O
chan- -X- _ O
nels -X- _ O
with -X- _ O
strides -X- _ O
( -X- _ O
5,2,2,2,2,2,2 -X- _ O
) -X- _ O
and -X- _ O
kernel -X- _ O
widths -X- _ O
( -X- _ O
10,3,3,3,3,2,2 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
speech -X- _ O
encoder -X- _ O
, -X- _ O
shared -X- _ O
en- -X- _ O
coder -X- _ O
and -X- _ O
shared -X- _ O
decoder -X- _ O
are -X- _ O
all -X- _ O
with -X- _ O
6 -X- _ O
transformer -X- _ O
layers -X- _ O
, -X- _ O
model -X- _ O
dimension -X- _ O
768 -X- _ O
, -X- _ O
inner -X- _ O
dimension -X- _ O
( -X- _ O
FFN -X- _ O
) -X- _ O
3,072 -X- _ O
and -X- _ O
8 -X- _ O
attention -X- _ O
heads -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
Pre- -X- _ O
LN -X- _ O
in -X- _ O
the -X- _ O
transformer -X- _ O
block -X- _ O
as -X- _ O
Xiong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
is -X- _ O
169 -X- _ O
million -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
weight -X- _ O
for -X- _ O
each -X- _ O
subtask -X- _ O
is -X- _ O
set -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
mini -X- _ O
- -X- _ O
batches -X- _ O
used -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
numbers -X- _ O
for -X- _ O
each -X- _ O
subtasks -X- _ O
are -X- _ O
1.0 -X- _ O
, -X- _ O
7.0 -X- _ O
, -X- _ O
0.5 -X- _ O
and -X- _ O
0.5 -X- _ O
for -X- _ O
theT2 -X- _ B-TaskName
T -X- _ I-TaskName
, -X- _ O
SSL -X- _ B-TaskName
, -X- _ O
S2P -X- _ B-TaskName
and -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtasks -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
mask -X- _ O
30 -X- _ O
% -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
T2 -X- _ O
T -X- _ O
BART -X- _ O
subtask -X- _ O
in -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
no -X- _ O
masking -X- _ O
is -X- _ O
applied -X- _ O
for -X- _ O
the -X- _ O
T2 -X- _ O
T -X- _ O
NMT -X- _ O
subtask -X- _ O
in -X- _ O
the -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
7 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
feature -X- _ O
frames -X- _ O
in -X- _ O
the -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
and -X- _ O
3 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
feature -X- _ O
frames -X- _ O
in -X- _ O
the -X- _ O
two -X- _ O
supervised -X- _ O
speech -X- _ O
subtasks -X- _ O
are -X- _ O
randomly -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
mask -X- _ O
span -X- _ O
starting -X- _ O
time -X- _ O
- -X- _ O
step -X- _ O
. -X- _ O
The -X- _ O
mask -X- _ O
span -X- _ O
length -X- _ O
is -X- _ O
10 -X- _ O
. -X- _ O
The -X- _ O
masking -X- _ B-HyperparameterName
percentage -X- _ I-HyperparameterName
is -X- _ O
selected -X- _ O
via -X- _ O
grid -X- _ O
search -X- _ O
( -X- _ O
( -X- _ O
20 -X- _ B-HyperparameterValue
; -X- _ O
30 -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
text -X- _ B-TaskName
masking -X- _ I-TaskName
, -X- _ O
( -X- _ O
6 -X- _ B-HyperparameterValue
; -X- _ O
6:5 -X- _ B-HyperparameterValue
; -X- _ O
7 -X- _ B-HyperparameterValue
) -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ B-HyperparameterValue
; -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
for -X- _ O
speech -X- _ B-TaskName
masking -X- _ I-TaskName
) -X- _ O
. -X- _ O
Additional -X- _ O
experimental -X- _ O
details -X- _ O
such -X- _ O
as -X- _ O
optimization -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
5 -X- _ O
Experimental -X- _ O
results -X- _ O
5.1 -X- _ O
Main -X- _ O
results -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
L -X- _ O
recognition -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Recognition -X- _ O
results -X- _ O
without -X- _ O
/ -X- _ O
with -X- _ O
an -X- _ O
decoding -X- _ O
LM -X- _ O
are -X- _ O
reported -X- _ O
. -X- _ O
The -X- _ O
WERs -X- _ B-MetricName
obtained -X- _ O
with -X- _ O
LM -X- _ O
are -X- _ O
displayed -X- _ O
within -X- _ O
“ -X- _ O
( -X- _ O
) -X- _ O
” -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
column -X- _ O
shows -X- _ O
the -X- _ O
dataset -X- _ O
used -X- _ O
as -X- _ O
unlabeled -X- _ O
data -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
“ -X- _ O
LS-960 -X- _ O
” -X- _ O
stands -X- _ O
for -X- _ O
L -X- _ O
training -X- _ O
dataset -X- _ O
and -X- _ O
“ -X- _ O
LV-60k -X- _ O
” -X- _ O
is -X- _ O
the -X- _ O
60,000 -X- _ O
hours -X- _ O
Librilight -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
decoding -X- _ O
LM -X- _ O
is -X- _ O
built -X- _ O
with -X- _ O
theL -X- _ O
text -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
text -X- _ O
corpus -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
shows -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
wav2vec -X- _ O
2.0 -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
CTC -X- _ O
based -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
. -X- _ O
Second -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
presents -X- _ O
re- -X- _ O
sults -X- _ O
from -X- _ O
two -X- _ O
AED -X- _ B-HyperparameterName
based -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
mainly -X- _ O
compare -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
with -X- _ O
those -X- _ O
two -X- _ O
AED -X- _ B-HyperparameterName
systems -X- _ O
. -X- _ O
LAS -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
LSTM -X- _ B-HyperparameterName
based -X- _ O
system -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
L -X- _ O
data -X- _ O
only -X- _ O
. -X- _ O
Trans- -X- _ B-HyperparameterName
former -X- _ I-HyperparameterName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
and -X- _ O
jointly -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
text -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
from -X- _ O
STPT -X- _ B-HyperparameterName
models -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
third -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
. -X- _ O
The -X- _ O
fourth -X- _ O
row -X- _ O
shows -X- _ O
results -X- _ O
from -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
960 -X- _ O
hours -X- _ O
L -X- _ O
training -X- _ O
data -X- _ O
as -X- _ O
the -X- _ O
unlabelled -X- _ O
pre- -X- _ O
training -X- _ O
data -X- _ O
while -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
ﬁfth -X- _ O
row -X- _ O
is -X- _ O
pre- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
60k -X- _ O
hours -X- _ O
Librilight -X- _ B-DatasetName
data -X- _ O
. -X- _ O
STPT -X- _ O
outperforms -X- _ O
all -X- _ O
previous -X- _ O
reported -X- _ O
AED -X- _ B-HyperparameterName
- -X- _ O
based -X- _ O
sys- -X- _ O
tems -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
1.2 -X- _ O
absolute -X- _ O
WER -X- _ O
reduction -X- _ O
obtained -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
jointly -X- _ O
trained -X- _ O
transformer -X- _ O
model -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
STPT -X- _ B-HyperparameterName
also -X- _ O
reduces -X- _ O
2.2 -X- _ O
WER -X- _ B-MetricName
compared -X- _ O
with -X- _ O
the -X- _ O
CTC -X- _ B-HyperparameterName
based -X- _ O
wav2vec -X- _ B-HyperparameterName
model -X- _ O
if -X- _ O
no -X- _ O
external -X- _ O
LM -X- _ O
is -X- _ O
applied -X- _ O
and -X- _ O
achieves -X- _ O
comparable -X- _ O
WERs -X- _ B-MetricName
when -X- _ O
it -X- _ O
is -X- _ O
decoded -X- _ O
with -X- _ O
a -X- _ O
LM -X- _ B-HyperparameterName
. -X- _ O
One -X- _ O
interesting -X- _ O
observation -X- _ O
is -X- _ O
the -X- _ O
de- -X- _ O
coding -X- _ O
LM -X- _ O
is -X- _ O
not -X- _ O
very -X- _ O
helpful -X- _ O
for -X- _ O
the -X- _ O
STPT -X- _ B-HyperparameterName
model,1492 -X- _ O
that -X- _ O
only -X- _ O
0.2 -X- _ O
WER -X- _ B-MetricName
reduction -X- _ O
is -X- _ O
observed -X- _ O
when -X- _ O
a -X- _ O
decoding -X- _ O
LM -X- _ B-HyperparameterName
is -X- _ O
applied -X- _ O
. -X- _ O
Other -X- _ O
systems -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
show -X- _ O
a -X- _ O
considerable -X- _ O
WER -X- _ B-MetricName
reduction -X- _ O
when -X- _ O
the -X- _ O
LM -X- _ O
is -X- _ O
applied -X- _ O
during -X- _ O
decoding -X- _ O
. -X- _ O
It -X- _ O
indi- -X- _ O
cates -X- _ O
that -X- _ O
our -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
stages -X- _ O
can -X- _ O
effectively -X- _ O
fuse -X- _ O
linguis- -X- _ O
tic -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
data -X- _ O
corpus -X- _ O
into -X- _ O
the -X- _ O
ASR -X- _ O
model -X- _ O
. -X- _ O
LM -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
required -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
text -X- _ O
corpus -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
results -X- _ O
from -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
60k -X- _ O
hours -X- _ O
Librilight -X- _ O
data -X- _ O
at -X- _ O
the -X- _ O
ﬁfth -X- _ O
row -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
LS-960 -X- _ O
STPT -X- _ B-HyperparameterName
model -X- _ O
, -X- _ O
Librilight -X- _ B-DatasetName
data -X- _ O
helps -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
WER -X- _ B-MetricName
in -X- _ O
two -X- _ O
difﬁcult -X- _ O
“ -X- _ O
other -X- _ O
” -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
Librilight -X- _ O
as -X- _ O
unlabelled -X- _ O
data -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
speech -X- _ O
translation -X- _ O
re- -X- _ O
sults -X- _ O
on -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
datasets -X- _ O
. -X- _ O
Row -X- _ O
one -X- _ O
to -X- _ O
four -X- _ O
are -X- _ O
the -X- _ O
latest -X- _ O
results -X- _ O
from -X- _ O
literature -X- _ O
. -X- _ O
Row -X- _ O
one -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
speech -X- _ O
to -X- _ O
text -X- _ O
trans- -X- _ O
lation -X- _ O
task -X- _ O
alone -X- _ O
. -X- _ O
Row -X- _ O
two -X- _ O
and -X- _ O
three -X- _ O
present -X- _ O
re- -X- _ O
sults -X- _ O
from -X- _ O
two -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
systems -X- _ O
with -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
jointly -X- _ O
trained -X- _ O
together -X- _ O
. -X- _ O
Row -X- _ O
four -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
system -X- _ O
reported -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre- -X- _ O
trained -X- _ O
wav2vec -X- _ B-HyperparameterName
2.0 -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
model -X- _ O
, -X- _ O
then -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
the -X- _ O
joint -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
train- -X- _ O
ing -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
achieves -X- _ O
2.3 -X- _ B-MetricValue
and -X- _ O
1.7 -X- _ B-MetricValue
more -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
for -X- _ O
EN -X- _ O
- -X- _ O
ES -X- _ O
and -X- _ O
EN -X- _ O
- -X- _ O
FR -X- _ O
translation -X- _ O
directions -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
system -X- _ O
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
5.2 -X- _ O
Impact -X- _ O
of -X- _ O
model -X- _ O
structure -X- _ O
Interference -X- _ O
among -X- _ O
subtasks -X- _ O
may -X- _ O
impede -X- _ O
the -X- _ O
progress -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
and -X- _ O
lead -X- _ O
to -X- _ O
inferior -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
the -X- _ O
task -X- _ O
interfer -X- _ O
- -X- _ O
ence -X- _ O
via -X- _ O
comparing -X- _ O
the -X- _ O
gradient -X- _ O
similarity -X- _ O
between -X- _ O
pair -X- _ O
subtasks -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
FSE -X- _ O
conﬁguration -X- _ O
discussed -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
and -X- _ O
accumulate -X- _ O
gradients -X- _ O
from -X- _ O
one -X- _ O
of -X- _ O
four -X- _ O
jointly -X- _ O
trained -X- _ O
subtasks -X- _ O
. -X- _ O
We -X- _ O
prepare -X- _ O
20batches -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
for -X- _ O
each -X- _ O
subtask -X- _ O
, -X- _ O
and -X- _ O
retrieve -X- _ O
the -X- _ O
accu- -X- _ O
mulated -X- _ O
gradients -X- _ O
by -X- _ O
sending -X- _ O
these -X- _ O
batches -X- _ O
to -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
pairwise -X- _ O
cosine -X- _ O
sim- -X- _ O
ilarity -X- _ O
between -X- _ O
gradients -X- _ O
from -X- _ O
any -X- _ O
two -X- _ O
subtasks -X- _ O
. -X- _ O
The -X- _ O
pairwise -X- _ O
subtask -X- _ O
gradient -X- _ O
similarity -X- _ O
from -X- _ O
the -X- _ O
shared -X- _ O
encoder -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
demonstrates -X- _ O
the -X- _ O
gradient -X- _ O
similarity -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
most -X- _ O
layers -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
similarities -X- _ O
are -X- _ O
small -X- _ O
. -X- _ O
No -X- _ O
serious -X- _ O
gradient -X- _ O
inter- -X- _ O
ference -X- _ O
is -X- _ O
observed -X- _ O
. -X- _ O
The -X- _ O
Figure -X- _ O
2 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
depicts -X- _ O
the -X- _ O
gradient -X- _ O
similarity -X- _ O
from -X- _ O
the -X- _ O
ST -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Com- -X- _ O
pared -X- _ O
with -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
S2 -X- _ O
T -X- _ O
and -X- _ O
T2 -X- _ O
T -X- _ O
subtasks -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
speech -X- _ O
translation -X- _ O
and -X- _ O
text -X- _ O
based -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
subtasks -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
interference -X- _ O
between -X- _ O
different -X- _ O
subtasks -X- _ O
is -X- _ O
signiﬁcant -X- _ O
as -X- _ O
large -X- _ O
positive -X- _ O
and -X- _ O
nega- -X- _ O
tive -X- _ O
gradient -X- _ O
similarities -X- _ O
are -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
third -X- _ O
and -X- _ O
ﬁfth -X- _ O
layers -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
task -X- _ O
gradients -X- _ O
in -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
and -X- _ O
no -X- _ O
obvious -X- _ O
task -X- _ O
interference -X- _ O
is -X- _ O
observed -X- _ O
within -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
for -X- _ O
both -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Detailed -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
is -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
C. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
task -X- _ O
interference -X- _ O
, -X- _ O
the -X- _ O
PSE -X- _ O
conﬁguration -X- _ O
is -X- _ O
proposed -X- _ O
for -X- _ O
the -X- _ O
ST -X- _ B-TaskName
pre- -X- _ O
training -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
presents -X- _ O
the -X- _ O
performance -X- _ O
com- -X- _ O
parison -X- _ O
between -X- _ O
two -X- _ O
conﬁgurations -X- _ O
on -X- _ O
both -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
we -X- _ O
list -X- _ O
the -X- _ O
ASR -X- _ O
results -X- _ O
using -X- _ O
100 -X- _ O
hours -X- _ O
labelled -X- _ O
speech -X- _ O
data -X- _ O
( -X- _ O
train -X- _ O
- -X- _ O
clean-100 -X- _ O
) -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
right -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
shows -X- _ O
the -X- _ O
BLEU -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
MST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
expected -X- _ O
, -X- _ O
the -X- _ O
FSE -X- _ O
conﬁguration -X- _ O
encourages -X- _ O
information -X- _ O
sharing -X- _ O
among -X- _ O
tasks -X- _ O
and -X- _ O
it -X- _ O
achieves -X- _ O
lower -X- _ O
WER -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
task -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
subtasks -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
the -X- _ O
PSE -X- _ B-HyperparameterName
conﬁguration1493 -X- _ O
minimizes -X- _ O
the -X- _ O
information -X- _ O
sharing -X- _ O
between -X- _ O
AED -X- _ O
subtasks -X- _ O
and -X- _ O
encoder -X- _ O
only -X- _ O
subtasks -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
leads -X- _ O
to -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
for -X- _ O
the -X- _ O
ST -X- _ B-TaskName
task -X- _ O
. -X- _ O
5.3 -X- _ O
Impact -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
The -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
connects -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
speech -X- _ O
modeling -X- _ O
and -X- _ O
uniﬁes -X- _ O
the -X- _ O
representation -X- _ O
from -X- _ O
different -X- _ O
modalities -X- _ O
. -X- _ O
An -X- _ O
interesting -X- _ O
question -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
investigate -X- _ O
is -X- _ O
how -X- _ O
much -X- _ O
supervised -X- _ O
data -X- _ O
is -X- _ O
enough -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
good -X- _ O
cross -X- _ O
modality -X- _ O
repre- -X- _ O
sentation -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
different -X- _ O
amounts -X- _ O
of -X- _ O
labelled -X- _ O
data -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
varied -X- _ O
from -X- _ O
960 -X- _ O
hours -X- _ O
( -X- _ O
the -X- _ O
full -X- _ O
dataset -X- _ O
) -X- _ O
, -X- _ O
100 -X- _ O
hours -X- _ O
( -X- _ O
train -X- _ O
- -X- _ O
clean-100 -X- _ O
) -X- _ O
and -X- _ O
10 -X- _ O
hours -X- _ O
as -X- _ O
( -X- _ O
Kahn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
ﬁrst -X- _ O
column -X- _ O
shows -X- _ O
the -X- _ O
amounts -X- _ O
of -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
available -X- _ O
during -X- _ O
the -X- _ O
pre- -X- _ O
training -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
column -X- _ O
presents -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
labelled -X- _ O
data -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
. -X- _ O
In -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
S2P -X- _ B-TaskName
and -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtasks -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
more -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
is -X- _ O
always -X- _ O
help- -X- _ O
ful -X- _ O
to -X- _ O
get -X- _ O
smaller -X- _ O
WER -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
the -X- _ O
full -X- _ O
L -X- _ O
train- -X- _ O
ing -X- _ O
dataset -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
WER -X- _ B-MetricName
are -X- _ O
3.3 -X- _ B-MetricValue
( -X- _ O
row -X- _ O
one -X- _ O
) -X- _ O
, -X- _ O
3.6 -X- _ B-MetricValue
( -X- _ O
row -X- _ O
two -X- _ O
) -X- _ O
and -X- _ O
4.0 -X- _ B-MetricValue
( -X- _ O
row -X- _ O
four -X- _ O
) -X- _ O
for -X- _ O
experiments -X- _ O
with -X- _ O
960 -X- _ O
, -X- _ O
100 -X- _ O
and -X- _ O
10 -X- _ O
hours -X- _ O
labelled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
still -X- _ O
able -X- _ O
to -X- _ O
obtain -X- _ O
good -X- _ O
speech -X- _ O
representa- -X- _ O
tions -X- _ O
even -X- _ O
with -X- _ O
small -X- _ O
amounts -X- _ O
of -X- _ O
labelled -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
row -X- _ O
four -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
10 -X- _ O
hours -X- _ O
labelled -X- _ O
data -X- _ O
, -X- _ O
then -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
with -X- _ O
960 -X- _ O
hours -X- _ O
su- -X- _ O
pervised -X- _ O
speech -X- _ O
data -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
achieve -X- _ O
an -X- _ O
average -X- _ O
4.0 -X- _ B-MetricValue
WER -X- _ B-MetricName
, -X- _ O
which -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
AED -X- _ B-HyperparameterName
systems -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
no- -X- _ O
tice -X- _ O
the -X- _ O
performance -X- _ O
degrades -X- _ O
quickly -X- _ O
if -X- _ O
only -X- _ O
small -X- _ O
amounts -X- _ O
of -X- _ O
labelled -X- _ O
speech -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
WER -X- _ B-MetricName
is -X- _ O
increased -X- _ O
to -X- _ O
24.6 -X- _ B-MetricValue
( -X- _ O
row -X- _ O
six -X- _ O
) -X- _ O
when -X- _ O
only -X- _ O
10 -X- _ O
hours -X- _ O
of -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
is -X- _ O
em- -X- _ O
ployed -X- _ O
in -X- _ O
both -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Another -X- _ O
question -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
is -X- _ O
the -X- _ O
gen- -X- _ O
eralizability -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
data -X- _ O
partitions -X- _ O
in -X- _ O
L -X- _ O
: -X- _ O
“ -X- _ O
clean -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
other -X- _ O
” -X- _ O
. -X- _ O
The -X- _ O
“ -X- _ O
clean -X- _ O
” -X- _ O
partition -X- _ O
is -X- _ O
supposed -X- _ O
to -X- _ O
be -X- _ O
“ -X- _ O
higher -X- _ O
recording -X- _ O
quality -X- _ O
and -X- _ O
with -X- _ O
accents -X- _ O
closer -X- _ O
to -X- _ O
US -X- _ O
English -X- _ O
” -X- _ O
while -X- _ O
the -X- _ O
“ -X- _ O
other -X- _ O
” -X- _ O
partition -X- _ O
is -X- _ O
difﬁcult -X- _ O
speakers -X- _ O
with -X- _ O
high -X- _ O
WER -X- _ B-MetricName
( -X- _ O
Panayotov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
four -X- _ O
data -X- _ O
partitions -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
to -X- _ O
simulate -X- _ O
the -X- _ O
mismatched -X- _ O
training -X- _ O
conditions -X- _ O
. -X- _ O
“ -X- _ O
train -X- _ O
- -X- _ O
clean-100 -X- _ O
” -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
pre- -X- _ O
training -X- _ O
“ -X- _ O
clean -X- _ O
” -X- _ O
data -X- _ O
set -X- _ O
( -X- _ O
“ -X- _ O
PT -X- _ O
C -X- _ O
” -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
ﬁrst -X- _ O
30,000 -X- _ O
utterance -X- _ O
from -X- _ O
“ -X- _ O
train -X- _ O
- -X- _ O
clean-360 -X- _ O
” -X- _ O
as -X- _ O
the -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
“ -X- _ O
clean -X- _ O
” -X- _ O
dataset -X- _ O
( -X- _ O
“ -X- _ O
FT -X- _ O
C -X- _ O
” -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
30,000 -X- _ O
ut-1494 -X- _ O
terances -X- _ O
and -X- _ O
the -X- _ O
following -X- _ O
30,000 -X- _ O
utterances -X- _ O
from -X- _ O
“ -X- _ O
train -X- _ O
- -X- _ O
other -X- _ O
” -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
“ -X- _ O
PT -X- _ O
O -X- _ O
” -X- _ O
) -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
“ -X- _ O
other -X- _ O
” -X- _ O
( -X- _ O
“ -X- _ O
FT -X- _ O
O -X- _ O
” -X- _ O
) -X- _ O
datasets -X- _ O
. -X- _ O
Each -X- _ O
dataset -X- _ O
includes -X- _ O
approximately -X- _ O
100 -X- _ O
hours -X- _ O
speech -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
under -X- _ O
4 -X- _ O
dif- -X- _ O
ferent -X- _ O
combinations -X- _ O
with -X- _ O
different -X- _ O
supervised -X- _ O
pre- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
aver- -X- _ O
age -X- _ O
WER -X- _ O
on -X- _ O
the -X- _ O
” -X- _ O
dev -X- _ O
- -X- _ O
clean -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
test -X- _ O
- -X- _ O
clean -X- _ O
” -X- _ O
test -X- _ O
sets -X- _ O
as -X- _ O
“ -X- _ O
clean -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
average -X- _ O
WER -X- _ O
on -X- _ O
the“dev -X- _ O
- -X- _ O
other -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
test -X- _ O
- -X- _ O
other -X- _ O
” -X- _ O
as -X- _ O
“ -X- _ O
other -X- _ O
” -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
result -X- _ O
vari- -X- _ O
ation -X- _ O
. -X- _ O
From -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
following -X- _ O
observa- -X- _ O
tions -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
matched -X- _ O
condition -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
“ -X- _ O
PT -X- _ B-HyperparameterName
C -X- _ I-HyperparameterName
+ -X- _ I-HyperparameterName
FT -X- _ I-HyperparameterName
C -X- _ I-HyperparameterName
” -X- _ O
achieves -X- _ O
the -X- _ O
lowest -X- _ O
WER -X- _ B-MetricName
on -X- _ O
the -X- _ O
“ -X- _ O
clean -X- _ O
” -X- _ O
set -X- _ O
while -X- _ O
“ -X- _ O
PT -X- _ B-HyperparameterName
O -X- _ I-HyperparameterName
+ -X- _ I-HyperparameterName
FT -X- _ I-HyperparameterName
O -X- _ I-HyperparameterName
” -X- _ I-HyperparameterName
achieves -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
best -X- _ I-HyperparameterName
results -X- _ I-HyperparameterName
on -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
“ -X- _ I-HyperparameterName
other -X- _ I-HyperparameterName
” -X- _ I-HyperparameterName
set -X- _ I-HyperparameterName
. -X- _ I-HyperparameterName
2 -X- _ I-HyperparameterName
) -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
and -X- _ I-HyperparameterName
test -X- _ I-HyperparameterName
on -X- _ I-HyperparameterName
totally -X- _ I-HyperparameterName
differ- -X- _ I-HyperparameterName
ent -X- _ I-HyperparameterName
conditions -X- _ I-HyperparameterName
could -X- _ I-HyperparameterName
increase -X- _ I-HyperparameterName
WER -X- _ I-HyperparameterName
signiﬁcantly -X- _ I-HyperparameterName
. -X- _ I-HyperparameterName
The -X- _ I-HyperparameterName
model -X- _ I-HyperparameterName
“ -X- _ I-HyperparameterName
PT -X- _ I-HyperparameterName
C -X- _ I-HyperparameterName
+ -X- _ I-HyperparameterName
FT -X- _ I-HyperparameterName
C -X- _ I-HyperparameterName
” -X- _ O
increases -X- _ O
0.9 -X- _ B-MetricValue
WER -X- _ B-MetricName
on -X- _ O
the -X- _ O
“ -X- _ O
other -X- _ O
” -X- _ O
set -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
“ -X- _ O
PT -X- _ B-HyperparameterName
O -X- _ I-HyperparameterName
+ -X- _ I-HyperparameterName
FT -X- _ I-HyperparameterName
O -X- _ I-HyperparameterName
” -X- _ O
model -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
mismatched -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
might -X- _ O
slightly -X- _ O
increase -X- _ O
the -X- _ O
WER -X- _ B-MetricName
, -X- _ O
0.1 -X- _ B-MetricValue
to -X- _ O
0.2 -X- _ B-MetricValue
in -X- _ O
this -X- _ O
experiment -X- _ O
. -X- _ O
5.4 -X- _ O
Masked -X- _ O
KL -X- _ O
divergence -X- _ O
loss -X- _ O
v.s. -X- _ O
contrastive -X- _ O
loss -X- _ O
In -X- _ O
the -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
, -X- _ O
we -X- _ O
optimize -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
re- -X- _ O
duce -X- _ O
the -X- _ O
KL -X- _ O
divergence -X- _ O
loss -X- _ O
between -X- _ O
input -X- _ O
without -X- _ O
masking -X- _ O
and -X- _ O
with -X- _ O
masking -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
subsec- -X- _ O
tion -X- _ O
3.2 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
prediction -X- _ O
loss -X- _ O
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
and -X- _ O
no -X- _ O
target -X- _ O
labels -X- _ O
are -X- _ O
required -X- _ O
in -X- _ O
our -X- _ O
implementation -X- _ O
. -X- _ O
Contrastive -X- _ O
loss -X- _ O
is -X- _ O
another -X- _ O
widely -X- _ O
used -X- _ O
method -X- _ O
for -X- _ O
the -X- _ O
self- -X- _ O
supervised -X- _ O
speech -X- _ O
learning -X- _ O
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
both -X- _ O
criteria -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
The -X- _ O
num- -X- _ O
ber -X- _ O
of -X- _ O
distractors -X- _ O
in -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
is -X- _ O
100 -X- _ O
as -X- _ O
( -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
ST -X- _ B-TaskName
re- -X- _ O
sults -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
masked -X- _ O
KL -X- _ O
divergence -X- _ O
loss -X- _ O
achieves -X- _ O
about -X- _ O
0:6lower -X- _ B-MetricValue
WER -X- _ B-MetricName
in -X- _ O
the -X- _ O
Librispeech -X- _ O
dev -X- _ O
sets -X- _ O
and -X- _ O
0:71:4more -X- _ B-MetricValue
BLEU -X- _ B-MetricName
scores -X- _ O
in -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
C -X- _ I-DatasetName
tst -X- _ I-DatasetName
- -X- _ I-DatasetName
COMMON -X- _ I-DatasetName
sets -X- _ O
. -X- _ O
It -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
masked -X- _ O
KL -X- _ O
divergence -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
. -X- _ O
5.5 -X- _ O
Ablation -X- _ O
study -X- _ O
In -X- _ O
Table -X- _ O
7 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
by -X- _ O
remov- -X- _ O
ing -X- _ O
different -X- _ O
steps -X- _ O
/ -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
more -X- _ O
stable -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
training -X- _ O
adopts -X- _ O
a -X- _ O
three -X- _ O
- -X- _ O
stage -X- _ O
optimiza- -X- _ O
tion -X- _ O
strategy -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
good -X- _ O
initialization -X- _ O
on -X- _ O
the -X- _ O
phoneme -X- _ O
embed- -X- _ O
dings -X- _ O
2 -X- _ O
) -X- _ O
joint -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
four -X- _ O
subtasks -X- _ O
to -X- _ O
leverage -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
unlabelled -X- _ O
speech -X- _ O
data -X- _ O
and -X- _ O
abundant -X- _ O
text -X- _ O
data -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
for -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
row -X- _ O
, -X- _ O
we -X- _ O
skip -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
pre -X- _ O
- -X- _ O
training -X- _ O
step -X- _ O
and -X- _ O
initialize -X- _ O
the -X- _ O
model -X- _ O
randomly -X- _ O
for -X- _ O
the -X- _ O
joint -X- _ O
pre- -X- _ O
training -X- _ O
. -X- _ O
0.5 -X- _ O
WER -X- _ O
increase -X- _ O
is -X- _ O
observed -X- _ O
in -X- _ O
average -X- _ O
on -X- _ O
two -X- _ O
L -X- _ O
dev -X- _ O
sets -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
has -X- _ O
more -X- _ O
im- -X- _ O
pact -X- _ O
on -X- _ O
the -X- _ O
EN -X- _ O
- -X- _ O
ES -X- _ O
translation -X- _ O
direction -X- _ O
where -X- _ O
1.2 -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
is -X- _ O
lost -X- _ O
without -X- _ O
proper -X- _ O
initialization -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
third -X- _ O
row -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
without -X- _ O
the -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
, -X- _ O
signiﬁ- -X- _ O
ca -X- _ O
nt -X- _ O
performance -X- _ O
degradation -X- _ O
is -X- _ O
observed -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
1.1 -X- _ O
WER -X- _ B-MetricName
increase -X- _ O
for -X- _ O
two -X- _ O
ASR -X- _ B-TaskName
tests -X- _ O
and -X- _ O
1.8 -X- _ O
BLEU -X- _ B-MetricName
decrease -X- _ O
for -X- _ O
two -X- _ O
ST -X- _ B-TaskName
directions -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
try -X- _ O
removing -X- _ O
the -X- _ O
S2P -X- _ B-TaskName
subtask -X- _ O
while -X- _ O
still -X- _ O
keeping -X- _ O
the -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
does -X- _ O
n’t -X- _ O
converge -X- _ O
. -X- _ O
The -X- _ O
SSL -X- _ B-TaskName
subtask -X- _ O
is -X- _ O
with -X- _ O
very -X- _ O
small -X- _ O
or -X- _ O
zero -X- _ O
cost -X- _ O
since -X- _ O
all -X- _ O
predictions -X- _ O
collapse -X- _ O
into -X- _ O
one -X- _ O
or -X- _ O
two -X- _ O
target -X- _ O
phonemes -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
little -X- _ O
progress -X- _ O
has -X- _ O
been -X- _ O
made -X- _ O
for -X- _ O
the -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtask -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
is -X- _ O
co -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
SSL -X- _ O
and -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
subtasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
last -X- _ O
row -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
without -X- _ O
pre- -X- _ O
training -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
only -X- _ O
the -X- _ O
T2 -X- _ B-TaskName
T -X- _ I-TaskName
and -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
subtasks -X- _ O
are -X- _ O
optimized -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
STPT -X- _ B-HyperparameterName
results -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
about -X- _ O
1.4 -X- _ B-MetricValue
WER -X- _ B-MetricName
increase -X- _ O
for -X- _ O
two -X- _ O
L -X- _ O
test -X- _ O
sets -X- _ O
and -X- _ O
3.4 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
decrease -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
ST -X- _ B-TaskName
directions -X- _ O
on -X- _ O
average -X- _ O
. -X- _ O
6 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
jointly -X- _ O
pre- -X- _ O
train -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
in -X- _ O
one -X- _ O
model -X- _ O
for -X- _ O
speech -X- _ O
trans- -X- _ O
lation -X- _ O
and -X- _ O
recognition -X- _ O
under -X- _ O
the -X- _ O
AED -X- _ B-HyperparameterName
framework.1495 -X- _ O
It -X- _ O
includes -X- _ O
four -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
and -X- _ O
supervised -X- _ O
sub- -X- _ O
tasks -X- _ O
from -X- _ O
two -X- _ O
different -X- _ O
input -X- _ O
modalities -X- _ O
, -X- _ O
hence -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
can -X- _ O
leverage -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
un- -X- _ O
labelled -X- _ O
speech -X- _ O
data -X- _ O
and -X- _ O
abundant -X- _ O
text -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
detailed -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
interference -X- _ O
among -X- _ O
different -X- _ O
subtasks -X- _ O
and -X- _ O
propose -X- _ O
two -X- _ O
model -X- _ O
conﬁgurations -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
respectively -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
subtask -X- _ O
interference -X- _ O
. -X- _ O
Our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
STPT -X- _ B-HyperparameterName
can -X- _ O
effectively -X- _ O
fuse -X- _ O
information -X- _ O
within -X- _ O
text -X- _ O
and -X- _ O
speech -X- _ O
training -X- _ O
data -X- _ O
into -X- _ O
one -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
achieves -X- _ O
between -X- _ O
1:7and2:3BLEU -X- _ B-MetricValue
improvement -X- _ O
over -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
on -X- _ O
the -X- _ O
MST -X- _ O
- -X- _ O
C -X- _ O
EN -X- _ O
- -X- _ O
FR -X- _ O
and -X- _ O
EN -X- _ O
- -X- _ O
ES -X- _ O
speech -X- _ O
translation -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
comparable -X- _ O
WERs -X- _ O
as -X- _ O
wav2vec -X- _ B-HyperparameterName
2.0 -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
L -X- _ O
ASR -X- _ B-TaskName
task -X- _ O
. -X- _ O
7 -X- _ O
Acknowledgments -X- _ O
We -X- _ O
want -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O
and -X- _ O
suggestions -X- _ O
. -X- _ O
8 -X- _ O
Broader -X- _ O
Impact -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
potential -X- _ O
that -X- _ O
this -X- _ O
work -X- _ O
has -X- _ O
pos- -X- _ O
itive -X- _ O
impact -X- _ O
in -X- _ O
the -X- _ O
society -X- _ O
: -X- _ O
augmenting -X- _ O
speech -X- _ O
processing -X- _ O
tasks -X- _ O
with -X- _ O
text -X- _ O
corpus -X- _ O
, -X- _ O
and -X- _ O
improving -X- _ O
speech -X- _ O
related -X- _ O
applications -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
this -X- _ O
work -X- _ O
may -X- _ O
have -X- _ O
some -X- _ O
negative -X- _ O
consequences -X- _ O
if -X- _ O
the -X- _ O
text -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
handled -X- _ O
in -X- _ O
a -X- _ O
proper -X- _ O
way -X- _ O
. -X- _ O
Before -X- _ O
using -X- _ O
the -X- _ O
text -X- _ O
data -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
speech -X- _ O
system -X- _ O
, -X- _ O
one -X- _ O
should -X- _ O
evaluate -X- _ O
fairness -X- _ O
in -X- _ O
the -X- _ O
collected -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
make -X- _ O
sure -X- _ O
not -X- _ O
to -X- _ O
train -X- _ O
on -X- _ O
offensive -X- _ O
or -X- _ O
any -X- _ O
type -X- _ O
of -X- _ O
inappropriate -X- _ O
data -X- _ O
. -X- _ O
References14961497A -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
setting -X- _ O
T2 -X- _ O
T -X- _ O
: -X- _ O
For -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
training -X- _ O
datasetfor -X- _ O
L- -X- _ O
( -X- _ O
Panayotov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
monolingual -X- _ O
BART -X- _ O
model -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
about -X- _ O
800 -X- _ O
million -X- _ O
words -X- _ O
. -X- _ O
For -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
parallel -X- _ O
training -X- _ O
corpus -X- _ O
from -X- _ O
WMT -X- _ O
. -X- _ O
We -X- _ O
examine -X- _ O
our -X- _ O
methods -X- _ O
on -X- _ O
two -X- _ O
translation -X- _ O
directions -X- _ O
inMST -X- _ O
- -X- _ O
C -X- _ O
: -X- _ O
English -X- _ O
- -X- _ O
Spanish -X- _ O
( -X- _ O
EN -X- _ O
- -X- _ O
ES -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
WMT13 -X- _ O
training -X- _ O
corpus -X- _ O
, -X- _ O
and -X- _ O
English -X- _ O
- -X- _ O
French -X- _ O
( -X- _ O
EN -X- _ O
- -X- _ O
FR -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
takes -X- _ O
the -X- _ O
WMT14 -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
370 -X- _ O
million -X- _ O
and -X- _ O
1 -X- _ O
billion -X- _ O
English -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
EN -X- _ O
- -X- _ O
ES -X- _ O
and -X- _ O
EN -X- _ O
- -X- _ O
FR -X- _ O
parallel -X- _ O
training -X- _ O
datasets -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
“ -X- _ O
g2p -X- _ O
en -X- _ O
” -X- _ O
Python -X- _ O
package -X- _ O
( -X- _ O
Lee -X- _ O
and -X- _ O
Kim -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
training -X- _ O
text -X- _ O
into -X- _ O
the -X- _ O
corre- -X- _ O
sponding -X- _ O
phoneme -X- _ O
representation -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
CMU -X- _ O
English -X- _ O
dictionary -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
ex- -X- _ O
tend -X- _ O
the -X- _ O
phoneme -X- _ O
set -X- _ O
by -X- _ O
distinguishing -X- _ O
the -X- _ O
ﬁrst -X- _ O
phoneme -X- _ O
in -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
an -X- _ O
additional -X- _ O
“ -X- _ O
” -X- _ O
mark -X- _ O
appended -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
notation -X- _ O
in -X- _ O
the -X- _ O
SentencePiece -X- _ O
process -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
phoneme -X- _ O
vocab- -X- _ O
ulary -X- _ O
size -X- _ O
is -X- _ O
134 -X- _ O
. -X- _ O
SSL -X- _ O
: -X- _ O
For -X- _ O
both -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
60k -X- _ O
hours -X- _ O
of -X- _ O
unlabelled -X- _ O
English -X- _ O
speech -X- _ O
data -X- _ O
from -X- _ O
Libri- -X- _ O
light -X- _ O
( -X- _ O
Kahn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
self- -X- _ O
supervised -X- _ O
speech -X- _ O
task -X- _ O
if -X- _ O
not -X- _ O
speciﬁcally -X- _ O
men- -X- _ O
tioned -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ O
utterance -X- _ O
duration -X- _ O
to -X- _ O
37.5 -X- _ O
seconds -X- _ O
and -X- _ O
minimum -X- _ O
duration -X- _ O
to -X- _ O
4 -X- _ O
sec- -X- _ O
onds -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
sample -X- _ O
audio -X- _ O
segments -X- _ O
with -X- _ O
maximum -X- _ O
duration -X- _ O
if -X- _ O
utterances -X- _ O
are -X- _ O
longer -X- _ O
than -X- _ O
the -X- _ O
maximum -X- _ O
duration -X- _ O
. -X- _ O
No -X- _ O
voice -X- _ O
activity -X- _ O
detection -X- _ O
is -X- _ O
applied -X- _ O
. -X- _ O
S2P -X- _ O
: -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
transcribed -X- _ O
L -X- _ O
dataset -X- _ O
for -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
MST -X- _ O
- -X- _ O
C -X- _ O
training -X- _ O
dataset -X- _ O
is -X- _ O
used -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
corre- -X- _ O
sponding -X- _ O
English -X- _ O
transcription -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
train- -X- _ O
ing -X- _ O
target -X- _ O
labels -X- _ O
after -X- _ O
it -X- _ O
is -X- _ O
converted -X- _ O
into -X- _ O
phoneme -X- _ O
representation -X- _ O
. -X- _ O
The -X- _ O
phoneme -X- _ O
level -X- _ O
segmentation -X- _ O
is -X- _ O
obtained -X- _ O
via -X- _ O
force -X- _ O
- -X- _ O
alignment -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
conducted -X- _ O
using -X- _ O
HMM -X- _ O
/ -X- _ O
GMM -X- _ O
trained -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
speech -X- _ O
data -X- _ O
with -X- _ O
the -X- _ O
Kaldi -X- _ O
toolkit -X- _ O
( -X- _ O
Povey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
S2 -X- _ O
T -X- _ O
: -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
labelled -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
S2P -X- _ O
subtask -X- _ O
for -X- _ O
the -X- _ O
S2 -X- _ O
T -X- _ O
subtask -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
L -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
MST- -X- _ O
Cdata -X- _ O
for -X- _ O
the -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
using -X- _ O
phoneme -X- _ O
representation -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
labels -X- _ O
are -X- _ O
en- -X- _ O
coded -X- _ O
with -X- _ O
SentencePiece -X- _ O
( -X- _ O
Kudo -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
ASR -X- _ O
and -X- _ O
ST -X- _ O
tasks -X- _ O
, -X- _ O
the -X- _ O
vocabu- -X- _ O
lary -X- _ O
is -X- _ O
an -X- _ O
Unigram -X- _ O
model -X- _ O
with -X- _ O
size -X- _ O
10k -X- _ O
and -X- _ O
full1498 -X- _ O
character -X- _ O
coverage -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O
B -X- _ O
Optimization -X- _ O
setting -X- _ O
The -X- _ O
models -X- _ O
are -X- _ O
optimized -X- _ O
with -X- _ O
Adam -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
for -X- _ O
both -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
ﬁnal -X- _ O
results -X- _ O
are -X- _ O
evaluated -X- _ O
using -X- _ O
an -X- _ O
averaged -X- _ O
model -X- _ O
from -X- _ O
checkpoints -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
10 -X- _ O
epochs -X- _ O
. -X- _ O
T2 -X- _ O
T -X- _ O
subtask -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
The -X- _ O
T2 -X- _ O
T -X- _ O
model -X- _ O
is -X- _ O
pre- -X- _ O
trained -X- _ O
with -X- _ O
learning -X- _ O
rate -X- _ O
0.01 -X- _ O
using -X- _ O
Adam -X- _ O
opti- -X- _ O
mization -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ O
tokens -X- _ O
per -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
is -X- _ O
2048 -X- _ O
with -X- _ O
8 -X- _ O
V100 -X- _ O
GPU -X- _ O
cards -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
up- -X- _ O
dated -X- _ O
400,000 -X- _ O
until -X- _ O
fully -X- _ O
converged -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
all -X- _ O
subtasks -X- _ O
The -X- _ O
model -X- _ O
then -X- _ O
keeps -X- _ O
optimizing -X- _ O
with -X- _ O
all -X- _ O
four -X- _ O
subtasks -X- _ O
: -X- _ O
T2 -X- _ O
T -X- _ O
, -X- _ O
SSL -X- _ O
, -X- _ O
S2P -X- _ O
and -X- _ O
S2 -X- _ O
T -X- _ O
, -X- _ O
with -X- _ O
learning -X- _ O
rate -X- _ O
0.001 -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
16 -X- _ O
A100 -X- _ O
GPU -X- _ O
cards -X- _ O
with -X- _ O
update -X- _ O
fre- -X- _ O
quency -X- _ O
12 -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ O
token -X- _ O
number -X- _ O
per -X- _ O
batch -X- _ O
for -X- _ O
the -X- _ O
T2 -X- _ O
T -X- _ O
subtask -X- _ O
is -X- _ O
2048 -X- _ O
while -X- _ O
the -X- _ O
maximum -X- _ O
sample -X- _ O
number -X- _ O
is -X- _ O
750,000 -X- _ O
( -X- _ O
46s -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
speech -X- _ O
in- -X- _ O
put -X- _ O
in -X- _ O
three -X- _ O
speech -X- _ O
subtasks -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ O
update -X- _ O
number -X- _ O
is -X- _ O
800,000 -X- _ O
and -X- _ O
200,000 -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
pre- -X- _ O
training -X- _ O
and -X- _ O
the -X- _ O
ST -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
respectively -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
down- -X- _ O
stream -X- _ O
task -X- _ O
with -X- _ O
learning -X- _ O
rate -X- _ O
0.0003 -X- _ O
and -X- _ O
8 -X- _ O
V100 -X- _ O
GPU -X- _ O
cards -X- _ O
. -X- _ O
The -X- _ O
update -X- _ O
frequency -X- _ O
set -X- _ O
to -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ O
update -X- _ O
numbers -X- _ O
are -X- _ O
dependent -X- _ O
on -X- _ O
the -X- _ O
amounts -X- _ O
of -X- _ O
supervised -X- _ O
speech -X- _ O
data -X- _ O
available -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
100,000 -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
task -X- _ O
with -X- _ O
960 -X- _ O
hours -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
20,000 -X- _ O
for -X- _ O
100 -X- _ O
or -X- _ O
10 -X- _ O
hours -X- _ O
train- -X- _ O
ing -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
ST -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ O
update -X- _ O
number -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
50,000 -X- _ O
. -X- _ O
C -X- _ O
Gradient -X- _ O
similarity -X- _ O
of -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
Three -X- _ O
subtasks -X- _ O
: -X- _ O
SSL -X- _ O
, -X- _ O
S2P -X- _ O
, -X- _ O
and -X- _ O
S2 -X- _ O
T -X- _ O
, -X- _ O
share -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
during -X- _ O
the -X- _ O
joint -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Sim- -X- _ O
ilar -X- _ O
pairwise -X- _ O
gradient -X- _ O
similarity -X- _ O
analysis -X- _ O
is -X- _ O
con -X- _ O
- -X- _ O
ducted -X- _ O
on -X- _ O
these -X- _ O
three -X- _ O
subtasks -X- _ O
at -X- _ O
the -X- _ O
speech -X- _ O
en- -X- _ O
coder -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
gradient -X- _ O
similarity -X- _ O
analysis -X- _ O
for -X- _ O
the -X- _ O
ASR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
subﬁgure -X- _ O
while -X- _ O
the -X- _ O
ST -X- _ O
- -X- _ O
pretraining -X- _ O
is -X- _ O
listed -X- _ O
in -X- _ O
the -X- _ O
right -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
gradient -X- _ O
similarities -X- _ O
for -X- _ O
different -X- _ O
subtask -X- _ O
pairs -X- _ O
are -X- _ O
small -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
absolute -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
gradient -X- _ O
similarities -X- _ O
are -X- _ O
all -X- _ O
below -X- _ O
0.2 -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
the -X- _ O
task -X- _ O
interference -X- _ O
between -X- _ O
different -X- _ O
subtasks -X- _ O
are -X- _ O
not -X- _ O
signiﬁcant.1499 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
This -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
investigates -X- _ SUMMARY
how -X- _ SUMMARY
the -X- _ SUMMARY
number -X- _ SUMMARY
of -X- _ SUMMARY
pretraining -X- _ SUMMARY
languages -X- _ SUMMARY
influences -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
performance -X- _ SUMMARY
on -X- _ SUMMARY
unseen -X- _ SUMMARY
target -X- _ SUMMARY
languages -X- _ SUMMARY
and -X- _ SUMMARY
whether -X- _ SUMMARY
model -X- _ SUMMARY
adaptation -X- _ SUMMARY
affects -X- _ SUMMARY
this -X- _ SUMMARY
relationship -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
experiments -X- _ SUMMARY
are -X- _ SUMMARY
conducted -X- _ SUMMARY
on -X- _ SUMMARY
multilingual -X- _ SUMMARY
models -X- _ SUMMARY
pretrained -X- _ SUMMARY
on -X- _ SUMMARY
diverse -X- _ SUMMARY
and -X- _ SUMMARY
related -X- _ SUMMARY
languages -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
is -X- _ SUMMARY
performed -X- _ SUMMARY
on -X- _ SUMMARY
three -X- _ SUMMARY
downstream -X- _ SUMMARY
tasks -X- _ SUMMARY
: -X- _ SUMMARY
part -X- _ SUMMARY
- -X- _ SUMMARY
of -X- _ SUMMARY
- -X- _ SUMMARY
speech -X- _ SUMMARY
tagging -X- _ SUMMARY
, -X- _ SUMMARY
named -X- _ SUMMARY
entity -X- _ SUMMARY
recognition -X- _ SUMMARY
( -X- _ SUMMARY
NER -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
natural -X- _ SUMMARY
language -X- _ SUMMARY
inference -X- _ SUMMARY
( -X- _ SUMMARY
NLI -X- _ SUMMARY
) -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
findings -X- _ SUMMARY
suggest -X- _ SUMMARY
that -X- _ SUMMARY
increasing -X- _ SUMMARY
the -X- _ SUMMARY
number -X- _ SUMMARY
of -X- _ SUMMARY
pretraining -X- _ SUMMARY
languages -X- _ SUMMARY
improves -X- _ SUMMARY
performance -X- _ SUMMARY
up -X- _ SUMMARY
to -X- _ SUMMARY
a -X- _ SUMMARY
certain -X- _ SUMMARY
point -X- _ SUMMARY
, -X- _ SUMMARY
after -X- _ SUMMARY
which -X- _ SUMMARY
it -X- _ SUMMARY
plateaus -X- _ SUMMARY
. -X- _ SUMMARY
However -X- _ SUMMARY
, -X- _ SUMMARY
with -X- _ SUMMARY
model -X- _ SUMMARY
adaptation -X- _ SUMMARY
, -X- _ SUMMARY
pretraining -X- _ SUMMARY
on -X- _ SUMMARY
a -X- _ SUMMARY
larger -X- _ SUMMARY
number -X- _ SUMMARY
of -X- _ SUMMARY
languages -X- _ SUMMARY
often -X- _ SUMMARY
leads -X- _ SUMMARY
to -X- _ SUMMARY
further -X- _ SUMMARY
improvement -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
also -X- _ SUMMARY
find -X- _ SUMMARY
that -X- _ SUMMARY
choosing -X- _ SUMMARY
a -X- _ SUMMARY
diverse -X- _ SUMMARY
set -X- _ SUMMARY
of -X- _ SUMMARY
pretraining -X- _ SUMMARY
languages -X- _ SUMMARY
is -X- _ SUMMARY
crucial -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
experimental -X- _ SUMMARY
results -X- _ SUMMARY
highlight -X- _ SUMMARY
the -X- _ SUMMARY
impact -X- _ SUMMARY
of -X- _ SUMMARY
pretraining -X- _ SUMMARY
languages -X- _ SUMMARY
on -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
lingual -X- _ SUMMARY
transfer -X- _ SUMMARY
and -X- _ SUMMARY
provide -X- _ SUMMARY
insights -X- _ SUMMARY
for -X- _ SUMMARY
model -X- _ SUMMARY
development -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
focuses -X- _ SUMMARY
on -X- _ SUMMARY
low -X- _ SUMMARY
- -X- _ SUMMARY
resource -X- _ SUMMARY
languages -X- _ SUMMARY
and -X- _ SUMMARY
evaluates -X- _ SUMMARY
the -X- _ SUMMARY
models -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
GLUE -X- _ SUMMARY
benchmark -X- _ SUMMARY
dataset -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.106.txt -X- _ O
Yoshinari -X- _ O
Fujinuma -X- _ O
Labs -X- _ O
Amazon.comJordan -X- _ O
Boyd -X- _ O
- -X- _ O
Graber -X- _ O
, -X- _ O
, -X- _ O
, -X- _ O
iSchool -X- _ O
University -X- _ O
of -X- _ O
MarylandKatharina -X- _ O
Kann -X- _ O
Computer -X- _ O
Science -X- _ O
University -X- _ O
of -X- _ O
Colorado -X- _ O
Boulder -X- _ O
Abstract -X- _ O
Pretrained -X- _ O
multilingual -X- _ O
models -X- _ O
enable -X- _ O
zeroshot -X- _ O
learning -X- _ O
even -X- _ O
for -X- _ O
unseen -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
improved -X- _ O
via -X- _ O
adaptation -X- _ O
prior -X- _ O
to -X- _ O
finetuning -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
how -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
influences -X- _ O
a -X- _ O
model -X- _ O
’s -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
for -X- _ O
languages -X- _ O
unseen -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
To -X- _ O
fill -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
the -X- _ O
following -X- _ O
research -X- _ O
questions -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
influence -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
on -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
? -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Does -X- _ O
the -X- _ O
answer -X- _ O
to -X- _ O
that -X- _ O
question -X- _ O
change -X- _ O
with -X- _ O
model -X- _ O
adaptation -X- _ O
? -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Do -X- _ O
the -X- _ O
findings -X- _ O
for -X- _ O
our -X- _ O
first -X- _ O
question -X- _ O
change -X- _ O
if -X- _ O
the -X- _ O
languages -X- _ O
used -X- _ O
for -X- _ O
pretraining -X- _ O
are -X- _ O
all -X- _ O
related -X- _ O
? -X- _ O
Our -X- _ O
experiments -X- _ O
on -X- _ O
pretraining -X- _ O
with -X- _ O
related -X- _ O
languages -X- _ O
indicate -X- _ O
that -X- _ O
choosing -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
languages -X- _ O
is -X- _ O
crucial -X- _ O
. -X- _ O
Without -X- _ O
model -X- _ O
adaptation -X- _ O
, -X- _ O
surprisingly -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
yields -X- _ O
better -X- _ O
results -X- _ O
up -X- _ O
to -X- _ O
adding -X- _ O
related -X- _ O
languages -X- _ O
, -X- _ O
after -X- _ O
which -X- _ O
performance -X- _ O
plateaus -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
with -X- _ O
model -X- _ O
adaptation -X- _ O
via -X- _ O
continued -X- _ O
pretraining -X- _ O
, -X- _ O
pretraining -X- _ O
on -X- _ O
a -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
languages -X- _ O
often -X- _ O
gives -X- _ O
further -X- _ O
improvement -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
model -X- _ O
adaptation -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
exploit -X- _ O
additional -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Pretrained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
now -X- _ O
a -X- _ O
standard -X- _ O
approach -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
, -X- _ O
potentially -X- _ O
related -X- _ O
issues -X- _ O
on -X- _ O
pretraining -X- _ O
multilingual -X- _ O
models -X- _ O
. -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
find -X- _ O
the -X- _ O
“ -X- _ O
curse -X- _ O
of -X- _ O
multilinguality -X- _ O
” -X- _ O
: -X- _ O
for -X- _ O
a -X- _ O
fixed -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
on -X- _ O
target -X- _ O
languages -X- _ O
seen -X- _ O
during -X- _ O
pretraining -X- _ O
increases -X- _ O
with -X- _ O
additional -X- _ O
pretraining -X- _ O
languages -X- _ O
only -X- _ O
until -X- _ O
a -X- _ O
certain -X- _ O
point -X- _ O
, -X- _ O
afterwhich -X- _ O
performance -X- _ O
decreases -X- _ O
. -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
also -X- _ O
report -X- _ O
“ -X- _ O
negative -X- _ O
interference -X- _ O
” -X- _ O
, -X- _ O
where -X- _ O
monolingual -X- _ O
models -X- _ O
achieve -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
multilingual -X- _ O
models -X- _ O
, -X- _ O
both -X- _ O
on -X- _ O
subsets -X- _ O
of -X- _ O
high- -X- _ O
and -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
those -X- _ O
findings -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
target -X- _ O
languages -X- _ O
seen -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
Current -X- _ O
multilingual -X- _ O
models -X- _ O
cover -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
world -X- _ O
’s -X- _ O
languages -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
data -X- _ O
sparsity -X- _ O
, -X- _ O
monolingual -X- _ O
pretrained -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
likely -X- _ O
to -X- _ O
obtain -X- _ O
good -X- _ O
results -X- _ O
for -X- _ O
many -X- _ O
lowresource -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
those -X- _ O
cases -X- _ O
, -X- _ O
multilingual -X- _ O
models -X- _ O
can -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
learn -X- _ O
for -X- _ O
unseen -X- _ O
languages -X- _ O
with -X- _ O
an -X- _ O
above -X- _ O
- -X- _ O
chance -X- _ O
performance -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
improved -X- _ O
via -X- _ O
model -X- _ O
adaptation -X- _ O
with -X- _ O
targetlanguage -X- _ O
text -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
limited -X- _ O
amounts -X- _ O
( -X- _ O
Ebrahimi -X- _ O
and -X- _ O
Kann -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
poorly -X- _ O
understood -X- _ O
how -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
influences -X- _ O
performance -X- _ O
in -X- _ O
those -X- _ O
cases -X- _ O
. -X- _ O
Does -X- _ O
the -X- _ O
“ -X- _ O
curse -X- _ O
of -X- _ O
multilinguality -X- _ O
” -X- _ O
or -X- _ O
“ -X- _ O
negative -X- _ O
interference -X- _ O
” -X- _ O
also -X- _ O
impact -X- _ O
performance -X- _ O
on -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
? -X- _ O
And -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
want -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
applicable -X- _ O
to -X- _ O
as -X- _ O
many -X- _ O
unseen -X- _ O
languages -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
how -X- _ O
many -X- _ O
languages -X- _ O
should -X- _ O
it -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
? -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
the -X- _ O
following -X- _ O
research -X- _ O
questions -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
How -X- _ O
does -X- _ O
pretraining -X- _ O
on -X- _ O
an -X- _ O
increasing -X- _ O
number -X- _ O
of -X- _ O
languages -X- _ O
impact -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
on -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
? -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Does -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
change -X- _ O
with -X- _ O
model -X- _ O
adaptation -X- _ O
to -X- _ O
target -X- _ O
languages -X- _ O
? -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Does -X- _ O
the -X- _ O
answer -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
research -X- _ O
question -X- _ O
change -X- _ O
if -X- _ O
the -X- _ O
pretraining -X- _ O
languages -X- _ O
are -X- _ O
all -X- _ O
related -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
? -X- _ O
We -X- _ O
pretrain -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
monolingual -X- _ O
and -X- _ O
multilingual -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
then -X- _ O
finetune -X- _ O
on -X- _ O
English -X- _ O
and -X- _ O
apply -X- _ O
to -X- _ O
three -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
downstream -X- _ O
tasks -X- _ O
in -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
: -X- _ O
partof -X- _ B-TaskName
- -X- _ I-TaskName
speech -X- _ I-TaskName
( -X- _ I-TaskName
) -X- _ I-TaskName
tagging -X- _ I-TaskName
, -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
) -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
choosing -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
effective -X- _ O
transfer -X- _ O
. -X- _ O
Without -X- _ O
model -X- _ O
adaptation -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
im-1500proves -X- _ O
accuracy -X- _ O
on -X- _ O
unrelated -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
at -X- _ O
first -X- _ O
and -X- _ O
plateaus -X- _ O
thereafter -X- _ O
. -X- _ O
Last -X- _ O
, -X- _ O
with -X- _ O
model -X- _ O
adaptation -X- _ O
, -X- _ O
additional -X- _ O
pretraining -X- _ O
languages -X- _ O
beyond -X- _ O
English -X- _ O
generally -X- _ O
help -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
intense -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
pretraining -X- _ O
and -X- _ O
its -X- _ O
environmental -X- _ O
impact -X- _ O
( -X- _ O
Strubell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
experiments -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
are -X- _ O
on -X- _ O
a -X- _ O
relatively -X- _ O
small -X- _ O
scale -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
computational -X- _ O
budget -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
and -X- _ O
on -X- _ O
relatively -X- _ O
simple -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
tagging -X- _ O
, -X- _ O
, -X- _ O
and -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
validate -X- _ O
our -X- _ O
most -X- _ O
central -X- _ O
findings -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
on -X- _ O
large -X- _ O
publicly -X- _ O
available -X- _ O
pretrained -X- _ O
models -X- _ O
. -X- _ O
2 -X- _ O
Cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
Transfer -X- _ I-TaskName
via -X- _ O
Pretraining -X- _ O
Pretrained -X- _ O
multilingual -X- _ O
models -X- _ O
are -X- _ O
a -X- _ O
straightforward -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
approach -X- _ O
: -X- _ O
a -X- _ O
model -X- _ O
pretrained -X- _ O
on -X- _ O
multiple -X- _ O
languages -X- _ O
is -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
target -X- _ O
- -X- _ O
task -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
. -X- _ O
Subsequently -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
target -X- _ O
- -X- _ O
task -X- _ O
data -X- _ O
in -X- _ O
thetarget -X- _ O
language -X- _ O
. -X- _ O
Most -X- _ O
commonly -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
pretraining -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
is -X- _ O
possible -X- _ O
even -X- _ O
if -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
case -X- _ O
, -X- _ O
though -X- _ O
performance -X- _ O
tends -X- _ O
to -X- _ O
be -X- _ O
lower -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
extends -X- _ O
prior -X- _ O
work -X- _ O
exploring -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
abilities -X- _ O
of -X- _ O
pretrained -X- _ O
models -X- _ O
forseen -X- _ O
target -X- _ O
languages -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
to -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
transfer -X- _ O
via -X- _ O
pretrained -X- _ O
multilingual -X- _ O
models -X- _ O
and -X- _ O
introduce -X- _ O
the -X- _ O
models -X- _ O
and -X- _ O
methods -X- _ O
vetted -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
2.1 -X- _ O
Background -X- _ O
and -X- _ O
Methods -X- _ O
Pretrained -X- _ O
Language -X- _ O
Models -X- _ O
Contextual -X- _ O
representations -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
are -X- _ O
not -X- _ O
just -X- _ O
useful -X- _ O
for -X- _ O
monolingual -X- _ O
representations -X- _ O
. -X- _ O
Multilingual -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
, -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
- -X- _ O
) -X- _ O
have -X- _ O
surprisingly -X- _ O
high -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
performance -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
practice -X- _ O
: -X- _ O
static -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Multilingual -X- _ O
models -X- _ O
are -X- _ O
also -X- _ O
practical -X- _ O
— -X- _ O
why -X- _ O
have -X- _ O
hundreds -X- _ O
of -X- _ O
separate -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
when -X- _ O
you -X- _ O
could -X- _ O
do -X- _ O
better -X- _ O
with -X- _ O
just -X- _ O
one -X- _ O
? -X- _ O
Furthermore -X- _ O
, -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
report -X- _ O
that -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
100 -X- _ O
+ -X- _ O
languages -X- _ O
are -X- _ O
better -X- _ O
than -X- _ O
bilingual -X- _ O
or -X- _ O
monolingual -X- _ O
language -X- _ O
models -X- _ O
in -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
Model -X- _ O
Adaptation -X- _ O
to -X- _ O
Unseen -X- _ O
Languages -X- _ O
Adapting -X- _ O
pretrained -X- _ O
multilingual -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
and -X- _ O
-to -X- _ O
unseen -X- _ O
languages -X- _ O
is -X- _ O
one -X- _ O
way -X- _ O
to -X- _ O
use -X- _ O
such -X- _ O
models -X- _ O
beyond -X- _ O
the -X- _ O
languages -X- _ O
covered -X- _ O
during -X- _ O
pretraining -X- _ O
time -X- _ O
. -X- _ O
Several -X- _ O
methods -X- _ O
for -X- _ O
adapting -X- _ O
pretrained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
unseen -X- _ O
languages -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
including -X- _ O
continuing -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
) -X- _ O
training -X- _ O
( -X- _ O
Chau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Müller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
optionally -X- _ O
adding -X- _ O
Adapter -X- _ O
modules -X- _ O
( -X- _ O
Pfeiffer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
extending -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
( -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
adaptation -X- _ O
methods -X- _ O
assume -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
sufficient -X- _ O
monolingual -X- _ O
corpora -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Some -X- _ O
spoken -X- _ O
languages -X- _ O
, -X- _ O
dialects -X- _ O
, -X- _ O
or -X- _ O
extinct -X- _ O
languages -X- _ O
lack -X- _ O
monolingual -X- _ O
corpora -X- _ O
to -X- _ O
conduct -X- _ O
model -X- _ O
adaptation -X- _ O
, -X- _ O
which -X- _ O
motivates -X- _ O
us -X- _ O
to -X- _ O
look -X- _ O
into -X- _ O
languages -X- _ O
unseen -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
investigation -X- _ O
on -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
target -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
processing -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
transliteration -X- _ O
into -X- _ O
Latin -X- _ O
scripts -X- _ O
( -X- _ O
Muller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
2.2 -X- _ O
Research -X- _ O
Questions -X- _ O
A -X- _ O
single -X- _ O
pretrained -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
language -X- _ O
, -X- _ O
including -X- _ O
those -X- _ O
unseen -X- _ O
during -X- _ O
pretraining -X- _ O
, -X- _ O
is -X- _ O
both -X- _ O
more -X- _ O
efficient -X- _ O
and -X- _ O
more -X- _ O
practical -X- _ O
than -X- _ O
pretraining -X- _ O
one -X- _ O
model -X- _ O
per -X- _ O
language -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
practical -X- _ O
option -X- _ O
for -X- _ O
unknown -X- _ O
target -X- _ O
languages -X- _ O
or -X- _ O
for -X- _ O
languages -X- _ O
without -X- _ O
enough -X- _ O
resources -X- _ O
for -X- _ O
pretraining -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
or -X- _ O
at -X- _ O
least -X- _ O
easily -X- _ O
adapted -X- _ O
to -X- _ O
unseen -X- _ O
languages -X- _ O
are -X- _ O
an -X- _ O
important -X- _ O
research -X- _ O
focus -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
addresses -X- _ O
the -X- _ O
following -X- _ O
research -X- _ O
questions -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
using -X- _ O
English -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
for -X- _ O
finetuning -X- _ O
. -X- _ O
RQ1 -X- _ O
: -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
influence -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
of -X- _ O
simple -X- _ O
NLP -X- _ O
tasks -X- _ O
on -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
? -X- _ O
We -X- _ O
first -X- _ O
explore -X- _ O
how -X- _ O
many -X- _ O
languages -X- _ O
a -X- _ O
model -X- _ O
should -X- _ O
be -X- _ O
pretrained -X- _ O
on -X- _ O
if -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
unknown -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
or -X- _ O
has -X- _ O
too -X- _ O
limited -X- _ O
monolingual -X- _ O
resources -X- _ O
for -X- _ O
model -X- _ O
adaptation -X- _ O
. -X- _ O
On -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
will -X- _ O
improve -X- _ O
performance -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
sees -X- _ O
a -X- _ O
more -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
scripts -X- _ O
and -X- _ O
linguistic -X- _ O
phenomena -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
pretraining -X- _ O
languages -X- _ O
, -X- _ O
the -X- _ O
better -X- _ O
chance -X- _ O
of -X- _ O
having -X- _ O
a -X- _ O
related -X- _ O
language -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
multilingual -X- _ O
training -X- _ O
can -X- _ O
cause -X- _ O
interference -X- _ O
: -X- _ O
other -X- _ O
languages -X- _ O
could -X- _ O
distract -X- _ O
from -X- _ O
English -X- _ O
, -X- _ O
the -X- _ O
finetuning -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
thus -X- _ O
, -X- _ O
lower -X- _ O
performance.1501RQ2 -X- _ O
: -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
answer -X- _ O
to -X- _ O
RQ1 -X- _ O
change -X- _ O
with -X- _ O
model -X- _ O
adaptation -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
? -X- _ O
This -X- _ O
question -X- _ O
is -X- _ O
concerned -X- _ O
with -X- _ O
settings -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
enough -X- _ O
monolingual -X- _ O
data -X- _ O
to -X- _ O
adapt -X- _ O
a -X- _ O
pretrained -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
Like -X- _ O
our -X- _ O
hypothesis -X- _ O
for1 -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
having -X- _ O
seen -X- _ O
more -X- _ O
pretraining -X- _ O
languages -X- _ O
should -X- _ O
make -X- _ O
adaptation -X- _ O
to -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
easier -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
another -X- _ O
possibility -X- _ O
is -X- _ O
that -X- _ O
adapting -X- _ O
the -X- _ O
model -X- _ O
makes -X- _ O
any -X- _ O
languages -X- _ O
other -X- _ O
than -X- _ O
the -X- _ O
finetuning -X- _ O
source -X- _ O
language -X- _ O
unnecessary -X- _ O
; -X- _ O
performance -X- _ O
stays -X- _ O
the -X- _ O
same -X- _ O
or -X- _ O
decreases -X- _ O
when -X- _ O
adding -X- _ O
more -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
RQ3 -X- _ O
: -X- _ O
Do -X- _ O
the -X- _ O
answers -X- _ O
to -X- _ O
RQ1 -X- _ O
change -X- _ O
if -X- _ O
all -X- _ O
pretraining -X- _ O
languages -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
? -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
when -X- _ O
exploring1 -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
to -X- _ O
be -X- _ O
maximally -X- _ O
beneficial -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
might -X- _ O
change -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
exact -X- _ O
languages -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
repeat -X- _ O
all -X- _ O
experiments -X- _ O
using -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
closely -X- _ O
related -X- _ O
languages -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
benefits -X- _ O
due -X- _ O
to -X- _ O
adding -X- _ O
more -X- _ O
pretraining -X- _ O
languages -X- _ O
( -X- _ O
if -X- _ O
any -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
smaller -X- _ O
with -X- _ O
related -X- _ O
languages -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
reduce -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
linguistic -X- _ O
phenomena -X- _ O
in -X- _ O
the -X- _ O
pretraining -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
if -X- _ O
English -X- _ O
is -X- _ O
all -X- _ O
we -X- _ O
use -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
performance -X- _ O
might -X- _ O
increase -X- _ O
with -X- _ O
related -X- _ O
languages -X- _ O
, -X- _ O
as -X- _ O
this -X- _ O
will -X- _ O
approximate -X- _ O
training -X- _ O
on -X- _ O
more -X- _ O
English -X- _ O
data -X- _ O
more -X- _ O
closely -X- _ O
. -X- _ O
3 -X- _ O
Experimental -X- _ O
Setup -X- _ O
Pretraining -X- _ O
Corpora -X- _ O
All -X- _ O
our -X- _ O
models -X- _ O
are -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
2017 -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
dump -X- _ I-DatasetName
( -X- _ O
Ginter -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
use -X- _ O
equal -X- _ O
amounts -X- _ O
of -X- _ O
data -X- _ O
for -X- _ O
all -X- _ O
pretraining -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
downsample -X- _ O
all -X- _ O
Wikipedia -X- _ O
datasets -X- _ O
to -X- _ O
an -X- _ O
equal -X- _ O
number -X- _ O
of -X- _ O
sequences -X- _ O
. -X- _ O
We -X- _ O
standardize -X- _ O
to -X- _ O
the -X- _ O
smallest -X- _ O
corpus -X- _ O
, -X- _ O
Hindi -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
pretraining -X- _ O
corpus -X- _ O
size -X- _ O
is -X- _ O
around -X- _ O
200 -X- _ O
MB -X- _ O
per -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
hold -X- _ O
out -X- _ O
1 -X- _ O
K -X- _ O
sequences -X- _ O
with -X- _ O
around -X- _ O
512 -X- _ O
tokens -X- _ O
per -X- _ O
sequence -X- _ O
after -X- _ O
preprocessing -X- _ O
as -X- _ O
a -X- _ O
development -X- _ O
set -X- _ O
to -X- _ O
track -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
performance -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
Corpora -X- _ O
for -X- _ O
Model -X- _ O
Adaptation -X- _ O
For -X- _ O
model -X- _ O
adaptation -X- _ O
( -X- _ O
RQ2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
contained -X- _ O
in -X- _ O
both -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
and -X- _ O
Universal -X- _ O
Dependencies -X- _ O
2.5 -X- _ O
( -X- _ O
Nivre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
: -X- _ O
Farsi -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
Hebrew -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
French -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
Vietnamese -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
Tamil -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Bulgarian -X- _ O
( -X- _ O
) -X- _ O
. -X- _ O
Model -X- _ O
adaptation -X- _ O
is -X- _ O
typically -X- _ O
done -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
not -X- _ O
seen -X- _ O
during -X- _ O
pretraining -X- _ O
because -X- _ O
monolingual -X- _ O
corpora -X- _ O
are -X- _ O
too -X- _ O
small -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Johns -X- _ O
Hopkins -X- _ O
University -X- _ O
Bible -X- _ O
corpus -X- _ O
by -X- _ O
McCarthy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
following -X- _ O
Ebrahimi -X- _ O
and -X- _ O
Kann -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Tasks -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
pretrained -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
downstream -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
: -X- _ O
tagging -X- _ O
and -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
former -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
29 -X- _ O
languages -X- _ O
from -X- _ O
Universal -X- _ B-DatasetName
Dependencies -X- _ I-DatasetName
v2.5 -X- _ I-DatasetName
( -X- _ O
Nivre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
latter -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
all -X- _ O
fifteen -X- _ O
languages -X- _ O
in -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
default -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
split -X- _ O
in -X- _ O
. -X- _ O
Models -X- _ O
and -X- _ O
Hyperparameters -X- _ O
Following -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
’s -X- _ O
-Base -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
transformers -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
768 -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ B-HyperparameterName
per -X- _ I-HyperparameterName
sequence -X- _ I-HyperparameterName
. -X- _ O
To -X- _ O
accommodate -X- _ O
all1502 -X- _ O
languages -X- _ O
and -X- _ O
facilitate -X- _ O
comparability -X- _ O
between -X- _ O
all -X- _ O
pretraining -X- _ O
setups -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
- -X- _ O
’s -X- _ O
vocabulary -X- _ O
and -X- _ O
the -X- _ O
SentencePiece -X- _ O
( -X- _ O
Kudo -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
tokenizer -X- _ O
by -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
pretraining -X- _ O
objective -X- _ O
and -X- _ O
, -X- _ O
like -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
mask -X- _ B-HyperparameterName
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ O
the -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
pretrain -X- _ O
all -X- _ O
models -X- _ O
for -X- _ O
150 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
, -X- _ O
using -X- _ O
Adam -X- _ O
W -X- _ O
( -X- _ O
Loshchilov -X- _ O
and -X- _ O
Hutter -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1×10and -X- _ B-HyperparameterValue
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
two -X- _ B-HyperparameterValue
on -X- _ O
either -X- _ O
NVIDIA -X- _ O
RTX2080Ti -X- _ O
or -X- _ O
GTX1080Ti -X- _ O
12 -X- _ O
GB -X- _ O
, -X- _ O
on -X- _ O
which -X- _ O
it -X- _ O
approximately -X- _ O
took -X- _ O
four -X- _ O
days -X- _ O
to -X- _ O
train -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
When -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
preprocess -X- _ O
sentences -X- _ O
together -X- _ O
to -X- _ O
generate -X- _ O
sequences -X- _ O
of -X- _ O
approximately -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O
For -X- _ O
continued -X- _ O
pretraining -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2×10 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
for -X- _ O
forty -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
otherwise -X- _ O
following -X- _ O
the -X- _ O
setup -X- _ O
for -X- _ O
pretraining -X- _ O
. -X- _ O
For -X- _ O
finetuning -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2×10and -X- _ B-HyperparameterValue
train -X- _ O
for -X- _ O
an -X- _ O
additional -X- _ O
ten -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
for -X- _ O
bothtagging -X- _ O
and -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
additional -X- _ O
five -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
for -X- _ O
, -X- _ O
following -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Languages -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
languages -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
English -X- _ O
is -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
data -X- _ O
of -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
finetuning -X- _ O
source -X- _ O
language -X- _ O
for -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
following -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
different -X- _ O
sets -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
: -X- _ O
“ -X- _ O
Diverse -X- _ O
( -X- _ O
Div -X- _ O
) -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
Related -X- _ O
( -X- _ O
Rel -X- _ O
) -X- _ O
” -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
mainly -X- _ O
focus -X- _ O
on -X- _ O
pretraining -X- _ O
on -X- _ O
up -X- _ O
to -X- _ O
five -X- _ O
languages -X- _ O
, -X- _ O
except -X- _ O
fortagging -X- _ O
where -X- _ O
the -X- _ O
trend -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
and -X- _ O
we -X- _ O
further -X- _ O
experiment -X- _ O
on -X- _ O
up -X- _ O
to -X- _ O
ten -X- _ O
. -X- _ O
Fortagging -X- _ O
and -X- _ O
, -X- _ O
we -X- _ O
regard -X- _ O
seventeen -X- _ O
of -X- _ O
the -X- _ O
twenty -X- _ O
- -X- _ O
nine -X- _ O
languages -X- _ O
available -X- _ O
in -X- _ O
asunseen -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
remaining -X- _ O
twelve -X- _ O
languages -X- _ O
are -X- _ O
pretraining -X- _ O
languages -X- _ O
for -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
, -X- _ O
six -X- _ O
languages -X- _ O
are -X- _ O
seen -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
are -X- _ O
unseen -X- _ O
. -X- _ O
The -X- _ O
order -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
add -X- _ O
pretraining -X- _ O
languages -X- _ O
follows -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
their -X- _ O
original -X- _ O
2017 -X- _ O
Wikipedia -X- _ O
dumps -X- _ O
, -X- _ O
with -X- _ O
larger -X- _ O
sizes -X- _ O
being -X- _ O
added -X- _ O
first -X- _ O
. -X- _ O
4 -X- _ O
Results -X- _ O
We -X- _ O
now -X- _ O
present -X- _ O
experimental -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
RQ -X- _ O
. -X- _ O
4.1 -X- _ O
Findings -X- _ O
for -X- _ O
RQ1 -X- _ O
POS -X- _ B-TaskName
Tagging -X- _ I-TaskName
Figure -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
tagging -X- _ O
accuracy -X- _ B-MetricName
averaged -X- _ O
over -X- _ O
the -X- _ O
17 -X- _ O
languages -X- _ O
unseen -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
multiple -X- _ O
languages -X- _ O
have -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
unseen -X- _ O
languages -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
pretrained -X- _ O
exclusively -X- _ O
on -X- _ O
English -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
benefits -X- _ O
from -X- _ O
a -X- _ O
more -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
pretraining -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
accuracy -X- _ B-MetricName
only -X- _ O
increases -X- _ O
up -X- _ O
to -X- _ O
six -X- _ O
languages -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
our -X- _ O
initial -X- _ O
hypothesis -X- _ O
" -X- _ O
the -X- _ O
more -X- _ O
languages -X- _ O
the -X- _ O
better -X- _ O
" -X- _ O
might -X- _ O
not -X- _ O
be -X- _ O
true -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
provides -X- _ O
a -X- _ O
more -X- _ O
detailed -X- _ O
picture -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
for -X- _ O
all -X- _ O
seen -X- _ O
and -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
jumps -X- _ O
when -X- _ O
a -X- _ O
language -X- _ O
itself -X- _ O
is -X- _ O
added -X- _ O
as -X- _ O
a -X- _ O
pretraining -X- _ O
language -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
rises -X- _ O
if -X- _ O
a -X- _ O
pretraining -X- _ O
language -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
language -X- _ O
family -X- _ O
as -X- _ O
a -X- _ O
target -X- _ O
language -X- _ O
is -X- _ O
added -X- _ O
: -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
Marathi -X- _ O
goes -X- _ O
up -X- _ O
by -X- _ O
9.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
after -X- _ O
adding -X- _ O
Hindi -X- _ O
during -X- _ O
pretraining -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
Bulgarian -X- _ O
increases -X- _ O
by31.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
after -X- _ O
adding -X- _ O
Russian -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
that -X- _ O
related -X- _ O
languages -X- _ O
are -X- _ O
indeed -X- _ O
beneficial -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
( -X- _ O
partially -X- _ O
) -X- _ O
sharing -X- _ O
the -X- _ O
same -X- _ O
script -X- _ O
with -X- _ O
a -X- _ O
pretraining -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
and -X- _ O
) -X- _ O
helps -X- _ O
with -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
even -X- _ O
for -X- _ O
languages -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
from -X- _ O
the -X- _ O
same1503 -X- _ O
family -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
outcome -X- _ O
of -X- _ O
Müller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
partially -X- _ O
support -X- _ O
the -X- _ O
hypothesis -X- _ O
by -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
shared -X- _ O
scripts -X- _ O
are -X- _ O
effective -X- _ O
on -X- _ O
unseen -X- _ O
languages -X- _ O
. -X- _ O
But -X- _ O
how -X- _ O
important -X- _ O
are -X- _ O
the -X- _ O
scripts -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
features -X- _ O
? -X- _ O
To -X- _ O
quantify -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
it -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
linear -X- _ O
regression -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
tagging -X- _ O
result -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
linear -X- _ O
regression -X- _ O
analysis -X- _ O
results -X- _ O
using -X- _ O
typological -X- _ O
features -X- _ O
among -X- _ O
target -X- _ O
and -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
script -X- _ O
and -X- _ O
family -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
encoded -X- _ O
them -X- _ O
into -X- _ O
binary -X- _ O
values -X- _ O
set -X- _ O
to -X- _ O
one -X- _ O
if -X- _ O
a -X- _ O
language -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
script -X- _ O
or -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
family -X- _ O
is -X- _ O
included -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
For -X- _ O
syntax -X- _ O
and -X- _ O
phonology -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
those -X- _ O
vectors -X- _ O
from -X- _ O
the -X- _ O
URIEL -X- _ B-DatasetName
database -X- _ O
using -X- _ O
lang2vec -X- _ O
( -X- _ O
Littell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
following -X- _ O
Lauscher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
the -X- _ O
maximum -X- _ B-MetricName
cosine -X- _ I-MetricName
similarity -X- _ I-MetricName
between -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
further -X- _ O
confirms -X- _ O
that -X- _ O
having -X- _ O
a -X- _ O
pretraining -X- _ O
language -X- _ O
which -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
script -X- _ O
contributes -X- _ O
the -X- _ O
most -X- _ O
to -X- _ O
positive -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O
We -X- _ O
sadly -X- _ O
can -X- _ O
not -X- _ O
give -X- _ O
a -X- _ O
definitive -X- _ O
optimal -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
One -X- _ O
consistent -X- _ O
finding -X- _ O
is -X- _ O
that -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
majority -X- _ O
of -X- _ O
languages -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
English -X- _ O
yields -X- _ O
the -X- _ O
worst -X- _ O
results -X- _ O
for -X- _ O
unseen -X- _ O
languages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
adding -X- _ O
pretraining -X- _ O
languages -X- _ O
does -X- _ O
not -X- _ O
necessarily -X- _ O
improve -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
want -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
pretraining -X- _ O
language -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
smaller -X- _ O
number -X- _ O
than -X- _ O
the -X- _ O
100 -X- _ O
commonly -X- _ O
used -X- _ O
pretraining -X- _ O
languages -X- _ O
is -X- _ O
likely -X- _ O
sufficient -X- _ O
unless -X- _ O
we -X- _ O
expect -X- _ O
them -X- _ O
to -X- _ O
be -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
potential -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
NER -X- _ B-TaskName
Our -X- _ O
results -X- _ O
show -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
part -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
( -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
full1504 -X- _ O
details -X- _ O
are -X- _ O
available -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
For -X- _ O
, -X- _ O
transfer -X- _ O
to -X- _ O
unseen -X- _ O
languages -X- _ O
is -X- _ O
more -X- _ O
limited -X- _ O
, -X- _ O
likely -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
tokens -X- _ O
which -X- _ O
are -X- _ O
labeled -X- _ O
as -X- _ O
entities -X- _ O
when -X- _ O
compared -X- _ O
totags -X- _ O
. -X- _ O
NLI -X- _ B-TaskName
Ourresults -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
show -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
: -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
unseen -X- _ O
languages -X- _ O
plateaus -X- _ O
at -X- _ O
a -X- _ O
relatively -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
Div-4 -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
8 -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
while -X- _ O
Div-5 -X- _ O
is -X- _ O
best -X- _ O
only -X- _ O
for -X- _ O
two -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Accuracy -X- _ B-MetricName
again -X- _ O
increases -X- _ O
with -X- _ O
related -X- _ O
languages -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
3.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
for -X- _ O
Bulgarian -X- _ O
after -X- _ O
adding -X- _ O
Russian -X- _ O
as -X- _ O
a -X- _ O
pretraining -X- _ O
language -X- _ O
. -X- _ O
Full -X- _ O
results -X- _ O
are -X- _ O
available -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
4.2 -X- _ O
Findings -X- _ O
for -X- _ O
RQ2 -X- _ O
POS -X- _ B-TaskName
Tagging -X- _ I-TaskName
Figure -X- _ O
5a -X- _ O
shows -X- _ O
thetagging -X- _ O
results -X- _ O
for -X- _ O
six -X- _ O
languages -X- _ O
after -X- _ O
adaptation -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
via -X- _ O
continued -X- _ O
pretraining -X- _ O
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
overall -X- _ O
higher -X- _ O
than -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Importantly -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
accuracy -X- _ B-MetricName
gains -X- _ O
in -X- _ O
Farsi -X- _ O
when -X- _ O
adding -X- _ O
Turkish -X- _ O
( -X- _ O
+9.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
in -X- _ O
Hebrew -X- _ O
when -X- _ O
adding -X- _ O
Greek -X- _ O
( -X- _ O
+7.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
observed -X- _ O
before -X- _ O
adapting -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
investigate -X- _ O
it -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
NER -X- _ B-TaskName
results -X- _ O
in -X- _ O
Figure -X- _ O
5b -X- _ O
show -X- _ O
similarities -X- _ O
betweentagging -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
improvement -X- _ O
on -X- _ O
Bulgarian -X- _ O
after -X- _ O
adding -X- _ O
Russian -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
limited -X- _ O
improvement -X- _ O
on -X- _ O
Farsi -X- _ O
after -X- _ O
adding -X- _ O
Arabic -X- _ O
despite -X- _ O
partially -X- _ O
shared -X- _ O
scripts -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
languages -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
adding -X- _ O
related -X- _ O
pretraining -X- _ O
languages -X- _ O
is -X- _ O
partially -X- _ O
task -X- _ O
- -X- _ O
dependent -X- _ O
. -X- _ O
NLI -X- _ B-TaskName
For -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
increases -X- _ O
slightly -X- _ O
after -X- _ O
adding -X- _ O
a -X- _ O
second -X- _ O
pretraining -X- _ O
language -X- _ O
. -X- _ O
Results -X- _ O
for -X- _ O
two -X- _ O
to -X- _ O
five -X- _ O
pretraining -X- _ O
languages -X- _ O
are -X- _ O
similar -X- _ O
for -X- _ O
all -X- _ O
target -X- _ O
languages -X- _ O
and -X- _ O
, -X- _ O
for -X- _ O
Greek -X- _ O
and -X- _ O
Turkish -X- _ O
, -X- _ O
still -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
English -X- _ O
- -X- _ O
only -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
our -X- _ O
findings -X- _ O
fortagging -X- _ O
, -X- _ O
a -X- _ O
few -X- _ O
pretraining -X- _ O
languages -X- _ O
could -X- _ O
be -X- _ O
sufficient -X- _ O
for -X- _ O
model -X- _ O
adaptation -X- _ O
. -X- _ O
Full -X- _ O
results -X- _ O
are -X- _ O
available -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
Finally -X- _ O
, -X- _ O
ourresults -X- _ O
are -X- _ O
low -X- _ O
overall -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
likely -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
corpus -X- _ O
being -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
correlated -X- _ O
features -X- _ O
for -X- _ O
( -X- _ O
Lauscher1505 -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
unlike -X- _ O
for -X- _ O
tagging -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
4.3 -X- _ O
Findings -X- _ O
for -X- _ O
RQ3 -X- _ O
POS -X- _ B-TaskName
Tagging -X- _ I-TaskName
In -X- _ O
contrast -X- _ O
to1 -X- _ O
, -X- _ O
tagging -X- _ O
accuracy -X- _ B-MetricName
changes -X- _ O
for -X- _ O
most -X- _ O
languages -X- _ O
are -X- _ O
limited -X- _ O
when -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
( -X- _ O
Figure -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
unseen -X- _ O
languages -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
observe -X- _ O
gains -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
Germanic -X- _ O
, -X- _ O
Romance -X- _ O
, -X- _ O
and -X- _ O
Uralic -X- _ O
language -X- _ O
families -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
relatively -X- _ O
( -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
language -X- _ O
fami -X- _ O
- -X- _ O
lies -X- _ O
) -X- _ O
close -X- _ O
to -X- _ O
English -X- _ O
. -X- _ O
The -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
languages -X- _ O
from -X- _ O
other -X- _ O
language -X- _ O
families -X- _ O
changes -X- _ O
by -X- _ O
< -X- _ B-MetricValue
10 -X- _ I-MetricValue
% -X- _ I-MetricValue
, -X- _ O
which -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
change -X- _ O
for -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
similar -X- _ O
languages -X- _ O
struggle -X- _ O
to -X- _ O
transfer -X- _ O
to -X- _ O
unrelated -X- _ O
languages -X- _ O
. -X- _ O
NER -X- _ B-TaskName
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
, -X- _ O
Rel-2 -X- _ O
, -X- _ O
Rel-3 -X- _ O
, -X- _ O
Rel-4 -X- _ O
, -X- _ O
and -X- _ O
Rel-5 -X- _ O
are -X- _ O
.218 -X- _ B-MetricValue
, -X- _ O
.219 -X- _ B-MetricValue
, -X- _ O
.227 -X- _ B-MetricValue
, -X- _ O
.236 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
.237 -X- _ B-MetricValue
respectively -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
Div -X- _ O
- -X- _ O
X -X- _ O
, -X- _ O
pretraining -X- _ O
on -X- _ O
related -X- _ O
languages -X- _ O
also -X- _ O
improves -X- _ O
up -X- _ O
to -X- _ O
adding -X- _ O
five -X- _ O
languages -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
bring -X- _ O
a -X- _ O
smaller -X- _ O
improvement -X- _ O
, -X- _ O
similar -X- _ O
totagging -X- _ O
. -X- _ O
NLI -X- _ O
Figure -X- _ O
7 -X- _ O
shows -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
for -X- _ O
: -X- _ O
when -X- _ O
adding -X- _ O
related -X- _ O
pretraining -X- _ O
languages -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
languages -X- _ O
far -X- _ O
from -X- _ O
English -X- _ O
either -X- _ O
does -X- _ O
not -X- _ O
change -X- _ O
much -X- _ O
or -X- _ O
decreases -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
for -X- _ O
nine -X- _ O
out -X- _ O
of -X- _ O
thirteen -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
Rel-5 -X- _ O
is -X- _ O
the -X- _ O
worst -X- _ O
. -X- _ O
5 -X- _ O
More -X- _ O
Pretraining -X- _ O
Languages -X- _ O
Our -X- _ O
main -X- _ O
takeaways -X- _ O
from -X- _ O
the -X- _ O
last -X- _ O
section -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
without -X- _ O
model -X- _ O
adaptation -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
unrelated -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
model -X- _ O
adaptation -X- _ O
largely -X- _ O
helps -X- _ O
exploiting -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
more -X- _ O
languages -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
1506 -X- _ O
when -X- _ O
using -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
pretraining -X- _ O
language -X- _ O
, -X- _ O
diversity -X- _ O
is -X- _ O
important -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
limitations -X- _ O
in -X- _ O
the -X- _ O
experimental -X- _ O
settings -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
relatively -X- _ O
small -X- _ O
pretraining -X- _ O
corpora -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
are -X- _ O
included -X- _ O
when -X- _ O
building -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
vocabulary -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
fixed -X- _ O
computational -X- _ O
resources -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
only -X- _ O
up -X- _ O
to -X- _ O
ten -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
explore -X- _ O
if -X- _ O
our -X- _ O
findings -X- _ O
for1 -X- _ O
and2 -X- _ O
hold -X- _ O
without -X- _ O
such -X- _ O
limitations -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
two -X- _ O
publicly -X- _ O
available -X- _ O
pretrained -X- _ O
models -X- _ O
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
pretrained -X- _ O
on -X- _ O
full -X- _ O
size -X- _ O
Wikipedia -X- _ B-DatasetName
in -X- _ O
17 -X- _ O
( -X- _ O
-17 -X- _ O
) -X- _ O
and -X- _ O
100 -X- _ O
( -X- _ O
-100 -X- _ O
) -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
-base -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
larger -X- _ O
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
100 -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
on -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
unseen -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
, -X- _ O
including -X- _ O
unseen -X- _ O
vocabularies -X- _ O
: -X- _ O
Maltese -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
Wolof -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
Yoruba -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
Erzya -X- _ O
( -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Northern -X- _ O
Sami -X- _ O
( -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
pretraining -X- _ O
languages -X- _ O
used -X- _ O
in -X- _ O
Div -X- _ O
- -X- _ O
X -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
-17 -X- _ O
except -X- _ O
for -X- _ O
Finnish -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
17 -X- _ O
pretraining -X- _ O
languages -X- _ O
for -X- _ O
17 -X- _ O
are -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
languages -X- _ O
for -X- _ O
-100 -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
averages -X- _ O
with -X- _ O
standard -X- _ O
deviations -X- _ O
from -X- _ O
three -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O
5.1 -X- _ O
Results -X- _ O
RQ1 -X- _ O
For -X- _ O
models -X- _ O
without -X- _ O
adaptation -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
does -X- _ O
not -X- _ O
improve -X- _ O
for -X- _ O
increasing -X- _ O
numbers -X- _ O
of -X- _ O
source -X- _ O
languages -X- _ O
( -X- _ O
Figure -X- _ O
8a -X- _ O
) -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
both -X- _ O
-17 -X- _ O
and -X- _ O
-100 -X- _ O
are -X- _ O
on -X- _ O
par -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
former -X- _ O
uses -X- _ O
17 -X- _ O
pretraining -X- _ O
languages -X- _ O
and -X- _ O
the -X- _ O
latter -X- _ O
uses -X- _ O
100 -X- _ O
. -X- _ O
One -X- _ O
exception -X- _ O
is -X- _ O
Northern -X- _ O
Sami -X- _ O
( -X- _ O
Uralic -X- _ O
language -X- _ O
with -X- _ O
Latin -X- _ O
script -X- _ O
) -X- _ O
due -X- _ O
to -X- _ O
17 -X- _ O
not -X- _ O
seeing -X- _ O
any -X- _ O
Uralic -X- _ O
languages -X- _ O
, -X- _ O
but -X- _ O
-100does -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
When -X- _ O
further -X- _ O
comparing -X- _ O
Div-10 -X- _ O
and -X- _ O
-17 -X- _ O
, -X- _ O
increase -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
by -X- _ O
additional -X- _ O
pretraining -X- _ O
languages -X- _ O
is -X- _ O
limited -X- _ O
. -X- _ O
Erzya -X- _ O
remains -X- _ O
constant -X- _ O
from -X- _ O
five -X- _ O
to -X- _ O
100 -X- _ O
languages -X- _ O
( -X- _ O
except -X- _ O
for -X- _ O
- -X- _ O
) -X- _ O
, -X- _ O
even -X- _ O
when -X- _ O
increasing -X- _ O
the -X- _ O
pretraining -X- _ O
corpus -X- _ O
size -X- _ O
from -X- _ O
downsampled -X- _ O
( -X- _ O
Div -X- _ O
- -X- _ O
X -X- _ O
) -X- _ O
to -X- _ O
full -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
-17 -X- _ O
and -X- _ O
-100 -X- _ O
) -X- _ O
. -X- _ O
RQ2 -X- _ O
For -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
adaptation -X- _ O
( -X- _ O
Figure -X- _ O
8b -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
significant -X- _ O
gap -X- _ O
between -X- _ O
-17 -X- _ O
and -X- _ O
100 -X- _ O
. -X- _ O
This -X- _ O
confirms -X- _ O
our -X- _ O
findings -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
section -X- _ O
: -X- _ O
more -X- _ O
pretraining -X- _ O
languages -X- _ O
is -X- _ O
beneficial -X- _ O
if -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
are -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
a -X- _ O
possible -X- _ O
explanation -X- _ O
is -X- _ O
that -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
of -X- _ O
-100 -X- _ O
’s -X- _ O
pretraining -X- _ O
languages -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
our -X- _ O
target -X- _ O
languages -X- _ O
and -X- _ O
such -X- _ O
languages -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
exploited -X- _ O
through -X- _ O
continued -X- _ O
pretraining -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Ukrainian -X- _ O
included -X- _ O
in -X- _ O
-100 -X- _ O
but -X- _ O
not -X- _ O
in -X- _ O
Div -X- _ O
- -X- _ O
X -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
having -X- _ O
the -X- _ O
model -X- _ O
see -X- _ O
more -X- _ O
languages -X- _ O
during -X- _ O
pretraining -X- _ O
is -X- _ O
better -X- _ O
when -X- _ O
the -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
each -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
6 -X- _ O
Related -X- _ O
Work -X- _ O
Static -X- _ O
Cross -X- _ O
- -X- _ O
lingual -X- _ O
Word -X- _ O
Embeddings -X- _ O
Static -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
embed -X- _ O
and -X- _ O
align -X- _ O
words -X- _ O
from -X- _ O
multiple -X- _ O
languages -X- _ O
for -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Lample -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
a -X- _ O
massive -X- _ O
one -X- _ O
trained -X- _ O
on -X- _ O
50 -X- _ O
+ -X- _ O
languages -X- _ O
( -X- _ O
Ammar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Static -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
embedding -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
classified -X- _ O
into -X- _ O
two -X- _ O
groups -X- _ O
: -X- _ O
supervised -X- _ O
and -X- _ O
unsupervised -X- _ O
. -X- _ O
Supervised -X- _ O
methods -X- _ O
use -X- _ O
bilingual -X- _ O
lexica -X- _ O
as -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
supervision -X- _ O
signal -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
pretrained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
unsupervised1507cross -X- _ O
- -X- _ O
lingual -X- _ O
embeddings -X- _ O
are -X- _ O
similar -X- _ O
because -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
a -X- _ O
bilingual -X- _ O
lexicon -X- _ O
. -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
explore -X- _ O
the -X- _ O
selection -X- _ O
of -X- _ O
transfer -X- _ O
language -X- _ O
using -X- _ O
both -X- _ O
data -X- _ O
- -X- _ O
independent -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
typological -X- _ O
) -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
data -X- _ O
- -X- _ O
dependent -X- _ O
features -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
lexical -X- _ O
overlap -X- _ O
) -X- _ O
. -X- _ O
Their -X- _ O
work -X- _ O
is -X- _ O
on -X- _ O
static -X- _ O
supervised -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
whereas -X- _ O
this -X- _ O
paper -X- _ O
explores -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Analysis -X- _ O
of -X- _ O
Pretrained -X- _ O
Multilingual -X- _ O
Models -X- _ O
on -X- _ O
Seen -X- _ O
Languages -X- _ O
Starting -X- _ O
from -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transferability -X- _ O
of -X- _ O
pretrained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
topic -X- _ O
of -X- _ O
interest -X- _ O
. -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
hypothesize -X- _ O
that -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
occurs -X- _ O
due -X- _ O
to -X- _ O
shared -X- _ O
tokens -X- _ O
across -X- _ O
languages -X- _ O
, -X- _ O
but -X- _ O
Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
can -X- _ O
be -X- _ O
successful -X- _ O
even -X- _ O
among -X- _ O
languages -X- _ O
without -X- _ O
shared -X- _ O
scripts -X- _ O
. -X- _ O
Other -X- _ O
work -X- _ O
investigates -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
learning -X- _ O
and -X- _ O
typological -X- _ O
features -X- _ O
( -X- _ O
Lauscher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
encoding -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
features -X- _ O
( -X- _ O
Libovický -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
’s -X- _ O
multilinguality -X- _ O
( -X- _ O
Dufter -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
analyses -X- _ O
have -X- _ O
either -X- _ O
been -X- _ O
limited -X- _ O
to -X- _ O
large -X- _ O
public -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
, -X- _ O
- -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
up -X- _ O
to -X- _ O
two -X- _ O
pretraining -X- _ O
languages -X- _ O
( -X- _ O
K -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
to -X- _ O
target -X- _ O
languages -X- _ O
seen -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
One -X- _ O
exception -X- _ O
is -X- _ O
the -X- _ O
concurrent -X- _ O
work -X- _ O
by -X- _ O
de -X- _ O
Vries -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
on -X- _ O
analyzing -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
language -X- _ O
for -X- _ O
the -X- _ O
taskspecific -X- _ O
training -X- _ O
data -X- _ O
on -X- _ O
unseen -X- _ O
languages -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
models -X- _ O
to -X- _ O
benefit -X- _ O
from -X- _ O
an -X- _ O
increasing -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
languages -X- _ O
. -X- _ O
7 -X- _ O
Conclusion -X- _ O
This -X- _ O
paper -X- _ O
explores -X- _ O
the -X- _ O
effect -X- _ O
which -X- _ O
pretraining -X- _ O
on -X- _ O
different -X- _ O
numbers -X- _ O
of -X- _ O
languages -X- _ O
has -X- _ O
on -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
after -X- _ O
finetuning -X- _ O
on -X- _ O
English -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
if -X- _ O
not -X- _ O
adapting -X- _ O
the -X- _ O
pretrained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
diverse -X- _ O
pretraining -X- _ O
languages -X- _ O
which -X- _ O
covers -X- _ O
the -X- _ O
script -X- _ O
and -X- _ O
family -X- _ O
of -X- _ O
unseen -X- _ O
target -X- _ O
languages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
17 -X- _ O
languages -X- _ O
used -X- _ O
for -X- _ O
-17 -X- _ O
) -X- _ O
is -X- _ O
likely -X- _ O
sufficient -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
if -X- _ O
adapting -X- _ O
the -X- _ O
pretrained -X- _ O
multilingual -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
target -X- _ O
languages -X- _ O
, -X- _ O
then -X- _ O
one -X- _ O
should -X- _ O
pretrain -X- _ O
on -X- _ O
as -X- _ O
many -X- _ O
languages -X- _ O
as -X- _ O
possible -X- _ O
up -X- _ O
to -X- _ O
at -X- _ O
least -X- _ O
100 -X- _ O
. -X- _ O
Future -X- _ O
directions -X- _ O
include -X- _ O
analyzing -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
multilingual -X- _ O
pretraining -X- _ O
from -X- _ O
different -X- _ O
perspectives -X- _ O
such -X- _ O
as -X- _ O
different -X- _ O
pretraining -X- _ O
tasks -X- _ O
and -X- _ O
architectures -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
mT5 -X- _ O
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
complex -X- _ O
tasks -X- _ O
beyond -X- _ O
classification -X- _ O
or -X- _ O
sequence -X- _ O
tagging -X- _ O
. -X- _ O
Acknowledgements -X- _ O
We -X- _ O
sincerely -X- _ O
thank -X- _ O
the -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
constructive -X- _ O
and -X- _ O
detailed -X- _ O
feedback -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
thank -X- _ O
the -X- _ O
members -X- _ O
of -X- _ O
University -X- _ O
of -X- _ O
Colorado -X- _ O
Boulder -X- _ O
’s -X- _ O
NALA -X- _ O
group -X- _ O
, -X- _ O
especially -X- _ O
Abteen -X- _ O
Ebrahimi -X- _ O
for -X- _ O
providing -X- _ O
the -X- _ O
code -X- _ O
and -X- _ O
Stéphane -X- _ O
Aroca -X- _ O
- -X- _ O
Ouellette -X- _ O
for -X- _ O
giving -X- _ O
feedback -X- _ O
on -X- _ O
an -X- _ O
early -X- _ O
draft -X- _ O
. -X- _ O
Boyd -X- _ O
- -X- _ O
Graber -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
ODNI -X- _ O
, -X- _ O
IARPA -X- _ O
, -X- _ O
via -X- _ O
the -X- _ O
BETTER -X- _ O
Program -X- _ O
contract -X- _ O
2019 -X- _ O
- -X- _ O
19051600005 -X- _ O
. -X- _ O
The -X- _ O
views -X- _ O
and -X- _ O
conclusions -X- _ O
contained -X- _ O
herein -X- _ O
are -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
and -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
necessarily -X- _ O
representing -X- _ O
the -X- _ O
official -X- _ O
policies -X- _ O
, -X- _ O
either -X- _ O
expressed -X- _ O
or -X- _ O
implied -X- _ O
, -X- _ O
of -X- _ O
ODNI -X- _ O
, -X- _ O
IARPA -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
U.S. -X- _ O
Government -X- _ O
. -X- _ O
The -X- _ O
U.S. -X- _ O
Government -X- _ O
is -X- _ O
authorized -X- _ O
to -X- _ O
reproduce -X- _ O
and -X- _ O
distribute -X- _ O
reprints -X- _ O
for -X- _ O
governmental -X- _ O
purposes -X- _ O
notwithstanding -X- _ O
any -X- _ O
copyright -X- _ O
annotation -X- _ O
therein -X- _ O
. -X- _ O
References150815091510 -X- _ O
A -X- _ O
Results -X- _ O
We -X- _ O
show -X- _ O
additional -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
in -X- _ O
Figures -X- _ O
9 -X- _ O
and -X- _ O
10 -X- _ O
. -X- _ O
BResults -X- _ O
Tables -X- _ O
5 -X- _ O
and -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
without -X- _ O
model -X- _ O
adaptation -X- _ O
, -X- _ O
and -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
full -X- _ O
results -X- _ O
with -X- _ O
model -X- _ O
adaptation -X- _ O
. -X- _ O
C -X- _ O
Notes -X- _ O
on -X- _ O
the -X- _ O
Experimental -X- _ O
Setup -X- _ O
for -X- _ O
Model -X- _ O
Adaptation -X- _ O
Following -X- _ O
are -X- _ O
the -X- _ O
additional -X- _ O
notes -X- _ O
on -X- _ O
the -X- _ O
setup -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
adaptation -X- _ O
: -X- _ O
•No -X- _ O
vocabulary -X- _ O
augmentation -X- _ O
is -X- _ O
conducted -X- _ O
unlike -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
- -X- _ O
’s -X- _ O
vocabulary -X- _ O
throughout -X- _ O
all -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
•The -X- _ B-DatasetName
Bible -X- _ I-DatasetName
is -X- _ O
used -X- _ O
instead -X- _ O
of -X- _ O
Wikipedia -X- _ B-DatasetName
for -X- _ O
the -X- _ O
continued -X- _ O
pretraining -X- _ O
or -X- _ O
model -X- _ O
adaptation -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
corpus -X- _ O
size -X- _ O
and -X- _ O
contents -X- _ O
inconsistency -X- _ O
across -X- _ O
languages.15111512 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
This -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
proposes -X- _ SUMMARY
a -X- _ SUMMARY
framework -X- _ SUMMARY
called -X- _ SUMMARY
Few -X- _ SUMMARY
- -X- _ SUMMARY
Shot -X- _ SUMMARY
Transformer -X- _ SUMMARY
based -X- _ SUMMARY
Enrichment -X- _ SUMMARY
( -X- _ SUMMARY
FeSTE -X- _ SUMMARY
) -X- _ SUMMARY
for -X- _ SUMMARY
enriching -X- _ SUMMARY
tabular -X- _ SUMMARY
datasets -X- _ SUMMARY
using -X- _ SUMMARY
unstructured -X- _ SUMMARY
data -X- _ SUMMARY
. -X- _ SUMMARY
FeSTE -X- _ SUMMARY
utilizes -X- _ SUMMARY
a -X- _ SUMMARY
pretrained -X- _ SUMMARY
language -X- _ SUMMARY
model -X- _ SUMMARY
( -X- _ SUMMARY
LM -X- _ SUMMARY
) -X- _ SUMMARY
and -X- _ SUMMARY
a -X- _ SUMMARY
novel -X- _ SUMMARY
fine -X- _ SUMMARY
- -X- _ SUMMARY
tuning -X- _ SUMMARY
approach -X- _ SUMMARY
to -X- _ SUMMARY
generate -X- _ SUMMARY
high -X- _ SUMMARY
- -X- _ SUMMARY
quality -X- _ SUMMARY
features -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
evaluates -X- _ SUMMARY
FeSTE -X- _ SUMMARY
on -X- _ SUMMARY
17 -X- _ SUMMARY
datasets -X- _ SUMMARY
and -X- _ SUMMARY
compares -X- _ SUMMARY
it -X- _ SUMMARY
to -X- _ SUMMARY
two -X- _ SUMMARY
baseline -X- _ SUMMARY
methods -X- _ SUMMARY
: -X- _ SUMMARY
target -X- _ SUMMARY
dataset -X- _ SUMMARY
fine -X- _ SUMMARY
- -X- _ SUMMARY
tuning -X- _ SUMMARY
and -X- _ SUMMARY
MT -X- _ SUMMARY
- -X- _ SUMMARY
DNN -X- _ SUMMARY
fine -X- _ SUMMARY
- -X- _ SUMMARY
tuning -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
include -X- _ SUMMARY
AUC -X- _ SUMMARY
and -X- _ SUMMARY
F -X- _ SUMMARY
- -X- _ SUMMARY
score -X- _ SUMMARY
. -X- _ SUMMARY
FeSTE -X- _ SUMMARY
outperforms -X- _ SUMMARY
the -X- _ SUMMARY
baselines -X- _ SUMMARY
in -X- _ SUMMARY
terms -X- _ SUMMARY
of -X- _ SUMMARY
AUC -X- _ SUMMARY
, -X- _ SUMMARY
achieving -X- _ SUMMARY
an -X- _ SUMMARY
average -X- _ SUMMARY
improvement -X- _ SUMMARY
of -X- _ SUMMARY
9.2 -X- _ SUMMARY
% -X- _ SUMMARY
when -X- _ SUMMARY
combined -X- _ SUMMARY
with -X- _ SUMMARY
the -X- _ SUMMARY
datasets -X- _ SUMMARY
' -X- _ SUMMARY
original -X- _ SUMMARY
features -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
approach -X- _ SUMMARY
shows -X- _ SUMMARY
promising -X- _ SUMMARY
results -X- _ SUMMARY
even -X- _ SUMMARY
when -X- _ SUMMARY
applied -X- _ SUMMARY
to -X- _ SUMMARY
datasets -X- _ SUMMARY
with -X- _ SUMMARY
limited -X- _ SUMMARY
size -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
it -X- _ SUMMARY
demonstrates -X- _ SUMMARY
generalization -X- _ SUMMARY
capabilities -X- _ SUMMARY
by -X- _ SUMMARY
leveraging -X- _ SUMMARY
knowledge -X- _ SUMMARY
from -X- _ SUMMARY
multiple -X- _ SUMMARY
datasets -X- _ SUMMARY
. -X- _ SUMMARY
Additional -X- _ SUMMARY
experiments -X- _ SUMMARY
using -X- _ SUMMARY
a -X- _ SUMMARY
different -X- _ SUMMARY
entity -X- _ SUMMARY
linking -X- _ SUMMARY
approach -X- _ SUMMARY
also -X- _ SUMMARY
validate -X- _ SUMMARY
the -X- _ SUMMARY
effectiveness -X- _ SUMMARY
of -X- _ SUMMARY
FeSTE -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.111.txt -X- _ O
Asaf -X- _ O
Harari -X- _ O
, -X- _ O
Gilad -X- _ O
Katz -X- _ O
Ben -X- _ O
- -X- _ O
Gurion -X- _ O
University -X- _ O
of -X- _ O
the -X- _ O
Negev -X- _ O
, -X- _ O
P.O.B. -X- _ O
653 -X- _ O
Beer -X- _ O
- -X- _ O
Sheva -X- _ O
, -X- _ O
Israel -X- _ O
{ -X- _ O
hsaf -X- _ O
, -X- _ O
giladkz -X- _ O
} -X- _ O
@ -X- _ O
post.bgu.ac.il -X- _ O
Abstract -X- _ O
The -X- _ O
enrichment -X- _ O
of -X- _ O
tabular -X- _ O
datasets -X- _ O
using -X- _ O
external -X- _ O
sources -X- _ O
has -X- _ O
gained -X- _ O
significant -X- _ O
attention -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O
Existing -X- _ O
solutions -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
either -X- _ O
ignore -X- _ O
external -X- _ O
unstructured -X- _ O
data -X- _ O
completely -X- _ O
or -X- _ O
devise -X- _ O
dataset -X- _ O
- -X- _ O
specific -X- _ O
solutions -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
Few -X- _ B-TaskName
- -X- _ I-TaskName
Shot -X- _ I-TaskName
Transformer -X- _ I-TaskName
based -X- _ I-TaskName
Enrichment -X- _ I-TaskName
( -X- _ O
FeSTE -X- _ B-TaskName
) -X- _ O
, -X- _ O
a -X- _ O
generic -X- _ O
and -X- _ O
robust -X- _ O
framework -X- _ O
for -X- _ O
the -X- _ O
enrichment -X- _ O
of -X- _ O
tabular -X- _ O
datasets -X- _ O
using -X- _ O
unstructured -X- _ O
data -X- _ O
. -X- _ O
By -X- _ O
training -X- _ O
over -X- _ O
multiple -X- _ O
datasets -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
develop -X- _ O
generic -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
additional -X- _ O
datasets -X- _ O
with -X- _ O
minimal -X- _ O
training -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
adaptation -X- _ O
of -X- _ O
BERT -X- _ B-TaskName
, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
novel -X- _ O
finetuning -X- _ O
approach -X- _ O
that -X- _ O
reformulates -X- _ O
the -X- _ O
tuples -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
as -X- _ O
sentences -X- _ O
. -X- _ O
Our -X- _ O
evaluation -X- _ O
, -X- _ O
conducted -X- _ O
on -X- _ O
17 -X- _ O
datasets -X- _ O
, -X- _ O
shows -X- _ O
that -X- _ O
FeSTE -X- _ B-TaskName
is -X- _ O
able -X- _ O
to -X- _ O
generate -X- _ O
high -X- _ O
quality -X- _ O
features -X- _ O
and -X- _ O
significantly -X- _ O
outperform -X- _ O
existing -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
solutions -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Tabular -X- _ O
data -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
diverse -X- _ O
format -X- _ O
of -X- _ O
data -X- _ O
representation -X- _ O
, -X- _ O
spanning -X- _ O
domains -X- _ O
from -X- _ O
nutrition -X- _ O
to -X- _ O
banking -X- _ O
. -X- _ O
It -X- _ O
does -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
suffer -X- _ O
from -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
contextual -X- _ O
information -X- _ O
that -X- _ O
could -X- _ O
make -X- _ O
its -X- _ O
analysis -X- _ O
more -X- _ O
effective -X- _ O
. -X- _ O
Data -X- _ O
scientists -X- _ O
seek -X- _ O
to -X- _ O
overcome -X- _ O
this -X- _ O
limitation -X- _ O
by -X- _ O
using -X- _ O
feature -X- _ O
engineering -X- _ O
( -X- _ O
FE -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
involves -X- _ O
applying -X- _ O
transformations -X- _ O
on -X- _ O
existing -X- _ O
features -X- _ O
to -X- _ O
create -X- _ O
additional -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
available -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
sufficiently -X- _ O
diverse -X- _ O
( -X- _ O
or -X- _ O
when -X- _ O
additional -X- _ O
improvement -X- _ O
is -X- _ O
sought -X- _ O
) -X- _ O
, -X- _ O
one -X- _ O
may -X- _ O
attempt -X- _ O
to -X- _ O
use -X- _ O
external -X- _ O
information -X- _ O
sources -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
process -X- _ O
as -X- _ O
external -X- _ O
enrichment -X- _ O
of -X- _ O
datasets -X- _ O
( -X- _ O
EED -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
use -X- _ O
of -X- _ O
external -X- _ O
sources -X- _ O
for -X- _ O
feature -X- _ O
engineering -X- _ O
is -X- _ O
both -X- _ O
computationally -X- _ O
- -X- _ O
heavy -X- _ O
and -X- _ O
time -X- _ O
consuming -X- _ O
. -X- _ O
The -X- _ O
process -X- _ O
first -X- _ O
involves -X- _ O
matching -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
external -X- _ O
source -X- _ O
, -X- _ O
a -X- _ O
process -X- _ O
known -X- _ O
as -X- _ O
Entity -X- _ O
Linking -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Once -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
external -X- _ O
source -X- _ O
havebeen -X- _ O
matched -X- _ O
, -X- _ O
candidate -X- _ O
features -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
generated -X- _ O
, -X- _ O
evaluated -X- _ O
, -X- _ O
and -X- _ O
finally -X- _ O
integrated -X- _ O
into -X- _ O
the -X- _ O
tabular -X- _ O
dataset -X- _ O
. -X- _ O
While -X- _ O
multiple -X- _ O
studies -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
Paulheim -X- _ O
and -X- _ O
Fümkranz -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Ristoski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Friedman -X- _ O
and -X- _ O
Markovitch -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Mountantonakis -X- _ O
and -X- _ O
Tzitzikas -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Galhotra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Harari -X- _ O
and -X- _ O
Katz -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
have -X- _ O
sought -X- _ O
to -X- _ O
automate -X- _ O
the -X- _ O
EED -X- _ O
process -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
majority -X- _ O
focuses -X- _ O
solely -X- _ O
onstructured -X- _ O
external -X- _ O
sources -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
DBpedia -X- _ O
tables -X- _ O
, -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
attempt -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
available -X- _ O
unstructured -X- _ O
data -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
free -X- _ O
text -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
Few -X- _ B-TaskName
- -X- _ I-TaskName
Shot -X- _ I-TaskName
Transformer -X- _ I-TaskName
based -X- _ I-TaskName
Enrichment -X- _ I-TaskName
( -X- _ O
FeSTE -X- _ B-TaskName
) -X- _ O
a -X- _ O
generic -X- _ O
and -X- _ O
robust -X- _ O
framework -X- _ O
for -X- _ O
the -X- _ O
enrichment -X- _ O
of -X- _ O
tabular -X- _ O
datasets -X- _ O
using -X- _ O
unstructured -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
utilizes -X- _ O
transformer -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
, -X- _ I-TaskName
pre -X- _ I-TaskName
- -X- _ I-TaskName
trained -X- _ I-TaskName
Language -X- _ I-TaskName
Models -X- _ I-TaskName
( -X- _ O
LM -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
identify -X- _ O
and -X- _ O
prioritize -X- _ O
promising -X- _ O
candidate -X- _ O
features -X- _ O
in -X- _ O
the -X- _ O
external -X- _ O
data -X- _ O
source -X- _ O
. -X- _ O
FeSTE -X- _ B-TaskName
then -X- _ O
applies -X- _ O
a -X- _ O
novel -X- _ O
process -X- _ O
of -X- _ O
analyzing -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
the -X- _ O
unstructured -X- _ O
features -X- _ O
and -X- _ O
the -X- _ O
dataset -X- _ O
’s -X- _ O
target -X- _ O
class -X- _ O
values -X- _ O
, -X- _ O
and -X- _ O
automatically -X- _ O
generating -X- _ O
new -X- _ O
tabular -X- _ O
features -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
difficulty -X- _ O
imposed -X- _ O
by -X- _ O
datasets -X- _ O
of -X- _ O
limited -X- _ O
size -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
FeSTE -X- _ B-TaskName
on -X- _ O
multiple -X- _ O
datasets -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
generic -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
later -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
additional -X- _ O
datasets -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
( -X- _ O
FT -X- _ O
) -X- _ O
process -X- _ O
that -X- _ O
enables -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
to -X- _ O
quickly -X- _ O
adapt -X- _ O
to -X- _ O
new -X- _ O
datasets -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
perform -X- _ O
few -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
learning -X- _ I-TaskName
) -X- _ O
. -X- _ O
The -X- _ O
result -X- _ O
of -X- _ O
this -X- _ O
process -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
robust -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
also -X- _ O
more -X- _ O
effective -X- _ O
on -X- _ O
small -X- _ O
datasets -X- _ O
. -X- _ O
While -X- _ O
previous -X- _ O
studies -X- _ O
— -X- _ O
TAPAS -X- _ O
( -X- _ O
Herzig -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
TaBERT -X- _ O
( -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
TURL -X- _ O
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
TPN -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
—have -X- _ O
attempted -X- _ O
to -X- _ O
use -X- _ O
Transformers -X- _ O
for -X- _ O
analyzing -X- _ O
tabular -X- _ O
data -X- _ O
, -X- _ O
FeSTE -X- _ O
focuses -X- _ O
on -X- _ O
analyzing -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
external -X- _ O
texts -X- _ O
and -X- _ O
the -X- _ O
dataset -X- _ O
’s -X- _ O
entities -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
therefore -X- _ O
able -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
Transformer -X- _ O
architecture -X- _ O
to -X- _ O
generate -X- _ O
additional -X- _ O
features -X- _ O
and -X- _ O
finetune -X- _ O
the -X- _ O
generation -X- _ O
process -X- _ O
in -X- _ O
a -X- _ O
novel -X- _ O
way -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
FeSTE -X- _ B-TaskName
on -X- _ O
17 -X- _ O
tabular -X- _ O
datasets -X- _ O
with1577diverse -X- _ O
characteristics -X- _ O
( -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
, -X- _ O
feature -X- _ O
composition -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BERT -X- _ B-TaskName
as -X- _ O
the -X- _ O
Transformer -X- _ O
architecture -X- _ O
and -X- _ O
Wikipedia -X- _ O
as -X- _ O
the -X- _ O
external -X- _ O
source -X- _ O
, -X- _ O
with -X- _ O
its -X- _ O
page -X- _ O
abstracts -X- _ O
as -X- _ O
our -X- _ O
unstructured -X- _ O
texts -X- _ O
. -X- _ O
Our -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
FeSTE -X- _ B-TaskName
outperforms -X- _ O
existing -X- _ O
BERT -X- _ B-TaskName
finetuning -X- _ O
strategies -X- _ O
and -X- _ O
that -X- _ O
FeSTE -X- _ B-TaskName
is -X- _ O
highly -X- _ O
effective -X- _ O
, -X- _ O
achieving -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
9.2 -X- _ O
% -X- _ O
when -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
datasets -X- _ O
’ -X- _ O
original -X- _ O
features -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
FeSTE -X- _ B-TaskName
performs -X- _ O
well -X- _ O
even -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
applied -X- _ O
on -X- _ O
its -X- _ O
own -X- _ O
( -X- _ O
without -X- _ O
any -X- _ O
original -X- _ O
features -X- _ O
) -X- _ O
, -X- _ O
achieving -X- _ O
an -X- _ O
average -X- _ O
AUC -X- _ B-TaskName
of -X- _ O
0.664 -X- _ B-TaskName
. -X- _ O
To -X- _ O
summarize -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
•Our -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
propose -X- _ O
a -X- _ O
generic -X- _ O
and -X- _ O
fully -X- _ O
- -X- _ O
automated -X- _ O
approach -X- _ O
for -X- _ O
tabular -X- _ O
data -X- _ O
enrichment -X- _ O
using -X- _ O
unstructured -X- _ O
external -X- _ O
sources -X- _ O
. -X- _ O
•We -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
“ -X- _ B-TaskName
few -X- _ I-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
” -X- _ I-TaskName
fine -X- _ I-TaskName
- -X- _ I-TaskName
tuning -X- _ I-TaskName
approach -X- _ O
for -X- _ O
transformer -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
pre -X- _ I-TaskName
- -X- _ I-TaskName
trained -X- _ I-TaskName
LM -X- _ I-TaskName
, -X- _ O
which -X- _ O
performs -X- _ O
well -X- _ O
even -X- _ O
for -X- _ O
training -X- _ O
sets -X- _ O
consisting -X- _ O
of -X- _ O
as -X- _ O
little -X- _ O
as -X- _ O
tens -X- _ O
of -X- _ O
samples -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
make -X- _ O
our -X- _ O
code -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
2.1 -X- _ O
Features -X- _ O
Generation -X- _ O
from -X- _ O
External -X- _ O
Sources -X- _ O
The -X- _ O
large -X- _ O
majority -X- _ O
of -X- _ O
work -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
automated -X- _ O
features -X- _ O
generation -X- _ O
from -X- _ O
external -X- _ O
information -X- _ O
sources -X- _ O
mainly -X- _ O
focuses -X- _ O
on -X- _ O
leveraging -X- _ O
structured -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
( -X- _ O
Paulheim -X- _ O
and -X- _ O
Fümkranz -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
uses -X- _ O
structured -X- _ O
data -X- _ O
from -X- _ O
knowledge -X- _ O
bases -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
such -X- _ O
as -X- _ O
DBpedia -X- _ B-TaskName
to -X- _ O
generate -X- _ O
new -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
to -X- _ O
augment -X- _ O
tabular -X- _ O
datasets -X- _ O
. -X- _ O
RapidMiner -X- _ O
( -X- _ O
Ristoski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
processes -X- _ O
KB -X- _ O
of -X- _ O
structured -X- _ O
tabular -X- _ O
and -X- _ O
graphical -X- _ O
data -X- _ O
by -X- _ O
modeling -X- _ O
the -X- _ O
relations -X- _ O
among -X- _ O
their -X- _ O
entities -X- _ O
. -X- _ O
Friedman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
Friedman -X- _ O
and -X- _ O
Markovitch -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
focus -X- _ O
on -X- _ O
features -X- _ O
generation -X- _ O
for -X- _ O
text -X- _ O
classification -X- _ O
problems -X- _ O
. -X- _ O
They -X- _ O
leverage -X- _ O
structured -X- _ O
data -X- _ O
from -X- _ O
two -X- _ O
KBs -X- _ O
: -X- _ O
FreeBase -X- _ O
( -X- _ O
Bollacker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
YAGO2 -X- _ O
( -X- _ O
Hoffart -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
first -X- _ O
identify -X- _ O
each -X- _ O
entity -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
recursively -X- _ O
explore -X- _ O
the -X- _ O
KB -X- _ O
to -X- _ O
extract -X- _ O
new -X- _ O
features -X- _ O
. -X- _ O
The -X- _ O
LodsyndesisML -X- _ O
framework -X- _ O
( -X- _ O
Mountantonakis -X- _ O
and -X- _ O
Tzitzikas -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
leverages -X- _ O
KB -X- _ O
’s -X- _ O
( -X- _ O
e.g -X- _ O
DBpedia -X- _ O
) -X- _ O
to -X- _ O
create -X- _ O
thousands -X- _ O
of -X- _ O
new -X- _ O
features -X- _ O
for -X- _ O
classification -X- _ O
tasks -X- _ O
using -X- _ O
nine -X- _ O
operators -X- _ O
. -X- _ O
Each -X- _ O
operator -X- _ O
creates -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
. -X- _ O
Galhotra -X- _ O
et -X- _ O
el -X- _ O
. -X- _ O
( -X- _ O
Galhotraet -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
use -X- _ O
structured -X- _ O
web -X- _ O
data -X- _ O
to -X- _ O
generate -X- _ O
new -X- _ O
features -X- _ O
for -X- _ O
classification -X- _ O
and -X- _ O
regression -X- _ O
tasks -X- _ O
. -X- _ O
Their -X- _ O
approach -X- _ O
generates -X- _ O
thousands -X- _ O
of -X- _ O
candidate -X- _ O
features -X- _ O
, -X- _ O
then -X- _ O
selects -X- _ O
the -X- _ O
final -X- _ O
set -X- _ O
using -X- _ O
information -X- _ O
theory -X- _ O
- -X- _ O
based -X- _ O
measures -X- _ O
such -X- _ O
as -X- _ O
Information -X- _ O
Gain -X- _ O
and -X- _ O
Pearson -X- _ O
correlation -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
the -X- _ O
only -X- _ O
study -X- _ O
to -X- _ O
utilize -X- _ O
both -X- _ O
structured -X- _ O
and -X- _ O
unstructured -X- _ O
sources -X- _ O
is -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
FGSES -X- _ B-TaskName
framework -X- _ O
( -X- _ O
Harari -X- _ O
and -X- _ O
Katz -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
FGSES -X- _ B-TaskName
extracts -X- _ O
features -X- _ O
from -X- _ O
both -X- _ O
structured -X- _ O
and -X- _ O
unstructured -X- _ O
DBpedia -X- _ B-TaskName
content -X- _ O
, -X- _ O
generates -X- _ O
thousands -X- _ O
of -X- _ O
candidate -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
uses -X- _ O
a -X- _ O
meta -X- _ O
learning -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
to -X- _ O
rank -X- _ O
them -X- _ O
and -X- _ O
return -X- _ O
a -X- _ O
small -X- _ O
final -X- _ O
set -X- _ O
. -X- _ O
While -X- _ O
this -X- _ O
approach -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
one -X- _ O
proposed -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
significant -X- _ O
differences -X- _ O
: -X- _ O
FeSTE -X- _ B-TaskName
focuses -X- _ O
on -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
, -X- _ O
performs -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
rather -X- _ O
than -X- _ O
relying -X- _ O
on -X- _ O
a -X- _ O
general -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
takes -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
analyzed -X- _ O
datasets -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
generates -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
and -X- _ O
is -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
more -X- _ O
computationally -X- _ O
efficient -X- _ O
. -X- _ O
2.2 -X- _ O
Wikipedia -X- _ O
as -X- _ O
an -X- _ O
External -X- _ O
Information -X- _ O
Source -X- _ O
Wikipedia -X- _ O
is -X- _ O
widely -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
external -X- _ O
source -X- _ O
of -X- _ O
information -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
availability -X- _ O
, -X- _ O
richness -X- _ O
, -X- _ O
and -X- _ O
diversity -X- _ O
( -X- _ O
Lehmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
important -X- _ O
addition -X- _ O
to -X- _ O
Wikipedia -X- _ O
from -X- _ O
an -X- _ O
entity -X- _ O
linking -X- _ O
standpoint -X- _ O
is -X- _ O
DBpedia -X- _ O
, -X- _ O
a -X- _ O
project -X- _ O
that -X- _ O
extracts -X- _ O
Wikipedia -X- _ O
data -X- _ O
and -X- _ O
makes -X- _ O
it -X- _ O
accessible -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
structured -X- _ O
form -X- _ O
. -X- _ O
DBpedia -X- _ B-TaskName
is -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
external -X- _ O
data -X- _ O
source -X- _ O
for -X- _ O
feature -X- _ O
engineering -X- _ O
by -X- _ O
multiple -X- _ O
studies -X- _ O
( -X- _ O
Paulheim -X- _ O
and -X- _ O
Fümkranz -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Ristoski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Galhotra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Mountantonakis -X- _ O
and -X- _ O
Tzitzikas -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
because -X- _ O
of -X- _ O
its -X- _ O
accessible -X- _ O
format -X- _ O
. -X- _ O
To -X- _ O
utilize -X- _ O
DBpedia -X- _ O
for -X- _ O
feature -X- _ O
engineering -X- _ O
in -X- _ O
tabular -X- _ O
data -X- _ O
, -X- _ O
one -X- _ O
should -X- _ O
first -X- _ O
link -X- _ O
the -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
analyzed -X- _ O
dataset -X- _ O
to -X- _ O
unique -X- _ O
DBpedia -X- _ O
entities -X- _ O
. -X- _ O
DBpedia -X- _ O
Spotlight -X- _ O
( -X- _ O
Mendes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
tool -X- _ O
for -X- _ O
automatically -X- _ O
identifying -X- _ O
and -X- _ O
linking -X- _ O
textual -X- _ O
entities -X- _ O
to -X- _ O
ones -X- _ O
on -X- _ O
DBpedia -X- _ B-TaskName
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
DBpedia -X- _ O
Spotlight -X- _ O
tends -X- _ O
to -X- _ O
capture -X- _ O
entities -X- _ O
whose -X- _ O
name -X- _ O
consists -X- _ O
only -X- _ O
of -X- _ O
one -X- _ O
or -X- _ O
two -X- _ O
words -X- _ O
, -X- _ O
while -X- _ O
ignoring -X- _ O
entities -X- _ O
composed -X- _ O
of -X- _ O
longer -X- _ O
sequences -X- _ O
. -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
Transformers -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
other -X- _ O
deep -X- _ O
learning -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
are -X- _ O
being -X- _ O
applied -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
semantic -X- _ O
relatedness -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
link -X- _ O
free -X- _ O
texts -X- _ O
to -X- _ O
DBpedia -X- _ O
. -X- _ O
Blink -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
BERT -X- _ B-TaskName
- -X- _ O
based -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
approach -X- _ O
which -X- _ O
receives -X- _ O
a -X- _ O
mention -X- _ O
and -X- _ O
its -X- _ O
surrounding -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
links -X- _ O
the -X- _ O
mention -X- _ O
to -X- _ O
its -X- _ O
corre-1578sponding -X- _ O
DBpedia -X- _ B-TaskName
entity -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
names -X- _ O
of -X- _ O
DBpedia -X- _ O
entities -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
shorter -X- _ O
than -X- _ O
in -X- _ O
free -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
hampers -X- _ O
Blink -X- _ O
’s -X- _ O
performance -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
( -X- _ O
Harari -X- _ O
and -X- _ O
Katz -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
developed -X- _ O
an -X- _ O
entity -X- _ O
linking -X- _ O
algorithm -X- _ O
whose -X- _ O
aim -X- _ O
is -X- _ O
to -X- _ O
link -X- _ O
entities -X- _ O
in -X- _ O
tabular -X- _ O
datasets -X- _ O
with -X- _ O
Wikipedia -X- _ O
pages -X- _ O
. -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
this -X- _ O
approach -X- _ O
in -X- _ O
Section -X- _ O
5.3 -X- _ O
. -X- _ O
2.3 -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Language -X- _ O
Models -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
influential -X- _ O
developments -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
NLP -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
is -X- _ O
the -X- _ O
emergence -X- _ O
of -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
LM -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
BERT -X- _ B-TaskName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
its -X- _ O
various -X- _ O
extensions -X- _ O
, -X- _ O
GPT -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
XLnet -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
( -X- _ O
SOTA -X- _ O
) -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
text -X- _ O
classification -X- _ O
, -X- _ O
question -X- _ O
answering -X- _ O
, -X- _ O
next -X- _ O
word -X- _ O
prediction -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
training -X- _ O
these -X- _ O
models -X- _ O
requires -X- _ O
expensive -X- _ O
hardware -X- _ O
and -X- _ O
very -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
reasons -X- _ O
, -X- _ O
the -X- _ O
large -X- _ O
majority -X- _ O
of -X- _ O
studies -X- _ O
and -X- _ O
applications -X- _ O
use -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
versions -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
fine -X- _ O
tuning -X- _ O
( -X- _ O
FT -X- _ O
) -X- _ O
these -X- _ O
models -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
additional -X- _ O
limited -X- _ O
training -X- _ O
on -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
hand -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Studies -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
three -X- _ O
FT -X- _ O
strategies -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
one -X- _ O
trains -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
on -X- _ O
similar -X- _ O
ML -X- _ O
task -X- _ O
( -X- _ O
e.g -X- _ O
text -X- _ O
classification -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Domain -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
similar -X- _ O
domain -X- _ O
( -X- _ O
e.g -X- _ O
biology -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Target -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
final -X- _ O
training -X- _ O
step -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
targeted -X- _ O
dataset -X- _ O
directly -X- _ O
. -X- _ O
The -X- _ O
aforementioned -X- _ O
studies -X- _ O
report -X- _ O
a -X- _ O
significant -X- _ O
improvement -X- _ O
in -X- _ O
BERT -X- _ O
’s -X- _ O
performance -X- _ O
, -X- _ O
especially -X- _ O
where -X- _ O
multi -X- _ O
- -X- _ O
phase -X- _ O
FT -X- _ O
was -X- _ O
performed -X- _ O
. -X- _ O
Another -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
strategy -X- _ O
called -X- _ O
Multi -X- _ O
- -X- _ O
Task -X- _ O
Deep -X- _ O
Neural -X- _ O
Network -X- _ O
( -X- _ O
MT -X- _ O
- -X- _ O
DNN -X- _ O
) -X- _ O
training -X- _ O
was -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
: -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
in -X- _ O
each -X- _ O
training -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
approach -X- _ O
modifies -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
but -X- _ O
keeps -X- _ O
the -X- _ O
lower -X- _ O
layers -X- _ O
unchanged -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
applied -X- _ O
in -X- _ O
cases -X- _ O
where -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
target -X- _ O
datasets -X- _ O
have -X- _ O
different -X- _ O
characteristics -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
. -X- _ O
One -X- _ O
significant -X- _ O
drawback -X- _ O
of -X- _ O
MT -X- _ O
- -X- _ O
DNN -X- _ O
is -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
replace -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
softmax -X- _ O
layer -X- _ O
) -X- _ O
whenever -X- _ O
it -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
problem -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
has -X- _ O
two -X- _ O
potential -X- _ O
shortcomings -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
given -X- _ O
that -X- _ O
FT -X- _ O
mainly -X- _ O
affect -X- _ O
BERT -X- _ O
’s -X- _ O
final -X- _ O
layers -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
some -X- _ O
loss -X- _ O
of -X- _ O
earlier -X- _ O
knowledgemay -X- _ O
occur -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
MT -X- _ O
- -X- _ O
DNN -X- _ O
needs -X- _ O
to -X- _ O
maintain -X- _ O
separate -X- _ O
final -X- _ O
layers -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
during -X- _ O
training -X- _ O
( -X- _ O
three -X- _ O
different -X- _ O
heads -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
study -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
cases -X- _ O
where -X- _ O
MT -X- _ O
- -X- _ O
DNN -X- _ O
is -X- _ O
training -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
datasets -X- _ O
, -X- _ O
this -X- _ O
could -X- _ O
pose -X- _ O
problems -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
memory -X- _ O
consumption -X- _ O
. -X- _ O
A -X- _ O
different -X- _ O
FT -X- _ O
approach -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
layers -X- _ O
was -X- _ O
proposed -X- _ O
by -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
used -X- _ O
an -X- _ O
" -X- _ O
instruction -X- _ O
FT -X- _ O
" -X- _ O
phase -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
added -X- _ O
instructions -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
statements -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
required -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
statements -X- _ O
are -X- _ O
correct -X- _ O
. -X- _ O
While -X- _ O
effective -X- _ O
, -X- _ O
analysis -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
approach -X- _ O
is -X- _ O
only -X- _ O
applicable -X- _ O
to -X- _ O
very -X- _ O
large -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
over -X- _ O
8B -X- _ O
parameters -X- _ O
to -X- _ O
the -X- _ O
already -X- _ O
large -X- _ O
architecture -X- _ O
of -X- _ O
137B. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
all -X- _ O
the -X- _ O
aforementioned -X- _ O
studies -X- _ O
, -X- _ O
FeSTE -X- _ B-TaskName
uses -X- _ O
a -X- _ O
single -X- _ O
architecture -X- _ O
for -X- _ O
its -X- _ O
training -X- _ O
process -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
datasets -X- _ O
used -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
dataset -X- _ O
reformulation -X- _ O
process -X- _ O
that -X- _ O
enables -X- _ O
us -X- _ O
to -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
architecture -X- _ O
on -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
their -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
enables -X- _ O
a -X- _ O
much -X- _ O
more -X- _ O
efficient -X- _ O
FT -X- _ O
process -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Section -X- _ O
5.3 -X- _ O
. -X- _ O
3 -X- _ O
Problem -X- _ O
Definition -X- _ O
For -X- _ O
our -X- _ O
task -X- _ O
of -X- _ O
feature -X- _ O
generation -X- _ O
from -X- _ O
the -X- _ O
free -X- _ O
text -X- _ O
of -X- _ O
external -X- _ O
sources -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
a -X- _ O
target -X- _ O
tabular -X- _ O
dataset -X- _ O
Dwith -X- _ O
a -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
analyzed -X- _ O
tabular -X- _ O
datasets -X- _ O
with -X- _ O
different -X- _ O
classification -X- _ O
tasks -X- _ O
( -X- _ O
i.e. -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
) -X- _ O
D= -X- _ O
{ -X- _ O
D -X- _ O
... -X- _ O
D -X- _ O
} -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
dataset -X- _ O
, -X- _ O
let -X- _ O
there -X- _ O
be -X- _ O
target -X- _ O
class -X- _ O
values -X- _ O
tcand -X- _ O
original -X- _ O
features -X- _ O
F. -X- _ O
OfF -X- _ O
, -X- _ O
let -X- _ O
there -X- _ O
be -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
feature -X- _ O
representing -X- _ O
entities -X- _ O
e= -X- _ O
{ -X- _ O
e -X- _ O
... -X- _ O
e -X- _ O
} -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
generating -X- _ O
new -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
an -X- _ O
external -X- _ O
data -X- _ O
source -X- _ O
EX -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
entitieseand -X- _ O
text -X- _ O
related -X- _ O
to -X- _ O
these -X- _ O
entities -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
this -X- _ O
set -X- _ O
of -X- _ O
texts -X- _ O
as -X- _ O
T. -X- _ O
For -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
linking -X- _ O
eande -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
an -X- _ O
entity -X- _ O
linking -X- _ O
function -X- _ O
Γ. -X- _ O
We -X- _ O
generate -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
new -X- _ O
features -X- _ O
ffromT -X- _ O
using -X- _ O
a -X- _ O
Language -X- _ O
Model -X- _ O
LM -X- _ O
. -X- _ O
4 -X- _ O
The -X- _ O
Proposed -X- _ O
Method -X- _ O
Overview -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
approach -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
and -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O
FeSTE -X- _ B-TaskName
consists -X- _ O
of -X- _ O
three -X- _ O
main -X- _ O
phases -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
entity -X- _ B-TaskName
linking -X- _ I-TaskName
; -X- _ O
b -X- _ O
) -X- _ O
fine -X- _ B-TaskName
- -X- _ I-TaskName
tuning -X- _ I-TaskName
, -X- _ O
and -X- _ O
; -X- _ O
c -X- _ O
) -X- _ O
features -X- _ B-TaskName
generation -X- _ I-TaskName
. -X- _ O
In -X- _ O
the -X- _ O
entity -X- _ B-TaskName
linking -X- _ I-TaskName
phase -X- _ O
, -X- _ O
FeSTE -X- _ B-TaskName
automatically -X- _ O
matches -X- _ O
entity -X- _ O
names -X- _ O
in -X- _ O
the -X- _ O
tabular -X- _ O
dataset -X- _ O
to -X- _ O
their -X- _ O
corresponding -X- _ O
entries -X- _ O
in -X- _ O
the -X- _ O
external -X- _ O
data -X- _ O
source -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
fine -X- _ B-TaskName
- -X- _ I-TaskName
tuning -X- _ I-TaskName
phase -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
feature1579generation -X- _ O
. -X- _ O
This -X- _ O
phase -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
stages -X- _ O
: -X- _ O
a -X- _ O
preliminary -X- _ O
stage -X- _ O
where -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
“ -X- _ O
offline -X- _ O
” -X- _ O
on -X- _ O
multiple -X- _ O
datasets -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
“ -X- _ O
online -X- _ O
” -X- _ O
stage -X- _ O
where -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
analyzed -X- _ O
dataset -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
features -X- _ B-TaskName
generation -X- _ I-TaskName
phase -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
newly -X- _ O
- -X- _ O
generated -X- _ O
features -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
tabular -X- _ O
dataset -X- _ O
. -X- _ O
4.1 -X- _ O
The -X- _ O
Entity -X- _ B-TaskName
Linking -X- _ I-TaskName
Phase -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
phase -X- _ O
is -X- _ O
to -X- _ O
link -X- _ O
entities -X- _ O
from -X- _ O
our -X- _ O
analyzed -X- _ O
dataset -X- _ O
Dto -X- _ O
entries -X- _ O
/ -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
external -X- _ O
data -X- _ O
source -X- _ O
EX -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
step -X- _ O
# -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
identification -X- _ O
of -X- _ O
relevant -X- _ O
entities -X- _ O
is -X- _ O
a -X- _ O
necessary -X- _ O
first -X- _ O
step -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
entities -X- _ O
selected -X- _ O
in -X- _ O
this -X- _ O
phase -X- _ O
will -X- _ O
be -X- _ O
processed -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
phases -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
we -X- _ O
use -X- _ O
Wikipedia -X- _ O
as -X- _ O
our -X- _ O
external -X- _ O
source -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
Google -X- _ O
Search -X- _ O
as -X- _ O
our -X- _ O
linking -X- _ O
and -X- _ O
disambiguation -X- _ O
tool -X- _ O
. -X- _ O
Obviously -X- _ O
, -X- _ O
other -X- _ O
external -X- _ O
sources -X- _ O
of -X- _ O
information -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Reuters -X- _ O
news -X- _ O
or -X- _ O
Yago -X- _ O
( -X- _ O
Hoffart -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
) -X- _ O
will -X- _ O
require -X- _ O
a -X- _ O
different -X- _ O
linking -X- _ O
strategy -X- _ O
, -X- _ O
but -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
easily -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
support -X- _ O
them -X- _ O
. -X- _ O
Our -X- _ O
chosen -X- _ O
entity -X- _ O
linking -X- _ O
process -X- _ O
is -X- _ O
straightforward -X- _ O
: -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
entity -X- _ O
in -X- _ O
einDwe -X- _ O
query -X- _ O
Google -X- _ O
Search -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
Wikipedia -X- _ O
and -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
: -X- _ O
< -X- _ O
lookup -X- _ O
> -X- _ O
is -X- _ O
a -X- _ O
< -X- _ O
domain -X- _ O
> -X- _ O
site -X- _ O
: -X- _ O
en.wikipedia.org -X- _ O
where -X- _ O
< -X- _ O
lookup -X- _ O
> -X- _ O
is -X- _ O
the -X- _ O
entity -X- _ O
emention -X- _ O
and -X- _ O
< -X- _ O
domain -X- _ O
> -X- _ O
is -X- _ O
the -X- _ O
entities -X- _ O
domain -X- _ O
( -X- _ O
entities -X- _ O
column -X- _ O
name -X- _ O
) -X- _ O
. -X- _ O
for -X- _ O
example -X- _ O
: -X- _ O
USA -X- _ O
is -X- _ O
a -X- _ O
country -X- _ O
site -X- _ O
: -X- _ O
en.wikipedia.org -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
our -X- _ O
queries -X- _ O
returns -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
Wikipedia -X- _ O
pages -X- _ O
which -X- _ O
are -X- _ O
most -X- _ O
likely -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
entity -X- _ O
. -X- _ O
FeSTE -X- _ B-TaskName
then -X- _ O
extracts -X- _ O
the -X- _ O
Wikipedia -X- _ O
page -X- _ O
referenced -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
entry -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
also -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
automatic -X- _ O
disambiguation -X- _ O
, -X- _ O
because -X- _ O
we -X- _ O
pair -X- _ O
e -X- _ O
with -X- _ O
its -X- _ O
most -X- _ O
popular -X- _ O
interpretation -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
this -X- _ O
phase -X- _ O
, -X- _ O
each -X- _ O
dataset -X- _ O
Dentity -X- _ O
ehas -X- _ O
a -X- _ O
linked -X- _ O
Wikipedia -X- _ O
entity -X- _ O
e. -X- _ O
FeSTE -X- _ B-TaskName
then -X- _ O
extracts -X- _ O
the -X- _ O
abstracts -X- _ O
of -X- _ O
those -X- _ O
entities -X- _ O
using -X- _ O
DBpedia -X- _ O
. -X- _ O
4.2 -X- _ O
The -X- _ O
Fine -X- _ O
- -X- _ O
Tuning -X- _ O
Phase -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
phase -X- _ O
is -X- _ O
to -X- _ O
adapt -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
NLP -X- _ B-TaskName
architectures -X- _ O
, -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPT -X- _ B-TaskName
, -X- _ O
BERT -X- _ B-TaskName
, -X- _ O
and -X- _ O
their -X- _ O
extensions -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
selecting -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
features -X- _ O
from -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
linked -X- _ O
external -X- _ O
source -X- _ O
entities -X- _ O
e. -X- _ O
As -X- _ O
explained -X- _ O
in -X- _ O
Section -X- _ O
2.3 -X- _ O
, -X- _ O
two -X- _ O
common -X- _ O
FT -X- _ B-TaskName
approaches -X- _ O
are -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
finetuning -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
, -X- _ O
andpreliminary -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
applied -X- _ O
on -X- _ O
other -X- _ O
datasets -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
former -X- _ O
is -X- _ O
more -X- _ O
common -X- _ O
, -X- _ O
recent -X- _ O
studies -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
applying -X- _ O
both -X- _ O
— -X- _ O
the -X- _ O
latter -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
former -X- _ O
— -X- _ O
yields -X- _ O
better -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
difficulty -X- _ O
in -X- _ O
applying -X- _ O
preliminary -X- _ O
FT -X- _ B-TaskName
to -X- _ O
tabular -X- _ O
datasets -X- _ O
stems -X- _ O
from -X- _ O
their -X- _ O
diversity -X- _ O
: -X- _ O
tabular -X- _ O
datasets -X- _ O
differ -X- _ O
greatly -X- _ O
in -X- _ O
their -X- _ O
domains -X- _ O
, -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
, -X- _ O
feature -X- _ O
composition -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
These -X- _ O
differences -X- _ O
make -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
a -X- _ O
generic -X- _ O
features -X- _ O
engineering -X- _ O
tool -X- _ O
very -X- _ O
difficult -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
this -X- _ O
challenge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
FT -X- _ O
approach -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
step -X- _ O
# -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
stages -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
preliminary -X- _ O
FT -X- _ B-TaskName
with -X- _ O
dataset -X- _ O
task -X- _ O
reformulation -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
Target -X- _ B-TaskName
Dataset -X- _ I-TaskName
Fine -X- _ I-TaskName
- -X- _ I-TaskName
Tuning -X- _ I-TaskName
using -X- _ O
only -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
’s -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
FT -X- _ B-TaskName
. -X- _ O
Preliminary -X- _ O
FT -X- _ B-TaskName
with -X- _ O
dataset -X- _ O
task -X- _ O
reformulation -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
challenge -X- _ O
in -X- _ O
learning -X- _ O
from -X- _ O
multiple -X- _ O
tabular -X- _ O
datasets -X- _ O
, -X- _ O
aside -X- _ O
from -X- _ O
their -X- _ O
highly -X- _ O
diverse -X- _ O
content -X- _ O
and -X- _ O
characteristics -X- _ O
, -X- _ O
is -X- _ O
their -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
. -X- _ O
Such -X- _ O
a -X- _ O
setup -X- _ O
makes -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
output -X- _ O
layer -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
number -X- _ O
of -X- _ O
entries -X- _ O
impossible -X- _ O
. -X- _ O
We -X- _ O
overcome -X- _ O
this -X- _ O
challenge -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
For -X- _ O
each -X- _ O
dataset -X- _ O
Dlet -X- _ O
there -X- _ O
be -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
free -X- _ O
texts -X- _ O
T -X- _ O
, -X- _ O
each -X- _ O
associated -X- _ O
with -X- _ O
an -X- _ O
entity -X- _ O
einD. -X- _ O
For -X- _ O
eachT -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
Cartesian -X- _ O
product -X- _ O
TXTC -X- _ O
, -X- _ O
where -X- _ O
TCconsists -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
target -X- _ O
classes -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
D. -X- _ O
Namely -X- _ O
, -X- _ O
we -X- _ O
pair -X- _ O
the -X- _ O
text -X- _ O
Twith -X- _ O
all -X- _ O
possible -X- _ O
target -X- _ O
class -X- _ O
values -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
now -X- _ O
treat -X- _ O
the -X- _ O
problem -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
Sentence -X- _ O
- -X- _ O
pairs -X- _ O
classification -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
presented -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
consisting -X- _ O
of -X- _ O
three -X- _ O
elements -X- _ O
{ -X- _ O
T -X- _ O
, -X- _ O
tc -X- _ O
, -X- _ O
l -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
Tis -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
first -X- _ O
sentence -X- _ O
) -X- _ O
, -X- _ O
tcis -X- _ O
a -X- _ O
possible -X- _ O
target -X- _ O
class -X- _ O
value -X- _ O
( -X- _ O
second -X- _ O
sentence -X- _ O
) -X- _ O
and -X- _ O
lthe -X- _ O
label -X- _ O
. -X- _ O
lset -X- _ O
to -X- _ O
True -X- _ O
if -X- _ O
{ -X- _ O
T -X- _ O
, -X- _ O
tc -X- _ O
} -X- _ O
∈ -X- _ O
{ -X- _ O
T -X- _ O
, -X- _ O
tc -X- _ O
} -X- _ O
. -X- _ O
This -X- _ O
setting -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
full -X- _ O
in -X- _ O
Algorithm -X- _ O
2 -X- _ O
, -X- _ O
creates -X- _ O
a -X- _ O
unified -X- _ O
representation -X- _ O
for -X- _ O
all -X- _ O
tabular -X- _ O
datasets -X- _ O
regardless -X- _ O
of -X- _ O
their -X- _ O
original -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
. -X- _ O
Simply -X- _ O
put -X- _ O
, -X- _ O
we -X- _ O
reformulated -X- _ O
the -X- _ O
original -X- _ O
task -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
into -X- _ O
a -X- _ O
NLP -X- _ B-TaskName
downstream -X- _ O
task -X- _ O
whose -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
classify -X- _ O
whether -X- _ O
a -X- _ O
given -X- _ O
text -X- _ O
Tis -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
class -X- _ O
value -X- _ O
tc -X- _ O
. -X- _ O
Once -X- _ O
we -X- _ O
have -X- _ O
reformulated -X- _ O
our -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
it -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
preliminary -X- _ O
- -X- _ O
FT -X- _ B-TaskName
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
input -X- _ O
we -X- _ O
provide -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
a -X- _ O
classification -X- _ O
token -X- _ O
and -X- _ O
a -X- _ O
separation -X- _ O
token -X- _ O
: -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
< -X- _ O
T -X- _ O
> -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
< -X- _ O
tc -X- _ O
> -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
1580 -X- _ O
where -X- _ O
Tis -X- _ O
the -X- _ O
free -X- _ O
text -X- _ O
, -X- _ O
tcis -X- _ O
the -X- _ O
assigned -X- _ O
target -X- _ O
class -X- _ O
value -X- _ O
, -X- _ O
and -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
are -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
special -X- _ O
tokens -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
“ -X- _ O
AAUP -X- _ B-DatasetName
” -X- _ O
, -X- _ O
whose -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
a -X- _ O
university -X- _ O
is -X- _ O
ranked -X- _ O
as -X- _ O
“ -X- _ O
high -X- _ O
” -X- _ O
or -X- _ O
“ -X- _ O
low -X- _ O
” -X- _ O
, -X- _ O
is -X- _ O
presented -X- _ O
below -X- _ O
: -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
Alaska -X- _ O
Pacific -X- _ O
University -X- _ O
( -X- _ O
APU -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
private -X- _ O
university -X- _ O
in -X- _ O
Anchorage -X- _ O
, -X- _ O
Alaska -X- _ O
... -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
Low -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
This -X- _ O
phase -X- _ O
of -X- _ O
our -X- _ O
FT -X- _ O
process -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
BERT -X- _ O
’s -X- _ O
standard -X- _ O
auxiliary -X- _ O
training -X- _ O
task -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
architecture -X- _ O
is -X- _ O
tasked -X- _ O
with -X- _ O
determining -X- _ O
whether -X- _ O
the -X- _ O
class -X- _ O
assigned -X- _ O
to -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
correct -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
is -X- _ O
it -X- _ O
the -X- _ O
one -X- _ O
that -X- _ O
appeared -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
? -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
finetuning -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
loss -X- _ O
function -X- _ O
that -X- _ O
is -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
architecture -X- _ O
’s -X- _ O
auxiliary -X- _ O
task -X- _ O
. -X- _ O
Our -X- _ O
data -X- _ O
formulation -X- _ O
enables -X- _ O
us -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
BERT -X- _ B-MethodName
simultaneously -X- _ O
over -X- _ O
a -X- _ O
large -X- _ O
set -X- _ O
of -X- _ O
datasets -X- _ O
, -X- _ O
thus -X- _ O
creating -X- _ O
a -X- _ O
generic -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
effectively -X- _ O
applied -X- _ O
to -X- _ O
additional -X- _ O
datasets -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
a -X- _ O
similar -X- _ O
process -X- _ O
of -X- _ O
including -X- _ O
the -X- _ O
class -X- _ O
value -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
was -X- _ O
previously -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
Text -X- _ O
Classification -X- _ O
( -X- _ O
Yin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
new -X- _ O
classes -X- _ O
appearing -X- _ O
in -X- _ O
mid -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Target -X- _ O
dataset -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
preliminary -X- _ O
FT -X- _ B-TaskName
was -X- _ O
to -X- _ O
adapt -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LM -X- _ O
for -X- _ O
the -X- _ O
general -X- _ O
task -X- _ O
of -X- _ O
feature -X- _ O
generation -X- _ O
for -X- _ O
tabular -X- _ O
datasets -X- _ O
. -X- _ O
Now -X- _ O
we -X- _ O
perform -X- _ O
additional -X- _ O
FT -X- _ B-TaskName
, -X- _ O
designed -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
LM -X- _ O
for -X- _ O
the -X- _ O
currently -X- _ O
analyzed -X- _ O
dataset -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
now -X- _ O
repeat -X- _ O
the -X- _ O
process -X- _ O
described -X- _ O
above -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
processrepeats -X- _ O
all -X- _ O
the -X- _ O
steps -X- _ O
of -X- _ O
the -X- _ O
preliminary -X- _ O
FT -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
reformulation -X- _ O
into -X- _ O
a -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
deep -X- _ O
architecture -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
finetuning -X- _ O
phases -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
partition -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
D -X- _ O
into -X- _ O
two -X- _ O
equal -X- _ O
parts -X- _ O
. -X- _ O
One -X- _ O
half -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
FT -X- _ B-TaskName
, -X- _ O
while -X- _ O
the -X- _ O
second -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
features -X- _ O
generation -X- _ O
process -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
describe -X- _ O
next -X- _ O
. -X- _ O
4.3 -X- _ O
The -X- _ O
Features -X- _ B-TaskName
Generation -X- _ I-TaskName
Phase -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
phase -X- _ O
is -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
generated -X- _ O
features -X- _ O
that -X- _ O
will -X- _ O
augment -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
features -X- _ O
generation -X- _ O
process -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
dataset -X- _ O
tuple -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
pretrained -X- _ O
LM -X- _ O
with -X- _ O
an -X- _ O
input -X- _ O
consisting -X- _ O
of -X- _ O
: -X- _ O
a -X- _ O
) -X- _ O
all -X- _ O
the -X- _ O
free -X- _ O
text -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
tuple -X- _ O
’s -X- _ O
entity -X- _ O
T -X- _ O
, -X- _ O
and -X- _ O
; -X- _ O
b -X- _ O
) -X- _ O
the -X- _ O
possible -X- _ O
target -X- _ O
class -X- _ O
values -X- _ O
we -X- _ O
generated -X- _ O
tc -X- _ O
. -X- _ O
Simply -X- _ O
put -X- _ O
, -X- _ O
we -X- _ O
task -X- _ O
the -X- _ O
LM -X- _ O
with -X- _ O
predicting -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
belonging -X- _ O
to -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
’s -X- _ O
classes -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
of -X- _ O
this -X- _ O
process -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
values -X- _ O
, -X- _ O
equal -X- _ O
in -X- _ O
length -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
these -X- _ O
values -X- _ O
is -X- _ O
added -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
feature -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
this -X- _ O
process -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
step -X- _ O
# -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
example -X- _ O
has -X- _ O
only -X- _ O
two -X- _ O
class -X- _ O
values -X- _ O
— -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
— -X- _ O
so -X- _ O
FeSTE -X- _ B-MethodName
creates -X- _ O
only -X- _ O
two -X- _ O
additional -X- _ O
features -X- _ O
that -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
set -X- _ O
. -X- _ O
It -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
varying -X- _ O
number -X- _ O
of -X- _ O
target -X- _ O
class -X- _ O
values -X- _ O
in -X- _ O
our -X- _ O
analyzed -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Sigmoid -X- _ O
function -X- _ O
and -X- _ O
evaluate -X- _ O
each -X- _ O
class -X- _ O
individ-1581ually -X- _ O
( -X- _ O
which -X- _ O
is -X- _ O
why -X- _ O
our -X- _ O
values -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
entity -X- _ O
do -X- _ O
n’t -X- _ O
add -X- _ O
up -X- _ O
to -X- _ O
1 -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Once -X- _ O
the -X- _ O
new -X- _ O
features -X- _ O
F -X- _ O
have -X- _ O
been -X- _ O
generated -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
Softmax -X- _ O
function -X- _ O
row -X- _ O
- -X- _ O
wise -X- _ O
to -X- _ O
receive -X- _ O
a -X- _ O
distribution -X- _ O
over -X- _ O
each -X- _ O
target -X- _ O
class -X- _ O
value -X- _ O
. -X- _ O
The -X- _ O
process -X- _ O
described -X- _ O
above -X- _ O
is -X- _ O
first -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
’s -X- _ O
training -X- _ O
set -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
half -X- _ O
that -X- _ O
is -X- _ O
retained -X- _ O
for -X- _ O
this -X- _ O
purpose -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
train -X- _ O
our -X- _ O
classifier -X- _ O
and -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
Before -X- _ O
each -X- _ O
tuple -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
classified -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
LM -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
, -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
elaborate -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
, -X- _ O
another -X- _ O
advantage -X- _ O
of -X- _ O
FeSTE -X- _ B-MethodName
is -X- _ O
the -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
features -X- _ O
it -X- _ O
generates -X- _ O
. -X- _ O
Unlike -X- _ O
previously -X- _ O
- -X- _ O
proposed -X- _ O
approaches -X- _ O
such -X- _ O
as -X- _ O
( -X- _ O
Harari -X- _ O
and -X- _ O
Katz -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
generate -X- _ O
thousands -X- _ O
of -X- _ O
features -X- _ O
, -X- _ O
the -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
features -X- _ O
generated -X- _ O
by -X- _ O
FeSTE -X- _ O
does -X- _ O
not -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
large -X- _ O
computational -X- _ O
overhead -X- _ O
. -X- _ O
5 -X- _ O
Evaluation -X- _ O
5.1 -X- _ O
The -X- _ O
Evaluated -X- _ O
Algorithms -X- _ O
We -X- _ O
compare -X- _ O
FeSTE -X- _ B-MethodName
to -X- _ O
the -X- _ O
two -X- _ O
leading -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
methods -X- _ O
: -X- _ O
target -X- _ B-MethodName
dataset -X- _ I-MethodName
FT -X- _ I-MethodName
andMT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
FT -X- _ I-MethodName
: -X- _ O
Target -X- _ B-MethodName
dataset -X- _ I-MethodName
FT -X- _ I-MethodName
. -X- _ O
For -X- _ O
this -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
architecture -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
left -X- _ O
side -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
and -X- _ O
the -X- _ O
texts -X- _ O
without -X- _ O
reformulation -X- _ O
nor -X- _ O
preliminary -X- _ O
FT -X- _ O
( -X- _ O
Algorithem -X- _ O
1 -X- _ O
, -X- _ O
lines -X- _ O
1,9 -X- _ O
- -X- _ O
11 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
is -X- _ O
the -X- _ O
commonly -X- _ O
used -X- _ O
FT -X- _ O
strategy -X- _ O
. -X- _ O
Algorithm -X- _ O
1 -X- _ O
: -X- _ O
FeSTE -X- _ B-MethodName
Algorithm -X- _ O
2 -X- _ O
: -X- _ O
Dataset -X- _ O
task -X- _ O
reformulation -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
FT -X- _ I-MethodName
. -X- _ O
For -X- _ O
this -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
execute -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
preliminary -X- _ O
FT -X- _ B-MethodName
step -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
architecture -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
left -X- _ O
side -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
BERT -X- _ B-MethodName
again -X- _ O
using -X- _ O
Target -X- _ B-MethodName
Dataset -X- _ I-MethodName
FT -X- _ I-MethodName
( -X- _ O
Algorithm -X- _ O
1 -X- _ O
, -X- _ O
lines -X- _ O
1,6,9 -X- _ O
- -X- _ O
11 -X- _ O
) -X- _ O
. -X- _ O
No -X- _ O
reformulation -X- _ O
is -X- _ O
performed -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
all -X- _ O
baselines -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
FeSTE -X- _ B-MethodName
, -X- _ O
are -X- _ O
evaluated -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
experimental -X- _ O
settings -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
approaches -X- _ O
is -X- _ O
their -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
methods -X- _ O
. -X- _ O
For -X- _ O
full -X- _ O
details -X- _ O
on -X- _ O
our -X- _ O
baselines -X- _ O
, -X- _ O
see -X- _ O
Section -X- _ O
2 -X- _ O
. -X- _ O
5.2 -X- _ O
Experimental -X- _ O
Setup -X- _ O
Datasets -X- _ O
and -X- _ O
evaluated -X- _ O
classifiers -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
17 -X- _ O
classification -X- _ O
datasets -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
variance -X- _ O
in -X- _ O
their -X- _ O
characteristics -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
were -X- _ O
obtained -X- _ O
from -X- _ O
public -X- _ O
repositories -X- _ O
such -X- _ O
as -X- _ O
Kaggle -X- _ B-DatasetName
, -X- _ O
UCI -X- _ B-DatasetName
( -X- _ O
Dua -X- _ O
and -X- _ O
Graff -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
OpenML -X- _ B-DatasetName
( -X- _ O
Vanschoren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
relevant -X- _ O
studies -X- _ O
( -X- _ O
Ristoski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
and -X- _ O
their -X- _ O
characteristics -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
When -X- _ O
applying -X- _ O
the -X- _ O
classifiers -X- _ O
on -X- _ O
each -X- _ O
dataset -X- _ O
( -X- _ O
after -X- _ O
its -X- _ O
features -X- _ O
have -X- _ O
already -X- _ O
been -X- _ O
augmented -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
four -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
train -X- _ O
on -X- _ O
three -X- _ O
folds -X- _ O
and1582evaluate -X- _ O
the -X- _ O
fourth -X- _ O
. -X- _ O
We -X- _ O
repeat -X- _ O
the -X- _ O
evaluation -X- _ O
four -X- _ O
times -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
five -X- _ O
classifiers -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
FeSTE -X- _ O
and -X- _ O
the -X- _ O
baselines -X- _ O
: -X- _ O
RandomForest -X- _ B-MethodName
, -X- _ O
MLP -X- _ B-MethodName
, -X- _ O
SVC -X- _ B-MethodName
, -X- _ O
KNeighbors -X- _ B-MethodName
, -X- _ O
and -X- _ O
GradientBoosting -X- _ B-MethodName
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
implementations -X- _ O
available -X- _ O
in -X- _ O
Scikit -X- _ O
- -X- _ O
learn -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
default -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
settings -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
preprocessing -X- _ O
we -X- _ O
perform -X- _ O
is -X- _ O
feature -X- _ O
normalization -X- _ O
. -X- _ O
Since -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
for -X- _ O
all -X- _ O
algorithms -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
average -X- _ O
results -X- _ O
. -X- _ O
Individual -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
Architectures -X- _ O
and -X- _ O
parameter -X- _ O
tuning -X- _ O
. -X- _ O
All -X- _ O
evaluated -X- _ O
models -X- _ O
( -X- _ O
FeSTE -X- _ B-MethodName
and -X- _ O
baselines -X- _ O
) -X- _ O
use -X- _ O
a -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
architecture -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
transformer -X- _ B-HyperparameterName
blocks -X- _ I-HyperparameterName
, -X- _ O
12 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
110 -X- _ O
million -X- _ O
parameters -X- _ O
( -X- _ O
Hugging -X- _ O
Face -X- _ O
Tensorflow -X- _ O
implementation -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
functions -X- _ O
used -X- _ O
by -X- _ O
all -X- _ O
finetuning -X- _ O
approaches -X- _ O
were -X- _ O
either -X- _ O
binary -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
or -X- _ O
multi -X- _ O
- -X- _ O
class -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
target -X- _ O
classes -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
only -X- _ O
the -X- _ O
embedding -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
vector -X- _ O
was -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
layer -X- _ O
. -X- _ O
When -X- _ O
evaluating -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
dataset -X- _ O
D -X- _ O
=D -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
the -X- _ O
BERTbased -X- _ O
architecture -X- _ O
on -X- _ O
the -X- _ O
remaining -X- _ O
datasets -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
d∈Dwhere -X- _ O
i̸=t -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
evaluate -X- _ O
FeSTE -X- _ O
on -X- _ O
17 -X- _ O
datasets -X- _ O
, -X- _ O
our -X- _ O
architecture -X- _ O
was -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
16 -X- _ O
datasets -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
17th -X- _ O
. -X- _ O
This -X- _ O
form -X- _ O
of -X- _ O
training -X- _ O
was -X- _ O
also -X- _ O
performed -X- _ O
for -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
. -X- _ O
FeSTE -X- _ B-MethodName
’s -X- _ O
preliminary -X- _ O
and -X- _ O
target -X- _ O
- -X- _ O
dataset -X- _ O
finetuning -X- _ O
settings -X- _ O
were -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
20 -X- _ O
training -X- _ O
epochs -X- _ O
with -X- _ O
early -X- _ O
stopping -X- _ O
, -X- _ O
mini -X- _ O
- -X- _ O
batches -X- _ O
of -X- _ O
8 -X- _ O
samples -X- _ O
, -X- _ O
a -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
period -X- _ O
of -X- _ O
one -X- _ O
epoch -X- _ O
, -X- _ O
no -X- _ O
dropout -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
learning -X- _ O
rate -X- _ O
of -X- _ O
1e-5 -X- _ O
and -X- _ O
2e-5 -X- _ O
for -X- _ O
preliminary -X- _ O
and -X- _ O
target -X- _ O
- -X- _ O
dataset -X- _ O
FTs -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
used -X- _ O
a -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
decay -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
experiments -X- _ O
we -X- _ O
used -X- _ O
an -X- _ O
Intel -X- _ O
Xeon -X- _ O
Gold -X- _ O
6140 -X- _ O
2.3GHz -X- _ O
Processor -X- _ O
and -X- _ O
192 -X- _ O
GB -X- _ O
RAM -X- _ O
. -X- _ O
5.3 -X- _ O
Evaluation -X- _ O
Results -X- _ O
We -X- _ O
conducted -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
is -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
novel -X- _ O
FT -X- _ B-MethodName
approach -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
two -X- _ O
leading -X- _ O
baselines -X- _ O
: -X- _ O
target -X- _ B-MethodName
- -X- _ I-MethodName
dataset -X- _ I-MethodName
FT -X- _ I-MethodName
, -X- _ O
and -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
. -X- _ O
The -X- _ O
second -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
FeSTE -X- _ B-MethodName
is -X- _ O
generic -X- _ O
by -X- _ O
evaluating -X- _ O
its -X- _ O
performance -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
different -X- _ O
entity -X- _ O
linking -X- _ O
approach -X- _ O
. -X- _ O
Evaluating -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
FT -X- _ B-MethodName
method -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
the -X- _ O
features -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
data -X- _ O
source -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
DBpedia -X- _ O
unstructured -X- _ O
text -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
train -X- _ O
our -X- _ O
classifiers -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
generated -X- _ O
features -X- _ O
and -X- _ O
ignore -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
evaluation -X- _ O
enables -X- _ O
us -X- _ O
to -X- _ O
more -X- _ O
accurately -X- _ O
quantify -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
each -X- _ O
FT -X- _ B-MethodName
approach -X- _ O
. -X- _ O
The -X- _ O
setup -X- _ O
of -X- _ O
this -X- _ O
evaluation -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
the -X- _ O
FeSTE -X- _ B-MethodName
algorithm -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
all -X- _ O
experiments -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
FT -X- _ B-MethodName
phases -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
either -X- _ O
the -X- _ O
Reformulation -X- _ O
method -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
4.2 -X- _ O
( -X- _ O
Algorithm -X- _ O
1 -X- _ O
, -X- _ O
lines -X- _ O
2 -X- _ O
- -X- _ O
8 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
baselines -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
While -X- _ O
it -X- _ O
is -X- _ O
clear -X- _ O
that -X- _ O
FeSTE -X- _ B-MethodName
performs -X- _ O
well -X- _ O
with -X- _ O
all -X- _ O
FT -X- _ B-MethodName
approaches -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
reformulation -X- _ O
approach -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
achieving -X- _ O
the -X- _ O
highest -X- _ O
results -X- _ O
in -X- _ O
10 -X- _ O
out -X- _ O
of -X- _ O
17 -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
AUC -X- _ B-HyperparameterValue
, -X- _ O
Reformulated -X- _ O
FT -X- _ B-MethodName
improves -X- _ O
upon -X- _ O
the -X- _ O
baselines -X- _ O
by -X- _ O
4.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
-6.8 -X- _ I-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Using -X- _ O
the -X- _ O
paired -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
determine -X- _ O
that -X- _ O
Reformulated -X- _ B-MethodName
FT -X- _ I-MethodName
outperforms -X- _ O
both -X- _ O
baselines -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.001 -X- _ O
. -X- _ O
While -X- _ O
Reformulated -X- _ B-MethodName
FT -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
across -X- _ O
all -X- _ O
dataset -X- _ O
sizes -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
noteworthy -X- _ O
our -X- _ O
approach -X- _ O
achieves -X- _ O
a -X- _ O
larger -X- _ O
relative -X- _ O
improvement -X- _ O
for -X- _ O
smaller -X- _ O
datasets -X- _ O
. -X- _ O
Improving -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
such -X- _ O
datasets -X- _ O
is -X- _ O
more -X- _ O
difficult -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
limited -X- _ O
amount -X- _ O
of -X- _ O
data -X- _ O
available -X- _ O
for -X- _ O
the -X- _ O
FT -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
" -X- _ O
Zoo -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
Country -X- _ O
Codes -X- _ O
" -X- _ O
datasets -X- _ O
contain -X- _ O
only -X- _ O
35 -X- _ O
and -X- _ O
75 -X- _ O
records -X- _ O
in -X- _ O
their -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
Reformulated -X- _ B-MethodName
FT -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
other -X- _ O
baselines -X- _ O
by -X- _ O
37 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
AUC -X- _ B-MetricName
— -X- _ O
well -X- _ O
above -X- _ O
the -X- _ O
overall -X- _ O
average -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
novel -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
which -X- _ O
leverages1583 -X- _ O
multiple -X- _ O
tabular -X- _ O
datasets -X- _ O
in -X- _ O
its -X- _ O
FT -X- _ O
process -X- _ O
. -X- _ O
Evaluating -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
our -X- _ O
FT -X- _ B-MethodName
method -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
evaluate -X- _ O
all -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
joint -X- _ O
set -X- _ O
of -X- _ O
original -X- _ O
and -X- _ O
generated -X- _ O
features -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
preprocessing -X- _ O
we -X- _ O
apply -X- _ O
is -X- _ O
feature -X- _ O
normalization -X- _ O
( -X- _ O
no -X- _ O
feature -X- _ O
selection -X- _ O
or -X- _ O
engineering -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
this -X- _ O
setup -X- _ O
the -X- _ O
most -X- _ O
realistic -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
FeSTE -X- _ B-MethodName
performs -X- _ O
well -X- _ O
with -X- _ O
all -X- _ O
FT -X- _ B-MethodName
approaches -X- _ O
and -X- _ O
our -X- _ O
reformulation -X- _ O
approach -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
achieving -X- _ O
the -X- _ O
highest -X- _ O
results -X- _ O
in -X- _ O
9 -X- _ O
out -X- _ O
of -X- _ O
17 -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
AUC -X- _ B-MetricValue
, -X- _ O
Reformulated -X- _ O
FT -X- _ O
improves -X- _ O
upon -X- _ O
the -X- _ O
baselines -X- _ O
by -X- _ O
1.4 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ I-MetricValue
2.3 -X- _ I-MetricValue
% -X- _ I-MetricValue
, -X- _ I-MetricValue
and -X- _ I-MetricValue
9.2 -X- _ I-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Using -X- _ O
the -X- _ O
paired -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
determine -X- _ O
that -X- _ O
Reformulated -X- _ B-MethodName
FT -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
three -X- _ O
baselines -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.001 -X- _ O
. -X- _ O
Evaluating -X- _ O
FeSTE -X- _ O
using -X- _ O
additional -X- _ O
entity -X- _ O
linking -X- _ O
approaches -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
previous -X- _ O
experiment -X- _ O
we -X- _ O
demonstrated -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
the -X- _ O
features -X- _ O
generated -X- _ O
by -X- _ O
FeSTE -X- _ B-MethodName
. -X- _ O
Our -X- _ O
goal -X- _ O
now -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
sufficiently -X- _ O
generic -X- _ O
to -X- _ O
be -X- _ O
applied -X- _ O
with -X- _ O
additional -X- _ O
forms -X- _ O
of -X- _ O
entity -X- _ O
linking -X- _ O
. -X- _ O
We -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
evaluate -X- _ O
FeSTE -X- _ B-MethodName
’s -X- _ O
performance -X- _ O
when -X- _ O
our -X- _ O
Google -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
linking -X- _ O
approach -X- _ O
is -X- _ O
replaced -X- _ O
by -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
FGSES -X- _ B-MethodName
approaches -X- _ O
presented -X- _ O
in -X- _ O
( -X- _ O
Harari -X- _ O
and -X- _ O
Katz -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
experiment -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
FeSTE -X- _ O
versions -X- _ O
— -X- _ O
Google -X- _ O
and -X- _ O
FGSES -X- _ O
- -X- _ O
based -X- _ O
— -X- _ O
where -X- _ O
the -X- _ O
generated -X- _ O
features -X- _ O
are -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
set -X- _ O
. -X- _ O
To -X- _ O
provide -X- _ O
a -X- _ O
meaningful -X- _ O
point -X- _ O
of -X- _ O
reference -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
include -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
by -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
set -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
clear -X- _ O
that -X- _ O
both -X- _ O
versions -X- _ O
of -X- _ O
FeSTE -X- _ O
outperform -X- _ O
the -X- _ O
original -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
achieved -X- _ O
better -X- _ O
performances -X- _ O
in -X- _ O
10 -X- _ O
out -X- _ O
of -X- _ O
17 -X- _ O
datasets -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
achieving -X- _ O
top -X- _ O
performance -X- _ O
in -X- _ O
only -X- _ O
6 -X- _ O
datasets -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
FeSTE -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
by -X- _ O
9.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
5.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
the -X- _ O
Google -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
FGSES -X- _ B-MethodName
- -X- _ O
based -X- _ O
entity -X- _ O
linking -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Using -X- _ O
the -X- _ O
paired -X- _ O
- -X- _ O
t -X- _ O
statistical -X- _ O
tests -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
once -X- _ O
again -X- _ O
shown -X- _ O
that -X- _ O
FeSTE -X- _ B-MethodName
superior -X- _ O
performance -X- _ O
is -X- _ O
statistically -X- _ O
significant -X- _ O
, -X- _ O
with -X- _ O
p -X- _ O
< -X- _ O
0.001 -X- _ O
, -X- _ O
compare -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
set -X- _ O
of -X- _ O
features -X- _ O
. -X- _ O
6 -X- _ O
Discussion -X- _ O
Cases -X- _ O
where -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
outperformed -X- _ O
the -X- _ O
augmented -X- _ O
features -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
5.3 -X- _ O
clearly -X- _ O
show -X- _ O
that -X- _ O
FeSTE -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
baselines -X- _ O
in -X- _ O
a -X- _ O
large -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
evaluated -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
datasets -X- _ O
where -X- _ O
our -X- _ O
approach -X- _ O
did -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
set -X- _ O
of -X- _ O
features.1584As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
six -X- _ O
datasets -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
set -X- _ O
outperformed -X- _ O
FeSTE -X- _ B-MethodName
. -X- _ O
We -X- _ O
analyzed -X- _ O
these -X- _ O
datasets -X- _ O
in -X- _ O
an -X- _ O
attempt -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
causes -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
’s -X- _ O
lower -X- _ O
performance -X- _ O
. -X- _ O
Our -X- _ O
conclusion -X- _ O
is -X- _ O
that -X- _ O
FeSTE -X- _ B-MethodName
is -X- _ O
in -X- _ O
greater -X- _ O
danger -X- _ O
of -X- _ O
underperforming -X- _ O
in -X- _ O
cases -X- _ O
of -X- _ O
“ -X- _ O
specialized -X- _ O
” -X- _ O
datasets -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
datasets -X- _ O
that -X- _ O
are -X- _ O
dedicated -X- _ O
to -X- _ O
highly -X- _ O
specific -X- _ O
topics -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
of -X- _ O
general -X- _ O
interest -X- _ O
. -X- _ O
In -X- _ O
such -X- _ O
use -X- _ O
- -X- _ O
cases -X- _ O
, -X- _ O
information -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
“ -X- _ O
general -X- _ O
” -X- _ O
data -X- _ O
source -X- _ O
like -X- _ O
DBPedia -X- _ B-DatasetName
might -X- _ O
not -X- _ O
be -X- _ O
adequate -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
such -X- _ O
a -X- _ O
use -X- _ O
case -X- _ O
is -X- _ O
the -X- _ O
WDI -X- _ O
dataset -X- _ O
, -X- _ O
whose -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
income -X- _ O
groups -X- _ O
of -X- _ O
various -X- _ O
countries -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
abstracts -X- _ O
of -X- _ O
the -X- _ O
linked -X- _ O
entities -X- _ O
simply -X- _ O
do -X- _ O
not -X- _ O
elaborate -X- _ O
on -X- _ O
the -X- _ O
topic -X- _ O
of -X- _ O
income -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
achieved -X- _ O
using -X- _ O
only -X- _ O
FeSTE -X- _ B-MethodName
’s -X- _ O
generated -X- _ O
features -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
( -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
our -X- _ O
generated -X- _ O
features -X- _ O
outperform -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
in -X- _ O
10 -X- _ O
out -X- _ O
of -X- _ O
17 -X- _ O
datasets -X- _ O
— -X- _ O
an -X- _ O
impressive -X- _ O
accomplishment -X- _ O
given -X- _ O
that -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
are -X- _ O
often -X- _ O
highly -X- _ O
informative -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
for -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
features -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
approach -X- _ O
outperform -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
by -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Moreover -X- _ O
, -X- _ O
in -X- _ O
some -X- _ O
datasets -X- _ O
our -X- _ O
approach -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
by -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
192 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Analyzing -X- _ O
FeSTE -X- _ B-MethodName
’s -X- _ O
Generalization -X- _ O
Capabilities -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
our -X- _ O
previous -X- _ O
experiments -X- _ O
, -X- _ O
FeSTE -X- _ O
was -X- _ O
finetuned -X- _ O
on -X- _ O
16 -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
analyze -X- _ O
our -X- _ O
approach -X- _ O
’s -X- _ O
ability -X- _ O
to -X- _ O
generalize -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
its -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
datasets -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
presents -X- _ O
FeSTE -X- _ O
’s -X- _ O
relative -X- _ O
improvement -X- _ O
compared -X- _ O
to -X- _ O
preliminary -X- _ O
FT -X- _ B-MethodName
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
even -X- _ O
four -X- _ O
FT -X- _ B-MethodName
datasets -X- _ O
yields -X- _ O
an -X- _ O
improvement -X- _ O
( -X- _ O
1.8 -X- _ O
% -X- _ O
) -X- _ O
compared -X- _ O
to -X- _ O
this -X- _ O
baseline -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
gap -X- _ O
rapidly -X- _ O
expanding -X- _ O
as -X- _ O
new -X- _ O
datasets -X- _ O
are -X- _ O
added -X- _ O
. -X- _ O
This -X- _ O
analysis -X- _ O
highlights -X- _ O
FeSTE -X- _ B-MethodName
’s -X- _ O
generic -X- _ O
nature -X- _ O
and -X- _ O
its -X- _ O
ability -X- _ O
to -X- _ O
leverage -X- _ O
knowledge -X- _ O
from -X- _ O
multiple -X- _ O
sources -X- _ O
. -X- _ O
Analyzing -X- _ O
FeSTE -X- _ B-MethodName
Relative -X- _ O
Efficiency -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
analysis -X- _ O
we -X- _ O
compare -X- _ O
FeSTE -X- _ B-MethodName
both -X- _ O
to -X- _ O
target -X- _ O
dataset -X- _ O
FT -X- _ O
and -X- _ O
to -X- _ O
MT -X- _ O
- -X- _ O
DNN -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Target -X- _ O
dataset -X- _ O
FT -X- _ O
is -X- _ O
clearly -X- _ O
the -X- _ O
most -X- _ O
efficient -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
approaches -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
constitutes -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
approaches -X- _ O
. -X- _ O
While -X- _ O
FeSTE -X- _ O
and -X- _ O
MT -X- _ O
- -X- _ O
DNN -X- _ O
were -X- _ O
implemented -X- _ O
using -X- _ O
identical -X- _ O
architectures -X- _ O
( -X- _ O
with -X- _ O
one -X- _ O
minor -X- _ O
difference -X- _ O
, -X- _ O
described -X- _ O
below -X- _ O
) -X- _ O
, -X- _ O
their -X- _ O
comparison -X- _ O
requires -X- _ O
us -X- _ O
to -X- _ O
consider -X- _ O
two -X- _ O
aspects -X- _ O
of -X- _ O
their -X- _ O
respective -X- _ O
implementations -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
While -X- _ O
FeSTE -X- _ B-MethodName
employs -X- _ O
the -X- _ O
same -X- _ O
architecture -X- _ O
for -X- _ O
all -X- _ O
datasets -X- _ O
, -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
must -X- _ O
train -X- _ O
a -X- _ O
new -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
each -X- _ O
new -X- _ O
task -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
datasets -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
task -X- _ O
but -X- _ O
with -X- _ O
a -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
seven -X- _ O
output -X- _ O
layers -X- _ O
for -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
constantly -X- _ O
re -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
, -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
incurs -X- _ O
significant -X- _ O
storage -X- _ O
costs -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
maintain -X- _ O
multiple -X- _ O
architectures -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
FeSTE -X- _ B-MethodName
incurs -X- _ O
an -X- _ O
additional -X- _ O
computational -X- _ O
cost -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
reformulation -X- _ O
phase -X- _ O
. -X- _ O
The -X- _ O
cost -X- _ O
of -X- _ O
reformulation -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
parts -X- _ O
: -X- _ O
the -X- _ O
first -X- _ O
is -X- _ O
the -X- _ O
reformulation -X- _ O
process -X- _ O
itself -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
is -X- _ O
the -X- _ O
additional -X- _ O
FT -X- _ O
as -X- _ O
a -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
larger -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
both -X- _ O
tasks -X- _ O
is -X- _ O
O -X- _ O
( -X- _ O
|C|∗|UniqueEntities -X- _ O
| -X- _ O
) -X- _ O
. -X- _ O
Please -X- _ O
note -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
that -X- _ O
in -X- _ O
tabular -X- _ O
dataset -X- _ O
both -X- _ O
number -X- _ O
of -X- _ O
classes -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
entities -X- _ O
is -X- _ O
relatively -X- _ O
small -X- _ O
. -X- _ O
To -X- _ O
summarize -X- _ O
, -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
will -X- _ O
likely -X- _ O
be -X- _ O
more -X- _ O
efficient -X- _ O
for -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
tasks -X- _ O
/ -X- _ O
datasets -X- _ O
, -X- _ O
each -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
. -X- _ O
FeSTE -X- _ B-MethodName
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
will -X- _ O
be -X- _ O
more -X- _ O
effective -X- _ O
on -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
datasets -X- _ O
and -X- _ O
tasks -X- _ O
, -X- _ O
possibly -X- _ O
containing -X- _ O
a -X- _ O
relatively -X- _ O
smaller -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
. -X- _ O
7 -X- _ O
Conclusions -X- _ O
We -X- _ O
present -X- _ O
FeSTE -X- _ B-MethodName
, -X- _ O
a -X- _ O
framework -X- _ O
for -X- _ O
generating -X- _ O
new -X- _ O
features -X- _ O
for -X- _ O
tabular -X- _ O
datasets -X- _ O
from -X- _ O
unstructured -X- _ O
sources -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
uses -X- _ O
a -X- _ O
novel -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
finetuning -X- _ O
process -X- _ O
that -X- _ O
enables -X- _ O
it -X- _ O
to -X- _ O
effectively -X- _ O
apply -X- _ O
transformer -X- _ O
based -X- _ O
LM -X- _ O
for -X- _ O
the -X- _ O
extraction -X- _ O
of -X- _ O
useful -X- _ O
features -X- _ O
even -X- _ O
when -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
is -X- _ O
limited -X- _ O
in -X- _ O
size -X- _ O
. -X- _ O
Our -X- _ O
FT -X- _ B-MethodName
approach -X- _ O
significantly -X- _ O
outperforms -X- _ O
the -X- _ O
existing -X- _ O
SOTA.1585References15861587A -X- _ O
Appendix -X- _ O
In -X- _ O
this -X- _ O
chapter -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
additional -X- _ O
tables -X- _ O
with -X- _ O
information -X- _ O
that -X- _ O
can -X- _ O
assist -X- _ O
the -X- _ O
reader -X- _ O
to -X- _ O
further -X- _ O
explore -X- _ O
our -X- _ O
evaluation -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
list -X- _ O
of -X- _ O
tables -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1.The -X- _ O
detailed -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
evaluated -X- _ O
datasets -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
A.1 -X- _ O
and -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
2.The -X- _ O
full -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
five -X- _ O
evaluated -X- _ O
classifiers -X- _ O
which -X- _ O
were -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
FT -X- _ O
method -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
A.2 -X- _ O
and -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
3.The -X- _ O
results -X- _ O
for -X- _ O
FeSTE -X- _ B-MethodName
’s -X- _ O
evaluation -X- _ O
when -X- _ O
using -X- _ O
an -X- _ O
additional -X- _ O
entity -X- _ O
linking -X- _ O
approach -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
A.3 -X- _ O
and -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
A.1 -X- _ O
Full -X- _ O
Details -X- _ O
of -X- _ O
the -X- _ O
Evaluated -X- _ O
Datasets -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
17 -X- _ O
classification -X- _ O
datasets -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
variance -X- _ O
in -X- _ O
their -X- _ O
characteristics -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
were -X- _ O
obtained -X- _ O
from -X- _ O
public -X- _ O
repositories -X- _ O
such -X- _ O
as -X- _ O
Kaggle -X- _ B-DatasetName
, -X- _ O
UCI -X- _ B-DatasetName
( -X- _ O
Dua -X- _ O
and -X- _ O
Graff -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
OpenML -X- _ B-DatasetName
( -X- _ O
Vanschoren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
relevant -X- _ O
studies -X- _ O
( -X- _ O
Ristoski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
and -X- _ O
their -X- _ O
characteristics -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
A.2 -X- _ O
Evaluation -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
evaluation -X- _ O
classifier -X- _ O
In -X- _ O
Section -X- _ O
5.3 -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
average -X- _ O
AUC -X- _ O
of -X- _ O
five -X- _ O
classifiers -X- _ O
for -X- _ O
our -X- _ O
two -X- _ O
experiments -X- _ O
( -X- _ O
Tables -X- _ O
1 -X- _ O
& -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
present -X- _ O
the -X- _ O
full -X- _ O
results -X- _ O
of -X- _ O
( -X- _ O
both -X- _ O
AUC -X- _ O
and -X- _ O
F -X- _ O
- -X- _ O
score -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
classifiers -X- _ O
: -X- _ O
RandomForestClassifier -X- _ O
, -X- _ O
MLPClassifier -X- _ O
, -X- _ O
SVC -X- _ O
, -X- _ O
KNeighborsClassifier -X- _ O
, -X- _ O
and -X- _ O
GradientBoostingClassifier -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
classifier -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
A.3 -X- _ O
FeSTE -X- _ O
’s -X- _ O
Performance -X- _ O
Using -X- _ O
an -X- _ O
Additional -X- _ O
Entity -X- _ O
Linking -X- _ O
Approach -X- _ O
The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
present -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
our -X- _ O
five -X- _ O
classifiers -X- _ O
when -X- _ O
FeSTE -X- _ O
is -X- _ O
evaluated -X- _ O
using -X- _ O
the -X- _ O
entity -X- _ O
linking -X- _ O
approach -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
Harari -X- _ O
and -X- _ O
Katz -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
also -X- _ O
include -X- _ O
the -X- _ O
performance -X- _ B-MethodName
obtained -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
features.1588158915901591 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
introduces -X- _ SUMMARY
a -X- _ SUMMARY
clustering -X- _ SUMMARY
- -X- _ SUMMARY
based -X- _ SUMMARY
loss -X- _ SUMMARY
correction -X- _ SUMMARY
framework -X- _ SUMMARY
named -X- _ SUMMARY
Feature -X- _ SUMMARY
Cluster -X- _ SUMMARY
Loss -X- _ SUMMARY
Correction -X- _ SUMMARY
( -X- _ SUMMARY
FCLC -X- _ SUMMARY
) -X- _ SUMMARY
for -X- _ SUMMARY
Fine -X- _ SUMMARY
- -X- _ SUMMARY
grained -X- _ SUMMARY
Entity -X- _ SUMMARY
Typing -X- _ SUMMARY
( -X- _ SUMMARY
FET -X- _ SUMMARY
) -X- _ SUMMARY
. -X- _ SUMMARY
FCLC -X- _ SUMMARY
first -X- _ SUMMARY
trains -X- _ SUMMARY
a -X- _ SUMMARY
coarse -X- _ SUMMARY
backbone -X- _ SUMMARY
model -X- _ SUMMARY
as -X- _ SUMMARY
a -X- _ SUMMARY
feature -X- _ SUMMARY
extractor -X- _ SUMMARY
and -X- _ SUMMARY
noise -X- _ SUMMARY
estimator -X- _ SUMMARY
. -X- _ SUMMARY
Loss -X- _ SUMMARY
correction -X- _ SUMMARY
is -X- _ SUMMARY
then -X- _ SUMMARY
applied -X- _ SUMMARY
to -X- _ SUMMARY
each -X- _ SUMMARY
feature -X- _ SUMMARY
cluster -X- _ SUMMARY
, -X- _ SUMMARY
learning -X- _ SUMMARY
directly -X- _ SUMMARY
from -X- _ SUMMARY
the -X- _ SUMMARY
noisy -X- _ SUMMARY
labels -X- _ SUMMARY
. -X- _ SUMMARY
Experimental -X- _ SUMMARY
results -X- _ SUMMARY
on -X- _ SUMMARY
three -X- _ SUMMARY
public -X- _ SUMMARY
datasets -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
FCLC -X- _ SUMMARY
achieves -X- _ SUMMARY
the -X- _ SUMMARY
best -X- _ SUMMARY
performance -X- _ SUMMARY
compared -X- _ SUMMARY
to -X- _ SUMMARY
existing -X- _ SUMMARY
systems -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
model -X- _ SUMMARY
is -X- _ SUMMARY
stable -X- _ SUMMARY
to -X- _ SUMMARY
hyperparameters -X- _ SUMMARY
and -X- _ SUMMARY
helps -X- _ SUMMARY
mitigate -X- _ SUMMARY
confirmation -X- _ SUMMARY
bias -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
model -X- _ SUMMARY
performs -X- _ SUMMARY
well -X- _ SUMMARY
even -X- _ SUMMARY
with -X- _ SUMMARY
no -X- _ SUMMARY
clean -X- _ SUMMARY
data -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
are -X- _ SUMMARY
strict -X- _ SUMMARY
accuracy -X- _ SUMMARY
( -X- _ SUMMARY
Acc -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
Macro -X- _ SUMMARY
F1 -X- _ SUMMARY
( -X- _ SUMMARY
Ma -X- _ SUMMARY
- -X- _ SUMMARY
F1 -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
Micro -X- _ SUMMARY
F1 -X- _ SUMMARY
( -X- _ SUMMARY
Mi -X- _ SUMMARY
- -X- _ SUMMARY
F1 -X- _ SUMMARY
) -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
provides -X- _ SUMMARY
insights -X- _ SUMMARY
into -X- _ SUMMARY
the -X- _ SUMMARY
instance -X- _ SUMMARY
- -X- _ SUMMARY
dependent -X- _ SUMMARY
label -X- _ SUMMARY
noise -X- _ SUMMARY
problem -X- _ SUMMARY
in -X- _ SUMMARY
FET -X- _ SUMMARY
and -X- _ SUMMARY
demonstrates -X- _ SUMMARY
the -X- _ SUMMARY
effectiveness -X- _ SUMMARY
of -X- _ SUMMARY
the -X- _ SUMMARY
proposed -X- _ SUMMARY
FCLC -X- _ SUMMARY
framework -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
dataset -X- _ SUMMARY
used -X- _ SUMMARY
is -X- _ SUMMARY
not -X- _ SUMMARY
explicitly -X- _ SUMMARY
mentioned -X- _ SUMMARY
in -X- _ SUMMARY
the -X- _ SUMMARY
paper -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.141.txt -X- _ O
Kunyuan -X- _ O
Pang -X- _ O
, -X- _ O
Haoyu -X- _ O
Zhang -X- _ O
, -X- _ O
Jie -X- _ O
Zhou -X- _ O
, -X- _ O
Ting -X- _ O
WangSchool -X- _ O
of -X- _ O
Computer -X- _ O
, -X- _ O
National -X- _ O
University -X- _ O
of -X- _ O
Defense -X- _ O
TechnologyArtificial -X- _ O
Intelligence -X- _ O
Research -X- _ O
Center -X- _ O
, -X- _ O
Defense -X- _ O
Innovation -X- _ O
InstituteShanghai -X- _ O
Jiao -X- _ O
Tong -X- _ O
University -X- _ O
{ -X- _ O
pangkunyuan10 -X- _ O
, -X- _ O
zhanghaoyu10 -X- _ O
, -X- _ O
tingwang -X- _ O
} -X- _ O
@ -X- _ O
nudt.edu.cn -X- _ O
, -X- _ O
sanny02 -X- _ O
@ -X- _ O
sjtu.edu.cn -X- _ O
Abstract -X- _ B-TaskName
Fine -X- _ I-TaskName
- -X- _ I-TaskName
grained -X- _ I-TaskName
Entity -X- _ I-TaskName
Typing -X- _ I-TaskName
( -X- _ O
FET -X- _ B-TaskName
) -X- _ O
has -X- _ O
made -X- _ O
great -X- _ O
progress -X- _ O
based -X- _ O
on -X- _ O
distant -X- _ O
supervision -X- _ O
but -X- _ O
still -X- _ O
suffers -X- _ O
from -X- _ O
label -X- _ O
noise -X- _ O
. -X- _ O
Existing -X- _ O
FET -X- _ B-TaskName
noise -X- _ O
learning -X- _ O
methods -X- _ O
rely -X- _ O
on -X- _ O
prediction -X- _ O
distributions -X- _ O
in -X- _ O
an -X- _ O
instance -X- _ O
- -X- _ O
independent -X- _ O
manner -X- _ O
, -X- _ O
which -X- _ O
causes -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
confirmation -X- _ O
bias -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
clustering -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
loss -X- _ I-MethodName
correction -X- _ I-MethodName
framework -X- _ O
named -X- _ O
Feature -X- _ B-MethodName
Cluster -X- _ I-MethodName
Loss -X- _ I-MethodName
Correction -X- _ I-MethodName
( -X- _ O
FCLC -X- _ B-MethodName
) -X- _ O
, -X- _ O
to -X- _ O
address -X- _ O
these -X- _ O
two -X- _ O
problems -X- _ O
. -X- _ O
FCLC -X- _ B-MethodName
first -X- _ O
train -X- _ O
a -X- _ O
coarse -X- _ O
backbone -X- _ O
model -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
noise -X- _ O
estimator -X- _ O
. -X- _ O
Loss -X- _ O
correction -X- _ O
is -X- _ O
then -X- _ O
applied -X- _ O
to -X- _ O
each -X- _ O
feature -X- _ O
cluster -X- _ O
, -X- _ O
learning -X- _ O
directly -X- _ O
from -X- _ O
the -X- _ O
noisy -X- _ O
labels -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
public -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
FCLC -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
over -X- _ O
existing -X- _ O
competitive -X- _ O
systems -X- _ O
. -X- _ O
Auxiliary -X- _ O
experiments -X- _ O
further -X- _ O
demonstrate -X- _ O
that -X- _ O
FCLC -X- _ O
is -X- _ O
stable -X- _ O
to -X- _ O
hyperparameters -X- _ O
and -X- _ O
it -X- _ O
does -X- _ O
help -X- _ O
mitigate -X- _ O
confirmation -X- _ O
bias -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
extreme -X- _ O
case -X- _ O
of -X- _ O
no -X- _ O
clean -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
FCLC -X- _ O
framework -X- _ O
still -X- _ O
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Fine -X- _ B-TaskName
- -X- _ I-TaskName
grained -X- _ I-TaskName
entity -X- _ I-TaskName
typing -X- _ I-TaskName
( -X- _ O
FET -X- _ B-TaskName
) -X- _ O
is -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
classifying -X- _ O
named -X- _ O
entity -X- _ O
mentions -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
over -X- _ O
the -X- _ O
given -X- _ O
class -X- _ O
set -X- _ O
( -X- _ O
typically -X- _ O
a -X- _ O
hierarchical -X- _ O
class -X- _ O
structure -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
FET -X- _ O
serves -X- _ O
as -X- _ O
an -X- _ O
important -X- _ O
component -X- _ O
in -X- _ O
many -X- _ O
down -X- _ O
- -X- _ O
stream -X- _ O
NLP -X- _ B-TaskName
applications -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
entity -X- _ O
linking -X- _ O
( -X- _ O
Raiman -X- _ O
and -X- _ O
Raiman -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
FET -X- _ B-TaskName
task -X- _ O
has -X- _ O
a -X- _ O
more -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
entity -X- _ O
types -X- _ O
( -X- _ O
usually -X- _ O
over -X- _ O
100 -X- _ O
classes -X- _ O
) -X- _ O
compared -X- _ O
to -X- _ O
entity -X- _ O
typing -X- _ O
, -X- _ O
and -X- _ O
hence -X- _ O
neural -X- _ O
- -X- _ O
based -X- _ O
FET -X- _ B-TaskName
systems -X- _ O
require -X- _ O
largescale -X- _ O
annotated -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O
Recent -X- _ O
studies -X- _ O
apply -X- _ O
distant -X- _ O
supervision -X- _ O
to -X- _ O
label -X- _ O
the -X- _ O
corpora -X- _ O
automatically -X- _ O
by -X- _ O
linking -X- _ O
mentions -X- _ O
to -X- _ O
knowledge -X- _ O
base -X- _ O
entities -X- _ O
and -X- _ O
using -X- _ O
all -X- _ O
entity -X- _ O
typesFigure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
Example -X- _ O
of -X- _ O
noisy -X- _ O
labels -X- _ O
and -X- _ O
feature -X- _ O
space -X- _ O
illustration -X- _ O
in -X- _ O
FET -X- _ B-TaskName
task -X- _ O
. -X- _ O
as -X- _ O
the -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
. -X- _ O
Although -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
annotated -X- _ O
data -X- _ O
is -X- _ O
provided -X- _ O
, -X- _ O
it -X- _ O
brings -X- _ O
about -X- _ O
label -X- _ O
noises -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
noisy -X- _ O
label -X- _ O
, -X- _ O
some -X- _ O
works -X- _ O
directly -X- _ O
pruned -X- _ O
noisy -X- _ O
instances -X- _ O
( -X- _ O
Gillick -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Onoe -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
others -X- _ O
retain -X- _ O
noisy -X- _ O
training -X- _ O
data -X- _ O
but -X- _ O
further -X- _ O
improve -X- _ O
by -X- _ O
choosing -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
; -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
weighting -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
relabeling -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
noisy -X- _ O
labels -X- _ O
using -X- _ O
the -X- _ O
prediction -X- _ O
distribution -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
noise -X- _ O
combating -X- _ O
methods -X- _ O
have -X- _ O
two -X- _ O
major -X- _ O
limitations -X- _ O
. -X- _ O
1 -X- _ O
) -X- _ O
They -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
prediction -X- _ O
distribution -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
they -X- _ O
ought -X- _ O
to -X- _ O
cope -X- _ O
with -X- _ O
instance -X- _ O
- -X- _ O
agnostic -X- _ O
noise -X- _ O
better -X- _ O
. -X- _ O
The -X- _ O
previous -X- _ O
works -X- _ O
expirically -X- _ O
show -X- _ O
( -X- _ O
Zheng -X- _ O
and -X- _ O
Yang -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
that -X- _ O
the -X- _ O
prediction -X- _ O
distribution -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
affected -X- _ O
by -X- _ O
noisy -X- _ O
instances -X- _ O
and -X- _ O
suffer -X- _ O
from -X- _ O
confirmation -X- _ O
bias -X- _ O
. -X- _ O
This -X- _ O
bias -X- _ O
problem -X- _ O
is -X- _ O
also -X- _ O
verified -X- _ O
in -X- _ O
our -X- _ O
Sec -X- _ O
. -X- _ O
3.5 -X- _ O
. -X- _ O
The -X- _ O
limitation -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
intriguing -X- _ O
question -X- _ O
: -X- _ O
Besides -X- _ O
prediction -X- _ O
distribution -X- _ O
and -X- _ O
entropy -X- _ O
, -X- _ O
what -X- _ O
other -X- _ O
information -X- _ O
can -X- _ O
we -X- _ O
use -X- _ O
to -X- _ O
model -X- _ O
label -X- _ O
noise -X- _ O
? -X- _ O
2 -X- _ O
) -X- _ O
They -X- _ O
mostly -X- _ O
aim -X- _ O
to -X- _ O
modify -X- _ O
each -X- _ O
instance -X- _ O
isolatedly -X- _ O
and -X- _ O
only -X- _ O
use -X- _ O
instance -X- _ O
- -X- _ O
level -X- _ O
information -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
typical -X- _ O
anti -X- _ O
- -X- _ O
noise -X- _ O
machine -X- _ O
learning -X- _ O
( -X- _ O
Patrini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Hendrycks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
uses -X- _ O
instance -X- _ O
- -X- _ O
agnostic -X- _ O
global -X- _ O
statistics -X- _ O
. -X- _ O
The -X- _ O
latter -X- _ O
is1997more -X- _ O
robust -X- _ O
to -X- _ O
noise -X- _ O
but -X- _ O
might -X- _ O
be -X- _ O
too -X- _ O
general -X- _ O
. -X- _ O
Local -X- _ O
information -X- _ O
is -X- _ O
potentially -X- _ O
more -X- _ O
informative -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
distant -X- _ O
supervision -X- _ O
introduces -X- _ O
similar -X- _ O
noise -X- _ O
in -X- _ O
some -X- _ O
instances -X- _ O
, -X- _ O
these -X- _ O
noises -X- _ O
form -X- _ O
a -X- _ O
locality -X- _ O
in -X- _ O
feature -X- _ O
space -X- _ O
. -X- _ O
The -X- _ O
noisy -X- _ O
instances -X- _ O
are -X- _ O
near -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
are -X- _ O
separate -X- _ O
from -X- _ O
instances -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
but -X- _ O
true -X- _ O
labels -X- _ O
. -X- _ O
Our -X- _ O
experiment -X- _ O
result -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
even -X- _ O
when -X- _ O
the -X- _ O
feature -X- _ O
extractor -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
fit -X- _ O
noisy -X- _ O
labels -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
still -X- _ O
easily -X- _ O
separable -X- _ O
due -X- _ O
to -X- _ O
underlying -X- _ O
semantic -X- _ O
differences -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
limitations -X- _ O
are -X- _ O
inter -X- _ O
- -X- _ O
related -X- _ O
, -X- _ O
causing -X- _ O
noise -X- _ O
- -X- _ O
learning -X- _ O
- -X- _ O
based -X- _ O
FET -X- _ B-TaskName
methods -X- _ O
to -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
distantly -X- _ O
supervised -X- _ O
noise -X- _ O
. -X- _ O
To -X- _ O
alleviate -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
and -X- _ O
avert -X- _ O
these -X- _ O
limitations -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
FCLC -X- _ B-MethodName
for -X- _ O
noisy -X- _ O
label -X- _ O
learning -X- _ O
inspired -X- _ O
by -X- _ O
weighted -X- _ O
training -X- _ O
and -X- _ O
loss -X- _ O
correction -X- _ O
( -X- _ O
Hendrycks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
in -X- _ O
machine -X- _ O
learning -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
utilizes -X- _ O
feature -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
learns -X- _ O
global -X- _ O
( -X- _ O
local -X- _ O
) -X- _ O
information -X- _ O
, -X- _ O
i.e. -X- _ O
a -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
label -X- _ O
confusion -X- _ O
matrix -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
backbone -X- _ O
learner -X- _ O
on -X- _ O
noisy -X- _ O
data -X- _ O
. -X- _ O
It -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
a -X- _ O
noise -X- _ O
estimator -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
all -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
including -X- _ O
noisy -X- _ O
data -X- _ O
and -X- _ O
a -X- _ O
small -X- _ O
portion -X- _ O
of -X- _ O
clean -X- _ O
data -X- _ O
are -X- _ O
clustered -X- _ O
. -X- _ O
The -X- _ O
clean -X- _ O
data -X- _ O
serve -X- _ O
as -X- _ O
anchors -X- _ O
in -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
to -X- _ O
estimate -X- _ O
label -X- _ O
corruption -X- _ O
and -X- _ O
sample -X- _ O
quality -X- _ O
of -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
label -X- _ O
corruption -X- _ O
and -X- _ O
sample -X- _ O
quality -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
label -X- _ O
correction -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
contributions -X- _ O
are -X- _ O
three -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
( -X- _ O
i -X- _ O
) -X- _ O
This -X- _ O
study -X- _ O
provides -X- _ O
fresh -X- _ O
insight -X- _ O
into -X- _ O
instance -X- _ O
dependent -X- _ O
label -X- _ O
noise -X- _ O
in -X- _ O
FET -X- _ B-TaskName
. -X- _ O
We -X- _ O
pointed -X- _ O
out -X- _ O
a -X- _ O
novel -X- _ O
training -X- _ O
method -X- _ O
to -X- _ O
further -X- _ O
exploit -X- _ O
feature -X- _ O
space -X- _ O
and -X- _ O
global -X- _ O
information -X- _ O
. -X- _ O
( -X- _ O
ii -X- _ O
) -X- _ O
We -X- _ O
designed -X- _ O
a -X- _ O
framework -X- _ O
with -X- _ O
feature -X- _ O
clustering -X- _ O
, -X- _ O
estimating -X- _ O
cluster -X- _ O
- -X- _ O
level -X- _ O
confusion -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
loss -X- _ O
correction -X- _ O
. -X- _ O
( -X- _ O
iii -X- _ O
) -X- _ O
We -X- _ O
experimented -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
three -X- _ O
datasets -X- _ O
. -X- _ O
Results -X- _ O
show -X- _ O
that -X- _ O
we -X- _ O
made -X- _ O
significant -X- _ O
improvements -X- _ O
over -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
, -X- _ O
thus -X- _ O
proving -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Ablation -X- _ O
studies -X- _ O
further -X- _ O
prove -X- _ O
the -X- _ O
robustness -X- _ O
and -X- _ O
wide -X- _ O
applicability -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O
2 -X- _ O
Framework -X- _ O
2.1 -X- _ O
Definition -X- _ O
Given -X- _ O
a -X- _ O
finite -X- _ O
set -X- _ O
of -X- _ O
types -X- _ O
, -X- _ O
T= -X- _ O
{ -X- _ O
t -X- _ O
, -X- _ O
t -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
t -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
|T|denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
types -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
assign -X- _ O
appropriate -X- _ O
types -X- _ O
to -X- _ O
each -X- _ O
mention -X- _ O
under -X- _ O
context -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
an -X- _ O
instance -X- _ O
is -X- _ O
a -X- _ O
triplet -X- _ O
, -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
.c= -X- _ O
{ -X- _ O
w -X- _ O
, -X- _ O
w -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
w -X- _ O
} -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
m -X- _ O
, -X- _ O
usually -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
. -X- _ O
m= -X- _ O
{ -X- _ O
w -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
w -X- _ O
} -X- _ O
is -X- _ O
the -X- _ O
mention -X- _ O
. -X- _ O
obviously -X- _ O
, -X- _ O
mis -X- _ O
a -X- _ O
continuous -X- _ O
sub -X- _ O
- -X- _ O
sequence -X- _ O
of -X- _ O
c. -X- _ O
Y⊆Tdenotes -X- _ O
appropriate -X- _ O
types -X- _ O
for -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
convenience -X- _ O
, -X- _ O
denote -X- _ O
Y -X- _ O
’s -X- _ O
vector -X- _ O
form -X- _ O
y∈ -X- _ O
{ -X- _ O
0,1 -X- _ O
} -X- _ O
, -X- _ O
y= -X- _ O
1means -X- _ O
t∈Y. -X- _ O
When -X- _ O
the -X- _ O
instance -X- _ O
is -X- _ O
produced -X- _ O
with -X- _ O
crowdsourcing -X- _ O
or -X- _ O
distant -X- _ O
supervision -X- _ O
, -X- _ O
annotated -X- _ O
labels -X- _ O
might -X- _ O
contain -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
noise -X- _ O
. -X- _ O
We -X- _ O
denote -X- _ O
labels -X- _ O
with -X- _ O
noise -X- _ O
˜y -X- _ O
. -X- _ O
The -X- _ O
instance -X- _ O
is -X- _ O
thus -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
˜y -X- _ O
) -X- _ O
. -X- _ O
Denote -X- _ O
the -X- _ O
corpus -X- _ O
with -X- _ O
noisy -X- _ O
instances -X- _ O
˜D -X- _ O
, -X- _ O
the -X- _ O
corpus -X- _ O
with -X- _ O
trusted -X- _ O
instances -X- _ O
D.The -X- _ O
two -X- _ O
corpus -X- _ O
form -X- _ O
the -X- _ O
whole -X- _ O
training -X- _ O
corpus -X- _ O
D. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
appropriate -X- _ O
types -X- _ O
for -X- _ O
given -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
. -X- _ O
2.2 -X- _ O
Training -X- _ O
Procedure -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
FCLC -X- _ B-MethodName
framework -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
steps -X- _ O
: -X- _ O
Step -X- _ O
1 -X- _ O
. -X- _ O
( -X- _ O
Phase -X- _ O
1 -X- _ O
) -X- _ O
Train -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
with -X- _ O
noisy -X- _ O
data -X- _ O
˜Dforeepochs -X- _ O
and -X- _ O
get -X- _ O
M. -X- _ O
It -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
a -X- _ O
noise -X- _ O
estimator -X- _ O
. -X- _ O
( -X- _ O
Sec -X- _ O
. -X- _ O
2.3 -X- _ O
) -X- _ O
Step -X- _ O
2 -X- _ O
. -X- _ O
Cluster -X- _ O
all -X- _ O
training -X- _ O
samples -X- _ O
Dwith -X- _ O
the -X- _ O
feature -X- _ O
extracted -X- _ O
by -X- _ O
E -X- _ O
, -X- _ O
and -X- _ O
estimate -X- _ O
confusion -X- _ O
matrix -X- _ O
for -X- _ O
each -X- _ O
cluster -X- _ O
with -X- _ O
predictions -X- _ O
of -X- _ O
M. -X- _ O
( -X- _ O
Sec -X- _ O
. -X- _ O
2.4 -X- _ O
) -X- _ O
Step -X- _ O
3 -X- _ O
. -X- _ O
( -X- _ O
Phase -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
calculated -X- _ O
clusteringaware -X- _ O
confusion -X- _ O
matrix -X- _ O
and -X- _ O
FCLC -X- _ B-MethodName
loss -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
continue -X- _ O
training -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
. -X- _ O
( -X- _ O
Sec -X- _ O
. -X- _ O
2.5 -X- _ O
) -X- _ O
2.3 -X- _ O
Backbone -X- _ O
For -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
structure -X- _ O
as -X- _ O
NFETC -X- _ B-MethodName
( -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
an -X- _ O
instance -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
winc -X- _ O
, -X- _ O
word -X- _ O
embedding -X- _ O
is -X- _ O
e∈Rlooked -X- _ O
up -X- _ O
in -X- _ O
word -X- _ O
embedding -X- _ O
matrix -X- _ O
W∈R. -X- _ O
A -X- _ O
position -X- _ O
embedding -X- _ O
e∈Ris -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
context -X- _ O
word -X- _ O
position -X- _ O
iand -X- _ O
mention -X- _ O
position -X- _ O
( -X- _ O
p -X- _ O
, -X- _ O
p -X- _ O
) -X- _ O
by -X- _ O
looking -X- _ O
up -X- _ O
relative -X- _ O
position -X- _ O
in -X- _ O
position -X- _ O
embedding -X- _ O
matrix -X- _ O
P∈R. -X- _ O
The -X- _ O
final -X- _ O
embedding -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
e= -X- _ O
[ -X- _ O
e -X- _ O
, -X- _ O
e -X- _ O
] -X- _ O
. -X- _ O
Context -X- _ O
Representation -X- _ O
A -X- _ O
Bi -X- _ O
- -X- _ O
LSTM -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
context -X- _ O
representation -X- _ O
. -X- _ O
Feeding -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
ci.e. -X- _ O
{ -X- _ O
e -X- _ O
, -X- _ O
e -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
e -X- _ O
} -X- _ O
into -X- _ O
BiLSTM -X- _ O
gets -X- _ O
the -X- _ O
two -X- _ O
directional -X- _ O
hidden -X- _ O
states− -X- _ O
→hand← -X- _ O
−hfor -X- _ O
each -X- _ O
word -X- _ O
w. -X- _ O
Word -X- _ O
level -X- _ O
attention -X- _ O
weighted -X- _ O
sum -X- _ O
following -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
on -X- _ O
h= -X- _ O
[ -X- _ O
− -X- _ O
→h⊕← -X- _ O
−h -X- _ O
] -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
context -X- _ O
representation -X- _ O
r∈R,1998 -X- _ O
where -X- _ O
⊕means -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
sum -X- _ O
and -X- _ O
dis -X- _ O
the -X- _ O
hidden -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
BiLSTM -X- _ O
and -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
embedding -X- _ O
. -X- _ O
Mention -X- _ O
Representation -X- _ O
The -X- _ O
average -X- _ O
encoder -X- _ O
of -X- _ O
a -X- _ O
mention -X- _ O
takes -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
mention -X- _ O
{ -X- _ O
e -X- _ O
, -X- _ O
e -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
e -X- _ O
} -X- _ O
and -X- _ O
takes -X- _ O
the -X- _ O
average -X- _ O
: -X- _ O
r -X- _ O
= -X- _ O
Pe -X- _ O
. -X- _ O
The -X- _ O
LSTM -X- _ O
encoder -X- _ O
of -X- _ O
a -X- _ O
mention -X- _ O
takes -X- _ O
an -X- _ O
extended -X- _ O
mention -X- _ O
with -X- _ O
one -X- _ O
more -X- _ O
token -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
the -X- _ O
original -X- _ O
mention -X- _ O
and -X- _ O
produces -X- _ O
hidden -X- _ O
state -X- _ O
features -X- _ O
{ -X- _ O
h -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
h -X- _ O
} -X- _ O
. -X- _ O
Take -X- _ O
the -X- _ O
last -X- _ O
output -X- _ O
hasr -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
mention -X- _ O
is -X- _ O
r= -X- _ O
[ -X- _ O
r -X- _ O
, -X- _ O
r -X- _ O
] -X- _ O
Classification -X- _ O
Softmax -X- _ O
classifier -X- _ O
and -X- _ O
crossentropy -X- _ O
are -X- _ O
used -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
feature -X- _ O
r= -X- _ O
[ -X- _ O
r -X- _ O
, -X- _ O
r -X- _ O
] -X- _ O
ofx -X- _ O
: -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
= -X- _ O
Wr+b -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
ˆp -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
softmax -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
ℓ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
−log -X- _ O
( -X- _ O
ˆp -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
With -X- _ O
a -X- _ O
given -X- _ O
dataset -X- _ O
D -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
all -X- _ O
samples -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
inD. -X- _ O
For -X- _ O
baseline -X- _ O
, -X- _ O
D -X- _ O
= -X- _ O
D. -X- _ O
ForFCLC -X- _ O
step -X- _ O
1 -X- _ O
, -X- _ O
D=˜D -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
|D|Xℓ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
; -X- _ O
θ -X- _ O
) -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
2.4 -X- _ O
Feature -X- _ O
Clustering -X- _ O
We -X- _ O
make -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
the -X- _ O
noise -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
˜y -X- _ O
) -X- _ O
forms -X- _ O
locality -X- _ O
in -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
, -X- _ O
especially -X- _ O
when -X- _ O
the -X- _ O
feature -X- _ O
is -X- _ O
calculated -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
mention -X- _ O
andcontext -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
m -X- _ O
, -X- _ O
c -X- _ O
) -X- _ O
determines -X- _ O
y -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
feature -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
˜y -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
clustering -X- _ O
to -X- _ O
utilize -X- _ O
local -X- _ O
statistics -X- _ O
as -X- _ O
smaller -X- _ O
- -X- _ O
grained -X- _ O
feature -X- _ O
information -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
specific -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
k -X- _ O
- -X- _ O
means -X- _ O
with -X- _ O
ron -X- _ O
the -X- _ O
whole -X- _ O
training -X- _ O
set -X- _ O
D -X- _ O
, -X- _ O
and -X- _ O
separate -X- _ O
DintoKclusters -X- _ O
. -X- _ O
Denote -X- _ O
thek -X- _ O
- -X- _ O
th -X- _ O
cluster -X- _ O
¯C -X- _ O
, -X- _ O
C=¯C∩ -X- _ O
D -X- _ O
, -X- _ O
˜C=¯C∩˜D. -X- _ O
We -X- _ O
mainly -X- _ O
utilize -X- _ O
the -X- _ O
two -X- _ O
following -X- _ O
statistics -X- _ O
: -X- _ O
τ=|C| -X- _ O
|D| -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
τestimates -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
cluster -X- _ O
k. -X- _ O
It -X- _ O
acts -X- _ O
as -X- _ O
a -X- _ O
soft -X- _ O
cluster -X- _ O
sieving -X- _ O
. -X- _ O
bC=1 -X- _ O
|A|Xbp -X- _ O
( -X- _ O
y= -X- _ O
1|x -X- _ O
) -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
where -X- _ O
A= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈ -X- _ O
Candy= -X- _ O
1 -X- _ O
} -X- _ O
, -X- _ O
bCestimates -X- _ O
the -X- _ O
probability -X- _ O
in -X- _ O
cluster -X- _ O
kto -X- _ O
annotate -X- _ O
noise -X- _ O
jfor -X- _ O
true -X- _ O
label -X- _ O
i. -X- _ O
2.5 -X- _ O
Loss -X- _ O
Correction -X- _ O
The -X- _ O
idea -X- _ O
of -X- _ O
forward -X- _ O
loss -X- _ O
correction -X- _ O
is -X- _ O
proposed -X- _ O
by -X- _ O
Patrini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
basic -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
modify -X- _ O
the -X- _ O
loss -X- _ O
with -X- _ O
the -X- _ O
noise -X- _ O
transition -X- _ O
matrix -X- _ O
T. -X- _ O
Such -X- _ O
that -X- _ O
the -X- _ O
minimizer -X- _ O
under -X- _ O
the -X- _ O
new -X- _ O
loss -X- _ O
with -X- _ O
noisy -X- _ O
labels -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
minimizer -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
loss -X- _ O
under -X- _ O
clean -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
modification -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
the -X- _ O
label -X- _ O
noise -X- _ O
is -X- _ O
independent -X- _ O
from -X- _ O
instances -X- _ O
, -X- _ O
i.e. -X- _ O
˜y⊥x|y -X- _ O
. -X- _ O
Hendrycks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
to -X- _ O
estimate -X- _ O
Twith -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
clean -X- _ O
labels -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
˜y⊥y|x -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
assumptions -X- _ O
do -X- _ O
not -X- _ O
hold -X- _ O
globally -X- _ O
for -X- _ O
distantly1999supervised -X- _ O
FET -X- _ B-TaskName
, -X- _ O
they -X- _ O
hold -X- _ O
better -X- _ O
in -X- _ O
clusters -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
the -X- _ O
cluster -X- _ O
- -X- _ O
wise -X- _ O
loss -X- _ O
correction -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
sections -X- _ O
. -X- _ O
Transition -X- _ O
Matrix -X- _ O
Estimation -X- _ O
Assuming -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
is -X- _ O
well -X- _ O
trained -X- _ O
, -X- _ O
i.e. -X- _ O
ˆp -X- _ O
( -X- _ O
˜y= -X- _ O
1|x -X- _ O
) -X- _ O
is -X- _ O
close -X- _ O
enough -X- _ O
to -X- _ O
p -X- _ O
( -X- _ O
˜y= -X- _ O
1|x -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
on -X- _ O
trusted -X- _ O
instances -X- _ O
in -X- _ O
cluster- -X- _ O
k -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
transition -X- _ O
probability -X- _ O
. -X- _ O
C -X- _ O
= -X- _ O
p -X- _ O
( -X- _ O
˜y= -X- _ O
1|y= -X- _ O
1 -X- _ O
, -X- _ O
x∈˜C -X- _ O
) -X- _ O
≈p -X- _ O
( -X- _ O
˜y= -X- _ O
1|y= -X- _ O
1 -X- _ O
, -X- _ O
x∈ -X- _ O
C -X- _ O
) -X- _ O
≈1 -X- _ O
|A|Xˆp -X- _ O
( -X- _ O
˜y= -X- _ O
1|x -X- _ O
) -X- _ O
= -X- _ O
bC -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
Forward -X- _ O
Loss -X- _ O
Correction -X- _ O
Cross -X- _ O
- -X- _ O
entropy -X- _ O
is -X- _ O
composite -X- _ O
( -X- _ O
Reid -X- _ O
and -X- _ O
Williamson -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
denote -X- _ O
it -X- _ O
as -X- _ O
ℓ -X- _ O
, -X- _ O
its -X- _ O
inverse -X- _ O
link -X- _ O
function -X- _ O
ψissoftmax -X- _ O
. -X- _ O
Notice -X- _ O
Ccan -X- _ O
bridge -X- _ O
the -X- _ O
loss -X- _ O
with -X- _ O
noisy -X- _ O
label -X- _ O
˜y -X- _ O
, -X- _ O
( -X- _ O
x∈˜C -X- _ O
, -X- _ O
˜y= -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
predictions -X- _ O
for -X- _ O
the -X- _ O
true -X- _ O
label -X- _ O
: -X- _ O
−log -X- _ O
( -X- _ O
ˆp -X- _ O
( -X- _ O
˜y|x -X- _ O
) -X- _ O
) -X- _ O
≈ -X- _ O
−logXCˆp -X- _ O
( -X- _ O
y= -X- _ O
1|x -X- _ O
) -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
LetT -X- _ O
= -X- _ O
C -X- _ O
, -X- _ O
define -X- _ O
the -X- _ O
forward -X- _ O
loss -X- _ O
as -X- _ O
: -X- _ O
ℓ -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
ℓ -X- _ O
( -X- _ O
Ts -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
The -X- _ O
property -X- _ O
holds -X- _ O
on -X- _ O
each -X- _ O
cluster -X- _ O
similar -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Patrini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
all -X- _ O
x∈˜C -X- _ O
, -X- _ O
training -X- _ O
with -X- _ O
noisy -X- _ O
label -X- _ O
˜yonℓis -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
with -X- _ O
true -X- _ O
label -X- _ O
yon -X- _ O
the -X- _ O
original -X- _ O
loss -X- _ O
ℓ -X- _ O
: -X- _ O
argminEℓ -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
= -X- _ O
argminEℓ -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
Different -X- _ O
from -X- _ O
global -X- _ O
forward -X- _ O
loss -X- _ O
correction -X- _ O
, -X- _ O
the -X- _ O
parameters -X- _ O
that -X- _ O
minimize -X- _ O
the -X- _ O
loss -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O
We -X- _ O
balance -X- _ O
the -X- _ O
clusters -X- _ O
with -X- _ O
τ -X- _ O
. -X- _ O
The -X- _ O
trusted -X- _ O
samples -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈ -X- _ O
Dare -X- _ O
also -X- _ O
used -X- _ O
. -X- _ O
The -X- _ O
loss -X- _ O
of -X- _ O
the -X- _ O
full -X- _ O
model -X- _ O
is -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
Pℓ -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
βPτPℓ -X- _ B-HyperparameterValue
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−β -X- _ B-HyperparameterValue
) -X- _ O
PτPℓ -X- _ O
( -X- _ O
s -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
Where -X- _ O
βis -X- _ B-HyperparameterValue
the -X- _ O
hyperparameter -X- _ O
to -X- _ O
balance -X- _ O
FCLC -X- _ B-MethodName
loss -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
loss -X- _ O
. -X- _ O
Our -X- _ O
introduced -X- _ O
framework -X- _ O
has -X- _ O
several -X- _ O
advantages -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
Lightweight -X- _ O
. -X- _ O
This -X- _ O
method -X- _ O
does -X- _ O
not -X- _ O
include -X- _ O
extra -X- _ O
trainable -X- _ O
parameters -X- _ O
to -X- _ O
the -X- _ O
backbonemodel -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
Stable -X- _ O
. -X- _ O
The -X- _ O
framework -X- _ O
involves -X- _ O
two -X- _ O
hyperparameters -X- _ O
, -X- _ O
βand -X- _ B-HyperparameterValue
phase-1 -X- _ B-HyperparameterValue
train -X- _ I-HyperparameterValue
epochs -X- _ I-HyperparameterValue
e -X- _ B-HyperparameterValue
and -X- _ O
we -X- _ O
empirically -X- _ O
find -X- _ O
them -X- _ O
stable -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
Flexibility -X- _ O
. -X- _ O
Our -X- _ O
improvement -X- _ O
is -X- _ O
orthogonal -X- _ O
to -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
. -X- _ O
It -X- _ O
only -X- _ O
requires -X- _ O
that -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
is -X- _ O
sufficiently -X- _ O
expressive -X- _ O
and -X- _ O
uses -X- _ O
an -X- _ O
appropriate -X- _ O
composite -X- _ O
loss -X- _ O
( -X- _ O
Reid -X- _ O
and -X- _ O
Williamson -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
pluggable -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
FET -X- _ B-TaskName
models -X- _ O
. -X- _ O
3 -X- _ O
Experiments -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
on -X- _ O
three -X- _ O
different -X- _ O
FET -X- _ B-TaskName
datasets -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
to -X- _ O
several -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
to -X- _ O
support -X- _ O
our -X- _ O
claims -X- _ O
we -X- _ O
also -X- _ O
conduct -X- _ O
several -X- _ O
subsidiary -X- _ O
experiments -X- _ O
to -X- _ O
analyze -X- _ O
the -X- _ O
impacts -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
module -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O
3.1 -X- _ O
Datasets -X- _ O
The -X- _ O
datasets -X- _ O
are -X- _ O
described -X- _ O
below -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
train -X- _ O
/ -X- _ O
dev -X- _ O
/ -X- _ O
test -X- _ O
split -X- _ O
with -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Detailed -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
are -X- _ O
also -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
BBN -X- _ B-DatasetName
It -X- _ O
contains -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
Wall -X- _ O
Street -X- _ O
Journal -X- _ O
and -X- _ O
distantly -X- _ O
labeled -X- _ O
by -X- _ O
DBpedia -X- _ O
Spotlight -X- _ O
( -X- _ O
Weischedel -X- _ O
and -X- _ O
Brunstein -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
OntoNotes -X- _ B-DatasetName
It -X- _ O
was -X- _ O
constructed -X- _ O
using -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
OntoNotes -X- _ B-DatasetName
corpus -X- _ O
and -X- _ O
distantly -X- _ O
supervised -X- _ O
by -X- _ O
DBpedia -X- _ O
Spotlight -X- _ O
( -X- _ O
Weischedel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Wiki -X- _ B-DatasetName
/ -X- _ I-DatasetName
FIGER -X- _ I-DatasetName
It -X- _ O
was -X- _ O
derived -X- _ O
from -X- _ O
Wikipedia -X- _ O
articles -X- _ O
and -X- _ O
news -X- _ O
reports -X- _ O
, -X- _ O
entities -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
samples -X- _ O
are -X- _ O
distantly -X- _ O
annotated -X- _ O
using -X- _ O
Freebase -X- _ O
( -X- _ O
Ling -X- _ O
and -X- _ O
Weld -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
3.2 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
We -X- _ O
follow -X- _ O
prior -X- _ O
work -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
strict -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
Acc -X- _ B-MetricName
) -X- _ O
, -X- _ O
Macro -X- _ B-MetricName
F1 -X- _ I-MetricName
( -X- _ O
Ma -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
Micro -X- _ B-MetricName
F1 -X- _ I-MetricName
( -X- _ O
Mi -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
scores -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
all -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
calculated -X- _ O
by -X- _ O
running -X- _ O
the -X- _ O
model -X- _ O
five -X- _ O
times -X- _ O
and -X- _ O
computing -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
values.2000 -X- _ O
3.3 -X- _ O
Baselines -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
competitive -X- _ O
FET -X- _ B-TaskName
systems -X- _ O
as -X- _ O
our -X- _ O
baselines -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
AFET -X- _ B-MethodName
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016a -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Attentive -X- _ B-MethodName
( -X- _ O
Shimaoka -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
NFETC -X- _ B-MethodName
/ -X- _ I-MethodName
NFETC -X- _ I-MethodName
( -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
CLSC -X- _ B-MethodName
/ -X- _ I-MethodName
CLSC -X- _ I-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
AR -X- _ I-MethodName
/ -X- _ I-MethodName
NFETC -X- _ I-MethodName
- -X- _ I-MethodName
AR -X- _ I-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
V -X- _ I-MethodName
AT -X- _ I-MethodName
/ -X- _ I-MethodName
CLSC -X- _ I-MethodName
- -X- _ I-MethodName
V -X- _ I-MethodName
AT -X- _ I-MethodName
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
Multi -X- _ B-MethodName
Level -X- _ I-MethodName
Learning -X- _ I-MethodName
to -X- _ I-MethodName
Rank -X- _ I-MethodName
( -X- _ O
ML -X- _ O
- -X- _ O
L2R -X- _ O
) -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
Box -X- _ O
( -X- _ O
Onoe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
baselines -X- _ O
are -X- _ O
compared -X- _ O
with -X- _ O
several -X- _ O
variants -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
FCLC -X- _ B-MethodName
: -X- _ O
proposed -X- _ O
model -X- _ O
without -X- _ O
the -X- _ O
hierarchical -X- _ O
loss -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
FCLC -X- _ B-MethodName
proposed -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
hierarchical -X- _ O
loss -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
without -X- _ O
τ -X- _ O
) -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
trained -X- _ O
without -X- _ O
cluster -X- _ O
quality -X- _ O
estimation -X- _ O
, -X- _ O
i.e. -X- _ O
τ= -X- _ O
1 -X- _ O
for -X- _ O
all -X- _ O
clusters -X- _ O
; -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
without -X- _ O
loss -X- _ O
correction -X- _ O
) -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
without -X- _ O
loss -X- _ O
correction -X- _ O
, -X- _ O
only -X- _ O
cluster -X- _ O
quality -X- _ O
estimation -X- _ O
working -X- _ O
; -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
without -X- _ O
cluster -X- _ O
) -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
without -X- _ O
clustering -X- _ O
, -X- _ O
i.e. -X- _ O
calculated -X- _ O
a -X- _ O
globally -X- _ O
- -X- _ O
uniform -X- _ O
confusion -X- _ O
matrix -X- _ O
; -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
with -X- _ O
reinit -X- _ O
) -X- _ O
: -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
with -X- _ O
fresh -X- _ O
parameters -X- _ O
before -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
step -X- _ O
3 -X- _ O
as -X- _ O
suggested -X- _ O
by -X- _ O
Patrini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
- -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
are -X- _ O
implemented -X- _ O
based -X- _ O
on -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
configuration -X- _ O
between -X- _ O
FCLC -X- _ O
andFCLCon -X- _ O
each -X- _ O
dataset -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
FCLC -X- _ B-MethodName
on -X- _ O
BBN -X- _ B-DatasetName
and -X- _ O
compared -X- _ O
with -X- _ O
FCLCon -X- _ B-MethodName
Wiki -X- _ B-DatasetName
and -X- _ O
OntoNotes -X- _ B-DatasetName
. -X- _ O
3.4 -X- _ O
Implementation -X- _ O
Details -X- _ O
To -X- _ O
make -X- _ O
an -X- _ O
equal -X- _ O
comparison -X- _ O
, -X- _ O
following -X- _ O
( -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
300dimensional -X- _ O
GloVe -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
fix -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
parameters -X- _ O
are -X- _ O
optimized -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
optimizer -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
are -X- _ O
implemented -X- _ O
in -X- _ O
Tensorflow -X- _ O
. -X- _ O
As -X- _ O
NFETC -X- _ B-MethodName
and -X- _ O
NFETCare -X- _ B-MethodName
our -X- _ O
backbone -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
backbone -X- _ O
except -X- _ O
for -X- _ O
our -X- _ O
introduced -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
βande -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
detailed -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
settings -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
impact -X- _ O
curves -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
3.5 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O
Main -X- _ O
Result -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
approach -X- _ O
( -X- _ O
FCLC -X- _ B-MethodName
) -X- _ O
and -X- _ O
several -X- _ O
competitive -X- _ O
FET -X- _ B-TaskName
systems -X- _ O
. -X- _ O
We -X- _ O
highlight -X- _ O
the -X- _ O
statistically -X- _ O
significant -X- _ O
best -X- _ O
scores -X- _ O
of -X- _ O
each -X- _ O
metric -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
two -X- _ O
main -X- _ O
observations -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
performances -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
surpass -X- _ O
the -X- _ O
backbone -X- _ O
NFETC -X- _ B-MethodName
model -X- _ O
by -X- _ O
a -X- _ O
remarkable -X- _ O
large -X- _ O
margin -X- _ O
( -X- _ O
improving -X- _ O
Micro -X- _ B-MetricName
F1 -X- _ I-MetricName
by -X- _ O
2.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
3.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
7.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
separately -X- _ O
) -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
two -X- _ O
- -X- _ O
phase -X- _ O
FCLC -X- _ B-MethodName
module -X- _ O
. -X- _ O
The -X- _ O
relative -X- _ O
performance -X- _ O
improvements -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
or -X- _ O
without -X- _ O
the -X- _ O
hierarchy -X- _ O
loss -X- _ O
( -X- _ O
compared -X- _ O
FCLC -X- _ B-MethodName
and -X- _ O
FCLC -X- _ B-MethodName
hier -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
baselines -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Compared -X- _ O
to -X- _ O
other -X- _ O
noisy -X- _ O
learning -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
CLSC -X- _ B-MethodName
, -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
AR -X- _ I-MethodName
, -X- _ O
and -X- _ O
V -X- _ B-MethodName
AT -X- _ I-MethodName
, -X- _ O
our -X- _ O
model -X- _ O
still -X- _ O
achieves -X- _ O
considerable -X- _ O
improvements -X- _ O
under -X- _ O
most -X- _ O
metrics -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
backbone -X- _ O
and -X- _ O
very -X- _ O
similar -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
settings -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
NFETC -X- _ B-MethodName
- -X- _ I-MethodName
AR -X- _ I-MethodName
, -X- _ O
our -X- _ O
model -X- _ O
improves -X- _ O
Micro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
by -X- _ O
1.25 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
6.38 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
three -X- _ O
datasets -X- _ O
. -X- _ O
It -X- _ O
indicates -X- _ O
that -X- _ O
, -X- _ O
by -X- _ O
utilizing -X- _ O
both -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
representations -X- _ O
and -X- _ O
the -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
statistical -X- _ O
information -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
reduce -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
noisy -X- _ O
labels -X- _ O
more -X- _ O
effectively -X- _ O
. -X- _ O
Ablation -X- _ O
Study -X- _ O
To -X- _ O
study -X- _ O
the -X- _ O
detail -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
three -X- _ O
main -X- _ O
model -X- _ O
variants -X- _ O
, -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
several -X- _ O
rows -X- _ O
of -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
cluster -X- _ O
quality -X- _ O
τ -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
correction -X- _ O
module -X- _ O
and -X- _ O
the -X- _ O
feature -X- _ O
cluster -X- _ O
process -X- _ O
are -X- _ O
all -X- _ O
critical -X- _ O
to -X- _ O
model -X- _ O
performances -X- _ O
in -X- _ O
some -X- _ O
situations -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
without -X- _ O
cluster -X- _ O
) -X- _ O
, -X- _ O
feature -X- _ O
clustering -X- _ O
has -X- _ O
minor -X- _ O
impacts -X- _ O
on -X- _ O
Wiki -X- _ B-DatasetName
and -X- _ O
Ontonotes -X- _ B-DatasetName
. -X- _ O
This -X- _ O
is -X- _ O
probably -X- _ O
because -X- _ O
the -X- _ O
noisy -X- _ O
distribution -X- _ O
on -X- _ O
these -X- _ O
two -X- _ O
datasets -X- _ O
is -X- _ O
relatively -X- _ O
simple -X- _ O
and -X- _ O
the -X- _ O
global -X- _ O
confusion -X- _ O
matrix -X- _ O
is -X- _ O
sufficient -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
re -X- _ O
- -X- _ O
initialization -X- _ O
before -X- _ O
Step -X- _ O
3 -X- _ O
has -X- _ O
a -X- _ O
great -X- _ O
impact -X- _ O
on -X- _ O
all -X- _ O
metrics -X- _ O
. -X- _ O
Staring -X- _ O
Step -X- _ O
3 -X- _ O
with -X- _ O
a -X- _ O
fresh -X- _ O
re -X- _ O
- -X- _ O
initialized -X- _ O
FET -X- _ B-MethodName
model -X- _ O
degrades -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
by -X- _ O
3.2 -X- _ B-MetricName
% -X- _ I-MetricName
on -X- _ O
Ontonotes -X- _ B-DatasetName
. -X- _ O
It -X- _ O
denotes -X- _ O
that -X- _ O
the -X- _ O
learner -X- _ O
trained -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
phase -X- _ O
is -X- _ O
beneficial -X- _ O
for -X- _ O
the -X- _ O
noisy -X- _ O
robust -X- _ O
learning -X- _ O
process -X- _ O
, -X- _ O
by -X- _ O
providing -X- _ O
optimal -X- _ O
parameters -X- _ O
initialization.2001 -X- _ O
Sensitivity -X- _ O
of -X- _ O
the -X- _ O
introduced -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
Using -X- _ O
the -X- _ O
same -X- _ O
setting -X- _ O
for -X- _ O
model -X- _ O
training -X- _ O
, -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
analyses -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
FCLC -X- _ B-MethodName
to -X- _ O
the -X- _ O
introduced -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
: -X- _ O
the -X- _ O
FCLC -X- _ O
objective -X- _ O
weight -X- _ O
β -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
Step-1 -X- _ O
training -X- _ O
epochs -X- _ O
e. -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
( -X- _ O
a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
trend -X- _ O
on -X- _ O
the -X- _ O
Ontonotes -X- _ B-DatasetName
and -X- _ O
BBN -X- _ B-DatasetName
datasets -X- _ O
when -X- _ O
changing -X- _ O
β -X- _ B-HyperparameterName
. -X- _ O
While -X- _ O
selecting -X- _ O
a -X- _ O
proper -X- _ O
ratio -X- _ O
between -X- _ O
loss -X- _ O
- -X- _ O
correction -X- _ O
loss -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
loss -X- _ O
is -X- _ O
important -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
near -X- _ O
optimum -X- _ O
βis -X- _ B-HyperparameterName
stable -X- _ O
and -X- _ O
steadily -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
( -X- _ O
c -X- _ O
, -X- _ O
d -X- _ O
) -X- _ O
analyses -X- _ O
the -X- _ O
sensitivity -X- _ O
with -X- _ O
respect -X- _ O
toe -X- _ O
. -X- _ O
the -X- _ O
Micro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
improves -X- _ O
as -X- _ O
eincreases -X- _ O
but -X- _ O
stops -X- _ O
improving -X- _ O
and -X- _ O
become -X- _ O
unstable -X- _ O
when -X- _ O
eis -X- _ O
large -X- _ O
enough -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
model -X- _ O
starts -X- _ O
to -X- _ O
overfit -X- _ O
noise -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
reasonable -X- _ O
that -X- _ O
the -X- _ O
optimal -X- _ O
range -X- _ O
of -X- _ O
βandein -X- _ B-HyperparameterName
BBN -X- _ B-DatasetName
and -X- _ O
Ontonotes -X- _ B-DatasetName
are -X- _ O
different -X- _ O
as -X- _ O
they -X- _ O
have -X- _ O
different -X- _ O
training -X- _ O
set -X- _ O
sizes -X- _ O
and -X- _ O
different -X- _ O
distance -X- _ O
supervision -X- _ O
noise -X- _ O
distribution -X- _ O
. -X- _ O
Will -X- _ O
cluster -X- _ O
number -X- _ O
affect -X- _ O
performance -X- _ O
? -X- _ O
We -X- _ O
investigate -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
FCLC -X- _ B-MethodName
model -X- _ O
benefits -X- _ O
from -X- _ O
different -X- _ O
values -X- _ O
of -X- _ O
feature -X- _ O
cluster -X- _ O
number -X- _ O
k. -X- _ O
Fig -X- _ O
. -X- _ O
5 -X- _ O
demonstrates -X- _ O
that -X- _ O
under -X- _ O
a -X- _ O
reasonable -X- _ O
feature -X- _ O
cluster -X- _ O
range -X- _ O
( -X- _ O
near -X- _ O
|T| -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
achieve -X- _ O
competitive -X- _ O
and -X- _ O
similar -X- _ O
performances -X- _ O
. -X- _ O
How -X- _ O
many -X- _ O
trusted -X- _ O
instances -X- _ O
does -X- _ O
the -X- _ O
model -X- _ O
need -X- _ O
? -X- _ O
We -X- _ O
examine -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
clean -X- _ O
data -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
performances -X- _ O
with -X- _ O
5 -X- _ O
% -X- _ O
to -X- _ O
100 -X- _ O
% -X- _ O
trusted -X- _ O
instances -X- _ O
. -X- _ O
Refer -X- _ O
to -X- _ O
Fig -X- _ O
. -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
differences -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
comparable -X- _ O
accuracy -X- _ B-MetricName
with -X- _ O
30 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
Dsamples -X- _ O
on2002 -X- _ O
Wiki -X- _ B-DatasetName
, -X- _ O
Ontonotes -X- _ B-DatasetName
, -X- _ O
and -X- _ O
BBN -X- _ B-DatasetName
separately -X- _ O
. -X- _ O
With -X- _ O
only -X- _ O
a -X- _ O
very -X- _ O
small -X- _ O
size -X- _ O
of -X- _ O
trusted -X- _ O
instances -X- _ O
, -X- _ O
e.g. -X- _ O
20 -X- _ O
% -X- _ O
BBN -X- _ B-DatasetName
trusted -X- _ O
set -X- _ O
, -X- _ O
or -X- _ O
128 -X- _ O
samples -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
begins -X- _ O
to -X- _ O
improve -X- _ O
significantly -X- _ O
. -X- _ O
What -X- _ O
if -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
have -X- _ O
any -X- _ O
trusted -X- _ O
instances -X- _ O
? -X- _ O
Although -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
clean -X- _ O
samples -X- _ O
is -X- _ O
always -X- _ O
practical -X- _ O
to -X- _ O
obtain -X- _ O
or -X- _ O
relabel -X- _ O
with -X- _ O
an -X- _ O
expert -X- _ O
, -X- _ O
we -X- _ O
push -X- _ O
the -X- _ O
limit -X- _ O
to -X- _ O
no -X- _ O
trusted -X- _ O
instances -X- _ O
at -X- _ O
all -X- _ O
. -X- _ O
What -X- _ O
performance -X- _ O
can -X- _ O
our -X- _ O
model -X- _ O
achieve -X- _ O
in -X- _ O
such -X- _ O
a -X- _ O
situation -X- _ O
? -X- _ O
We -X- _ O
performed -X- _ O
the -X- _ O
" -X- _ O
no -X- _ O
clean -X- _ O
training -X- _ O
set -X- _ O
" -X- _ O
experiment -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
w -X- _ O
/ -X- _ O
oD -X- _ O
) -X- _ O
indicates -X- _ O
for -X- _ O
the -X- _ O
variant -X- _ O
that -X- _ O
the -X- _ O
trusted -X- _ O
instances -X- _ O
are -X- _ O
not -X- _ O
used -X- _ O
for -X- _ O
phase -X- _ O
2 -X- _ O
training -X- _ O
but -X- _ O
only -X- _ O
in -X- _ O
feature -X- _ O
clustering -X- _ O
and -X- _ O
confusion -X- _ O
matrix -X- _ O
calculation -X- _ O
. -X- _ O
In -X- _ O
that -X- _ O
situation -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
still -X- _ O
has -X- _ O
similar -X- _ O
performances -X- _ O
with -X- _ O
previous -X- _ O
SOTA -X- _ O
models -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
. -X- _ O
FCLC -X- _ B-MethodName
( -X- _ O
w -X- _ O
/ -X- _ O
pl -X- _ O
) -X- _ O
variant -X- _ O
means -X- _ O
that -X- _ O
, -X- _ O
during -X- _ O
the -X- _ O
clustering -X- _ O
process -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
the -X- _ O
trusted -X- _ O
instance -X- _ O
setDsplit -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
classic -X- _ O
pseudo -X- _ O
labeling -X- _ O
method -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
labels -X- _ O
needed -X- _ O
by -X- _ O
clustering -X- _ O
and -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
method -X- _ O
, -X- _ O
FCLC -X- _ O
with -X- _ O
pseudo -X- _ O
labeling -X- _ O
still -X- _ O
achieves -X- _ O
much -X- _ O
better -X- _ O
performances -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
proved -X- _ O
by -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
that -X- _ O
FCLC -X- _ B-MethodName
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
clean -X- _ O
training -X- _ O
subset -X- _ O
, -X- _ O
thus -X- _ O
having -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
applications -X- _ O
. -X- _ O
Visualization -X- _ O
of -X- _ O
the -X- _ O
representations -X- _ O
We -X- _ O
analyze -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
FCLC -X- _ B-MethodName
module -X- _ O
by -X- _ O
visualizing -X- _ O
the -X- _ O
feature -X- _ O
vectors -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
illustrates -X- _ O
samples -X- _ O
in -X- _ O
a -X- _ O
cluster -X- _ O
( -X- _ O
circled -X- _ O
in -X- _ O
all -X- _ O
4 -X- _ O
sub -X- _ O
- -X- _ O
figures -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
fails -X- _ O
to -X- _ O
distinguish -X- _ O
some -X- _ O
samples -X- _ O
of -X- _ O
class -X- _ O
A -X- _ O
( -X- _ O
/ -X- _ O
ORGANIZATION -X- _ O
/ -X- _ O
GOVERNMENT -X- _ O
, -X- _ O
red -X- _ O
) -X- _ O
and -X- _ O
class -X- _ O
B -X- _ O
( -X- _ O
/ -X- _ O
GPE -X- _ O
/ -X- _ O
COUNTRY -X- _ O
, -X- _ O
blue -X- _ O
) -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
noisy -X- _ O
labels -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
correct -X- _ O
these -X- _ O
instances -X- _ O
. -X- _ O
With -X- _ O
FCLC -X- _ B-MethodName
the -X- _ O
classifier -X- _ O
is -X- _ O
corrected -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
right -X- _ O
label -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
in -X- _ O
feature -X- _ O
space -X- _ O
, -X- _ O
the -X- _ O
boundary -X- _ O
between -X- _ O
these -X- _ O
samples -X- _ O
and -X- _ O
the -X- _ O
confusing -X- _ O
class -X- _ O
is -X- _ O
also -X- _ O
clearer -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
FCLC -X- _ O
also -X- _ O
helps -X- _ O
to -X- _ O
refine -X- _ O
feature -X- _ O
extraction -X- _ O
with -X- _ O
loss -X- _ O
correction -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
6 -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
row -X- _ O
of -X- _ O
’ -X- _ O
/ -X- _ O
GPE -X- _ O
/ -X- _ O
COUNTRY -X- _ O
’ -X- _ O
. -X- _ O
Managing -X- _ O
to -X- _ O
notice -X- _ O
the -X- _ O
confusion -X- _ O
from -X- _ O
’ -X- _ O
/ -X- _ O
GPE -X- _ O
/ -X- _ O
COUNTRY -X- _ O
’ -X- _ O
to -X- _ O
’ -X- _ O
/ -X- _ O
ORGANIZATION -X- _ O
/ -X- _ O
GOVERNMENT -X- _ O
’ -X- _ O
enables -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
appropriate -X- _ O
correction -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
this -X- _ O
, -X- _ O
FCLC -X- _ B-MethodName
are -X- _ O
resistant -X- _ O
to -X- _ O
the -X- _ O
noisy -X- _ O
labels -X- _ O
. -X- _ O
Quantitative -X- _ O
Results -X- _ O
of -X- _ O
Confirmation -X- _ O
Bias -X- _ O
To -X- _ O
further -X- _ O
verify -X- _ O
our -X- _ O
claim -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
alleviate -X- _ O
the -X- _ O
confirmation -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
noisy -X- _ O
FET -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
prediction -X- _ O
confidence -X- _ O
on -X- _ O
test -X- _ O
set -X- _ O
samples -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
7 -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
confidence -X- _ O
of -X- _ O
correct -X- _ O
and -X- _ O
wrong -X- _ O
test -X- _ O
samples -X- _ O
is -X- _ O
calculated -X- _ O
after -X- _ O
each -X- _ O
training -X- _ O
epoch -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
Wiki -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
after -X- _ O
phase -X- _ O
one -X- _ O
the -X- _ O
wrong -X- _ B-MetricName
sample -X- _ I-MetricName
average -X- _ I-MetricName
confidence -X- _ I-MetricName
is -X- _ O
0.700 -X- _ B-MetricValue
but -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
reached -X- _ O
0.833 -X- _ B-MetricValue
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
( -X- _ O
with -X- _ O
early -X- _ O
stopping -X- _ O
) -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
after -X- _ O
phase -X- _ O
two -X- _ O
FCLC -X- _ B-MethodName
improves -X- _ O
the -X- _ O
correct -X- _ O
sample -X- _ O
confidence -X- _ O
from -X- _ O
backbone -X- _ O
’s -X- _ O
0.939 -X- _ B-MetricValue
to -X- _ O
0.950 -X- _ B-MetricValue
on -X- _ O
Wiki -X- _ O
. -X- _ O
4 -X- _ O
Related -X- _ O
Work -X- _ O
4.1 -X- _ O
Noisy -X- _ O
Learning -X- _ O
The -X- _ O
usage -X- _ O
of -X- _ O
datasets -X- _ O
collected -X- _ O
with -X- _ O
distant -X- _ O
supervision -X- _ O
often -X- _ O
results -X- _ O
in -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
noisy -X- _ O
labels -X- _ O
. -X- _ O
Several -X- _ O
studies -X- _ O
have -X- _ O
investigated -X- _ O
deep -X- _ O
learning -X- _ O
approaches -X- _ O
with -X- _ O
noise -X- _ O
. -X- _ O
Existing -X- _ O
noisy -X- _ O
learning -X- _ O
methods -X- _ O
include -X- _ O
designing -X- _ O
robust -X- _ O
loss -X- _ O
functions -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
designing -X- _ O
robust -X- _ O
architectures -X- _ O
by -X- _ O
adding -X- _ O
noise -X- _ O
adaptation -X- _ O
layers -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Gupta -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Goldberger -X- _ O
and -X- _ O
Ben -X- _ O
- -X- _ O
Reuven -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
selecting -X- _ O
samples -X- _ O
( -X- _ O
Onoe -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
adding -X- _ O
noiserobust -X- _ O
regularization -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Among -X- _ O
them -X- _ O
, -X- _ O
Patrini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Hendrycks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
forward -X- _ O
loss -X- _ O
correction -X- _ O
. -X- _ O
It -X- _ O
avoided -X- _ O
explicit -X- _ O
relabeling -X- _ O
and -X- _ O
matrix -X- _ O
inversion -X- _ O
. -X- _ O
These -X- _ O
noisy -X- _ O
learning -X- _ O
methods -X- _ O
are -X- _ O
mostly -X- _ O
restricted -X- _ O
to -X- _ O
the2003noise -X- _ O
that -X- _ O
is -X- _ O
conditionally -X- _ O
independent -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
features -X- _ O
( -X- _ O
Frénay -X- _ O
and -X- _ O
Verleysen -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
FET -X- _ B-TaskName
, -X- _ O
noise -X- _ O
distributions -X- _ O
are -X- _ O
more -X- _ O
complex -X- _ O
and -X- _ O
instance -X- _ O
- -X- _ O
dependent -X- _ O
, -X- _ O
requiring -X- _ O
more -X- _ O
powerful -X- _ O
noisy -X- _ O
learning -X- _ O
methods -X- _ O
. -X- _ O
4.2 -X- _ O
Fine -X- _ B-TaskName
- -X- _ I-TaskName
Grained -X- _ I-TaskName
Entity -X- _ I-TaskName
Typing -X- _ I-TaskName
FET -X- _ B-TaskName
is -X- _ O
studied -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
distant -X- _ O
supervision -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Mintz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Ling -X- _ O
and -X- _ O
Weld -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
Various -X- _ O
features -X- _ O
( -X- _ O
Yogatama -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
network -X- _ O
structures -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Shimaoka -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
feature -X- _ O
space -X- _ O
( -X- _ O
Ali -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Onoe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
are -X- _ O
explored -X- _ O
to -X- _ O
refine -X- _ O
the -X- _ O
mention -X- _ O
and -X- _ O
type -X- _ O
representation -X- _ O
. -X- _ O
Label -X- _ O
inter -X- _ O
- -X- _ O
dependency -X- _ O
( -X- _ O
Lin -X- _ O
and -X- _ O
Ji -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
type -X- _ O
hierarchy -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
often -X- _ O
used -X- _ O
, -X- _ O
added -X- _ O
by -X- _ O
relations -X- _ O
among -X- _ O
instances -X- _ O
and -X- _ O
labels -X- _ O
( -X- _ O
Ali -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Label -X- _ O
noise -X- _ O
is -X- _ O
the -X- _ O
main -X- _ O
problem -X- _ O
brought -X- _ O
by -X- _ O
distance -X- _ O
supervision -X- _ O
. -X- _ O
Besides -X- _ O
common -X- _ O
noisy -X- _ O
learning -X- _ O
methods -X- _ O
discussed -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
4.1 -X- _ O
( -X- _ O
Onoe -X- _ O
and -X- _ O
Durrett -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
FET -X- _ B-TaskName
- -X- _ O
specific -X- _ O
noise -X- _ O
combat -X- _ O
methods -X- _ O
are -X- _ O
proposed -X- _ O
. -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
utilized -X- _ O
partial -X- _ O
- -X- _ O
label -X- _ O
embedding -X- _ O
. -X- _ O
Xu -X- _ O
and -X- _ O
Barbosa -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
modified -X- _ O
hierarchical -X- _ O
loss -X- _ O
to -X- _ O
cope -X- _ O
with -X- _ O
overly -X- _ O
- -X- _ O
specific -X- _ O
noise -X- _ O
. -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
automatically -X- _ O
generated -X- _ O
pseudo -X- _ O
- -X- _ O
truth -X- _ O
label -X- _ O
distribution -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
. -X- _ O
Additional -X- _ O
resource -X- _ O
also -X- _ O
help -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
resource -X- _ O
include -X- _ O
external -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
Xin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
with -X- _ O
BERT -X- _ O
- -X- _ O
like -X- _ O
pipeline -X- _ O
( -X- _ O
Patel -X- _ O
and -X- _ O
Ferraro -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Choi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
utilize -X- _ O
more -X- _ O
distance -X- _ O
supervision -X- _ O
and -X- _ O
crowd -X- _ O
source -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
Onoe -X- _ O
and -X- _ O
Durrett -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
. -X- _ O
Apart -X- _ O
from -X- _ O
the -X- _ O
above -X- _ O
, -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Ali -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
closest -X- _ O
to -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O
They -X- _ O
both -X- _ O
select -X- _ O
some -X- _ O
instances -X- _ O
by -X- _ O
feature -X- _ O
distance -X- _ O
to -X- _ O
modify -X- _ O
labels -X- _ O
or -X- _ O
refine -X- _ O
mention -X- _ O
representation -X- _ O
for -X- _ O
noisy -X- _ O
instances -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
their -X- _ O
refinement -X- _ O
is -X- _ O
still -X- _ O
explicit -X- _ O
and -X- _ O
isolated -X- _ O
to -X- _ O
each -X- _ O
instance -X- _ O
. -X- _ O
Thus -X- _ O
the -X- _ O
quality -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
instances -X- _ O
they -X- _ O
retrieve -X- _ O
for -X- _ O
label -X- _ O
propagation -X- _ O
/ -X- _ O
mention -X- _ O
reference -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
these -X- _ O
studies -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
any -X- _ O
of -X- _ O
these -X- _ O
external -X- _ O
resources -X- _ O
and -X- _ O
aim -X- _ O
to -X- _ O
impose -X- _ O
label -X- _ O
noise -X- _ O
with -X- _ O
only -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
without -X- _ O
explicit -X- _ O
sieving -X- _ O
or -X- _ O
label -X- _ O
changing -X- _ O
. -X- _ O
5 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
instancedependent -X- _ O
label -X- _ O
noise -X- _ O
in -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
entity -X- _ O
typing -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
neural -X- _ O
FET -X- _ B-TaskName
noisy -X- _ O
learning2004framework -X- _ O
that -X- _ O
utilizes -X- _ O
the -X- _ O
feature -X- _ O
space -X- _ O
information -X- _ O
and -X- _ O
global -X- _ O
information -X- _ O
jointly -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
compared -X- _ O
with -X- _ O
competitive -X- _ O
existing -X- _ O
FET -X- _ B-TaskName
systems -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
extensive -X- _ O
auxiliary -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
noisy -X- _ O
learning -X- _ O
framework -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
with -X- _ O
qualitative -X- _ O
and -X- _ O
quantitative -X- _ O
analysis -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
can -X- _ O
motivate -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
further -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
dataset -X- _ O
noise -X- _ O
distribution -X- _ O
estimation -X- _ O
and -X- _ O
the -X- _ O
instance -X- _ O
features -X- _ O
. -X- _ O
More -X- _ O
work -X- _ O
can -X- _ O
be -X- _ O
done -X- _ O
towards -X- _ O
this -X- _ O
direction -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
under -X- _ O
different -X- _ O
backbone -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
dug -X- _ O
to -X- _ O
validate -X- _ O
the -X- _ O
flexibility -X- _ O
of -X- _ O
the -X- _ O
framework -X- _ O
. -X- _ O
Acknowledgements -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Key -X- _ O
Research -X- _ O
and -X- _ O
Development -X- _ O
Project -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2021ZD0110700 -X- _ O
) -X- _ O
. -X- _ O
References20052006 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
presents -X- _ SUMMARY
a -X- _ SUMMARY
study -X- _ SUMMARY
on -X- _ SUMMARY
leveraging -X- _ SUMMARY
multilingual -X- _ SUMMARY
pre -X- _ SUMMARY
- -X- _ SUMMARY
trained -X- _ SUMMARY
generative -X- _ SUMMARY
language -X- _ SUMMARY
models -X- _ SUMMARY
for -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
lingual -X- _ SUMMARY
event -X- _ SUMMARY
argument -X- _ SUMMARY
extraction -X- _ SUMMARY
( -X- _ SUMMARY
EAE -X- _ SUMMARY
) -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
model -X- _ SUMMARY
, -X- _ SUMMARY
X -X- _ SUMMARY
- -X- _ SUMMARY
G -X- _ SUMMARY
( -X- _ SUMMARY
Cross -X- _ SUMMARY
- -X- _ SUMMARY
lingual -X- _ SUMMARY
Generative -X- _ SUMMARY
Event -X- _ SUMMARY
Argument -X- _ SUMMARY
extractor -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
effectively -X- _ SUMMARY
encodes -X- _ SUMMARY
event -X- _ SUMMARY
structures -X- _ SUMMARY
and -X- _ SUMMARY
captures -X- _ SUMMARY
dependencies -X- _ SUMMARY
between -X- _ SUMMARY
arguments -X- _ SUMMARY
. -X- _ SUMMARY
It -X- _ SUMMARY
uses -X- _ SUMMARY
language -X- _ SUMMARY
- -X- _ SUMMARY
agnostic -X- _ SUMMARY
templates -X- _ SUMMARY
to -X- _ SUMMARY
represent -X- _ SUMMARY
event -X- _ SUMMARY
argument -X- _ SUMMARY
structures -X- _ SUMMARY
, -X- _ SUMMARY
allowing -X- _ SUMMARY
for -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
lingual -X- _ SUMMARY
transfer -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
model -X- _ SUMMARY
is -X- _ SUMMARY
trained -X- _ SUMMARY
on -X- _ SUMMARY
source -X- _ SUMMARY
languages -X- _ SUMMARY
and -X- _ SUMMARY
applied -X- _ SUMMARY
to -X- _ SUMMARY
target -X- _ SUMMARY
languages -X- _ SUMMARY
for -X- _ SUMMARY
event -X- _ SUMMARY
argument -X- _ SUMMARY
extraction -X- _ SUMMARY
. -X- _ SUMMARY
Experiments -X- _ SUMMARY
on -X- _ SUMMARY
ACE-2005 -X- _ SUMMARY
and -X- _ SUMMARY
ERE -X- _ SUMMARY
datasets -X- _ SUMMARY
demonstrate -X- _ SUMMARY
that -X- _ SUMMARY
X -X- _ SUMMARY
- -X- _ SUMMARY
G -X- _ SUMMARY
outperforms -X- _ SUMMARY
existing -X- _ SUMMARY
state -X- _ SUMMARY
- -X- _ SUMMARY
of -X- _ SUMMARY
- -X- _ SUMMARY
the -X- _ SUMMARY
- -X- _ SUMMARY
art -X- _ SUMMARY
models -X- _ SUMMARY
on -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
lingual -X- _ SUMMARY
EAE -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metric -X- _ SUMMARY
used -X- _ SUMMARY
is -X- _ SUMMARY
the -X- _ SUMMARY
argument -X- _ SUMMARY
classification -X- _ SUMMARY
F1 -X- _ SUMMARY
score -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
model -X- _ SUMMARY
shows -X- _ SUMMARY
promise -X- _ SUMMARY
for -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
lingual -X- _ SUMMARY
EAE -X- _ SUMMARY
without -X- _ SUMMARY
the -X- _ SUMMARY
need -X- _ SUMMARY
for -X- _ SUMMARY
additional -X- _ SUMMARY
modules -X- _ SUMMARY
or -X- _ SUMMARY
annotations -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-long.317.txt -X- _ O
Kuan -X- _ O
- -X- _ O
Hao -X- _ O
HuangI -X- _ O
- -X- _ O
Hung -X- _ O
HsuPremkumar -X- _ O
Natarajan -X- _ O
Kai -X- _ O
- -X- _ O
Wei -X- _ O
ChangNanyun -X- _ O
PengComputer -X- _ O
Science -X- _ O
Department -X- _ O
, -X- _ O
University -X- _ O
of -X- _ O
California -X- _ O
, -X- _ O
Los -X- _ O
AngelesInformation -X- _ O
Science -X- _ O
Institute -X- _ O
, -X- _ O
University -X- _ O
of -X- _ O
Southern -X- _ O
California -X- _ O
{ -X- _ O
khhuang -X- _ O
, -X- _ O
kwchang -X- _ O
, -X- _ O
violetpeng -X- _ O
} -X- _ O
@ -X- _ O
cs.ucla.edu -X- _ O
{ -X- _ O
ihunghsu -X- _ O
, -X- _ O
pnataraj -X- _ O
} -X- _ O
@ -X- _ O
isi.edu -X- _ O
Abstract -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
study -X- _ O
on -X- _ O
leveraging -X- _ O
multilingual -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
generative -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
event -X- _ I-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
( -X- _ O
EAE -X- _ B-TaskName
) -X- _ O
. -X- _ O
By -X- _ O
formulating -X- _ O
EAE -X- _ B-TaskName
as -X- _ O
a -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
task -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
effectively -X- _ O
encodes -X- _ O
event -X- _ O
structures -X- _ O
and -X- _ O
captures -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
arguments -X- _ O
. -X- _ O
We -X- _ O
design -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
event -X- _ O
argument -X- _ O
structures -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
compatible -X- _ O
with -X- _ O
any -X- _ O
language -X- _ O
, -X- _ O
hence -X- _ O
facilitating -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
model -X- _ O
ﬁnetunes -X- _ O
multilingual -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
sentences -X- _ O
that -X- _ O
ﬁll -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
with -X- _ O
arguments -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
passage -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
source -X- _ O
languages -X- _ O
and -X- _ O
is -X- _ O
then -X- _ O
directly -X- _ O
applied -X- _ O
to -X- _ O
target -X- _ O
languages -X- _ O
for -X- _ O
event -X- _ O
argument -X- _ O
extraction -X- _ O
. -X- _ O
Experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
outperforms -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
. -X- _ O
Comprehensive -X- _ O
studies -X- _ O
and -X- _ O
error -X- _ O
analyses -X- _ O
are -X- _ O
presented -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ O
advantages -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
limitations -X- _ O
of -X- _ O
using -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
EAE -X- _ I-TaskName
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Event -X- _ B-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
( -X- _ O
EAE -X- _ B-TaskName
) -X- _ O
aims -X- _ O
to -X- _ O
recognize -X- _ O
the -X- _ O
entities -X- _ O
serving -X- _ O
as -X- _ O
event -X- _ O
arguments -X- _ O
and -X- _ O
identify -X- _ O
their -X- _ O
corresponding -X- _ O
roles -X- _ O
. -X- _ O
As -X- _ O
illustrated -X- _ O
by -X- _ O
the -X- _ O
English -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
trigger -X- _ O
word -X- _ O
“ -X- _ O
destroyed -X- _ O
” -X- _ O
for -X- _ O
a -X- _ O
Conﬂict -X- _ O
: -X- _ O
Attack -X- _ O
event -X- _ O
, -X- _ O
an -X- _ O
event -X- _ O
argument -X- _ O
extractor -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
identify -X- _ O
“ -X- _ O
commando -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Iraq -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
post -X- _ O
” -X- _ O
as -X- _ O
the -X- _ O
event -X- _ O
arguments -X- _ O
and -X- _ O
predict -X- _ O
their -X- _ O
roles -X- _ O
as -X- _ O
“ -X- _ O
Attacker -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Place -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
Target -X- _ O
” -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
has -X- _ O
attracted -X- _ O
considerable -X- _ O
attention -X- _ O
since -X- _ O
it -X- _ O
eliminates -X- _ O
the -X- _ O
requirement -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
constructing -X- _ O
EAE -X- _ B-TaskName
models -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Nguyen -X- _ O
and -X- _ O
Nguyen -X- _ O
, -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
illustration -X- _ O
of -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
event -X- _ I-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
Given -X- _ O
sentences -X- _ O
in -X- _ O
arbitrary -X- _ O
languages -X- _ O
and -X- _ O
their -X- _ O
event -X- _ O
triggers -X- _ O
( -X- _ O
destroyed -X- _ O
and起义 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
identify -X- _ O
arguments -X- _ O
( -X- _ O
commando -X- _ O
, -X- _ O
Iraq -X- _ O
andpost -X- _ O
v.s.军队 -X- _ O
, -X- _ O
and反对派 -X- _ O
) -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
roles -X- _ O
( -X- _ O
Attacker -X- _ O
, -X- _ O
Target -X- _ O
, -X- _ O
and -X- _ O
Place -X- _ O
) -X- _ O
. -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
languages -X- _ O
and -X- _ O
directly -X- _ O
tested -X- _ O
on -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
modelshave -X- _ O
shown -X- _ O
strong -X- _ O
performances -X- _ O
on -X- _ O
monolingual -X- _ O
structured -X- _ O
prediction -X- _ O
tasks -X- _ O
( -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Paolini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
EAE -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Hsu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
works -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
outputs -X- _ O
following -X- _ O
designed -X- _ O
templates -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
ﬁnal -X- _ O
predictions -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
decoded -X- _ O
from -X- _ O
the -X- _ O
outputs -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
traditional -X- _ O
classiﬁcation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wadden -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
they -X- _ O
better -X- _ O
capture -X- _ O
the -X- _ O
structures -X- _ O
and -X- _ O
dependencies -X- _ O
between -X- _ O
entities -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
templates -X- _ O
provide -X- _ O
additional -X- _ O
declarative -X- _ O
information -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
successes -X- _ O
, -X- _ O
the -X- _ O
designs -X- _ O
of -X- _ O
templates -X- _ O
in -X- _ O
prior -X- _ O
works -X- _ O
are -X- _ O
language -X- _ O
- -X- _ O
dependent -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
hard -X- _ O
to -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
setting -X- _ O
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Naively -X- _ O
applying -X- _ O
such -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
languages -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
usually -X- _ O
generates -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
outputs -X- _ O
, -X- _ O
yielding -X- _ O
poor -X- _ O
performance -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot4633cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
will -X- _ O
empirically -X- _ O
show -X- _ O
in -X- _ O
Section -X- _ O
5.4 -X- _ O
. -X- _ O
How -X- _ O
to -X- _ O
design -X- _ O
languageagnostic -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
structured -X- _ I-TaskName
prediction -X- _ I-TaskName
problems -X- _ O
is -X- _ O
still -X- _ O
an -X- _ O
open -X- _ O
question -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
study -X- _ O
that -X- _ O
leverage -X- _ O
multilingual -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
models -X- _ O
for -X- _ O
zeroshot -X- _ B-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
event -X- _ I-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
and -X- _ O
propose -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
Cross -X- _ O
-lingual -X- _ O
Generative -X- _ O
Event -X- _ O
Argument -X- _ O
extracto -X- _ O
R -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
passage -X- _ O
and -X- _ O
a -X- _ O
carefully -X- _ O
designed -X- _ O
prompt -X- _ O
that -X- _ O
contains -X- _ O
an -X- _ O
event -X- _ O
trigger -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
, -X- _ O
X -X- _ B-TaskName
- -X- _ I-TaskName
G -X- _ I-TaskName
is -X- _ O
trained -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
sentence -X- _ O
that -X- _ O
ﬁlls -X- _ O
in -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
with -X- _ O
arguments -X- _ O
. -X- _ O
X -X- _ B-TaskName
- -X- _ I-TaskName
G -X- _ I-TaskName
inherits -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
that -X- _ O
captures -X- _ O
event -X- _ O
structures -X- _ O
and -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
entities -X- _ O
better -X- _ O
than -X- _ O
classiﬁcation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
decoder -X- _ O
inherently -X- _ O
identiﬁes -X- _ O
named -X- _ O
entities -X- _ O
as -X- _ O
candidates -X- _ O
for -X- _ O
event -X- _ O
arguments -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
need -X- _ O
an -X- _ O
additional -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
module -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
prevents -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
overﬁtting -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
’s -X- _ O
vocabulary -X- _ O
and -X- _ O
facilitates -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
multilingual -X- _ O
EAE -X- _ B-TaskName
datasets -X- _ O
: -X- _ O
ACE-2005 -X- _ B-DatasetName
( -X- _ O
Doddington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
and -X- _ O
ERE -X- _ B-DatasetName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
EAE -X- _ B-TaskName
models -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
perform -X- _ O
ablation -X- _ O
studies -X- _ O
to -X- _ O
justify -X- _ O
our -X- _ O
design -X- _ O
and -X- _ O
present -X- _ O
comprehensive -X- _ O
error -X- _ O
analyses -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
using -X- _ O
multilingual -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
crosslingual -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
PlusLabNLP -X- _ O
/ -X- _ O
X -X- _ O
- -X- _ O
Gear -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
Zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
structured -X- _ O
prediction -X- _ O
. -X- _ O
Zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
learning -X- _ I-TaskName
is -X- _ O
an -X- _ O
emerging -X- _ O
research -X- _ O
topic -X- _ O
as -X- _ O
it -X- _ O
eliminates -X- _ O
the -X- _ O
requirement -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
models -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
( -X- _ O
Ruder -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
Various -X- _ O
structured -X- _ O
prediction -X- _ O
tasks -X- _ O
have -X- _ O
been -X- _ O
studied -X- _ O
, -X- _ O
including -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
dependency -X- _ O
parsing -X- _ O
( -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
, -X- _ O
a -X- _ O
; -X- _ O
Menget -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Ni -X- _ O
and -X- _ O
Florian -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
event -X- _ O
argument -X- _ O
extraction -X- _ O
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Nguyen -X- _ O
and -X- _ O
Nguyen -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Fincke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
them -X- _ O
areclassiﬁcation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
that -X- _ O
build -X- _ O
classiﬁers -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
a -X- _ O
multilingual -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
masked -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O
To -X- _ O
further -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
discrepancy -X- _ O
between -X- _ O
languages -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
require -X- _ O
additional -X- _ O
information -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
bilingual -X- _ O
dictionaries -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ni -X- _ O
and -X- _ O
Florian -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
translation -X- _ O
pairs -X- _ O
( -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
dependency -X- _ O
parse -X- _ O
trees -X- _ O
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Nguyen -X- _ O
and -X- _ O
Nguyen -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
pointed -X- _ O
out -X- _ O
by -X- _ O
previous -X- _ O
literature -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Hsu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
classiﬁcation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
are -X- _ O
less -X- _ O
powerful -X- _ O
to -X- _ O
model -X- _ O
dependencies -X- _ O
between -X- _ O
entities -X- _ O
compared -X- _ O
to -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
Generation -X- _ O
- -X- _ O
based -X- _ O
structured -X- _ O
prediction -X- _ O
. -X- _ O
Several -X- _ O
works -X- _ O
have -X- _ O
demonstrated -X- _ O
the -X- _ O
great -X- _ O
success -X- _ O
of -X- _ O
generation -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
on -X- _ O
monolingual -X- _ O
structured -X- _ O
prediction -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021b -X- _ O
; -X- _ O
Paolini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
event -X- _ O
extraction -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Hsu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
1 -X- _ O
, -X- _ O
their -X- _ O
designed -X- _ O
generating -X- _ O
targets -X- _ O
are -X- _ O
language -X- _ O
- -X- _ O
dependent -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
directly -X- _ O
applying -X- _ O
their -X- _ O
methods -X- _ O
to -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
setting -X- _ O
would -X- _ O
result -X- _ O
in -X- _ O
less -X- _ O
- -X- _ O
preferred -X- _ O
performance -X- _ O
. -X- _ O
Prompting -X- _ O
methods -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
growing -X- _ O
interests -X- _ O
recently -X- _ O
to -X- _ O
incorporate -X- _ O
prompts -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
behavior -X- _ O
or -X- _ O
elicit -X- _ O
knowledge -X- _ O
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Sheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Qin -X- _ O
and -X- _ O
Eisner -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Scao -X- _ O
and -X- _ O
Rush -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
taxonomy -X- _ O
in -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
classiﬁed -X- _ O
depending -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
’ -X- _ O
parameters -X- _ O
are -X- _ O
tuned -X- _ O
and -X- _ O
on -X- _ O
whether -X- _ O
trainable -X- _ O
prompts -X- _ O
are -X- _ O
introduced -X- _ O
. -X- _ O
Our -X- _ O
method -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
category -X- _ O
that -X- _ O
ﬁxes -X- _ O
the -X- _ O
prompts -X- _ O
and -X- _ O
tunes -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
’ -X- _ O
parameters -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
ﬂourish -X- _ O
of -X- _ O
the -X- _ O
research -X- _ O
in -X- _ O
prompting -X- _ O
methods -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
only -X- _ O
limited -X- _ O
attention -X- _ O
being -X- _ O
put -X- _ O
on -X- _ O
multilingual -X- _ O
tasks -X- _ O
( -X- _ O
Winata -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
Zero -X- _ B-TaskName
- -X- _ I-TaskName
Shot -X- _ I-TaskName
Cross -X- _ I-TaskName
- -X- _ I-TaskName
Lingual -X- _ I-TaskName
Event -X- _ I-TaskName
Argument -X- _ I-TaskName
Extraction -X- _ I-TaskName
We -X- _ O
focus -X- _ O
on -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
passage -X- _ O
and -X- _ O
an -X- _ O
event -X- _ O
trigger -X- _ O
, -X- _ O
an -X- _ O
EAE4634 -X- _ B-MethodName
model -X- _ O
identiﬁes -X- _ O
arguments -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
roles -X- _ O
. -X- _ O
More -X- _ O
speciﬁcally -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
by -X- _ O
the -X- _ O
training -X- _ O
examples -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
input -X- _ O
passage -X- _ O
xand -X- _ O
an -X- _ O
event -X- _ O
trigger -X- _ O
t -X- _ O
( -X- _ O
killed -X- _ O
) -X- _ O
belonging -X- _ O
to -X- _ O
an -X- _ O
event -X- _ O
type -X- _ O
e -X- _ O
( -X- _ O
Life -X- _ O
: -X- _ O
Die -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
EAE -X- _ B-MethodName
model -X- _ O
predicts -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
arguments -X- _ O
a= -X- _ O
[ -X- _ O
a -X- _ O
; -X- _ O
a -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
a -X- _ O
] -X- _ O
( -X- _ O
coalition -X- _ O
, -X- _ O
civilians -X- _ O
, -X- _ O
woman -X- _ O
, -X- _ O
missile -X- _ O
, -X- _ O
houses -X- _ O
) -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
roles -X- _ O
r= -X- _ O
[ -X- _ O
r -X- _ O
; -X- _ O
r -X- _ O
; -X- _ O
: -X- _ O
: -X- _ O
; -X- _ O
r -X- _ O
] -X- _ O
( -X- _ O
Agent -X- _ O
, -X- _ O
Victim -X- _ O
, -X- _ O
Victim -X- _ O
, -X- _ O
Instrument -X- _ O
, -X- _ O
Place -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
setting -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
setX -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
t -X- _ O
; -X- _ O
e -X- _ O
; -X- _ O
a -X- _ O
; -X- _ O
r -X- _ O
) -X- _ O
gbelongs -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
languages -X- _ O
while -X- _ O
the -X- _ O
testing -X- _ O
set -X- _ O
X= -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
t -X- _ O
; -X- _ O
e -X- _ O
; -X- _ O
a -X- _ O
; -X- _ O
r -X- _ O
) -X- _ O
gare -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
monolingual -X- _ O
EAE -X- _ B-MethodName
, -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
crosslingual -X- _ I-TaskName
EAE -X- _ I-TaskName
models -X- _ O
are -X- _ O
expected -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
arguments -X- _ O
and -X- _ O
make -X- _ O
structured -X- _ O
predictions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
unlike -X- _ O
monolingual -X- _ B-TaskName
EAE -X- _ I-TaskName
, -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
models -X- _ O
need -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
differences -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
grammar -X- _ O
, -X- _ O
word -X- _ O
order -X- _ O
) -X- _ O
between -X- _ O
languages -X- _ O
and -X- _ O
learn -X- _ O
to -X- _ O
transfer -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
languages -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
4 -X- _ O
Proposed -X- _ O
Method -X- _ O
: -X- _ O
X -X- _ O
- -X- _ O
G -X- _ O
We -X- _ O
formulate -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
as -X- _ O
a -X- _ O
language -X- _ O
generation -X- _ O
task -X- _ O
and -X- _ O
propose -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
, -X- _ O
aCross -X- _ O
-lingual -X- _ O
Generative -X- _ O
Event -X- _ O
Argument -X- _ O
extracto -X- _ O
Rthat -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
challenges -X- _ O
raised -X- _ O
by -X- _ O
this -X- _ O
formulation -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
input -X- _ O
language -X- _ O
may -X- _ O
vary -X- _ O
during -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
The -X- _ O
generated -X- _ O
output -X- _ O
strings -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
easily -X- _ O
parsed -X- _ O
into -X- _ O
ﬁnal -X- _ O
predictions -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
output -X- _ O
strings -X- _ O
have -X- _ O
to -X- _ O
reﬂect -X- _ O
the -X- _ O
change -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
language -X- _ O
accordingly -X- _ O
while -X- _ O
remaining -X- _ O
well -X- _ O
- -X- _ O
structured -X- _ O
. -X- _ O
We -X- _ O
address -X- _ O
these -X- _ O
challenges -X- _ O
by -X- _ O
designing -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
input -X- _ O
passage -X- _ O
xand -X- _ O
a -X- _ O
designed -X- _ O
prompt -X- _ O
that -X- _ O
contains -X- _ O
the -X- _ O
given -X- _ O
trigger -X- _ O
t -X- _ O
, -X- _ O
its -X- _ O
event -X- _ O
type -X- _ O
e -X- _ O
, -X- _ O
and -X- _ O
alanguage -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
, -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
learns -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
output -X- _ O
string -X- _ O
that -X- _ O
ﬁlls -X- _ O
in -X- _ O
the -X- _ O
languageagnostic -X- _ O
template -X- _ O
with -X- _ O
information -X- _ O
extracted -X- _ O
from -X- _ O
input -X- _ O
passage -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
is -X- _ O
designed -X- _ O
in -X- _ O
a -X- _ O
structured -X- _ O
way -X- _ O
such -X- _ O
that -X- _ O
parsing -X- _ O
the -X- _ O
ﬁnal -X- _ O
argument -X- _ O
predictions -X- _ O
aand -X- _ O
role -X- _ O
predictions -X- _ O
r -X- _ O
from -X- _ O
the -X- _ O
generated -X- _ O
output -X- _ O
is -X- _ O
trivial -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
template -X- _ O
is -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
, -X- _ O
it -X- _ O
facilitates -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
ﬁne -X- _ O
- -X- _ O
tunes -X- _ O
multilingual -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
generative -X- _ I-MethodName
models -X- _ I-MethodName
, -X- _ O
such -X- _ O
as -X- _ O
mBART-50 -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
mT5 -X- _ O
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
augments -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
copy -X- _ O
mechanism -X- _ O
to -X- _ O
better -X- _ O
adapt -X- _ O
to -X- _ O
input -X- _ O
language -X- _ O
changes -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
its -X- _ O
details -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
output -X- _ O
string -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
format -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
training -X- _ O
details -X- _ O
. -X- _ O
4.1 -X- _ O
Language -X- _ O
- -X- _ O
Agnostic -X- _ O
Template -X- _ O
We -X- _ O
create -X- _ O
one -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
Tfor -X- _ O
each -X- _ O
event -X- _ O
type -X- _ O
e -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
list -X- _ O
all -X- _ O
possible -X- _ O
associated -X- _ O
rolesand -X- _ O
form -X- _ O
a -X- _ O
unique -X- _ O
HTML -X- _ O
- -X- _ O
tag -X- _ O
- -X- _ O
style -X- _ O
template -X- _ O
for -X- _ O
that -X- _ O
event -X- _ O
type -X- _ O
e. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
Life -X- _ O
: -X- _ O
Die -X- _ O
event -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
four -X- _ O
roles -X- _ O
: -X- _ O
Agent -X- _ O
, -X- _ O
Victim -X- _ O
, -X- _ O
Instrument -X- _ O
, -X- _ O
and -X- _ O
Place -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
template -X- _ O
for -X- _ O
Life -X- _ O
: -X- _ O
Die -X- _ O
events -X- _ O
is -X- _ O
designed -X- _ O
as:4635 -X- _ O
For -X- _ O
ease -X- _ O
of -X- _ O
understanding -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
English -X- _ O
words -X- _ O
to -X- _ O
present -X- _ O
the -X- _ O
template -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
tokens -X- _ O
( -X- _ O
[ -X- _ O
None -X- _ O
] -X- _ O
, -X- _ O
< -X- _ O
Agent -X- _ O
> -X- _ O
, -X- _ O
< -X- _ O
/ -X- _ O
Agent -X- _ O
> -X- _ O
, -X- _ O
< -X- _ O
Victim -X- _ O
> -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
are -X- _ O
encoded -X- _ O
as -X- _ O
special -X- _ O
tokensthat -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
have -X- _ O
never -X- _ O
seen -X- _ O
and -X- _ O
thus -X- _ O
their -X- _ O
representations -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
Since -X- _ O
these -X- _ O
special -X- _ O
tokens -X- _ O
are -X- _ O
not -X- _ O
associated -X- _ O
with -X- _ O
any -X- _ O
language -X- _ O
and -X- _ O
are -X- _ O
not -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
considered -X- _ O
as -X- _ O
languageagnostic -X- _ O
. -X- _ O
4.2 -X- _ O
Target -X- _ O
Output -X- _ O
String -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
learns -X- _ O
to -X- _ O
generate -X- _ O
target -X- _ O
output -X- _ O
strings -X- _ O
that -X- _ O
follow -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
. -X- _ O
To -X- _ O
compose -X- _ O
the -X- _ O
target -X- _ O
output -X- _ O
string -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
instance -X- _ O
( -X- _ O
x -X- _ O
; -X- _ O
t -X- _ O
; -X- _ O
e -X- _ O
; -X- _ O
a -X- _ O
; -X- _ O
r -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
pick -X- _ O
out -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
Tfor -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
eand -X- _ O
then -X- _ O
replace -X- _ O
all -X- _ O
“ -X- _ O
[ -X- _ O
None -X- _ O
] -X- _ O
” -X- _ O
inTwith -X- _ O
the -X- _ O
corresponding -X- _ O
arguments -X- _ O
in -X- _ O
a -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
roles -X- _ O
r. -X- _ O
If -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
arguments -X- _ O
for -X- _ O
one -X- _ O
role -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
“ -X- _ O
[ -X- _ O
and -X- _ O
] -X- _ O
” -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
has -X- _ O
two -X- _ O
arguments -X- _ O
( -X- _ O
civilians -X- _ O
and -X- _ O
woman -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
Victim -X- _ O
role -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
string -X- _ O
would -X- _ O
be -X- _ O
If -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
corresponding -X- _ O
arguments -X- _ O
for -X- _ O
one -X- _ O
role -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
“ -X- _ O
[ -X- _ O
None -X- _ O
] -X- _ O
” -X- _ O
inT. -X- _ O
By -X- _ O
applying -X- _ O
this -X- _ O
rule -X- _ O
, -X- _ O
the -X- _ O
full -X- _ O
output -X- _ O
string -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
becomes -X- _ O
Since -X- _ O
the -X- _ O
output -X- _ O
string -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
HTML -X- _ O
- -X- _ O
tag -X- _ O
style -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
easily -X- _ O
decode -X- _ O
the -X- _ O
argument -X- _ O
and -X- _ O
role -X- _ O
predictions -X- _ O
from -X- _ O
the -X- _ O
generated -X- _ O
output -X- _ O
string -X- _ O
via -X- _ O
a -X- _ O
simple -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
algorithm -X- _ O
. -X- _ O
4.3 -X- _ O
Input -X- _ O
Format -X- _ O
As -X- _ O
we -X- _ O
mentioned -X- _ O
previously -X- _ O
, -X- _ O
the -X- _ O
key -X- _ O
for -X- _ O
the -X- _ O
generative -X- _ O
formulation -X- _ O
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
is -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
output -X- _ O
strings -X- _ O
in -X- _ O
the -X- _ O
desired -X- _ O
format -X- _ O
. -X- _ O
To -X- _ O
facilitate -X- _ O
this -X- _ O
behavior -X- _ O
, -X- _ O
we -X- _ O
feed -X- _ O
the -X- _ O
input -X- _ O
passage -X- _ O
xas -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
prompt -X- _ O
toX -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
, -X- _ O
as -X- _ O
shown -X- _ O
by -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
prompt -X- _ O
contains -X- _ O
allvaluable -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
make -X- _ O
predictions -X- _ O
, -X- _ O
including -X- _ O
a -X- _ O
trigger -X- _ O
tand -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templateT. -X- _ O
Notice -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
explicitly -X- _ O
include -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
ein -X- _ O
the -X- _ O
prompt -X- _ O
because -X- _ O
the -X- _ O
templateTimplicitly -X- _ O
contains -X- _ O
this -X- _ O
information -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
6.1 -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
the -X- _ O
experiments -X- _ O
on -X- _ O
explicitly -X- _ O
adding -X- _ O
event -X- _ O
type -X- _ O
eto -X- _ O
the -X- _ O
prompt -X- _ O
and -X- _ O
discuss -X- _ O
its -X- _ O
inﬂuence -X- _ O
on -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O
4.4 -X- _ O
Training -X- _ O
To -X- _ O
enable -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
to -X- _ O
generate -X- _ O
sentences -X- _ O
in -X- _ O
different -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
resort -X- _ O
multilingual -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
our -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
models -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
of -X- _ O
generating -X- _ O
a -X- _ O
new -X- _ O
token -X- _ O
given -X- _ O
the -X- _ O
previous -X- _ O
generated -X- _ O
tokens -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
context -X- _ O
to -X- _ O
the -X- _ O
encoder -X- _ O
c -X- _ O
, -X- _ O
i.e -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
xjc -X- _ O
) -X- _ O
= -X- _ O
YP -X- _ O
( -X- _ O
xjx -X- _ O
; -X- _ O
c -X- _ O
) -X- _ O
; -X- _ O
wherexis -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
at -X- _ O
step -X- _ O
i. -X- _ O
Copy -X- _ O
mechanism -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
multilingual -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
generative -X- _ I-MethodName
models -X- _ I-MethodName
can -X- _ O
generate -X- _ O
sequences -X- _ O
in -X- _ O
many -X- _ O
languages -X- _ O
, -X- _ O
solely -X- _ O
relying -X- _ O
on -X- _ O
them -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
generating -X- _ O
hallucinating -X- _ O
arguments -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
output -X- _ O
string -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
multilingual -X- _ B-MethodName
pre -X- _ I-MethodName
- -X- _ I-MethodName
trained -X- _ I-MethodName
generative -X- _ I-MethodName
models -X- _ I-MethodName
with -X- _ O
a -X- _ O
copy -X- _ O
mechanism -X- _ O
to -X- _ O
help -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
better -X- _ O
adapt -X- _ O
to -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
scenario -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
decide -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
of -X- _ O
generating -X- _ O
a -X- _ O
token -X- _ O
t -X- _ O
as -X- _ O
a -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
distribution -X- _ O
computed -X- _ O
by -X- _ O
multilingual -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
modelPand -X- _ O
copy -X- _ O
distribution -X- _ O
P -X- _ O
wherew2 -X- _ O
[ -X- _ O
0 -X- _ O
; -X- _ O
1 -X- _ O
] -X- _ O
is -X- _ O
the -X- _ O
copy -X- _ O
probability -X- _ O
computed -X- _ O
by -X- _ O
passing -X- _ O
the -X- _ O
decoder -X- _ O
hidden -X- _ O
state -X- _ O
at -X- _ O
time -X- _ O
stepito -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
. -X- _ O
As -X- _ O
for -X- _ O
P -X- _ O
, -X- _ O
it -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
probability -X- _ O
over -X- _ O
input -X- _ O
tokens -X- _ O
weighted -X- _ O
by -X- _ O
the -X- _ O
crossattention -X- _ O
that -X- _ O
the -X- _ O
last -X- _ O
decoder -X- _ O
layer -X- _ O
computed -X- _ O
( -X- _ O
at -X- _ O
time -X- _ O
stepi -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
is -X- _ O
then -X- _ O
trained -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
loss -X- _ O
: -X- _ O
L=logXP -X- _ O
( -X- _ O
xjx -X- _ O
; -X- _ O
c -X- _ O
) -X- _ O
: -X- _ O
5 -X- _ O
Experiments -X- _ O
5.1 -X- _ O
Datasets -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
commonly -X- _ O
used -X- _ O
event -X- _ O
extraction -X- _ O
datasets -X- _ O
: -X- _ O
ACE-2005 -X- _ B-DatasetName
and -X- _ O
ERE -X- _ B-DatasetName
. -X- _ O
We -X- _ O
consider -X- _ O
En-4636glish -X- _ O
, -X- _ O
Arabic -X- _ O
, -X- _ O
and -X- _ O
Chinese -X- _ O
annotations -X- _ O
for -X- _ O
ACE2005 -X- _ B-DatasetName
( -X- _ O
Doddington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
preprocessing -X- _ O
in -X- _ O
Wadden -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
keep -X- _ O
33 -X- _ O
event -X- _ O
types -X- _ O
and -X- _ O
22 -X- _ O
argument -X- _ O
roles -X- _ O
. -X- _ O
ERE -X- _ B-DatasetName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
is -X- _ O
created -X- _ O
by -X- _ O
the -X- _ O
Deep -X- _ O
Exploration -X- _ O
and -X- _ O
Filtering -X- _ O
of -X- _ O
Test -X- _ O
program -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
its -X- _ O
English -X- _ O
and -X- _ O
Spanish -X- _ O
annotations -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
preprocessing -X- _ O
in -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
keep -X- _ O
38 -X- _ O
event -X- _ O
types -X- _ O
and -X- _ O
21 -X- _ O
argument -X- _ O
roles -X- _ O
. -X- _ O
Detailed -X- _ O
statistics -X- _ O
and -X- _ O
preprocessing -X- _ O
steps -X- _ O
about -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
are -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
Notice -X- _ O
that -X- _ O
prior -X- _ O
works -X- _ O
working -X- _ O
on -X- _ O
the -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
of -X- _ O
event -X- _ O
arguments -X- _ O
mostly -X- _ O
focus -X- _ O
on -X- _ O
event -X- _ O
argument -X- _ O
role -X- _ O
labeling -X- _ O
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
they -X- _ O
assume -X- _ O
ground -X- _ O
truth -X- _ O
entities -X- _ O
are -X- _ O
provided -X- _ O
during -X- _ O
both -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
. -X- _ O
In -X- _ O
their -X- _ O
experimental -X- _ O
data -X- _ O
splits -X- _ O
, -X- _ O
events -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
can -X- _ O
be -X- _ O
scattered -X- _ O
in -X- _ O
all -X- _ O
training -X- _ O
, -X- _ O
development -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
split -X- _ O
since -X- _ O
they -X- _ O
treat -X- _ O
each -X- _ O
event -X- _ O
- -X- _ O
entity -X- _ O
pair -X- _ O
as -X- _ O
a -X- _ O
different -X- _ O
instance -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
event -X- _ O
argument -X- _ O
extraction -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wadden -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
realistic -X- _ O
setting -X- _ O
. -X- _ O
5.2 -X- _ O
Evaluation -X- _ O
Metric -X- _ O
We -X- _ O
follow -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
consider -X- _ O
the -X- _ O
argument -X- _ B-MetricName
classiﬁcation -X- _ I-MetricName
F1 -X- _ I-MetricName
score -X- _ I-MetricName
to -X- _ O
measure -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
. -X- _ O
An -X- _ O
argument -X- _ O
- -X- _ O
role -X- _ O
pair -X- _ O
is -X- _ O
counted -X- _ O
as -X- _ O
correct -X- _ O
if -X- _ O
both -X- _ O
the -X- _ O
argument -X- _ O
offsets -X- _ O
and -X- _ O
the -X- _ O
role -X- _ O
type -X- _ O
match -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
arguments -X- _ O
a -X- _ O
, -X- _ O
ground -X- _ O
truth -X- _ O
roles -X- _ O
r -X- _ O
, -X- _ O
predicted -X- _ O
arguments -X- _ O
~a -X- _ O
, -X- _ O
and -X- _ O
predicted -X- _ O
roles -X- _ O
~r -X- _ O
, -X- _ O
the -X- _ O
argument -X- _ B-MetricName
classiﬁcation -X- _ I-MetricName
F1 -X- _ I-MetricName
score -X- _ O
is -X- _ O
deﬁned -X- _ O
as -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
between -X- _ O
the -X- _ O
set -X- _ O
f -X- _ O
( -X- _ O
a -X- _ O
; -X- _ O
r -X- _ O
) -X- _ O
gand -X- _ O
the -X- _ O
setf -X- _ O
( -X- _ O
~a -X- _ O
; -X- _ O
~r -X- _ O
) -X- _ O
g -X- _ O
. -X- _ O
For -X- _ O
every -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
three -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
results -X- _ O
. -X- _ O
5.3 -X- _ O
Compared -X- _ O
Models -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
following -X- _ O
models -X- _ O
and -X- _ O
their -X- _ O
implementation -X- _ O
details -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
•OneIE -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
for -X- _ O
monolingual -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
is -X- _ O
a -X- _ O
classiﬁcationbased -X- _ O
model -X- _ O
trained -X- _ O
with -X- _ O
multitasking -X- _ O
, -X- _ O
including -X- _ O
entity -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
, -X- _ O
and -X- _ O
event -X- _ B-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
We -X- _ O
simply -X- _ O
replace -X- _ O
its -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
embedding -X- _ O
with -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
ﬁt -X- _ O
the -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
setting -X- _ I-TaskName
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
task -X- _ I-TaskName
learning -X- _ I-TaskName
makes -X- _ O
OneIE -X- _ O
require -X- _ O
additional -X- _ O
annotations -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
named -X- _ O
entity -X- _ O
annotations -X- _ O
and -X- _ O
relation -X- _ O
annotations.•CL -X- _ O
- -X- _ O
GCN -X- _ O
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
classiﬁcation -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
for -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
event -X- _ I-TaskName
argument -X- _ I-TaskName
role -X- _ I-TaskName
labeling -X- _ I-TaskName
( -X- _ O
EARL -X- _ B-TaskName
) -X- _ O
. -X- _ O
It -X- _ O
considers -X- _ O
dependency -X- _ O
parsing -X- _ O
annotations -X- _ O
to -X- _ O
bridge -X- _ O
different -X- _ O
languages -X- _ O
and -X- _ O
use -X- _ O
GCN -X- _ B-MethodName
layers -X- _ O
( -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
parsing -X- _ O
information -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
implementation -X- _ O
of -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
add -X- _ O
two -X- _ O
GCN -X- _ B-MethodName
layers -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
. -X- _ O
Since -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
focuses -X- _ O
on -X- _ O
EARL -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
which -X- _ O
assume -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
entities -X- _ O
are -X- _ O
available -X- _ O
during -X- _ O
testing -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
one -X- _ O
name -X- _ O
entity -X- _ O
recognition -X- _ O
module -X- _ O
jointly -X- _ O
trained -X- _ O
with -X- _ O
CL -X- _ O
- -X- _ O
GCN -X- _ O
. -X- _ O
•GATE -X- _ O
( -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
model -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
EARL -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
classiﬁcation -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
which -X- _ O
considers -X- _ O
dependency -X- _ O
parsing -X- _ O
annotations -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
Unlike -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
, -X- _ O
it -X- _ O
uses -X- _ O
a -X- _ O
Transformer -X- _ B-MethodName
layer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
modiﬁed -X- _ O
attention -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
parsing -X- _ O
information -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
and -X- _ O
add -X- _ O
two -X- _ O
GATE -X- _ B-MethodName
layers -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
, -X- _ O
we -X- _ O
add -X- _ O
one -X- _ O
name -X- _ O
entity -X- _ O
recognition -X- _ O
module -X- _ O
jointly -X- _ O
trained -X- _ O
with -X- _ O
GATE -X- _ B-MethodName
. -X- _ O
•TANL -X- _ B-MethodName
( -X- _ O
Paolini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
generationbased -X- _ O
model -X- _ O
for -X- _ O
monolingual -X- _ B-TaskName
EAE -X- _ I-TaskName
. -X- _ O
Their -X- _ O
predicted -X- _ O
target -X- _ O
is -X- _ O
a -X- _ O
sentence -X- _ O
that -X- _ O
embeds -X- _ O
labels -X- _ O
into -X- _ O
the -X- _ O
input -X- _ O
passage -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
[ -X- _ O
Two -X- _ O
soldiers|target -X- _ O
] -X- _ O
were -X- _ O
attacked -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
“ -X- _ O
Two -X- _ O
soldiers -X- _ O
” -X- _ O
is -X- _ O
a -X- _ O
“ -X- _ O
target -X- _ O
” -X- _ O
argument -X- _ O
. -X- _ O
To -X- _ O
adapt -X- _ O
TANL -X- _ O
to -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
EAE -X- _ B-TaskName
, -X- _ O
we -X- _ O
change -X- _ O
its -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
model -X- _ O
from -X- _ O
T5 -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
mT5 -X- _ O
- -X- _ O
base -X- _ O
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
•X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
is -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
three -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
: -X- _ O
mBART-50 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
, -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
5.4 -X- _ O
Results -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
Table -X- _ O
2 -X- _ O
list -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
ACE-2005 -X- _ B-DatasetName
and -X- _ O
ERE -X- _ B-DatasetName
, -X- _ O
respectively -X- _ O
, -X- _ O
with -X- _ O
all -X- _ O
combinations -X- _ O
of -X- _ O
source -X- _ O
languages -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
have -X- _ O
similar -X- _ O
numbers -X- _ O
of -X- _ O
parameters4637 -X- _ O
except -X- _ O
for -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
with -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
. -X- _ O
Comparison -X- _ O
to -X- _ O
prior -X- _ O
generative -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
ﬁrst -X- _ O
observe -X- _ O
that -X- _ O
TANL -X- _ B-MethodName
has -X- _ O
poor -X- _ O
performance -X- _ O
when -X- _ O
transferring -X- _ O
to -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
its -X- _ O
language -X- _ O
- -X- _ O
dependent -X- _ O
template -X- _ O
makes -X- _ O
TANL -X- _ B-MethodName
easily -X- _ O
generate -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
outputs -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
case -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
model -X- _ O
rarely -X- _ O
seen -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
considers -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
and -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
for -X- _ O
zeroshot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
Comparison -X- _ O
to -X- _ O
classiﬁcation -X- _ O
models -X- _ O
. -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
with -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
outperforms -X- _ O
OneIE -X- _ B-MethodName
, -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
, -X- _ O
and -X- _ O
GATE -X- _ B-MethodName
on -X- _ O
almost -X- _ O
all -X- _ O
the -X- _ O
combinations -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
indeed -X- _ O
a -X- _ O
promising -X- _ O
approach -X- _ O
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
OneIE -X- _ O
, -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
, -X- _ O
and -X- _ O
GATE -X- _ B-MethodName
require -X- _ O
an -X- _ O
additional -X- _ O
pipeline -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
module -X- _ O
to -X- _ O
make -X- _ O
predictions -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
and -X- _ O
GATE -X- _ B-MethodName
need -X- _ O
additional -X- _ O
dependencyparsing -X- _ O
annotations -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
contrary -X- _ O
, -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
learned -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
no -X- _ O
additional -X- _ O
modules -X- _ O
or -X- _ O
annotations -X- _ O
are -X- _ O
needed -X- _ O
. -X- _ O
Comparison -X- _ O
to -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
using -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
is -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
using -X- _ O
mBART-50 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
for -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
, -X- _ O
although -X- _ O
they -X- _ O
have -X- _ O
a -X- _ O
similar -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
special -X- _ O
tokens -X- _ O
leads -X- _ O
to -X- _ O
this -X- _ O
difference -X- _ O
. -X- _ O
mBART-50 -X- _ B-MethodName
has -X- _ O
different -X- _ O
begin -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
sequence -X- _ O
( -X- _ O
BOS -X- _ O
) -X- _ O
tokens -X- _ O
for -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
During -X- _ O
generation -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
specify -X- _ O
which -X- _ O
BOS -X- _ O
token -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
use -X- _ O
as -X- _ O
the -X- _ O
start -X- _ O
token -X- _ O
. -X- _ O
We -X- _ O
guess -X- _ O
that -X- _ O
this -X- _ O
language -X- _ O
- -X- _ O
speciﬁc -X- _ O
BOS -X- _ O
token -X- _ O
makes -X- _ O
mBART-50 -X- _ B-MethodName
harder -X- _ O
to -X- _ O
transfer -X- _ O
the -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
. -X- _ O
Unlike -X- _ O
mBART-50 -X- _ B-MethodName
, -X- _ O
mT5 -X- _ B-MethodName
does -X- _ O
not -X- _ O
have -X- _ O
such -X- _ O
language -X- _ O
- -X- _ O
speciﬁc -X- _ O
BOS -X- _ O
tokens -X- _ O
. -X- _ O
During -X- _ O
generation -X- _ O
, -X- _ O
mT5 -X- _ B-MethodName
uses -X- _ O
the -X- _ O
padding -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
start -X- _ O
token -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
sequence -X- _ O
. -X- _ O
This -X- _ O
design -X- _ O
is -X- _ O
more -X- _ O
general -X- _ O
and -X- _ O
beneﬁt -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
Larger -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
are -X- _ O
better -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
can -X- _ O
be -X- _ O
further -X- _ O
boosted -X- _ O
with -X- _ O
a -X- _ O
larger -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
by -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
Table2 -X- _ O
, -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
with -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
scores -X- _ O
on -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
. -X- _ O
6 -X- _ O
Analysis -X- _ O
6.1 -X- _ O
Ablation -X- _ O
Studies -X- _ O
Copy -X- _ O
mechanism -X- _ O
. -X- _ O
We -X- _ O
ﬁrst -X- _ O
study -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
copy -X- _ O
mechanism -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
lists -X- _ O
the -X- _ O
performance -X- _ O
ofX -X- _ O
- -X- _ O
G -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
copy -X- _ O
mechanism -X- _ O
. -X- _ O
It -X- _ O
shows -X- _ O
improvements -X- _ O
in -X- _ O
adding -X- _ O
a -X- _ O
copy -X- _ O
mechanism4638 -X- _ O
when -X- _ O
using -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
and -X- _ O
mT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
interestingly -X- _ O
, -X- _ O
adding -X- _ O
a -X- _ O
copy -X- _ O
mechanism -X- _ O
is -X- _ O
not -X- _ O
effective -X- _ O
for -X- _ O
mBART-50 -X- _ B-MethodName
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
objective -X- _ O
of -X- _ O
mBART-50 -X- _ B-MethodName
is -X- _ O
denoising -X- _ B-TaskName
autoencoding -X- _ I-TaskName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
has -X- _ O
already -X- _ O
learned -X- _ O
to -X- _ O
copy -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
adding -X- _ O
a -X- _ O
copy -X- _ O
mechanism -X- _ O
is -X- _ O
less -X- _ O
useful -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
objective -X- _ O
of -X- _ O
mT5 -X- _ B-MethodName
is -X- _ O
to -X- _ O
only -X- _ O
generate -X- _ O
tokens -X- _ O
been -X- _ O
masked -X- _ O
out -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
lacking -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
copy -X- _ O
input -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
copy -X- _ O
mechanism -X- _ O
becomes -X- _ O
beneﬁcial -X- _ O
for -X- _ O
mT5 -X- _ B-MethodName
. -X- _ O
Including -X- _ O
event -X- _ O
type -X- _ O
in -X- _ O
prompts -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
mentioned -X- _ O
that -X- _ O
the -X- _ O
designed -X- _ O
prompt -X- _ O
for -X- _ O
XG -X- _ B-MethodName
consists -X- _ O
of -X- _ O
only -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
whether -X- _ O
explicitly -X- _ O
including -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
prompt -X- _ O
is -X- _ O
helpful -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
three -X- _ O
ways -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
information -X- _ O
: -X- _ O
•English -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
put -X- _ O
the -X- _ O
English -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
in -X- _ O
the -X- _ O
prompt -X- _ O
even -X- _ O
if -X- _ O
we -X- _ O
are -X- _ O
training -X- _ O
or -X- _ O
testing -X- _ O
on -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
languages -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
using -X- _ O
Attack -X- _ O
for -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
Attack -X- _ O
. -X- _ O
•Translated -X- _ O
tokens -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
event -X- _ O
type -X- _ O
, -X- _ O
we -X- _ O
prepare -X- _ O
the -X- _ O
translated -X- _ O
version -X- _ O
of -X- _ O
that -X- _ O
event -X- _ O
type -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
both -X- _ O
Attack -X- _ O
and攻击represents -X- _ O
the -X- _ O
Attack -X- _ O
event -X- _ O
type -X- _ O
. -X- _ O
During -X- _ O
training -X- _ O
or -X- _ O
testing -X- _ O
, -X- _ O
we -X- _ O
decide -X- _ O
the -X- _ O
used -X- _ O
token -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
passage -X- _ O
. -X- _ O
Since -X- _ O
all -X- _ O
the -X- _ O
event -X- _ O
types -X- _ O
are -X- _ O
written -X- _ O
in -X- _ O
English -X- _ O
in -X- _ O
ACE2005 -X- _ B-DatasetName
and -X- _ O
ERE -X- _ B-DatasetName
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
self -X- _ O
machine -X- _ O
translation -X- _ O
tool -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O
•Special -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
for -X- _ O
every -X- _ O
event -X- _ O
type -X- _ O
and -X- _ O
let -X- _ O
the -X- _ O
model -X- _ O
learn -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
tokens -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
< -X- _ O
-attack- -X- _ O
> -X- _ O
to -X- _ O
represent -X- _ O
theAttack -X- _ O
event -X- _ O
type -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
most -X- _ O
cases -X- _ O
, -X- _ O
including -X- _ O
event -X- _ O
type -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
prompt -X- _ O
decreases -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
One -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
one -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
language -X- _ O
can -X- _ O
be -X- _ O
mapped -X- _ O
to -X- _ O
several -X- _ O
words -X- _ O
in -X- _ O
another -X- _ O
language -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
Lifeevent -X- _ O
type -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
Marry -X- _ O
, -X- _ O
Divorce -X- _ O
, -X- _ O
Born -X- _ O
, -X- _ O
and -X- _ O
Diefour -X- _ O
subevent -X- _ O
types -X- _ O
. -X- _ O
In -X- _ O
English -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
just -X- _ O
one -X- _ O
word -X- _ O
Lifeto -X- _ O
cover -X- _ O
all -X- _ O
four -X- _ O
sub -X- _ O
- -X- _ O
event -X- _ O
types -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
In -X- _ O
Chinese -X- _ O
, -X- _ O
when -X- _ O
talking -X- _ O
about -X- _ O
Marry -X- _ O
andDivorce -X- _ O
, -X- _ O
Lifeshould -X- _ O
be -X- _ O
translated -X- _ O
to -X- _ O
“ -X- _ O
生活 -X- _ O
” -X- _ O
; -X- _ O
when -X- _ O
talking -X- _ O
about -X- _ O
Born -X- _ O
andDie -X- _ O
, -X- _ O
Life -X- _ O
should -X- _ O
be -X- _ O
translated -X- _ O
to -X- _ O
“ -X- _ O
生命 -X- _ O
” -X- _ O
. -X- _ O
This -X- _ O
mismatch -X- _ O
may -X- _ O
cause -X- _ O
the -X- _ O
performance -X- _ O
drop -X- _ O
when -X- _ O
considering -X- _ O
event -X- _ O
types -X- _ O
in -X- _ O
prompts -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
how -X- _ O
to -X- _ O
efﬁciently -X- _ O
use -X- _ O
event -X- _ O
type -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
setting -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Inﬂuence -X- _ O
of -X- _ O
role -X- _ O
order -X- _ O
in -X- _ O
templates -X- _ O
. -X- _ O
The -X- _ O
order -X- _ O
of -X- _ O
roles -X- _ O
in -X- _ O
the -X- _ O
designed -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
can -X- _ O
potentially -X- _ O
inﬂuence -X- _ O
performance -X- _ O
. -X- _ O
When -X- _ O
designing -X- _ O
the -X- _ O
templates -X- _ O
, -X- _ O
we -X- _ O
intentionally -X- _ O
make -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
roles -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
order -X- _ O
in -X- _ O
natural -X- _ O
sentences -X- _ O
. -X- _ O
To -X- _ O
study -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
orders -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
with -X- _ O
templates -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
orders -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
with -X- _ O
random -X- _ O
orders -X- _ O
still -X- _ O
achieve -X- _ O
good -X- _ O
performance -X- _ O
but -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
order -X- _ O
. -X- _ O
It -X- _ O
suggests -X- _ O
that -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
is -X- _ O
not -X- _ O
very -X- _ O
sensitive -X- _ O
to -X- _ O
different -X- _ O
templates -X- _ O
while -X- _ O
providing -X- _ O
appropriate -X- _ O
order -X- _ O
of -X- _ O
roles -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
small -X- _ O
improvement -X- _ O
. -X- _ O
Using -X- _ O
English -X- _ O
tokens -X- _ O
instead -X- _ O
of -X- _ O
special -X- _ O
tokens -X- _ O
for -X- _ O
roles -X- _ O
in -X- _ O
templates -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
mentioned -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates4639 -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
cross -X- _ B-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
transfer -X- _ I-TaskName
. -X- _ O
To -X- _ O
further -X- _ O
validate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
template -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
using -X- _ O
English -X- _ O
tokens -X- _ O
as -X- _ O
the -X- _ O
templates -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
format -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
template -X- _ O
for -X- _ O
Life -X- _ O
: -X- _ O
Die -X- _ O
events -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
instances -X- _ O
, -X- _ O
the -X- _ O
targeted -X- _ O
output -X- _ O
string -X- _ O
is -X- _ O
a -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
sequence -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
lists -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
applying -X- _ O
languageagnostic -X- _ O
templates -X- _ O
bring -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
2.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
scores -X- _ O
improvements -X- _ O
in -X- _ O
average -X- _ O
. -X- _ O
6.2 -X- _ O
Error -X- _ O
Analysis -X- _ O
We -X- _ O
perform -X- _ O
error -X- _ O
analysis -X- _ O
on -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
) -X- _ O
when -X- _ O
transferring -X- _ O
from -X- _ O
Arabic -X- _ O
to -X- _ O
English -X- _ O
and -X- _ O
transferring -X- _ O
from -X- _ O
Chinese -X- _ O
to -X- _ O
English -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
30 -X- _ O
failed -X- _ O
examples -X- _ O
and -X- _ O
present -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
various -X- _ O
error -X- _ O
types -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
Errors -X- _ O
on -X- _ O
both -X- _ O
monolingual -X- _ O
and -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
predicted -X- _ O
results -X- _ O
from -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
ar -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
with -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
en -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
from -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
zh -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
with -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
en -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
their -X- _ O
predictions -X- _ O
are -X- _ O
similar -X- _ O
and -X- _ O
both -X- _ O
of -X- _ O
themare -X- _ O
wrong -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
gold -X- _ O
output -X- _ O
, -X- _ O
we -X- _ O
classify -X- _ O
the -X- _ O
error -X- _ O
into -X- _ O
this -X- _ O
category -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
errors -X- _ O
in -X- _ O
this -X- _ O
category -X- _ O
, -X- _ O
the -X- _ O
potential -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
improve -X- _ O
monolingual -X- _ O
models -X- _ O
for -X- _ O
EAE -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Over -X- _ O
- -X- _ O
generating -X- _ O
. -X- _ O
Errors -X- _ O
in -X- _ O
this -X- _ O
category -X- _ O
happen -X- _ O
more -X- _ O
often -X- _ O
in -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
ar -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
likely -X- _ O
because -X- _ O
the -X- _ O
entities -X- _ O
in -X- _ O
Arabic -X- _ O
are -X- _ O
usually -X- _ O
much -X- _ O
longer -X- _ O
than -X- _ O
that -X- _ O
in -X- _ O
English -X- _ O
when -X- _ O
measuring -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
words -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
our -X- _ O
statistics -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
entity -X- _ O
span -X- _ O
length -X- _ O
is -X- _ O
2.85 -X- _ O
for -X- _ O
Arabic -X- _ O
and -X- _ O
is -X- _ O
2.00 -X- _ O
for -X- _ O
English -X- _ O
( -X- _ O
length -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
natural -X- _ O
for -X- _ O
our -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
ar -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
to -X- _ O
overly -X- _ O
generate -X- _ O
some -X- _ O
tokens -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
have -X- _ O
captured -X- _ O
the -X- _ O
correct -X- _ O
concept -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
“ -X- _ O
The -X- _ O
EU -X- _ O
foreign -X- _ O
ministers -X- _ O
” -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
is -X- _ O
“ -X- _ O
ministers -X- _ O
” -X- _ O
. -X- _ O
Label -X- _ O
disagreement -X- _ O
on -X- _ O
different -X- _ O
language -X- _ O
splits -X- _ O
. -X- _ O
The -X- _ O
annotations -X- _ O
for -X- _ O
the -X- _ O
ACE -X- _ B-DatasetName
dataset -X- _ O
in -X- _ O
different -X- _ O
language -X- _ O
split -X- _ O
contain -X- _ O
some -X- _ O
ambiguity -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
given -X- _ O
sentence -X- _ O
“ -X- _ O
He -X- _ O
now -X- _ O
also -X- _ O
advocates -X- _ O
letting -X- _ O
in -X- _ O
U.S. -X- _ O
troops -X- _ O
for -X- _ O
a -X- _ O
war -X- _ O
against -X- _ O
Iraq -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
fellow -X- _ O
Muslim -X- _ O
state -X- _ O
. -X- _ O
” -X- _ O
and -X- _ O
the -X- _ O
queried -X- _ O
trigger -X- _ O
“ -X- _ O
war -X- _ O
” -X- _ O
, -X- _ O
the -X- _ O
annotations -X- _ O
in -X- _ O
English -X- _ O
tends -X- _ O
to -X- _ O
label -X- _ O
Iraq -X- _ O
as -X- _ O
the -X- _ O
Place -X- _ O
where -X- _ O
the -X- _ O
event -X- _ O
happen -X- _ O
, -X- _ O
while -X- _ O
similar -X- _ O
situations -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
will -X- _ O
mark -X- _ O
Iraq -X- _ O
as -X- _ O
the -X- _ O
Target -X- _ O
for -X- _ O
the -X- _ O
war -X- _ O
. -X- _ O
Grammar -X- _ O
difference -X- _ O
between -X- _ O
languages -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
for -X- _ O
this -X- _ O
category -X- _ O
is -X- _ O
“ -X- _ O
... -X- _ O
Blackstone -X- _ O
Group -X- _ O
would -X- _ O
buy -X- _ O
Vivendi -X- _ O
’s -X- _ O
theme -X- _ O
park -X- _ O
division -X- _ O
, -X- _ O
including -X- _ O
Universal -X- _ O
Studios -X- _ O
Hollywood -X- _ O
... -X- _ O
” -X- _ O
and -X- _ O
the -X- _ O
queried -X- _ O
trigger -X- _ O
“ -X- _ O
buy -X- _ O
” -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
ar -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
predicts -X- _ O
Videndi -X- _ O
as -X- _ O
the -X- _ O
Artifact -X- _ O
been -X- _ O
sold -X- _ O
and -X- _ O
division -X- _ O
is -X- _ O
the -X- _ O
Seller -X- _ O
, -X- _ O
while -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
en -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
4640can -X- _ O
correctly -X- _ O
understand -X- _ O
that -X- _ O
Videndi -X- _ O
are -X- _ O
the -X- _ O
Seller -X- _ O
anddivision -X- _ O
is -X- _ O
the -X- _ O
Artifact -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
the -X- _ O
reason -X- _ O
being -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
grammar -X- _ O
in -X- _ O
Arabic -X- _ O
and -X- _ O
English -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
“ -X- _ O
Vivendi -X- _ O
’s -X- _ O
theme -X- _ O
park -X- _ O
division -X- _ O
” -X- _ O
in -X- _ O
Arabic -X- _ O
is -X- _ O
reversed -X- _ O
with -X- _ O
its -X- _ O
English -X- _ O
counterpart -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
“ -X- _ O
theme -X- _ O
park -X- _ O
division -X- _ O
” -X- _ O
will -X- _ O
be -X- _ O
written -X- _ O
before“Vivendi -X- _ O
” -X- _ O
in -X- _ O
Arabic -X- _ O
. -X- _ O
Such -X- _ O
difference -X- _ O
leads -X- _ O
to -X- _ O
errors -X- _ O
in -X- _ O
this -X- _ O
category -X- _ O
. -X- _ O
Generating -X- _ O
words -X- _ O
not -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
InX -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
zh -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
several -X- _ O
cases -X- _ O
that -X- _ O
generate -X- _ O
words -X- _ O
not -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
typical -X- _ O
situations -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
case -X- _ O
is -X- _ O
thatX -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
zh -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
mixes -X- _ O
up -X- _ O
singular -X- _ O
and -X- _ O
plural -X- _ O
nouns -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
generates -X- _ O
“ -X- _ O
studios -X- _ O
” -X- _ O
as -X- _ O
prediction -X- _ O
while -X- _ O
only -X- _ O
“ -X- _ O
studio -X- _ O
” -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
Chinese -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
morphological -X- _ O
inﬂection -X- _ O
for -X- _ O
plural -X- _ O
nouns -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
case -X- _ O
is -X- _ O
that -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
( -X- _ O
zh -X- _ O
) -X- _ O
en -X- _ O
) -X- _ O
will -X- _ O
generate -X- _ O
random -X- _ O
predictions -X- _ O
in -X- _ O
Chinese -X- _ O
. -X- _ O
Generating -X- _ O
correct -X- _ O
predictions -X- _ O
but -X- _ O
in -X- _ O
Chinese -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
special -X- _ O
case -X- _ O
of -X- _ O
“ -X- _ O
Generating -X- _ O
words -X- _ O
not -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
” -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
category -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
although -X- _ O
the -X- _ O
prediction -X- _ O
is -X- _ O
in -X- _ O
Chinese -X- _ O
( -X- _ O
hence -X- _ O
, -X- _ O
a -X- _ O
wrong -X- _ O
prediction -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
correct -X- _ O
if -X- _ O
we -X- _ O
translate -X- _ O
the -X- _ O
prediction -X- _ O
into -X- _ O
English -X- _ O
. -X- _ O
6.3 -X- _ O
Constrained -X- _ O
Decoding -X- _ O
Among -X- _ O
all -X- _ O
the -X- _ O
errors -X- _ O
, -X- _ O
we -X- _ O
highlight -X- _ O
two -X- _ O
speciﬁc -X- _ O
categories -X- _ O
— -X- _ O
“ -X- _ O
Generating -X- _ O
words -X- _ O
not -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
” -X- _ O
and“Generating -X- _ O
correct -X- _ O
predictions -X- _ O
but -X- _ O
in -X- _ O
Chinese -X- _ O
” -X- _ O
. -X- _ O
These -X- _ O
errors -X- _ O
can -X- _ O
be -X- _ O
resolved -X- _ O
by -X- _ O
applying -X- _ O
constrained -X- _ O
decoding -X- _ O
( -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
force -X- _ O
all -X- _ O
the -X- _ O
generated -X- _ O
tokens -X- _ O
to -X- _ O
appear -X- _ O
input -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
presents -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
with -X- _ O
constrained -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
adapting -X- _ O
such -X- _ O
constraints -X- _ O
indeed -X- _ O
helps -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transferability -X- _ O
, -X- _ O
yet -X- _ O
it -X- _ O
also -X- _ O
hurts -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
some -X- _ O
monolingual -X- _ O
cases -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
a -X- _ O
qualitative -X- _ O
inspection -X- _ O
of -X- _ O
the -X- _ O
predictions -X- _ O
. -X- _ O
The -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
constrained -X- _ O
decoding -X- _ O
algorithm -X- _ O
although -X- _ O
guarantees -X- _ O
all -X- _ O
generated -X- _ O
tokens -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
coercive -X- _ O
method -X- _ O
breaks -X- _ O
the -X- _ O
overall -X- _ O
sequence -X- _ O
distribution -X- _ O
that -X- _ O
learned -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
in -X- _ O
many -X- _ O
monolingual -X- _ O
examples -X- _ O
, -X- _ O
once -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
is -X- _ O
corrected -X- _ O
by -X- _ O
constrained -X- _ O
decoding -X- _ O
, -X- _ O
its -X- _ O
following -X- _ O
generated -X- _ O
sequence -X- _ O
changes -X- _ O
a -X- _ O
lot -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
original -X- _ O
predicted -X- _ O
sufﬁxed -X- _ O
sequence -X- _ O
using -X- _ O
beam -X- _ O
decoding -X- _ O
are -X- _ O
actually -X- _ O
correct -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
performance -X- _ O
decrease -X- _ O
. -X- _ O
7 -X- _ O
Conclusion -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
ﬁrst -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
for -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
event -X- _ I-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
discrepancy -X- _ O
between -X- _ O
languages -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
language -X- _ O
- -X- _ O
agnostic -X- _ O
templates -X- _ O
and -X- _ O
propose -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
, -X- _ O
which -X- _ O
well -X- _ O
capture -X- _ O
output -X- _ O
dependencies -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
without -X- _ O
additional -X- _ O
named -X- _ O
entity -X- _ O
extraction -X- _ O
modules -X- _ O
. -X- _ O
Our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
, -X- _ O
which -X- _ O
demonstrates -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
language -X- _ O
generation -X- _ O
framework -X- _ O
to -X- _ O
solve -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
structured -X- _ O
prediction -X- _ O
tasks -X- _ O
. -X- _ O
Acknowledgments -X- _ O
We -X- _ O
thank -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
feedback -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
the -X- _ O
UCLA -X- _ O
PLUSLab -X- _ O
and -X- _ O
UCLA -X- _ O
- -X- _ O
NLP -X- _ O
group -X- _ O
for -X- _ O
the -X- _ O
valuable -X- _ O
discussions -X- _ O
and -X- _ O
comments -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
thank -X- _ O
Steven -X- _ O
Fincke -X- _ O
, -X- _ O
Shantanu -X- _ O
Agarwal -X- _ O
, -X- _ O
and -X- _ O
Elizabeth -X- _ O
Boschee -X- _ O
for -X- _ O
their -X- _ O
help -X- _ O
on -X- _ O
data -X- _ O
preparation -X- _ O
in -X- _ O
Arabic -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
Intelligence -X- _ O
Advanced -X- _ O
Research -X- _ O
Projects -X- _ O
Activity -X- _ O
( -X- _ O
IARPA -X- _ O
) -X- _ O
, -X- _ O
via -X- _ O
Contract -X- _ O
No -X- _ O
. -X- _ O
2019 -X- _ O
- -X- _ O
19051600007 -X- _ O
, -X- _ O
and -X- _ O
research -X- _ O
awards -X- _ O
sponsored -X- _ O
by -X- _ O
CISCO -X- _ O
and -X- _ O
Google -X- _ O
. -X- _ O
Ethics -X- _ O
Considerations -X- _ O
Our -X- _ O
proposed -X- _ O
models -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
multilingual -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
that -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
text -X- _ O
corpus -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
known -X- _ O
that -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
could -X- _ O
capture -X- _ O
the -X- _ O
bias -X- _ O
reﬂecting -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
our -X- _ O
models -X- _ O
can -X- _ O
potentially -X- _ O
generate -X- _ O
offensive -X- _ O
or -X- _ O
biased -X- _ O
content -X- _ O
learned -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
carefully -X- _ O
examining -X- _ O
the -X- _ O
potential -X- _ O
bias -X- _ O
before -X- _ O
deploying -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
any -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
applications.4641References464246434644A -X- _ O
Dataset -X- _ O
Statistics -X- _ O
and -X- _ O
Data -X- _ O
Preprocessing -X- _ O
Table -X- _ O
8 -X- _ O
presents -X- _ O
the -X- _ O
detailed -X- _ O
statistics -X- _ O
for -X- _ O
the -X- _ O
ACE2005 -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
ERE -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
English -X- _ O
and -X- _ O
Chinese -X- _ O
splits -X- _ O
in -X- _ O
ACE-2005 -X- _ B-DatasetName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
setting -X- _ O
provided -X- _ O
by -X- _ O
Wadden -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
As -X- _ O
for -X- _ O
Arabic -X- _ O
part -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
setup -X- _ O
proposed -X- _ O
by -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Observing -X- _ O
that -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
breaks -X- _ O
made -X- _ O
from -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
being -X- _ O
extremely -X- _ O
long -X- _ O
for -X- _ O
pretrained -X- _ O
models -X- _ O
to -X- _ O
encode -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
additional -X- _ O
preprocessing -X- _ O
and -X- _ O
postprocessing -X- _ O
procedures -X- _ O
for -X- _ O
Arabic -X- _ O
data -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
Arabic -X- _ O
sentences -X- _ O
into -X- _ O
several -X- _ O
portions -X- _ O
that -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
portion -X- _ O
is -X- _ O
shorter -X- _ O
than -X- _ O
80 -X- _ O
tokens -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
map -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
predictions -X- _ O
of -X- _ O
the -X- _ O
split -X- _ O
sentences -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
during -X- _ O
postprocessing -X- _ O
. -X- _ O
B -X- _ O
Implementation -X- _ O
Details -X- _ O
We -X- _ O
describe -X- _ O
the -X- _ O
implementation -X- _ O
details -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
•OneIE -X- _ B-MethodName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
their -X- _ O
provided -X- _ O
codeto -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
provided -X- _ O
default -X- _ O
settings -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
worth -X- _ O
mention -X- _ O
that -X- _ O
for -X- _ O
the -X- _ O
Arabic -X- _ O
split -X- _ O
in -X- _ O
the -X- _ O
ACE-2005 -X- _ O
dataset -X- _ O
, -X- _ O
OneIE -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
only -X- _ O
entity -X- _ O
extraction -X- _ O
, -X- _ O
event -X- _ O
extraction -X- _ O
, -X- _ O
and -X- _ O
event -X- _ O
argument -X- _ O
extraction -X- _ O
since -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
relation -X- _ O
labels -X- _ O
in -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
’s -X- _ O
preprocessing -X- _ O
script -X- _ O
. -X- _ O
All -X- _ O
other -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
the -X- _ O
default -X- _ O
values -X- _ O
. -X- _ O
•CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
( -X- _ O
Subburathinam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
the -X- _ O
released -X- _ O
code -X- _ O
from -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
implement -X- _ O
the -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
method -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
baseline -X- _ O
framework -X- _ O
that -X- _ O
described -X- _ O
and -X- _ O
implemented -X- _ O
in -X- _ O
OneIE -X- _ B-MethodName
’s -X- _ O
code -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
remove -X- _ O
its -X- _ O
relation -X- _ O
extraction -X- _ O
module -X- _ O
and -X- _ O
add -X- _ O
two -X- _ O
layers -X- _ O
of -X- _ O
GCN -X- _ B-MethodName
on -X- _ O
top -X- _ O
of -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
. -X- _ O
The -X- _ O
pos -X- _ O
- -X- _ O
tag -X- _ O
and -X- _ O
dependency -X- _ O
parsing -X- _ O
annotations -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
applying -X- _ O
Stanza -X- _ O
( -X- _ O
Qi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
other -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
the -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
OneIE -X- _ B-MethodName
. -X- _ O
•GATE -X- _ B-MethodName
( -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
the -X- _ O
ofﬁcial -X- _ O
released -X- _ O
code -X- _ O
from -X- _ O
Ahmad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
implement -X- _ O
GATE -X- _ B-MethodName
. -X- _ O
Similar -X- _ O
to -X- _ O
CL -X- _ B-MethodName
- -X- _ I-MethodName
GCN -X- _ I-MethodName
, -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
baseline -X- _ O
framework -X- _ O
that -X- _ O
described -X- _ O
and -X- _ O
implemented -X- _ O
in -X- _ O
OneIE -X- _ O
’s -X- _ O
code -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
removeits -X- _ O
relation -X- _ O
extraction -X- _ O
module -X- _ O
and -X- _ O
add -X- _ O
two -X- _ O
layers -X- _ O
of -X- _ O
GATE -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
XLM -X- _ B-MethodName
- -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
, -X- _ O
mT5 -X- _ B-MethodName
, -X- _ O
or -X- _ O
mBART-50 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
. -X- _ O
The -X- _ O
pos -X- _ O
- -X- _ O
tag -X- _ O
and -X- _ O
dependency -X- _ O
parsing -X- _ O
annotations -X- _ O
are -X- _ O
also -X- _ O
obtained -X- _ O
by -X- _ O
applying -X- _ O
Stanza -X- _ O
( -X- _ O
Qi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
hyperparameter -X- _ O
of -X- _ O
in -X- _ O
GATE -X- _ B-MethodName
is -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
[ -X- _ O
2 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
4 -X- _ O
, -X- _ O
4 -X- _ O
, -X- _ O
1,1,1,1 -X- _ O
] -X- _ O
. -X- _ O
All -X- _ O
other -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
the -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
OneIE -X- _ B-MethodName
. -X- _ O
•TANL -X- _ B-MethodName
( -X- _ O
Paolini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
adapt -X- _ O
TANL -X- _ O
to -X- _ O
zero -X- _ B-TaskName
- -X- _ I-TaskName
shot -X- _ I-TaskName
cross -X- _ I-TaskName
- -X- _ I-TaskName
lingual -X- _ I-TaskName
EAE -X- _ I-TaskName
, -X- _ O
we -X- _ O
adapt -X- _ O
the -X- _ O
public -X- _ O
codeand -X- _ O
replace -X- _ O
its -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
based -X- _ O
model -X- _ O
T5 -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
other -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
their -X- _ O
default -X- _ O
values -X- _ O
. -X- _ O
•X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
is -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
three -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
generative -X- _ O
language -X- _ O
models -X- _ O
: -X- _ O
mBART-50 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
, -X- _ O
and -X- _ O
mT5 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Xue -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
10for -X- _ B-HyperparameterValue
mT5 -X- _ B-MethodName
, -X- _ O
and -X- _ O
10for -X- _ B-HyperparameterValue
mBART-50 -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
. -X- _ O
The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
8 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
is -X- _ O
60 -X- _ B-HyperparameterValue
. -X- _ O
C -X- _ O
Constrained -X- _ O
Decoding -X- _ O
Detailed -X- _ O
Results -X- _ O
Table -X- _ O
9 -X- _ O
shows -X- _ O
the -X- _ O
detailed -X- _ O
results -X- _ O
for -X- _ O
X -X- _ B-MethodName
- -X- _ I-MethodName
G -X- _ I-MethodName
using -X- _ O
constrained -X- _ O
decoding -X- _ O
algorithm -X- _ O
during -X- _ O
testing -X- _ O
time -X- _ O
. -X- _ O
We -X- _ O
directly -X- _ O
apply -X- _ O
constrained -X- _ O
decoding -X- _ O
algorithms -X- _ O
on -X- _ O
the -X- _ O
trained -X- _ O
models -X- _ O
we -X- _ O
have -X- _ O
in -X- _ O
Table -X- _ O
1.46454646 -X- _ O

This -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
focuses -X- _ SUMMARY
on -X- _ SUMMARY
document -X- _ SUMMARY
- -X- _ SUMMARY
level -X- _ SUMMARY
text -X- _ SUMMARY
simplification -X- _ SUMMARY
through -X- _ SUMMARY
sentence -X- _ SUMMARY
deletions -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
propose -X- _ SUMMARY
incorporating -X- _ SUMMARY
a -X- _ SUMMARY
news -X- _ SUMMARY
genre -X- _ SUMMARY
- -X- _ SUMMARY
specific -X- _ SUMMARY
functional -X- _ SUMMARY
discourse -X- _ SUMMARY
structure -X- _ SUMMARY
to -X- _ SUMMARY
predict -X- _ SUMMARY
sentence -X- _ SUMMARY
deletions -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
explore -X- _ SUMMARY
two -X- _ SUMMARY
methods -X- _ SUMMARY
of -X- _ SUMMARY
incorporating -X- _ SUMMARY
the -X- _ SUMMARY
structure -X- _ SUMMARY
: -X- _ SUMMARY
adding -X- _ SUMMARY
it -X- _ SUMMARY
as -X- _ SUMMARY
additional -X- _ SUMMARY
features -X- _ SUMMARY
or -X- _ SUMMARY
jointly -X- _ SUMMARY
predicting -X- _ SUMMARY
sentence -X- _ SUMMARY
deletions -X- _ SUMMARY
and -X- _ SUMMARY
discourse -X- _ SUMMARY
content -X- _ SUMMARY
types -X- _ SUMMARY
. -X- _ SUMMARY
Experimental -X- _ SUMMARY
results -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
Newsela -X- _ SUMMARY
corpus -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
both -X- _ SUMMARY
methods -X- _ SUMMARY
improve -X- _ SUMMARY
the -X- _ SUMMARY
recall -X- _ SUMMARY
and -X- _ SUMMARY
F1 -X- _ SUMMARY
- -X- _ SUMMARY
score -X- _ SUMMARY
of -X- _ SUMMARY
sentence -X- _ SUMMARY
deletion -X- _ SUMMARY
prediction -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
includes -X- _ SUMMARY
a -X- _ SUMMARY
baseline -X- _ SUMMARY
model -X- _ SUMMARY
using -X- _ SUMMARY
a -X- _ SUMMARY
document -X- _ SUMMARY
- -X- _ SUMMARY
level -X- _ SUMMARY
neural -X- _ SUMMARY
network -X- _ SUMMARY
and -X- _ SUMMARY
two -X- _ SUMMARY
methods -X- _ SUMMARY
for -X- _ SUMMARY
incorporating -X- _ SUMMARY
the -X- _ SUMMARY
functional -X- _ SUMMARY
structure -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
are -X- _ SUMMARY
recall -X- _ SUMMARY
and -X- _ SUMMARY
F1 -X- _ SUMMARY
- -X- _ SUMMARY
score -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
is -X- _ SUMMARY
evaluated -X- _ SUMMARY
on -X- _ SUMMARY
predicting -X- _ SUMMARY
sentence -X- _ SUMMARY
deletions -X- _ SUMMARY
in -X- _ SUMMARY
news -X- _ SUMMARY
documents -X- _ SUMMARY
using -X- _ SUMMARY
the -X- _ SUMMARY
Newsela -X- _ SUMMARY
corpus -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
baseline -X- _ SUMMARY
model -X- _ SUMMARY
outperforms -X- _ SUMMARY
a -X- _ SUMMARY
previous -X- _ SUMMARY
model -X- _ SUMMARY
proposed -X- _ SUMMARY
by -X- _ SUMMARY
Zhong -X- _ SUMMARY
et -X- _ SUMMARY
al -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
dataset -X- _ SUMMARY
used -X- _ SUMMARY
for -X- _ SUMMARY
evaluation -X- _ SUMMARY
is -X- _ SUMMARY
the -X- _ SUMMARY
Newsela -X- _ SUMMARY
corpus -X- _ SUMMARY
, -X- _ SUMMARY
which -X- _ SUMMARY
contains -X- _ SUMMARY
1492 -X- _ SUMMARY
English -X- _ SUMMARY
news -X- _ SUMMARY
articles -X- _ SUMMARY
and -X- _ SUMMARY
their -X- _ SUMMARY
simplified -X- _ SUMMARY
versions -X- _ SUMMARY
for -X- _ SUMMARY
different -X- _ SUMMARY
reading -X- _ SUMMARY
levels -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-short.28.txt -X- _ O
Bohan -X- _ O
Zhang -X- _ O
University -X- _ O
of -X- _ O
Michigan -X- _ O
zbohan -X- _ O
@ -X- _ O
umich.eduPrafulla -X- _ O
Kumar -X- _ O
Choubey -X- _ O
Salesforce -X- _ O
Research -X- _ O
pchoubey -X- _ O
@ -X- _ O
salesforce.comRuihong -X- _ O
Huang -X- _ O
Texas -X- _ O
A -X- _ O
& -X- _ O
M -X- _ O
University -X- _ O
huangrh -X- _ O
@ -X- _ O
tamu.edu -X- _ O
Abstract -X- _ O
Document -X- _ B-TaskName
- -X- _ I-TaskName
level -X- _ I-TaskName
text -X- _ I-TaskName
simplification -X- _ I-TaskName
often -X- _ O
deletes -X- _ O
some -X- _ O
sentences -X- _ O
besides -X- _ O
performing -X- _ O
lexical -X- _ O
, -X- _ O
grammatical -X- _ O
or -X- _ O
structural -X- _ O
simplification -X- _ O
to -X- _ O
reduce -X- _ O
text -X- _ O
complexity -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
sentence -X- _ B-TaskName
deletions -X- _ I-TaskName
for -X- _ I-TaskName
text -X- _ I-TaskName
simplification -X- _ I-TaskName
and -X- _ O
use -X- _ O
a -X- _ O
news -X- _ O
genre -X- _ O
- -X- _ O
specific -X- _ O
functional -X- _ O
discourse -X- _ O
structure -X- _ O
, -X- _ O
which -X- _ O
categorizes -X- _ O
sentences -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
contents -X- _ O
and -X- _ O
their -X- _ O
function -X- _ O
roles -X- _ O
in -X- _ O
telling -X- _ O
a -X- _ O
news -X- _ O
story -X- _ O
, -X- _ O
for -X- _ O
predicting -X- _ O
sentence -X- _ O
deletion -X- _ O
. -X- _ O
We -X- _ O
incorporate -X- _ O
sentence -X- _ O
categories -X- _ O
into -X- _ O
a -X- _ O
neural -X- _ O
net -X- _ O
model -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
for -X- _ O
predicting -X- _ B-TaskName
sentence -X- _ I-TaskName
deletions -X- _ I-TaskName
, -X- _ O
either -X- _ O
as -X- _ O
additional -X- _ O
features -X- _ O
or -X- _ O
by -X- _ O
jointly -X- _ O
predicting -X- _ O
sentence -X- _ O
deletions -X- _ O
and -X- _ O
sentence -X- _ O
categories -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
using -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
data -X- _ O
show -X- _ O
that -X- _ O
incorporating -X- _ O
the -X- _ O
functional -X- _ O
structure -X- _ O
improves -X- _ O
the -X- _ O
recall -X- _ O
of -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
by -X- _ O
6.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
10.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
respectively -X- _ O
using -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
, -X- _ O
and -X- _ O
improves -X- _ O
the -X- _ O
overall -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
by -X- _ O
3.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
4.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
respectively -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Text -X- _ B-TaskName
simplification -X- _ I-TaskName
aims -X- _ O
to -X- _ O
rewrite -X- _ O
complex -X- _ O
texts -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
them -X- _ O
easier -X- _ O
to -X- _ O
read -X- _ O
and -X- _ O
understand -X- _ O
. -X- _ O
This -X- _ O
task -X- _ O
can -X- _ O
benefit -X- _ O
vast -X- _ O
low -X- _ O
literacy -X- _ O
readers -X- _ O
, -X- _ O
including -X- _ O
children -X- _ O
, -X- _ O
language -X- _ O
learners -X- _ O
and -X- _ O
people -X- _ O
with -X- _ O
aphasia -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
recently -X- _ O
attracted -X- _ O
increasing -X- _ O
attention -X- _ O
from -X- _ O
the -X- _ O
research -X- _ O
community -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Martin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
most -X- _ O
previous -X- _ O
research -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
text -X- _ O
simplification -X- _ O
and -X- _ O
aim -X- _ O
to -X- _ O
simplify -X- _ O
one -X- _ O
sentence -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
few -X- _ O
discourse -X- _ O
- -X- _ O
level -X- _ O
phenomena -X- _ O
have -X- _ O
been -X- _ O
examined -X- _ O
or -X- _ O
understood -X- _ O
for -X- _ O
achieving -X- _ O
document -X- _ B-TaskName
- -X- _ I-TaskName
level -X- _ I-TaskName
text -X- _ I-TaskName
simplification -X- _ I-TaskName
. -X- _ O
Sentence -X- _ O
deletion -X- _ O
is -X- _ O
a -X- _ O
commonly -X- _ O
used -X- _ O
strategy -X- _ O
to -X- _ O
achieve -X- _ O
intense -X- _ O
simplification -X- _ O
( -X- _ O
Drndarevic -X- _ O
and -X- _ O
Saggion -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Woodsend -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
some -X- _ O
less -X- _ O
important -X- _ O
sentences -X- _ O
from -X- _ O
an -X- _ O
originalarticle -X- _ O
are -X- _ O
simply -X- _ O
deleted -X- _ O
and -X- _ O
ignored -X- _ O
for -X- _ O
simplification -X- _ O
. -X- _ O
While -X- _ O
professional -X- _ O
re -X- _ O
- -X- _ O
writers -X- _ O
may -X- _ O
consider -X- _ O
many -X- _ O
factors -X- _ O
and -X- _ O
use -X- _ O
several -X- _ O
measures -X- _ O
of -X- _ O
importance -X- _ O
to -X- _ O
decide -X- _ O
if -X- _ O
a -X- _ O
sentence -X- _ O
should -X- _ O
be -X- _ O
deleted -X- _ O
, -X- _ O
some -X- _ O
discourse -X- _ O
structures -X- _ O
provide -X- _ O
automated -X- _ O
measures -X- _ O
to -X- _ O
derive -X- _ O
importance -X- _ O
for -X- _ O
sentences -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
functional -X- _ O
discourse -X- _ O
structures -X- _ O
categorize -X- _ O
text -X- _ O
units -X- _ O
( -X- _ O
sentences -X- _ O
or -X- _ O
paragraphs -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
contents -X- _ O
and -X- _ O
their -X- _ O
function -X- _ O
roles -X- _ O
in -X- _ O
serving -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
text -X- _ O
- -X- _ O
genre -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
scientific -X- _ O
papers -X- _ O
( -X- _ O
Teufel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1999 -X- _ O
; -X- _ O
Liakata -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
and -X- _ O
news -X- _ O
articles -X- _ O
( -X- _ O
Yarlott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Choubey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
therefore -X- _ O
, -X- _ O
expected -X- _ O
to -X- _ O
directly -X- _ O
reveal -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
within -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
news -X- _ O
genrespecific -X- _ O
functional -X- _ O
structures -X- _ O
for -X- _ O
predicting -X- _ B-TaskName
sentence -X- _ I-TaskName
deletions -X- _ I-TaskName
in -X- _ O
news -X- _ O
documents -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
news -X- _ O
discourse -X- _ O
profiling -X- _ O
structure -X- _ O
, -X- _ O
which -X- _ O
categorizes -X- _ O
contents -X- _ O
of -X- _ O
news -X- _ O
articles -X- _ O
around -X- _ O
the -X- _ O
main -X- _ O
news -X- _ O
event -X- _ O
, -X- _ O
constructed -X- _ O
through -X- _ O
a -X- _ O
publicly -X- _ O
available -X- _ O
system -X- _ O
( -X- _ O
Choubey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
system -X- _ O
labels -X- _ O
each -X- _ O
sentence -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
eight -X- _ O
content -X- _ O
types -X- _ O
reflecting -X- _ O
common -X- _ O
discourse -X- _ O
roles -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
in -X- _ O
telling -X- _ O
a -X- _ O
news -X- _ O
story -X- _ O
, -X- _ O
including -X- _ O
two -X- _ O
content -X- _ O
types -X- _ O
for -X- _ O
sentences -X- _ O
describing -X- _ O
the -X- _ O
main -X- _ O
news -X- _ O
event -X- _ O
and -X- _ O
its -X- _ O
immediate -X- _ O
consequences -X- _ O
( -X- _ O
main -X- _ O
content -X- _ O
) -X- _ O
, -X- _ O
two -X- _ O
content -X- _ O
types -X- _ O
for -X- _ O
sentences -X- _ O
providing -X- _ O
contextinforming -X- _ O
contents -X- _ O
and -X- _ O
four -X- _ O
content -X- _ O
types -X- _ O
for -X- _ O
sentences -X- _ O
providing -X- _ O
further -X- _ O
supportive -X- _ O
information -X- _ O
in -X- _ O
a -X- _ O
news -X- _ O
article -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
experiments -X- _ O
using -X- _ O
the -X- _ O
Newsela -X- _ B-DatasetName
corpus -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
widely -X- _ O
used -X- _ O
dataset -X- _ O
for -X- _ O
text -X- _ B-TaskName
simplification -X- _ I-TaskName
research -X- _ O
that -X- _ O
contains -X- _ O
1492 -X- _ O
English -X- _ O
news -X- _ O
articles -X- _ O
and -X- _ O
four -X- _ O
simplified -X- _ O
versions -X- _ O
for -X- _ O
each -X- _ O
news -X- _ O
article -X- _ O
targeting -X- _ O
audience -X- _ O
of -X- _ O
different -X- _ O
reading -X- _ O
levels -X- _ O
( -X- _ O
from -X- _ O
elementary -X- _ O
to -X- _ O
high -X- _ O
school -X- _ O
students -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
achieve -X- _ O
maximal -X- _ O
simplification -X- _ O
, -X- _ O
we -X- _ O
predict -X- _ O
sentence -X- _ O
deletions -X- _ O
for -X- _ O
tar-255get -X- _ O
reading -X- _ O
level -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
elementary -X- _ O
school -X- _ O
students -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
build -X- _ O
a -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
neural -X- _ O
network -X- _ O
as -X- _ O
the -X- _ O
basic -X- _ O
model -X- _ O
for -X- _ O
predicting -X- _ B-TaskName
sentence -X- _ I-TaskName
deletions -X- _ I-TaskName
. -X- _ O
We -X- _ O
then -X- _ O
incorporate -X- _ O
content -X- _ O
types -X- _ O
of -X- _ O
sentences -X- _ O
into -X- _ O
the -X- _ O
prediction -X- _ O
system -X- _ O
using -X- _ O
two -X- _ O
methods -X- _ O
, -X- _ O
1 -X- _ O
) -X- _ O
by -X- _ O
using -X- _ O
content -X- _ O
type -X- _ O
labels -X- _ O
as -X- _ O
additional -X- _ O
features -X- _ O
to -X- _ O
enrich -X- _ O
sentence -X- _ O
representations -X- _ O
, -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
by -X- _ O
jointly -X- _ O
predicting -X- _ O
both -X- _ O
sentence -X- _ O
deletion -X- _ O
labels -X- _ O
and -X- _ O
discourse -X- _ O
content -X- _ O
type -X- _ O
labels -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
with -X- _ O
little -X- _ O
to -X- _ O
no -X- _ O
drop -X- _ O
on -X- _ O
precision -X- _ O
, -X- _ O
both -X- _ O
methods -X- _ O
for -X- _ O
incorporating -X- _ O
sentence -X- _ O
content -X- _ O
type -X- _ O
information -X- _ O
improve -X- _ O
the -X- _ O
recall -X- _ B-MetricName
( -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
task -X- _ O
by -X- _ O
6.5 -X- _ O
% -X- _ O
( -X- _ O
3.6 -X- _ O
% -X- _ O
) -X- _ O
and -X- _ O
10.7 -X- _ O
% -X- _ O
( -X- _ O
4.3 -X- _ O
% -X- _ O
) -X- _ O
respectively -X- _ O
. -X- _ O
Analysis -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
additional -X- _ O
deletions -X- _ O
correctly -X- _ O
recognized -X- _ O
by -X- _ O
our -X- _ O
system -X- _ O
are -X- _ O
all -X- _ O
sentences -X- _ O
providing -X- _ O
context -X- _ O
- -X- _ O
informing -X- _ O
or -X- _ O
supportive -X- _ O
contents -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
The -X- _ O
previous -X- _ O
research -X- _ O
on -X- _ O
text -X- _ B-TaskName
simplification -X- _ I-TaskName
has -X- _ O
focused -X- _ O
on -X- _ O
word -X- _ O
or -X- _ O
phrase -X- _ O
level -X- _ O
simplification -X- _ O
( -X- _ O
Yatskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Biran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Paetzold -X- _ O
and -X- _ O
Specia -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
sentencelevel -X- _ O
simplification -X- _ O
( -X- _ O
Wubben -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Nisioi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
few -X- _ O
research -X- _ O
has -X- _ O
been -X- _ O
conducted -X- _ O
for -X- _ O
document -X- _ B-TaskName
- -X- _ I-TaskName
level -X- _ I-TaskName
text -X- _ I-TaskName
simplification -X- _ I-TaskName
. -X- _ O
Sentence -X- _ O
deletion -X- _ O
, -X- _ O
as -X- _ O
an -X- _ O
interesting -X- _ O
phenomenon -X- _ O
for -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
text -X- _ O
simplification -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
studied -X- _ O
in -X- _ O
several -X- _ O
pilot -X- _ O
studies -X- _ O
. -X- _ O
( -X- _ O
Petersen -X- _ O
and -X- _ O
Ostendorf -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
conducted -X- _ O
a -X- _ O
corpus -X- _ O
analysis -X- _ O
and -X- _ O
showed -X- _ O
that -X- _ O
sentence -X- _ O
position -X- _ O
and -X- _ O
content -X- _ O
influence -X- _ O
sentence -X- _ O
deletion -X- _ O
or -X- _ O
retention -X- _ O
. -X- _ O
The -X- _ O
recent -X- _ O
pilot -X- _ O
research -X- _ O
for -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
considers -X- _ O
sentence -X- _ O
position -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
, -X- _ O
document -X- _ O
length -X- _ O
and -X- _ O
topic -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
exploits -X- _ O
rhetorical -X- _ O
discourse -X- _ O
structures -X- _ O
that -X- _ O
capture -X- _ O
text -X- _ O
coherence -X- _ O
in -X- _ O
general -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
derive -X- _ O
thesalience -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
in -X- _ O
a -X- _ O
discourse -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
while -X- _ O
sentence -X- _ O
position -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
document -X- _ O
characteristics -X- _ O
are -X- _ O
shown -X- _ O
useful -X- _ O
for -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
, -X- _ O
discourse -X- _ O
features -X- _ O
based -X- _ O
on -X- _ O
rhetorical -X- _ O
discourse -X- _ O
structures -X- _ O
are -X- _ O
shown -X- _ O
to -X- _ O
have -X- _ O
little -X- _ O
impact -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
general -X- _ O
rhetorical -X- _ O
discourse -X- _ O
structures -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
genre -X- _ O
specialties -X- _ O
, -X- _ O
the -X- _ O
genre -X- _ O
- -X- _ O
specific -X- _ O
functional -X- _ O
structure -X- _ O
we -X- _ O
examine -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
can -X- _ O
more -X- _ O
directly -X- _ O
reveal -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
within -X- _ O
a -X- _ O
document.3 -X- _ O
The -X- _ O
News -X- _ O
Discourse -X- _ O
Structure -X- _ O
and -X- _ O
Sentence -X- _ O
Types -X- _ O
News -X- _ O
discourse -X- _ O
profiling -X- _ O
( -X- _ O
Choubey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
categorizes -X- _ O
sentences -X- _ O
in -X- _ O
news -X- _ O
articles -X- _ O
into -X- _ O
eight -X- _ O
schematic -X- _ O
categories -X- _ O
that -X- _ O
describe -X- _ O
the -X- _ O
common -X- _ O
discourse -X- _ O
roles -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
telling -X- _ O
a -X- _ O
news -X- _ O
story -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
schemata -X- _ O
proposed -X- _ O
by -X- _ O
Van -X- _ O
Dijk -X- _ O
( -X- _ O
Teun -X- _ O
A -X- _ O
, -X- _ O
1986 -X- _ O
; -X- _ O
Van -X- _ O
Dijk -X- _ O
, -X- _ O
1988a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
eight -X- _ O
sentence -X- _ O
categories -X- _ O
fall -X- _ O
into -X- _ O
three -X- _ O
groups -X- _ O
. -X- _ O
Main -X- _ O
Contents -X- _ O
: -X- _ O
are -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
information -X- _ O
of -X- _ O
news -X- _ O
articles -X- _ O
, -X- _ O
including -X- _ O
sentences -X- _ O
that -X- _ O
introduce -X- _ O
the -X- _ O
main -X- _ O
event -X- _ O
as -X- _ O
the -X- _ O
major -X- _ O
subjects -X- _ O
of -X- _ O
a -X- _ O
news -X- _ O
article -X- _ O
( -X- _ O
Main -X- _ O
Event -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
sentences -X- _ O
that -X- _ O
describe -X- _ O
consequence -X- _ O
events -X- _ O
immediately -X- _ O
triggered -X- _ O
by -X- _ O
the -X- _ O
main -X- _ O
event -X- _ O
( -X- _ O
Consequence -X- _ O
) -X- _ O
. -X- _ O
Context -X- _ O
Informing -X- _ O
Contents -X- _ O
: -X- _ O
provide -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
actual -X- _ O
situation -X- _ O
in -X- _ O
which -X- _ O
main -X- _ O
event -X- _ O
occurred -X- _ O
, -X- _ O
including -X- _ O
sentences -X- _ O
that -X- _ O
describe -X- _ O
the -X- _ O
recent -X- _ O
events -X- _ O
that -X- _ O
act -X- _ O
as -X- _ O
possible -X- _ O
causes -X- _ O
or -X- _ O
preconditions -X- _ O
for -X- _ O
the -X- _ O
main -X- _ O
event -X- _ O
( -X- _ O
Previous -X- _ O
Events -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
sentences -X- _ O
that -X- _ O
describe -X- _ O
ongoing -X- _ O
situation -X- _ O
and -X- _ O
other -X- _ O
context -X- _ O
informing -X- _ O
contents -X- _ O
( -X- _ O
Current -X- _ O
Context -X- _ O
) -X- _ O
. -X- _ O
Additional -X- _ O
Supportive -X- _ O
Contents -X- _ O
: -X- _ O
contain -X- _ O
the -X- _ O
least -X- _ O
relevant -X- _ O
information -X- _ O
, -X- _ O
including -X- _ O
sentences -X- _ O
that -X- _ O
describe -X- _ O
past -X- _ O
events -X- _ O
that -X- _ O
precede -X- _ O
the -X- _ O
main -X- _ O
events -X- _ O
in -X- _ O
months -X- _ O
and -X- _ O
years -X- _ O
( -X- _ O
Historical -X- _ O
Event -X- _ O
) -X- _ O
, -X- _ O
sentences -X- _ O
that -X- _ O
describe -X- _ O
unverifiable -X- _ O
situations -X- _ O
, -X- _ O
fictional -X- _ O
or -X- _ O
personal -X- _ O
account -X- _ O
of -X- _ O
incidents -X- _ O
of -X- _ O
an -X- _ O
unknown -X- _ O
person -X- _ O
( -X- _ O
Anecdotal -X- _ O
Event -X- _ O
) -X- _ O
, -X- _ O
opinionated -X- _ O
contents -X- _ O
that -X- _ O
describe -X- _ O
reactions -X- _ O
from -X- _ O
immediate -X- _ O
participants -X- _ O
, -X- _ O
experts -X- _ O
, -X- _ O
known -X- _ O
personalities -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
journalist -X- _ O
or -X- _ O
news -X- _ O
source -X- _ O
( -X- _ O
Evaluation -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
speculations -X- _ O
on -X- _ O
the -X- _ O
possible -X- _ O
consequences -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
or -X- _ O
contextual -X- _ O
events -X- _ O
( -X- _ O
Expectation -X- _ O
) -X- _ O
3.1 -X- _ O
Analysis -X- _ O
of -X- _ O
Deletions -X- _ O
w.r.t -X- _ O
Sentence -X- _ O
Types -X- _ O
We -X- _ O
conducted -X- _ O
an -X- _ O
analysis -X- _ O
on -X- _ O
deletion -X- _ O
rate -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
category -X- _ O
using -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
( -X- _ O
Section -X- _ O
5.1 -X- _ O
) -X- _ O
which -X- _ O
was -X- _ O
manually -X- _ O
annotated -X- _ O
with -X- _ O
sentence -X- _ O
deletion -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
discourse -X- _ O
content -X- _ O
type -X- _ O
labels -X- _ O
of -X- _ O
sentences -X- _ O
were -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
news -X- _ O
discourse -X- _ O
profiling -X- _ O
system -X- _ O
( -X- _ O
Choubey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
Main -X- _ O
Event -X- _ O
sentences -X- _ O
have -X- _ O
the -X- _ O
lowest -X- _ O
deletion -X- _ O
rate -X- _ O
of -X- _ O
14.7 -X- _ O
% -X- _ O
, -X- _ O
much -X- _ O
lower -X- _ O
than -X- _ O
other -X- _ O
types -X- _ O
of -X- _ O
sentences -X- _ O
. -X- _ O
Previous -X- _ O
Event -X- _ O
sentences -X- _ O
, -X- _ O
as -X- _ O
one -X- _ O
type -X- _ O
of -X- _ O
context -X- _ O
informing -X- _ O
contents -X- _ O
, -X- _ O
have -X- _ O
a -X- _ O
relatively -X- _ O
low -X- _ O
deletion -X- _ O
rate -X- _ O
as -X- _ O
well -X- _ O
to -X- _ O
provide -X- _ O
necessary -X- _ O
context -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
possible -X- _ O
causes -X- _ O
or -X- _ O
preconditions -X- _ O
, -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
main -X- _ O
news -X- _ O
events -X- _ O
. -X- _ O
While -X- _ O
additional -X- _ O
supportive -X- _ O
contents -X- _ O
overall -X- _ O
have -X- _ O
a -X- _ O
high -X- _ O
deletion -X- _ O
rate -X- _ O
, -X- _ O
Anecdotal256 -X- _ O
Event -X- _ O
sentences -X- _ O
have -X- _ O
a -X- _ O
low -X- _ O
deletion -X- _ O
rate -X- _ O
, -X- _ O
possibly -X- _ O
because -X- _ O
personal -X- _ O
account -X- _ O
of -X- _ O
incidents -X- _ O
present -X- _ O
especially -X- _ O
interesting -X- _ O
contents -X- _ O
for -X- _ O
elementary -X- _ O
students -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
group -X- _ O
of -X- _ O
our -X- _ O
chosen -X- _ O
simplification -X- _ O
level -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
document -X- _ O
where -X- _ O
both -X- _ O
deleted -X- _ O
sentences -X- _ O
( -X- _ O
colored -X- _ O
in -X- _ O
purple -X- _ O
) -X- _ O
are -X- _ O
of -X- _ O
one -X- _ O
additional -X- _ O
supportive -X- _ O
content -X- _ O
type -X- _ O
, -X- _ O
Historical -X- _ O
Event -X- _ O
. -X- _ O
4 -X- _ O
ModelsAs -X- _ O
a -X- _ O
baseline -X- _ O
model -X- _ O
, -X- _ O
( -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
built -X- _ O
a -X- _ O
document -X- _ B-MethodName
- -X- _ I-MethodName
level -X- _ I-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
model -X- _ O
to -X- _ O
learn -X- _ O
context -X- _ O
aware -X- _ O
sentence -X- _ O
representations -X- _ O
for -X- _ O
predicting -X- _ O
sentence -X- _ O
deletions -X- _ O
. -X- _ O
Similar -X- _ O
architectures -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
useful -X- _ O
for -X- _ O
several -X- _ O
other -X- _ O
discourselevel -X- _ O
tasks -X- _ O
( -X- _ O
Nallapati -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Choubey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
takes -X- _ O
a -X- _ O
document -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
has -X- _ O
two -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
BiLSTM -X- _ O
layers -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
stacked -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
between -X- _ O
them -X- _ O
, -X- _ O
to -X- _ O
sufficiently -X- _ O
exploit -X- _ O
document -X- _ O
wide -X- _ O
contexts -X- _ O
for -X- _ O
building -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
concatenate -X- _ O
its -X- _ O
sentence -X- _ O
representation -X- _ O
with -X- _ O
two -X- _ O
vectors -X- _ O
obtained -X- _ O
by -X- _ O
max -X- _ O
pooling -X- _ O
over -X- _ O
representations -X- _ O
of -X- _ O
its -X- _ O
surrounding -X- _ O
sentences -X- _ O
( -X- _ O
two -X- _ O
sentences -X- _ O
to -X- _ O
each -X- _ O
side -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
sentence -X- _ O
representation -X- _ O
R -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
better -X- _ O
aware -X- _ O
of -X- _ O
the -X- _ O
local -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
feed -X- _ O
forward -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
1024 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
2 -X- _ I-HyperparameterValue
units -X- _ B-HyperparameterName
to -X- _ O
predict -X- _ O
a -X- _ O
binary -X- _ O
label -X- _ O
( -X- _ O
deleted -X- _ O
or -X- _ O
not -X- _ O
) -X- _ O
for -X- _ O
each -X- _ O
sentencebased -X- _ O
on -X- _ O
its -X- _ O
final -X- _ O
sentence -X- _ O
representation -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
base -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
initial -X- _ O
sentence -X- _ O
representations -X- _ O
of -X- _ O
768 -X- _ O
dimensions -X- _ O
. -X- _ O
Both -X- _ O
BiLSTMs257 -X- _ O
have -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
two -X- _ O
methods -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
functional -X- _ O
structure -X- _ O
for -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
. -X- _ O
4.1 -X- _ O
Feature -X- _ O
Concatenation -X- _ O
For -X- _ O
each -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
feature -X- _ O
vector -X- _ O
F -X- _ O
with -X- _ O
eight -X- _ B-HyperparameterValue
dimensions -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
eight -X- _ O
discourse -X- _ O
content -X- _ O
types -X- _ O
, -X- _ O
and -X- _ O
values -X- _ O
in -X- _ O
the -X- _ O
vector -X- _ O
are -X- _ O
probabilities -X- _ O
of -X- _ O
content -X- _ O
types -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
as -X- _ O
output -X- _ O
by -X- _ O
the -X- _ O
news -X- _ O
discourse -X- _ O
profiling -X- _ O
system -X- _ O
. -X- _ O
We -X- _ O
concatenate -X- _ O
the -X- _ O
feature -X- _ O
vector -X- _ O
F -X- _ O
with -X- _ O
the -X- _ O
final -X- _ O
sentence -X- _ O
representation -X- _ O
Rand -X- _ O
feed -X- _ O
the -X- _ O
concatenated -X- _ O
vector -X- _ O
to -X- _ O
the -X- _ O
sentence -X- _ O
deletion -X- _ O
prediction -X- _ O
layer -X- _ O
. -X- _ O
4.2 -X- _ O
Joint -X- _ O
Learning -X- _ O
Instead -X- _ O
of -X- _ O
creating -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
learn -X- _ O
to -X- _ O
jointly -X- _ O
predict -X- _ O
both -X- _ O
sentence -X- _ O
deletion -X- _ O
labels -X- _ O
and -X- _ O
discourse -X- _ O
content -X- _ O
type -X- _ O
labels -X- _ O
( -X- _ O
system -X- _ O
predicted -X- _ O
) -X- _ O
using -X- _ O
shared -X- _ O
sentence -X- _ O
representations -X- _ O
( -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
new -X- _ O
prediction -X- _ O
layer -X- _ O
with -X- _ O
1024 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
9units -X- _ I-HyperparameterValue
to -X- _ O
predict -X- _ O
discourse -X- _ O
content -X- _ O
types -X- _ O
for -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
learn -X- _ O
to -X- _ O
jointly -X- _ O
predict -X- _ O
both -X- _ O
types -X- _ O
of -X- _ O
labels -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
aggregated -X- _ O
loss -X- _ O
of -X- _ O
two -X- _ O
tasks -X- _ O
: -X- _ O
L -X- _ O
= -X- _ O
L+γ∗L -X- _ O
, -X- _ O
where -X- _ O
Lis -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
sentence -X- _ O
deletion -X- _ O
prediction -X- _ O
task -X- _ O
and -X- _ O
L -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
squared -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
discourse -X- _ O
content -X- _ O
type -X- _ O
prediction -X- _ O
task.5 -X- _ O
Evaluation -X- _ O
5.1 -X- _ O
Dataset -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
using -X- _ O
the -X- _ O
Newsela -X- _ B-DatasetName
corpus -X- _ O
for -X- _ O
text -X- _ O
simplification -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
corpus -X- _ O
contains -X- _ O
1492 -X- _ O
English -X- _ O
news -X- _ O
articles -X- _ O
and -X- _ O
four -X- _ O
simplified -X- _ O
versions -X- _ O
for -X- _ O
each -X- _ O
article -X- _ O
targeting -X- _ O
students -X- _ O
ranging -X- _ O
from -X- _ O
grade -X- _ O
2 -X- _ O
to -X- _ O
grade -X- _ O
12 -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
predicting -X- _ O
sentence -X- _ O
deletions -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
relatively -X- _ O
aggressive -X- _ O
level -X- _ O
of -X- _ O
simplification -X- _ O
that -X- _ O
targets -X- _ O
elementary -X- _ O
school -X- _ O
students -X- _ O
( -X- _ O
grades -X- _ O
2 -X- _ O
to -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
Test -X- _ O
and -X- _ O
Development -X- _ O
Data -X- _ O
: -X- _ O
We -X- _ O
created -X- _ O
a -X- _ O
new -X- _ O
annotated -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
annotated -X- _ O
dataset -X- _ O
of -X- _ O
50 -X- _ O
documents -X- _ O
used -X- _ O
in -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
was -X- _ O
not -X- _ O
released -X- _ O
yet -X- _ O
when -X- _ O
we -X- _ O
started -X- _ O
to -X- _ O
work -X- _ O
on -X- _ O
this -X- _ O
project -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
and -X- _ O
the -X- _ O
method -X- _ O
to -X- _ O
obtain -X- _ O
our -X- _ O
annotated -X- _ O
dataset -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
on -X- _ O
github -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
crowd -X- _ O
- -X- _ O
sourcing -X- _ O
based -X- _ O
annotation -X- _ O
method -X- _ O
of -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
decomposes -X- _ O
the -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
sentence -X- _ O
alignment -X- _ O
task -X- _ O
to -X- _ O
a -X- _ O
paragraph -X- _ O
alignment -X- _ O
task -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
paragraphlevel -X- _ O
sentence -X- _ O
alignment -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
our -X- _ O
two -X- _ O
annotators -X- _ O
to -X- _ O
read -X- _ O
through -X- _ O
a -X- _ O
whole -X- _ O
news -X- _ O
article -X- _ O
and -X- _ O
its -X- _ O
simplified -X- _ O
article -X- _ O
before -X- _ O
annotating -X- _ O
alignment -X- _ O
sentence -X- _ O
by -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
thorough -X- _ O
annotations -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
an -X- _ O
original -X- _ O
article -X- _ O
, -X- _ O
we -X- _ O
instruct -X- _ O
our -X- _ O
annotators -X- _ O
to -X- _ O
align -X- _ O
it -X- _ O
with -X- _ O
all -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
simplified -X- _ O
article -X- _ O
that -X- _ O
contain -X- _ O
part -X- _ O
or -X- _ O
all -X- _ O
of -X- _ O
its -X- _ O
contents -X- _ O
( -X- _ O
or -X- _ O
paraphrases -X- _ O
) -X- _ O
, -X- _ O
one -X- _ O
sentence -X- _ O
in -X- _ O
an -X- _ O
original -X- _ O
article -X- _ O
will -X- _ O
be -X- _ O
labeled -X- _ O
as -X- _ O
“ -X- _ O
deleted -X- _ O
” -X- _ O
if -X- _ O
nosentence -X- _ O
in -X- _ O
its -X- _ O
simplified -X- _ O
article -X- _ O
is -X- _ O
aligned -X- _ O
with -X- _ O
this -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
annotated -X- _ O
95 -X- _ O
( -X- _ O
containing -X- _ O
4,334 -X- _ O
sentences -X- _ O
) -X- _ O
randomly -X- _ O
selected -X- _ O
news -X- _ O
articles -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
annotators -X- _ O
first -X- _ O
annotated -X- _ O
five -X- _ O
news -X- _ O
articles -X- _ O
( -X- _ O
228 -X- _ O
sentences -X- _ O
) -X- _ O
in -X- _ O
common -X- _ O
and -X- _ O
achieved -X- _ O
a -X- _ O
high -X- _ O
kappa -X- _ O
agreement -X- _ O
( -X- _ O
Artstein -X- _ O
and -X- _ O
Poesio -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
of -X- _ O
0.911 -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
them -X- _ O
annotated -X- _ O
45 -X- _ O
more -X- _ O
articles -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
selected -X- _ O
25 -X- _ O
annotated -X- _ O
articles -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
as -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
other -X- _ O
70 -X- _ O
articles -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
48 -X- _ O
% -X- _ O
and -X- _ O
38 -X- _ O
% -X- _ O
of -X- _ O
sentences -X- _ O
are -X- _ O
annotated -X- _ O
as -X- _ O
deleted -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
publish -X- _ O
our -X- _ O
annotations -X- _ O
. -X- _ O
Training -X- _ O
Data -X- _ O
: -X- _ O
We -X- _ O
create -X- _ O
noisy -X- _ O
supervision -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
systems -X- _ O
by -X- _ O
applying -X- _ O
an -X- _ O
automatic -X- _ O
sentence -X- _ O
alignment -X- _ O
tool -X- _ O
CATS -X- _ O
( -X- _ O
Štajner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
remaining -X- _ O
1397 -X- _ O
unlabeled -X- _ O
news -X- _ O
articles -X- _ O
and -X- _ O
quickly -X- _ O
obtained -X- _ O
alignments -X- _ O
between -X- _ O
these -X- _ O
news258 -X- _ O
articles -X- _ O
and -X- _ O
their -X- _ O
simplified -X- _ O
articles -X- _ O
. -X- _ O
82.11 -X- _ O
% -X- _ O
of -X- _ O
sentence -X- _ O
alignments -X- _ O
produced -X- _ O
by -X- _ O
CATS -X- _ O
are -X- _ O
correct -X- _ O
when -X- _ O
evaluated -X- _ O
on -X- _ O
our -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
5.2 -X- _ O
Experimental -X- _ O
Settings -X- _ O
For -X- _ O
regularization -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
dropout -X- _ B-HyperparameterName
of -X- _ O
0.5 -X- _ B-HyperparameterValue
on -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
both -X- _ O
BiLSTMs -X- _ O
and -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
Adam -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
3e-4 -X- _ B-HyperparameterValue
. -X- _ O
All -X- _ O
the -X- _ O
neural -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
15 -X- _ B-HyperparameterName
epochs -X- _ B-HyperparameterValue
and -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
epoch -X- _ O
yielding -X- _ O
the -X- _ O
best -X- _ O
validation -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
searched -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
γvalue -X- _ B-HyperparameterName
over -X- _ O
the -X- _ O
range -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
3 -X- _ O
] -X- _ O
with -X- _ O
a -X- _ O
step -X- _ O
size -X- _ O
of -X- _ O
0.5 -X- _ O
, -X- _ O
and -X- _ O
its -X- _ O
best -X- _ O
value -X- _ O
equals -X- _ O
to -X- _ O
1.5 -X- _ B-HyperparameterValue
. -X- _ O
5.3 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
baseline -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
news -X- _ O
discourse -X- _ O
profiling -X- _ O
structureaware -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
better -X- _ O
positioning -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
re -X- _ O
- -X- _ O
implemented -X- _ O
the -X- _ O
model -X- _ O
proposed -X- _ O
in -X- _ O
a -X- _ O
recent -X- _ O
work -X- _ O
by -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
feedforwardneural -X- _ B-MethodName
network -X- _ I-MethodName
( -X- _ I-MethodName
FNN -X- _ I-MethodName
) -X- _ I-MethodName
model -X- _ I-MethodName
with -X- _ I-MethodName
sparse -X- _ I-MethodName
features -X- _ I-MethodName
. -X- _ O
First -X- _ O
, -X- _ O
our -X- _ O
baseline -X- _ O
system -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
feature -X- _ B-MethodName
based -X- _ I-MethodName
FNN -X- _ I-MethodName
model -X- _ O
with -X- _ O
5.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
5.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
on -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
datasets -X- _ O
respectively -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
both -X- _ O
methods -X- _ O
for -X- _ O
incorporating -X- _ O
discourse -X- _ O
information -X- _ O
have -X- _ O
noticeably -X- _ O
improved -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
evaluate -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
from -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
similar -X- _ O
trends -X- _ O
were -X- _ O
observed -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
performance -X- _ O
gains -X- _ O
of -X- _ O
both -X- _ O
discourseaware -X- _ O
models -X- _ O
are -X- _ O
mainly -X- _ O
on -X- _ O
recall -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
additional -X- _ O
deleted -X- _ O
sentences -X- _ O
correctly -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
two -X- _ O
models -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
additional -X- _ O
deleted -X- _ O
sentences -X- _ O
are -X- _ O
either -X- _ O
context -X- _ O
informing -X- _ O
contents -X- _ O
or -X- _ O
additional -X- _ O
supportive -X- _ O
contents -X- _ O
, -X- _ O
but -X- _ O
none -X- _ O
is -X- _ O
main -X- _ O
content -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
corroborates -X- _ O
our -X- _ O
analysis -X- _ O
in -X- _ O
section -X- _ O
3.1 -X- _ O
. -X- _ O
6 -X- _ O
Conclusion -X- _ O
We -X- _ O
study -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
to -X- _ O
achieve -X- _ O
document -X- _ B-TaskName
- -X- _ I-TaskName
level -X- _ I-TaskName
text -X- _ I-TaskName
simplification -X- _ I-TaskName
. -X- _ O
We -X- _ O
have -X- _ O
showed -X- _ O
that -X- _ O
a -X- _ O
genre -X- _ O
- -X- _ O
specific -X- _ O
functional -X- _ O
discourse -X- _ O
structure -X- _ O
improves -X- _ O
the -X- _ O
prediction -X- _ O
performance -X- _ O
by -X- _ O
large -X- _ O
margins -X- _ O
, -X- _ O
when -X- _ O
incorporated -X- _ O
into -X- _ O
a -X- _ O
neural -X- _ O
net -X- _ O
model -X- _ O
either -X- _ O
as -X- _ O
new -X- _ O
features -X- _ O
or -X- _ O
for -X- _ O
joint -X- _ O
learning -X- _ O
. -X- _ O
For -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
study -X- _ O
other -X- _ O
useful -X- _ O
discourse -X- _ O
- -X- _ O
level -X- _ O
factors -X- _ O
for -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
, -X- _ O
we -X- _ O
will -X- _ O
also -X- _ O
investigate -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
to -X- _ O
benefit -X- _ O
both -X- _ O
sentence -X- _ B-TaskName
deletion -X- _ I-TaskName
prediction -X- _ I-TaskName
and -X- _ O
discourse -X- _ O
parsing -X- _ O
tasks -X- _ O
. -X- _ O
7 -X- _ O
Acknowledgements -X- _ O
We -X- _ O
gratefully -X- _ O
acknowledge -X- _ O
support -X- _ O
from -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
via -X- _ O
the -X- _ O
awards -X- _ O
IIS-1942918 -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
also -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
feedback.259References260261 -X- _ O

This -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
compares -X- _ SUMMARY
three -X- _ SUMMARY
transfer -X- _ SUMMARY
learning -X- _ SUMMARY
methods -X- _ SUMMARY
in -X- _ SUMMARY
natural -X- _ SUMMARY
language -X- _ SUMMARY
processing -X- _ SUMMARY
: -X- _ SUMMARY
training -X- _ SUMMARY
on -X- _ SUMMARY
an -X- _ SUMMARY
intermediate -X- _ SUMMARY
task -X- _ SUMMARY
before -X- _ SUMMARY
the -X- _ SUMMARY
target -X- _ SUMMARY
task -X- _ SUMMARY
( -X- _ SUMMARY
STILTs -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
using -X- _ SUMMARY
multi -X- _ SUMMARY
- -X- _ SUMMARY
task -X- _ SUMMARY
learning -X- _ SUMMARY
( -X- _ SUMMARY
MTL -X- _ SUMMARY
) -X- _ SUMMARY
to -X- _ SUMMARY
train -X- _ SUMMARY
on -X- _ SUMMARY
both -X- _ SUMMARY
tasks -X- _ SUMMARY
simultaneously -X- _ SUMMARY
( -X- _ SUMMARY
pairwise -X- _ SUMMARY
MTL -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
training -X- _ SUMMARY
on -X- _ SUMMARY
all -X- _ SUMMARY
available -X- _ SUMMARY
tasks -X- _ SUMMARY
together -X- _ SUMMARY
( -X- _ SUMMARY
MTL -X- _ SUMMARY
) -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
study -X- _ SUMMARY
focuses -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
GLUE -X- _ SUMMARY
dataset -X- _ SUMMARY
and -X- _ SUMMARY
finds -X- _ SUMMARY
that -X- _ SUMMARY
pairwise -X- _ SUMMARY
MTL -X- _ SUMMARY
performs -X- _ SUMMARY
better -X- _ SUMMARY
than -X- _ SUMMARY
STILTs -X- _ SUMMARY
when -X- _ SUMMARY
the -X- _ SUMMARY
target -X- _ SUMMARY
task -X- _ SUMMARY
has -X- _ SUMMARY
fewer -X- _ SUMMARY
instances -X- _ SUMMARY
than -X- _ SUMMARY
the -X- _ SUMMARY
supporting -X- _ SUMMARY
task -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
vice -X- _ SUMMARY
versa -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
size -X- _ SUMMARY
heuristic -X- _ SUMMARY
holds -X- _ SUMMARY
true -X- _ SUMMARY
in -X- _ SUMMARY
over -X- _ SUMMARY
92 -X- _ SUMMARY
% -X- _ SUMMARY
of -X- _ SUMMARY
applicable -X- _ SUMMARY
cases -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
results -X- _ SUMMARY
also -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
MTL -X- _ SUMMARY
is -X- _ SUMMARY
generally -X- _ SUMMARY
worse -X- _ SUMMARY
than -X- _ SUMMARY
the -X- _ SUMMARY
pairwise -X- _ SUMMARY
methods -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
concludes -X- _ SUMMARY
that -X- _ SUMMARY
this -X- _ SUMMARY
analysis -X- _ SUMMARY
can -X- _ SUMMARY
help -X- _ SUMMARY
researchers -X- _ SUMMARY
make -X- _ SUMMARY
better -X- _ SUMMARY
decisions -X- _ SUMMARY
for -X- _ SUMMARY
NLP -X- _ SUMMARY
tasks -X- _ SUMMARY
. -X- _ SUMMARY
2022.acl-short.30.txt -X- _ O
Orion -X- _ O
Weller -X- _ O
* -X- _ O
Johns -X- _ O
Hopkins -X- _ O
UniversityKevin -X- _ O
Seppi -X- _ O
Brigham -X- _ O
Young -X- _ O
UniversityMatt -X- _ O
Gardner -X- _ O
Microsoft -X- _ O
Semantic -X- _ O
Machines -X- _ O
Abstract -X- _ O
Transfer -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
TL -X- _ B-TaskName
) -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
has -X- _ O
seen -X- _ O
a -X- _ O
surge -X- _ O
of -X- _ O
interest -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
as -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
have -X- _ O
shown -X- _ O
an -X- _ O
impressive -X- _ O
ability -X- _ O
to -X- _ O
transfer -X- _ O
to -X- _ O
novel -X- _ O
tasks -X- _ O
. -X- _ O
Three -X- _ O
main -X- _ O
strategies -X- _ O
have -X- _ O
emerged -X- _ O
for -X- _ O
making -X- _ O
use -X- _ O
of -X- _ O
multiple -X- _ O
supervised -X- _ O
datasets -X- _ O
during -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
: -X- _ O
training -X- _ O
on -X- _ O
an -X- _ O
intermediate -X- _ O
task -X- _ O
before -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
, -X- _ O
using -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning -X- _ I-MethodName
( -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
to -X- _ O
train -X- _ O
jointly -X- _ O
on -X- _ O
a -X- _ O
supplementary -X- _ O
task -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
) -X- _ O
, -X- _ O
or -X- _ O
simply -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
to -X- _ O
train -X- _ O
jointly -X- _ O
on -X- _ O
all -X- _ O
available -X- _ O
datasets -X- _ O
( -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
all -X- _ O
three -X- _ O
TL -X- _ B-TaskName
methods -X- _ O
in -X- _ O
a -X- _ O
comprehensive -X- _ O
analysis -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
heuristic -X- _ O
for -X- _ O
when -X- _ O
to -X- _ O
use -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
techniques -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
: -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
has -X- _ O
fewer -X- _ O
instances -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
holds -X- _ O
true -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
92 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
applicable -X- _ O
cases -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
validate -X- _ O
this -X- _ O
hypothesis -X- _ O
with -X- _ O
experiments -X- _ O
varying -X- _ O
dataset -X- _ O
size -X- _ O
. -X- _ O
The -X- _ O
simplicity -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
this -X- _ O
heuristic -X- _ O
is -X- _ O
surprising -X- _ O
and -X- _ O
warrants -X- _ O
additional -X- _ O
exploration -X- _ O
by -X- _ O
the -X- _ O
TL -X- _ B-TaskName
community -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
MTLis -X- _ B-MethodName
worse -X- _ O
than -X- _ O
the -X- _ O
pairwise -X- _ O
methods -X- _ O
in -X- _ O
almost -X- _ O
every -X- _ O
case -X- _ O
. -X- _ O
We -X- _ O
hope -X- _ O
this -X- _ O
study -X- _ O
will -X- _ O
aid -X- _ O
others -X- _ O
as -X- _ O
they -X- _ O
choose -X- _ O
between -X- _ O
TL -X- _ B-TaskName
methods -X- _ O
for -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
The -X- _ O
standard -X- _ O
supervised -X- _ O
training -X- _ O
paradigm -X- _ O
in -X- _ O
NLP -X- _ O
research -X- _ O
is -X- _ O
to -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
some -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
additional -X- _ O
non -X- _ O
- -X- _ O
target -X- _ O
supervised -X- _ O
datasets -X- _ O
are -X- _ O
available -X- _ O
during -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
clear -X- _ O
how -X- _ O
to -X- _ O
best -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
data -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
, -X- _ O
a -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Althoughthere -X- _ O
are -X- _ O
an -X- _ O
exponential -X- _ O
number -X- _ O
of -X- _ O
ways -X- _ O
to -X- _ O
combine -X- _ O
or -X- _ O
alternate -X- _ O
between -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
supporting -X- _ O
tasks -X- _ O
, -X- _ O
three -X- _ O
predominant -X- _ O
methods -X- _ O
have -X- _ O
emerged -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
ﬁne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ I-MethodName
a -X- _ I-MethodName
supporting -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
then -X- _ I-MethodName
the -X- _ I-MethodName
target -X- _ I-MethodName
task -X- _ I-MethodName
consecutively -X- _ I-MethodName
, -X- _ O
often -X- _ O
called -X- _ O
STILTs -X- _ B-MethodName
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
ﬁne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ I-MethodName
a -X- _ I-MethodName
supporting -X- _ I-MethodName
task -X- _ I-MethodName
and -X- _ I-MethodName
the -X- _ I-MethodName
target -X- _ I-MethodName
task -X- _ I-MethodName
simultaneously -X- _ I-MethodName
( -X- _ O
here -X- _ O
called -X- _ O
pairwise -X- _ B-MethodName
multi -X- _ I-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning -X- _ I-MethodName
, -X- _ O
or -X- _ O
simply -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
ﬁne -X- _ B-MethodName
- -X- _ I-MethodName
tuning -X- _ I-MethodName
on -X- _ I-MethodName
all -X- _ I-MethodName
Navailable -X- _ I-MethodName
supporting -X- _ I-MethodName
tasks -X- _ I-MethodName
and -X- _ I-MethodName
the -X- _ I-MethodName
target -X- _ I-MethodName
tasks -X- _ I-MethodName
together -X- _ I-MethodName
( -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
N -X- _ O
> -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Application -X- _ O
papers -X- _ O
that -X- _ O
use -X- _ O
these -X- _ O
methods -X- _ O
generally -X- _ O
focus -X- _ O
on -X- _ O
only -X- _ O
one -X- _ O
method -X- _ O
( -X- _ O
Søgaard -X- _ O
and -X- _ O
Bingel -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Keskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Glavas -X- _ O
and -X- _ O
Vuli -X- _ O
´ -X- _ O
c -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Sileo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Weller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Chang -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
a -X- _ O
limited -X- _ O
amount -X- _ O
of -X- _ O
papers -X- _ O
consider -X- _ O
running -X- _ O
two -X- _ O
. -X- _ O
Those -X- _ O
that -X- _ O
do -X- _ O
examine -X- _ O
them -X- _ O
do -X- _ O
so -X- _ O
with -X- _ O
a -X- _ O
limited -X- _ O
number -X- _ O
of -X- _ O
conﬁgurations -X- _ O
: -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
examines -X- _ O
STILTS -X- _ B-MethodName
and -X- _ O
one -X- _ O
instance -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
Changpinyo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Schröder -X- _ O
and -X- _ O
Biemann -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
compare -X- _ O
MTL -X- _ B-MethodName
with -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
and -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
; -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
; -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
but -X- _ O
not -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
perform -X- _ O
comprehensive -X- _ O
experiments -X- _ O
using -X- _ O
all -X- _ O
three -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
9 -X- _ O
datasets -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
surprisingly -X- _ O
ﬁnd -X- _ O
that -X- _ O
a -X- _ O
simple -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
determine -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
92 -X- _ O
% -X- _ O
accuracy -X- _ O
which -X- _ O
method -X- _ O
to -X- _ O
use -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
target -X- _ O
and -X- _ O
supporting -X- _ O
task -X- _ O
: -X- _ O
when -X- _ O
the -X- _ O
target -X- _ O
dataset -X- _ O
is -X- _ O
larger -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
dataset -X- _ O
, -X- _ O
STILTS -X- _ B-MethodName
should -X- _ O
be -X- _ O
used -X- _ O
; -X- _ O
otherwise -X- _ O
, -X- _ O
MTL -X- _ B-MethodName
should -X- _ O
be -X- _ O
used -X- _ O
( -X- _ O
MTLis -X- _ B-MethodName
almost -X- _ O
universally -X- _ O
the -X- _ O
worst -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
conﬁrm -X- _ O
the -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
, -X- _ O
we -X- _ O
additionally -X- _ O
perform -X- _ O
a -X- _ O
targeted -X- _ O
experiment -X- _ O
varying -X- _ O
dataset -X- _ O
size -X- _ O
for -X- _ O
two -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
crossover -X- _ O
point -X- _ O
in -X- _ O
performance -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
when -X- _ O
the -X- _ O
dataset -X- _ O
sizes -X- _ O
are -X- _ O
equal -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
analysis -X- _ O
will -X- _ O
help -X- _ O
NLP -X- _ O
researchers -X- _ O
to -X- _ O
make -X- _ O
better -X- _ O
decisions -X- _ O
when -X- _ O
choosing272 -X- _ O
a -X- _ O
TL -X- _ B-TaskName
method -X- _ O
and -X- _ O
will -X- _ O
open -X- _ O
up -X- _ O
future -X- _ O
research -X- _ O
into -X- _ O
understanding -X- _ O
the -X- _ O
cause -X- _ O
of -X- _ O
this -X- _ O
heuristic -X- _ O
’s -X- _ O
success -X- _ O
. -X- _ O
2 -X- _ O
Experimental -X- _ O
Settings -X- _ O
Dataset -X- _ O
Suite -X- _ O
To -X- _ O
conduct -X- _ O
this -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
to -X- _ O
employ -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
, -X- _ O
following -X- _ O
and -X- _ O
comparing -X- _ O
to -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
transfer -X- _ B-TaskName
learning -X- _ I-TaskName
for -X- _ O
NLP -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
. -X- _ O
Training -X- _ O
Framework -X- _ O
We -X- _ O
use -X- _ O
Huggingface -X- _ O
’s -X- _ O
transformers -X- _ O
library -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
accessing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
base -X- _ O
training -X- _ O
framework -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
this -X- _ O
framework -X- _ O
to -X- _ O
combine -X- _ O
multiple -X- _ O
tasks -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
PyTorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
dataloader -X- _ O
for -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
training -X- _ O
. -X- _ O
Many -X- _ O
previous -X- _ O
techniques -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
for -X- _ O
how -X- _ O
to -X- _ O
best -X- _ O
perform -X- _ O
MTL -X- _ B-MethodName
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
recent -X- _ O
paper -X- _ O
by -X- _ O
Gottumukkala -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
compared -X- _ O
the -X- _ O
main -X- _ O
approaches -X- _ O
and -X- _ O
showed -X- _ O
that -X- _ O
a -X- _ O
new -X- _ O
dynamic -X- _ O
approach -X- _ O
provides -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
general -X- _ O
. -X- _ O
We -X- _ O
implement -X- _ O
all -X- _ O
methods -X- _ O
described -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
and -X- _ O
experimented -X- _ O
with -X- _ O
several -X- _ O
approaches -X- _ O
( -X- _ O
sampling -X- _ O
by -X- _ O
size -X- _ O
, -X- _ O
uniformity -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
initial -X- _ O
results -X- _ O
found -X- _ O
that -X- _ O
dynamic -X- _ O
sampling -X- _ O
was -X- _ O
indeed -X- _ O
the -X- _ O
most -X- _ O
effective -X- _ O
on -X- _ O
pairwise -X- _ O
tasks -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
our -X- _ O
MTL -X- _ B-MethodName
framework -X- _ O
uses -X- _ O
dynamic -X- _ O
sampling -X- _ O
with -X- _ O
heterogeneous -X- _ O
batch -X- _ O
schedules -X- _ O
. -X- _ O
Forconsistency -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
models -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
code -X- _ O
, -X- _ O
but -X- _ O
include -X- _ O
only -X- _ O
one -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
dataloader -X- _ O
instead -X- _ O
of -X- _ O
multiple -X- _ O
. -X- _ O
The -X- _ O
MTLsetup -X- _ B-MethodName
uses -X- _ O
the -X- _ O
same -X- _ O
MTL -X- _ B-MethodName
code -X- _ O
, -X- _ O
but -X- _ O
includes -X- _ O
all -X- _ O
9 -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
each -X- _ O
model -X- _ O
on -X- _ O
5 -X- _ O
different -X- _ O
seeds -X- _ O
to -X- _ O
control -X- _ O
for -X- _ O
randomness -X- _ O
( -X- _ O
Dodge -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
5 -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
seeds -X- _ O
on -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
then -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
those -X- _ O
models -X- _ O
to -X- _ O
train -X- _ O
with -X- _ O
5 -X- _ O
more -X- _ O
random -X- _ O
seeds -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
ﬁnal -X- _ O
reported -X- _ O
numbers -X- _ O
, -X- _ O
we -X- _ O
record -X- _ O
both -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
and -X- _ O
the -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
comparing -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
approach -X- _ O
to -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
approach -X- _ O
with -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
sample -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
985 -X- _ O
= -X- _ O
360 -X- _ O
different -X- _ O
MTL -X- _ B-MethodName
versions -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
5 -X- _ O
MTLmodels -X- _ B-MethodName
, -X- _ O
and -X- _ O
95 -X- _ O
+ -X- _ O
95 -X- _ O
= -X- _ O
90 -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
setting -X- _ O
. -X- _ O
Model -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
DistilRoBERTa -X- _ B-MethodName
model -X- _ O
( -X- _ O
pretrained -X- _ O
and -X- _ O
distributed -X- _ O
from -X- _ O
the -X- _ O
transformers -X- _ O
library -X- _ O
similarly -X- _ O
to -X- _ O
the -X- _ O
DistilBERT -X- _ O
model -X- _ O
in -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
strong -X- _ O
performance -X- _ O
and -X- _ O
efﬁciency -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
details -X- _ O
regarding -X- _ O
model -X- _ O
and -X- _ O
compute -X- _ O
parameters -X- _ O
, -X- _ O
see -X- _ O
Appendix -X- _ O
A. -X- _ O
Our -X- _ O
purpose -X- _ O
is -X- _ O
notto -X- _ O
train -X- _ O
the -X- _ O
next -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
task -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
absolute -X- _ O
scores -X- _ O
are -X- _ O
not -X- _ O
immediately -X- _ O
relevant -X- _ O
; -X- _ O
our -X- _ O
purpose -X- _ O
is -X- _ O
to -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
different -X- _ O
methods -X- _ O
score -X- _ O
relative -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
conducted -X- _ O
the -X- _ O
same -X- _ O
analysis -X- _ O
in -X- _ O
Fig-273 -X- _ O
ure -X- _ O
1 -X- _ O
for -X- _ O
BERT -X- _ O
and -X- _ O
found -X- _ O
the -X- _ O
same -X- _ O
conclusion -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
D -X- _ O
) -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
extend -X- _ O
to -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
transformers -X- _ O
. -X- _ O
3 -X- _ O
Results -X- _ O
We -X- _ O
provide -X- _ O
three -X- _ O
different -X- _ O
analyses -X- _ O
: -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
vs -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
experiments -X- _ O
varying -X- _ O
dataset -X- _ O
size -X- _ O
to -X- _ O
validate -X- _ O
our -X- _ O
ﬁndings -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
pairwise -X- _ O
approaches -X- _ O
vs -X- _ O
MTL -X- _ B-MethodName
. -X- _ O
MTL -X- _ B-MethodName
vs -X- _ O
STILTs -X- _ B-MethodName
We -X- _ O
ﬁrst -X- _ O
calculate -X- _ O
the -X- _ O
absolute -X- _ O
score -X- _ O
matrices -X- _ O
from -X- _ O
computing -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
on -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
, -X- _ O
then -X- _ O
subtract -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
average -X- _ O
score -X- _ O
matrix -X- _ O
from -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
one -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
this -X- _ O
shows -X- _ O
the -X- _ O
absolute -X- _ B-MetricName
score -X- _ I-MetricName
gain -X- _ I-MetricName
for -X- _ O
using -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
method -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
( -X- _ O
negative -X- _ O
scores -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
was -X- _ O
better -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
matrix -X- _ O
does -X- _ O
not -X- _ O
tell -X- _ O
us -X- _ O
whether -X- _ O
these -X- _ O
differences -X- _ O
are -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
; -X- _ O
for -X- _ O
this -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
sample -X- _ O
t -X- _ O
- -X- _ O
test -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
each -X- _ O
method -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
cell -X- _ O
. -X- _ O
Scores -X- _ O
that -X- _ O
are -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
are -X- _ O
color -X- _ O
coded -X- _ O
green -X- _ O
( -X- _ O
if -X- _ O
STILTs -X- _ B-MethodName
is -X- _ O
better -X- _ O
) -X- _ O
or -X- _ O
blue -X- _ O
( -X- _ O
if -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
) -X- _ O
, -X- _ O
whereas -X- _ O
they -X- _ O
are -X- _ O
coded -X- _ O
grey -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
difference -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
although -X- _ O
some -X- _ O
differences -X- _ O
are -X- _ O
large -X- _ O
( -X- _ O
e.g. -X- _ O
a -X- _ O
9 -X- _ B-MetricValue
point -X- _ I-MetricValue
difference -X- _ O
on -X- _ O
( -X- _ O
WNLI -X- _ B-DatasetName
, -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
) -X- _ O
) -X- _ O
the -X- _ O
variance -X- _ O
of -X- _ O
these -X- _ O
results -X- _ O
is -X- _ O
high -X- _ O
enough -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
and -X- _ O
MTL -X- _ B-MethodName
score -X- _ O
distributions -X- _ O
. -X- _ O
We -X- _ O
order -X- _ O
the -X- _ O
datasets -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
by -X- _ O
size -X- _ O
, -X- _ O
to -X- _ O
visually -X- _ O
illustrate -X- _ O
the -X- _ O
trend -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
green -X- _ O
cells -X- _ O
in -X- _ O
a -X- _ O
row -X- _ O
is -X- _ O
highly -X- _ O
correlated -X- _ O
with -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
represented -X- _ O
by -X- _ O
that -X- _ O
row -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
MNLI -X- _ B-DatasetName
is -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
every -X- _ O
cell -X- _ O
in -X- _ O
the -X- _ O
MNLI -X- _ B-DatasetName
row -X- _ O
is -X- _ O
green -X- _ O
. -X- _ O
QQP -X- _ B-DatasetName
is -X- _ O
the -X- _ O
2nd -X- _ O
largest -X- _ O
and -X- _ O
every -X- _ O
cell -X- _ O
in -X- _ O
its -X- _ O
row -X- _ O
is -X- _ O
also -X- _ O
green -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
( -X- _ O
QQP -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
. -X- _ O
The -X- _ O
smallest -X- _ O
dataset -X- _ O
, -X- _ O
WNLI -X- _ B-DatasetName
, -X- _ O
has -X- _ O
zero -X- _ O
green -X- _ O
cells -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
summarize -X- _ O
these -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
size -X- _ O
heuristic -X- _ O
: -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
has -X- _ O
fewer -X- _ O
training -X- _ O
instances -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
use -X- _ O
this -X- _ O
heuristic -X- _ O
to -X- _ O
predict -X- _ O
which -X- _ O
method -X- _ O
will -X- _ O
be -X- _ O
better -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
it -X- _ O
predicts -X- _ O
49 -X- _ B-MetricValue
/ -X- _ I-MetricValue
53 -X- _ I-MetricValue
signiﬁcant -X- _ O
cells -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
92.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ O
. -X- _ O
To -X- _ O
more -X- _ O
clearly -X- _ O
visualize -X- _ O
which -X- _ O
cells -X- _ O
it -X- _ O
fails -X- _ O
to -X- _ O
predict -X- _ O
accurately -X- _ O
, -X- _ O
those -X- _ O
four -X- _ O
cells -X- _ O
are -X- _ O
indicated -X- _ O
with -X- _ O
red -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
this -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
hold -X- _ O
on -X- _ O
the -X- _ O
cells -X- _ O
that -X- _ O
have -X- _ O
no -X- _ O
statistically -X- _ O
signiﬁca -X- _ O
nt -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
: -X- _ O
but -X- _ O
for -X- _ O
almost -X- _ O
every -X- _ O
signiﬁcant -X- _ O
cell -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
clear -X- _ O
answer -X- _ O
to -X- _ O
why -X- _ O
those -X- _ O
four -X- _ O
cells -X- _ O
are -X- _ O
misclassiﬁed -X- _ O
. -X- _ O
Three -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
misclassiﬁed -X- _ O
cells -X- _ O
come -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
MRPC -X- _ B-DatasetName
dataset -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
obvious -X- _ O
reason -X- _ O
why -X- _ O
it -X- _ O
fails -X- _ O
on -X- _ O
MRPC -X- _ B-DatasetName
. -X- _ O
We -X- _ O
recognize -X- _ O
that -X- _ O
this -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
is -X- _ O
not -X- _ O
an -X- _ O
absolute -X- _ O
law -X- _ O
, -X- _ O
but -X- _ O
merely -X- _ O
a -X- _ O
good -X- _ O
heuristic -X- _ O
that -X- _ O
does -X- _ O
so -X- _ O
with -X- _ O
high -X- _ O
accuracy -X- _ O
: -X- _ O
there -X- _ O
are -X- _ O
still -X- _ O
other -X- _ O
pieces -X- _ O
to -X- _ O
this -X- _ O
puzzle -X- _ O
that -X- _ O
this -X- _ O
work -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
dataset -X- _ O
similarity -X- _ O
. -X- _ O
Dataset -X- _ O
Size -X- _ O
Experiments -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
validate274 -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
further -X- _ O
we -X- _ O
conduct -X- _ O
controlled -X- _ O
experiments -X- _ O
that -X- _ O
alter -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
to -X- _ O
be -X- _ O
above -X- _ O
and -X- _ O
below -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
to -X- _ O
test -X- _ O
QNLI -X- _ B-DatasetName
primary -X- _ O
with -X- _ O
MNLI -X- _ B-DatasetName
supporting -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
should -X- _ O
be -X- _ O
closely -X- _ O
related -X- _ O
and -X- _ O
thus -X- _ O
have -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
disprove -X- _ O
this -X- _ O
heuristic -X- _ O
. -X- _ O
We -X- _ O
subsample -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
so -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
proportion -X- _ O
Kof -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
primary -X- _ O
task -X- _ O
( -X- _ O
whereK2f1=3 -X- _ O
; -X- _ O
1=2 -X- _ O
; -X- _ O
1 -X- _ O
; -X- _ O
2 -X- _ O
; -X- _ O
3 -X- _ O
g -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
whether -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
holds -X- _ O
while -X- _ O
explicitly -X- _ O
controlling -X- _ O
for -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
’s -X- _ O
size -X- _ O
. -X- _ O
Other -X- _ O
than -X- _ O
dataset -X- _ O
size -X- _ O
, -X- _ O
all -X- _ O
experimental -X- _ O
parameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
comparison -X- _ O
( -X- _ O
§ -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
test -X- _ O
whether -X- _ O
these -X- _ O
results -X- _ O
hold -X- _ O
if -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
primary -X- _ O
dataset -X- _ O
is -X- _ O
changed -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
perhaps -X- _ O
there -X- _ O
is -X- _ O
something -X- _ O
special -X- _ O
about -X- _ O
the -X- _ O
current -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
dataset -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
the -X- _ O
same -X- _ O
pair -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
QNLI -X- _ B-DatasetName
in -X- _ O
half -X- _ O
, -X- _ O
varying -X- _ O
MNLI -X- _ B-DatasetName
around -X- _ O
the -X- _ O
new -X- _ O
number -X- _ O
of -X- _ O
instances -X- _ O
in -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
training -X- _ O
set -X- _ O
as -X- _ O
above -X- _ O
( -X- _ O
e.g. -X- _ O
1 -X- _ O
/ -X- _ O
3rd -X- _ O
, -X- _ O
1 -X- _ O
/ -X- _ O
2 -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
experiments -X- _ O
are -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
as -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
supporting -X- _ O
dataset -X- _ O
increases -X- _ O
, -X- _ O
MTL -X- _ B-MethodName
becomes -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
when -X- _ O
both -X- _ O
datasets -X- _ O
are -X- _ O
equal -X- _ O
sizes -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
are -X- _ O
statistically -X- _ O
similar -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
from -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
( -X- _ O
Support -X- _ O
Task -X- _ O
Proportion -X- _ O
= -X- _ O
1.0 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
synthetic -X- _ O
experiments -X- _ O
corroborate -X- _ O
our -X- _ O
main -X- _ O
ﬁnding -X- _ O
; -X- _ O
the -X- _ O
size -X- _ O
heuristic -X- _ O
holds -X- _ O
even -X- _ O
on -X- _ O
controlled -X- _ O
instances -X- _ O
where -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
are -X- _ O
artiﬁcially -X- _ O
manipulated -X- _ O
. -X- _ O
Pairwise -X- _ O
TL -X- _ O
vs -X- _ O
MTL -X- _ B-MethodName
We -X- _ O
also -X- _ O
experiment -X- _ O
with -X- _ O
MTLon -X- _ B-MethodName
GLUE -X- _ B-DatasetName
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
implementation -X- _ O
details -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
pairwise -X- _ O
approach -X- _ O
consistently -X- _ O
outperforms -X- _ O
the -X- _ O
MTLmethod -X- _ B-MethodName
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
RTE -X- _ B-DatasetName
task -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
and -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
supporting -X- _ O
task -X- _ O
outperforms -X- _ O
MTLin -X- _ B-MethodName
every -X- _ O
case -X- _ O
( -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
although -X- _ O
MTLis -X- _ B-MethodName
conceptually -X- _ O
simple -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
best -X- _ O
choice -X- _ O
w.r.t -X- _ O
. -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
score -X- _ O
: -X- _ O
on -X- _ O
a -X- _ O
randomdataset -X- _ O
simply -X- _ O
using -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
will -X- _ O
likely -X- _ O
perform -X- _ O
better -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
on -X- _ O
the -X- _ O
average -X- _ O
supplementary -X- _ O
task -X- _ O
increases -X- _ O
the -X- _ O
score -X- _ O
by -X- _ O
5 -X- _ B-MetricValue
points -X- _ I-MetricValue
over -X- _ O
MTL -X- _ B-MethodName
( -X- _ O
78.3 -X- _ O
vs -X- _ O
73.3 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
Related -X- _ O
Work -X- _ O
A -X- _ O
large -X- _ O
body -X- _ O
of -X- _ O
recent -X- _ O
work -X- _ O
( -X- _ O
Søgaard -X- _ O
and -X- _ O
Bingel -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Vu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bettgenhäuser -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Poth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
exists -X- _ O
that -X- _ O
examines -X- _ O
when -X- _ O
these -X- _ O
transfer -X- _ O
learning -X- _ O
methods -X- _ O
are -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
simply -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
. -X- _ O
Oftentimes -X- _ O
, -X- _ O
these -X- _ O
explanations -X- _ O
involve -X- _ O
recognizing -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
although -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
called -X- _ O
for -X- _ O
them -X- _ O
to -X- _ O
be -X- _ O
reexamined -X- _ O
( -X- _ O
Chang -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
is -X- _ O
orthogonal -X- _ O
to -X- _ O
those -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
examine -X- _ O
when -X- _ O
you -X- _ O
should -X- _ O
choose -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
rather -X- _ O
than -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
case -X- _ O
( -X- _ O
in -X- _ O
fact -X- _ O
, -X- _ O
these -X- _ O
strategies -X- _ O
could -X- _ O
be -X- _ O
combined -X- _ O
to -X- _ O
predict -X- _ O
transfer -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
method -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
task -X- _ O
is -X- _ O
different -X- _ O
, -X- _ O
theoretical -X- _ O
explanations -X- _ O
for -X- _ O
how -X- _ O
these -X- _ O
methods -X- _ O
work -X- _ O
in -X- _ O
relation -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
will -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
explored -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Potential -X- _ O
theories -X- _ O
suggested -X- _ O
by -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
Appendix -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
left -X- _ O
to -X- _ O
guide -X- _ O
those -X- _ O
efforts -X- _ O
. -X- _ O
5 -X- _ O
Conclusion -X- _ O
We -X- _ O
examined -X- _ O
the -X- _ O
three -X- _ O
main -X- _ O
strategies -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
: -X- _ O
training -X- _ B-MethodName
on -X- _ I-MethodName
an -X- _ I-MethodName
intermediate -X- _ I-MethodName
supporting -X- _ I-MethodName
task -X- _ I-MethodName
to -X- _ I-MethodName
aid -X- _ I-MethodName
the -X- _ I-MethodName
target -X- _ I-MethodName
task -X- _ I-MethodName
( -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
, -X- _ O
training -X- _ B-MethodName
on -X- _ I-MethodName
the -X- _ I-MethodName
target -X- _ I-MethodName
and -X- _ I-MethodName
supporting -X- _ I-MethodName
task -X- _ I-MethodName
simultaneously -X- _ I-MethodName
( -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
, -X- _ O
or -X- _ O
training -X- _ B-MethodName
on -X- _ I-MethodName
multiple -X- _ I-MethodName
supporting -X- _ I-MethodName
tasks -X- _ I-MethodName
alongside -X- _ I-MethodName
the -X- _ I-MethodName
target -X- _ I-MethodName
task -X- _ I-MethodName
( -X- _ O
MTL -X- _ B-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
the -X- _ O
ﬁrst -X- _ O
comprehensive -X- _ O
comparison -X- _ O
between -X- _ O
these -X- _ O
three -X- _ O
methods -X- _ O
using -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
suite -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
rule -X- _ O
for -X- _ O
when -X- _ O
to -X- _ O
use -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
techniques -X- _ O
over -X- _ O
the -X- _ O
other -X- _ O
. -X- _ O
This -X- _ O
simple -X- _ O
heuristic -X- _ O
, -X- _ O
which -X- _ O
holds -X- _ O
true -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
92 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
applicable -X- _ O
cases -X- _ O
, -X- _ O
states -X- _ O
that -X- _ O
multi -X- _ B-MethodName
- -X- _ I-MethodName
task -X- _ I-MethodName
learning275is -X- _ I-MethodName
better -X- _ O
than -X- _ O
intermediate -X- _ O
ﬁne -X- _ O
tuning -X- _ O
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
vice -X- _ O
versa -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
showed -X- _ O
that -X- _ O
these -X- _ O
pairwise -X- _ B-MethodName
transfer -X- _ I-MethodName
learning -X- _ I-MethodName
techniques -X- _ O
outperform -X- _ O
the -X- _ O
MTLapproach -X- _ B-MethodName
in -X- _ O
almost -X- _ O
every -X- _ O
case -X- _ O
. -X- _ O
References276277 -X- _ O
A -X- _ O
Training -X- _ O
and -X- _ O
Compute -X- _ O
Details -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
hyperparameters -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
transformer -X- _ O
library -X- _ O
example -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
as -X- _ O
the -X- _ O
default -X- _ O
for -X- _ O
our -X- _ O
model -X- _ O
( -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
AdamW -X- _ O
optimizer -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
checkpointing -X- _ O
every -X- _ O
half -X- _ O
an -X- _ O
epoch -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
on -X- _ O
a -X- _ O
mix -X- _ O
of -X- _ O
approximately -X- _ O
10 -X- _ O
K80 -X- _ O
and -X- _ O
P100 -X- _ O
GPUs -X- _ O
for -X- _ O
approximately -X- _ O
two -X- _ O
weeks -X- _ O
for -X- _ O
the -X- _ O
main -X- _ O
experiment -X- _ O
, -X- _ O
using -X- _ O
another -X- _ O
week -X- _ O
of -X- _ O
compute -X- _ O
time -X- _ O
for -X- _ O
the -X- _ O
synthetic -X- _ O
experiments -X- _ O
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
CPUs -X- _ O
use -X- _ O
12 -X- _ O
- -X- _ O
core -X- _ O
Intel -X- _ O
Haswell -X- _ O
( -X- _ O
2.3 -X- _ O
GHz -X- _ O
) -X- _ O
processors -X- _ O
with -X- _ O
32 -X- _ O
GB -X- _ O
of -X- _ O
RAM -X- _ O
. -X- _ O
B -X- _ O
Pairwise -X- _ O
Approaches -X- _ O
vs -X- _ O
MTL -X- _ B-MethodName
Experimental -X- _ O
Setup -X- _ O
We -X- _ O
use -X- _ O
MTLwith -X- _ B-MethodName
three -X- _ O
different -X- _ O
sampling -X- _ O
methods -X- _ O
: -X- _ O
uniform -X- _ O
sampling -X- _ O
, -X- _ O
sampling -X- _ O
by -X- _ O
dataset -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
dynamic -X- _ O
sampling -X- _ O
. -X- _ O
To -X- _ O
illustrate -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
MTLand -X- _ B-MethodName
the -X- _ O
pairwise -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
across -X- _ O
all -X- _ O
supplementary -X- _ O
tasks -X- _ O
for -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
found -X- _ O
by -X- _ O
choosing -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
using -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
as -X- _ O
Ave -X- _ B-MethodName
. -X- _ I-MethodName
S.H. -X- _ I-MethodName
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
score -X- _ O
from -X- _ O
the -X- _ O
best -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
best -X- _ O
pairwise -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
the -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Results -X- _ O
Although -X- _ O
dynamic -X- _ O
sampling -X- _ O
was -X- _ O
more -X- _ O
effective -X- _ O
for -X- _ O
the -X- _ O
pairwise -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
dynamic -X- _ O
sampling -X- _ O
was -X- _ O
worse -X- _ O
than -X- _ O
sampling -X- _ O
by -X- _ O
size -X- _ O
when -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
on -X- _ O
all -X- _ O
nine -X- _ O
datasets -X- _ O
( -X- _ O
top -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
.However -X- _ O
, -X- _ O
when -X- _ O
the -X- _ O
MTLmethod -X- _ B-MethodName
is -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
pairwise -X- _ O
methods -X- _ O
, -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
( -X- _ O
bottom -X- _ O
half -X- _ O
of -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
, -X- _ O
which -X- _ O
uses -X- _ O
the -X- _ O
best -X- _ O
supplementary -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
outperforms -X- _ O
all -X- _ O
methods -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
although -X- _ O
MTLis -X- _ B-MethodName
conceptually -X- _ O
simple -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
best -X- _ O
choice -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
target -X- _ O
task -X- _ O
accuracy -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
could -X- _ O
predict -X- _ O
which -X- _ O
supplementary -X- _ O
task -X- _ O
would -X- _ O
be -X- _ O
most -X- _ O
effective -X- _ O
( -X- _ O
Pairwise -X- _ B-MethodName
Oracle -X- _ I-MethodName
, -X- _ O
c.f -X- _ O
. -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
Vu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Poth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
you -X- _ O
would -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
even -X- _ O
larger -X- _ O
gains -X- _ O
over -X- _ O
MTL -X- _ B-MethodName
. -X- _ O
C -X- _ O
Theories -X- _ O
for -X- _ O
Transfer -X- _ O
Effectiveness -X- _ O
Previous -X- _ O
work -X- _ O
often -X- _ O
invokes -X- _ O
ideas -X- _ O
such -X- _ O
as -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
to -X- _ O
describe -X- _ O
why -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
does -X- _ O
or -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
over -X- _ O
the -X- _ O
basic -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
case -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
our -X- _ O
work -X- _ O
provides -X- _ O
a -X- _ O
novel -X- _ O
comparison -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
vs. -X- _ O
STILTs -X- _ B-MethodName
there -X- _ O
exists -X- _ O
no -X- _ O
previous -X- _ O
work -X- _ O
that -X- _ O
shows -X- _ O
how -X- _ O
these -X- _ O
methods -X- _ O
differ -X- _ O
in -X- _ O
any -X- _ O
practical -X- _ O
or -X- _ O
theoretical -X- _ O
terms -X- _ O
( -X- _ O
e.g. -X- _ O
does -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
cause -X- _ O
more -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
) -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
previous -X- _ O
explanations -X- _ O
for -X- _ O
why -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
works -X- _ O
has -X- _ O
been -X- _ O
called -X- _ O
into -X- _ O
question -X- _ O
( -X- _ O
Chang -X- _ O
and -X- _ O
Lu -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
leaving -X- _ O
it -X- _ O
an -X- _ O
open -X- _ O
research -X- _ O
area -X- _ O
. -X- _ O
A -X- _ O
naive -X- _ O
explanation -X- _ O
for -X- _ O
our -X- _ O
task -X- _ O
would -X- _ O
be -X- _ O
to -X- _ O
think -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
is -X- _ O
larger -X- _ O
, -X- _ O
STILTs -X- _ B-MethodName
should -X- _ O
be -X- _ O
worse -X- _ O
because -X- _ O
of -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
whereas -X- _ O
MTL -X- _ B-MethodName
would -X- _ O
still -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
STILTs -X- _ B-MethodName
this -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
would -X- _ O
mainly -X- _ O
effect -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
not -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
making -X- _ O
that -X- _ O
explanation -X- _ O
unlikely -X- _ O
in -X- _ O
some -X- _ O
contexts -X- _ O
( -X- _ O
e.g. -X- _ O
when -X- _ O
the -X- _ O
tasks -X- _ O
are -X- _ O
not -X- _ O
closely -X- _ O
related -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
potential -X- _ O
explanation -X- _ O
based -X- _ O
on -X- _ O
our -X- _ O
results -X- _ O
is -X- _ O
that -X- _ O
a -X- _ O
small -X- _ O
supporting -X- _ O
task -X- _ O
is -X- _ O
best -X- _ O
used -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
good -X- _ O
ini-278tialization -X- _ O
for -X- _ O
a -X- _ O
larger -X- _ O
target -X- _ O
task -X- _ O
( -X- _ O
e.g. -X- _ O
STILTs -X- _ B-MethodName
) -X- _ O
while -X- _ O
a -X- _ O
large -X- _ O
supporting -X- _ O
task -X- _ O
used -X- _ O
for -X- _ O
initialization -X- _ O
would -X- _ O
change -X- _ O
the -X- _ O
weights -X- _ O
too -X- _ O
much -X- _ O
for -X- _ O
the -X- _ O
small -X- _ O
target -X- _ O
task -X- _ O
to -X- _ O
use -X- _ O
effectively -X- _ O
( -X- _ O
thus -X- _ O
making -X- _ O
MTL -X- _ B-MethodName
the -X- _ O
more -X- _ O
effective -X- _ O
strategy -X- _ O
for -X- _ O
a -X- _ O
larger -X- _ O
supporting -X- _ O
task -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
explanation -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
a -X- _ O
larger -X- _ O
target -X- _ O
task -X- _ O
does -X- _ O
not -X- _ O
beneﬁt -X- _ O
from -X- _ O
MTL -X- _ B-MethodName
( -X- _ O
and -X- _ O
perhaps -X- _ O
is -X- _ O
harmed -X- _ O
by -X- _ O
it -X- _ O
, -X- _ O
e.g. -X- _ O
catastrophic -X- _ O
interference -X- _ O
) -X- _ O
and -X- _ O
therefore -X- _ O
, -X- _ O
STILTs -X- _ B-MethodName
is -X- _ O
more -X- _ O
effective -X- _ O
- -X- _ O
while -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
more -X- _ O
effective -X- _ O
for -X- _ O
small -X- _ O
target -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
explanations -X- _ O
also -X- _ O
fail -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
task -X- _ O
relatedness -X- _ O
, -X- _ O
which -X- _ O
likely -X- _ O
also -X- _ O
plays -X- _ O
a -X- _ O
role -X- _ O
in -X- _ O
the -X- _ O
theoretical -X- _ O
explanation -X- _ O
( -X- _ O
although -X- _ O
even -X- _ O
that -X- _ O
too -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
called -X- _ O
into -X- _ O
question -X- _ O
with -X- _ O
Chang -X- _ O
and -X- _ O
Lu -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
a -X- _ O
myriad -X- _ O
of -X- _ O
possible -X- _ O
explanations -X- _ O
( -X- _ O
and -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
likely -X- _ O
a -X- _ O
complex -X- _ O
combination -X- _ O
of -X- _ O
possible -X- _ O
explanations -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
are -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
aims -X- _ O
to -X- _ O
show -X- _ O
what -X- _ O
happens -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
proposing -X- _ O
a -X- _ O
theoretical -X- _ O
framework -X- _ O
. -X- _ O
As -X- _ O
theoretical -X- _ O
explanations -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
are -X- _ O
still -X- _ O
an -X- _ O
active -X- _ O
area -X- _ O
of -X- _ O
research -X- _ O
, -X- _ O
we -X- _ O
leave -X- _ O
them -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
and -X- _ O
provide -X- _ O
this -X- _ O
empirical -X- _ O
comparison -X- _ O
to -X- _ O
guide -X- _ O
their -X- _ O
efforts -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
efforts -X- _ O
of -X- _ O
NLP -X- _ O
researchers -X- _ O
and -X- _ O
practitioners -X- _ O
. -X- _ O
D -X- _ O
Alternate -X- _ O
Model -X- _ O
: -X- _ O
BERT -X- _ B-MethodName
We -X- _ O
conduct -X- _ O
the -X- _ O
same -X- _ O
analysis -X- _ O
as -X- _ O
Figure -X- _ O
1 -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
and -X- _ O
ﬁnd -X- _ O
similar -X- _ O
results -X- _ O
( -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
thus -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
transfer -X- _ O
to -X- _ O
other -X- _ O
pretrained -X- _ O
transformer -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
using -X- _ O
two -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
for -X- _ O
our -X- _ O
analysis -X- _ O
( -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
E -X- _ O
Additional -X- _ O
Background -X- _ O
Discussion -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
is -X- _ O
supported -X- _ O
by -X- _ O
and -X- _ O
helps -X- _ O
explain -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
previous -X- _ O
work -X- _ O
in -X- _ O
this -X- _ O
area -X- _ O
. -X- _ O
Although -X- _ O
this -X- _ O
section -X- _ O
is -X- _ O
not -X- _ O
crucial -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
result -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
it -X- _ O
to -X- _ O
help -X- _ O
readers -X- _ O
who -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
as -X- _ O
familiar -X- _ O
with -X- _ O
the -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
examine -X- _ O
two -X- _ O
works -X- _ O
in -X- _ O
depth -X- _ O
and -X- _ O
then -X- _ O
discuss -X- _ O
broader -X- _ O
themes -X- _ O
of -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O
BERT -X- _ O
on -X- _ O
STILTs -X- _ B-MethodName
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
This -X- _ O
work -X- _ O
deﬁned -X- _ O
the -X- _ O
acronym -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
or -X- _ O
Supplementary -X- _ B-MethodName
Training -X- _ I-MethodName
on -X- _ I-MethodName
Intermediate -X- _ I-MethodName
Labeled -X- _ I-MethodName
- -X- _ I-MethodName
data -X- _ I-MethodName
Tasks -X- _ I-MethodName
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
inﬂuential -X- _ O
idea -X- _ O
in -X- _ O
the -X- _ O
community -X- _ O
( -X- _ O
V -X- _ O
oskarides -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
ClarkModel -X- _ O
RTE -X- _ B-DatasetName
accuracy -X- _ O
GPT -X- _ O
! -X- _ O
RTE -X- _ O
54.2 -X- _ O
GPT -X- _ O
! -X- _ O
MNLI -X- _ B-DatasetName
! -X- _ O
RTE -X- _ O
70.4 -X- _ O
GPT -X- _ O
! -X- _ O
{ -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
RTE -X- _ B-DatasetName
} -X- _ O
68.6 -X- _ O
GPT -X- _ O
! -X- _ O
{ -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
RTE -X- _ B-DatasetName
} -X- _ O
! -X- _ O
RTE -X- _ B-DatasetName
67.5 -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
determine -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
intermediate -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
computed -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
matrix -X- _ O
of -X- _ O
each -X- _ O
pair -X- _ O
in -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
training -X- _ O
framework -X- _ O
are -X- _ O
different -X- _ O
from -X- _ O
their -X- _ O
methodology -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
compare -X- _ O
our -X- _ O
matrix -X- _ O
with -X- _ O
the -X- _ O
absolute -X- _ O
numbers -X- _ O
in -X- _ O
their -X- _ O
matrix -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
Section -X- _ O
4 -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
, -X- _ O
they -X- _ O
conduct -X- _ O
an -X- _ O
experiment -X- _ O
with -X- _ O
MTL -X- _ B-DatasetName
and -X- _ O
compare -X- _ O
the -X- _ O
results -X- _ O
to -X- _ O
their -X- _ O
STILTs -X- _ B-DatasetName
matrix -X- _ O
( -X- _ O
their -X- _ O
experimental -X- _ O
results -X- _ O
are -X- _ O
reproduced -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
for -X- _ O
convenience -X- _ O
) -X- _ O
. -X- _ O
Their -X- _ O
analysis -X- _ O
uses -X- _ O
MNLI -X- _ B-DatasetName
as -X- _ O
the -X- _ O
supporting -X- _ O
task -X- _ O
and -X- _ O
RTE -X- _ B-DatasetName
as -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
trying -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
STILTs -X- _ B-MethodName
, -X- _ O
MTL+ﬁnetuning -X- _ B-MethodName
, -X- _ O
and -X- _ O
only -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
RTE -X- _ B-DatasetName
. -X- _ O
Their -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
STILTs -X- _ B-MethodName
provides -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
, -X- _ O
with -X- _ O
all -X- _ O
MTL -X- _ B-MethodName
varieties -X- _ O
being -X- _ O
worse -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
they -X- _ O
conclude -X- _ O
that -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
worse -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O
How -X- _ O
does -X- _ O
this -X- _ O
compare -X- _ O
to -X- _ O
our -X- _ O
results -X- _ O
? -X- _ O
In -X- _ O
Figure -X- _ O
1 -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
method -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
method -X- _ O
for -X- _ O
the -X- _ O
( -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
pair -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
4 -X- _ O
signiﬁcant -X- _ O
cells -X- _ O
in -X- _ O
our -X- _ O
matrix -X- _ O
where -X- _ O
the -X- _ O
size -X- _ O
heuristic -X- _ O
does -X- _ O
not -X- _ O
accurately -X- _ O
predict -X- _ O
the -X- _ O
best -X- _ O
method -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
unfortunate -X- _ O
that -X- _ O
the -X- _ O
task -X- _ O
they -X- _ O
decided -X- _ O
to -X- _ O
pick -X- _ O
happened -X- _ O
to -X- _ O
be -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
anomalies -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
paper -X- _ O
extends -X- _ O
and -X- _ O
completes -X- _ O
their -X- _ O
results -X- _ O
with -X- _ O
more -X- _ O
rigor -X- _ O
. -X- _ O
MultiQA -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
MultiQA -X- _ O
showed -X- _ O
that -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
questionanswering -X- _ O
( -X- _ O
QA -X- _ O
) -X- _ O
datasets -X- _ O
made -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
could -X- _ O
outperform -X- _ O
the -X- _ O
current -X- _ O
SOTA -X- _ O
on -X- _ O
those -X- _ O
QA -X- _ O
datasets -X- _ O
. -X- _ O
They -X- _ O
used -X- _ O
an -X- _ O
interesting -X- _ O
approach -X- _ O
to -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
pulling -X- _ O
15k -X- _ O
examples -X- _ O
from -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
5 -X- _ O
major -X- _ O
datasets -X- _ O
to -X- _ O
compose -X- _ O
one -X- _ O
new -X- _ O
“ -X- _ O
MTL -X- _ B-MethodName
" -X- _ O
task -X- _ O
, -X- _ O
called -X- _ O
Multi-75K. -X- _ O
They -X- _ O
then -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
STILTs -X- _ B-MethodName
transfer -X- _ O
on -X- _ O
those -X- _ O
same -X- _ O
datasets -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
dataset -X- _ O
( -X- _ O
their -X- _ O
data -X- _ O
is -X- _ O
reproduced -X- _ O
with -X- _ O
new -X- _ O
emphasis -X- _ O
in -X- _ O
Appendix -X- _ O
E -X- _ O
Table -X- _ O
4 -X- _ O
for -X- _ O
conve-279 -X- _ O
nience -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
this -X- _ O
STILTs -X- _ B-MethodName
- -X- _ O
like -X- _ O
transfer -X- _ O
with -X- _ O
the -X- _ O
“ -X- _ O
MTL -X- _ B-MethodName
" -X- _ O
dataset -X- _ O
is -X- _ O
an -X- _ O
equivalent -X- _ O
method -X- _ O
to -X- _ O
doing -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
then -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
, -X- _ O
reminiscent -X- _ O
of -X- _ O
the -X- _ O
third -X- _ O
example -X- _ O
in -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
( -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
GPT -X- _ O
! -X- _ O
{ -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
RTE -X- _ B-DatasetName
} -X- _ O
! -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
c.f -X- _ O
. -X- _ O
Appendix -X- _ O
E -X- _ O
) -X- _ O
. -X- _ O
How -X- _ O
does -X- _ O
this -X- _ O
relate -X- _ O
to -X- _ O
our -X- _ O
results -X- _ O
? -X- _ O
The -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
says -X- _ O
that -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
STILTs -X- _ B-MethodName
when -X- _ O
the -X- _ O
target -X- _ O
task -X- _ O
has -X- _ O
fewer -X- _ O
training -X- _ O
instances -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
MultiQA -X- _ O
paper -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
each -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
artiﬁcially -X- _ O
controlled -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
( -X- _ O
75k -X- _ O
instances -X- _ O
) -X- _ O
, -X- _ O
thus -X- _ O
our -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
would -X- _ O
say -X- _ O
that -X- _ O
the -X- _ O
methods -X- _ O
should -X- _ O
be -X- _ O
comparable -X- _ O
. -X- _ O
Although -X- _ O
no -X- _ O
error -X- _ O
bounds -X- _ O
or -X- _ O
standard -X- _ O
deviations -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
their -X- _ O
paper -X- _ O
( -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
exact -X- _ O
comparison -X- _ O
difﬁcult -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
approach -X- _ O
performs -X- _ O
equal -X- _ O
or -X- _ O
better -X- _ O
on -X- _ O
almost -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
MultiQA -X- _ O
paper -X- _ O
is -X- _ O
not -X- _ O
strictly -X- _ O
comparable -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
training -X- _ O
setup -X- _ O
( -X- _ O
the -X- _ O
MTL+ﬁne -X- _ B-MethodName
tuning -X- _ O
) -X- _ O
, -X- _ O
their -X- _ O
results -X- _ O
agree -X- _ O
with -X- _ O
our -X- _ O
hypothesis -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
For -X- _ O
convenience -X- _ O
, -X- _ O
Table -X- _ O
4 -X- _ O
from -X- _ O
Talmor -X- _ O
and -X- _ O
Be -X- _ O
- -X- _ O
rant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
reproduced -X- _ O
here -X- _ O
in -X- _ O
the -X- _ O
appendix -X- _ O
. -X- _ O
The -X- _ O
top -X- _ O
half -X- _ O
contains -X- _ O
the -X- _ O
results -X- _ O
using -X- _ O
the -X- _ O
DocQA -X- _ O
model -X- _ O
while -X- _ O
the -X- _ O
bottom -X- _ O
half -X- _ O
uses -X- _ O
BERT -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
both -X- _ O
model -X- _ O
’s -X- _ O
Multi-75 -X- _ O
K -X- _ O
scores -X- _ O
perform -X- _ O
approximately -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
methods -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
expected -X- _ O
given -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
. -X- _ O
TQAG -X- _ O
and -X- _ O
TQA -X- _ O
- -X- _ O
W -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
. -X- _ O
As -X- _ O
stated -X- _ O
in -X- _ O
the -X- _ O
body -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
no -X- _ O
standard -X- _ O
deviation -X- _ O
is -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
MultiQA -X- _ O
paper -X- _ O
and -X- _ O
thus -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
know -X- _ O
whether -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
results -X- _ O
are -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
. -X- _ O
Even -X- _ O
if -X- _ O
all -X- _ O
results -X- _ O
were -X- _ O
statistically -X- _ O
signiﬁcant -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
highly -X- _ O
unlikely -X- _ O
, -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
Multi-75 -X- _ O
K -X- _ O
models -X- _ O
perform -X- _ O
equal -X- _ O
or -X- _ O
better -X- _ O
on -X- _ O
2 -X- _ O
of -X- _ O
the -X- _ O
6 -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
statistically -X- _ O
different -X- _ O
from -X- _ O
random -X- _ O
. -X- _ O
Combining -X- _ O
All -X- _ O
Tasks -X- _ O
Our -X- _ O
results -X- _ O
using -X- _ O
MTL -X- _ B-MethodName
showed -X- _ O
that -X- _ O
although -X- _ O
MTLis -X- _ B-MethodName
conceptually -X- _ O
easy -X- _ O
( -X- _ O
just -X- _ O
put -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
together -X- _ O
) -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
similar -X- _ O
results -X- _ O
in -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
in -X- _ O
their -X- _ O
Table -X- _ O
3 -X- _ O
they -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
approach -X- _ O
outperforms -X- _ O
the280SQuAD -X- _ O
NewsQA -X- _ O
SearchQA -X- _ O
TQA -X- _ O
- -X- _ O
G -X- _ O
TQA -X- _ O
- -X- _ O
W -X- _ O
HotpotQA -X- _ O
SQuAD -X- _ O
- -X- _ O
33.3 -X- _ O
39.2 -X- _ O
49.2 -X- _ O
34.5 -X- _ O
17.8 -X- _ O
NewsQA -X- _ O
59.6 -X- _ O
- -X- _ O
41.6 -X- _ O
44.2 -X- _ O
33.9 -X- _ O
16.5 -X- _ O
SearchQA -X- _ O
57 -X- _ O
31.4 -X- _ O
- -X- _ O
57.5 -X- _ O
39.6 -X- _ O
19.2 -X- _ O
TQA -X- _ O
- -X- _ O
G -X- _ O
57.7 -X- _ O
31.8 -X- _ O
49.5 -X- _ O
- -X- _ O
41.4 -X- _ O
19.1 -X- _ O
TQA -X- _ O
- -X- _ O
W -X- _ O
57.6 -X- _ O
31.7 -X- _ O
44.4 -X- _ O
50.7 -X- _ O
- -X- _ O
17.2 -X- _ O
HotpotQA -X- _ O
59.8 -X- _ O
32.4 -X- _ O
46.3 -X- _ O
54.6 -X- _ O
37.4 -X- _ O
Multi-75 -X- _ O
K -X- _ O
59.8 -X- _ O
33.0 -X- _ O
47.5 -X- _ O
56.4 -X- _ O
40.4 -X- _ O
19.2 -X- _ O
SQuAD -X- _ O
- -X- _ O
41.2 -X- _ O
47.8 -X- _ O
55.2 -X- _ O
45.4 -X- _ O
20.8 -X- _ O
NewsQA -X- _ O
72.1 -X- _ O
- -X- _ O
47.4 -X- _ O
55.9 -X- _ O
45.2 -X- _ O
20.6 -X- _ O
SearchQA -X- _ O
70.2 -X- _ O
40.2 -X- _ O
- -X- _ O
57.3 -X- _ O
45.5 -X- _ O
20.4 -X- _ O
TQA -X- _ O
- -X- _ O
G -X- _ O
69.9 -X- _ O
41.2 -X- _ O
50.0 -X- _ O
- -X- _ O
46.2 -X- _ O
20.8 -X- _ O
TQA -X- _ O
- -X- _ O
W -X- _ O
71.0 -X- _ O
39.2 -X- _ O
48.4 -X- _ O
55.7 -X- _ O
- -X- _ O
20.9 -X- _ O
HotpotQA -X- _ O
71.2 -X- _ O
39.5 -X- _ O
48.6 -X- _ O
56.6 -X- _ O
45.6 -X- _ O
Multi-75 -X- _ O
K -X- _ O
71.5 -X- _ O
42.1 -X- _ O
48.5 -X- _ O
56.6 -X- _ O
46.5 -X- _ O
20.4 -X- _ O
MTLapproach -X- _ B-MethodName
for -X- _ O
all -X- _ O
but -X- _ O
one -X- _ O
task -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
follow -X- _ O
up -X- _ O
work -X- _ O
from -X- _ O
the -X- _ O
initial -X- _ O
STILTs -X- _ B-MethodName
paper -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
they -X- _ O
ﬁnd -X- _ O
that -X- _ O
although -X- _ O
MTL -X- _ B-MethodName
has -X- _ O
a -X- _ O
slightly -X- _ O
higher -X- _ O
average -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
setting -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
pairwise -X- _ O
approach -X- _ O
in -X- _ O
75 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
evaluated -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
current -X- _ O
literature -X- _ O
( -X- _ O
and -X- _ O
our -X- _ O
work -X- _ O
) -X- _ O
seems -X- _ O
to -X- _ O
suggest -X- _ O
that -X- _ O
naively -X- _ O
combining -X- _ O
as -X- _ O
many -X- _ O
tasks -X- _ O
as -X- _ O
possible -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
the -X- _ O
best -X- _ O
approach -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
more -X- _ O
work -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
training -X- _ O
dynamics -X- _ O
of -X- _ O
MTL -X- _ B-MethodName
. -X- _ O
Combining -X- _ O
Helpful -X- _ O
Tasks -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
examine -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
, -X- _ O
STILTs -X- _ B-MethodName
or -X- _ O
MTL -X- _ B-MethodName
, -X- _ O
due -X- _ O
to -X- _ O
time -X- _ O
and -X- _ O
space -X- _ O
. -X- _ O
Although -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
our -X- _ O
heuristic -X- _ O
may -X- _ O
extrapolate -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
tasks -X- _ O
, -X- _ O
computing -X- _ O
the -X- _ O
power -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
possible -X- _ O
task -X- _ O
combinations -X- _ O
for -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
STILTs -X- _ B-MethodName
would -X- _ O
be -X- _ O
extremely -X- _ O
time -X- _ O
and -X- _ O
resource -X- _ O
intensive -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
it -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
to -X- _ O
examine -X- _ O
how -X- _ O
the -X- _ O
size -X- _ O
heuristic -X- _ O
may -X- _ O
hold -X- _ O
when -X- _ O
using -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
datasets -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
further -X- _ O
value -X- _ O
in -X- _ O
computing -X- _ O
this -X- _ O
power -X- _ O
set -X- _ O
: -X- _ O
Changpinyo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
showed -X- _ O
that -X- _ O
taking -X- _ O
the -X- _ O
pairwise -X- _ O
tasks -X- _ O
that -X- _ O
proved -X- _ O
beneﬁcial -X- _ O
in -X- _ O
pairwise -X- _ O
MTL -X- _ B-MethodName
and -X- _ O
combining -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
larger -X- _ O
MTL -X- _ B-MethodName
set -X- _ O
( -X- _ O
an -X- _ O
“ -X- _ O
Oracle -X- _ O
" -X- _ O
set -X- _ O
) -X- _ O
oftentimes -X- _ O
provides -X- _ O
higher -X- _ O
scores -X- _ O
than -X- _ O
pairwise -X- _ B-MethodName
MTL -X- _ I-MethodName
. -X- _ O
Exploring -X- _ O
which -X- _ O
subsets -X- _ O
of -X- _ O
tasks -X- _ O
provide -X- _ O
the -X- _ O
best -X- _ O
transfer -X- _ O
with -X- _ O
which -X- _ O
method -X- _ O
would -X- _ O
be -X- _ O
valuable -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Dataset -X- _ O
Size -X- _ O
in -X- _ O
TL -X- _ O
Dataset -X- _ O
size -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
often -X- _ O
in -X- _ O
transfer -X- _ O
learning -X- _ O
techniques -X- _ O
( -X- _ O
Søgaard -X- _ O
and -X- _ O
Bingel -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Pruksachatkun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Poth -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
size -X- _ B-MethodName
heuristic -X- _ I-MethodName
, -X- _ O
although -X- _ O
related -X- _ O
, -X- _ O
focuses -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
problem -X- _ O
: -X- _ O
whether -X- _ O
to -X- _ O
use -X- _ O
MTL -X- _ B-MethodName
or -X- _ O
STILTs -X- _ B-MethodName
. -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
provides -X- _ O
additional -X- _ O
insight -X- _ O
into -X- _ O
how -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
after -X- _ O
MTL -X- _ B-MethodName
Many -X- _ O
papers -X- _ O
that -X- _ O
use -X- _ O
MTLalso -X- _ B-MethodName
perform -X- _ O
some -X- _ O
sort -X- _ O
of -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
after -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
phase -X- _ O
. -X- _ O
Since -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
after -X- _ O
MTL -X- _ B-MethodName
makes -X- _ O
the -X- _ O
MTL -X- _ B-MethodName
phase -X- _ O
an -X- _ O
intermediate -X- _ O
step -X- _ O
, -X- _ O
it -X- _ O
essential -X- _ O
combines -X- _ O
the -X- _ O
STILTs -X- _ B-MethodName
and -X- _ O
MTL -X- _ B-MethodName
methods -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
STILTs -X- _ B-MethodName
- -X- _ O
like -X- _ O
method -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
whether -X- _ O
ﬁnetuning -X- _ O
after -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
simply -X- _ O
MTL -X- _ B-MethodName
is -X- _ O
still -X- _ O
controversial -X- _ O
: -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Talmor -X- _ O
and -X- _ O
Berant -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
say -X- _ O
that -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
after -X- _ O
MTL -X- _ O
helps -X- _ O
but -X- _ O
Lourie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
say -X- _ O
that -X- _ O
it -X- _ O
does -X- _ O
n’t -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
only -X- _ O
one -X- _ O
whose -X- _ O
experiments -X- _ O
include -X- _ O
multiple -X- _ O
random -X- _ O
seeds -X- _ O
, -X- _ O
giving -X- _ O
more -X- _ O
credence -X- _ O
to -X- _ O
their -X- _ O
results -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
opinion -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
which -X- _ O
method -X- _ O
is -X- _ O
actually -X- _ O
better -X- _ O
; -X- _ O
we -X- _ O
leave -X- _ O
this -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
F -X- _ O
GLUE -X- _ B-DatasetName
Dataset -X- _ O
Sizes -X- _ O
and -X- _ O
References -X- _ O
To -X- _ O
give -X- _ O
credit -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
authors -X- _ O
and -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
exact -X- _ O
sizes -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
Table -X- _ O
5.281282 -X- _ O

This -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
investigates -X- _ SUMMARY
the -X- _ SUMMARY
ability -X- _ SUMMARY
of -X- _ SUMMARY
vision -X- _ SUMMARY
- -X- _ SUMMARY
and -X- _ SUMMARY
- -X- _ SUMMARY
language -X- _ SUMMARY
models -X- _ SUMMARY
to -X- _ SUMMARY
track -X- _ SUMMARY
predicate -X- _ SUMMARY
- -X- _ SUMMARY
noun -X- _ SUMMARY
dependencies -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
create -X- _ SUMMARY
a -X- _ SUMMARY
new -X- _ SUMMARY
multimodal -X- _ SUMMARY
task -X- _ SUMMARY
to -X- _ SUMMARY
evaluate -X- _ SUMMARY
this -X- _ SUMMARY
ability -X- _ SUMMARY
and -X- _ SUMMARY
test -X- _ SUMMARY
a -X- _ SUMMARY
range -X- _ SUMMARY
of -X- _ SUMMARY
state -X- _ SUMMARY
- -X- _ SUMMARY
of -X- _ SUMMARY
- -X- _ SUMMARY
the -X- _ SUMMARY
- -X- _ SUMMARY
art -X- _ SUMMARY
models -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
find -X- _ SUMMARY
that -X- _ SUMMARY
the -X- _ SUMMARY
models -X- _ SUMMARY
' -X- _ SUMMARY
performance -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
task -X- _ SUMMARY
varies -X- _ SUMMARY
considerably -X- _ SUMMARY
, -X- _ SUMMARY
with -X- _ SUMMARY
some -X- _ SUMMARY
models -X- _ SUMMARY
performing -X- _ SUMMARY
well -X- _ SUMMARY
and -X- _ SUMMARY
others -X- _ SUMMARY
at -X- _ SUMMARY
chance -X- _ SUMMARY
level -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
analyze -X- _ SUMMARY
the -X- _ SUMMARY
results -X- _ SUMMARY
and -X- _ SUMMARY
attribute -X- _ SUMMARY
the -X- _ SUMMARY
variability -X- _ SUMMARY
in -X- _ SUMMARY
performance -X- _ SUMMARY
to -X- _ SUMMARY
the -X- _ SUMMARY
quality -X- _ SUMMARY
of -X- _ SUMMARY
pretraining -X- _ SUMMARY
data -X- _ SUMMARY
and -X- _ SUMMARY
the -X- _ SUMMARY
use -X- _ SUMMARY
of -X- _ SUMMARY
fine -X- _ SUMMARY
- -X- _ SUMMARY
grained -X- _ SUMMARY
multimodal -X- _ SUMMARY
pretraining -X- _ SUMMARY
objectives -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
highlights -X- _ SUMMARY
the -X- _ SUMMARY
importance -X- _ SUMMARY
of -X- _ SUMMARY
targeted -X- _ SUMMARY
and -X- _ SUMMARY
controlled -X- _ SUMMARY
evaluations -X- _ SUMMARY
for -X- _ SUMMARY
assessing -X- _ SUMMARY
the -X- _ SUMMARY
multimodal -X- _ SUMMARY
knowledge -X- _ SUMMARY
of -X- _ SUMMARY
such -X- _ SUMMARY
models -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
models -X- _ SUMMARY
evaluated -X- _ SUMMARY
include -X- _ SUMMARY
LXMERT -X- _ SUMMARY
, -X- _ SUMMARY
UNITER -X- _ SUMMARY
, -X- _ SUMMARY
ViLBERT -X- _ SUMMARY
, -X- _ SUMMARY
ViLT -X- _ SUMMARY
, -X- _ SUMMARY
Oscar -X- _ SUMMARY
, -X- _ SUMMARY
VinVL -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
CLIP -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
are -X- _ SUMMARY
accuracy -X- _ SUMMARY
scores -X- _ SUMMARY
for -X- _ SUMMARY
image -X- _ SUMMARY
- -X- _ SUMMARY
text -X- _ SUMMARY
matching -X- _ SUMMARY
in -X- _ SUMMARY
a -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
setting -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
task -X- _ SUMMARY
is -X- _ SUMMARY
focused -X- _ SUMMARY
on -X- _ SUMMARY
understanding -X- _ SUMMARY
predicate -X- _ SUMMARY
- -X- _ SUMMARY
noun -X- _ SUMMARY
dependencies -X- _ SUMMARY
on -X- _ SUMMARY
a -X- _ SUMMARY
controlled -X- _ SUMMARY
dataset -X- _ SUMMARY
derived -X- _ SUMMARY
from -X- _ SUMMARY
Open -X- _ SUMMARY
Images -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
results -X- _ SUMMARY
indicate -X- _ SUMMARY
that -X- _ SUMMARY
some -X- _ SUMMARY
models -X- _ SUMMARY
perform -X- _ SUMMARY
better -X- _ SUMMARY
than -X- _ SUMMARY
others -X- _ SUMMARY
in -X- _ SUMMARY
capturing -X- _ SUMMARY
these -X- _ SUMMARY
dependencies -X- _ SUMMARY
, -X- _ SUMMARY
with -X- _ SUMMARY
LXMERT -X- _ SUMMARY
and -X- _ SUMMARY
UNITER -X- _ SUMMARY
showing -X- _ SUMMARY
the -X- _ SUMMARY
highest -X- _ SUMMARY
scores -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
dataset -X- _ SUMMARY
used -X- _ SUMMARY
for -X- _ SUMMARY
evaluation -X- _ SUMMARY
consists -X- _ SUMMARY
of -X- _ SUMMARY
2584 -X- _ SUMMARY
triplets -X- _ SUMMARY
with -X- _ SUMMARY
carefully -X- _ SUMMARY
selected -X- _ SUMMARY
images -X- _ SUMMARY
and -X- _ SUMMARY
pairs -X- _ SUMMARY
of -X- _ SUMMARY
sentences -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
discuss -X- _ SUMMARY
limitations -X- _ SUMMARY
such -X- _ SUMMARY
as -X- _ SUMMARY
the -X- _ SUMMARY
small -X- _ SUMMARY
range -X- _ SUMMARY
of -X- _ SUMMARY
concepts -X- _ SUMMARY
evaluated -X- _ SUMMARY
and -X- _ SUMMARY
the -X- _ SUMMARY
subjective -X- _ SUMMARY
annotations -X- _ SUMMARY
of -X- _ SUMMARY
perceived -X- _ SUMMARY
gender -X- _ SUMMARY
. -X- _ SUMMARY
Code -X- _ SUMMARY
to -X- _ SUMMARY
reproduce -X- _ SUMMARY
the -X- _ SUMMARY
analyses -X- _ SUMMARY
is -X- _ SUMMARY
available -X- _ SUMMARY
at -X- _ SUMMARY
a -X- _ SUMMARY
GitHub -X- _ SUMMARY
repository -X- _ SUMMARY
. -X- _ SUMMARY
2022.emnlp-main.100.txt -X- _ O
Mitja -X- _ O
Nikolaus -X- _ O
mitja.nikolaus -X- _ O
@ -X- _ O
univ-amu.fr -X- _ O
Emmanuelle -X- _ O
Salinand -X- _ O
Stephane -X- _ O
Ayacheand -X- _ O
Abdellah -X- _ O
Fourtassiand -X- _ O
Benoit -X- _ O
FavreAix -X- _ O
Marseille -X- _ O
Univ -X- _ O
, -X- _ O
Université -X- _ O
de -X- _ O
Toulon -X- _ O
, -X- _ O
CNRS -X- _ O
, -X- _ O
LIS -X- _ O
, -X- _ O
Marseille -X- _ O
, -X- _ O
FranceAix -X- _ O
- -X- _ O
Marseille -X- _ O
Univ -X- _ O
, -X- _ O
CNRS -X- _ O
, -X- _ O
LPL -X- _ O
, -X- _ O
Aix -X- _ O
- -X- _ O
en -X- _ O
- -X- _ O
Provence -X- _ O
, -X- _ O
France -X- _ O
Abstract -X- _ O
Recent -X- _ O
advances -X- _ O
in -X- _ O
vision -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
language -X- _ O
modeling -X- _ O
have -X- _ O
seen -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
Transformer -X- _ O
architectures -X- _ O
that -X- _ O
achieve -X- _ O
remarkable -X- _ O
performance -X- _ O
on -X- _ O
multimodal -X- _ O
reasoning -X- _ O
tasks -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
the -X- _ O
exact -X- _ O
capabilities -X- _ O
of -X- _ O
these -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
models -X- _ O
are -X- _ O
still -X- _ O
poorly -X- _ O
understood -X- _ O
. -X- _ O
While -X- _ O
much -X- _ O
of -X- _ O
previous -X- _ O
work -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
studying -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
learn -X- _ O
meaning -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
track -X- _ O
syntactic -X- _ O
dependencies -X- _ O
between -X- _ O
words -X- _ O
has -X- _ O
received -X- _ O
less -X- _ O
attention -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
a -X- _ O
first -X- _ O
step -X- _ O
in -X- _ O
closing -X- _ O
this -X- _ O
gap -X- _ O
by -X- _ O
creating -X- _ O
a -X- _ O
new -X- _ O
multimodal -X- _ O
task -X- _ O
targeted -X- _ O
at -X- _ O
evaluating -X- _ O
understanding -X- _ O
of -X- _ O
predicate -X- _ B-TaskName
- -X- _ I-TaskName
noun -X- _ I-TaskName
dependencies -X- _ I-TaskName
in -X- _ O
a -X- _ O
controlled -X- _ O
setup -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
their -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
varies -X- _ O
considerably -X- _ O
, -X- _ O
with -X- _ O
some -X- _ O
models -X- _ O
performing -X- _ O
relatively -X- _ O
well -X- _ O
and -X- _ O
others -X- _ O
at -X- _ O
chance -X- _ O
level -X- _ O
. -X- _ O
In -X- _ O
an -X- _ O
effort -X- _ O
to -X- _ O
explain -X- _ O
this -X- _ O
variability -X- _ O
, -X- _ O
our -X- _ O
analyses -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
quality -X- _ O
( -X- _ O
and -X- _ O
not -X- _ O
only -X- _ O
sheer -X- _ O
quantity -X- _ O
) -X- _ O
of -X- _ O
pretraining -X- _ O
data -X- _ O
is -X- _ O
essential -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
models -X- _ O
leverage -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
standard -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
objectives -X- _ O
. -X- _ O
This -X- _ O
study -X- _ O
highlights -X- _ O
that -X- _ O
targeted -X- _ O
and -X- _ O
controlled -X- _ O
evaluations -X- _ O
are -X- _ O
a -X- _ O
crucial -X- _ O
step -X- _ O
for -X- _ O
a -X- _ O
precise -X- _ O
and -X- _ O
rigorous -X- _ O
test -X- _ O
of -X- _ O
the -X- _ O
multimodal -X- _ O
knowledge -X- _ O
of -X- _ O
vision -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Vision -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
language -X- _ O
( -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
) -X- _ O
models -X- _ O
have -X- _ O
recently -X- _ O
shown -X- _ O
substantial -X- _ O
improvement -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
multimodal -X- _ B-TaskName
reasoning -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
Taking -X- _ O
inspiration -X- _ O
from -X- _ O
successes -X- _ O
in -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
are -X- _ O
usually -X- _ O
composed -X- _ O
of -X- _ O
a -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
architecture -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
in -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
manner -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
models -X- _ O
show -X- _ O
remarkable -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
more -X- _ O
controlled -X- _ O
and -X- _ O
systematic -X- _ O
analyses -X- _ O
are -X- _ O
necessary -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
obtainFigure -X- _ O
1 -X- _ O
: -X- _ O
We -X- _ O
evaluate -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
on -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
track -X- _ O
predicate -X- _ B-TaskName
- -X- _ I-TaskName
noun -X- _ I-TaskName
dependencies -X- _ I-TaskName
that -X- _ O
require -X- _ O
a -X- _ O
joint -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
and -X- _ O
visual -X- _ O
modalities -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
correct -X- _ O
sentence -X- _ O
( -X- _ O
choosing -X- _ O
between -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
) -X- _ O
that -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
scene -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
should -X- _ O
connect -X- _ O
the -X- _ O
predicate -X- _ O
“ -X- _ O
is -X- _ O
wearing -X- _ O
a -X- _ O
hat -X- _ O
” -X- _ O
to -X- _ O
“ -X- _ O
man -X- _ O
” -X- _ O
. -X- _ O
A -X- _ O
model -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
track -X- _ O
dependencies -X- _ O
would -X- _ O
judge -X- _ O
the -X- _ O
distractor -X- _ O
sentence -X- _ O
“ -X- _ O
A -X- _ O
man -X- _ O
is -X- _ O
wearing -X- _ O
glasses -X- _ O
” -X- _ O
as -X- _ O
equally -X- _ O
likely -X- _ O
, -X- _ O
as -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
man -X- _ O
is -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
person -X- _ O
that -X- _ O
is -X- _ O
wearing -X- _ O
glasses -X- _ O
. -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
their -X- _ O
exact -X- _ O
multimodal -X- _ O
knowledge -X- _ O
. -X- _ O
A -X- _ O
range -X- _ O
of -X- _ O
studies -X- _ O
has -X- _ O
investigated -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
map -X- _ O
words -X- _ O
to -X- _ O
their -X- _ O
visual -X- _ O
referents -X- _ O
for -X- _ O
nouns -X- _ O
( -X- _ O
Kazemzadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Shekhar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
verbs -X- _ O
( -X- _ O
Ronchi -X- _ O
and -X- _ O
Perona -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Yatskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Pratt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Hendricks -X- _ O
and -X- _ O
Nematzadeh -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
are -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
studies -X- _ O
on -X- _ O
whether -X- _ O
recent -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
can -X- _ O
capture -X- _ O
multimodal -X- _ O
syntactic -X- _ O
dependencies -X- _ O
between -X- _ O
words -X- _ O
and -X- _ O
concepts -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
how -X- _ O
well -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
learn -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
across -X- _ O
modalities -X- _ O
( -X- _ O
see -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
an -X- _ O
evaluation -X- _ O
set -X- _ O
that -X- _ O
contains -X- _ O
carefully -X- _ O
selected -X- _ O
images -X- _ O
and -X- _ O
pairs -X- _ O
of -X- _ O
sentences -X- _ O
with -X- _ O
minimal1538differences -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
image -X- _ O
and -X- _ O
two -X- _ O
predicatenoun -X- _ O
sentences -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
need -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
correct -X- _ O
sentence -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
they -X- _ O
can -X- _ O
only -X- _ O
succeed -X- _ O
by -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
visual -X- _ O
concepts -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
noun -X- _ O
and -X- _ O
predicate -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
As -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
visual -X- _ O
reasoning -X- _ O
performance -X- _ O
in -X- _ O
several -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
spuriously -X- _ O
augmented -X- _ O
by -X- _ O
capitalizing -X- _ O
on -X- _ O
textual -X- _ O
biases -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Hendricks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
counter -X- _ O
- -X- _ O
balance -X- _ O
our -X- _ O
evaluation -X- _ O
dataset -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
controls -X- _ O
for -X- _ O
such -X- _ O
exploitation -X- _ O
of -X- _ O
linguistic -X- _ O
biases -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
track -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
varies -X- _ O
considerably -X- _ O
from -X- _ O
model -X- _ O
to -X- _ O
model -X- _ O
. -X- _ O
Of -X- _ O
all -X- _ O
models -X- _ O
tested -X- _ O
, -X- _ O
UNITER -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
LXMERT -X- _ B-MethodName
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
show -X- _ O
the -X- _ O
highest -X- _ O
scores -X- _ O
, -X- _ O
but -X- _ O
their -X- _ O
performance -X- _ O
is -X- _ O
still -X- _ O
far -X- _ O
from -X- _ O
optimal -X- _ O
. -X- _ O
Other -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
ViLBERT -X- _ B-MethodName
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
perform -X- _ O
at -X- _ O
chance -X- _ O
level -X- _ O
. -X- _ O
We -X- _ O
discuss -X- _ O
how -X- _ O
differences -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
could -X- _ O
explain -X- _ O
their -X- _ O
performance -X- _ O
variability -X- _ O
, -X- _ O
highlighting -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
pretraining -X- _ O
data -X- _ O
quality -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
. -X- _ O
Code -X- _ O
to -X- _ O
reproduce -X- _ O
the -X- _ O
analyses -X- _ O
and -X- _ O
run -X- _ O
the -X- _ O
evaluation -X- _ O
on -X- _ O
new -X- _ O
models -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
mitjanikolaus -X- _ O
/ -X- _ O
multimodal -X- _ O
- -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
- -X- _ O
dependencies -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
Targeted -X- _ O
evaluation -X- _ O
of -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
Recently -X- _ O
, -X- _ O
a -X- _ O
growing -X- _ O
number -X- _ O
of -X- _ O
tasks -X- _ O
have -X- _ O
been -X- _ O
created -X- _ O
for -X- _ O
targeted -X- _ O
evaluation -X- _ O
of -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
’ -X- _ O
abilities -X- _ O
to -X- _ O
perform -X- _ O
various -X- _ O
multimodal -X- _ B-TaskName
reasoning -X- _ I-TaskName
. -X- _ O
Shekhar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
create -X- _ O
sets -X- _ O
of -X- _ O
distractor -X- _ O
captions -X- _ O
to -X- _ O
analyze -X- _ O
whether -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
are -X- _ O
sensitive -X- _ O
to -X- _ O
single -X- _ O
word -X- _ O
replacements -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
focus -X- _ O
on -X- _ O
nouns -X- _ O
) -X- _ O
. -X- _ O
Similar -X- _ O
targeted -X- _ O
evaluation -X- _ O
datasets -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
proposed -X- _ O
for -X- _ O
referring -X- _ O
expressions -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
image -X- _ O
- -X- _ O
sentence -X- _ O
matching -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Visual -X- _ O
Question -X- _ O
Answering -X- _ O
( -X- _ O
VQA -X- _ O
; -X- _ O
Bogin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
focus -X- _ O
on -X- _ O
compositional -X- _ O
reasoning -X- _ O
. -X- _ O
Tasks -X- _ O
such -X- _ O
as -X- _ O
visual -X- _ O
semantic -X- _ O
role -X- _ O
labeling -X- _ O
or -X- _ O
situation -X- _ O
recognition -X- _ O
, -X- _ O
typically -X- _ O
involve -X- _ O
classifying -X- _ O
the -X- _ O
primary -X- _ O
activity -X- _ O
depicted -X- _ O
in -X- _ O
an -X- _ O
image -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
semantic -X- _ O
roles -X- _ O
of -X- _ O
involved -X- _ O
entities -X- _ O
( -X- _ O
Ronchi -X- _ O
and -X- _ O
Perona -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Chao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Gupta -X- _ O
and -X- _ O
Malik -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Yatskar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Pratt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
studies -X- _ O
demonstrate -X- _ O
that -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
can -X- _ O
learn -X- _ O
semantic -X- _ O
roles -X- _ O
to -X- _ O
some -X- _ O
degree -X- _ O
in -X- _ O
a -X- _ O
supervised -X- _ O
learning -X- _ O
setup -X- _ O
, -X- _ O
such -X- _ O
tasks -X- _ O
do -X- _ O
not -X- _ O
allow -X- _ O
for -X- _ O
a -X- _ O
controlled -X- _ O
evaluation -X- _ O
of -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
In -X- _ O
Hendricks -X- _ O
and -X- _ O
Nematzadeh -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
evaluate -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
controlled -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setup -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
they -X- _ O
still -X- _ O
have -X- _ O
more -X- _ O
trouble -X- _ O
understanding -X- _ O
verbs -X- _ O
compared -X- _ O
to -X- _ O
subjects -X- _ O
or -X- _ O
objects -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
larger -X- _ O
datasets -X- _ O
with -X- _ O
less -X- _ O
descriptive -X- _ O
captions -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
smaller -X- _ O
, -X- _ O
manually -X- _ O
- -X- _ O
annotated -X- _ O
datasets -X- _ O
. -X- _ O
Several -X- _ O
works -X- _ O
have -X- _ O
also -X- _ O
tried -X- _ O
to -X- _ O
shed -X- _ O
more -X- _ O
light -X- _ O
on -X- _ O
the -X- _ O
precise -X- _ O
multimodal -X- _ O
semantic -X- _ O
capabilities -X- _ O
of -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
using -X- _ O
probing -X- _ O
techniques -X- _ O
. -X- _ O
Salin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
although -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
can -X- _ O
grasp -X- _ O
some -X- _ O
multimodal -X- _ O
concepts -X- _ O
such -X- _ O
as -X- _ O
color -X- _ O
, -X- _ O
they -X- _ O
still -X- _ O
do -X- _ O
not -X- _ O
fully -X- _ O
understand -X- _ O
more -X- _ O
difficult -X- _ O
concepts -X- _ O
such -X- _ O
as -X- _ O
object -X- _ O
size -X- _ O
and -X- _ O
position -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Parcalabescu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
use -X- _ O
probing -X- _ O
to -X- _ O
demonstrate -X- _ O
that -X- _ O
such -X- _ O
models -X- _ O
still -X- _ O
lack -X- _ O
the -X- _ O
capability -X- _ O
to -X- _ O
correctly -X- _ O
count -X- _ O
entities -X- _ O
in -X- _ O
an -X- _ O
image -X- _ O
. -X- _ O
Evaluation -X- _ O
of -X- _ O
grounded -X- _ O
syntax -X- _ O
Akula -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
tests -X- _ O
for -X- _ O
sensitivity -X- _ O
to -X- _ O
word -X- _ O
order -X- _ O
in -X- _ O
referring -X- _ O
expressions -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
Thrush -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
studies -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
to -X- _ O
take -X- _ O
word -X- _ O
order -X- _ O
into -X- _ O
account -X- _ O
by -X- _ O
designing -X- _ O
adversarial -X- _ O
examples -X- _ O
that -X- _ O
require -X- _ O
differentiating -X- _ O
between -X- _ O
similar -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
pairs -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
text -X- _ O
pairs -X- _ O
only -X- _ O
differ -X- _ O
in -X- _ O
their -X- _ O
word -X- _ O
order -X- _ O
. -X- _ O
Their -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
stateof -X- _ O
- -X- _ O
the -X- _ O
art -X- _ O
models -X- _ O
still -X- _ O
lack -X- _ O
precise -X- _ O
compositional -X- _ O
reasoning -X- _ O
abilities -X- _ O
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020a -X- _ O
) -X- _ O
studies -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
syntactic -X- _ O
grounding -X- _ O
of -X- _ O
VisualBERT -X- _ O
. -X- _ O
They -X- _ O
show -X- _ O
that -X- _ O
certain -X- _ O
attention -X- _ O
heads -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
architecture -X- _ O
attend -X- _ O
to -X- _ O
entities -X- _ O
that -X- _ O
are -X- _ O
connected -X- _ O
via -X- _ O
syntactic -X- _ O
dependency -X- _ O
relationships -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
such -X- _ O
probing -X- _ O
experiments -X- _ O
do -X- _ O
not -X- _ O
necessarily -X- _ O
indicate -X- _ O
to -X- _ O
what -X- _ O
degree -X- _ O
a -X- _ O
model -X- _ O
is -X- _ O
actually -X- _ O
using -X- _ O
the -X- _ O
encoded -X- _ O
information -X- _ O
when -X- _ O
making -X- _ O
predictions -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
models -X- _ O
specifically -X- _ O
on -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
track -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
much -X- _ O
more -X- _ O
controlled -X- _ O
setting -X- _ O
compared -X- _ O
to -X- _ O
previous -X- _ O
work -X- _ O
: -X- _ O
Our -X- _ O
setup -X- _ O
involves -X- _ O
visual -X- _ O
distractors -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
control -X- _ O
task -X- _ O
, -X- _ O
disentangling -X- _ O
the -X- _ O
challenge -X- _ O
of -X- _ O
understanding -X- _ O
syntactic -X- _ O
dependencies -X- _ O
from -X- _ O
more -X- _ O
simple -X- _ O
object -X- _ O
and -X- _ O
predicate -X- _ O
recognition -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
strictly -X- _ O
control -X- _ O
for -X- _ O
any -X- _ O
possible1539linguistic -X- _ O
bias -X- _ O
by -X- _ O
counter -X- _ O
- -X- _ O
balancing -X- _ O
all -X- _ O
evaluation -X- _ O
examples -X- _ O
. -X- _ O
3 -X- _ O
Methods -X- _ O
3.1 -X- _ O
Evaluation -X- _ O
Dataset -X- _ O
We -X- _ O
construct -X- _ O
an -X- _ O
evaluation -X- _ O
dataset -X- _ O
that -X- _ O
is -X- _ O
suited -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
sensitivity -X- _ O
to -X- _ O
visually -X- _ O
grounded -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setup -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
consists -X- _ O
of -X- _ O
pairs -X- _ O
of -X- _ O
triplets -X- _ O
, -X- _ O
and -X- _ O
each -X- _ O
triplet -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
Image -X- _ O
I -X- _ O
, -X- _ O
a -X- _ O
target -X- _ O
sentence -X- _ O
S -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
distractor -X- _ O
sentence -X- _ O
S. -X- _ O
Target -X- _ O
and -X- _ O
distractor -X- _ O
sentences -X- _ O
are -X- _ O
minimal -X- _ O
pairs -X- _ O
, -X- _ O
i.e. -X- _ O
one -X- _ O
sentence -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
only -X- _ O
with -X- _ O
regard -X- _ O
to -X- _ O
either -X- _ O
the -X- _ O
noun -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
A -X- _ O
girl -X- _ O
is -X- _ O
sitting -X- _ O
. -X- _ O
” -X- _ O
vs. -X- _ O
“ -X- _ O
A -X- _ O
man -X- _ O
is -X- _ O
sitting -X- _ O
. -X- _ O
” -X- _ O
, -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
predicate -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
A -X- _ O
man -X- _ O
is -X- _ O
wearing -X- _ O
a -X- _ O
hat -X- _ O
. -X- _ O
” -X- _ O
vs. -X- _ O
“ -X- _ O
A -X- _ O
man -X- _ O
is -X- _ O
wearing -X- _ O
glasses -X- _ O
. -X- _ O
” -X- _ O
, -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
the -X- _ O
images -X- _ O
always -X- _ O
contain -X- _ O
visual -X- _ O
distractors -X- _ O
, -X- _ O
meaning -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
noun -X- _ O
and -X- _ O
the -X- _ O
predicate -X- _ O
of -X- _ O
the -X- _ O
distractor -X- _ O
sentence -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
a -X- _ O
noun -X- _ O
- -X- _ O
predicate -X- _ O
relationship -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
distractor -X- _ O
sentence -X- _ O
“ -X- _ O
A -X- _ O
man -X- _ O
is -X- _ O
wearing -X- _ O
glasses -X- _ O
” -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
man -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
who -X- _ O
is -X- _ O
not -X- _ O
wearing -X- _ O
glasses -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
person -X- _ O
wearing -X- _ O
glasses -X- _ O
, -X- _ O
who -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
man -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
dependency -X- _ O
between -X- _ O
noun -X- _ O
and -X- _ O
predicate -X- _ O
to -X- _ O
distinguish -X- _ O
between -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentence -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Controlling -X- _ O
for -X- _ O
linguistic -X- _ O
biases -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
have -X- _ O
shown -X- _ O
to -X- _ O
rely -X- _ O
sometimes -X- _ O
on -X- _ O
textual -X- _ O
bias -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
visual -X- _ O
information -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Hendricks -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
training -X- _ O
dataset -X- _ O
contains -X- _ O
more -X- _ O
often -X- _ O
the -X- _ O
phrase -X- _ O
“ -X- _ O
a -X- _ O
girl -X- _ O
is -X- _ O
sitting -X- _ O
” -X- _ O
than -X- _ O
“ -X- _ O
a -X- _ O
man -X- _ O
is -X- _ O
sitting -X- _ O
” -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
might -X- _ O
prefer -X- _ O
the -X- _ O
caption -X- _ O
“ -X- _ O
a -X- _ O
girl -X- _ O
is -X- _ O
sitting -X- _ O
” -X- _ O
during -X- _ O
evaluation -X- _ O
only -X- _ O
based -X- _ O
on -X- _ O
linguistic -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
heuristics -X- _ O
, -X- _ O
irrespective -X- _ O
of -X- _ O
the -X- _ O
visual -X- _ O
content -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
evaluation -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
control -X- _ O
for -X- _ O
potential -X- _ O
linguistic -X- _ O
biases -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
datasets -X- _ O
by -X- _ O
pairing -X- _ O
every -X- _ O
triplet -X- _ O
with -X- _ O
a -X- _ O
corresponding -X- _ O
counter -X- _ O
- -X- _ O
balanced -X- _ O
example -X- _ O
where -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentence -X- _ O
are -X- _ O
flipped -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
for -X- _ O
every -X- _ O
triplet -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
corresponding -X- _ O
triplet -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
that -X- _ O
way -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
visual -X- _ O
modality -X- _ O
can -X- _ O
not -X- _ O
succeed -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
( -X- _ O
see -X- _ O
also -X- _ O
Nikolaus -X- _ O
and -X- _ O
Fourtassi -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Automatic -X- _ O
pre -X- _ O
- -X- _ O
filtering -X- _ O
Our -X- _ O
evaluation -X- _ O
dataset -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Open -X- _ B-DatasetName
Images -X- _ I-DatasetName
( -X- _ O
Kuznetsova -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
filter -X- _ O
the -X- _ O
images -X- _ O
based -X- _ O
on -X- _ O
existing -X- _ O
humanannotated -X- _ O
object -X- _ O
and -X- _ O
relationship -X- _ O
labels -X- _ O
and -X- _ O
bounding -X- _ O
boxes -X- _ O
. -X- _ O
The -X- _ O
objects -X- _ O
refer -X- _ O
to -X- _ O
persons -X- _ O
, -X- _ O
animals -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
inanimate -X- _ O
objects -X- _ O
. -X- _ O
The -X- _ O
relationships -X- _ O
can -X- _ O
either -X- _ O
describe -X- _ O
an -X- _ O
action -X- _ O
that -X- _ O
an -X- _ O
object -X- _ O
is -X- _ O
engaged -X- _ O
in -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
- -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
an -X- _ O
action -X- _ O
linking -X- _ O
two -X- _ O
objects -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
- -X- _ O
- -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
nouns -X- _ O
in -X- _ O
the -X- _ O
selected -X- _ O
relationships -X- _ O
for -X- _ O
our -X- _ O
dataset -X- _ O
refer -X- _ O
to -X- _ O
persons -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
sufficient -X- _ O
annotations -X- _ O
for -X- _ O
other -X- _ O
kinds -X- _ O
of -X- _ O
agents -X- _ O
. -X- _ O
We -X- _ O
look -X- _ O
for -X- _ O
images -X- _ O
that -X- _ O
contain -X- _ O
a -X- _ O
target -X- _ O
objectrelationship -X- _ O
pair -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
distractor -X- _ O
objectrelationship -X- _ O
pair -X- _ O
for -X- _ O
which -X- _ O
either -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
object -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
relationships -X- _ O
differ -X- _ O
, -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
( -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Additional -X- _ O
details -X- _ O
on -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
filtering -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.1 -X- _ O
. -X- _ O
Manual -X- _ O
selection -X- _ O
We -X- _ O
manually -X- _ O
select -X- _ O
suitable -X- _ O
images -X- _ O
after -X- _ O
the -X- _ O
automated -X- _ O
pre -X- _ O
- -X- _ O
filtering -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
ensure -X- _ O
high -X- _ O
quality -X- _ O
of -X- _ O
each -X- _ O
example -X- _ O
and -X- _ O
in -X- _ O
particular -X- _ O
to -X- _ O
verify -X- _ O
that -X- _ O
the -X- _ O
distractor -X- _ O
sentences -X- _ O
are -X- _ O
indeed -X- _ O
incorrect -X- _ O
given -X- _ O
the -X- _ O
images -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
crucial -X- _ O
, -X- _ O
because -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
annotations -X- _ O
in -X- _ O
Open -X- _ O
Images -X- _ O
are -X- _ O
incomplete -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
image -X- _ O
may -X- _ O
contain -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
woman -X- _ O
that -X- _ O
is -X- _ O
sitting -X- _ O
but -X- _ O
not -X- _ O
annotated -X- _ O
as -X- _ O
such -X- _ O
( -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
disregard -X- _ O
the -X- _ O
image -X- _ O
for -X- _ O
our -X- _ O
evaluation -X- _ O
set -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
pairs -X- _ O
of -X- _ O
examples -X- _ O
and -X- _ O
counterexamples -X- _ O
and -X- _ O
ensure -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
duplicate -X- _ O
images -X- _ O
within -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
images -X- _ O
for -X- _ O
each -X- _ O
objectrelationship -X- _ O
pair -X- _ O
. -X- _ O
Sentence -X- _ O
generation -X- _ O
We -X- _ O
generate -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentences -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
verified -X- _ O
object -X- _ O
and -X- _ O
relationship -X- _ O
annotations -X- _ O
from -X- _ O
Open -X- _ O
Images -X- _ O
. -X- _ O
We -X- _ O
construct -X- _ O
English -X- _ O
sentences -X- _ O
using -X- _ O
a -X- _ O
templatebased -X- _ O
approach -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
object -X- _ O
and -X- _ O
a -X- _ O
relationship,1540we -X- _ O
add -X- _ O
the -X- _ O
indefinite -X- _ O
article -X- _ O
( -X- _ O
a -X- _ O
/ -X- _ O
an -X- _ O
) -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
each -X- _ O
noun -X- _ O
and -X- _ O
use -X- _ O
all -X- _ O
verbs -X- _ O
in -X- _ O
present -X- _ O
progressive -X- _ O
tense -X- _ O
as -X- _ O
this -X- _ O
is -X- _ O
most -X- _ O
frequent -X- _ O
in -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
datasets -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
from -X- _ O
-- -X- _ O
we -X- _ O
generate -X- _ O
“ -X- _ O
a -X- _ O
woman -X- _ O
is -X- _ O
sitting -X- _ O
. -X- _ O
” -X- _ O
; -X- _ O
and -X- _ O
from -X- _ O
- -X- _ O
- -X- _ O
- -X- _ O
“ -X- _ O
a -X- _ O
man -X- _ O
is -X- _ O
holding -X- _ O
a -X- _ O
camera -X- _ O
. -X- _ O
” -X- _ O
. -X- _ O
This -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
is -X- _ O
necessary -X- _ O
for -X- _ O
our -X- _ O
controlled -X- _ O
evaluation -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
the -X- _ O
exact -X- _ O
template -X- _ O
for -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
may -X- _ O
influence -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
additionally -X- _ O
, -X- _ O
using -X- _ O
a -X- _ O
slightly -X- _ O
different -X- _ O
template -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
overall -X- _ O
result -X- _ O
patterns -X- _ O
remain -X- _ O
largely -X- _ O
similar -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A.4.2 -X- _ O
) -X- _ O
. -X- _ O
Final -X- _ O
evaluation -X- _ O
set -X- _ O
The -X- _ O
final -X- _ O
evaluation -X- _ O
set -X- _ O
contains -X- _ O
2584 -X- _ O
triplets -X- _ O
. -X- _ O
For -X- _ O
1486 -X- _ O
of -X- _ O
these -X- _ O
triplets -X- _ O
, -X- _ O
the -X- _ O
distractor -X- _ O
sentence -X- _ O
contains -X- _ O
an -X- _ O
incorrect -X- _ O
predicate -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
1098 -X- _ O
triplets -X- _ O
, -X- _ O
the -X- _ O
distractor -X- _ O
contains -X- _ O
an -X- _ O
incorrect -X- _ O
noun -X- _ O
. -X- _ O
More -X- _ O
detailed -X- _ O
statistics -X- _ O
regarding -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
triplets -X- _ O
concerning -X- _ O
specific -X- _ O
concepts -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Appendix -X- _ O
A.2 -X- _ O
. -X- _ O
A -X- _ O
note -X- _ O
on -X- _ O
perceived -X- _ O
gender -X- _ O
annotations -X- _ O
Our -X- _ O
evaluation -X- _ O
dataset -X- _ O
uses -X- _ O
annotations -X- _ O
from -X- _ O
the -X- _ O
Open -X- _ B-DatasetName
Images -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
which -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
physical -X- _ O
appearance -X- _ O
of -X- _ O
persons -X- _ O
to -X- _ O
annotate -X- _ O
their -X- _ O
perceived -X- _ O
gender -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
provided -X- _ O
annotations -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
resulting -X- _ O
biases -X- _ O
are -X- _ O
unfortunately -X- _ O
reproduced -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
discuss -X- _ O
this -X- _ O
issue -X- _ O
in -X- _ O
further -X- _ O
detail -X- _ O
in -X- _ O
the -X- _ O
Ethics -X- _ O
Statement -X- _ O
( -X- _ O
Section -X- _ O
8 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Salminen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
gender -X- _ O
classification -X- _ O
from -X- _ O
face -X- _ O
pictures -X- _ O
by -X- _ O
human -X- _ O
annotators -X- _ O
shows -X- _ O
an -X- _ O
inter -X- _ O
annotator -X- _ O
agreement -X- _ O
greater -X- _ O
than -X- _ O
95 -X- _ O
% -X- _ O
. -X- _ O
True -X- _ O
gender -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
classified -X- _ O
, -X- _ O
and -X- _ O
high -X- _ O
interannotator -X- _ O
agreement -X- _ O
does -X- _ O
not -X- _ O
imply -X- _ O
a -X- _ O
correct -X- _ O
gender -X- _ O
choice -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
gender -X- _ O
annotations -X- _ O
of -X- _ O
Open -X- _ B-DatasetName
Images -X- _ I-DatasetName
to -X- _ O
be -X- _ O
reliable -X- _ O
enough -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
basis -X- _ O
for -X- _ O
our -X- _ O
analyses -X- _ O
. -X- _ O
3.2 -X- _ O
Metric -X- _ O
We -X- _ O
evaluate -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
on -X- _ O
their -X- _ O
image -X- _ B-MetricName
- -X- _ I-MetricName
text -X- _ I-MetricName
matching -X- _ I-MetricName
performance -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
, -X- _ O
i.e. -X- _ O
without -X- _ O
any -X- _ O
further -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
triplet -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
whether -X- _ O
the -X- _ O
models -X- _ O
give -X- _ O
a -X- _ O
higher -X- _ O
similarity -X- _ B-MetricName
score -X- _ I-MetricName
for -X- _ O
the -X- _ O
correct -X- _ O
sentence -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
distractorsentence -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
accuracy -X- _ O
for -X- _ O
each -X- _ O
pair -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
succeed -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
example -X- _ O
and -X- _ O
the -X- _ O
counter -X- _ O
- -X- _ O
balanced -X- _ O
example -X- _ O
triplet -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
pair -X- _ O
of -X- _ O
triplets -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
= -X- _ O
( -X- _ O
[ -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
, -X- _ O
S -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
, -X- _ O
S -X- _ O
] -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
following -X- _ O
score -X- _ O
: -X- _ O
f -X- _ O
( -X- _ O
t -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
= -X- _ O
 -X- _ O
 -X- _ O
1 -X- _ O
, -X- _ O
ifs -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
> -X- _ O
s -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
ands -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
> -X- _ O
s -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
0 -X- _ O
, -X- _ O
otherwise -X- _ O
where -X- _ O
s -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
an -X- _ O
image -X- _ O
Iand -X- _ O
a -X- _ O
sentence -X- _ O
S. -X- _ O
To -X- _ O
obtain -X- _ O
the -X- _ O
similarity -X- _ B-MetricName
score -X- _ I-MetricName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
softmaxed -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
imagetext -X- _ O
matching -X- _ O
pretraining -X- _ O
heads -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
over -X- _ O
all -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
set -X- _ O
. -X- _ O
Chance -X- _ O
performance -X- _ O
is -X- _ O
at -X- _ O
25 -X- _ O
% -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
dataset -X- _ O
was -X- _ O
manually -X- _ O
filtered -X- _ O
and -X- _ O
requires -X- _ O
only -X- _ O
rather -X- _ O
simple -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
images -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
human -X- _ O
performance -X- _ O
to -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
100 -X- _ O
% -X- _ O
. -X- _ O
To -X- _ O
verify -X- _ O
this -X- _ O
claim -X- _ O
, -X- _ O
we -X- _ O
had -X- _ O
a -X- _ O
one -X- _ O
person -X- _ O
annotate -X- _ O
a -X- _ O
randomly -X- _ O
sampled -X- _ O
subset -X- _ O
of -X- _ O
500 -X- _ O
triplets -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
triplet -X- _ O
, -X- _ O
the -X- _ O
annotator -X- _ O
was -X- _ O
asked -X- _ O
to -X- _ O
judge -X- _ O
which -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
describes -X- _ O
the -X- _ O
image -X- _ O
better -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
performance -X- _ O
was -X- _ O
at -X- _ O
100 -X- _ O
% -X- _ O
. -X- _ O
A -X- _ O
topline -X- _ O
: -X- _ O
the -X- _ O
cropped -X- _ O
task -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
visual -X- _ O
distractors -X- _ O
on -X- _ O
this -X- _ O
nounpredicate -X- _ O
dependency -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
additionally -X- _ O
evaluate -X- _ O
all -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
cropped -X- _ O
task -X- _ O
: -X- _ O
We -X- _ O
reduce -X- _ O
the -X- _ O
image -X- _ O
to -X- _ O
the -X- _ O
bounding -X- _ O
box -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
object -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
cropped -X- _ O
image -X- _ O
usuallyonly -X- _ O
contains -X- _ O
the -X- _ O
target -X- _ O
object -X- _ O
, -X- _ O
and -X- _ O
no -X- _ O
more -X- _ O
visual -X- _ O
distractors -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
referent -X- _ O
of -X- _ O
the -X- _ O
noun -X- _ O
or -X- _ O
the -X- _ O
predicate -X- _ O
in -X- _ O
the -X- _ O
distractor -X- _ O
sentence -X- _ O
is -X- _ O
no -X- _ O
longer -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
cropped -X- _ O
image -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
succeed -X- _ O
at -X- _ O
this -X- _ O
( -X- _ O
simpler -X- _ O
) -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
no -X- _ O
longer -X- _ O
needs -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
predicatenoun -X- _ O
dependency -X- _ O
, -X- _ O
it -X- _ O
just -X- _ O
needs -X- _ O
to -X- _ O
ground -X- _ O
the -X- _ O
single -X- _ O
words -X- _ O
correctly -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
this -X- _ O
task -X- _ O
to -X- _ O
estimate -X- _ O
how -X- _ O
much -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
is -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
ground -X- _ O
nouns -X- _ O
and -X- _ O
predicates -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
dataset -X- _ O
, -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
the -X- _ O
( -X- _ O
more1541sophisticated -X- _ O
) -X- _ O
ability -X- _ O
of -X- _ O
understanding -X- _ O
predicatenoun -X- _ O
dependencies -X- _ O
. -X- _ O
3.3 -X- _ O
Models -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
using -X- _ O
text -X- _ O
, -X- _ O
image -X- _ O
, -X- _ O
and -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
on -X- _ O
corpora -X- _ O
of -X- _ O
parallel -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
use -X- _ O
the -X- _ O
transformer -X- _ O
architecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
vary -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
pretraining -X- _ O
data -X- _ O
and -X- _ O
objectives -X- _ O
, -X- _ O
image -X- _ O
encoders -X- _ O
, -X- _ O
and -X- _ O
multimodal -X- _ O
fusion -X- _ O
approaches -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
their -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
pretraining -X- _ O
objectives -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
commonly -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
objective -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
describes -X- _ O
an -X- _ O
image -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
We -X- _ O
leverage -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
pretraining -X- _ O
head -X- _ O
for -X- _ O
calculating -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
similarities -X- _ O
for -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
LXMERT -X- _ B-MethodName
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
UNITER -X- _ B-MethodName
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
ViLBERT -X- _ B-MethodName
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Oscar -X- _ B-MethodName
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
VinVL -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
ViLT -X- _ B-MethodName
( -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
could -X- _ O
not -X- _ O
evaluate -X- _ O
the -X- _ O
original -X- _ O
VL -X- _ O
- -X- _ O
BERT -X- _ O
( -X- _ O
Su -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
because -X- _ O
it -X- _ O
was -X- _ O
not -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
using -X- _ O
an -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
loss -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
did -X- _ O
not -X- _ O
evaluate -X- _ O
the -X- _ O
original -X- _ O
VisualBERT -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
their -X- _ O
implementation -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
loss -X- _ O
requires -X- _ O
one -X- _ O
correct -X- _ O
caption -X- _ O
( -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
a -X- _ O
possibly -X- _ O
faulty -X- _ O
caption -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
available -X- _ O
for -X- _ O
the -X- _ O
Open -X- _ B-DatasetName
Images -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
Both -X- _ O
models -X- _ O
were -X- _ O
however -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
controlled -X- _ O
conditions -X- _ O
using -X- _ O
VOLTA -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O
Pretraining -X- _ O
datasets -X- _ O
ViLBERT -X- _ B-MethodName
and -X- _ O
VL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
are -X- _ O
pretrained -X- _ O
on -X- _ O
Conceptual -X- _ O
Captions -X- _ O
( -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
UNITER -X- _ B-MethodName
, -X- _ O
LXMERT -X- _ B-MethodName
, -X- _ O
ViLT -X- _ B-MethodName
, -X- _ O
and -X- _ O
VinVLmake -X- _ B-MethodName
use -X- _ O
of -X- _ O
additional -X- _ O
publicly -X- _ O
available -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
COCO -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
SBU -X- _ O
captions -X- _ O
( -X- _ O
Ordonez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
Flickr30 -X- _ O
K -X- _ O
( -X- _ O
Young -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
VisualGenome -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
VQA -X- _ O
datasets -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
VisualBERT -X- _ B-MethodName
is -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
COCO -X- _ O
. -X- _ O
Appendix -X- _ O
A.3 -X- _ O
details -X- _ O
the -X- _ O
pretraining -X- _ O
datasets -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
their -X- _ O
sizes -X- _ O
. -X- _ O
The -X- _ O
pretraining -X- _ O
data -X- _ O
for -X- _ O
CLIP -X- _ B-MethodName
has -X- _ O
not -X- _ O
been -X- _ O
publicly -X- _ O
released -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
state -X- _ O
that -X- _ O
it -X- _ O
consists -X- _ O
of -X- _ O
400 -X- _ O
M -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
internet -X- _ O
( -X- _ O
an -X- _ O
order -X- _ O
of -X- _ O
magnitude -X- _ O
more -X- _ O
data -X- _ O
than -X- _ O
for -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
surpass -X- _ O
10 -X- _ O
M -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
in -X- _ O
size -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
Results -X- _ O
4.1 -X- _ O
Original -X- _ O
Implementations -X- _ O
We -X- _ O
test -X- _ O
all -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
evaluation -X- _ O
methods -X- _ O
and -X- _ O
data -X- _ O
described -X- _ O
above -X- _ O
. -X- _ O
We -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
pretrained -X- _ O
models -X- _ O
made -X- _ O
publicly -X- _ O
available -X- _ O
by -X- _ O
the -X- _ O
authors -X- _ O
. -X- _ O
Resulting -X- _ O
accuracies -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
only -X- _ O
some -X- _ O
models -X- _ O
perform -X- _ O
substantially -X- _ O
above -X- _ O
chance -X- _ O
, -X- _ O
notably -X- _ O
ViLT -X- _ B-MethodName
, -X- _ O
UNITER -X- _ B-MethodName
and -X- _ O
LXMERT -X- _ B-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
cropped -X- _ O
task -X- _ O
, -X- _ O
performance -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
, -X- _ O
with -X- _ O
VinVL -X- _ B-MethodName
and -X- _ O
ViLT -X- _ B-MethodName
reaching -X- _ O
the -X- _ O
highest -X- _ O
performance -X- _ O
. -X- _ O
This -X- _ O
gap -X- _ O
in -X- _ O
performance -X- _ O
between -X- _ O
the -X- _ O
full -X- _ O
andcropped -X- _ O
tasks -X- _ O
indicates -X- _ O
that -X- _ O
while -X- _ O
those -X- _ O
models -X- _ O
can -X- _ O
match -X- _ O
nouns -X- _ O
and -X- _ O
predicates -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
words -X- _ O
rather -X- _ O
well -X- _ O
, -X- _ O
they -X- _ O
struggle -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
Accuracy -X- _ B-MetricName
Model -X- _ O
Full -X- _ B-TaskName
Cropped -X- _ B-TaskName
LXMERT -X- _ B-MethodName
0.57 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.69 -X- _ I-MetricValue
UNITER -X- _ B-MethodName
0.54 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.64 -X- _ I-MetricValue
ViLBERT -X- _ B-MethodName
0.28 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.66 -X- _ I-MetricValue
ViLT -X- _ B-MethodName
0.40 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.75 -X- _ I-MetricValue
Oscar -X- _ B-MethodName
0.32 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.67 -X- _ I-MetricValue
VinVL -X- _ B-MethodName
0.30 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.76 -X- _ I-MetricValue
CLIP -X- _ B-MethodName
0.20 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.59 -X- _ I-MetricValue
Chance -X- _ O
0.25 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.25 -X- _ I-MetricValue
4.2 -X- _ B-MetricValue
Controlled -X- _ O
Training -X- _ O
Conditions -X- _ O
We -X- _ O
additionally -X- _ O
evaluate -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
trained -X- _ O
in -X- _ O
controlled -X- _ O
( -X- _ O
and -X- _ O
therefore -X- _ O
more -X- _ O
directly -X- _ O
comparable -X- _ O
) -X- _ O
conditions -X- _ O
as -X- _ O
proposed -X- _ O
in -X- _ O
the -X- _ O
VOLTA -X- _ O
framework -X- _ O
( -X- _ O
Bugliarello -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setup -X- _ O
, -X- _ O
all1542models -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
Conceptual -X- _ O
Captions -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
pretraining -X- _ O
objectives -X- _ O
( -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
masked -X- _ O
object -X- _ O
classification -X- _ O
, -X- _ O
and -X- _ O
imagetext -X- _ O
matching -X- _ O
) -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
image -X- _ O
features -X- _ O
, -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
all -X- _ O
models -X- _ O
for -X- _ O
which -X- _ O
pretrained -X- _ O
weights -X- _ O
are -X- _ O
available -X- _ O
. -X- _ O
Resulting -X- _ O
accuracy -X- _ O
scores -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Accuracy -X- _ B-MetricName
Model -X- _ O
Full -X- _ B-TaskName
Cropped -X- _ B-TaskName
CTRL_UNITER -X- _ B-MethodName
0.24 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.63 -X- _ I-MetricValue
CTRL_LXMERT -X- _ B-MethodName
0.20 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.56 -X- _ I-MetricValue
CTRL_ViLBERT -X- _ B-MethodName
0.27 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.66 -X- _ I-MetricValue
CTRL_VL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
0.24 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.66 -X- _ I-MetricValue
CTRL_VisualBERT -X- _ B-MethodName
0.20 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.64 -X- _ I-MetricValue
Chance -X- _ O
0.25 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.25 -X- _ I-MetricValue
We -X- _ O
find -X- _ O
that -X- _ O
under -X- _ O
these -X- _ O
controlled -X- _ O
conditions -X- _ O
, -X- _ O
all -X- _ O
models -X- _ O
perform -X- _ O
comparably -X- _ O
and -X- _ O
generally -X- _ O
around -X- _ O
chance -X- _ O
level -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
therefore -X- _ O
not -X- _ O
straightforward -X- _ O
to -X- _ O
draw -X- _ O
any -X- _ O
conclusions -X- _ O
regarding -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
from -X- _ O
these -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
cropped -X- _ O
task -X- _ O
, -X- _ O
performance -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
, -X- _ O
with -X- _ O
ViLBERT -X- _ B-MethodName
and -X- _ O
VL -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
reaching -X- _ O
the -X- _ O
highest -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
tasks -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
full -X- _ O
vs.cropped -X- _ O
) -X- _ O
is -X- _ O
substantially -X- _ O
larger -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
original -X- _ O
implementations -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
even -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
under -X- _ O
these -X- _ O
controlled -X- _ O
training -X- _ O
conditions -X- _ O
. -X- _ O
5 -X- _ O
Analyses -X- _ O
and -X- _ O
Discussion -X- _ O
5.1 -X- _ O
Comparing -X- _ O
Model -X- _ O
Performances -X- _ O
The -X- _ O
role -X- _ O
of -X- _ O
pretraining -X- _ O
data -X- _ O
Within -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
evaluated -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
find -X- _ O
evidence -X- _ O
for -X- _ O
a -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
pretraining -X- _ O
dataset -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
predicatenoun -X- _ O
dependencies -X- _ O
( -X- _ O
see -X- _ O
also -X- _ O
Appendix -X- _ O
A.3 -X- _ O
) -X- _ O
. -X- _ O
Despite -X- _ O
being -X- _ O
trained -X- _ O
on -X- _ O
comparable -X- _ O
or -X- _ O
even -X- _ O
larger -X- _ O
amounts -X- _ O
of -X- _ O
data -X- _ O
, -X- _ O
ViLT -X- _ B-MethodName
, -X- _ O
Oscar -X- _ B-MethodName
and -X- _ O
VinVL -X- _ B-MethodName
perform -X- _ O
substantially -X- _ O
worse -X- _ O
than -X- _ O
LXMERT -X- _ B-MethodName
and -X- _ O
UNITER -X- _ B-MethodName
. -X- _ O
CLIP -X- _ B-MethodName
performs -X- _ O
below -X- _ O
chance -X- _ O
level -X- _ O
, -X- _ O
despite -X- _ O
having -X- _ O
by -X- _ O
far -X- _ O
the -X- _ O
largest -X- _ O
pretraining -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
pretraining -X- _ O
data -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
is -X- _ O
not -X- _ O
publicly -X- _ O
available -X- _ O
, -X- _ O
but -X- _ O
as -X- _ O
it -X- _ O
was -X- _ O
automatically -X- _ O
scraped -X- _ O
fromthe -X- _ O
internet -X- _ O
we -X- _ O
believe -X- _ O
the -X- _ O
quality -X- _ O
( -X- _ O
i.e -X- _ O
descriptiveness -X- _ O
) -X- _ O
of -X- _ O
its -X- _ O
captions -X- _ O
to -X- _ O
be -X- _ O
comparable -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
Conceptual -X- _ O
Captions -X- _ O
. -X- _ O
In -X- _ O
additional -X- _ O
experiments -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A.4.1 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
models -X- _ O
trained -X- _ O
on -X- _ O
different -X- _ O
datasets -X- _ O
using -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
publicly -X- _ O
available -X- _ O
model -X- _ O
checkpoints -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
remains -X- _ O
below -X- _ O
chance -X- _ O
level -X- _ O
for -X- _ O
all -X- _ O
tested -X- _ O
checkpoints -X- _ O
. -X- _ O
This -X- _ O
might -X- _ O
be -X- _ O
because -X- _ O
all -X- _ O
available -X- _ O
checkpoints -X- _ O
are -X- _ O
all -X- _ O
trained -X- _ O
on -X- _ O
rather -X- _ O
noisy -X- _ O
data -X- _ O
, -X- _ O
or -X- _ O
because -X- _ O
the -X- _ O
architecture -X- _ O
and -X- _ O
pretraining -X- _ O
objectives -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
do -X- _ O
n’t -X- _ O
allow -X- _ O
it -X- _ O
to -X- _ O
learn -X- _ O
grounded -X- _ O
predicate -X- _ B-TaskName
- -X- _ I-TaskName
noun -X- _ I-TaskName
dependencies -X- _ I-TaskName
. -X- _ O
Datasets -X- _ O
that -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
highly -X- _ O
descriptive -X- _ O
captions -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
advantageous -X- _ O
for -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
noun -X- _ B-TaskName
- -X- _ I-TaskName
predicate -X- _ I-TaskName
dependencies -X- _ I-TaskName
. -X- _ O
Indeed -X- _ O
, -X- _ O
for -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
COCO -X- _ O
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
or -X- _ O
VQA -X- _ O
( -X- _ O
Antol -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
images -X- _ O
are -X- _ O
not -X- _ O
only -X- _ O
strongly -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
captions -X- _ O
or -X- _ O
question -X- _ O
– -X- _ O
answer -X- _ O
pairs -X- _ O
( -X- _ O
as -X- _ O
they -X- _ O
were -X- _ O
crowdsourced -X- _ O
specifically -X- _ O
for -X- _ O
the -X- _ O
tasks -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
precise -X- _ O
and -X- _ O
detailed -X- _ O
in -X- _ O
nature -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
Conceptual -X- _ O
Captions -X- _ O
( -X- _ O
Sharma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
images -X- _ O
with -X- _ O
captions -X- _ O
that -X- _ O
were -X- _ O
automatically -X- _ O
collected -X- _ O
from -X- _ O
web -X- _ O
pages -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
generally -X- _ O
rather -X- _ O
broad -X- _ O
descriptions -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
content -X- _ O
. -X- _ O
ViLBERT -X- _ B-MethodName
and -X- _ O
models -X- _ O
trained -X- _ O
in -X- _ O
the -X- _ O
controlled -X- _ O
conditions -X- _ O
are -X- _ O
only -X- _ O
trained -X- _ O
using -X- _ O
Conceptual -X- _ O
Captions -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
resulting -X- _ O
performances -X- _ O
are -X- _ O
around -X- _ O
chance -X- _ O
level -X- _ O
. -X- _ O
UNITER -X- _ B-MethodName
and -X- _ O
LXMERT -X- _ B-MethodName
perform -X- _ O
much -X- _ O
worse -X- _ O
compared -X- _ O
to -X- _ O
their -X- _ O
original -X- _ O
training -X- _ O
setups -X- _ O
. -X- _ O
One -X- _ O
main -X- _ O
difference -X- _ O
for -X- _ O
these -X- _ O
two -X- _ O
models -X- _ O
in -X- _ O
their -X- _ O
original -X- _ O
implementation -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
controlled -X- _ O
condition -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
richer -X- _ O
datasets -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
modality -X- _ O
, -X- _ O
leveraging -X- _ O
more -X- _ O
descriptive -X- _ O
captions -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
is -X- _ O
coherent -X- _ O
with -X- _ O
what -X- _ O
Hendricks -X- _ O
and -X- _ O
Nematzadeh -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
found -X- _ O
when -X- _ O
studying -X- _ O
verb -X- _ O
understanding -X- _ O
of -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
: -X- _ O
They -X- _ O
compare -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
Conceptual -X- _ O
Captions -X- _ O
or -X- _ O
COCO -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
trained -X- _ O
on -X- _ O
COCO -X- _ O
performs -X- _ O
better -X- _ O
, -X- _ O
despite -X- _ O
Conceptual -X- _ O
Captions -X- _ O
being -X- _ O
bigger -X- _ O
and -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
image -X- _ O
and -X- _ O
language -X- _ O
distribution -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
, -X- _ O
when -X- _ O
considering -X- _ O
multimodal -X- _ O
dependencies -X- _ O
, -X- _ O
having -X- _ O
a -X- _ O
high -X- _ O
quality -X- _ O
pretraining -X- _ O
dataset -X- _ O
with -X- _ O
less -X- _ O
noise -X- _ O
and -X- _ O
more -X- _ O
de-1543scriptive -X- _ O
textual -X- _ O
data -X- _ O
could -X- _ O
be -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
having -X- _ O
a -X- _ O
larger -X- _ O
dataset -X- _ O
. -X- _ O
Highly -X- _ O
descriptive -X- _ O
textual -X- _ O
data -X- _ O
is -X- _ O
essential -X- _ O
to -X- _ O
learn -X- _ O
precise -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
. -X- _ O
The -X- _ O
role -X- _ O
of -X- _ O
pretraining -X- _ O
objectives -X- _ O
While -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
ViLT -X- _ B-MethodName
, -X- _ O
Oscar -X- _ B-MethodName
, -X- _ O
and -X- _ O
VinVL -X- _ B-MethodName
are -X- _ O
trained -X- _ O
on -X- _ O
datasets -X- _ O
that -X- _ O
are -X- _ O
comparable -X- _ O
in -X- _ O
size -X- _ O
and -X- _ O
quality -X- _ O
to -X- _ O
those -X- _ O
of -X- _ O
LXMERT -X- _ B-MethodName
and -X- _ O
UNITER -X- _ B-MethodName
, -X- _ O
they -X- _ O
still -X- _ O
perform -X- _ O
substantially -X- _ O
worse -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
One -X- _ O
explanation -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
contrary -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
UNITER -X- _ B-MethodName
and -X- _ O
LXMERT -X- _ B-MethodName
both -X- _ O
have -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
: -X- _ O
Visual -X- _ O
question -X- _ O
answering -X- _ O
for -X- _ O
LXMERT -X- _ B-MethodName
and -X- _ O
word -X- _ O
- -X- _ O
region -X- _ O
alignment -X- _ O
for -X- _ O
UNITER.This -X- _ B-MethodName
could -X- _ O
help -X- _ O
the -X- _ O
models -X- _ O
to -X- _ O
establish -X- _ O
finer -X- _ O
multimodal -X- _ O
dependencies -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
ViLT -X- _ B-MethodName
and -X- _ O
VinVL -X- _ B-MethodName
show -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
UNITER -X- _ B-MethodName
and -X- _ O
LXMERT -X- _ B-MethodName
in -X- _ O
the -X- _ O
cropped -X- _ B-TaskName
task -X- _ O
( -X- _ O
indicating -X- _ O
that -X- _ O
their -X- _ O
object -X- _ O
/ -X- _ O
predicate -X- _ O
recognition -X- _ O
performance -X- _ O
even -X- _ O
surpasses -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
worse -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
full -X- _ B-TaskName
task -X- _ O
. -X- _ O
Our -X- _ O
hypothesis -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
pretraining -X- _ O
objectives -X- _ O
of -X- _ O
UNITER -X- _ B-MethodName
and -X- _ O
LXMERT -X- _ B-MethodName
enable -X- _ O
them -X- _ O
to -X- _ O
learn -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
multimodal -X- _ O
dependencies -X- _ O
than -X- _ O
ViLT -X- _ B-MethodName
and -X- _ O
VinVL -X- _ B-MethodName
, -X- _ O
even -X- _ O
though -X- _ O
their -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
cropped -X- _ B-TaskName
task -X- _ O
is -X- _ O
worse -X- _ O
. -X- _ O
This -X- _ O
gap -X- _ O
in -X- _ O
performance -X- _ O
should -X- _ O
not -X- _ O
only -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
additional -X- _ O
pretraining -X- _ O
objectives -X- _ O
, -X- _ O
as -X- _ O
VinVL -X- _ B-MethodName
also -X- _ O
uses -X- _ O
data -X- _ O
from -X- _ O
Visual -X- _ O
Question -X- _ O
Answering -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
without -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
objective -X- _ O
. -X- _ O
The -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
of -X- _ O
UNITER -X- _ B-MethodName
and -X- _ O
LXMERT -X- _ B-MethodName
can -X- _ O
be -X- _ O
an -X- _ O
additional -X- _ O
explanation -X- _ O
for -X- _ O
the -X- _ O
drop -X- _ O
in -X- _ O
performance -X- _ O
of -X- _ O
CTRL_UNITER -X- _ B-MethodName
and -X- _ O
CTRL_LXMERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
were -X- _ O
only -X- _ O
trained -X- _ O
using -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
as -X- _ O
a -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objective -X- _ O
. -X- _ O
The -X- _ O
gap -X- _ O
in -X- _ O
performance -X- _ O
between -X- _ O
those -X- _ O
controlled -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
models -X- _ O
indicate -X- _ O
that -X- _ O
using -X- _ O
more -X- _ O
precise -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
and -X- _ O
better -X- _ O
annotated -X- _ O
datasets -X- _ O
can -X- _ O
greatly -X- _ O
improve -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
multimodal -X- _ O
dependencies -X- _ O
. -X- _ O
The -X- _ O
lack -X- _ O
of -X- _ O
suitable -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
could -X- _ O
also -X- _ O
offer -X- _ O
an -X- _ O
explanation -X- _ O
for -X- _ O
the -X- _ O
poor -X- _ O
performance -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
in -X- _ O
our -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
role -X- _ O
of -X- _ O
image -X- _ O
encoders -X- _ O
The -X- _ O
authors -X- _ O
of -X- _ O
ViLT -X- _ B-MethodName
and -X- _ O
VinVL -X- _ B-MethodName
motivate -X- _ O
their -X- _ O
work -X- _ O
by -X- _ O
suggesting -X- _ O
that -X- _ O
improved -X- _ O
image -X- _ O
features -X- _ O
are -X- _ O
mandatory -X- _ O
for -X- _ O
improved -X- _ O
multimodal -X- _ O
reasoning -X- _ O
of -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
transformers -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
these -X- _ O
improved -X- _ O
features -X- _ O
only -X- _ O
translate -X- _ O
to -X- _ O
better -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
cropped -X- _ B-TaskName
task -X- _ O
( -X- _ O
where -X- _ O
ViLT -X- _ B-MethodName
and -X- _ O
VinVL -X- _ B-MethodName
perform -X- _ O
best -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
the -X- _ O
improved -X- _ O
image -X- _ O
encoders -X- _ O
allow -X- _ O
for -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
visual -X- _ O
entities -X- _ O
, -X- _ O
but -X- _ O
not -X- _ O
necessarily -X- _ O
of -X- _ O
the -X- _ O
dependencies -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
more -X- _ O
conclusive -X- _ O
interpretations -X- _ O
regarding -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
image -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
require -X- _ O
more -X- _ O
targeted -X- _ O
experiments -X- _ O
which -X- _ O
control -X- _ O
for -X- _ O
other -X- _ O
confounding -X- _ O
factors -X- _ O
present -X- _ O
here -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
different -X- _ O
pretraining -X- _ O
objectives -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
role -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
suitable -X- _ O
pretraining -X- _ O
objectives -X- _ O
, -X- _ O
the -X- _ O
worse -X- _ O
performance -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
could -X- _ O
also -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
support -X- _ O
any -X- _ O
kind -X- _ O
of -X- _ O
inter -X- _ O
- -X- _ O
modal -X- _ O
fusion -X- _ O
of -X- _ O
features -X- _ O
within -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
are -X- _ O
processed -X- _ O
in -X- _ O
separate -X- _ O
submodules -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
allow -X- _ O
for -X- _ O
intermodal -X- _ O
interaction -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
shortcoming -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
is -X- _ O
also -X- _ O
discussed -X- _ O
in -X- _ O
Kim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
authors -X- _ O
find -X- _ O
representations -X- _ O
from -X- _ O
CLIP -X- _ B-MethodName
to -X- _ O
be -X- _ O
not -X- _ O
useful -X- _ O
for -X- _ O
the -X- _ O
more -X- _ O
advanced -X- _ O
multimodal -X- _ O
reasoning -X- _ O
task -X- _ O
NLVR2 -X- _ O
( -X- _ O
Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
seems -X- _ O
to -X- _ O
be -X- _ O
no -X- _ O
major -X- _ O
effect -X- _ O
of -X- _ O
architecture -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
multimodal -X- _ O
fusion -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
single -X- _ O
and -X- _ O
dual -X- _ O
stream -X- _ O
transformers -X- _ O
: -X- _ O
LXMERT -X- _ B-MethodName
and -X- _ O
UNITER -X- _ B-MethodName
have -X- _ O
comparable -X- _ O
performances -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
one -X- _ O
is -X- _ O
dual -X- _ O
- -X- _ O
stream -X- _ O
transformer -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
stream -X- _ O
transformer -X- _ O
. -X- _ O
5.2 -X- _ O
Performance -X- _ O
for -X- _ O
Nouns -X- _ O
vs. -X- _ O
Predicates -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
performance -X- _ O
for -X- _ O
pairs -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
sentences -X- _ O
differ -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
noun -X- _ O
, -X- _ O
to -X- _ O
sentences -X- _ O
with -X- _ O
a -X- _ O
different -X- _ O
predicate -X- _ O
. -X- _ O
Detailed -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Appendix -X- _ O
A.4.3 -X- _ O
. -X- _ O
Overall -X- _ O
patterns -X- _ O
show -X- _ O
a -X- _ O
slightly -X- _ O
better -X- _ O
performance -X- _ O
for -X- _ O
cases -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
noun -X- _ O
was -X- _ O
switched -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
cropped -X- _ B-TaskName
task -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
findings -X- _ O
that -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
are -X- _ O
better -X- _ O
at -X- _ O
grounding -X- _ O
nouns -X- _ O
than -X- _ O
verbs -X- _ O
( -X- _ O
Hendricks -X- _ O
and -X- _ O
Nematzadeh -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
5.3 -X- _ O
Analysis -X- _ O
of -X- _ O
individual -X- _ O
nouns -X- _ O
and -X- _ O
predicates -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
concept -X- _ O
( -X- _ O
noun -X- _ O
or -X- _ O
predicate -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
all -X- _ O
pairs -X- _ O
that -X- _ O
contain -X- _ O
this -X- _ O
concept -X- _ O
in -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
i.e. -X- _ O
cases -X- _ O
in -X- _ O
which -X- _ O
a1544model -X- _ O
’s -X- _ O
understanding -X- _ O
of -X- _ O
a -X- _ O
concept -X- _ O
is -X- _ O
instrumental -X- _ O
for -X- _ O
making -X- _ O
the -X- _ O
correct -X- _ O
decision -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
concept -X- _ O
accuracies -X- _ B-MetricName
of -X- _ O
the -X- _ O
best -X- _ O
performing -X- _ O
model -X- _ O
, -X- _ O
LXMERT -X- _ B-MethodName
. -X- _ O
Appendix -X- _ O
A.4.4 -X- _ O
shows -X- _ O
the -X- _ O
per -X- _ O
- -X- _ O
concept -X- _ O
accuracies -X- _ B-MetricName
for -X- _ O
all -X- _ O
models -X- _ O
in -X- _ O
their -X- _ O
original -X- _ O
implementations -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
large -X- _ O
variation -X- _ O
in -X- _ O
accuracy -X- _ O
scores -X- _ O
of -X- _ O
predicates -X- _ O
, -X- _ O
and -X- _ O
less -X- _ O
variation -X- _ O
for -X- _ O
nouns -X- _ O
. -X- _ O
We -X- _ O
could -X- _ O
not -X- _ O
find -X- _ O
any -X- _ O
simple -X- _ O
reasons -X- _ O
that -X- _ O
explain -X- _ O
the -X- _ O
predicates -X- _ O
’ -X- _ O
variability -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
verbs -X- _ O
can -X- _ O
have -X- _ O
good -X- _ O
or -X- _ O
bad -X- _ O
performances -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
running -X- _ O
” -X- _ O
vs -X- _ O
“ -X- _ O
talking -X- _ O
” -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
can -X- _ O
be -X- _ O
said -X- _ O
for -X- _ O
predicates -X- _ O
that -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
both -X- _ O
verb -X- _ O
and -X- _ O
noun -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
holding -X- _ O
a -X- _ O
bottle -X- _ O
” -X- _ O
vs. -X- _ O
“ -X- _ O
wearing -X- _ O
a -X- _ O
helmet -X- _ O
” -X- _ O
) -X- _ O
. -X- _ O
That -X- _ O
said -X- _ O
, -X- _ O
factors -X- _ O
that -X- _ O
may -X- _ O
influence -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
specific -X- _ O
nouns -X- _ O
or -X- _ O
predicates -X- _ O
are -X- _ O
further -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
5.4 -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
for -X- _ O
some -X- _ O
concepts -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
perform -X- _ O
better -X- _ O
if -X- _ O
the -X- _ O
concept -X- _ O
is -X- _ O
the -X- _ O
target -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
others -X- _ O
, -X- _ O
performance -X- _ O
is -X- _ O
better -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
distractor -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
case -X- _ O
for -X- _ O
the -X- _ O
pair -X- _ O
“ -X- _ O
sing -X- _ O
” -X- _ O
vs -X- _ O
“ -X- _ O
stand -X- _ O
” -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
models -X- _ O
consistently -X- _ O
perform -X- _ O
better -X- _ O
if -X- _ O
“ -X- _ O
sing -X- _ O
” -X- _ O
is -X- _ O
the -X- _ O
target -X- _ O
predicate -X- _ O
. -X- _ O
Appendix -X- _ O
A.4.5 -X- _ O
shows -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
each -X- _ O
( -X- _ O
target -X- _ O
, -X- _ O
distractor -X- _ O
) -X- _ O
concept -X- _ O
tuple.5.4 -X- _ O
Confounding -X- _ O
Factors -X- _ O
Here -X- _ O
we -X- _ O
discuss -X- _ O
possible -X- _ O
factors -X- _ O
influencing -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
performances -X- _ O
. -X- _ O
Object -X- _ O
salience -X- _ O
In -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
images -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
persons -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
are -X- _ O
not -X- _ O
of -X- _ O
equal -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
equally -X- _ O
salient -X- _ O
( -X- _ O
sometimes -X- _ O
one -X- _ O
is -X- _ O
more -X- _ O
in -X- _ O
the -X- _ O
foreground -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
explore -X- _ O
whether -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
decisions -X- _ O
by -X- _ O
correlating -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
predictions -X- _ O
with -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
bounding -X- _ O
box -X- _ O
size -X- _ O
and -X- _ O
location -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
similarity -X- _ O
for -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentence -X- _ O
s -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
−s -X- _ O
( -X- _ O
I -X- _ O
, -X- _ O
S -X- _ O
) -X- _ O
and -X- _ O
correlate -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
bounding -X- _ O
box -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
object -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
correlate -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
distances -X- _ O
from -X- _ O
the -X- _ O
center -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
For -X- _ O
LXMERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
find -X- _ O
no -X- _ O
significant -X- _ O
correlation -X- _ O
( -X- _ O
Bounding -X- _ O
box -X- _ O
size -X- _ O
: -X- _ O
Pearson -X- _ O
r=−0.03 -X- _ B-MetricName
, -X- _ O
p= -X- _ O
0.16 -X- _ O
, -X- _ O
bounding -X- _ O
box -X- _ O
distance -X- _ O
from -X- _ O
center -X- _ O
: -X- _ O
Pearson -X- _ O
r= -X- _ B-MetricName
0.03 -X- _ B-MetricValue
, -X- _ O
p= -X- _ O
0.14 -X- _ O
) -X- _ O
. -X- _ O
Correlation -X- _ O
scores -X- _ O
for -X- _ O
other -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.4.6 -X- _ O
. -X- _ O
While -X- _ O
there -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
correlations -X- _ O
for -X- _ O
some -X- _ O
models -X- _ O
, -X- _ O
these -X- _ O
are -X- _ O
small -X- _ O
and -X- _ O
of -X- _ O
varying -X- _ O
direction -X- _ O
. -X- _ O
The -X- _ O
largest -X- _ O
correlations -X- _ O
are -X- _ O
found -X- _ O
for -X- _ O
CLIP -X- _ B-MethodName
( -X- _ O
Bounding -X- _ O
box -X- _ O
size -X- _ O
: -X- _ O
Pearson -X- _ O
r= -X- _ B-MetricName
0.14 -X- _ B-MetricValue
, -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
, -X- _ O
bounding -X- _ O
box -X- _ O
distance -X- _ O
from -X- _ O
center -X- _ O
: -X- _ O
Pearson -X- _ O
r= -X- _ B-MetricName
−0.24 -X- _ B-MetricValue
, -X- _ O
p -X- _ O
< -X- _ O
0.01 -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CLIP -X- _ B-MethodName
could -X- _ O
be -X- _ O
affected -X- _ O
, -X- _ O
to -X- _ O
some -X- _ O
extent -X- _ O
, -X- _ O
by -X- _ O
object -X- _ O
salience -X- _ O
. -X- _ O
Concept -X- _ O
recognizability -X- _ O
We -X- _ O
also -X- _ O
correlate -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
similarity -X- _ O
judgments -X- _ O
differences -X- _ O
to -X- _ O
differences -X- _ O
in -X- _ O
concept -X- _ O
recognizability -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
operationalize -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
object -X- _ O
or -X- _ O
attribute -X- _ O
confidence -X- _ B-MetricName
score -X- _ I-MetricName
for -X- _ O
a -X- _ O
given -X- _ O
concept -X- _ O
in -X- _ O
an -X- _ O
image -X- _ O
from -X- _ O
a -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
VisualGenome -X- _ O
. -X- _ O
For -X- _ O
most -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
a -X- _ O
small -X- _ O
positive -X- _ O
correlation -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A.4.6 -X- _ O
) -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
similarity -X- _ O
judgments -X- _ O
are -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
varying -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
concepts -X- _ O
are -X- _ O
recognizable -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
Linguistic -X- _ O
biases -X- _ O
Another -X- _ O
aspect -X- _ O
, -X- _ O
already -X- _ O
mentioned -X- _ O
earlier -X- _ O
, -X- _ O
is -X- _ O
that -X- _ O
models -X- _ O
’ -X- _ O
performance -X- _ O
could -X- _ O
be -X- _ O
affected -X- _ O
by -X- _ O
linguistic -X- _ O
biases -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
frequency -X- _ O
and -X- _ O
co -X- _ O
- -X- _ O
occurrence -X- _ O
of -X- _ O
words -X- _ O
and -X- _ O
phrases.1545To -X- _ O
explore -X- _ O
this -X- _ O
possible -X- _ O
effect -X- _ O
, -X- _ O
we -X- _ O
correlate -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
similarity -X- _ O
for -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentence -X- _ O
with -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentence -X- _ O
perplexity -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
the -X- _ O
perplexity -X- _ B-MetricName
for -X- _ O
each -X- _ O
sentence -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
modality -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
bert -X- _ O
- -X- _ O
base -X- _ O
- -X- _ O
uncased -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
was -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
on -X- _ O
the -X- _ O
textual -X- _ O
data -X- _ O
of -X- _ O
Conceptual -X- _ O
Captions -X- _ O
. -X- _ O
For -X- _ O
LXMERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
find -X- _ O
no -X- _ O
significant -X- _ O
correlation -X- _ O
( -X- _ O
Pearson -X- _ O
r=−0.01 -X- _ B-MetricName
, -X- _ O
p= -X- _ O
0.48 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
very -X- _ O
small -X- _ O
positive -X- _ O
correlations -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A.4.6 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
only -X- _ O
on -X- _ O
shallow -X- _ O
heuristics -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
textual -X- _ O
modality -X- _ O
. -X- _ O
6 -X- _ O
Conclusion -X- _ O
This -X- _ O
work -X- _ O
examines -X- _ O
whether -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
learn -X- _ O
multimodal -X- _ O
syntactic -X- _ O
dependencies -X- _ O
, -X- _ O
by -X- _ O
focusing -X- _ O
on -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
on -X- _ O
simple -X- _ O
predicatenoun -X- _ B-TaskName
dependencies -X- _ I-TaskName
. -X- _ O
Our -X- _ O
controlled -X- _ O
experiments -X- _ O
and -X- _ O
analyses -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
recent -X- _ O
models -X- _ O
reveal -X- _ O
that -X- _ O
their -X- _ O
capability -X- _ O
track -X- _ O
such -X- _ O
dependencies -X- _ O
is -X- _ O
variable -X- _ O
, -X- _ O
with -X- _ O
some -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
LXMERT -X- _ B-MethodName
and -X- _ O
UNITER -X- _ B-MethodName
) -X- _ O
show -X- _ O
performance -X- _ O
above -X- _ O
chance -X- _ O
level -X- _ O
and -X- _ O
others -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CLIP -X- _ B-MethodName
) -X- _ O
performing -X- _ O
even -X- _ O
below -X- _ O
chance -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
recent -X- _ O
trend -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
focused -X- _ O
on -X- _ O
increasing -X- _ O
pretraining -X- _ O
data -X- _ O
and -X- _ O
using -X- _ O
simple -X- _ O
general -X- _ O
- -X- _ O
purpose -X- _ O
pretraining -X- _ O
objectives -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
here -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
best -X- _ O
performance -X- _ O
is -X- _ O
achieved -X- _ O
, -X- _ O
rather -X- _ O
, -X- _ O
with -X- _ O
highquality -X- _ O
pretraining -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
pretraining -X- _ O
objectives -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
multimodal -X- _ O
pretraining -X- _ O
objectives -X- _ O
have -X- _ O
a -X- _ O
major -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
learning -X- _ O
of -X- _ O
grounded -X- _ O
predicatenoun -X- _ O
dependencies -X- _ O
. -X- _ O
Models -X- _ O
that -X- _ O
include -X- _ O
more -X- _ O
targeted -X- _ O
objectives -X- _ O
such -X- _ O
as -X- _ O
visual -X- _ O
question -X- _ O
answering -X- _ O
and -X- _ O
word -X- _ O
region -X- _ O
alignment -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
general -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
matching -X- _ O
objective -X- _ O
show -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
having -X- _ O
highly -X- _ O
descriptive -X- _ O
pretraining -X- _ O
datasets -X- _ O
seems -X- _ O
to -X- _ O
help -X- _ O
with -X- _ O
learning -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
multimodal -X- _ O
dependencies -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
larger -X- _ O
, -X- _ O
web -X- _ O
- -X- _ O
scraped -X- _ O
datasets -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
well -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
highly -X- _ O
- -X- _ O
controlled -X- _ O
evaluation -X- _ O
protocol -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
conduct -X- _ O
more -X- _ O
targeted -X- _ O
studies -X- _ O
regarding -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
, -X- _ O
pretraining -X- _ O
objectives -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
training -X- _ O
data -X- _ O
quality -X- _ O
and -X- _ O
quantity -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
build -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
better -X- _ O
at -X- _ O
learning -X- _ O
grounded -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
, -X- _ O
and -X- _ O
possibly -X- _ O
also -X- _ O
other -X- _ O
, -X- _ O
move -X- _ O
advanced -X- _ O
multimodal -X- _ O
reasoning -X- _ O
tasks.7 -X- _ O
Limitations -X- _ O
While -X- _ O
our -X- _ O
analyses -X- _ O
revealed -X- _ O
patterns -X- _ O
that -X- _ O
seems -X- _ O
to -X- _ O
explain -X- _ O
observed -X- _ O
variability -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
’ -X- _ O
performance -X- _ O
, -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
some -X- _ O
architectural -X- _ O
choices -X- _ O
such -X- _ O
as -X- _ O
image -X- _ O
encoding -X- _ O
techniques -X- _ O
remains -X- _ O
ambiguous -X- _ O
. -X- _ O
A -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
all -X- _ O
factors -X- _ O
influencing -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
grounded -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
could -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
training -X- _ O
sets -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
comparable -X- _ O
conditions -X- _ O
and -X- _ O
by -X- _ O
varying -X- _ O
only -X- _ O
one -X- _ O
factor -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
( -X- _ O
as -X- _ O
done -X- _ O
for -X- _ O
example -X- _ O
in -X- _ O
Bugliarello -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
, -X- _ O
regarding -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
range -X- _ O
of -X- _ O
concepts -X- _ O
evaluated -X- _ O
is -X- _ O
rather -X- _ O
small -X- _ O
and -X- _ O
therefore -X- _ O
not -X- _ O
representative -X- _ O
for -X- _ O
the -X- _ O
understanding -X- _ O
of -X- _ O
grounded -X- _ O
predicate -X- _ O
- -X- _ O
noun -X- _ O
dependencies -X- _ O
in -X- _ O
general -X- _ O
. -X- _ O
More -X- _ O
targeted -X- _ O
data -X- _ O
collection -X- _ O
will -X- _ O
be -X- _ O
necessary -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
more -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
evaluation -X- _ O
datasets -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
evaluation -X- _ O
paradigm -X- _ O
introduces -X- _ O
a -X- _ O
possible -X- _ O
mismatch -X- _ O
between -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
: -X- _ O
Models -X- _ O
are -X- _ O
trained -X- _ O
using -X- _ O
pairs -X- _ O
of -X- _ O
images -X- _ O
and -X- _ O
descriptions -X- _ O
where -X- _ O
the -X- _ O
descriptions -X- _ O
often -X- _ O
describe -X- _ O
allsalient -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
, -X- _ O
whereas -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
set -X- _ O
the -X- _ O
descriptions -X- _ O
focus -X- _ O
on -X- _ O
only -X- _ O
oneaspect -X- _ O
/ -X- _ O
person -X- _ O
in -X- _ O
the -X- _ O
image -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
cropped -X- _ O
condition -X- _ O
, -X- _ O
the -X- _ O
images -X- _ O
are -X- _ O
not -X- _ O
are -X- _ O
not -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
typical -X- _ O
photographic -X- _ O
framing -X- _ O
of -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
corpora -X- _ O
, -X- _ O
which -X- _ O
could -X- _ O
deteriorate -X- _ O
our -X- _ O
results -X- _ O
. -X- _ O
That -X- _ O
said -X- _ O
, -X- _ O
random -X- _ O
cropping -X- _ O
is -X- _ O
a -X- _ O
frequent -X- _ O
data -X- _ O
augmentation -X- _ O
technique -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
research -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
improve -X- _ O
generalization -X- _ O
performance -X- _ O
( -X- _ O
Krizhevsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
some -X- _ O
scenes -X- _ O
, -X- _ O
actions -X- _ O
and -X- _ O
cultures -X- _ O
are -X- _ O
disproportionally -X- _ O
represented -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
dataset -X- _ O
. -X- _ O
As -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
pursue -X- _ O
further -X- _ O
work -X- _ O
on -X- _ O
more -X- _ O
diverse -X- _ O
datasets.15468 -X- _ O
Ethics -X- _ O
Statement -X- _ O
The -X- _ O
proposed -X- _ O
evaluation -X- _ O
set -X- _ O
relies -X- _ O
on -X- _ O
subjective -X- _ O
annotations -X- _ O
of -X- _ O
perceived -X- _ O
gender -X- _ O
. -X- _ O
Attempting -X- _ O
to -X- _ O
classify -X- _ O
gender -X- _ O
based -X- _ O
on -X- _ O
physical -X- _ O
appearance -X- _ O
is -X- _ O
an -X- _ O
illposed -X- _ O
problem -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
limitations -X- _ O
of -X- _ O
object -X- _ O
detectors -X- _ O
, -X- _ O
biases -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
annotators -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
the -X- _ O
annotations -X- _ O
only -X- _ O
consider -X- _ O
binary -X- _ O
gender -X- _ O
classes -X- _ O
( -X- _ O
woman -X- _ O
/ -X- _ O
man -X- _ O
, -X- _ O
girl -X- _ O
/ -X- _ O
boy -X- _ O
) -X- _ O
. -X- _ O
Algorithms -X- _ O
that -X- _ O
perform -X- _ O
such -X- _ O
classifications -X- _ O
are -X- _ O
neither -X- _ O
ideal -X- _ O
nor -X- _ O
desirable -X- _ O
, -X- _ O
as -X- _ O
they -X- _ O
perpetuate -X- _ O
harmful -X- _ O
stereotypes -X- _ O
and -X- _ O
exclude -X- _ O
non -X- _ O
- -X- _ O
binary -X- _ O
gender -X- _ O
identities -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Dev -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Hamidi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Blodgett -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bender -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
explored -X- _ O
whether -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
use -X- _ O
other -X- _ O
classes -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
find -X- _ O
many -X- _ O
examples -X- _ O
that -X- _ O
would -X- _ O
allow -X- _ O
for -X- _ O
an -X- _ O
evaluation -X- _ O
of -X- _ O
sensitivity -X- _ O
to -X- _ O
predicate -X- _ B-TaskName
- -X- _ I-TaskName
noun -X- _ I-TaskName
dependencies -X- _ I-TaskName
in -X- _ O
a -X- _ O
controlled -X- _ O
fashion -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
image -X- _ O
selection -X- _ O
is -X- _ O
very -X- _ O
constrained -X- _ O
( -X- _ O
we -X- _ O
require -X- _ O
a -X- _ O
visual -X- _ O
distractor -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
counter -X- _ O
- -X- _ O
example -X- _ O
image -X- _ O
with -X- _ O
reverse -X- _ O
properties -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
only -X- _ O
sufficient -X- _ O
examples -X- _ O
for -X- _ O
the -X- _ O
categories -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
initially -X- _ O
started -X- _ O
a -X- _ O
bottom -X- _ O
- -X- _ O
up -X- _ O
data -X- _ O
exploration -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
considered -X- _ O
all -X- _ O
labels -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
Open -X- _ B-DatasetName
Images -X- _ I-DatasetName
dataset -X- _ O
, -X- _ O
but -X- _ O
found -X- _ O
only -X- _ O
very -X- _ O
few -X- _ O
examples -X- _ O
for -X- _ O
a -X- _ O
few -X- _ O
other -X- _ O
categories -X- _ O
( -X- _ O
generally -X- _ O
less -X- _ O
than -X- _ O
5 -X- _ O
examples -X- _ O
after -X- _ O
manual -X- _ O
filtering -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
might -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
focus -X- _ O
of -X- _ O
the -X- _ O
annotations -X- _ O
in -X- _ O
Open -X- _ B-DatasetName
Images -X- _ I-DatasetName
, -X- _ O
future -X- _ O
work -X- _ O
could -X- _ O
explore -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
other -X- _ O
datasets -X- _ O
that -X- _ O
are -X- _ O
focused -X- _ O
on -X- _ O
other -X- _ O
types -X- _ O
of -X- _ O
annotations -X- _ O
, -X- _ O
the -X- _ O
main -X- _ O
challenge -X- _ O
being -X- _ O
the -X- _ O
requirement -X- _ O
for -X- _ O
sufficiently -X- _ O
large -X- _ O
datasets -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
find -X- _ O
matching -X- _ O
examples -X- _ O
and -X- _ O
counter -X- _ O
- -X- _ O
examples -X- _ O
. -X- _ O
Future -X- _ O
efforts -X- _ O
should -X- _ O
be -X- _ O
dedicated -X- _ O
to -X- _ O
creating -X- _ O
datasets -X- _ O
that -X- _ O
aim -X- _ O
at -X- _ O
more -X- _ O
inclusive -X- _ O
annotations -X- _ O
. -X- _ O
We -X- _ O
acknowledge -X- _ O
the -X- _ O
severity -X- _ O
of -X- _ O
these -X- _ O
issues -X- _ O
, -X- _ O
and -X- _ O
emphasize -X- _ O
that -X- _ O
our -X- _ O
work -X- _ O
does -X- _ O
not -X- _ O
promote -X- _ O
applications -X- _ O
of -X- _ O
gender -X- _ O
classification -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
uses -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
basis -X- _ O
for -X- _ O
analysis -X- _ O
of -X- _ O
existing -X- _ O
models -X- _ O
. -X- _ O
9 -X- _ O
Acknowledgements -X- _ O
We -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
useful -X- _ O
comments -X- _ O
and -X- _ O
feedback -X- _ O
. -X- _ O
Research -X- _ O
supported -X- _ O
by -X- _ O
grants -X- _ O
ANR-16 -X- _ O
- -X- _ O
CONV0002 -X- _ O
( -X- _ O
ILCB -X- _ O
) -X- _ O
, -X- _ O
ANR-11 -X- _ O
- -X- _ O
LABX-0036 -X- _ O
( -X- _ O
BLRI -X- _ O
) -X- _ O
, -X- _ O
ANR21 -X- _ O
- -X- _ O
CE28 -X- _ O
- -X- _ O
0005 -X- _ O
- -X- _ O
01 -X- _ O
( -X- _ O
MACOMIC -X- _ O
) -X- _ O
, -X- _ O
AMX-19 -X- _ O
- -X- _ O
IET009 -X- _ O
( -X- _ O
Archimedes -X- _ O
Institute -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Excellence -X- _ O
Initiative -X- _ O
of -X- _ O
Aix -X- _ O
- -X- _ O
Marseille -X- _ O
University -X- _ O
( -X- _ O
A*MIDEX -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
performed -X- _ O
using -X- _ O
HPC -X- _ O
resources -X- _ O
from -X- _ O
GENCI -X- _ O
– -X- _ O
IDRIS -X- _ O
( -X- _ O
Grant -X- _ O
2021- -X- _ O
[ -X- _ O
101693 -X- _ O
] -X- _ O
) -X- _ O
.References1547154815491550A -X- _ O
Appendix -X- _ O
A.1 -X- _ O
Image -X- _ O
Pre -X- _ O
- -X- _ O
Filtering -X- _ O
We -X- _ O
consider -X- _ O
labels -X- _ O
that -X- _ O
occur -X- _ O
at -X- _ O
least -X- _ O
100 -X- _ O
times -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
As -X- _ O
some -X- _ O
labels -X- _ O
are -X- _ O
similar -X- _ O
and -X- _ O
sometimes -X- _ O
used -X- _ O
interchangeably -X- _ O
by -X- _ O
the -X- _ O
annotators -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
groups -X- _ O
of -X- _ O
synonyms -X- _ O
for -X- _ O
some -X- _ O
labels -X- _ O
and -X- _ O
treat -X- _ O
labels -X- _ O
within -X- _ O
a -X- _ O
group -X- _ O
as -X- _ O
identical -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O
The -X- _ O
groups -X- _ O
of -X- _ O
synonyms -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
verify -X- _ O
that -X- _ O
the -X- _ O
bounding -X- _ O
boxes -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
objects -X- _ O
are -X- _ O
big -X- _ O
enough -X- _ O
( -X- _ O
at -X- _ O
least -X- _ O
20 -X- _ O
% -X- _ O
width -X- _ O
and -X- _ O
20 -X- _ O
% -X- _ O
height -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
) -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
bounding -X- _ O
box -X- _ O
sizes -X- _ O
of -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
objects -X- _ O
do -X- _ O
n’t -X- _ O
differ -X- _ O
by -X- _ O
more -X- _ O
than -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
2 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
ensure -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
counter -X- _ O
- -X- _ O
example -X- _ O
for -X- _ O
each -X- _ O
triplet -X- _ O
before -X- _ O
starting -X- _ O
the -X- _ O
manual -X- _ O
image -X- _ O
selection -X- _ O
phase -X- _ O
. -X- _ O
“ -X- _ O
Table -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Desk -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Coffee -X- _ O
table -X- _ O
” -X- _ O
“ -X- _ O
Mug -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Coffee -X- _ O
cup -X- _ O
” -X- _ O
“ -X- _ O
Glasses -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Sunglasses -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Goggles -X- _ O
” -X- _ O
“ -X- _ O
Sun -X- _ O
hat -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Fedora -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Cowboy -X- _ O
hat -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Sombrero -X- _ O
” -X- _ O
“ -X- _ O
Bicycle -X- _ O
helmet -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Football -X- _ O
helmet -X- _ O
” -X- _ O
“ -X- _ O
High -X- _ O
heels -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Sandal -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Boot -X- _ O
” -X- _ O
“ -X- _ O
Racket -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Tennis -X- _ O
racket -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Table -X- _ O
tennis -X- _ O
racket -X- _ O
” -X- _ O
“ -X- _ O
Crown -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Tiara -X- _ O
” -X- _ O
“ -X- _ O
Handbag -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Briefcase -X- _ O
” -X- _ O
“ -X- _ O
Cart -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Golf -X- _ O
cart -X- _ O
” -X- _ O
“ -X- _ O
Tree -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Palm -X- _ O
tree -X- _ O
” -X- _ O
“ -X- _ O
Football -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
V -X- _ O
olleyball -X- _ O
( -X- _ O
Ball -X- _ O
) -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Rugby -X- _ O
ball -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
Cricket -X- _ O
ball -X- _ O
” -X- _ O
, -X- _ O
Tennis -X- _ O
ball -X- _ O
” -X- _ O
A.2 -X- _ O
Dataset -X- _ O
statistics -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
triplets -X- _ O
for -X- _ O
each -X- _ O
noun -X- _ O
and -X- _ O
predicate -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
noun -X- _ O
or -X- _ O
predicate -X- _ O
, -X- _ O
we -X- _ O
count -X- _ O
all -X- _ O
pairs -X- _ O
that -X- _ O
contain -X- _ O
this -X- _ O
concept -X- _ O
in -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
i.e. -X- _ O
cases -X- _ O
in -X- _ O
which -X- _ O
correct -X- _ O
understanding -X- _ O
of -X- _ O
a -X- _ O
concept -X- _ O
is -X- _ O
useful -X- _ O
for -X- _ O
making -X- _ O
the -X- _ O
correct -X- _ O
decisions -X- _ O
. -X- _ O
A.3 -X- _ O
Details -X- _ O
on -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
Models -X- _ O
A.3.1 -X- _ O
Pretraining -X- _ O
Datasets -X- _ O
Table -X- _ O
4 -X- _ O
details -X- _ O
the -X- _ O
multimodal -X- _ O
datasets -X- _ O
used -X- _ O
for -X- _ O
V -X- _ O
& -X- _ O
L -X- _ O
models -X- _ O
. -X- _ O
Dataset -X- _ O
sizes -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
papers -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
these -X- _ O
sizes -X- _ O
are -X- _ O
also -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
some -X- _ O
models -X- _ O
leverage -X- _ O
validation -X- _ O
sets -X- _ O
for -X- _ O
pretraining -X- _ O
, -X- _ O
while -X- _ O
others -X- _ O
constrain -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
different -X- _ O
approaches -X- _ O
for -X- _ O
dataset -X- _ O
overlap -X- _ O
detection -X- _ O
have -X- _ O
been -X- _ O
applied -X- _ O
. -X- _ O
The -X- _ O
pretraining -X- _ O
data -X- _ O
size -X- _ O
for -X- _ O
CLIP -X- _ B-MethodName
is -X- _ O
reportedly -X- _ O
400 -X- _ O
M -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
. -X- _ O
A.3.2 -X- _ O
Number -X- _ O
of -X- _ O
parameters -X- _ O
Table -X- _ O
5 -X- _ O
compares -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
that -X- _ O
was -X- _ O
tested -X- _ O
in -X- _ O
their -X- _ O
original -X- _ O
implementations -X- _ O
. -X- _ O
A.4 -X- _ O
Additional -X- _ O
Analyses -X- _ O
A.4.1 -X- _ O
Results -X- _ O
for -X- _ O
CLIP -X- _ B-MethodName
with -X- _ O
varying -X- _ O
pretraining -X- _ O
data -X- _ O
Table -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
accuracy -X- _ O
scores -X- _ O
of -X- _ O
multiple -X- _ O
publicly -X- _ O
available -X- _ O
checkpoints -X- _ O
for -X- _ O
CLIP -X- _ B-MethodName
trained -X- _ O
on -X- _ O
different -X- _ O
training -X- _ O
data.1551Total -X- _ O
size -X- _ O
Model -X- _ O
CC -X- _ O
COCO -X- _ O
SBU -X- _ O
VG -X- _ O
QA -X- _ O
F30 -X- _ O
K -X- _ O
OI -X- _ O
# -X- _ O
images -X- _ O
# -X- _ O
image -X- _ O
- -X- _ O
text -X- _ O
pairs -X- _ O
LXMERT -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
0.18 -X- _ O
M -X- _ O
9.18 -X- _ O
M -X- _ O
UNITER -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
4.16 -X- _ O
M -X- _ O
9.59 -X- _ O
M -X- _ O
ViLBERT -X- _ O
✓ -X- _ O
3.10 -X- _ O
M -X- _ O
3.10 -X- _ O
M -X- _ O
ViLT -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
4.05 -X- _ O
M -X- _ O
9.85 -X- _ O
M -X- _ O
Oscar -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
4.10 -X- _ O
M -X- _ O
6.50 -X- _ O
M -X- _ O
VinVL -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
✓ -X- _ O
5.65 -X- _ O
M -X- _ O
8.85 -X- _ O
M -X- _ O
Model -X- _ O
# -X- _ O
Parameters -X- _ O
LXMERT -X- _ O
228,051,752 -X- _ O
UNITER -X- _ O
112,938,887 -X- _ O
ViLBERT -X- _ O
250,044,029 -X- _ O
ViLT -X- _ O
111,596,546 -X- _ O
Oscar -X- _ O
111,062,018 -X- _ O
VinVL -X- _ O
111,686,973 -X- _ O
CLIP -X- _ O
151,277,313 -X- _ O
Visual -X- _ O
Encoder -X- _ O
Dataset -X- _ O
Accuracy -X- _ O
RN101 -X- _ O
YFCC-15 -X- _ O
M -X- _ O
0.18 -X- _ O
RN101 -X- _ O
400 -X- _ O
M -X- _ O
0.21 -X- _ O
RN50 -X- _ O
cc12 -X- _ O
m -X- _ O
0.18 -X- _ O
RN50 -X- _ O
400 -X- _ O
M -X- _ O
0.20 -X- _ O
RN50 -X- _ O
YFCC-15 -X- _ O
M -X- _ O
0.17 -X- _ O
ViT -X- _ O
- -X- _ O
B-32 -X- _ O
aion2b_e16 -X- _ O
0.21 -X- _ O
ViT -X- _ O
- -X- _ O
B-32 -X- _ O
laion400m_e31 -X- _ O
0.20 -X- _ O
ViT -X- _ O
- -X- _ O
B-32 -X- _ O
laion400m_e32 -X- _ O
0.19 -X- _ O
ViT -X- _ O
- -X- _ O
B-32 -X- _ O
400 -X- _ O
M -X- _ O
0.20 -X- _ O
ViT -X- _ O
- -X- _ O
L-14 -X- _ O
400 -X- _ O
M -X- _ O
( -X- _ O
336px -X- _ O
) -X- _ O
0.20 -X- _ O
A.4.2 -X- _ O
Controlling -X- _ O
for -X- _ O
linguistic -X- _ O
robustness -X- _ O
As -X- _ O
the -X- _ O
sentences -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
dataset -X- _ O
are -X- _ O
built -X- _ O
from -X- _ O
a -X- _ O
template -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
vary -X- _ O
in -X- _ O
syntax -X- _ O
. -X- _ O
We -X- _ O
verify -X- _ O
that -X- _ O
results -X- _ O
obtained -X- _ O
do -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
exact -X- _ O
template -X- _ O
chosen -X- _ O
. -X- _ O
We -X- _ O
vary -X- _ O
the -X- _ O
original -X- _ O
templates -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
definite -X- _ O
article -X- _ O
( -X- _ O
“ -X- _ O
the -X- _ O
” -X- _ O
) -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
using -X- _ O
verbs -X- _ O
in -X- _ O
simple -X- _ O
present -X- _ O
instead -X- _ O
of -X- _ O
present -X- _ O
progressive -X- _ O
tense -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
the -X- _ O
woman -X- _ O
sits -X- _ O
. -X- _ O
” -X- _ O
or -X- _ O
“ -X- _ O
the -X- _ O
man -X- _ O
holds -X- _ O
a -X- _ O
camera -X- _ O
. -X- _ O
” -X- _ O
) -X- _ O
.Results -X- _ O
with -X- _ O
these -X- _ O
alternative -X- _ O
sentences -X- _ O
are -X- _ O
show -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
overall -X- _ O
result -X- _ O
patterns -X- _ O
are -X- _ O
highly -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Accuracy -X- _ B-MetricName
Model -X- _ O
Full -X- _ B-TaskName
Cropped -X- _ B-TaskName
LXMERT -X- _ B-MethodName
0.55 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.70 -X- _ I-MetricValue
UNITER -X- _ B-MethodName
0.54 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.66 -X- _ I-MetricValue
ViLBERT -X- _ B-MethodName
0.26 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.67 -X- _ I-MetricValue
ViLT -X- _ B-MethodName
0.34 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.72 -X- _ I-MetricValue
Oscar -X- _ B-MethodName
0.32 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.65 -X- _ I-MetricValue
VinVL -X- _ B-MethodName
0.30 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.74 -X- _ I-MetricValue
CLIP -X- _ B-MethodName
0.21 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.58 -X- _ I-MetricValue
A.4.3 -X- _ O
Switching -X- _ O
noun -X- _ O
vs. -X- _ O
switching -X- _ O
predicate -X- _ O
Table -X- _ O
8 -X- _ O
presents -X- _ O
the -X- _ O
accuracy -X- _ O
for -X- _ O
cases -X- _ O
in -X- _ O
which -X- _ O
target -X- _ O
and -X- _ O
distractor -X- _ O
sentence -X- _ O
differ -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
predicate -X- _ O
, -X- _ O
or -X- _ O
noun -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
scores -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
in -X- _ O
their -X- _ O
original -X- _ O
implementations -X- _ O
. -X- _ O
A.4.4 -X- _ O
Analysis -X- _ O
of -X- _ O
individual -X- _ O
nouns -X- _ O
and -X- _ O
predicates -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
accuracies -X- _ B-MetricName
for -X- _ O
split -X- _ O
up -X- _ O
for -X- _ O
the -X- _ O
different -X- _ O
predicates -X- _ O
and -X- _ O
nouns -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
more -X- _ O
details -X- _ O
, -X- _ O
refer -X- _ O
to -X- _ O
Section -X- _ O
5.3 -X- _ O
. -X- _ O
A.4.5 -X- _ O
Accuracies -X- _ B-MetricName
for -X- _ O
( -X- _ O
target -X- _ O
, -X- _ O
distractor -X- _ O
) -X- _ O
tuples -X- _ O
Figure -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
accuracy -X- _ O
for -X- _ O
target -X- _ O
- -X- _ O
distractor -X- _ O
tuples -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O
A.4.6 -X- _ O
Confounding -X- _ O
Factors -X- _ O
In -X- _ O
Table -X- _ O
9 -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
correlation -X- _ O
scores -X- _ O
for -X- _ O
several -X- _ O
confounding -X- _ O
factors -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
5.4.1552Full -X- _ B-TaskName
Cropped -X- _ B-TaskName
Model -X- _ O
Noun -X- _ O
Predicate -X- _ O
Noun -X- _ O
Predicate -X- _ O
LXMERT -X- _ B-MethodName
0.60 -X- _ B-MetricValue
0 -X- _ B-MetricValue
.55 -X- _ I-MetricValue
0 -X- _ B-MetricValue
.78 -X- _ I-MetricValue
0 -X- _ B-MetricValue
.62 -X- _ I-MetricValue
UNITER -X- _ B-MethodName
0.60 -X- _ B-MetricValue
0 -X- _ I-MetricValue
.50 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.76 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.56 -X- _ I-MetricValue
ViLBERT -X- _ B-MethodName
0.27 -X- _ B-MetricValue
0 -X- _ I-MetricValue
.28 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.74 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.59 -X- _ I-MetricValue
ViLT -X- _ B-MethodName
0.44 -X- _ B-MetricValue
0 -X- _ I-MetricValue
.37 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.80 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.72 -X- _ I-MetricValue
Oscar -X- _ B-MethodName
0.36 -X- _ B-MetricValue
0 -X- _ I-MetricValue
.30 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.75 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.62 -X- _ I-MetricValue
VinVL -X- _ B-MethodName
0.33 -X- _ B-MetricValue
0 -X- _ I-MetricValue
.28 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.83 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.71 -X- _ I-MetricValue
CLIP -X- _ B-MethodName
0.21 -X- _ B-MetricValue
0 -X- _ I-MetricValue
.19 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.69 -X- _ I-MetricValue
0 -X- _ I-MetricValue
.52 -X- _ I-MetricValue
Model -X- _ O
Bounding -X- _ O
box -X- _ O
size -X- _ O
Distance -X- _ O
from -X- _ O
center -X- _ O
Perplexity -X- _ B-MetricName
Object -X- _ O
detector -X- _ O
confidence -X- _ B-MetricName
LXMERT -X- _ B-MethodName
-0.03 -X- _ O
( -X- _ O
p=0.12 -X- _ O
) -X- _ O
0.03 -X- _ O
( -X- _ O
p=0.08 -X- _ O
) -X- _ O
-0.01 -X- _ B-MetricValue
( -X- _ O
p=0.48 -X- _ O
) -X- _ O
0.30 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
UNITER -X- _ B-MethodName
-0.09 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.09 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.05 -X- _ B-MetricValue
( -X- _ O
p=0.01 -X- _ O
) -X- _ O
0.26 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
ViLBERT -X- _ B-MethodName
0.11 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
-0.16 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.05 -X- _ B-MetricValue
( -X- _ O
p=0.02 -X- _ O
) -X- _ O
0.22 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
ViLT -X- _ B-MethodName
-0.01 -X- _ O
( -X- _ O
p=0.73 -X- _ O
) -X- _ O
0.03 -X- _ O
( -X- _ O
p=0.13 -X- _ O
) -X- _ O
0.05 -X- _ B-MetricValue
( -X- _ O
p=0.02 -X- _ O
) -X- _ O
0.26 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
Oscar -X- _ B-MethodName
0.12 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
-0.17 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.06 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.15 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
VinVL -X- _ B-MethodName
0.12 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
-0.12 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.05 -X- _ B-MetricValue
( -X- _ O
p=0.01 -X- _ O
) -X- _ O
0.04 -X- _ B-MetricValue
( -X- _ O
p=0.05 -X- _ O
) -X- _ O
CLIP -X- _ B-MethodName
0.14 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
-0.24 -X- _ O
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.08 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
0.17 -X- _ B-MetricValue
( -X- _ O
p=0.00 -X- _ O
) -X- _ O
155315541555 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
investigates -X- _ SUMMARY
the -X- _ SUMMARY
use -X- _ SUMMARY
of -X- _ SUMMARY
unlabeled -X- _ SUMMARY
data -X- _ SUMMARY
in -X- _ SUMMARY
improving -X- _ SUMMARY
instruction -X- _ SUMMARY
learning -X- _ SUMMARY
for -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
task -X- _ SUMMARY
generalization -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
, -X- _ SUMMARY
Unlabeled -X- _ SUMMARY
Data -X- _ SUMMARY
Augmented -X- _ SUMMARY
Instruction -X- _ SUMMARY
Tuning -X- _ SUMMARY
( -X- _ SUMMARY
UDIT -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
constructs -X- _ SUMMARY
pseudo -X- _ SUMMARY
- -X- _ SUMMARY
labeled -X- _ SUMMARY
data -X- _ SUMMARY
from -X- _ SUMMARY
unlabeled -X- _ SUMMARY
plain -X- _ SUMMARY
texts -X- _ SUMMARY
and -X- _ SUMMARY
incorporates -X- _ SUMMARY
them -X- _ SUMMARY
into -X- _ SUMMARY
instruction -X- _ SUMMARY
tuning -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
experiments -X- _ SUMMARY
demonstrate -X- _ SUMMARY
that -X- _ SUMMARY
UDIT -X- _ SUMMARY
outperforms -X- _ SUMMARY
other -X- _ SUMMARY
methods -X- _ SUMMARY
in -X- _ SUMMARY
various -X- _ SUMMARY
scenarios -X- _ SUMMARY
with -X- _ SUMMARY
or -X- _ SUMMARY
without -X- _ SUMMARY
labeled -X- _ SUMMARY
data -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
results -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
PLMs -X- _ SUMMARY
can -X- _ SUMMARY
learn -X- _ SUMMARY
to -X- _ SUMMARY
follow -X- _ SUMMARY
human -X- _ SUMMARY
- -X- _ SUMMARY
written -X- _ SUMMARY
instructions -X- _ SUMMARY
even -X- _ SUMMARY
with -X- _ SUMMARY
few -X- _ SUMMARY
or -X- _ SUMMARY
no -X- _ SUMMARY
annotated -X- _ SUMMARY
samples -X- _ SUMMARY
. -X- _ SUMMARY
UDIT -X- _ SUMMARY
also -X- _ SUMMARY
improves -X- _ SUMMARY
the -X- _ SUMMARY
performance -X- _ SUMMARY
of -X- _ SUMMARY
instruction -X- _ SUMMARY
tuning -X- _ SUMMARY
in -X- _ SUMMARY
both -X- _ SUMMARY
text -X- _ SUMMARY
classification -X- _ SUMMARY
and -X- _ SUMMARY
language -X- _ SUMMARY
generation -X- _ SUMMARY
tasks -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
findings -X- _ SUMMARY
highlight -X- _ SUMMARY
the -X- _ SUMMARY
importance -X- _ SUMMARY
of -X- _ SUMMARY
instruction -X- _ SUMMARY
semantics -X- _ SUMMARY
, -X- _ SUMMARY
task -X- _ SUMMARY
diversity -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
domain -X- _ SUMMARY
diversity -X- _ SUMMARY
in -X- _ SUMMARY
zero -X- _ SUMMARY
- -X- _ SUMMARY
shot -X- _ SUMMARY
cross -X- _ SUMMARY
- -X- _ SUMMARY
task -X- _ SUMMARY
generalization -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
provides -X- _ SUMMARY
insights -X- _ SUMMARY
into -X- _ SUMMARY
using -X- _ SUMMARY
unlabeled -X- _ SUMMARY
data -X- _ SUMMARY
to -X- _ SUMMARY
enhance -X- _ SUMMARY
instruction -X- _ SUMMARY
learning -X- _ SUMMARY
and -X- _ SUMMARY
suggests -X- _ SUMMARY
future -X- _ SUMMARY
directions -X- _ SUMMARY
for -X- _ SUMMARY
further -X- _ SUMMARY
research -X- _ SUMMARY
. -X- _ SUMMARY
2022.emnlp-main.105.txt -X- _ O
Yuxian -X- _ O
Gu -X- _ O
, -X- _ O
Pei -X- _ O
Ke -X- _ O
, -X- _ O
Xiaoyan -X- _ O
Zhu -X- _ O
, -X- _ O
Minlie -X- _ O
Huang -X- _ O
The -X- _ O
CoAI -X- _ O
group -X- _ O
, -X- _ O
Tsinghua -X- _ O
University -X- _ O
, -X- _ O
Beijing -X- _ O
, -X- _ O
China -X- _ O
Institute -X- _ O
for -X- _ O
Artificial -X- _ O
Intelligence -X- _ O
, -X- _ O
State -X- _ O
Key -X- _ O
Lab -X- _ O
of -X- _ O
Intelligent -X- _ O
Technology -X- _ O
and -X- _ O
Systems -X- _ O
, -X- _ O
Beijing -X- _ O
National -X- _ O
Research -X- _ O
Center -X- _ O
for -X- _ O
Information -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
, -X- _ O
Department -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
, -X- _ O
Tsinghua -X- _ O
University -X- _ O
, -X- _ O
Beijing -X- _ O
, -X- _ O
China -X- _ O
guyx21 -X- _ O
@ -X- _ O
mails.tsinghua.edu.cn -X- _ O
, -X- _ O
kepei1106 -X- _ O
@ -X- _ O
outlook.com -X- _ O
{ -X- _ O
zxy-dcs -X- _ O
, -X- _ O
aihuang -X- _ O
} -X- _ O
@ -X- _ O
tsinghua.edu.cn -X- _ O
Abstract -X- _ O
Training -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
from -X- _ O
human -X- _ O
instructions -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
has -X- _ O
attracted -X- _ O
much -X- _ O
attention -X- _ O
in -X- _ O
NLP -X- _ O
communities -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
instruction -X- _ O
tuning -X- _ O
( -X- _ O
IT -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
massive -X- _ O
collection -X- _ O
of -X- _ O
tasks -X- _ O
described -X- _ O
via -X- _ O
human -X- _ O
- -X- _ O
craft -X- _ O
instructions -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
effective -X- _ O
in -X- _ O
instruction -X- _ O
learning -X- _ O
for -X- _ O
unseen -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
IT -X- _ O
relies -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
humanannotated -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
restricts -X- _ O
its -X- _ O
generalization -X- _ O
. -X- _ O
Unlike -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
unlabeled -X- _ O
data -X- _ O
are -X- _ O
often -X- _ O
massive -X- _ O
and -X- _ O
cheap -X- _ O
to -X- _ O
obtain -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
how -X- _ O
IT -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
with -X- _ O
unlabeled -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
empirically -X- _ O
explore -X- _ O
the -X- _ O
IT -X- _ O
performance -X- _ O
trends -X- _ O
versus -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
instructions -X- _ O
, -X- _ O
and -X- _ O
training -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
it -X- _ O
critical -X- _ O
to -X- _ O
enlarge -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
instructions -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
instructions -X- _ O
can -X- _ O
be -X- _ O
underutilized -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
scarcity -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Unlabeled -X- _ B-MethodName
Data -X- _ I-MethodName
Augmented -X- _ I-MethodName
Instruction -X- _ I-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
UDIT -X- _ B-MethodName
) -X- _ O
to -X- _ O
take -X- _ O
better -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
instructions -X- _ O
during -X- _ O
IT -X- _ O
by -X- _ O
constructing -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
to -X- _ O
show -X- _ O
UDIT -X- _ B-MethodName
’s -X- _ O
effectiveness -X- _ O
in -X- _ O
various -X- _ O
scenarios -X- _ O
of -X- _ O
tasks -X- _ O
and -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
comprehensively -X- _ O
analyze -X- _ O
the -X- _ O
key -X- _ O
factors -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
to -X- _ O
investigate -X- _ O
how -X- _ O
to -X- _ O
better -X- _ O
improve -X- _ O
IT -X- _ O
with -X- _ O
unlabeled -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
code -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
thu-coai -X- _ O
/ -X- _ O
UDIT -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
The -X- _ O
instruction -X- _ O
learning -X- _ O
paradigm -X- _ O
( -X- _ O
Weller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
language -X- _ O
models -X- _ O
learn -X- _ O
from -X- _ O
human -X- _ O
instructions -X- _ O
to -X- _ O
perform -X- _ O
unseen -X- _ O
tasks -X- _ O
in -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
scenarios -X- _ O
, -X- _ O
has -X- _ O
received -X- _ O
increasing -X- _ O
attention -X- _ O
recently -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
conventional -X- _ O
machine -X- _ O
learning -X- _ O
paradigms -X- _ O
that -X- _ O
mainly -X- _ O
learn -X- _ O
from -X- _ O
data -X- _ O
examples -X- _ O
, -X- _ O
instruction -X- _ O
learning -X- _ O
requires -X- _ O
models -X- _ O
to -X- _ O
complete -X- _ O
tasks -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
understanding -X- _ O
of -X- _ O
humanwritten -X- _ O
task -X- _ O
descriptions -X- _ O
without -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
, -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
IT -X- _ O
and -X- _ O
UDIT -X- _ B-MethodName
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
instruction -X- _ O
numbers -X- _ O
and -X- _ O
labeled -X- _ O
data -X- _ O
amounts -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
a -X- _ O
700 -X- _ O
M -X- _ O
PLM -X- _ O
and -X- _ O
then -X- _ O
test -X- _ O
its -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
generalization -X- _ O
ability -X- _ O
on -X- _ O
unseen -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
x -X- _ O
- -X- _ O
axis -X- _ O
represents -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labeled -X- _ O
samples -X- _ O
in -X- _ O
each -X- _ O
training -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
y -X- _ O
- -X- _ O
axis -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
on -X- _ O
evaluation -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
control -X- _ O
the -X- _ O
instruction -X- _ O
numbers -X- _ O
by -X- _ O
gradually -X- _ O
adding -X- _ O
training -X- _ O
tasks -X- _ O
. -X- _ O
which -X- _ O
is -X- _ O
closer -X- _ O
to -X- _ O
general -X- _ O
AI -X- _ O
systems -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
summarization -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
is -X- _ O
only -X- _ O
given -X- _ O
an -X- _ O
explicit -X- _ O
instruction -X- _ O
“ -X- _ O
Summarize -X- _ O
the -X- _ O
following -X- _ O
article -X- _ O
in -X- _ O
brief -X- _ O
: -X- _ O
” -X- _ O
and -X- _ O
an -X- _ O
article -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
corresponding -X- _ O
summary -X- _ O
. -X- _ O
To -X- _ O
realize -X- _ O
instruction -X- _ O
learning -X- _ O
, -X- _ O
recent -X- _ O
works -X- _ O
such -X- _ O
as -X- _ O
FLAN -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
T0 -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
propose -X- _ O
instruction -X- _ O
tuning -X- _ O
( -X- _ O
IT -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
PLMs -X- _ O
) -X- _ O
( -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
collection -X- _ O
of -X- _ O
tasks -X- _ O
with -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
data -X- _ O
specified -X- _ O
in -X- _ O
descriptive -X- _ O
instructions -X- _ O
. -X- _ O
Through -X- _ O
IT -X- _ O
, -X- _ O
PLMs -X- _ O
learn -X- _ O
to -X- _ O
follow -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
written -X- _ O
instructions -X- _ O
to -X- _ O
complete -X- _ O
the -X- _ O
corresponding -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
enables -X- _ O
them -X- _ O
to -X- _ O
perform -X- _ O
instruction -X- _ O
learning -X- _ O
in -X- _ O
unseen -X- _ O
tasks -X- _ O
. -X- _ O
An -X- _ O
intuitive -X- _ O
way -X- _ O
to -X- _ O
boost -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
IT -X- _ O
is -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
instructions -X- _ O
and -X- _ O
data -X- _ O
examples -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
instructions -X- _ O
largely -X- _ O
determines -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
of -X- _ O
IT -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
data -X- _ O
should -X- _ O
be -X- _ O
also -X- _ O
sufficient -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
these -X- _ O
instructions -X- _ O
well -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
amount -X- _ O
and -X- _ O
domain -X- _ O
diversity -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
in1617different -X- _ O
tasks -X- _ O
vary -X- _ O
greatly -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
many -X- _ O
lowresource -X- _ O
tasks -X- _ O
lack -X- _ O
sufficient -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
humanannotated -X- _ O
examples -X- _ O
. -X- _ O
This -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
easy -X- _ O
overfitting -X- _ O
to -X- _ O
specific -X- _ O
domains -X- _ O
or -X- _ O
examples -X- _ O
when -X- _ O
learning -X- _ O
the -X- _ O
corresponding -X- _ O
instructions -X- _ O
, -X- _ O
which -X- _ O
affects -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
in -X- _ O
instruction -X- _ O
learning -X- _ O
. -X- _ O
Introducing -X- _ O
unlabeled -X- _ O
data -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
approach -X- _ O
to -X- _ O
alleviating -X- _ O
the -X- _ O
data -X- _ O
scarcity -X- _ O
problem -X- _ O
in -X- _ O
supervised -X- _ O
learning -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
because -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
are -X- _ O
much -X- _ O
easier -X- _ O
to -X- _ O
access -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
their -X- _ O
benefit -X- _ O
to -X- _ O
IT -X- _ O
is -X- _ O
still -X- _ O
inconclusive -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
IT -X- _ O
is -X- _ O
much -X- _ O
more -X- _ O
challenging -X- _ O
, -X- _ O
requiring -X- _ O
learning -X- _ O
the -X- _ O
mapping -X- _ O
between -X- _ O
human -X- _ O
instructions -X- _ O
and -X- _ O
task -X- _ O
semantics -X- _ O
rather -X- _ O
than -X- _ O
that -X- _ O
between -X- _ O
samples -X- _ O
and -X- _ O
labels -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
incorporating -X- _ O
unlabeled -X- _ O
data -X- _ O
into -X- _ O
instruction -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
questions -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Is -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
perform -X- _ O
IT -X- _ O
with -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
few -X- _ O
or -X- _ O
even -X- _ O
no -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
data -X- _ O
? -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
How -X- _ O
to -X- _ O
better -X- _ O
use -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
to -X- _ O
improve -X- _ O
IT -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
? -X- _ O
To -X- _ O
study -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
Unlabeled -X- _ B-MethodName
Data -X- _ I-MethodName
Augmented -X- _ I-MethodName
Instruction -X- _ I-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
UDIT -X- _ B-MethodName
) -X- _ O
to -X- _ O
effectively -X- _ O
use -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
help -X- _ O
instruction -X- _ O
learning -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
according -X- _ O
to -X- _ O
task -X- _ O
instructions -X- _ O
. -X- _ O
The -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
which -X- _ O
enlarge -X- _ O
training -X- _ O
samples -X- _ O
and -X- _ O
diversify -X- _ O
data -X- _ O
domains -X- _ O
help -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
meanings -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
task -X- _ O
instructions -X- _ O
better -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
UDIT -X- _ B-MethodName
under -X- _ O
various -X- _ O
scenarios -X- _ O
of -X- _ O
training -X- _ O
tasks -X- _ O
and -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
verify -X- _ O
that -X- _ O
learning -X- _ O
instructions -X- _ O
from -X- _ O
unlabeled -X- _ O
data -X- _ O
is -X- _ O
possible -X- _ O
. -X- _ O
To -X- _ O
study -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
UDIT -X- _ B-MethodName
with -X- _ O
previous -X- _ O
methods -X- _ O
to -X- _ O
show -X- _ O
its -X- _ O
superior -X- _ O
performance -X- _ O
in -X- _ O
using -X- _ O
unlabeled -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
to -X- _ O
reveal -X- _ O
the -X- _ O
underlying -X- _ O
factors -X- _ O
to -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
Specifically -X- _ O
, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
•We -X- _ O
introduce -X- _ O
UDIT -X- _ B-MethodName
, -X- _ O
a -X- _ O
training -X- _ O
framework -X- _ O
that -X- _ O
incorporates -X- _ O
unlabeled -X- _ O
data -X- _ O
into -X- _ O
instruction -X- _ O
tuning -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
. -X- _ O
•Through -X- _ O
UDIT -X- _ B-MethodName
, -X- _ O
we -X- _ O
empirically -X- _ O
verify -X- _ O
that -X- _ O
PLMs -X- _ O
can -X- _ O
learn -X- _ O
to -X- _ O
follow -X- _ O
human -X- _ O
- -X- _ O
written -X- _ O
instructions -X- _ O
with -X- _ O
unlabeled -X- _ O
data -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
few -X- _ O
or -X- _ O
even -X- _ O
no -X- _ O
annotated -X- _ O
samples -X- _ O
. -X- _ O
•We -X- _ O
show -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
is -X- _ O
a -X- _ O
significantly -X- _ O
better -X- _ O
way -X- _ O
to -X- _ O
use -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
improve -X- _ O
instruc -X- _ O
- -X- _ O
tion -X- _ O
tuning -X- _ O
, -X- _ O
making -X- _ O
a -X- _ O
700 -X- _ O
M -X- _ O
PLM -X- _ O
with -X- _ O
UDIT -X- _ B-MethodName
outperform -X- _ O
the -X- _ O
3B -X- _ O
counterpart -X- _ O
based -X- _ O
on -X- _ O
IT -X- _ O
. -X- _ O
•We -X- _ O
comprehensively -X- _ O
analyze -X- _ O
the -X- _ O
key -X- _ O
factors -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
and -X- _ O
give -X- _ O
some -X- _ O
insights -X- _ O
into -X- _ O
using -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
improve -X- _ O
instruction -X- _ O
learning -X- _ O
. -X- _ O
2 -X- _ O
Related -X- _ O
Works -X- _ O
Instruction -X- _ O
Learning -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
large -X- _ O
PLMs -X- _ O
like -X- _ O
GPT-3 -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
shown -X- _ O
promising -X- _ O
performance -X- _ O
in -X- _ O
learning -X- _ O
from -X- _ O
human -X- _ O
instructions -X- _ O
to -X- _ O
solve -X- _ O
tasks -X- _ O
in -X- _ O
few -X- _ O
- -X- _ O
shot -X- _ O
and -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
scenarios -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Several -X- _ O
works -X- _ O
propose -X- _ O
benchmarks -X- _ O
( -X- _ O
Weller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Efrat -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Finlayson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
instruction -X- _ O
learning -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
crosstask -X- _ O
generalization -X- _ O
( -X- _ O
Ye -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
enhance -X- _ O
instruction -X- _ O
understanding -X- _ O
, -X- _ O
many -X- _ O
works -X- _ O
adopt -X- _ O
IT -X- _ O
, -X- _ O
which -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
PLMs -X- _ O
on -X- _ O
massive -X- _ O
task -X- _ O
clusters -X- _ O
described -X- _ O
by -X- _ O
instructions -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
fashion -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
FLAN -X- _ O
( -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
T0 -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
ZeroPrompt -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022a -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
InstructGPT -X- _ O
( -X- _ O
Ouyang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
show -X- _ O
superior -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
on -X- _ O
unseen -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
better -X- _ O
understand -X- _ O
IT -X- _ O
and -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
learning -X- _ O
of -X- _ O
PLMs -X- _ O
, -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
compares -X- _ O
different -X- _ O
model -X- _ O
architectures -X- _ O
and -X- _ O
training -X- _ O
objectives -X- _ O
. -X- _ O
Some -X- _ O
works -X- _ O
also -X- _ O
incorporate -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
of -X- _ O
IT -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
But -X- _ O
they -X- _ O
assume -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
unlabeled -X- _ O
samples -X- _ O
in -X- _ O
evaluation -X- _ O
tasks -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
plain -X- _ O
texts -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
evaluation -X- _ O
scenario -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
Supervised -X- _ O
Learning -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
adopts -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
improve -X- _ O
supervised -X- _ O
learners -X- _ O
( -X- _ O
Chapelle -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
Many -X- _ O
previous -X- _ O
works -X- _ O
use -X- _ O
consistency -X- _ O
training -X- _ O
to -X- _ O
regularize -X- _ O
model -X- _ O
predictions -X- _ O
( -X- _ O
Bachman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Rasmus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Self -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
Scudder -X- _ O
, -X- _ O
1965 -X- _ O
; -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
also -X- _ O
widely -X- _ O
used -X- _ O
, -X- _ O
which -X- _ O
assigns -X- _ O
synthetic -X- _ O
labels -X- _ O
to -X- _ O
unlabeled -X- _ O
data -X- _ O
with -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
These -X- _ O
data -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
typically -X- _ O
assume -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
unannotated -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
while -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
using -X- _ O
taskagnostic -X- _ O
plain -X- _ O
texts -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
practical -X- _ O
. -X- _ O
Self -X- _ O
- -X- _ O
Supervised -X- _ O
Training -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
Training -X- _ O
with -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
tasks -X- _ O
is -X- _ O
also -X- _ O
related -X- _ O
to -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
models -X- _ O
obtain -X- _ O
versatile -X- _ O
knowledge -X- _ O
from -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
plain -X- _ O
texts -X- _ O
and -X- _ O
boosts -X- _ O
the -X- _ O
model1618 -X- _ O
performance -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Fang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Some -X- _ O
works -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
carefully -X- _ O
designed -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
tasks -X- _ O
can -X- _ O
bring -X- _ O
further -X- _ O
improvement -X- _ O
to -X- _ O
lowresource -X- _ O
tasks -X- _ O
( -X- _ O
Bansal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
conventional -X- _ O
selfsupervised -X- _ O
tasks -X- _ O
are -X- _ O
designed -X- _ O
independent -X- _ O
of -X- _ O
human -X- _ O
instructions -X- _ O
( -X- _ O
Aroca -X- _ O
- -X- _ O
Ouellette -X- _ O
and -X- _ O
Rudzicz -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
tasks -X- _ O
in -X- _ O
UDIT -X- _ B-MethodName
match -X- _ O
the -X- _ O
instruction -X- _ O
semantics -X- _ O
closely -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
instruction -X- _ O
learning -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
. -X- _ O
3 -X- _ O
Method -X- _ O
3.1 -X- _ O
Background -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
give -X- _ O
a -X- _ O
formal -X- _ O
description -X- _ O
of -X- _ O
IT -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
a -X- _ O
“ -X- _ O
task -X- _ O
” -X- _ O
as -X- _ O
a -X- _ O
pair -X- _ O
( -X- _ O
D -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
Dis -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
Iis -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
instructions -X- _ O
describing -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
nclustersT= -X- _ O
{ -X- _ O
T -X- _ O
, -X- _ O
T -X- _ O
, -X- _ O
· -X- _ O
· -X- _ O
· -X- _ O
, -X- _ O
T -X- _ O
} -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
similarities -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
icluster -X- _ O
T= -X- _ O
{ -X- _ O
( -X- _ O
D -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
D -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
··· -X- _ O
, -X- _ O
( -X- _ O
D -X- _ O
, -X- _ O
I -X- _ O
) -X- _ O
} -X- _ O
contains -X- _ O
k -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
cluster -X- _ O
“ -X- _ O
Multiple -X- _ B-TaskName
- -X- _ I-TaskName
Choice -X- _ I-TaskName
QA -X- _ I-TaskName
” -X- _ O
, -X- _ O
a -X- _ O
data -X- _ O
sample -X- _ O
typically -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
several -X- _ O
answer -X- _ O
options -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
instructions -X- _ O
serve -X- _ O
as -X- _ O
templates -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
to -X- _ O
natural -X- _ O
texts -X- _ O
and -X- _ O
formulate -X- _ O
all -X- _ O
tasks -X- _ O
into -X- _ O
text -X- _ O
- -X- _ O
totext -X- _ O
language -X- _ O
modeling -X- _ O
problems -X- _ O
. -X- _ O
In -X- _ O
IT -X- _ O
, -X- _ O
a -X- _ O
PLMis -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
several -X- _ O
clusters -X- _ O
T⫋T -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
fashion -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
tasks -X- _ O
in -X- _ O
novel -X- _ O
clusters -X- _ O
T -X- _ O
= -X- _ O
T -X- _ O
\T -X- _ O
with -X- _ O
instructions -X- _ O
only -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
“ -X- _ O
Zero -X- _ O
- -X- _ O
Shot -X- _ O
Cross -X- _ O
- -X- _ O
Task -X- _ O
Generalization -X- _ O
” -X- _ O
part -X- _ O
of -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
mainly -X- _ O
follow -X- _ O
the -X- _ O
settings -X- _ O
of -X- _ O
T0 -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
training -X- _ O
tasks -X- _ O
, -X- _ O
instructions -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
split -X- _ O
of -X- _ O
task -X- _ O
clusters -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
findings -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
other -X- _ O
scenarios -X- _ O
. -X- _ O
T0 -X- _ O
is -X- _ O
a -X- _ O
representative -X- _ O
model -X- _ O
instructiontuned -X- _ O
on -X- _ O
8 -X- _ O
task -X- _ O
clusters -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
T5 -X- _ O
model -X- _ O
( -X- _ O
Raffel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
tested -X- _ O
on -X- _ O
4 -X- _ O
task -X- _ O
clusters -X- _ O
. -X- _ O
The -X- _ O
instructions -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
Public -X- _ B-DatasetName
Pool -X- _ I-DatasetName
of -X- _ I-DatasetName
Prompts -X- _ I-DatasetName
( -X- _ O
P3 -X- _ O
) -X- _ O
( -X- _ O
Bach -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
which -X- _ O
contains -X- _ O
thousands -X- _ O
of -X- _ O
crowdsourced -X- _ O
instructions -X- _ O
. -X- _ O
3.2 -X- _ O
Overview -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
To -X- _ O
better -X- _ O
learn -X- _ O
the -X- _ O
instructions -X- _ O
in -X- _ O
T -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
pseudolabeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
instructions -X- _ O
in -X- _ O
each -X- _ O
task -X- _ O
cluster -X- _ O
T∈ -X- _ O
T. -X- _ O
The -X- _ O
plain -X- _ O
texts -X- _ O
are -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
corpora -X- _ O
, -X- _ O
including -X- _ O
BookCorpus -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
( -X- _ O
Sebastian -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
OpenWebText -X- _ B-DatasetName
( -X- _ O
Gokaslan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
Foundation -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
IMDB -X- _ B-DatasetName
Review -X- _ I-DatasetName
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
totaling -X- _ O
about -X- _ O
37.2G. -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
these -X- _ O
corpora -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
The -X- _ O
constructing -X- _ O
process -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
heuristic -X- _ O
rules -X- _ O
, -X- _ O
widely -X- _ O
used1619NLP -X- _ O
toolkits -X- _ O
like -X- _ O
NLTK -X- _ O
, -X- _ O
and -X- _ O
basic -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
like -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
instructions -X- _ O
in -X- _ O
Tto -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
samples -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
PLM -X- _ O
on -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
and -X- _ O
labeled -X- _ O
samples -X- _ O
with -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
constructed -X- _ O
at -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
task -X- _ O
clusters -X- _ O
rather -X- _ O
than -X- _ O
single -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
they -X- _ O
match -X- _ O
the -X- _ O
meanings -X- _ O
of -X- _ O
most -X- _ O
instructions -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
cluster -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
similarities -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
assume -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
during -X- _ O
the -X- _ O
constructing -X- _ O
process -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
is -X- _ O
applicable -X- _ O
under -X- _ O
various -X- _ O
settings -X- _ O
with -X- _ O
or -X- _ O
without -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
section -X- _ O
briefly -X- _ O
introduces -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
construction -X- _ O
for -X- _ O
the -X- _ O
8 -X- _ O
task -X- _ O
clusters -X- _ O
in -X- _ O
T0 -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
some -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
constructed -X- _ O
data -X- _ O
in -X- _ O
Appendix -X- _ O
D. -X- _ O
3.3 -X- _ O
Constructing -X- _ O
Pseudo -X- _ O
- -X- _ O
Labeled -X- _ O
Data -X- _ O
Multiple -X- _ B-TaskName
- -X- _ I-TaskName
Choice -X- _ I-TaskName
QA -X- _ I-TaskName
( -X- _ O
MCQA -X- _ B-TaskName
) -X- _ O
. -X- _ O
The -X- _ O
sample -X- _ O
in -X- _ O
MCQA -X- _ B-TaskName
consists -X- _ O
of -X- _ O
a -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
related -X- _ O
question -X- _ O
, -X- _ O
an -X- _ O
answer -X- _ O
, -X- _ O
and -X- _ O
several -X- _ O
options -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
plain -X- _ O
- -X- _ O
text -X- _ O
document -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
two -X- _ O
methods -X- _ O
to -X- _ O
construct -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
first -X- _ O
randomly -X- _ O
replace -X- _ O
one -X- _ O
noun -X- _ O
in -X- _ O
a -X- _ O
randomly -X- _ O
selected -X- _ O
sentence -X- _ O
with -X- _ O
a -X- _ O
" -X- _ O
_ -X- _ O
" -X- _ O
symbol -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
“ -X- _ O
? -X- _ O
” -X- _ O
mark -X- _ O
to -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
treat -X- _ O
the -X- _ O
texts -X- _ O
before -X- _ O
the -X- _ O
sentence -X- _ O
as -X- _ O
the -X- _ O
passage -X- _ O
and -X- _ O
the -X- _ O
replaced -X- _ O
word -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
The -X- _ O
options -X- _ O
are -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
many -X- _ O
questions -X- _ O
are -X- _ O
naturally -X- _ O
followed -X- _ O
by -X- _ O
its -X- _ O
answer -X- _ O
in -X- _ O
our -X- _ O
corpus -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
search -X- _ O
for -X- _ O
questions -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
and -X- _ O
treat -X- _ O
previous -X- _ O
texts -X- _ O
as -X- _ O
the -X- _ O
passage -X- _ O
and -X- _ O
the -X- _ O
following -X- _ O
sentence -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
The -X- _ O
options -X- _ O
are -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
sentences -X- _ O
after -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
Extractive -X- _ B-TaskName
QA -X- _ I-TaskName
( -X- _ O
EXQA -X- _ B-TaskName
) -X- _ O
. -X- _ O
EXQA -X- _ B-TaskName
aims -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
questions -X- _ O
using -X- _ O
the -X- _ O
phrases -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
passages -X- _ O
. -X- _ O
We -X- _ O
mainly -X- _ O
follow -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
which -X- _ O
first -X- _ O
selects -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
plain -X- _ O
- -X- _ O
text -X- _ O
documents -X- _ O
as -X- _ O
the -X- _ O
answers -X- _ O
and -X- _ O
uses -X- _ O
templates -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
sentences -X- _ O
containing -X- _ O
the -X- _ O
answers -X- _ O
to -X- _ O
questions -X- _ O
. -X- _ O
Close -X- _ B-TaskName
- -X- _ I-TaskName
Book -X- _ I-TaskName
QA -X- _ I-TaskName
( -X- _ O
CBQA -X- _ B-TaskName
) -X- _ O
. -X- _ O
CBQA -X- _ B-TaskName
is -X- _ O
similar -X- _ O
to -X- _ O
EXQA -X- _ B-TaskName
except -X- _ O
for -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pair -X- _ O
from -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
of -X- _ O
EXQA -X- _ B-TaskName
. -X- _ O
Sentiment -X- _ B-TaskName
( -X- _ O
SENT -X- _ B-TaskName
) -X- _ O
. -X- _ O
SENT -X- _ B-TaskName
requires -X- _ O
identifying -X- _ O
the -X- _ O
sentiment -X- _ O
labels -X- _ O
of -X- _ O
given -X- _ O
texts -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
akeyword -X- _ O
- -X- _ O
based -X- _ O
sentiment -X- _ O
analyzer -X- _ O
in -X- _ O
NLTK -X- _ O
to -X- _ O
annotate -X- _ O
sentiment -X- _ O
labels -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
label -X- _ O
quality -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
construct -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
IMDB -X- _ O
Review -X- _ O
corpus -X- _ O
for -X- _ O
this -X- _ O
cluster -X- _ O
. -X- _ O
Topic -X- _ B-TaskName
Classification -X- _ I-TaskName
( -X- _ O
TC -X- _ B-TaskName
) -X- _ O
. -X- _ O
TC -X- _ B-TaskName
requires -X- _ O
finding -X- _ O
proper -X- _ O
topic -X- _ O
labels -X- _ O
for -X- _ O
input -X- _ O
passages -X- _ O
. -X- _ O
We -X- _ O
notice -X- _ O
that -X- _ O
many -X- _ O
URLs -X- _ O
of -X- _ O
the -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
corpus -X- _ O
contain -X- _ O
the -X- _ O
topic -X- _ O
of -X- _ O
passages -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
heuristic -X- _ O
rules -X- _ O
to -X- _ O
extract -X- _ O
topic -X- _ O
labels -X- _ O
from -X- _ O
the -X- _ O
URLs -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
split -X- _ O
the -X- _ O
URL -X- _ O
by -X- _ O
“ -X- _ O
/ -X- _ O
” -X- _ O
and -X- _ O
search -X- _ O
for -X- _ O
topic -X- _ O
words -X- _ O
from -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
. -X- _ O
We -X- _ O
stop -X- _ O
at -X- _ O
the -X- _ O
first -X- _ O
string -X- _ O
that -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
English -X- _ O
letters -X- _ O
, -X- _ O
shorter -X- _ O
than -X- _ O
20 -X- _ O
characters -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
in -X- _ O
[ -X- _ O
“ -X- _ O
news -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
en -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
story -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
us -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
articles -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
local -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
english -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
tag -X- _ O
” -X- _ O
, -X- _ O
“ -X- _ O
post -X- _ O
” -X- _ O
] -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
14 -X- _ O
strings -X- _ O
as -X- _ O
the -X- _ O
topic -X- _ O
labels -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
passages -X- _ O
as -X- _ O
the -X- _ O
inputs -X- _ O
. -X- _ O
Structure -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
Text -X- _ I-TaskName
( -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
) -X- _ O
. -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
requires -X- _ O
generating -X- _ O
natural -X- _ O
sentences -X- _ O
that -X- _ O
describe -X- _ O
input -X- _ O
structural -X- _ O
data -X- _ O
like -X- _ O
graphs -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
input -X- _ O
data -X- _ O
are -X- _ O
usually -X- _ O
linearized -X- _ O
as -X- _ O
word -X- _ O
sequences -X- _ O
in -X- _ O
the -X- _ O
instructions -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
keyword -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
text -X- _ O
generation -X- _ O
task -X- _ O
that -X- _ O
takes -X- _ O
a -X- _ O
random -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
notional -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
the -X- _ O
sentence -X- _ O
as -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
Summarization -X- _ B-TaskName
( -X- _ O
SUM -X- _ B-TaskName
) -X- _ O
. -X- _ O
For -X- _ O
summarization -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
Leading -X- _ B-TaskName
Sentence -X- _ I-TaskName
Generation -X- _ I-TaskName
( -X- _ O
LSG -X- _ B-TaskName
) -X- _ O
and -X- _ O
Gap -X- _ B-TaskName
Sentence -X- _ I-TaskName
Generation -X- _ I-TaskName
( -X- _ O
GSG -X- _ B-TaskName
) -X- _ O
from -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
LSG -X- _ O
takes -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
a -X- _ O
passage -X- _ O
as -X- _ O
the -X- _ O
summary -X- _ O
and -X- _ O
the -X- _ O
body -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
GSG -X- _ B-TaskName
treats -X- _ O
the -X- _ O
sentence -X- _ O
overlapping -X- _ O
other -X- _ O
document -X- _ O
parts -X- _ O
the -X- _ O
most -X- _ O
as -X- _ O
the -X- _ O
summary -X- _ O
and -X- _ O
the -X- _ O
remaining -X- _ O
sentences -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
Paraphrase -X- _ B-TaskName
Identification -X- _ I-TaskName
( -X- _ O
PARA -X- _ B-TaskName
) -X- _ O
. -X- _ O
PARA -X- _ B-TaskName
aims -X- _ O
to -X- _ O
identify -X- _ O
whether -X- _ O
two -X- _ O
sentences -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
sentence -X- _ O
sin -X- _ O
the -X- _ O
plain -X- _ O
texts -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
perturbation -X- _ O
to -X- _ O
sto -X- _ O
get -X- _ O
s. -X- _ O
We -X- _ O
consider -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
perturbations -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Randomly -X- _ O
choosing -X- _ O
a -X- _ O
word -X- _ O
and -X- _ O
replacing -X- _ O
it -X- _ O
with -X- _ O
its -X- _ O
antonym -X- _ O
via -X- _ O
NLTK -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Picking -X- _ O
out -X- _ O
nouns -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
via -X- _ O
NLTK -X- _ O
and -X- _ O
shuffling -X- _ O
their -X- _ O
order -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
get -X- _ O
/ -X- _ O
tildewides -X- _ O
and -X- _ O
/ -X- _ O
tildewidesby -X- _ O
adopting -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
to -X- _ O
sands -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
treat -X- _ O
( -X- _ O
s -X- _ O
, -X- _ O
/ -X- _ O
tildewides -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
positive -X- _ O
pair -X- _ O
and -X- _ O
( -X- _ O
s -X- _ O
, -X- _ O
/ -X- _ O
tildewides -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
negative -X- _ O
pair -X- _ O
. -X- _ O
4 -X- _ O
Experiment -X- _ O
4.1 -X- _ O
Setup -X- _ O
Settings -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
three -X- _ O
scenarios -X- _ O
in -X- _ O
which -X- _ O
unlabeled -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
enhance -X- _ O
instruction -X- _ O
learning -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
No -X- _ O
Labeled -X- _ O
Data -X- _ O
, -X- _ O
where -X- _ O
only -X- _ O
the -X- _ O
instructions -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
are -X- _ O
available -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Few1620Labeled -X- _ O
Data -X- _ O
, -X- _ O
where -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
is -X- _ O
available -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Full -X- _ O
Labeled -X- _ O
Data -X- _ O
, -X- _ O
where -X- _ O
all -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
during -X- _ O
IT -X- _ O
. -X- _ O
Datasets -X- _ O
. -X- _ O
Following -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
8 -X- _ O
task -X- _ O
clusters -X- _ O
as -X- _ O
T -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
36 -X- _ O
datasets -X- _ O
and -X- _ O
304 -X- _ O
instructions -X- _ O
. -X- _ O
Tcontains -X- _ O
6 -X- _ O
task -X- _ O
clusters -X- _ O
consisting -X- _ O
of -X- _ O
9 -X- _ O
text -X- _ O
classification -X- _ O
tasksand -X- _ O
2 -X- _ O
language -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O
Detailed -X- _ O
data -X- _ O
information -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
Training -X- _ O
and -X- _ O
Evaluation -X- _ O
Details -X- _ O
. -X- _ O
For -X- _ O
computational -X- _ O
efficiency -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
our -X- _ O
experiments -X- _ O
mainly -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
700 -X- _ O
M -X- _ O
T5 -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
mix -X- _ O
the -X- _ O
labeled -X- _ O
and -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
finetuning -X- _ O
. -X- _ O
Unless -X- _ O
specified -X- _ O
otherwise -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
at -X- _ O
most -X- _ O
10k -X- _ B-HyperparameterValue
labeled -X- _ B-HyperparameterName
/ -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
samples -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
because -X- _ O
we -X- _ O
find -X- _ O
more -X- _ O
samples -X- _ O
bring -X- _ O
little -X- _ O
improvement -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
checkpoint -X- _ O
on -X- _ O
the -X- _ O
merged -X- _ O
validation -X- _ O
splits -X- _ O
of -X- _ O
datasets -X- _ O
in -X- _ O
T -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
More -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
details -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
In -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ O
( -X- _ O
Section -X- _ O
4.2 -X- _ O
) -X- _ O
and -X- _ O
median -X- _ O
( -X- _ O
Appendix -X- _ O
C.2 -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
across -X- _ O
different -X- _ O
instructions -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
task -X- _ O
in -X- _ O
T. -X- _ O
For -X- _ O
the -X- _ O
multiplechoice -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O
Baselines -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
baselines -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Direct -X- _ B-MethodName
Zero -X- _ I-MethodName
- -X- _ I-MethodName
Shot -X- _ I-MethodName
( -X- _ O
DirectZS -X- _ B-MethodName
) -X- _ O
: -X- _ O
The -X- _ O
PLM -X- _ O
is -X- _ O
directly -X- _ O
evaluated -X- _ O
on -X- _ O
Twithout -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Vanilla -X- _ B-MethodName
Instruction -X- _ I-MethodName
Tuning -X- _ I-MethodName
( -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
) -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
instruction -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
T -X- _ O
, -X- _ O
which -X- _ O
stays -X- _ O
the -X- _ O
same -X- _ O
with -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Self -X- _ O
- -X- _ O
Supervised -X- _ O
Training -X- _ O
: -X- _ O
Besides -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
IT -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
also -X- _ O
tuned -X- _ O
on -X- _ O
our -X- _ O
unlabeled -X- _ O
plain -X- _ O
- -X- _ O
text -X- _ O
corpus -X- _ O
with -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
( -X- _ O
ExtraLM -X- _ O
) -X- _ O
or -X- _ O
the -X- _ O
four -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
objectives -X- _ O
proposed -X- _ O
in -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
( -X- _ O
SelfSup -X- _ O
- -X- _ O
IT -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
proportion -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
to -X- _ O
our -X- _ O
pseudolabeled -X- _ O
samples -X- _ O
is -X- _ O
1:1 -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Data -X- _ O
Augmentation -X- _ O
( -X- _ O
DataAug -X- _ O
- -X- _ O
IT -X- _ O
) -X- _ O
: -X- _ O
For -X- _ O
the -X- _ O
tasks -X- _ O
with -X- _ O
few -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
backtranslation -X- _ O
and -X- _ O
augment -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
twice -X- _ O
as -X- _ O
large -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022b -X- _ O
) -X- _ O
. -X- _ O
4.2 -X- _ O
Results -X- _ O
4.2.1 -X- _ O
No -X- _ O
Labeled -X- _ O
Data -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
where -X- _ O
no -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
, -X- _ O
from -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
3 -X- _ O
observations -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
all -X- _ O
methods -X- _ O
that -X- _ O
use -X- _ O
unlabeled -X- _ O
data -X- _ O
( -X- _ O
ExtraLM -X- _ O
, -X- _ O
SelfSup -X- _ O
- -X- _ O
IT -X- _ O
, -X- _ O
and -X- _ O
UDIT -X- _ O
) -X- _ O
outperform -X- _ O
DirectZS -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
PLMs -X- _ O
can -X- _ O
learn -X- _ O
to -X- _ O
follow -X- _ O
instructions -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
with -X- _ O
unlabeled -X- _ O
data -X- _ O
when -X- _ O
human -X- _ O
- -X- _ O
labeled -X- _ O
samples -X- _ O
are -X- _ O
absent -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
among -X- _ O
different -X- _ O
methods -X- _ O
using -X- _ O
unlabeled -X- _ O
data -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
training -X- _ O
only -X- _ O
brings -X- _ O
marginal -X- _ O
improvement -X- _ O
, -X- _ O
while -X- _ O
UDIT -X- _ B-MethodName
boosts -X- _ O
the -X- _ O
performance -X- _ O
largely -X- _ O
on -X- _ O
most -X- _ O
tasks -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
using -X- _ O
unlabeled -X- _ O
data -X- _ O
to -X- _ O
improve -X- _ O
instruction -X- _ O
learning -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
. -X- _ O
Simple -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
tasks -X- _ O
can -X- _ O
not -X- _ O
reflect -X- _ O
the -X- _ O
characteristics -X- _ O
of -X- _ O
human -X- _ O
instructions -X- _ O
, -X- _ O
while -X- _ O
UDIT -X- _ B-MethodName
directly -X- _ O
helps -X- _ O
the -X- _ O
PLM -X- _ O
learn -X- _ O
the -X- _ O
mapping -X- _ O
between -X- _ O
instructions -X- _ O
and -X- _ O
task -X- _ O
semantics -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
UDIT -X- _ B-MethodName
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
selfsupervised -X- _ O
training -X- _ O
when -X- _ O
we -X- _ O
mix -X- _ O
the -X- _ O
training -X- _ O
samples -X- _ O
augmented -X- _ O
by -X- _ O
these -X- _ O
two -X- _ O
methods -X- _ O
. -X- _ O
The -X- _ O
row -X- _ O
“ -X- _ O
UDIT -X- _ B-MethodName
+ -X- _ O
SelfSup -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
” -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
average -X- _ O
performance -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
these -X- _ O
two -X- _ O
methods -X- _ O
are -X- _ O
complementary -X- _ O
in -X- _ O
this -X- _ O
scenario -X- _ O
. -X- _ O
4.2.2 -X- _ O
Few -X- _ O
Labeled -X- _ O
Data -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
a -X- _ O
more -X- _ O
practical -X- _ O
scenario -X- _ O
where -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
available -X- _ O
for -X- _ O
IT -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
explore -X- _ O
three -X- _ O
different -X- _ O
data -X- _ O
scarcity -X- _ O
settings -X- _ O
. -X- _ O
“ -X- _ O
Few -X- _ O
Tasks -X- _ O
” -X- _ O
simulates -X- _ O
the -X- _ O
setting -X- _ O
where -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
task -X- _ O
clusters -X- _ O
have -X- _ O
enough -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
EXQA -X- _ B-DatasetName
as -X- _ O
the -X- _ O
data -X- _ O
- -X- _ O
sufficient -X- _ O
cluster -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
task -X- _ O
contains -X- _ O
10 -X- _ O
K -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
other -X- _ O
choices -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
C.1 -X- _ O
. -X- _ O
“ -X- _ O
Few -X- _ O
Datasets -X- _ O
” -X- _ O
means -X- _ O
only -X- _ O
10 -X- _ O
% -X- _ O
human -X- _ O
- -X- _ O
labeled -X- _ O
datasets -X- _ O
exist -X- _ O
in -X- _ O
each -X- _ O
task -X- _ O
cluster -X- _ O
. -X- _ O
And -X- _ O
the -X- _ O
“ -X- _ O
Few -X- _ O
Samples -X- _ O
” -X- _ O
block -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
where -X- _ O
IT -X- _ O
is -X- _ O
performed -X- _ O
on -X- _ O
all -X- _ O
task -X- _ O
clusters -X- _ O
, -X- _ O
but -X- _ O
each -X- _ O
dataset -X- _ O
contains -X- _ O
only -X- _ O
100 -X- _ O
samples -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
data -X- _ O
augmentation -X- _ O
( -X- _ O
DataAug -X- _ O
- -X- _ O
IT -X- _ O
) -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
“ -X- _ O
Few -X- _ O
Samples -X- _ O
” -X- _ O
setting -X- _ O
because -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
source -X- _ O
data -X- _ O
for -X- _ O
back -X- _ O
- -X- _ O
translation -X- _ O
in -X- _ O
other -X- _ O
settings -X- _ O
. -X- _ O
UDIT -X- _ B-MethodName
adds -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
those -X- _ O
data -X- _ O
- -X- _ O
scarce -X- _ O
tasks -X- _ O
to -X- _ O
enhance -X- _ O
instruction -X- _ O
learning -X- _ O
. -X- _ O
Our -X- _ O
findings -X- _ O
from -X- _ O
Table -X- _ O
2 -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
1.SelfSup -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
and -X- _ O
DataAug -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
fail -X- _ O
to -X- _ O
bring -X- _ O
significant -X- _ O
improvement -X- _ O
over -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
. -X- _ O
It -X- _ O
is -X- _ O
probably -X- _ O
because -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
tasks -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
instructions -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
are -X- _ O
too -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
samples -X- _ O
. -X- _ O
2.UDIT -X- _ B-MethodName
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
average -X- _ O
under -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
settings -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
learning -X- _ O
instruction -X- _ O
semantics -X- _ O
and -X- _ O
training -X- _ O
on -X- _ O
sufficient1621 -X- _ O
diverse -X- _ O
data -X- _ O
are -X- _ O
crucial -X- _ O
to -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
of -X- _ O
PLMs -X- _ O
. -X- _ O
3.Unlike -X- _ O
the -X- _ O
observations -X- _ O
in -X- _ O
Section -X- _ O
4.2.1 -X- _ O
, -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
combining -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
tasks -X- _ O
with -X- _ O
UDIT -X- _ B-MethodName
vanishes -X- _ O
with -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
the -X- _ O
few -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
evaluate -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
and -X- _ O
UDIT -X- _ B-MethodName
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
data -X- _ O
- -X- _ O
sufficient -X- _ O
tasks -X- _ O
varies -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
incrementally -X- _ O
add -X- _ O
task -X- _ O
clusters -X- _ O
containing -X- _ O
full -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
And -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
gradually -X- _ O
increase -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
data -X- _ O
- -X- _ O
sufficient -X- _ O
tasks -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O
In -X- _ O
these -X- _ O
processes -X- _ O
, -X- _ O
other -X- _ O
tasks -X- _ O
are -X- _ O
considered -X- _ O
data -X- _ O
- -X- _ O
scarce -X- _ O
, -X- _ O
containing -X- _ O
100 -X- _ O
( -X- _ O
Few -X- _ O
Extra -X- _ O
Labeled -X- _ O
) -X- _ O
or -X- _ O
no -X- _ O
( -X- _ O
No -X- _ O
Extra -X- _ O
Labeled -X- _ O
) -X- _ O
labeled -X- _ O
samples -X- _ O
to -X- _ O
simulate -X- _ O
the -X- _ O
situation -X- _ O
when -X- _ O
both -X- _ O
data -X- _ O
- -X- _ O
sufficient -X- _ O
and -X- _ O
data -X- _ O
- -X- _ O
scarce -X- _ O
tasks -X- _ O
exist -X- _ O
. -X- _ O
UDIT -X- _ B-MethodName
enhances -X- _ O
the -X- _ O
data -X- _ O
- -X- _ O
scarce -X- _ O
tasks -X- _ O
with -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data.1622 -X- _ O
By -X- _ O
comparing -X- _ O
the -X- _ O
solid -X- _ O
anddashed -X- _ O
lines -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
training -X- _ O
on -X- _ O
more -X- _ O
tasks -X- _ O
and -X- _ O
instructions -X- _ O
is -X- _ O
beneficial -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
some -X- _ O
tasks -X- _ O
contain -X- _ O
only -X- _ O
100 -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
orange -X- _ O
and -X- _ O
blue -X- _ O
lines -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
leads -X- _ O
to -X- _ O
further -X- _ O
improvement -X- _ O
when -X- _ O
applied -X- _ O
to -X- _ O
those -X- _ O
data -X- _ O
- -X- _ O
scarce -X- _ O
tasks -X- _ O
, -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
the -X- _ O
100 -X- _ O
labeled -X- _ O
samples -X- _ O
. -X- _ O
From -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
the -X- _ O
performance -X- _ O
drop -X- _ O
when -X- _ O
adding -X- _ O
TC -X- _ O
, -X- _ O
which -X- _ O
matches -X- _ O
the -X- _ O
observation -X- _ O
in -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022a -X- _ O
) -X- _ O
that -X- _ O
not -X- _ O
all -X- _ O
the -X- _ O
task -X- _ O
clusters -X- _ O
are -X- _ O
helpful -X- _ O
. -X- _ O
But -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
IT -X- _ O
has -X- _ O
a -X- _ O
positive -X- _ O
correlation -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
number -X- _ O
and -X- _ O
diversity -X- _ O
. -X- _ O
4.2.3 -X- _ O
Full -X- _ O
Labeled -X- _ O
Data -X- _ O
When -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
sufficient -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
mix -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
perform -X- _ O
IT -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
adding -X- _ O
10 -X- _ O
K -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
IT -X- _ O
performance -X- _ O
, -X- _ O
making -X- _ O
our -X- _ O
700 -X- _ O
M -X- _ O
model -X- _ O
outperform -X- _ O
the -X- _ O
3B -X- _ O
model -X- _ O
with -X- _ O
VanillaIT -X- _ B-MethodName
. -X- _ O
But -X- _ O
increasing -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
50k -X- _ O
only -X- _ O
leads -X- _ O
to -X- _ O
little -X- _ O
further -X- _ O
improvement -X- _ O
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
do -X- _ O
not -X- _ O
merely -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
amount -X- _ O
per -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
these -X- _ O
samples -X- _ O
also -X- _ O
help -X- _ O
avoid -X- _ O
overfitting -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
specific -X- _ O
datasets -X- _ O
during -X- _ O
IT -X- _ O
, -X- _ O
owing -X- _ O
to -X- _ O
the -X- _ O
domain -X- _ O
diversity -X- _ O
of -X- _ O
unlabeled -X- _ O
corpora -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
be -X- _ O
further -X- _ O
analyzed -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
. -X- _ O
4.2.4 -X- _ O
Language -X- _ O
Generation -X- _ O
Tasks -X- _ O
We -X- _ O
also -X- _ O
test -X- _ O
the -X- _ O
instruction -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
on -X- _ O
two -X- _ O
language -X- _ O
generation -X- _ O
tasks -X- _ O
. -X- _ O
From -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
the -X- _ O
similar -X- _ O
phenomenon -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
improves -X- _ O
IT -X- _ O
the -X- _ O
most -X- _ O
in -X- _ O
all -X- _ O
scenarios -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
training -X- _ O
is -X- _ O
more -X- _ O
beneficial -X- _ O
to -X- _ O
language -X- _ O
generation -X- _ O
than -X- _ O
classification -X- _ O
. -X- _ O
Thisis -X- _ O
likely -X- _ O
because -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
tasks -X- _ O
include -X- _ O
Next -X- _ O
Sentence -X- _ O
Generation -X- _ O
and -X- _ O
Next -X- _ O
Phrase -X- _ O
Generation -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
resemble -X- _ O
the -X- _ O
generation -X- _ O
tasks -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
evaluation -X- _ O
. -X- _ O
4.3 -X- _ O
Discussion -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
4.2 -X- _ O
, -X- _ O
we -X- _ O
conclude -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
is -X- _ O
effective -X- _ O
under -X- _ O
all -X- _ O
three -X- _ O
settings -X- _ O
on -X- _ O
both -X- _ O
classification -X- _ B-TaskName
and -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
brings -X- _ O
larger -X- _ O
improvements -X- _ O
to -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
and -X- _ O
Sentence -X- _ B-TaskName
Completion -X- _ I-TaskName
( -X- _ O
Sentence -X- _ B-TaskName
Comp -X- _ I-TaskName
. -X- _ O
) -X- _ O
compared -X- _ O
to -X- _ O
Coreference -X- _ B-TaskName
Resolution -X- _ I-TaskName
( -X- _ O
Coref -X- _ B-TaskName
. -X- _ O
) -X- _ O
and -X- _ O
Word -X- _ B-TaskName
Sense -X- _ I-TaskName
Disambiguation -X- _ I-TaskName
( -X- _ O
WSD -X- _ B-TaskName
) -X- _ O
, -X- _ O
which -X- _ O
resembles -X- _ O
the -X- _ O
phenomenon -X- _ O
of -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
. -X- _ O
We -X- _ O
suspect -X- _ O
that -X- _ O
our -X- _ O
training -X- _ O
tasks -X- _ O
are -X- _ O
mostly -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
tasks -X- _ O
in -X- _ O
Coref -X- _ B-TaskName
. -X- _ O
and -X- _ O
WSD -X- _ B-TaskName
are -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O
Although -X- _ O
IT -X- _ O
enables -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
for -X- _ O
PLMs -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
challenging -X- _ O
to -X- _ O
generalize -X- _ O
from -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
to -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
. -X- _ O
This -X- _ O
also -X- _ O
emphasizes -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
using -X- _ O
instructions -X- _ O
from -X- _ O
more -X- _ O
diverse -X- _ O
tasks -X- _ O
for -X- _ O
IT -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
variance -X- _ O
across -X- _ O
different -X- _ O
testing -X- _ O
instructions -X- _ O
is -X- _ O
high -X- _ O
on -X- _ O
some -X- _ O
tasks -X- _ O
( -X- _ O
Figure -X- _ O
5 -X- _ O
in -X- _ O
Appendix -X- _ O
C.3 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
observations -X- _ O
in -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Reducing -X- _ O
the -X- _ O
sensitivity -X- _ O
of -X- _ O
PLMs -X- _ O
to -X- _ O
prompts -X- _ O
and -X- _ O
instructions -X- _ O
has -X- _ O
been -X- _ O
largely -X- _ O
discussed -X- _ O
in -X- _ O
previous -X- _ O
literature -X- _ O
( -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
are -X- _ O
applicable -X- _ O
to -X- _ O
our -X- _ O
settings -X- _ O
. -X- _ O
5 -X- _ O
Analysis -X- _ O
5.1 -X- _ O
Effect -X- _ O
of -X- _ O
Instruction -X- _ O
Tuning -X- _ O
IT -X- _ O
brings -X- _ O
two -X- _ O
effects -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
helping -X- _ O
the -X- _ O
model -X- _ O
get -X- _ O
familiar -X- _ O
with -X- _ O
the -X- _ O
input -X- _ O
form -X- _ O
containing -X- _ O
human -X- _ O
instructions -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
enabling -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
mapping -X- _ O
between -X- _ O
the -X- _ O
instructions -X- _ O
and -X- _ O
task -X- _ O
semantics -X- _ O
. -X- _ O
To -X- _ O
differentiate -X- _ O
these -X- _ O
effects -X- _ O
, -X- _ O
we -X- _ O
construct1623 -X- _ O
tasks -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
match -X- _ O
the -X- _ O
instructions -X- _ O
by -X- _ O
randomly -X- _ O
setting -X- _ O
the -X- _ O
labels -X- _ O
in -X- _ O
the -X- _ O
labeled -X- _ O
and -X- _ O
pseudolabeled -X- _ O
samples -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
although -X- _ O
we -X- _ O
randomize -X- _ O
the -X- _ O
labels -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
IT -X- _ O
are -X- _ O
still -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
No -X- _ O
IT -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
form -X- _ O
matters -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
performance -X- _ O
gap -X- _ O
exists -X- _ O
between -X- _ O
the -X- _ O
random -X- _ O
and -X- _ O
correct -X- _ O
labels -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
the -X- _ O
instruction -X- _ O
- -X- _ O
task -X- _ O
mapping -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
instruction -X- _ O
form -X- _ O
. -X- _ O
5.2 -X- _ O
Effect -X- _ O
of -X- _ O
Domain -X- _ O
Diversity -X- _ O
As -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
our -X- _ O
unlabeled -X- _ O
data -X- _ O
are -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
plain -X- _ O
- -X- _ O
text -X- _ O
corpora -X- _ O
. -X- _ O
To -X- _ O
investigate -X- _ O
the -X- _ O
domain -X- _ O
diversity -X- _ O
effect -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
only -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
for -X- _ O
the -X- _ O
task -X- _ O
clusters -X- _ O
other -X- _ O
than -X- _ O
SENT -X- _ B-TaskName
and -X- _ O
TC -X- _ B-TaskName
, -X- _ O
where -X- _ O
we -X- _ O
still -X- _ O
use -X- _ O
IMDB -X- _ B-DatasetName
Review -X- _ I-DatasetName
and -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
. -X- _ O
This -X- _ O
ensures -X- _ O
that -X- _ O
each -X- _ O
cluster -X- _ O
contains -X- _ O
a -X- _ O
single -X- _ O
domain -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
maintain -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
samples -X- _ O
as -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
circumstance -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
reducing -X- _ O
the -X- _ O
domain -X- _ O
diversity -X- _ O
hurts -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
“ -X- _ O
No -X- _ O
Labeled -X- _ O
Data -X- _ O
” -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
mostly -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
additional -X- _ O
instructions -X- _ O
. -X- _ O
But -X- _ O
in -X- _ O
the -X- _ O
“ -X- _ O
Full -X- _ O
Labeled -X- _ O
Data -X- _ O
” -X- _ O
scenario -X- _ O
, -X- _ O
the -X- _ O
domain -X- _ O
diversity -X- _ O
contributes -X- _ O
most -X- _ O
to -X- _ O
the -X- _ O
improvement -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
5.3 -X- _ O
Effect -X- _ O
of -X- _ O
Data -X- _ O
Amount -X- _ O
Since -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
are -X- _ O
constructed -X- _ O
from -X- _ O
the -X- _ O
plain -X- _ O
- -X- _ O
text -X- _ O
corpus -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
numerous -X- _ O
training -X- _ O
samples -X- _ O
for -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
converges -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
training -X- _ O
samples -X- _ O
per -X- _ O
task -X- _ O
reaches -X- _ O
10k -X- _ O
in -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
scenarios -X- _ O
we -X- _ O
consider -X- _ O
in -X- _ O
Section -X- _ O
4.2 -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
other -X- _ O
methods -X- _ O
using -X- _ O
unlabeled -X- _ O
data -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
where -X- _ O
increasing -X- _ O
the -X- _ O
data -X- _ O
amount -X- _ O
continuously -X- _ O
improves -X- _ O
downstream -X- _ O
performance -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Kaplan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
is -X- _ O
not -X- _ O
data -X- _ O
- -X- _ O
hungry -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
consume -X- _ O
much -X- _ O
more -X- _ O
training -X- _ O
resources -X- _ O
than -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
. -X- _ O
5.4 -X- _ O
Effect -X- _ O
of -X- _ O
Individual -X- _ O
Task -X- _ O
Clusters -X- _ O
The -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
inevitably -X- _ O
contain -X- _ O
noises -X- _ O
which -X- _ O
may -X- _ O
hurt -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
Therefore,1624 -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
these -X- _ O
noises -X- _ O
in -X- _ O
each -X- _ O
task -X- _ O
cluster -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
one -X- _ O
task -X- _ O
cluster -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
replace -X- _ O
the -X- _ O
labeled -X- _ O
samples -X- _ O
with -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
samples -X- _ O
, -X- _ O
and -X- _ O
perform -X- _ O
IT -X- _ O
on -X- _ O
the -X- _ O
mixed -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
4 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
using -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
MCQA -X- _ O
affects -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
the -X- _ O
most -X- _ O
. -X- _ O
But -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
replacing -X- _ O
one -X- _ O
task -X- _ O
cluster -X- _ O
does -X- _ O
not -X- _ O
bring -X- _ O
much -X- _ O
influence -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
that -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
are -X- _ O
of -X- _ O
high -X- _ O
quality -X- _ O
and -X- _ O
UDIT -X- _ B-MethodName
is -X- _ O
robust -X- _ O
to -X- _ O
the -X- _ O
noises -X- _ O
in -X- _ O
individual -X- _ O
task -X- _ O
clusters -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
comparing -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
still -X- _ O
has -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
that -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
ignored -X- _ O
when -X- _ O
replacing -X- _ O
all -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
probably -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
noise -X- _ O
accumulation -X- _ O
in -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
of -X- _ O
multiple -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
how -X- _ O
to -X- _ O
further -X- _ O
reduce -X- _ O
the -X- _ O
noises -X- _ O
in -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
6 -X- _ O
Conclusion -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
performing -X- _ O
IT -X- _ O
with -X- _ O
unlabeled -X- _ O
data -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
empirically -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
IT -X- _ O
performance -X- _ O
is -X- _ O
largely -X- _ O
restricted -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
distinct -X- _ O
tasks -X- _ O
, -X- _ O
instructions -X- _ O
, -X- _ O
and -X- _ O
training -X- _ O
samples -X- _ O
in -X- _ O
data -X- _ O
- -X- _ O
scarce -X- _ O
tasks -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
UDIT -X- _ B-MethodName
to -X- _ O
take -X- _ O
better -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
instructions -X- _ O
by -X- _ O
constructing -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
. -X- _ O
Through -X- _ O
UDIT -X- _ B-MethodName
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
perform -X- _ O
IT -X- _ O
with -X- _ O
unlabeled -X- _ O
data -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
few -X- _ O
or -X- _ O
no -X- _ O
humanannotated -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
offers -X- _ O
a -X- _ O
better -X- _ O
way -X- _ O
to -X- _ O
incorporate -X- _ O
unlabeled -X- _ O
data -X- _ O
compared -X- _ O
with -X- _ O
other -X- _ O
approaches -X- _ O
. -X- _ O
Through -X- _ O
comprehensive -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
domain -X- _ O
diversity -X- _ O
and -X- _ O
the -X- _ O
matching -X- _ O
between -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
and -X- _ O
corresponding -X- _ O
instructions -X- _ O
are -X- _ O
essential -X- _ O
for -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
noises -X- _ O
in -X- _ O
individual -X- _ O
task -X- _ O
clusters -X- _ O
and -X- _ O
colossal -X- _ O
data -X- _ O
amount -X- _ O
are -X- _ O
less -X- _ O
influential -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
three -X- _ O
directions -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Designing -X- _ O
automatic -X- _ O
and -X- _ O
generalizable -X- _ O
methods -X- _ O
to -X- _ O
construct -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
instruction -X- _ O
tuning -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Mining -X- _ O
novel -X- _ O
in -X- _ O
- -X- _ O
structions -X- _ O
from -X- _ O
the -X- _ O
unlabeled -X- _ O
corpus -X- _ O
to -X- _ O
enlarge -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
instructions -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Further -X- _ O
denoising -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
built -X- _ O
from -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
. -X- _ O
Limitations -X- _ O
The -X- _ O
limitation -X- _ O
of -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
constructing -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
still -X- _ O
needs -X- _ O
manual -X- _ O
design -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
strategies -X- _ O
we -X- _ O
use -X- _ O
are -X- _ O
easy -X- _ O
to -X- _ O
implement -X- _ O
and -X- _ O
our -X- _ O
pseudolabeled -X- _ O
data -X- _ O
have -X- _ O
covered -X- _ O
a -X- _ O
big -X- _ O
part -X- _ O
of -X- _ O
classic -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
there -X- _ O
may -X- _ O
exist -X- _ O
some -X- _ O
“ -X- _ O
hard -X- _ O
tasks -X- _ O
” -X- _ O
where -X- _ O
finding -X- _ O
suitable -X- _ O
methods -X- _ O
to -X- _ O
construct -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
easy -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
severe -X- _ O
problem -X- _ O
in -X- _ O
practice -X- _ O
because -X- _ O
UDIT -X- _ B-MethodName
boosts -X- _ O
instruction -X- _ O
learning -X- _ O
for -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
. -X- _ O
This -X- _ O
means -X- _ O
we -X- _ O
can -X- _ O
still -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
“ -X- _ O
hard -X- _ O
tasks -X- _ O
” -X- _ O
with -X- _ O
UDIT -X- _ B-MethodName
based -X- _ O
on -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
“ -X- _ O
easy -X- _ O
tasks -X- _ O
” -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
more -X- _ O
generalizable -X- _ O
and -X- _ O
elaborate -X- _ O
data -X- _ O
construction -X- _ O
methods -X- _ O
would -X- _ O
further -X- _ O
improve -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
this -X- _ O
as -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
findings -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
can -X- _ O
guide -X- _ O
the -X- _ O
design -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
. -X- _ O
Acknowledgements -X- _ O
This -X- _ O
paper -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Key -X- _ O
Research -X- _ O
and -X- _ O
Development -X- _ O
Program -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
2021ZD0113304 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
for -X- _ O
Distinguished -X- _ O
Young -X- _ O
Scholars -X- _ O
( -X- _ O
with -X- _ O
No -X- _ O
. -X- _ O
62125604 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
NSFC -X- _ O
projects -X- _ O
( -X- _ O
Key -X- _ O
project -X- _ O
with -X- _ O
No -X- _ O
. -X- _ O
61936010 -X- _ O
and -X- _ O
regular -X- _ O
project -X- _ O
with -X- _ O
No -X- _ O
. -X- _ O
61876096 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
also -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Guoqiang -X- _ O
Institute -X- _ O
of -X- _ O
Tsinghua -X- _ O
University -X- _ O
, -X- _ O
with -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
2019GQG1 -X- _ O
and -X- _ O
2020GQG0005 -X- _ O
, -X- _ O
and -X- _ O
sponsored -X- _ O
by -X- _ O
Tsinghua -X- _ O
- -X- _ O
Toyota -X- _ O
Joint -X- _ O
Research -X- _ O
Fund -X- _ O
. -X- _ O
References16251626162716281629Appendices -X- _ O
A -X- _ O
Data -X- _ O
Information -X- _ O
A.1 -X- _ O
Training -X- _ O
Tasks -X- _ O
Following -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
8 -X- _ O
task -X- _ O
clusters -X- _ O
containing -X- _ O
36 -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
datasets -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
instructions -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
All -X- _ O
instructions -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
the -X- _ O
Public -X- _ O
Pool -X- _ O
of -X- _ O
Prompts -X- _ O
( -X- _ O
P3 -X- _ O
) -X- _ O
( -X- _ O
Bach -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
A.2 -X- _ O
Evaluation -X- _ O
Tasks -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
4 -X- _ O
text -X- _ O
classification -X- _ O
task -X- _ O
clusters -X- _ O
and -X- _ O
2 -X- _ O
language -X- _ O
generation -X- _ O
task -X- _ O
clusters -X- _ O
. -X- _ O
The -X- _ O
text -X- _ O
classification -X- _ O
task -X- _ O
clusters -X- _ O
and -X- _ O
datasets -X- _ O
include -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Coreference -X- _ B-TaskName
Resolution -X- _ I-TaskName
( -X- _ O
Coref -X- _ B-TaskName
. -X- _ O
) -X- _ O
: -X- _ O
WSC -X- _ B-TaskName
and -X- _ O
Winogrande -X- _ B-TaskName
( -X- _ O
Wino -X- _ B-TaskName
. -X- _ O
) -X- _ O
( -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
: -X- _ O
CB -X- _ B-TaskName
( -X- _ O
De -X- _ O
Marneffe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
RTE -X- _ B-TaskName
( -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ANLI -X- _ B-TaskName
- -X- _ I-TaskName
R1 -X- _ I-TaskName
( -X- _ O
Nie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Sentence -X- _ B-TaskName
Completion -X- _ I-TaskName
( -X- _ O
Sentence -X- _ B-TaskName
Comp -X- _ I-TaskName
. -X- _ O
) -X- _ O
: -X- _ O
COPA -X- _ B-TaskName
( -X- _ O
Gordon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
HellaSwag -X- _ B-TaskName
( -X- _ O
H -X- _ O
- -X- _ O
Swag -X- _ O
) -X- _ O
( -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Story -X- _ B-TaskName
Cloze -X- _ I-TaskName
( -X- _ O
Mostafazadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Word -X- _ B-TaskName
Sense -X- _ I-TaskName
Diasambiguation -X- _ I-TaskName
( -X- _ O
WSD -X- _ O
) -X- _ O
: -X- _ O
WIC -X- _ B-TaskName
( -X- _ O
Pilehvar -X- _ O
and -X- _ O
Camacho -X- _ O
- -X- _ O
Collados -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
generation -X- _ O
task -X- _ O
clusters -X- _ O
and -X- _ O
datasets -X- _ O
include -X- _ O
: -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Question -X- _ B-TaskName
Generation -X- _ I-TaskName
( -X- _ O
QG -X- _ B-TaskName
) -X- _ O
: -X- _ O
SQuAD -X- _ B-TaskName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
OpenEnded -X- _ B-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Generation -X- _ I-TaskName
( -X- _ O
ONLG -X- _ B-TaskName
) -X- _ O
: -X- _ O
Roc -X- _ B-TaskName
Story -X- _ I-TaskName
( -X- _ O
Mostafazadeh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
instructions -X- _ O
are -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
Public -X- _ B-DatasetName
Pool -X- _ I-DatasetName
of -X- _ I-DatasetName
Prompts -X- _ I-DatasetName
( -X- _ O
P3 -X- _ O
) -X- _ O
( -X- _ O
Bach -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
A.3 -X- _ O
Unlabeled -X- _ O
Data -X- _ O
Our -X- _ O
unlabeled -X- _ O
plain -X- _ O
texts -X- _ O
consist -X- _ O
of -X- _ O
the -X- _ O
multidomain -X- _ O
corpus -X- _ O
, -X- _ O
including -X- _ O
BookCorpus -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
( -X- _ O
5.5 -X- _ O
G -X- _ O
) -X- _ O
, -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
Foundation -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
( -X- _ O
20 -X- _ O
G -X- _ O
) -X- _ O
, -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
News -X- _ I-DatasetName
( -X- _ O
Sebastian -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
( -X- _ O
1.7 -X- _ O
G -X- _ O
) -X- _ O
, -X- _ O
OpenWebText -X- _ B-DatasetName
( -X- _ O
Gokaslan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
10 -X- _ O
G -X- _ O
) -X- _ O
, -X- _ O
IMDB -X- _ B-DatasetName
Review -X- _ I-DatasetName
( -X- _ O
Maas -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
( -X- _ O
65 -X- _ O
M -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
access -X- _ O
these -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
HuggingFace -X- _ O
Datasets -X- _ O
( -X- _ O
Lhoest -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
OpenWebText -X- _ B-DatasetName
, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
10 -X- _ O
GB -X- _ O
sample -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
38 -X- _ O
GB -X- _ O
samples -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
data -X- _ O
sources -X- _ O
. -X- _ O
B -X- _ O
More -X- _ O
Training -X- _ O
Details -X- _ O
We -X- _ O
run -X- _ O
IT -X- _ O
on -X- _ O
a -X- _ O
700 -X- _ O
M -X- _ O
T5 -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
max -X- _ O
input -X- _ O
sequence -X- _ O
lengths -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
decoder -X- _ O
are -X- _ O
512 -X- _ O
and -X- _ O
128 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
run -X- _ O
VanillaIT -X- _ B-MethodName
to -X- _ O
select -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
that -X- _ O
yield -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
splits -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
datasets -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
fix -X- _ O
the -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
in -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
We -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
1e-4 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
512 -X- _ B-HyperparameterValue
, -X- _ O
1024 -X- _ B-HyperparameterValue
, -X- _ O
2048 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
training -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
in -X- _ O
[ -X- _ O
10 -X- _ B-MetricName
K -X- _ I-MetricName
, -X- _ O
30 -X- _ B-MetricName
K -X- _ I-MetricName
] -X- _ O
. -X- _ O
We -X- _ O
finally -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
1024 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
training -X- _ I-HyperparameterName
steps -X- _ I-HyperparameterName
to -X- _ O
10 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
for -X- _ O
both -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
and -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
β= -X- _ B-HyperparameterName
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β= -X- _ B-HyperparameterName
0.999 -X- _ B-HyperparameterValue
, -X- _ O
ϵ= -X- _ B-HyperparameterName
1e−8 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
weight_decay -X- _ B-HyperparameterName
= -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
follow -X- _ O
Wei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
to -X- _ O
balance -X- _ O
each -X- _ O
dataset -X- _ O
by -X- _ O
treating -X- _ O
each -X- _ O
task -X- _ O
at -X- _ O
most -X- _ O
3 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
samples -X- _ B-HyperparameterName
per -X- _ I-HyperparameterName
instruction -X- _ I-HyperparameterName
for -X- _ O
sampling -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
training -X- _ O
efficiency -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
mixed -X- _ O
- -X- _ O
precision -X- _ O
training -X- _ O
( -X- _ O
Micikevicius -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
1630 -X- _ O
and -X- _ O
ZeRO -X- _ O
( -X- _ O
stage-1 -X- _ O
) -X- _ O
( -X- _ O
Rajbhandari -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
implemented -X- _ O
in -X- _ O
DeepSpeed -X- _ O
( -X- _ O
Rasley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
T0 -X- _ O
- -X- _ O
3B -X- _ O
model -X- _ O
is -X- _ O
evaluated -X- _ O
in -X- _ O
FP32 -X- _ O
precision -X- _ O
. -X- _ O
Our -X- _ O
experiments -X- _ O
are -X- _ O
all -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
NVIDIA -X- _ O
32 -X- _ O
G -X- _ O
V100 -X- _ O
GPU -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
GPUs -X- _ O
for -X- _ O
each -X- _ O
run -X- _ O
of -X- _ O
IT -X- _ O
, -X- _ O
which -X- _ O
completes -X- _ O
in -X- _ O
about -X- _ O
12 -X- _ O
hours -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
total -X- _ O
training -X- _ O
data -X- _ O
amount -X- _ O
. -X- _ O
The -X- _ O
inference -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
occupies -X- _ O
one -X- _ O
GPU -X- _ O
and -X- _ O
takes -X- _ O
about -X- _ O
10 -X- _ O
minutes -X- _ O
. -X- _ O
C -X- _ O
More -X- _ O
results -X- _ O
C.1 -X- _ O
Other -X- _ O
Choices -X- _ O
of -X- _ O
the -X- _ O
“ -X- _ O
Few -X- _ O
Tasks -X- _ O
” -X- _ O
Setting -X- _ O
In -X- _ O
Table -X- _ O
9 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
when -X- _ O
we -X- _ O
use -X- _ O
different -X- _ O
task -X- _ O
clusters -X- _ O
as -X- _ O
the -X- _ O
data -X- _ O
- -X- _ O
sufficient -X- _ O
cluster -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
complementary -X- _ O
to -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
improves -X- _ O
Vanilla -X- _ B-MethodName
IT -X- _ I-MethodName
in -X- _ O
most -X- _ O
cases -X- _ O
. -X- _ O
One -X- _ O
exception -X- _ O
is -X- _ O
the -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
tasks -X- _ O
when -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
EXQA -X- _ B-TaskName
. -X- _ O
We -X- _ O
think -X- _ O
the -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
some -X- _ O
tasks -X- _ O
in -X- _ O
EXQA -X- _ B-TaskName
are -X- _ O
also -X- _ O
formulated -X- _ O
to -X- _ O
question -X- _ O
generation -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
too -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
evaluation -X- _ O
task -X- _ O
and -X- _ O
cover -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
of -X- _ O
Vanilla -X- _ B-MethodName
- -X- _ I-MethodName
IT -X- _ I-MethodName
on -X- _ O
language -X- _ O
generation -X- _ O
tasks -X- _ O
is -X- _ O
really -X- _ O
poor -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ O
SENT -X- _ B-TaskName
, -X- _ O
TC -X- _ B-TaskName
, -X- _ O
or -X- _ O
PARA -X- _ B-TaskName
, -X- _ O
which -X- _ O
mainly -X- _ O
consist -X- _ O
of -X- _ O
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
all -X- _ O
output -X- _ O
texts -X- _ O
are -X- _ O
biased -X- _ O
to -X- _ O
the -X- _ O
labels -X- _ O
of -X- _ O
corresponding -X- _ O
training -X- _ O
datasets -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
model -X- _ O
overfits -X- _ O
the -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
during -X- _ O
IT -X- _ O
and -X- _ O
fails -X- _ O
to -X- _ O
learn -X- _ O
to -X- _ O
follow -X- _ O
instructions -X- _ O
in -X- _ O
unseen -X- _ O
tasks -X- _ O
. -X- _ O
C.2 -X- _ O
Median -X- _ O
Results -X- _ O
Across -X- _ O
Different -X- _ O
Testing -X- _ O
Instructions -X- _ O
Following -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
median -X- _ O
of -X- _ O
the -X- _ O
performances -X- _ O
across -X- _ O
different -X- _ O
testing -X- _ O
instructions -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
, -X- _ O
Table -X- _ O
11 -X- _ O
, -X- _ O
and -X- _ O
Table -X- _ O
12 -X- _ O
as -X- _ O
a -X- _ O
supplement -X- _ O
to -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
the -X- _ O
performances -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
and -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Comparing -X- _ O
different -X- _ O
approaches -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
draw -X- _ O
similar -X- _ O
conclusions -X- _ O
as -X- _ O
Section -X- _ O
4.2 -X- _ O
that -X- _ O
UDIT -X- _ B-MethodName
offers -X- _ O
a -X- _ O
significantly -X- _ O
better -X- _ O
way -X- _ O
to -X- _ O
incorporate -X- _ O
unlabeled -X- _ O
data -X- _ O
into -X- _ O
IT -X- _ O
and -X- _ O
improves -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
cross -X- _ O
- -X- _ O
task -X- _ O
generalization -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
median -X- _ O
do -X- _ O
not -X- _ O
differ -X- _ O
much -X- _ O
on -X- _ O
most -X- _ O
datasets -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
CB -X- _ O
where -X- _ O
the -X- _ O
median -X- _ O
is -X- _ O
much -X- _ O
better -X- _ O
. -X- _ O
C.3 -X- _ O
Variance -X- _ O
Across -X- _ O
Instructions -X- _ O
We -X- _ O
draw -X- _ O
the -X- _ O
box -X- _ O
plot -X- _ O
of -X- _ O
UDIT -X- _ B-MethodName
and -X- _ O
some -X- _ O
baselines -X- _ O
under -X- _ O
the -X- _ O
“ -X- _ O
No -X- _ O
Labeled -X- _ O
Data -X- _ O
” -X- _ O
( -X- _ O
Section -X- _ O
4.2.1 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
“ -X- _ O
Full -X- _ O
Labeled -X- _ O
Data -X- _ O
” -X- _ O
( -X- _ O
Section -X- _ O
4.2.3 -X- _ O
) -X- _ O
settings -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
variance -X- _ O
across -X- _ O
different -X- _ O
instructions -X- _ O
. -X- _ O
From -X- _ O
Figure -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
vary -X- _ O
across -X- _ O
instructions -X- _ O
in -X- _ O
all -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
observed -X- _ O
in -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
plenty -X- _ O
of -X- _ O
studies -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
variance -X- _ O
across -X- _ O
prompts -X- _ O
or -X- _ O
instructions -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
them -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
our -X- _ O
methods -X- _ O
. -X- _ O
C.4 -X- _ O
Human -X- _ O
Evaluation -X- _ O
on -X- _ O
Pseudo -X- _ O
- -X- _ O
Labeled -X- _ O
Data -X- _ O
We -X- _ O
conduct -X- _ O
human -X- _ O
evaluation -X- _ O
on -X- _ O
the -X- _ O
pseudolabeled -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
13 -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
cluster -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
select -X- _ O
50 -X- _ O
sample -X- _ O
- -X- _ O
instruction -X- _ O
pairs -X- _ O
and -X- _ O
recruit -X- _ O
3 -X- _ O
different -X- _ O
annotators -X- _ O
from -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turkto -X- _ O
evalu-1631 -X- _ O
ate -X- _ O
whether -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
sample -X- _ O
is -X- _ O
aligned -X- _ O
with -X- _ O
the -X- _ O
instruction -X- _ O
( -X- _ O
scored -X- _ O
as -X- _ O
1 -X- _ O
) -X- _ O
or -X- _ O
not -X- _ O
( -X- _ O
scored -X- _ O
as -X- _ O
0 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
cluster -X- _ O
is -X- _ O
averaged -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
samples -X- _ O
and -X- _ O
3 -X- _ O
different -X- _ O
annotators -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
although -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
samples -X- _ O
make -X- _ O
sense -X- _ O
to -X- _ O
humans -X- _ O
, -X- _ O
there -X- _ O
inevitably -X- _ O
exist -X- _ O
some -X- _ O
mislabeled -X- _ O
samples -X- _ O
that -X- _ O
may -X- _ O
be -X- _ O
harmful -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
how -X- _ O
to -X- _ O
further -X- _ O
denoise -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
D -X- _ O
Examples -X- _ O
of -X- _ O
Pseudo -X- _ O
- -X- _ O
Labeled -X- _ O
Data -X- _ O
We -X- _ O
list -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
8 -X- _ O
task -X- _ O
clusters -X- _ O
in -X- _ O
Table -X- _ O
14 -X- _ O
. -X- _ O
In -X- _ O
MCQA -X- _ B-TaskName
, -X- _ O
EXQA -X- _ B-TaskName
, -X- _ O
and -X- _ O
CBQA -X- _ B-TaskName
, -X- _ O
although -X- _ O
the -X- _ O
constructing -X- _ O
process -X- _ O
relies -X- _ O
on -X- _ O
some -X- _ O
assumptions -X- _ O
, -X- _ O
the -X- _ O
pseudolabeled -X- _ O
data -X- _ O
reflect -X- _ O
the -X- _ O
task -X- _ O
semantics -X- _ O
well -X- _ O
and -X- _ O
thus -X- _ O
match -X- _ O
the -X- _ O
meanings -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
instructions -X- _ O
. -X- _ O
We -X- _ O
notice -X- _ O
some -X- _ O
incoherence -X- _ O
and -X- _ O
typos -X- _ O
in -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
affect -X- _ O
the -X- _ O
general -X- _ O
meanings -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
. -X- _ O
For -X- _ O
TC -X- _ B-TaskName
, -X- _ O
SENT -X- _ B-TaskName
, -X- _ O
and -X- _ O
SUM -X- _ B-TaskName
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
to -X- _ O
be -X- _ O
of -X- _ O
high -X- _ O
quality -X- _ O
. -X- _ O
For -X- _ O
S2 -X- _ B-TaskName
T -X- _ I-TaskName
and -X- _ O
PARA -X- _ B-TaskName
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
is -X- _ O
much -X- _ O
easier -X- _ O
than -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
harm -X- _ O
conventional -X- _ O
supervised -X- _ O
learning -X- _ O
since -X- _ O
these -X- _ O
data -X- _ O
can -X- _ O
hurt -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
ability -X- _ O
to -X- _ O
solve -X- _ O
hard -X- _ O
samples -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
this -X- _ O
issue -X- _ O
is -X- _ O
not -X- _ O
that -X- _ O
severe -X- _ O
in -X- _ O
instruction -X- _ O
learning -X- _ O
because -X- _ O
“ -X- _ O
learning -X- _ O
to -X- _ O
follow -X- _ O
instructions -X- _ O
” -X- _ O
only -X- _ O
requires -X- _ O
the -X- _ O
correct -X- _ O
mapping -X- _ O
between -X- _ O
the -X- _ O
instructions -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
semantics -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
satisfied -X- _ O
in -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
despite -X- _ O
its -X- _ O
simpleness.163216331634 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
presents -X- _ SUMMARY
a -X- _ SUMMARY
data -X- _ SUMMARY
augmentation -X- _ SUMMARY
method -X- _ SUMMARY
called -X- _ SUMMARY
Counterfactual -X- _ SUMMARY
data -X- _ SUMMARY
Augmentation -X- _ SUMMARY
method -X- _ SUMMARY
via -X- _ SUMMARY
Perspective -X- _ SUMMARY
Transition -X- _ SUMMARY
( -X- _ SUMMARY
CAPT -X- _ SUMMARY
) -X- _ SUMMARY
to -X- _ SUMMARY
automatically -X- _ SUMMARY
augment -X- _ SUMMARY
high -X- _ SUMMARY
- -X- _ SUMMARY
quality -X- _ SUMMARY
responses -X- _ SUMMARY
with -X- _ SUMMARY
different -X- _ SUMMARY
semantics -X- _ SUMMARY
for -X- _ SUMMARY
open -X- _ SUMMARY
- -X- _ SUMMARY
domain -X- _ SUMMARY
dialogue -X- _ SUMMARY
systems -X- _ SUMMARY
. -X- _ SUMMARY
CAPT -X- _ SUMMARY
uses -X- _ SUMMARY
counterfactual -X- _ SUMMARY
inference -X- _ SUMMARY
to -X- _ SUMMARY
generate -X- _ SUMMARY
semantically -X- _ SUMMARY
different -X- _ SUMMARY
responses -X- _ SUMMARY
by -X- _ SUMMARY
replacing -X- _ SUMMARY
the -X- _ SUMMARY
observed -X- _ SUMMARY
reply -X- _ SUMMARY
perspective -X- _ SUMMARY
with -X- _ SUMMARY
valid -X- _ SUMMARY
alternatives -X- _ SUMMARY
, -X- _ SUMMARY
while -X- _ SUMMARY
keeping -X- _ SUMMARY
the -X- _ SUMMARY
current -X- _ SUMMARY
environment -X- _ SUMMARY
unchanged -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
build -X- _ SUMMARY
a -X- _ SUMMARY
shift -X- _ SUMMARY
graph -X- _ SUMMARY
based -X- _ SUMMARY
on -X- _ SUMMARY
observed -X- _ SUMMARY
dialogues -X- _ SUMMARY
to -X- _ SUMMARY
predict -X- _ SUMMARY
valid -X- _ SUMMARY
substituted -X- _ SUMMARY
reply -X- _ SUMMARY
perspectives -X- _ SUMMARY
. -X- _ SUMMARY
Experimental -X- _ SUMMARY
results -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
CAPT -X- _ SUMMARY
outperforms -X- _ SUMMARY
baseline -X- _ SUMMARY
methods -X- _ SUMMARY
on -X- _ SUMMARY
multiple -X- _ SUMMARY
downstream -X- _ SUMMARY
tasks -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
is -X- _ SUMMARY
evaluated -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
Chinese -X- _ SUMMARY
Weibo -X- _ SUMMARY
corpus -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
provides -X- _ SUMMARY
detailed -X- _ SUMMARY
descriptions -X- _ SUMMARY
of -X- _ SUMMARY
the -X- _ SUMMARY
data -X- _ SUMMARY
, -X- _ SUMMARY
implementation -X- _ SUMMARY
details -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
. -X- _ SUMMARY
2022.emnlp-main.106.txt -X- _ O
Jiao -X- _ O
Ou -X- _ O
, -X- _ O
Jinchao -X- _ O
Zhang -X- _ O
, -X- _ O
Yang -X- _ O
Feng -X- _ O
, -X- _ O
Jie -X- _ O
ZhouKey -X- _ O
Laboratory -X- _ O
of -X- _ O
Intelligent -X- _ O
Information -X- _ O
Processing -X- _ O
, -X- _ O
Institute -X- _ O
of -X- _ O
Computing -X- _ O
Technology -X- _ O
, -X- _ O
Chinese -X- _ O
Academy -X- _ O
of -X- _ O
Sciences -X- _ O
( -X- _ O
ICT -X- _ O
/ -X- _ O
CAS -X- _ O
) -X- _ O
University -X- _ O
of -X- _ O
Chinese -X- _ O
Academy -X- _ O
of -X- _ O
SciencesPattern -X- _ O
Recognition -X- _ O
Center -X- _ O
, -X- _ O
WeChat -X- _ O
AI -X- _ O
, -X- _ O
Tencent -X- _ O
Inc -X- _ O
, -X- _ O
China -X- _ O
{ -X- _ O
oujiao17b -X- _ O
, -X- _ O
fengyang -X- _ O
} -X- _ O
@ -X- _ O
ict.ac.cn -X- _ O
, -X- _ O
{ -X- _ O
dayerzhang -X- _ O
, -X- _ O
withtomzhou -X- _ O
} -X- _ O
@ -X- _ O
tencent.com -X- _ O
Abstract -X- _ O
The -X- _ O
construction -X- _ O
of -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
dialogue -X- _ O
systems -X- _ O
requires -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
dialogue -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
dialogue -X- _ O
data -X- _ O
admits -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
responses -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
, -X- _ O
especially -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
collecting -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
such -X- _ O
a -X- _ O
dataset -X- _ O
in -X- _ O
most -X- _ O
scenarios -X- _ O
is -X- _ O
labor -X- _ O
- -X- _ O
intensive -X- _ O
and -X- _ O
timeconsuming -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
to -X- _ O
automatically -X- _ O
augment -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
by -X- _ O
counterfactual -X- _ O
inference -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
observed -X- _ O
dialogue -X- _ O
, -X- _ O
our -X- _ O
counterfactual -X- _ O
generation -X- _ O
model -X- _ O
first -X- _ O
infers -X- _ O
semantically -X- _ O
different -X- _ O
responses -X- _ O
by -X- _ O
replacing -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
with -X- _ O
substituted -X- _ O
ones -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
our -X- _ O
data -X- _ O
selection -X- _ O
method -X- _ O
filters -X- _ O
out -X- _ O
detrimental -X- _ O
augmented -X- _ O
responses -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
can -X- _ O
augment -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
outperform -X- _ O
competitive -X- _ O
baselines -X- _ O
on -X- _ O
multiple -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Open -X- _ O
- -X- _ O
domain -X- _ O
dialogue -X- _ O
systems -X- _ O
have -X- _ O
attracted -X- _ O
much -X- _ O
attention -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Ni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Fu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
potential -X- _ O
applications -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
training -X- _ O
opendomain -X- _ O
dialogue -X- _ O
systems -X- _ O
requires -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
dialogue -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
dialogue -X- _ O
data -X- _ O
admits -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
responses -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
( -X- _ O
Hou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
can -X- _ O
exist -X- _ O
many -X- _ O
valid -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
response -X- _ O
of -X- _ O
each -X- _ O
semantic -X- _ O
information -X- _ O
can -X- _ O
also -X- _ O
have -X- _ O
abundant -X- _ O
alternative -X- _ O
expressions -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
manually -X- _ O
collecting -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
such -X- _ O
datasets -X- _ O
is -X- _ O
usually -X- _ O
laborintensive -X- _ O
and -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O
A -X- _ O
feasible -X- _ O
solution -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
problem -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
. -X- _ O
Currently -X- _ O
, -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
counterfactual -X- _ O
response -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
semantically -X- _ O
different -X- _ O
response -X- _ O
re -X- _ O
- -X- _ O
inferred -X- _ O
by -X- _ O
changing -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
. -X- _ O
some -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
dialogues -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Niu -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
to -X- _ O
augment -X- _ O
data -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
have -X- _ O
limited -X- _ O
semantic -X- _ O
differences -X- _ O
from -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
restrained -X- _ O
changes -X- _ O
. -X- _ O
These -X- _ O
existing -X- _ O
methods -X- _ O
only -X- _ O
consider -X- _ O
word- -X- _ O
or -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
alternative -X- _ O
expressions -X- _ O
of -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
without -X- _ O
augmenting -X- _ O
more -X- _ O
valid -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
augment -X- _ O
valid -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
. -X- _ O
Imagine -X- _ O
that -X- _ O
when -X- _ O
humans -X- _ O
infer -X- _ O
different -X- _ O
- -X- _ O
semantic -X- _ O
responses -X- _ O
, -X- _ O
they -X- _ O
may -X- _ O
naturally -X- _ O
ask -X- _ O
a -X- _ O
question -X- _ O
: -X- _ O
Given -X- _ O
an -X- _ O
observed -X- _ O
dialogue -X- _ O
, -X- _ O
what -X- _ O
the -X- _ O
response -X- _ O
would -X- _ O
happen -X- _ O
if -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
unchanged -X- _ O
? -X- _ O
Answering -X- _ O
this -X- _ O
question -X- _ O
will -X- _ O
infer -X- _ O
a -X- _ O
different -X- _ O
response -X- _ O
, -X- _ O
given -X- _ O
an -X- _ O
example -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
imagination -X- _ O
of -X- _ O
different -X- _ O
responses -X- _ O
under -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
is -X- _ O
so -X- _ O
- -X- _ O
called -X- _ O
counterfactual -X- _ B-TaskName
inference -X- _ I-TaskName
( -X- _ O
Pearl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
ensures -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
inferred -X- _ O
responses -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Motivated -X- _ O
by -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Counterfactual -X- _ B-MethodName
data -X- _ I-MethodName
Augmentation -X- _ I-MethodName
method -X- _ I-MethodName
via -X- _ I-MethodName
Perspective -X- _ I-MethodName
Transition -X- _ I-MethodName
, -X- _ O
CAPT -X- _ B-MethodName
for -X- _ O
short -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
counterfactual -X- _ O
responses -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
observed -X- _ O
dialogue -X- _ O
. -X- _ O
CAPT -X- _ B-MethodName
interprets -X- _ O
a -X- _ O
counterfactual -X- _ B-TaskName
generation -X- _ I-TaskName
model -X- _ O
as -X- _ O
a -X- _ O
structural -X- _ O
causal -X- _ O
model -X- _ O
( -X- _ O
SCM -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
de-1635scribes -X- _ O
the -X- _ O
generation -X- _ O
process -X- _ O
under -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
. -X- _ O
The -X- _ O
current -X- _ O
environment -X- _ O
is -X- _ O
modeled -X- _ O
by -X- _ O
unobserved -X- _ O
variables -X- _ O
in -X- _ O
the -X- _ O
SCM -X- _ O
that -X- _ O
capture -X- _ O
all -X- _ O
unobserved -X- _ O
but -X- _ O
relevant -X- _ O
factors -X- _ O
that -X- _ O
affect -X- _ O
response -X- _ O
generation -X- _ O
. -X- _ O
Counterfactual -X- _ O
responses -X- _ O
are -X- _ O
then -X- _ O
generated -X- _ O
by -X- _ O
intervening -X- _ O
in -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
in -X- _ O
the -X- _ O
SCM -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
replacing -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
with -X- _ O
valid -X- _ O
alternatives -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
these -X- _ O
unobserved -X- _ O
variables -X- _ O
unchanged -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
an -X- _ O
alternative -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
construct -X- _ O
a -X- _ O
shift -X- _ O
graph -X- _ O
based -X- _ O
on -X- _ O
all -X- _ O
observed -X- _ O
dialogues -X- _ O
, -X- _ O
which -X- _ O
explicitly -X- _ O
represents -X- _ O
the -X- _ O
shift -X- _ O
associations -X- _ O
between -X- _ O
both -X- _ O
focuses -X- _ O
of -X- _ O
attention -X- _ O
on -X- _ O
dialogue -X- _ O
histories -X- _ O
and -X- _ O
their -X- _ O
corresponding -X- _ O
responses -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
randomly -X- _ O
choose -X- _ O
a -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
and -X- _ O
regard -X- _ O
its -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
neighbors -X- _ O
in -X- _ O
the -X- _ O
shift -X- _ O
graph -X- _ O
as -X- _ O
candidates -X- _ O
. -X- _ O
A -X- _ O
valid -X- _ O
alternative -X- _ O
can -X- _ O
be -X- _ O
predicted -X- _ O
from -X- _ O
these -X- _ O
candidates -X- _ O
. -X- _ O
After -X- _ O
achieving -X- _ O
all -X- _ O
counterfactual -X- _ O
augmented -X- _ O
responses -X- _ O
, -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
are -X- _ O
further -X- _ O
filtered -X- _ O
using -X- _ O
a -X- _ O
data -X- _ O
selection -X- _ O
module -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
merge -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
with -X- _ O
this -X- _ O
augmented -X- _ O
data -X- _ O
as -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Experiment -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
can -X- _ O
augment -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
augmented -X- _ O
data -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
improvement -X- _ O
of -X- _ O
both -X- _ O
retrieval -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
Our -X- _ O
contributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
counterfactual -X- _ B-MethodName
data -X- _ I-MethodName
augmentation -X- _ I-MethodName
method -X- _ I-MethodName
via -X- _ I-MethodName
perspective -X- _ I-MethodName
transition -X- _ I-MethodName
to -X- _ O
augment -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
study -X- _ O
to -X- _ O
augment -X- _ O
more -X- _ O
valid -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
in -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
dialogues -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Automatic -X- _ O
and -X- _ O
manual -X- _ O
evaluation -X- _ O
show -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
generates -X- _ O
semantically -X- _ O
different -X- _ O
responses -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Extensive -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
providing -X- _ O
more -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
performance -X- _ O
. -X- _ O
2 -X- _ O
Background -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
task -X- _ O
definitions -X- _ O
and -X- _ O
review -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
the -X- _ O
structural -X- _ O
causal -X- _ O
model -X- _ O
. -X- _ O
Please -X- _ O
see -X- _ O
task -X- _ O
definitions -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
2.1 -X- _ O
Structural -X- _ O
Causal -X- _ O
Model -X- _ O
Definition -X- _ O
. -X- _ O
A -X- _ O
structural -X- _ O
causal -X- _ O
model -X- _ O
( -X- _ O
SCM -X- _ O
) -X- _ O
consists -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
observed -X- _ O
variables -X- _ O
V= -X- _ O
{ -X- _ O
V -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
V -X- _ O
} -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
independent -X- _ O
unobserved -X- _ O
random -X- _ O
variables -X- _ O
U= -X- _ O
{ -X- _ O
U -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
U -X- _ O
} -X- _ O
withdistribution -X- _ O
P -X- _ O
( -X- _ O
U -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
connected -X- _ O
by -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
functions -X- _ O
F= -X- _ O
{ -X- _ O
f -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
f -X- _ O
} -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
∀i -X- _ O
, -X- _ O
V -X- _ O
is -X- _ O
caused -X- _ O
by -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
parent -X- _ O
variables -X- _ O
PAandU -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
V -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
PA -X- _ O
, -X- _ O
U -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
PA⊆V\Vin -X- _ O
the -X- _ O
causal -X- _ O
DAG -X- _ O
( -X- _ O
Buesing -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
counterfactual -X- _ O
generation -X- _ O
model -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
cast -X- _ O
as -X- _ O
an -X- _ O
SCM -X- _ O
with -X- _ O
three -X- _ O
observed -X- _ O
variables -X- _ O
, -X- _ O
including -X- _ O
dialogue -X- _ O
history -X- _ O
X -X- _ O
, -X- _ O
reply -X- _ O
perspective -X- _ O
Zandresponse -X- _ O
Y. -X- _ O
The -X- _ O
counterfactual -X- _ O
generation -X- _ O
SCM -X- _ O
turns -X- _ O
the -X- _ O
conditional -X- _ O
distribution -X- _ O
P -X- _ O
( -X- _ O
Y|X -X- _ O
, -X- _ O
Z -X- _ O
) -X- _ O
into -X- _ O
a -X- _ O
deterministic -X- _ O
function -X- _ O
Y= -X- _ O
f -X- _ O
( -X- _ O
X -X- _ O
, -X- _ O
Z -X- _ O
, -X- _ O
U -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
Ucaptures -X- _ O
all -X- _ O
unobserved -X- _ O
but -X- _ O
influential -X- _ O
factors -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
speaking -X- _ O
style -X- _ O
. -X- _ O
The -X- _ O
function -X- _ O
fis -X- _ O
defined -X- _ O
by -X- _ O
the -X- _ O
learned -X- _ O
counterfactual -X- _ O
generation -X- _ O
model -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
SCM -X- _ O
can -X- _ O
infer -X- _ O
counterfactual -X- _ O
responses -X- _ O
given -X- _ O
the -X- _ O
known -X- _ O
function -X- _ O
fand -X- _ O
the -X- _ O
posterior -X- _ O
of -X- _ O
the -X- _ O
unobserved -X- _ O
variable -X- _ O
P -X- _ O
( -X- _ O
U|X -X- _ O
= -X- _ O
x -X- _ O
, -X- _ O
Z -X- _ O
= -X- _ O
z -X- _ O
, -X- _ O
Y -X- _ O
= -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
Intervention -X- _ O
. -X- _ O
Before -X- _ O
observing -X- _ O
what -X- _ O
the -X- _ O
observed -X- _ O
variable -X- _ O
Vwould -X- _ O
happen -X- _ O
, -X- _ O
an -X- _ O
intervention -X- _ O
would -X- _ O
be -X- _ O
given -X- _ O
on -X- _ O
a -X- _ O
parent -X- _ O
variable -X- _ O
V -X- _ O
, -X- _ O
V∈PA -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
intervention -X- _ O
in -X- _ O
the -X- _ O
SCM -X- _ O
is -X- _ O
an -X- _ O
action -X- _ O
by -X- _ O
changing -X- _ O
the -X- _ O
observed -X- _ O
value -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
counterfactual -X- _ B-TaskName
generation -X- _ I-TaskName
SCM -X- _ O
, -X- _ O
the -X- _ O
intervention -X- _ O
is -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
observed -X- _ O
value -X- _ O
zof -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
Zwith -X- _ O
a -X- _ O
different -X- _ O
value -X- _ O
˜z -X- _ O
. -X- _ O
Counterfactual -X- _ B-TaskName
Inference -X- _ I-TaskName
. -X- _ O
Given -X- _ O
an -X- _ O
SCM -X- _ O
and -X- _ O
observed -X- _ O
a -X- _ O
variable -X- _ O
V -X- _ O
= -X- _ O
v -X- _ O
, -X- _ O
counterfactual -X- _ B-TaskName
inference -X- _ I-TaskName
answers -X- _ O
the -X- _ O
question -X- _ O
that -X- _ O
what -X- _ O
the -X- _ O
observed -X- _ O
variable -X- _ O
Vwould -X- _ O
have -X- _ O
changed -X- _ O
if -X- _ O
a -X- _ O
parent -X- _ O
variableVhas -X- _ O
been -X- _ O
intervened -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
unchanged -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
generating -X- _ O
a -X- _ O
counterfactual -X- _ O
response -X- _ O
involves -X- _ O
a -X- _ O
query -X- _ O
about -X- _ O
what -X- _ O
the -X- _ O
response -X- _ O
Ywould -X- _ O
have -X- _ O
happened -X- _ O
if -X- _ O
an -X- _ O
intervention -X- _ O
is -X- _ O
taken -X- _ O
by -X- _ O
setting -X- _ O
Zas -X- _ O
a -X- _ O
different -X- _ O
value˜z -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
observed -X- _ O
value -X- _ O
z. -X- _ O
Overall -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
counterfactual -X- _ O
responses -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
follow -X- _ O
a -X- _ O
three -X- _ O
- -X- _ O
step -X- _ O
procedure -X- _ O
( -X- _ O
Pearl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Abduction -X- _ O
: -X- _ O
Predict -X- _ O
the -X- _ O
“ -X- _ O
current -X- _ O
environment -X- _ O
of -X- _ O
the -X- _ O
SCM -X- _ O
” -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
compute -X- _ O
the -X- _ O
posterior -X- _ O
P -X- _ O
( -X- _ O
U|X -X- _ O
= -X- _ O
x -X- _ O
, -X- _ O
Z -X- _ O
= -X- _ O
z -X- _ O
, -X- _ O
Y -X- _ O
= -X- _ O
y -X- _ O
) -X- _ O
and -X- _ O
sample -X- _ O
u -X- _ O
from -X- _ O
it -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Action -X- _ O
: -X- _ O
Perform -X- _ O
an -X- _ O
intervention -X- _ O
by -X- _ O
replacing -X- _ O
the -X- _ O
observed -X- _ O
value -X- _ O
zofZwith -X- _ O
a -X- _ O
different -X- _ O
value -X- _ O
˜z -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Prediction -X- _ O
: -X- _ O
Reason -X- _ O
a -X- _ O
counterfactual -X- _ O
response -X- _ O
˜y -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
posterior -X- _ O
sample -X- _ O
uand -X- _ O
the -X- _ O
known -X- _ O
function -X- _ O
f. -X- _ O
3 -X- _ O
Method -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
take -X- _ O
an -X- _ O
input -X- _ O
dialogue -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
and -X- _ O
augment -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
responses1636 -X- _ O
that -X- _ O
have -X- _ O
different -X- _ O
semantics -X- _ O
from -X- _ O
y. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
technique -X- _ O
called -X- _ O
Counterfactual -X- _ B-MethodName
Generation -X- _ I-MethodName
via -X- _ I-MethodName
Perspective -X- _ I-MethodName
Transition -X- _ I-MethodName
for -X- _ O
intervening -X- _ O
in -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
to -X- _ O
augment -X- _ O
responses -X- _ O
under -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
how -X- _ O
to -X- _ O
train -X- _ O
those -X- _ O
models -X- _ O
involved -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
predictor -X- _ O
and -X- _ O
the -X- _ O
counterfactual -X- _ O
generator -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
3.3 -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
data -X- _ O
selection -X- _ O
method -X- _ O
, -X- _ O
named -X- _ O
Bi -X- _ O
- -X- _ O
directional -X- _ O
Perplexity -X- _ O
Selection -X- _ O
, -X- _ O
to -X- _ O
select -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
augmented -X- _ O
data -X- _ O
. -X- _ O
3.1 -X- _ O
Counterfactual -X- _ B-MethodName
Generation -X- _ I-MethodName
via -X- _ I-MethodName
Perspective -X- _ I-MethodName
Transition -X- _ I-MethodName
This -X- _ O
paper -X- _ O
mainly -X- _ O
focuses -X- _ O
on -X- _ O
single -X- _ O
- -X- _ O
turn -X- _ O
dialogues -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
post -X- _ O
- -X- _ O
response -X- _ O
pair -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
SCM -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
counterfactual -X- _ O
response -X- _ O
˜yfollowing -X- _ O
the -X- _ O
three -X- _ O
- -X- _ O
step -X- _ O
procedure -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
1 -X- _ O
. -X- _ O
Abduction -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
unobserved -X- _ O
variable -X- _ O
given -X- _ O
the -X- _ O
observed -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
z -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
( -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
about -X- _ O
zsee -X- _ O
the -X- _ O
action -X- _ O
step -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
when -X- _ O
generating -X- _ O
the -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
of -X- _ O
y -X- _ O
, -X- _ O
our -X- _ O
counterfactual -X- _ O
generator -X- _ O
outputs -X- _ O
a -X- _ O
categorical -X- _ O
distribution -X- _ O
P -X- _ O
( -X- _ O
Y|X -X- _ O
= -X- _ O
x -X- _ O
, -X- _ O
Z -X- _ O
= -X- _ O
z -X- _ O
, -X- _ O
Y -X- _ O
= -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
yis -X- _ O
the -X- _ O
token -X- _ O
sequence -X- _ O
generated -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
time -X- _ O
step -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
Oberst -X- _ O
and -X- _ O
Sontag -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
unobserved -X- _ O
random -X- _ O
variable -X- _ O
Uis -X- _ O
simulated -X- _ O
by -X- _ O
introducing -X- _ O
Gumbel -X- _ O
random -X- _ O
noises -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
the -X- _ O
Gumbel -X- _ O
- -X- _ O
Max -X- _ O
Trick -X- _ O
( -X- _ O
Luce -X- _ O
, -X- _ O
1959 -X- _ O
) -X- _ O
for -X- _ O
this -X- _ O
categorical -X- _ O
distributionas -X- _ O
follows -X- _ O
, -X- _ O
p -X- _ O
= -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
= -X- _ O
k|X -X- _ O
= -X- _ O
x -X- _ O
, -X- _ O
Z -X- _ O
= -X- _ O
z -X- _ O
, -X- _ O
Y -X- _ O
= -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
= -X- _ O
arg -X- _ O
max -X- _ O
( -X- _ O
logp+u -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
u∼Gumbel -X- _ O
( -X- _ O
0,1 -X- _ O
) -X- _ O
and|V|denotes -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
our -X- _ O
counterfactual -X- _ O
generation -X- _ O
SCM -X- _ O
transforms -X- _ O
into -X- _ O
a -X- _ O
Gumbel -X- _ O
- -X- _ O
Max -X- _ O
SCM -X- _ O
( -X- _ O
Oberst -X- _ O
and -X- _ O
Sontag -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
estimation -X- _ O
of -X- _ O
the -X- _ O
unobserved -X- _ O
variable -X- _ O
is -X- _ O
then -X- _ O
to -X- _ O
sample -X- _ O
from -X- _ O
the -X- _ O
posterior -X- _ O
distribution -X- _ O
over -X- _ O
these -X- _ O
Gumbel -X- _ O
random -X- _ O
variables -X- _ O
. -X- _ O
Fortunately -X- _ O
, -X- _ O
a -X- _ O
straightforward -X- _ O
way -X- _ O
to -X- _ O
infer -X- _ O
posterior -X- _ O
( -X- _ O
Maddison -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
is -X- _ O
utilizing -X- _ O
the -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
shifted -X- _ O
Gumbel -X- _ O
variables -X- _ O
g= -X- _ O
log -X- _ O
p+u -X- _ O
: -X- _ O
in -X- _ O
the -X- _ O
posterior -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
is -X- _ O
independent -X- _ O
with -X- _ O
the -X- _ O
argmax -X- _ O
of -X- _ O
the -X- _ O
shifted -X- _ O
Gumbel -X- _ O
variables -X- _ O
and -X- _ O
is -X- _ O
distributed -X- _ O
as -X- _ O
a -X- _ O
standard -X- _ O
Gumbel -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
let -X- _ O
y -X- _ O
= -X- _ O
k -X- _ O
( -X- _ O
* -X- _ O
denotes -X- _ O
the -X- _ O
observed -X- _ O
token -X- _ O
) -X- _ O
and -X- _ O
sample -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
gfrom -X- _ O
Gumbel -X- _ O
( -X- _ O
0,1 -X- _ O
) -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
the -X- _ O
remaining -X- _ O
values -X- _ O
gfrom -X- _ O
the -X- _ O
shifted -X- _ O
Gumbel -X- _ O
distribution -X- _ O
Gumbel -X- _ O
( -X- _ O
logp,1 -X- _ O
) -X- _ O
truncated -X- _ O
atg -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
index -X- _ O
of -X- _ O
k -X- _ O
, -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
u -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
subtracting -X- _ O
off -X- _ O
the -X- _ O
location -X- _ O
parameterlogpfrom -X- _ O
g. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
resulting -X- _ O
sample -X- _ O
u= -X- _ O
[ -X- _ O
u -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
u -X- _ O
] -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
counterfactual -X- _ O
responses -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
Action -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
zwith -X- _ O
a -X- _ O
substituted -X- _ O
reply -X- _ O
per-1637spective -X- _ O
˜z -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
two -X- _ O
sub -X- _ O
- -X- _ O
problems -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
addressed -X- _ O
: -X- _ O
representing -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
andpredicting -X- _ O
a -X- _ O
substituted -X- _ O
valid -X- _ O
reply -X- _ O
perspective -X- _ O
. -X- _ O
By -X- _ O
observing -X- _ O
human -X- _ O
dialogues -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
a -X- _ O
reply -X- _ O
perspective -X- _ O
can -X- _ O
be -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
keyword -X- _ O
, -X- _ O
like -X- _ O
“ -X- _ O
stop -X- _ O
smoking -X- _ O
” -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
process -X- _ O
that -X- _ O
humans -X- _ O
first -X- _ O
naturally -X- _ O
focus -X- _ O
on -X- _ O
a -X- _ O
certain -X- _ O
point -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
post -X- _ O
like -X- _ O
“ -X- _ O
smoking -X- _ O
” -X- _ O
and -X- _ O
then -X- _ O
would -X- _ O
unconsciously -X- _ O
shifting -X- _ O
this -X- _ O
focus -X- _ O
point -X- _ O
to -X- _ O
another -X- _ O
one -X- _ O
. -X- _ O
The -X- _ O
focus -X- _ O
point -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
can -X- _ O
be -X- _ O
similarly -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
keyword -X- _ O
. -X- _ O
We -X- _ O
name -X- _ O
the -X- _ O
focus -X- _ O
point -X- _ O
on -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
the -X- _ O
shifted -X- _ O
one -X- _ O
as -X- _ O
the -X- _ O
focus -X- _ O
andreply -X- _ O
perspective -X- _ O
respectively -X- _ O
. -X- _ O
When -X- _ O
humans -X- _ O
have -X- _ O
different -X- _ O
focuses -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
“ -X- _ O
health -X- _ O
” -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
or -X- _ O
different -X- _ O
shifts -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
focus -X- _ O
, -X- _ O
they -X- _ O
will -X- _ O
obtain -X- _ O
substituted -X- _ O
reply -X- _ O
perspectives -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
valid -X- _ O
alternatives -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
make -X- _ O
valid -X- _ O
shifts -X- _ O
from -X- _ O
a -X- _ O
focus -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
a -X- _ O
shift -X- _ O
graph -X- _ O
based -X- _ O
on -X- _ O
all -X- _ O
observed -X- _ O
samples -X- _ O
, -X- _ O
where -X- _ O
head -X- _ O
and -X- _ O
tail -X- _ O
vertices -X- _ O
are -X- _ O
focuses -X- _ O
and -X- _ O
reply -X- _ O
perspectives -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
edges -X- _ O
represent -X- _ O
observed -X- _ O
shifts -X- _ O
between -X- _ O
focuses -X- _ O
and -X- _ O
reply -X- _ O
perspectives -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
regard -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
neighbors -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
focus -X- _ O
as -X- _ O
candidates -X- _ O
and -X- _ O
predict -X- _ O
a -X- _ O
valid -X- _ O
alternative -X- _ O
from -X- _ O
these -X- _ O
candidates -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
corresponding -X- _ O
reply -X- _ O
perspectives -X- _ O
can -X- _ O
be -X- _ O
shared -X- _ O
if -X- _ O
posts -X- _ O
containing -X- _ O
the -X- _ O
same -X- _ O
focus -X- _ O
have -X- _ O
similar -X- _ O
semantics -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
the -X- _ O
shift -X- _ O
graph -X- _ O
Gwith -X- _ O
two -X- _ O
steps -X- _ O
: -X- _ O
vertex -X- _ O
construction -X- _ O
and -X- _ O
edge -X- _ O
construction -X- _ O
. -X- _ O
For -X- _ O
vertex -X- _ O
construction -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
exploit -X- _ O
a -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
keyword -X- _ O
extraction -X- _ O
method -X- _ O
( -X- _ O
Campos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
identify -X- _ O
salient -X- _ O
keywords -X- _ O
from -X- _ O
utterances -X- _ O
in -X- _ O
the -X- _ O
observed -X- _ O
dialogue -X- _ O
dataset -X- _ O
D. -X- _ O
To -X- _ O
further -X- _ O
identify -X- _ O
the -X- _ O
focuscfrom -X- _ O
all -X- _ O
keywords -X- _ O
of -X- _ O
x -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
guidance -X- _ O
from -X- _ O
the -X- _ O
future -X- _ O
information -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
response -X- _ O
) -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
keyword -X- _ O
that -X- _ O
is -X- _ O
semantically -X- _ O
closest -X- _ O
to -X- _ O
y. -X- _ O
To -X- _ O
identify -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
z -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
keyword -X- _ O
with -X- _ O
the -X- _ O
closest -X- _ O
semantics -X- _ O
to -X- _ O
c. -X- _ O
More -X- _ O
concretely -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
their -X- _ O
embedding -X- _ O
via -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
measure -X- _ O
of -X- _ O
semantic -X- _ O
closeness -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
embedding -X- _ O
is -X- _ O
achieved -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
edge -X- _ O
construction -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
an -X- _ O
edge -X- _ O
by -X- _ O
connecting -X- _ O
cwithz -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
characterize -X- _ O
all -X- _ O
shift -X- _ O
associations -X- _ O
in -X- _ O
D. -X- _ O
Once -X- _ O
the -X- _ O
shift -X- _ O
graph -X- _ O
is -X- _ O
built -X- _ O
, -X- _ O
we -X- _ O
predict -X- _ O
˜zas -X- _ O
˜z= -X- _ O
arg -X- _ O
maxP -X- _ O
( -X- _ O
Z|C=˜c -X- _ O
, -X- _ O
X -X- _ O
= -X- _ O
x -X- _ O
, -X- _ O
N -X- _ O
= -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
a -X- _ O
trained -X- _ O
reply -X- _ O
perspective -X- _ O
predictor -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
˜ccan -X- _ O
be -X- _ O
any -X- _ O
keyword -X- _ O
in -X- _ O
the -X- _ O
postxandN -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
) -X- _ O
denotes -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
neighbors -X- _ O
of -X- _ O
˜c -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
Prediction -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
counterfactual -X- _ O
response -X- _ O
given -X- _ O
the -X- _ O
posterior -X- _ O
sample -X- _ O
u= -X- _ O
[ -X- _ O
u -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
u -X- _ O
] -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
when -X- _ O
generating -X- _ O
the -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
of -X- _ O
the -X- _ O
counterfactual -X- _ O
response -X- _ O
, -X- _ O
our -X- _ O
counterfactual -X- _ O
generator -X- _ O
computes -X- _ O
the -X- _ O
categorical -X- _ O
distribution -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O
˜p -X- _ O
= -X- _ O
P -X- _ O
( -X- _ O
Y -X- _ O
= -X- _ O
k|X -X- _ O
= -X- _ O
x -X- _ O
, -X- _ O
Z=˜z -X- _ O
, -X- _ O
Y=˜y -X- _ O
) -X- _ O
, -X- _ O
˜y -X- _ O
= -X- _ O
arg -X- _ O
max -X- _ O
( -X- _ O
log -X- _ O
˜p+u -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
˜zis -X- _ O
the -X- _ O
predicted -X- _ O
reply -X- _ O
perspective -X- _ O
, -X- _ O
˜yis -X- _ O
the -X- _ O
token -X- _ O
sequence -X- _ O
generated -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
step -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
counterfactual -X- _ O
generation -X- _ O
via -X- _ O
perspective -X- _ O
transition -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
effective -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
for -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
dialogues -X- _ O
to -X- _ O
augment -X- _ O
responses -X- _ O
with -X- _ O
wider -X- _ O
semantic -X- _ O
coverage -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
this -X- _ O
method -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
algorithm -X- _ O
takes -X- _ O
an -X- _ O
observed -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
as -X- _ O
an -X- _ O
input -X- _ O
and -X- _ O
loop -X- _ O
through -X- _ O
every -X- _ O
keyword -X- _ O
of -X- _ O
xas -X- _ O
a -X- _ O
different -X- _ O
focus -X- _ O
˜c -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
˜c -X- _ O
, -X- _ O
to -X- _ O
sample -X- _ O
multiple -X- _ O
corresponding -X- _ O
reply -X- _ O
perspectives -X- _ O
, -X- _ O
we -X- _ O
equally -X- _ O
divide -X- _ O
the -X- _ O
candidate -X- _ O
set -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
intoKsub -X- _ O
- -X- _ O
sets -X- _ O
{ -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
} -X- _ O
for -X- _ O
nested -X- _ O
loop -X- _ O
. -X- _ O
At -X- _ O
each -X- _ O
iteration -X- _ O
it -X- _ O
predicts -X- _ O
a -X- _ O
different -X- _ O
˜zfor -X- _ O
perspective -X- _ O
transition -X- _ O
to -X- _ O
output -X- _ O
a -X- _ O
counterfactual -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
˜y -X- _ O
) -X- _ O
. -X- _ O
3.2 -X- _ O
Model -X- _ O
Training -X- _ O
CAPT -X- _ B-MethodName
relies -X- _ O
on -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
predictor -X- _ O
and -X- _ O
the -X- _ O
counterfactual -X- _ O
generator -X- _ O
, -X- _ O
which -X- _ O
greatly -X- _ O
influence -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
augmentation -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
model -X- _ O
BART -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
. -X- _ O
Reply -X- _ O
Perspective -X- _ O
Predictor -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
BART -X- _ O
on -X- _ O
Dto -X- _ O
learn -X- _ O
P -X- _ O
( -X- _ O
Z|C -X- _ O
, -X- _ O
X -X- _ O
, -X- _ O
N -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
a -X- _ O
concatenated -X- _ O
text -X- _ O
sequence -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
X -X- _ O
, -X- _ O
the -X- _ O
focus -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
candidates -X- _ O
N. -X- _ O
The -X- _ O
output -X- _ O
is -X- _ O
the -X- _ O
predicted -X- _ O
reply -X- _ O
perspective -X- _ O
Z. -X- _ O
We -X- _ O
maximize -X- _ O
the -X- _ O
objective -X- _ O
as -X- _ O
follows -X- _ O
, -X- _ O
L=− -X- _ O
/ -X- _ O
summationdisplaylogP -X- _ O
( -X- _ O
Z| -X- _ O
[ -X- _ O
C -X- _ O
, -X- _ O
X -X- _ O
, -X- _ O
N -X- _ O
] -X- _ O
, -X- _ O
Z -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
the -X- _ O
bracket -X- _ O
[ -X- _ O
· -X- _ O
, -X- _ O
· -X- _ O
, -X- _ O
· -X- _ O
] -X- _ O
denotes -X- _ O
concatenation -X- _ O
with -X- _ O
the -X- _ O
token -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
. -X- _ O
The -X- _ O
candidates -X- _ O
Nare -X- _ O
also -X- _ O
concatenated -X- _ O
with -X- _ O
commas -X- _ O
. -X- _ O
Zis -X- _ O
a -X- _ O
prefix -X- _ O
of -X- _ O
the -X- _ O
reply -X- _ O
perspectives -X- _ O
. -X- _ O
|Z|denotes -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
Z. -X- _ O
Counterfactual -X- _ O
Generator -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
BART -X- _ O
onDto -X- _ O
learn -X- _ O
P -X- _ O
( -X- _ O
Y|X -X- _ O
, -X- _ O
Z -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
generator -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
response -X- _ O
Ywith1638Algorithm -X- _ O
1 -X- _ O
: -X- _ O
Data -X- _ O
Augmentation -X- _ O
Input -X- _ O
: -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
: -X- _ O
An -X- _ O
observed -X- _ O
sample -X- _ O
C -X- _ O
: -X- _ O
All -X- _ O
keywords -X- _ O
{ -X- _ O
˜c -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
˜c -X- _ O
} -X- _ O
ofx -X- _ O
G -X- _ O
: -X- _ O
The -X- _ O
shift -X- _ O
graph -X- _ O
Output -X- _ O
: -X- _ O
A -X- _ O
counterfactual -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
˜y -X- _ O
) -X- _ O
Get -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
z -X- _ O
; -X- _ O
fori←1to|C|do -X- _ O
Get -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
neighbors -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
fromG -X- _ O
Remove -X- _ O
zfromN -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
Equally -X- _ O
divide -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
into -X- _ O
{ -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
} -X- _ O
forj←1toKdo -X- _ O
˜y←Trans -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
z -X- _ O
, -X- _ O
˜c -X- _ O
, -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
) -X- _ O
Function -X- _ O
Trans -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
z -X- _ O
, -X- _ O
˜c -X- _ O
, -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
) -X- _ O
: -X- _ O
InferufromP -X- _ O
( -X- _ O
U|x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
Predict -X- _ O
˜zfromP -X- _ O
( -X- _ O
Z|x -X- _ O
, -X- _ O
˜c -X- _ O
, -X- _ O
N -X- _ O
( -X- _ O
˜c -X- _ O
) -X- _ O
) -X- _ O
Reason -X- _ O
˜yfromP -X- _ O
( -X- _ O
Y|x -X- _ O
, -X- _ O
˜z -X- _ O
) -X- _ O
under -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
u -X- _ O
return -X- _ O
˜y -X- _ O
the -X- _ O
input -X- _ O
prompt -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
Xand -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
Z. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
maximize -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
: -X- _ O
L=− -X- _ O
/ -X- _ O
summationdisplaylogP -X- _ O
( -X- _ O
Y| -X- _ O
[ -X- _ O
X -X- _ O
, -X- _ O
Z -X- _ O
] -X- _ O
, -X- _ O
Y -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
3.3 -X- _ O
Bi -X- _ O
- -X- _ O
directional -X- _ O
Perplexity -X- _ O
Selection -X- _ O
Filtering -X- _ O
out -X- _ O
detrimental -X- _ O
augmented -X- _ O
samples -X- _ O
can -X- _ O
improve -X- _ O
downstream -X- _ O
performance -X- _ O
( -X- _ O
Bras -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Existing -X- _ O
methods -X- _ O
( -X- _ O
Axelrod -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
pick -X- _ O
out -X- _ O
samples -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
only -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
is -X- _ O
most -X- _ O
confident -X- _ O
about -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
have -X- _ O
only -X- _ O
seen -X- _ O
limited -X- _ O
samples -X- _ O
so -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
identify -X- _ O
valid -X- _ O
but -X- _ O
unseen -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
counterfactual -X- _ O
- -X- _ O
generated -X- _ O
data -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dialogue -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
DialoFlow -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
utilizing -X- _ O
its -X- _ O
powerful -X- _ O
ability -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
. -X- _ O
Since -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dialogues -X- _ O
have -X- _ O
been -X- _ O
seen -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
identify -X- _ O
valid -X- _ O
but -X- _ O
unseen -X- _ O
samples -X- _ O
like -X- _ O
“ -X- _ O
an -X- _ O
expert -X- _ O
” -X- _ O
via -X- _ O
perplexity -X- _ O
( -X- _ O
PPL -X- _ O
) -X- _ O
scores -X- _ O
. -X- _ O
Nonetheless -X- _ O
, -X- _ O
the -X- _ O
resulting -X- _ O
samples -X- _ O
might -X- _ O
contain -X- _ O
samples -X- _ O
with -X- _ O
generic -X- _ O
responses -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
introduce -X- _ O
backward -X- _ O
PPL -X- _ O
to -X- _ O
rerank -X- _ O
responses -X- _ O
for -X- _ O
prioritizing -X- _ O
those -X- _ O
valid -X- _ O
and -X- _ O
interesting -X- _ O
samples -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
independently -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
DialoFlow -X- _ O
to -X- _ O
learn -X- _ O
P -X- _ O
( -X- _ O
Y|X -X- _ O
) -X- _ O
andP -X- _ O
( -X- _ O
X|Y -X- _ O
) -X- _ O
onD -X- _ O
for -X- _ O
calculating -X- _ O
forward -X- _ O
andbackward -X- _ O
PPL -X- _ O
scores -X- _ O
. -X- _ O
Once -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
forward -X- _ O
PPL -X- _ O
scores -X- _ O
for -X- _ O
all -X- _ O
samples -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
threshold -X- _ O
ηthat -X- _ O
separates -X- _ O
valid -X- _ O
samples -X- _ O
from -X- _ O
invalid -X- _ O
samples -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
optimal -X- _ O
single -X- _ O
threshold -X- _ O
parameter -X- _ O
η -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
regard -X- _ O
observed -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
as -X- _ O
valid -X- _ O
samples -X- _ O
, -X- _ O
and -X- _ O
invalid -X- _ O
samples -X- _ O
are -X- _ O
constructed -X- _ O
by -X- _ O
replacing -X- _ O
the -X- _ O
responses -X- _ O
of -X- _ O
valid -X- _ O
samples -X- _ O
with -X- _ O
randomly -X- _ O
- -X- _ O
sampled -X- _ O
responses -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
rerank -X- _ O
the -X- _ O
responses -X- _ O
of -X- _ O
each -X- _ O
post -X- _ O
in -X- _ O
the -X- _ O
valid -X- _ O
samples -X- _ O
via -X- _ O
backward -X- _ O
PPL -X- _ O
scores -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
higher -X- _ O
the -X- _ O
backward -X- _ O
PPL -X- _ O
score -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
likely -X- _ O
the -X- _ O
response -X- _ O
is -X- _ O
dull -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
samples -X- _ O
in -X- _ O
order -X- _ O
from -X- _ O
low -X- _ O
to -X- _ O
high -X- _ O
until -X- _ O
the -X- _ O
desired -X- _ O
number -X- _ O
of -X- _ O
augmented -X- _ O
samples -X- _ O
are -X- _ O
obtained -X- _ O
. -X- _ O
4 -X- _ O
Experimental -X- _ O
Setup -X- _ O
4.1 -X- _ O
Settings -X- _ O
The -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
Chinese -X- _ B-DatasetName
Weibo -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
dataset -X- _ O
Dcontains -X- _ O
training -X- _ B-HyperparameterName
, -X- _ O
validation -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
test -X- _ B-HyperparameterName
sets -X- _ O
with -X- _ O
300K,5 -X- _ B-HyperparameterValue
K -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
post -X- _ O
- -X- _ O
response -X- _ O
samples -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Please -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
on -X- _ O
data -X- _ O
and -X- _ O
method -X- _ O
implementations -X- _ O
. -X- _ O
4.2 -X- _ O
Baselines -X- _ O
We -X- _ O
compare -X- _ O
CAPT -X- _ B-MethodName
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
baselines -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Observed -X- _ B-MethodName
, -X- _ O
which -X- _ O
only -X- _ O
uses -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Augmented -X- _ B-MethodName
, -X- _ O
which -X- _ O
only -X- _ O
uses -X- _ O
our -X- _ O
augmented -X- _ O
data -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Back -X- _ B-MethodName
- -X- _ I-MethodName
Trans -X- _ I-MethodName
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
back -X- _ O
- -X- _ O
translates -X- _ O
responses -X- _ O
via -X- _ O
Google -X- _ O
Translate -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
MLM -X- _ B-MethodName
( -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
the -X- _ O
BERT -X- _ O
- -X- _ O
large -X- _ O
model -X- _ O
on -X- _ O
Dto -X- _ O
substitute -X- _ O
some -X- _ O
words -X- _ O
of -X- _ O
responses -X- _ O
. -X- _ O
The -X- _ O
substituting -X- _ O
probability -X- _ O
is -X- _ O
0.15 -X- _ O
. -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
DL -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
constructs -X- _ O
post -X- _ O
- -X- _ O
response -X- _ O
pairs -X- _ O
where -X- _ O
both -X- _ O
post -X- _ O
and -X- _ O
response -X- _ O
are -X- _ O
retrieved -X- _ O
from -X- _ O
the -X- _ O
unpaired -X- _ O
data -X- _ O
. -X- _ O
Augmented -X- _ O
dialogues -X- _ O
are -X- _ O
further -X- _ O
filtered -X- _ O
by -X- _ O
their -X- _ O
ranking -X- _ O
module -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
BM25 -X- _ B-MethodName
( -X- _ O
Gangal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
the -X- _ O
BM25 -X- _ O
algorithm -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
similar -X- _ O
post -X- _ O
to -X- _ O
the -X- _ O
observed -X- _ O
post -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
response -X- _ O
of -X- _ O
the -X- _ O
retrieved -X- _ O
post -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
augmented -X- _ O
response -X- _ O
. -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
fine -X- _ O
- -X- _ O
tunes -X- _ O
the -X- _ O
BART -X- _ O
- -X- _ O
large -X- _ O
model -X- _ O
that -X- _ O
takes -X- _ O
the -X- _ O
post -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
generate -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
decode -X- _ O
strategies -X- _ O
, -X- _ O
including -X- _ O
greedy -X- _ O
search -X- _ O
, -X- _ O
sampling -X- _ O
with -X- _ O
temperature -X- _ O
0.5 -X- _ O
, -X- _ O
and -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
sampling -X- _ O
( -X- _ O
k=10,25 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
denoted -X- _ O
as -X- _ O
BART -X- _ O
- -X- _ O
greedy -X- _ O
, -X- _ O
BART -X- _ O
- -X- _ O
samp -X- _ O
, -X- _ O
BART -X- _ O
- -X- _ O
k10 -X- _ O
, -X- _ O
and -X- _ O
BART -X- _ O
- -X- _ O
k25 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Augmented -X- _ O
pairs -X- _ O
generated -X- _ O
by -X- _ O
BM25 -X- _ O
and1639 -X- _ O
BART -X- _ O
are -X- _ O
filtered -X- _ O
by -X- _ O
our -X- _ O
data -X- _ O
selection -X- _ O
method -X- _ O
. -X- _ O
4.3 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
Automatic -X- _ O
Evaluation -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
metrics -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
automatically -X- _ O
evaluate -X- _ O
retrieval -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Mean -X- _ B-MetricName
Average -X- _ I-MetricName
Precision -X- _ I-MetricName
( -X- _ O
MAP -X- _ B-MetricName
) -X- _ O
: -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
Average -X- _ O
Precision -X- _ O
( -X- _ O
AP -X- _ O
) -X- _ O
over -X- _ O
test -X- _ O
samples -X- _ O
. -X- _ O
AP -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
precision -X- _ O
scores -X- _ O
at -X- _ O
the -X- _ O
ranks -X- _ O
where -X- _ O
references -X- _ O
are -X- _ O
found -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
R -X- _ B-MetricName
@ -X- _ I-MetricName
k -X- _ I-MetricName
: -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
references -X- _ O
among -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
selected -X- _ O
responses -X- _ O
( -X- _ O
k=1,2,5 -X- _ O
) -X- _ O
when -X- _ O
given -X- _ O
10 -X- _ O
candidates -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
metrics -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BLEU -X- _ B-MetricName
: -X- _ O
the -X- _ O
overlap -X- _ O
of -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
( -X- _ O
n -X- _ O
< -X- _ O
4 -X- _ O
) -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
response -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Dist -X- _ B-MetricName
- -X- _ I-MetricName
n -X- _ I-MetricName
: -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
unique -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
( -X- _ O
n=1,2 -X- _ O
) -X- _ O
over -X- _ O
all -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
in -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
diversity -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
sample -X- _ O
3 -X- _ O
responses -X- _ O
for -X- _ O
each -X- _ O
test -X- _ O
post -X- _ O
, -X- _ O
evaluation -X- _ O
is -X- _ O
performed -X- _ O
both -X- _ O
within -X- _ O
and -X- _ O
among -X- _ O
the -X- _ O
sampled -X- _ O
responses -X- _ O
. -X- _ O
Intra -X- _ B-MetricName
- -X- _ I-MetricName
Dist -X- _ I-MetricName
calculates -X- _ O
that -X- _ O
ratio -X- _ O
within -X- _ O
each -X- _ O
sampled -X- _ O
response -X- _ O
, -X- _ O
and -X- _ O
Inter -X- _ B-MetricName
- -X- _ I-MetricName
Dist -X- _ I-MetricName
calculates -X- _ O
that -X- _ O
ratio -X- _ O
among -X- _ O
all -X- _ O
three -X- _ O
responses -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
BS -X- _ B-MetricName
: -X- _ O
the -X- _ O
F1 -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
BERTScore -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
the -X- _ O
semantic -X- _ O
similarity -X- _ O
between -X- _ O
each -X- _ O
2 -X- _ O
responses -X- _ O
in -X- _ O
3 -X- _ O
sampled -X- _ O
responses -X- _ O
. -X- _ O
Lower -X- _ O
scores -X- _ O
imply -X- _ O
greater -X- _ O
semantic -X- _ O
diversity -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
use -X- _ O
Dist -X- _ B-MetricName
- -X- _ I-MetricName
n -X- _ I-MetricName
andBSto -X- _ O
automatically -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
evaluates -X- _ O
the -X- _ O
diversity -X- _ O
among -X- _ O
the -X- _ O
generated -X- _ O
responses -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
following -X- _ O
metrics -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
diversity -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
response -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Novelty -X- _ B-MetricName
- -X- _ I-MetricName
n -X- _ I-MetricName
: -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
new -X- _ O
ngrams -X- _ O
( -X- _ O
n=1,2 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
augmented -X- _ O
responses -X- _ O
. -X- _ O
IntraNovelty -X- _ B-MetricName
similarly -X- _ O
calculates -X- _ O
the -X- _ O
ratio -X- _ O
within -X- _ O
each -X- _ O
augmented -X- _ O
response -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
n -X- _ O
- -X- _ O
grams -X- _ O
that -X- _ O
are -X- _ O
covered -X- _ O
by -X- _ O
the -X- _ O
augmented -X- _ O
response -X- _ O
but -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
response -X- _ O
. -X- _ O
Inter -X- _ B-MetricName
- -X- _ I-MetricName
Novelty -X- _ I-MetricName
calculates -X- _ O
the -X- _ O
ratio -X- _ O
within -X- _ O
the -X- _ O
three -X- _ O
augmented -X- _ O
responses -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BS -X- _ B-MetricName
: -X- _ O
the -X- _ O
F1 -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
BERTScore -X- _ O
, -X- _ O
which -X- _ O
measures -X- _ O
the -X- _ O
semantic -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
augmented -X- _ O
response -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
original -X- _ O
response -X- _ O
. -X- _ O
Manual -X- _ O
Evaluation -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
metrics -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
manually -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
and -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
Three -X- _ O
annotators -X- _ O
are -X- _ O
employed -X- _ O
to -X- _ O
rate -X- _ O
the -X- _ O
samples -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Fluency -X- _ B-MetricName
( -X- _ O
Flu -X- _ B-MetricName
. -X- _ O
) -X- _ O
: -X- _ O
is -X- _ O
the -X- _ O
response -X- _ O
fluent -X- _ O
? -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Coherence -X- _ B-MetricName
( -X- _ O
Coh -X- _ B-MetricName
. -X- _ O
) -X- _ O
: -X- _ O
is -X- _ O
the -X- _ O
response -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
valid -X- _ O
continuation -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
post -X- _ O
? -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Interesting -X- _ B-MetricName
( -X- _ O
Int -X- _ B-MetricName
. -X- _ O
) -X- _ O
: -X- _ O
is -X- _ O
the -X- _ O
response -X- _ O
generic -X- _ O
? -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Richness -X- _ B-MetricName
( -X- _ O
Rich -X- _ B-MetricName
. -X- _ O
) -X- _ O
: -X- _ O
do -X- _ O
the -X- _ O
three -X- _ O
sampled -X- _ O
responses -X- _ O
express -X- _ O
different -X- _ O
semantics -X- _ O
? -X- _ O
The -X- _ O
rating -X- _ O
scale -X- _ O
is -X- _ O
of -X- _ O
0 -X- _ O
to -X- _ O
2 -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
0 -X- _ O
means -X- _ O
worst -X- _ O
and -X- _ O
2 -X- _ O
best -X- _ O
. -X- _ O
5 -X- _ O
Results -X- _ O
and -X- _ O
Discussion -X- _ O
5.1 -X- _ O
Evaluating -X- _ O
Augmented -X- _ O
Data -X- _ O
We -X- _ O
first -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
respectively -X- _ O
select -X- _ O
900 -X- _ O
K -X- _ O
augmented -X- _ O
post -X- _ O
- -X- _ O
response -X- _ O
pairs -X- _ O
generated -X- _ O
by -X- _ O
these -X- _ O
methods -X- _ O
, -X- _ O
on -X- _ O
which -X- _ O
automatic -X- _ O
evaluation -X- _ O
is -X- _ O
performed -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
conduct -X- _ O
manual -X- _ O
evaluation -X- _ O
on -X- _ O
600 -X- _ O
samples -X- _ O
, -X- _ O
which -X- _ O
contain -X- _ O
200 -X- _ O
randomly -X- _ O
- -X- _ O
sampled -X- _ O
posts -X- _ O
and -X- _ O
each -X- _ O
post -X- _ O
has -X- _ O
3 -X- _ O
corresponding -X- _ O
responses -X- _ O
. -X- _ O
The -X- _ O
inter -X- _ O
- -X- _ O
annotator -X- _ O
agreement -X- _ O
is -X- _ O
measured -X- _ O
via -X- _ O
the -X- _ O
Fleiss -X- _ B-MetricName
’s -X- _ I-MetricName
kappa -X- _ I-MetricName
κ -X- _ B-MetricName
( -X- _ O
Randolph -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
κvalues -X- _ B-MetricName
forFluency -X- _ B-MetricName
, -X- _ O
Coherence -X- _ B-MetricName
, -X- _ O
Interesting -X- _ B-MetricName
andRichness -X- _ B-MetricName
are -X- _ O
0.67 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
, -X- _ O
0.46 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
, -X- _ O
0.64 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
and -X- _ O
0.69 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
our -X- _ O
augmented -X- _ O
data -X- _ O
outperforms -X- _ O
all -X- _ O
the -X- _ O
baselines -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Our -X- _ O
augmented -X- _ O
data -X- _ O
achieve -X- _ O
similar -X- _ O
scores -X- _ O
as -X- _ O
the -X- _ O
observed -X- _ O
data -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
our -X- _ O
augmented -X- _ O
data -X- _ O
is -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
some -X- _ O
cases -X- _ O
of -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
gen-1640 -X- _ O
eration -X- _ O
process -X- _ O
of -X- _ O
different -X- _ O
- -X- _ O
semantic -X- _ O
responses -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Our -X- _ O
augmented -X- _ O
data -X- _ O
achieve -X- _ O
better -X- _ O
scores -X- _ O
of -X- _ O
BS -X- _ O
, -X- _ O
BSand -X- _ O
Richness -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
can -X- _ O
augment -X- _ O
more -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
samp -X- _ I-MethodName
vs. -X- _ O
CAPT -X- _ B-MethodName
shows -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
intervention -X- _ O
in -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
k10 -X- _ I-MethodName
achieves -X- _ O
relatively -X- _ O
good -X- _ O
scores -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
baselines -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
sampling -X- _ O
( -X- _ O
k=10 -X- _ O
) -X- _ O
is -X- _ O
superior -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
decoding -X- _ O
strategies -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
sampling -X- _ O
( -X- _ O
k=10 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
following -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
5.2 -X- _ O
Evaluating -X- _ O
Dialogue -X- _ O
Model -X- _ O
We -X- _ O
further -X- _ O
evaluate -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
our -X- _ O
augmented -X- _ O
data -X- _ O
on -X- _ O
retrieve -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020a -X- _ O
) -X- _ O
and -X- _ O
select -X- _ O
300 -X- _ O
K -X- _ O
augmented -X- _ O
post -X- _ O
- -X- _ O
response -X- _ O
samples -X- _ O
for -X- _ O
all -X- _ O
methods -X- _ O
for -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
automatic -X- _ O
evaluation -X- _ O
on -X- _ O
5 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
test -X- _ B-HyperparameterName
data -X- _ O
and -X- _ O
manual -X- _ O
evaluation -X- _ O
on -X- _ O
600 -X- _ O
samples -X- _ O
that -X- _ O
contain -X- _ O
200 -X- _ O
randomly -X- _ O
- -X- _ O
sampled -X- _ O
posts -X- _ O
with -X- _ O
3 -X- _ O
generated -X- _ O
responses -X- _ O
. -X- _ O
The -X- _ O
κvalue -X- _ B-MetricName
for -X- _ O
Fluency -X- _ B-MetricName
, -X- _ O
Coherence -X- _ B-MetricName
, -X- _ O
Interesting -X- _ B-MetricName
andRichness -X- _ B-MetricName
are -X- _ O
0.67 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
are -X- _ O
0.71 -X- _ B-MetricValue
( -X- _ O
substantial -X- _ O
agreement -X- _ O
) -X- _ O
, -X- _ O
0.59 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
, -X- _ O
0.48 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
and -X- _ O
0.53 -X- _ B-MetricValue
( -X- _ O
moderate -X- _ O
agreement -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
retrieve -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
generationbased -X- _ O
models -X- _ O
are -X- _ O
respectively -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
the -X- _ O
baselines -X- _ O
on -X- _ O
almost -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
for -X- _ O
both -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
This -X- _ O
confirms -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
augmenting -X- _ O
valid -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
further -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
CAPT -X- _ B-MethodName
achieves -X- _ O
higher -X- _ O
scores -X- _ O
for -X- _ O
almost -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
compared -X- _ O
to -X- _ O
other -X- _ O
BART -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
especially -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
samp -X- _ I-MethodName
. -X- _ O
This -X- _ O
demonstrates -X- _ O
that -X- _ O
intervention -X- _ O
in -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
is -X- _ O
effective -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
CAPT -X- _ B-MethodName
achieves -X- _ O
higher -X- _ O
BSand -X- _ B-MetricName
Richness -X- _ B-MetricName
ratings -X- _ O
but -X- _ O
a -X- _ O
relatively -X- _ O
lower -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
augmenting -X- _ O
more -X- _ O
semantically -X- _ O
different -X- _ O
samples -X- _ O
enables -X- _ O
dialogue -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
more -X- _ O
responses -X- _ O
that -X- _ O
differ -X- _ O
from -X- _ O
references -X- _ O
. -X- _ O
5.3 -X- _ O
Further -X- _ O
Discussion -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
investigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
augmented -X- _ O
responses -X- _ O
and -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
CAPT.1641 -X- _ B-MethodName
The -X- _ O
Impact -X- _ O
of -X- _ O
Amount -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
0x -X- _ B-HyperparameterValue
, -X- _ O
1x -X- _ B-HyperparameterValue
, -X- _ O
2x -X- _ B-HyperparameterValue
, -X- _ O
3x -X- _ B-HyperparameterValue
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ B-HyperparameterName
samples -X- _ I-HyperparameterName
to -X- _ O
assess -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
providing -X- _ O
more -X- _ O
responses -X- _ O
and -X- _ O
compare -X- _ O
CAPT -X- _ B-MethodName
with -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
samp -X- _ I-MethodName
. -X- _ O
Note -X- _ O
that -X- _ O
3x -X- _ B-HyperparameterValue
represents -X- _ O
that -X- _ O
3 -X- _ B-HyperparameterValue
* -X- _ I-HyperparameterValue
300 -X- _ I-HyperparameterValue
K -X- _ I-HyperparameterValue
augmented -X- _ O
post -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
response -X- _ I-HyperparameterName
samples -X- _ I-HyperparameterName
are -X- _ O
selected -X- _ O
. -X- _ O
Considering -X- _ O
that -X- _ O
samples -X- _ O
selected -X- _ O
in -X- _ O
order -X- _ O
have -X- _ O
different -X- _ O
interesting -X- _ O
degrees -X- _ O
, -X- _ O
we -X- _ O
eliminate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
interesting -X- _ O
by -X- _ O
uniformly -X- _ O
selecting -X- _ O
900 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
augmented -X- _ O
samples -X- _ B-HyperparameterName
and -X- _ O
randomly -X- _ O
select -X- _ O
from -X- _ O
them -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
The -X- _ O
MAP -X- _ B-MetricName
score -X- _ O
on -X- _ O
BARTsamp -X- _ B-MethodName
reaches -X- _ O
a -X- _ O
peak -X- _ O
at -X- _ O
2x -X- _ B-HyperparameterValue
and -X- _ O
drops -X- _ O
afterward -X- _ O
, -X- _ O
and -X- _ O
BSkeeps -X- _ B-MetricName
increasing -X- _ O
from -X- _ O
0x -X- _ B-HyperparameterValue
to -X- _ O
3x -X- _ B-HyperparameterValue
augmentation -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
samp -X- _ I-MethodName
only -X- _ O
outputs -X- _ O
alternative -X- _ O
expressions -X- _ O
with -X- _ O
diversified -X- _ O
words -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
limited -X- _ O
semantic -X- _ O
differences -X- _ O
. -X- _ O
Augmentation -X- _ O
of -X- _ O
similar -X- _ O
samples -X- _ O
at -X- _ O
high -X- _ O
amounts -X- _ O
would -X- _ O
negatively -X- _ O
affect -X- _ O
training -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
MAP -X- _ B-MetricName
score -X- _ O
on -X- _ O
CAPT -X- _ B-MethodName
keeps -X- _ O
increasing -X- _ O
and -X- _ O
BSdoes -X- _ B-MetricName
not -X- _ O
increase -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
can -X- _ O
augment -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
, -X- _ O
and -X- _ O
providing -X- _ O
more -X- _ O
semantically -X- _ O
different -X- _ O
responses -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Ablation -X- _ O
Study -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
the -X- _ O
following -X- _ O
ablation -X- _ O
tests -X- _ O
to -X- _ O
validate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Randomly -X- _ O
choose -X- _ O
a -X- _ O
keyword -X- _ O
from -X- _ O
candidates -X- _ O
as -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
without -X- _ O
the -X- _ O
prediction -X- _ O
step -X- _ O
( -X- _ O
-Predictor -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Only -X- _ O
take -X- _ O
the -X- _ O
post -X- _ O
and -X- _ O
the -X- _ O
focus -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
predictor -X- _ O
without -X- _ O
1 -X- _ O
- -X- _ O
hop -X- _ O
neighbors -X- _ O
as -X- _ O
candidates -X- _ O
( -X- _ O
-Candidate -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Do -X- _ O
not -X- _ O
filter -X- _ O
out -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
via -X- _ O
data -X- _ O
selection -X- _ O
( -X- _ O
-Selection -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Leverage -X- _ O
a -X- _ O
general -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
GPT2 -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
see -X- _ O
enough -X- _ O
dialogue -X- _ O
samples -X- _ O
, -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
dialogue -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
model -X- _ O
DialoFlow -X- _ O
( -X- _ O
-Dial -X- _ O
PLM -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
Only -X- _ O
use -X- _ O
the -X- _ O
forward -X- _ O
PPL -X- _ O
scores -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
invalid -X- _ O
samples -X- _ O
without -X- _ O
ranking -X- _ O
via -X- _ O
the -X- _ O
backward -X- _ O
PPL -X- _ O
scores -X- _ O
( -X- _ O
-Back -X- _ O
PPL -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Generate -X- _ O
responses -X- _ O
not -X- _ O
under -X- _ O
the -X- _ O
current -X- _ O
environment -X- _ O
, -X- _ O
i.e -X- _ O
, -X- _ O
without -X- _ O
the -X- _ O
posterior -X- _ O
Gumbel -X- _ O
noises -X- _ O
( -X- _ O
-Gumbel -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
ablating -X- _ O
each -X- _ O
component -X- _ O
brings -X- _ O
varying -X- _ O
degrees -X- _ O
of -X- _ O
performance -X- _ O
drop -X- _ O
. -X- _ O
This -X- _ O
demonstrates -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
designing -X- _ O
all -X- _ O
these1642components -X- _ O
. -X- _ O
6 -X- _ O
Related -X- _ O
Work -X- _ O
Data -X- _ O
Augmentation -X- _ O
. -X- _ O
Data -X- _ O
augmentation -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
surveyed -X- _ O
by -X- _ O
Shorten -X- _ O
and -X- _ O
Khoshgoftaar -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Wen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
Feng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
Ni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
either -X- _ O
add -X- _ O
slightly -X- _ O
modified -X- _ O
copies -X- _ O
of -X- _ O
existing -X- _ O
data -X- _ O
or -X- _ O
create -X- _ O
synthetic -X- _ O
data -X- _ O
. -X- _ O
Some -X- _ O
work -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
heuristic -X- _ O
rules -X- _ O
( -X- _ O
Du -X- _ O
and -X- _ O
Black -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
paraphrasing -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
( -X- _ O
Niu -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Cao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
( -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
is -X- _ O
exploiting -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
existing -X- _ O
methods -X- _ O
do -X- _ O
not -X- _ O
focus -X- _ O
on -X- _ O
creating -X- _ O
semantically -X- _ O
different -X- _ O
responses -X- _ O
. -X- _ O
Semantically -X- _ O
Different -X- _ O
Augmentation -X- _ O
. -X- _ O
Gangal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
utilizes -X- _ O
knowledge -X- _ O
sources -X- _ O
, -X- _ O
including -X- _ O
COMET -X- _ O
( -X- _ O
Bosselut -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
corpus -X- _ O
retrieval -X- _ O
( -X- _ O
Robertson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
to -X- _ O
augment -X- _ O
semantically -X- _ O
diverse -X- _ O
references -X- _ O
for -X- _ O
dialogue -X- _ O
evaluation -X- _ O
. -X- _ O
Both -X- _ O
methods -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
define -X- _ O
limited -X- _ O
augmented -X- _ O
perspectives -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
CAPT -X- _ B-MethodName
obtains -X- _ O
richer -X- _ O
reply -X- _ O
perspectives -X- _ O
by -X- _ O
building -X- _ O
a -X- _ O
shift -X- _ O
graph -X- _ O
. -X- _ O
Counterfactual -X- _ O
Inference -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
counterfactual -X- _ O
inference -X- _ O
( -X- _ O
Pearl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
shown -X- _ O
promising -X- _ O
results -X- _ O
in -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Paranjape -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
; -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
story -X- _ O
generation -X- _ O
( -X- _ O
Qin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Hao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
uses -X- _ O
counterfactual -X- _ O
inference -X- _ O
for -X- _ O
response -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
explores -X- _ O
potential -X- _ O
responses -X- _ O
via -X- _ O
counterfactual -X- _ O
off -X- _ O
- -X- _ O
policy -X- _ O
training -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
CAPT -X- _ B-MethodName
focuses -X- _ O
on -X- _ O
counterfactual -X- _ O
data -X- _ O
augmentation -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
multiple -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Graph -X- _ O
Construction -X- _ O
. -X- _ O
Some -X- _ O
researches -X- _ O
( -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
also -X- _ O
build -X- _ O
a -X- _ O
graph -X- _ O
to -X- _ O
manage -X- _ O
concept -X- _ O
shifts -X- _ O
for -X- _ O
response -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
more -X- _ O
coherent -X- _ O
and -X- _ O
controllable -X- _ O
dialogue -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
CAPT -X- _ B-MethodName
builds -X- _ O
a -X- _ O
shift -X- _ O
graph -X- _ O
to -X- _ O
predict -X- _ O
valid -X- _ O
substituted -X- _ O
reply -X- _ O
perspectives -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
augment -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
purposesof -X- _ O
use -X- _ O
, -X- _ O
our -X- _ O
graph -X- _ O
construction -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
these -X- _ O
existing -X- _ O
works -X- _ O
. -X- _ O
7 -X- _ O
Conclusion -X- _ O
This -X- _ O
paper -X- _ O
presents -X- _ O
a -X- _ O
counterfactual -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
, -X- _ O
CAPT -X- _ B-MethodName
, -X- _ O
to -X- _ O
augment -X- _ O
more -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
dialogue -X- _ O
history -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
CAPT -X- _ B-MethodName
employs -X- _ O
counterfactual -X- _ O
inference -X- _ O
to -X- _ O
generate -X- _ O
counterfactual -X- _ O
responses -X- _ O
by -X- _ O
intervening -X- _ O
in -X- _ O
the -X- _ O
observed -X- _ O
reply -X- _ O
perspective -X- _ O
, -X- _ O
which -X- _ O
replaces -X- _ O
with -X- _ O
different -X- _ O
reply -X- _ O
perspectives -X- _ O
for -X- _ O
generating -X- _ O
semantically -X- _ O
different -X- _ O
responses -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
can -X- _ O
augment -X- _ O
highquality -X- _ O
responses -X- _ O
with -X- _ O
different -X- _ O
semantics -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
explore -X- _ O
an -X- _ O
appropriate -X- _ O
training -X- _ O
strategy -X- _ O
for -X- _ O
further -X- _ O
preventing -X- _ O
dialogue -X- _ O
models -X- _ O
from -X- _ O
being -X- _ O
affected -X- _ O
by -X- _ O
noises -X- _ O
in -X- _ O
our -X- _ O
augmented -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
extend -X- _ O
CAPT -X- _ B-MethodName
on -X- _ O
multi -X- _ O
- -X- _ O
turn -X- _ O
dialogues -X- _ O
. -X- _ O
We -X- _ O
hope -X- _ O
that -X- _ O
CAPT -X- _ B-MethodName
will -X- _ O
encourage -X- _ O
future -X- _ O
research -X- _ O
for -X- _ O
other -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Limitations -X- _ O
CAPT -X- _ B-MethodName
works -X- _ O
well -X- _ O
in -X- _ O
scenarios -X- _ O
with -X- _ O
a -X- _ O
certain -X- _ O
amount -X- _ O
of -X- _ O
observed -X- _ O
data -X- _ O
. -X- _ O
A -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
observed -X- _ O
data -X- _ O
would -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
small -X- _ O
- -X- _ O
scale -X- _ O
shift -X- _ O
graph -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
provide -X- _ O
enough -X- _ O
candidates -X- _ O
to -X- _ O
pick -X- _ O
out -X- _ O
more -X- _ O
valid -X- _ O
reply -X- _ O
perspectives -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
augment -X- _ O
sufficient -X- _ O
valid -X- _ O
post -X- _ O
- -X- _ O
response -X- _ O
samples -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
CAPT -X- _ B-MethodName
may -X- _ O
be -X- _ O
more -X- _ O
suitable -X- _ O
for -X- _ O
opendomain -X- _ O
dialogue -X- _ O
augmentation -X- _ O
in -X- _ O
some -X- _ O
languages -X- _ O
that -X- _ O
require -X- _ O
good -X- _ O
- -X- _ O
quality -X- _ O
keyword -X- _ O
extraction -X- _ O
methods -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
for -X- _ O
that -X- _ O
language -X- _ O
. -X- _ O
e.g. -X- _ O
, -X- _ O
Chinese -X- _ O
and -X- _ O
English -X- _ O
. -X- _ O
When -X- _ O
transferred -X- _ O
to -X- _ O
different -X- _ O
languages -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
the -X- _ O
modifications -X- _ O
are -X- _ O
required -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
English -X- _ O
- -X- _ O
version -X- _ O
keyword -X- _ O
extraction -X- _ O
method -X- _ O
and -X- _ O
keyword -X- _ O
/ -X- _ O
sentence -X- _ O
encoder -X- _ O
when -X- _ O
building -X- _ O
the -X- _ O
graph -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
Englishversion -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
for -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
predictor -X- _ O
and -X- _ O
the -X- _ O
counterfactual -X- _ O
generator -X- _ O
. -X- _ O
Ethics -X- _ O
Statement -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
three -X- _ O
annotators -X- _ O
to -X- _ O
manually -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
and -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
dialogue -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
pay -X- _ O
$ -X- _ O
0.2to -X- _ O
each -X- _ O
annotator -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
. -X- _ O
Acknowledgement -X- _ O
We -X- _ O
sincerely -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
thorough -X- _ O
reviewing -X- _ O
and -X- _ O
valuable -X- _ O
suggestions.1643References164416451646A -X- _ O
Task -X- _ O
Definitions -X- _ O
Response -X- _ O
Selection -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
dataset -X- _ O
D= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
l -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
retrieval -X- _ O
- -X- _ O
based -X- _ O
dialogue -X- _ O
model -X- _ O
learns -X- _ O
a -X- _ O
matching -X- _ O
function -X- _ O
to -X- _ O
correctly -X- _ O
identify -X- _ O
the -X- _ O
positive -X- _ O
response -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
negative -X- _ O
responses -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
matching -X- _ O
functionP -X- _ O
( -X- _ O
l|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
predicts -X- _ O
whether -X- _ O
the -X- _ O
response -X- _ O
y -X- _ O
matches -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
x.l∈ -X- _ O
{ -X- _ O
0,1 -X- _ O
} -X- _ O
denotes -X- _ O
a -X- _ O
matching -X- _ O
label -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
yis -X- _ O
a -X- _ O
proper -X- _ O
response -X- _ O
for -X- _ O
xifl= -X- _ O
1 -X- _ O
, -X- _ O
otherwise -X- _ O
l= -X- _ O
0 -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
parameters -X- _ O
θcan -X- _ O
be -X- _ O
learned -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
that -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
L=− -X- _ O
/ -X- _ O
summationdisplay -X- _ O
[ -X- _ O
llogP -X- _ O
( -X- _ O
l= -X- _ O
1|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−l -X- _ O
) -X- _ O
logP -X- _ O
( -X- _ O
l= -X- _ O
0|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
] -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
Generally -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
negative -X- _ O
responses -X- _ O
are -X- _ O
randomly -X- _ O
selected -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
D. -X- _ O
Response -X- _ O
Generation -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
dataset -X- _ O
D= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
the -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
dialogue -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
distribution -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
response -X- _ O
ygiven -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
x. -X- _ O
The -X- _ O
model -X- _ O
parameters -X- _ O
ϕcan -X- _ O
be -X- _ O
learned -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
following -X- _ O
loss -X- _ O
: -X- _ O
L=− -X- _ O
/ -X- _ O
summationdisplaylogP -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
However -X- _ O
, -X- _ O
a -X- _ O
dialogue -X- _ O
dataset -X- _ O
that -X- _ O
admits -X- _ O
multiple -X- _ O
semantically -X- _ O
different -X- _ O
responses -X- _ O
for -X- _ O
each -X- _ O
dialogue -X- _ O
history -X- _ O
is -X- _ O
usually -X- _ O
expensive -X- _ O
to -X- _ O
collect -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
requires -X- _ O
annotators -X- _ O
to -X- _ O
write -X- _ O
a -X- _ O
large -X- _ O
variety -X- _ O
of -X- _ O
valid -X- _ O
responses -X- _ O
. -X- _ O
Although -X- _ O
such -X- _ O
a -X- _ O
dataset -X- _ O
can -X- _ O
be -X- _ O
crawled -X- _ O
from -X- _ O
social -X- _ O
networks -X- _ O
, -X- _ O
it -X- _ O
will -X- _ O
contain -X- _ O
many -X- _ O
noisy -X- _ O
and -X- _ O
meaningless -X- _ O
responses -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
expensive -X- _ O
to -X- _ O
pick -X- _ O
out -X- _ O
sufficient -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
dialogues -X- _ O
that -X- _ O
meet -X- _ O
requirements -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
counterfactual -X- _ O
data -X- _ O
augmentation -X- _ O
aims -X- _ O
to -X- _ O
further -X- _ O
augment -X- _ O
different -X- _ O
- -X- _ O
semantic -X- _ O
responses -X- _ O
˜yforxinDwithout -X- _ O
manually -X- _ O
collecting -X- _ O
new -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
sections -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
omit -X- _ O
the -X- _ O
superscript -X- _ O
ifor -X- _ O
simplicity -X- _ O
. -X- _ O
B -X- _ O
Experimental -X- _ O
Details -X- _ O
B.1 -X- _ O
Data -X- _ O
The -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
Chinese -X- _ B-DatasetName
Weibo -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
dataset -X- _ O
Dcontains -X- _ O
training -X- _ B-HyperparameterName
, -X- _ O
validation -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
test -X- _ B-HyperparameterName
sets -X- _ O
with -X- _ O
300K,5 -X- _ B-HyperparameterValue
K -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
post -X- _ O
- -X- _ O
response -X- _ O
samples -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
To -X- _ O
build -X- _ O
the -X- _ O
shift -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
YAKE -X- _ O
( -X- _ O
Campos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
that -X- _ O
relies -X- _ O
on -X- _ O
thestatistical -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
automatically -X- _ O
extract -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
keywords -X- _ O
of -X- _ O
each -X- _ O
utterance -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Keywords -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
nouns -X- _ O
, -X- _ O
adjectives -X- _ O
and -X- _ O
verbs -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
keyword -X- _ O
vertices -X- _ O
and -X- _ O
edges -X- _ O
are -X- _ O
77,439and202,266respectively -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
200 -X- _ O
post -X- _ O
- -X- _ O
response -X- _ O
samples -X- _ O
and -X- _ O
employ -X- _ O
three -X- _ O
human -X- _ O
annotators -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
appropriateness -X- _ O
of -X- _ O
both -X- _ O
keywords -X- _ O
of -X- _ O
focus -X- _ O
and -X- _ O
reply -X- _ O
perspective -X- _ O
. -X- _ O
About -X- _ O
86 -X- _ O
% -X- _ O
keyword -X- _ O
pairs -X- _ O
are -X- _ O
accepted -X- _ O
by -X- _ O
the -X- _ O
annotators -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
candidate -X- _ O
keywords -X- _ O
at -X- _ O
training -X- _ O
and -X- _ O
augmentation -X- _ O
times -X- _ O
are -X- _ O
102 -X- _ O
and -X- _ O
124 -X- _ O
respectively -X- _ O
. -X- _ O
After -X- _ O
achieving -X- _ O
augmented -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
similarly -X- _ O
evaluate -X- _ O
whether -X- _ O
the -X- _ O
responses -X- _ O
share -X- _ O
similar -X- _ O
core -X- _ O
semantics -X- _ O
with -X- _ O
the -X- _ O
given -X- _ O
reply -X- _ O
perspectives -X- _ O
. -X- _ O
About -X- _ O
96.5 -X- _ O
% -X- _ O
responses -X- _ O
are -X- _ O
accepted -X- _ O
by -X- _ O
the -X- _ O
annotators -X- _ O
. -X- _ O
B.2 -X- _ O
Implementation -X- _ O
Details -X- _ O
CAPT -X- _ B-MethodName
. -X- _ O
For -X- _ O
graph -X- _ O
construction -X- _ O
, -X- _ O
we -X- _ O
pursue -X- _ O
bertas -X- _ O
- -X- _ O
service -X- _ O
( -X- _ O
Xiao -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
embedding -X- _ O
by -X- _ O
mapping -X- _ O
a -X- _ O
variable -X- _ O
- -X- _ O
length -X- _ O
text -X- _ O
sequence -X- _ O
to -X- _ O
a -X- _ O
fixed -X- _ O
- -X- _ O
length -X- _ O
vector -X- _ O
. -X- _ O
Our -X- _ O
predictor -X- _ O
and -X- _ O
generator -X- _ O
are -X- _ O
independently -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
BART -X- _ O
- -X- _ O
large -X- _ O
model -X- _ O
( -X- _ O
Shao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
loss -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
for -X- _ O
ten -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
with -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
other -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
setting -X- _ O
follows -X- _ O
that -X- _ O
of -X- _ O
Shao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
thus -X- _ O
limit -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
candidate -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
our -X- _ O
predictor -X- _ O
to -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O
If -X- _ O
the -X- _ O
candidate -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
greater -X- _ O
than -X- _ O
100 -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
100 -X- _ B-HyperparameterValue
candidates -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
filter -X- _ O
out -X- _ O
those -X- _ O
samples -X- _ O
whose -X- _ O
candidate -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
less -X- _ O
than -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
data -X- _ O
selection -X- _ O
, -X- _ O
we -X- _ O
implement -X- _ O
the -X- _ O
score -X- _ O
functions -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
DialoFlow -X- _ O
( -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
model -X- _ O
with -X- _ O
Dfor -X- _ O
two -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
with -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
best -X- _ O
threshold -X- _ B-HyperparameterName
ηis -X- _ I-HyperparameterName
10 -X- _ B-HyperparameterValue
. -X- _ O
At -X- _ O
augmentation -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
limit -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
from -X- _ O
5to100 -X- _ B-HyperparameterValue
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
whole -X- _ O
candidate -X- _ O
set -X- _ O
into -X- _ O
Ksub -X- _ O
- -X- _ O
sets -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
candidate -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
each -X- _ O
sub -X- _ O
- -X- _ O
set -X- _ O
N= -X- _ O
max -X- _ B-HyperparameterValue
( -X- _ I-HyperparameterValue
min -X- _ I-HyperparameterValue
( -X- _ I-HyperparameterValue
,100 -X- _ I-HyperparameterValue
) -X- _ I-HyperparameterValue
,5 -X- _ I-HyperparameterValue
) -X- _ I-HyperparameterValue
, -X- _ O
where -X- _ O
Kis -X- _ B-HyperparameterName
initialized -X- _ O
by -X- _ O
20 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
further -X- _ O
update -X- _ O
K=. -X- _ O
The -X- _ O
predictor -X- _ O
outputs -X- _ O
reply -X- _ O
perspectives -X- _ O
with -X- _ O
greedy -X- _ O
search -X- _ O
. -X- _ O
The -X- _ O
generator -X- _ O
samples -X- _ O
counterfactual -X- _ O
responses -X- _ O
from -X- _ O
posterior -X- _ O
Gumbel -X- _ O
noises -X- _ O
, -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O
Retrieve -X- _ O
- -X- _ O
based -X- _ O
Model -X- _ O
. -X- _ O
The -X- _ O
retrieve -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
is -X- _ O
built -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ O
- -X- _ O
base -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
two -X- _ B-HyperparameterValue
epochs,1647with -X- _ B-HyperparameterName
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
last -X- _ O
checkpoint -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
Generation -X- _ O
- -X- _ O
based -X- _ O
Model -X- _ O
. -X- _ O
The -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
is -X- _ O
built -X- _ O
by -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BARTlarge -X- _ O
( -X- _ O
Shao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
for -X- _ O
five -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
with -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
At -X- _ O
inference -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
sampling -X- _ O
( -X- _ O
k=10 -X- _ B-HyperparameterName
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
decoded -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
last -X- _ O
checkpoint -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
Training -X- _ O
and -X- _ O
Evaluation -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
retrievebased -X- _ O
dialogue -X- _ O
models -X- _ O
with -X- _ O
4 -X- _ O
GPUs -X- _ O
, -X- _ O
generationbased -X- _ O
models -X- _ O
with -X- _ O
8 -X- _ O
GPUs -X- _ O
, -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
predictor -X- _ O
with -X- _ O
8 -X- _ O
GPUs -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
counterfactual -X- _ O
generator -X- _ O
with -X- _ O
8 -X- _ O
GPUs -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Nvidia -X- _ O
Tesla -X- _ O
V100 -X- _ O
GPUs -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
time -X- _ O
for -X- _ O
retrieve -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
reply -X- _ O
perspective -X- _ O
predictor -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
counterfactual -X- _ O
generator -X- _ O
is -X- _ O
approximately -X- _ O
2h -X- _ O
, -X- _ O
4h -X- _ O
, -X- _ O
4h -X- _ O
and -X- _ O
5h -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
At -X- _ O
augmentation -X- _ O
time -X- _ O
, -X- _ O
it -X- _ O
takes -X- _ O
55min -X- _ O
to -X- _ O
predict -X- _ O
reply -X- _ O
perspectives -X- _ O
and -X- _ O
1h -X- _ O
to -X- _ O
generate -X- _ O
counterfactual -X- _ O
responses -X- _ O
for -X- _ O
all -X- _ O
augmented -X- _ O
samples -X- _ O
. -X- _ O
When -X- _ O
calculating -X- _ O
the -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
PPL -X- _ O
scores -X- _ O
, -X- _ O
it -X- _ O
takes -X- _ O
40min -X- _ O
respectively.1648 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
proposes -X- _ SUMMARY
quality -X- _ SUMMARY
- -X- _ SUMMARY
aware -X- _ SUMMARY
decoding -X- _ SUMMARY
for -X- _ SUMMARY
neural -X- _ SUMMARY
machine -X- _ SUMMARY
translation -X- _ SUMMARY
( -X- _ SUMMARY
NMT -X- _ SUMMARY
) -X- _ SUMMARY
to -X- _ SUMMARY
improve -X- _ SUMMARY
translation -X- _ SUMMARY
quality -X- _ SUMMARY
. -X- _ SUMMARY
It -X- _ SUMMARY
combines -X- _ SUMMARY
recent -X- _ SUMMARY
advancements -X- _ SUMMARY
in -X- _ SUMMARY
reference -X- _ SUMMARY
- -X- _ SUMMARY
free -X- _ SUMMARY
and -X- _ SUMMARY
reference -X- _ SUMMARY
- -X- _ SUMMARY
based -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
with -X- _ SUMMARY
NMT -X- _ SUMMARY
decoding -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
experiment -X- _ SUMMARY
with -X- _ SUMMARY
various -X- _ SUMMARY
candidate -X- _ SUMMARY
generation -X- _ SUMMARY
and -X- _ SUMMARY
ranking -X- _ SUMMARY
methods -X- _ SUMMARY
and -X- _ SUMMARY
evaluate -X- _ SUMMARY
their -X- _ SUMMARY
performance -X- _ SUMMARY
on -X- _ SUMMARY
four -X- _ SUMMARY
datasets -X- _ SUMMARY
using -X- _ SUMMARY
metrics -X- _ SUMMARY
such -X- _ SUMMARY
as -X- _ SUMMARY
BLEU -X- _ SUMMARY
, -X- _ SUMMARY
COMET -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
BLEURT -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
find -X- _ SUMMARY
that -X- _ SUMMARY
quality -X- _ SUMMARY
- -X- _ SUMMARY
aware -X- _ SUMMARY
decoding -X- _ SUMMARY
consistently -X- _ SUMMARY
outperforms -X- _ SUMMARY
MAP -X- _ SUMMARY
- -X- _ SUMMARY
based -X- _ SUMMARY
decoding -X- _ SUMMARY
according -X- _ SUMMARY
to -X- _ SUMMARY
both -X- _ SUMMARY
automatic -X- _ SUMMARY
metrics -X- _ SUMMARY
and -X- _ SUMMARY
human -X- _ SUMMARY
assessments -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
compare -X- _ SUMMARY
N -X- _ SUMMARY
- -X- _ SUMMARY
best -X- _ SUMMARY
reranking -X- _ SUMMARY
and -X- _ SUMMARY
minimum -X- _ SUMMARY
Bayes -X- _ SUMMARY
risk -X- _ SUMMARY
( -X- _ SUMMARY
MBR -X- _ SUMMARY
) -X- _ SUMMARY
decoding -X- _ SUMMARY
and -X- _ SUMMARY
explore -X- _ SUMMARY
a -X- _ SUMMARY
two -X- _ SUMMARY
- -X- _ SUMMARY
stage -X- _ SUMMARY
ranking -X- _ SUMMARY
approach -X- _ SUMMARY
that -X- _ SUMMARY
combines -X- _ SUMMARY
both -X- _ SUMMARY
methods -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
experiments -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
N -X- _ SUMMARY
- -X- _ SUMMARY
best -X- _ SUMMARY
reranking -X- _ SUMMARY
performs -X- _ SUMMARY
better -X- _ SUMMARY
than -X- _ SUMMARY
MBR -X- _ SUMMARY
decoding -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
the -X- _ SUMMARY
two -X- _ SUMMARY
- -X- _ SUMMARY
stage -X- _ SUMMARY
approach -X- _ SUMMARY
provides -X- _ SUMMARY
the -X- _ SUMMARY
best -X- _ SUMMARY
results -X- _ SUMMARY
according -X- _ SUMMARY
to -X- _ SUMMARY
fine -X- _ SUMMARY
- -X- _ SUMMARY
tuned -X- _ SUMMARY
metrics -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
also -X- _ SUMMARY
highlights -X- _ SUMMARY
the -X- _ SUMMARY
importance -X- _ SUMMARY
of -X- _ SUMMARY
using -X- _ SUMMARY
powerful -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
and -X- _ SUMMARY
their -X- _ SUMMARY
potential -X- _ SUMMARY
impact -X- _ SUMMARY
on -X- _ SUMMARY
translation -X- _ SUMMARY
quality -X- _ SUMMARY
. -X- _ SUMMARY
2022.naacl-main.100.txt -X- _ O
Patrick -X- _ O
FernandesAntónio -X- _ O
FarinhasRicardo -X- _ O
ReiJosé -X- _ O
G. -X- _ O
C. -X- _ O
de -X- _ O
Souza -X- _ O
Perez -X- _ O
OgayoGraham -X- _ O
NeubigAndré -X- _ O
F. -X- _ O
T. -X- _ O
MartinsCarnegie -X- _ O
Mellon -X- _ O
UniversityInstituto -X- _ O
Superior -X- _ O
Técnico -X- _ O
( -X- _ O
Lisbon -X- _ O
ELLIS -X- _ O
Unit -X- _ O
) -X- _ O
Instituto -X- _ O
de -X- _ O
TelecomunicaçõesINESC -X- _ O
- -X- _ O
IDUnbabel -X- _ O
Abstract -X- _ O
Despite -X- _ O
the -X- _ O
progress -X- _ O
in -X- _ O
machine -X- _ O
translation -X- _ O
quality -X- _ O
estimation -X- _ O
and -X- _ O
evaluation -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
years -X- _ O
, -X- _ O
decoding -X- _ B-TaskName
in -X- _ I-TaskName
neural -X- _ I-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
NMT -X- _ B-TaskName
) -X- _ O
is -X- _ O
mostly -X- _ O
oblivious -X- _ O
to -X- _ O
this -X- _ O
and -X- _ O
centers -X- _ O
around -X- _ O
finding -X- _ O
the -X- _ O
most -X- _ O
probable -X- _ O
translation -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
MAP -X- _ O
decoding -X- _ O
) -X- _ O
, -X- _ O
approximated -X- _ O
with -X- _ O
beam -X- _ O
search -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
bring -X- _ O
together -X- _ O
these -X- _ O
two -X- _ O
lines -X- _ O
of -X- _ O
research -X- _ O
and -X- _ O
propose -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
for -X- _ O
NMT -X- _ B-TaskName
, -X- _ O
by -X- _ O
leveraging -X- _ O
recent -X- _ O
breakthroughs -X- _ O
in -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
and -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
MT -X- _ O
evaluation -X- _ O
through -X- _ O
various -X- _ O
inference -X- _ O
methods -X- _ O
like -X- _ O
N -X- _ O
- -X- _ O
best -X- _ O
reranking -X- _ O
and -X- _ O
minimum -X- _ O
Bayes -X- _ O
risk -X- _ O
decoding -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
comparison -X- _ O
of -X- _ O
various -X- _ O
possible -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
ranking -X- _ O
methods -X- _ O
across -X- _ O
four -X- _ O
datasets -X- _ O
and -X- _ O
two -X- _ O
model -X- _ O
classes -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
consistently -X- _ O
outperforms -X- _ O
MAP -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
decoding -X- _ I-MethodName
according -X- _ O
both -X- _ O
to -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
automatic -X- _ O
metrics -X- _ O
( -X- _ O
COMET -X- _ B-MetricName
and -X- _ O
BLEURT -X- _ B-MetricName
) -X- _ O
and -X- _ O
to -X- _ O
human -X- _ B-MetricName
assessments -X- _ I-MetricName
. -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
athttps -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
github.com -X- _ O
/ -X- _ O
deep-spin -X- _ O
/ -X- _ O
qaware -X- _ O
- -X- _ O
decode -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
The -X- _ O
most -X- _ O
common -X- _ O
procedure -X- _ O
in -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
NMT -X- _ B-MethodName
) -X- _ O
is -X- _ O
to -X- _ O
train -X- _ O
models -X- _ O
using -X- _ O
maximum -X- _ O
likelihood -X- _ O
estimation -X- _ O
( -X- _ O
MLE -X- _ O
) -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
decode -X- _ O
with -X- _ O
beam -X- _ O
search -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
approximate -X- _ O
maximum -X- _ B-MethodName
- -X- _ I-MethodName
a -X- _ I-MethodName
- -X- _ I-MethodName
posteriori -X- _ I-MethodName
( -X- _ I-MethodName
MAP -X- _ I-MethodName
) -X- _ I-MethodName
decoding -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
several -X- _ O
works -X- _ O
have -X- _ O
questioned -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
model -X- _ O
likelihood -X- _ O
as -X- _ O
a -X- _ O
good -X- _ O
proxy -X- _ O
for -X- _ O
translation -X- _ O
quality -X- _ O
( -X- _ O
Koehn -X- _ O
and -X- _ O
Knowles -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Stahlberg -X- _ O
and -X- _ O
Byrne -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
parallel -X- _ O
, -X- _ O
significant -X- _ O
progress -X- _ O
has -X- _ O
been -X- _ O
made -X- _ O
in -X- _ O
methods -X- _ O
for -X- _ O
quality -X- _ O
estimation -X- _ O
and -X- _ O
evaluation -X- _ O
of -X- _ O
generated -X- _ O
translations -X- _ O
( -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
progress -X- _ O
is -X- _ O
, -X- _ O
by -X- _ O
and -X- _ O
large -X- _ O
, -X- _ O
not -X- _ O
yet -X- _ O
reflected -X- _ O
in -X- _ O
either -X- _ O
training -X- _ O
or -X- _ O
decoding -X- _ O
methods -X- _ O
. -X- _ O
Exceptions -X- _ O
such -X- _ O
as -X- _ O
minimum -X- _ O
risk -X- _ O
training -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
framework -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
translation -X- _ O
candidates -X- _ O
are -X- _ O
generated -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
using -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
referencebased -X- _ O
MT -X- _ O
metrics -X- _ O
, -X- _ O
these -X- _ O
candidates -X- _ O
are -X- _ O
ranked -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
highest -X- _ O
ranked -X- _ O
one -X- _ O
is -X- _ O
picked -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
translation -X- _ O
. -X- _ O
come -X- _ O
at -X- _ O
a -X- _ O
cost -X- _ O
of -X- _ O
more -X- _ O
expensive -X- _ O
and -X- _ O
unstable -X- _ O
training -X- _ O
, -X- _ O
often -X- _ O
with -X- _ O
modest -X- _ O
quality -X- _ O
improvements -X- _ O
. -X- _ O
An -X- _ O
appealing -X- _ O
alternative -X- _ O
is -X- _ O
to -X- _ O
modify -X- _ O
the -X- _ O
decoding -X- _ O
procedure -X- _ O
only -X- _ O
, -X- _ O
separating -X- _ O
it -X- _ O
into -X- _ O
two -X- _ O
stages -X- _ O
: -X- _ O
candidate -X- _ O
generation -X- _ O
( -X- _ O
§ -X- _ O
2.1 -X- _ O
; -X- _ O
where -X- _ O
candidates -X- _ O
are -X- _ O
generated -X- _ O
with -X- _ O
beam -X- _ O
search -X- _ O
or -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
whole -X- _ O
distribution -X- _ O
) -X- _ O
and -X- _ O
ranking -X- _ O
( -X- _ O
§ -X- _ O
2.2 -X- _ O
; -X- _ O
where -X- _ O
they -X- _ O
are -X- _ O
scored -X- _ O
using -X- _ O
a -X- _ O
quality -X- _ O
metric -X- _ O
of -X- _ O
interest -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
translation -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
is -X- _ O
picked -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
strategy -X- _ O
has -X- _ O
been -X- _ O
explored -X- _ O
in -X- _ O
approaches -X- _ O
using -X- _ O
N -X- _ O
- -X- _ O
best -X- _ O
reranking -X- _ O
( -X- _ O
Ng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Bhattacharyya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
minimum -X- _ B-MethodName
Bayes -X- _ I-MethodName
risk -X- _ I-MethodName
( -X- _ O
MBR -X- _ B-MethodName
) -X- _ O
decoding -X- _ O
( -X- _ O
Shu -X- _ O
and -X- _ O
Nakayama -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Müller -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
this -X- _ O
previous -X- _ O
work -X- _ O
has -X- _ O
exhibited -X- _ O
promising -X- _ O
results -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
mostly -X- _ O
focused -X- _ O
on -X- _ O
optimizing -X- _ O
lexical -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
BLEU -X- _ B-MetricName
or -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Lavie -X- _ O
and -X- _ O
Denkowski -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
limited -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
( -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
a -X- _ O
rigorous -X- _ O
apples -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
apples -X- _ O
comparison -X- _ O
among -X- _ O
this -X- _ O
suite -X- _ O
of -X- _ O
techniques -X- _ O
and -X- _ O
their -X- _ O
variants -X- _ O
is -X- _ O
still -X- _ O
missing -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
share -X- _ O
similar -X- _ O
building -X- _ O
blocks -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
fills -X- _ O
these -X- _ O
gaps -X- _ O
by -X- _ O
asking -X- _ O
the -X- _ O
question -X- _ O
: -X- _ O
“ -X- _ O
Can -X- _ O
we -X- _ O
leverage -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
MT -X- _ O
quality -X- _ O
evaluation -X- _ O
to -X- _ O
generate -X- _ O
better -X- _ O
translations -X- _ O
? -X- _ O
If -X- _ O
so -X- _ O
, -X- _ O
how -X- _ O
can -X- _ O
we -X- _ O
most -X- _ O
effectively -X- _ O
do -X- _ O
so -X- _ O
? -X- _ O
” -X- _ O
To -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
systematically -X- _ O
explore1396NMT -X- _ B-TaskName
decoding -X- _ O
using -X- _ O
a -X- _ O
suite -X- _ O
of -X- _ O
ranking -X- _ O
procedures -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
recent -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
learnable -X- _ O
metrics -X- _ O
, -X- _ O
both -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
COMET -X- _ B-MetricName
and -X- _ O
BLEURT -X- _ B-MetricName
( -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
; -X- _ O
Sellam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
( -X- _ O
also -X- _ O
known -X- _ O
asquality -X- _ O
estimation -X- _ O
; -X- _ O
QE -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
TransQuest -X- _ B-MetricName
and -X- _ O
OpenKiwi -X- _ B-MetricName
( -X- _ O
Ranasinghe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kepler -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
different -X- _ O
ranking -X- _ O
strategies -X- _ O
under -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
name -X- _ O
quality -X- _ O
- -X- _ O
aware -X- _ O
decoding -X- _ O
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
decoding -X- _ O
using -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
both -X- _ O
fixed -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
metric -X- _ O
and -X- _ O
learned -X- _ O
using -X- _ O
multiple -X- _ O
metrics -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
coefficients -X- _ O
for -X- _ O
each -X- _ O
metric -X- _ O
are -X- _ O
optimized -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
ranking -X- _ O
using -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
directly -X- _ O
through -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
Finally -X- _ O
, -X- _ O
to -X- _ O
circumvent -X- _ O
the -X- _ O
expensive -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidates -X- _ O
is -X- _ O
large -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
ranking -X- _ O
procedure -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
use -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
to -X- _ O
pick -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
candidates -X- _ O
to -X- _ O
be -X- _ O
ranked -X- _ O
through -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
We -X- _ O
explore -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
these -X- _ O
different -X- _ O
ranking -X- _ O
methods -X- _ O
with -X- _ O
various -X- _ O
candidate -X- _ O
generation -X- _ O
procedures -X- _ O
including -X- _ O
beam -X- _ O
search -X- _ O
, -X- _ O
vanilla -X- _ O
sampling -X- _ O
, -X- _ O
and -X- _ O
nucleus -X- _ O
sampling -X- _ O
. -X- _ O
Experiments -X- _ O
with -X- _ O
two -X- _ O
model -X- _ O
sizes -X- _ O
and -X- _ O
four -X- _ O
datasets -X- _ O
( -X- _ O
§ -X- _ O
4 -X- _ O
) -X- _ O
reveal -X- _ O
that -X- _ O
while -X- _ O
MAP -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
decoding -X- _ I-MethodName
appears -X- _ O
competitive -X- _ O
when -X- _ O
evaluating -X- _ O
with -X- _ O
lexical -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
ChrF -X- _ B-MetricName
) -X- _ O
, -X- _ O
the -X- _ O
story -X- _ O
is -X- _ O
very -X- _ O
different -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
where -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
shows -X- _ O
significant -X- _ O
gains -X- _ O
, -X- _ O
both -X- _ O
with -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
and -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
human -X- _ O
- -X- _ O
study -X- _ O
to -X- _ O
more -X- _ O
faithfully -X- _ O
evaluate -X- _ O
our -X- _ O
systems -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
, -X- _ O
while -X- _ O
performance -X- _ O
on -X- _ O
learnable -X- _ O
metrics -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
predictive -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
system -X- _ O
, -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
usually -X- _ O
results -X- _ O
in -X- _ O
translations -X- _ O
with -X- _ O
higher -X- _ O
quality -X- _ O
than -X- _ O
MAP -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
decoding -X- _ I-MethodName
. -X- _ O
2 -X- _ O
Candidate -X- _ O
Generation -X- _ O
and -X- _ O
Ranking -X- _ O
We -X- _ O
start -X- _ O
by -X- _ O
reviewing -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
commonly -X- _ O
used -X- _ O
methods -X- _ O
for -X- _ O
both -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
ranking -X- _ O
under -X- _ O
a -X- _ O
common -X- _ O
lens -X- _ O
. -X- _ O
2.1 -X- _ O
Candidate -X- _ O
Generation -X- _ O
An -X- _ O
NMT -X- _ B-TaskName
model -X- _ O
defines -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
over -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
hypotheses -X- _ O
Y -X- _ O
, -X- _ O
conditioned -X- _ O
on -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
x -X- _ O
, -X- _ O
where -X- _ O
θare -X- _ O
learned -X- _ O
parameters -X- _ O
. -X- _ O
A -X- _ O
translation -X- _ O
is -X- _ O
typically -X- _ O
predicted -X- _ O
usingMAP -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
formalized -X- _ O
as -X- _ O
ˆy= -X- _ O
arg -X- _ O
maxlogp -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
In -X- _ O
words -X- _ O
, -X- _ O
MAP -X- _ B-MethodName
decoding -X- _ I-MethodName
searches -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
probable -X- _ O
translation -X- _ O
under -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
, -X- _ O
i.e -X- _ O
. -X- _ O
, -X- _ O
the -X- _ O
mode -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
distribution -X- _ O
. -X- _ O
Finding -X- _ O
the -X- _ O
exact -X- _ O
ˆy -X- _ O
is -X- _ O
intractable -X- _ O
since -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
Yis -X- _ O
combinatorially -X- _ O
large -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
approximations -X- _ O
like -X- _ O
beam -X- _ O
search -X- _ O
( -X- _ O
Graves -X- _ O
, -X- _ O
2012 -X- _ O
; -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
are -X- _ O
used -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
degrades -X- _ O
for -X- _ O
large -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
beam -X- _ O
size -X- _ O
( -X- _ O
Koehn -X- _ O
and -X- _ O
Knowles -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Murray -X- _ O
and -X- _ O
Chiang -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Meister -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
empty -X- _ O
string -X- _ O
often -X- _ O
being -X- _ O
the -X- _ O
true -X- _ O
MAP -X- _ O
hypothesis -X- _ O
( -X- _ O
Stahlberg -X- _ O
and -X- _ O
Byrne -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
stochastic -X- _ O
alternative -X- _ O
to -X- _ O
beam -X- _ O
search -X- _ O
is -X- _ O
to -X- _ O
draw -X- _ O
samples -X- _ O
directly -X- _ O
from -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
with -X- _ O
ancestral -X- _ O
sampling -X- _ O
, -X- _ O
optionally -X- _ O
with -X- _ O
variants -X- _ O
that -X- _ O
truncate -X- _ O
this -X- _ O
distribution -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
top- -X- _ O
ksampling -X- _ O
( -X- _ O
Fan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
orp -X- _ O
- -X- _ O
nucleus -X- _ O
sampling -X- _ O
( -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
– -X- _ O
the -X- _ O
latter -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
smallest -X- _ O
set -X- _ O
of -X- _ O
words -X- _ O
whose -X- _ O
cumulative -X- _ O
probability -X- _ O
is -X- _ O
larger -X- _ O
than -X- _ O
a -X- _ O
predefined -X- _ O
value -X- _ O
p. -X- _ O
Deterministic -X- _ O
methods -X- _ O
combining -X- _ O
beam -X- _ O
and -X- _ O
nucleus -X- _ O
search -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
proposed -X- _ O
( -X- _ O
Shaham -X- _ O
and -X- _ O
Levy -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Unlike -X- _ O
beam -X- _ O
search -X- _ O
, -X- _ O
sampling -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
search -X- _ O
algorithm -X- _ O
nor -X- _ O
a -X- _ O
decision -X- _ O
rule -X- _ O
– -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
expected -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
sample -X- _ O
to -X- _ O
outperform -X- _ O
MAP -X- _ B-MethodName
decoding -X- _ I-MethodName
( -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
still -X- _ O
be -X- _ O
useful -X- _ O
for -X- _ O
alternative -X- _ O
decoding -X- _ O
methods -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
shall -X- _ O
see -X- _ O
. -X- _ O
While -X- _ O
beam -X- _ O
search -X- _ O
focus -X- _ O
on -X- _ O
high -X- _ O
probability -X- _ O
candidates -X- _ O
, -X- _ O
typically -X- _ O
similar -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
, -X- _ O
sampling -X- _ O
allows -X- _ O
for -X- _ O
more -X- _ O
exploration -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
higher -X- _ O
candidate -X- _ O
diversity -X- _ O
. -X- _ O
2.2 -X- _ O
Ranking -X- _ O
We -X- _ O
assume -X- _ O
access -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
¯Y -X- _ O
⊆ -X- _ O
Y -X- _ O
containing -X- _ O
N -X- _ O
candidate -X- _ O
translations -X- _ O
for -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
, -X- _ O
obtained -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
generation -X- _ O
procedures -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
2.1 -X- _ O
. -X- _ O
As -X- _ O
long -X- _ O
as -X- _ O
Nis -X- _ O
relatively -X- _ O
small -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
( -X- _ O
re- -X- _ O
) -X- _ O
rank -X- _ O
these -X- _ O
candidates -X- _ O
in -X- _ O
a -X- _ O
posthoc -X- _ O
manner -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
best -X- _ O
translation -X- _ O
maximizes -X- _ O
a -X- _ O
given -X- _ O
metric -X- _ O
of -X- _ O
interest -X- _ O
. -X- _ O
We -X- _ O
highlight -X- _ O
two -X- _ O
different -X- _ O
lines -X- _ O
of -X- _ O
work -X- _ O
for -X- _ O
ranking -X- _ O
in -X- _ O
MT -X- _ O
decoding -X- _ O
: -X- _ O
first -X- _ O
, -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
using -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
as -X- _ O
features -X- _ O
; -X- _ O
second -X- _ O
, -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
using -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
. -X- _ O
2.2.1 -X- _ O
N -X- _ O
- -X- _ O
best -X- _ O
Reranking -X- _ O
In -X- _ O
its -X- _ O
simplest -X- _ O
form -X- _ O
( -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
fixed -X- _ O
reranking -X- _ O
) -X- _ O
, -X- _ O
asingle -X- _ O
feature -X- _ O
fis -X- _ O
used -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
an -X- _ O
estimated -X- _ O
quality1397score -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
candidate -X- _ O
that -X- _ O
maximizes -X- _ O
this -X- _ O
score -X- _ O
is -X- _ O
picked -X- _ O
as -X- _ O
the -X- _ O
final -X- _ O
translation -X- _ O
, -X- _ O
ˆy= -X- _ O
arg -X- _ O
maxf -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
When -X- _ O
multiple -X- _ O
features -X- _ O
[ -X- _ O
f -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
f -X- _ O
] -X- _ O
are -X- _ O
available -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
tune -X- _ O
weights -X- _ O
[ -X- _ O
w -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
w -X- _ O
] -X- _ O
for -X- _ O
these -X- _ O
features -X- _ O
to -X- _ O
maximize -X- _ O
a -X- _ O
given -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
evaluation -X- _ O
metric -X- _ O
on -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
( -X- _ O
Och -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Duh -X- _ O
and -X- _ O
Kirchhoff -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
– -X- _ O
we -X- _ O
call -X- _ O
this -X- _ O
tuned -X- _ B-MethodName
reranking -X- _ I-MethodName
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
translation -X- _ O
is -X- _ O
ˆy= -X- _ O
arg -X- _ O
max -X- _ O
/ -X- _ O
summationtextwf -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
2.2.2 -X- _ O
Minimum -X- _ B-MethodName
Bayes -X- _ I-MethodName
Risk -X- _ I-MethodName
( -X- _ O
MBR -X- _ B-MethodName
) -X- _ O
Decoding -X- _ B-MethodName
While -X- _ O
the -X- _ O
techniques -X- _ O
above -X- _ O
rely -X- _ O
on -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
for -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
features -X- _ O
, -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
uses -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
to -X- _ O
rank -X- _ O
candidates -X- _ O
. -X- _ O
Unlike -X- _ O
MAP -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
which -X- _ O
searches -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
probable -X- _ O
translation -X- _ O
, -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
aims -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
translation -X- _ O
that -X- _ O
maximizes -X- _ O
the -X- _ O
expected -X- _ O
utility -X- _ O
( -X- _ O
equivalently -X- _ O
, -X- _ O
that -X- _ O
minimizes -X- _ O
risk -X- _ O
, -X- _ O
Kumar -X- _ O
and -X- _ O
Byrne -X- _ O
2002 -X- _ O
, -X- _ O
2004 -X- _ O
; -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Let -X- _ O
again -X- _ O
¯Y -X- _ O
⊆ -X- _ O
Y -X- _ O
be -X- _ O
a -X- _ O
set -X- _ O
containing -X- _ O
Nhypotheses -X- _ O
andu -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
a -X- _ O
utility -X- _ O
function -X- _ O
measuring -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
a -X- _ O
hypothesis -X- _ O
y∈ -X- _ O
Y -X- _ O
and -X- _ O
a -X- _ O
reference -X- _ O
y∈¯Y -X- _ O
( -X- _ O
e.g -X- _ O
, -X- _ O
an -X- _ O
automatic -X- _ O
evaluation -X- _ O
metric -X- _ O
such -X- _ O
as -X- _ O
BLEU -X- _ B-MetricName
or -X- _ O
COMET -X- _ B-MetricName
) -X- _ O
. -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
seeks -X- _ O
for -X- _ O
ˆy= -X- _ O
arg -X- _ O
maxE -X- _ O
[ -X- _ O
u -X- _ O
( -X- _ O
Y -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
] -X- _ O
/ -X- _ O
bracehtipupleft -X- _ O
/ -X- _ O
bracehtipdownright -X- _ O
/ -X- _ O
bracehtipdownleft -X- _ O
/ -X- _ O
bracehtipupright -X- _ O
≈ -X- _ O
/ -X- _ O
summationtextu -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
the -X- _ O
expectation -X- _ O
is -X- _ O
approximated -X- _ O
as -X- _ O
a -X- _ O
Monte -X- _ O
Carlo -X- _ O
( -X- _ O
MC -X- _ O
) -X- _ O
sum -X- _ O
using -X- _ O
model -X- _ O
samples -X- _ O
y -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y∼p -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
.In -X- _ O
practice -X- _ O
, -X- _ O
the -X- _ O
translation -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
expected -X- _ O
utility -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
by -X- _ O
comparing -X- _ O
each -X- _ O
hypothesis -X- _ O
y∈¯Yto -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
hypotheses -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
. -X- _ O
3 -X- _ O
Quality -X- _ B-MethodName
- -X- _ I-MethodName
Aware -X- _ I-MethodName
Decoding -X- _ I-MethodName
While -X- _ O
recent -X- _ O
works -X- _ O
have -X- _ O
explored -X- _ O
various -X- _ O
combinations -X- _ O
of -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
ranking -X- _ O
procedures -X- _ O
for -X- _ O
NMT -X- _ B-TaskName
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Bhattacharyya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Müller -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
they -X- _ O
suffer -X- _ O
from -X- _ O
two -X- _ O
limitations -X- _ O
: -X- _ O
•The -X- _ O
ranking -X- _ O
procedure -X- _ O
is -X- _ O
usually -X- _ O
based -X- _ O
on -X- _ O
simple -X- _ O
lexical -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
chrF -X- _ B-MetricName
, -X- _ O
METEOR -X- _ O
) -X- _ O
.Although -X- _ O
these -X- _ O
metrics -X- _ O
are -X- _ O
well -X- _ O
established -X- _ O
and -X- _ O
inexpensive -X- _ O
to -X- _ O
compute -X- _ O
, -X- _ O
they -X- _ O
correlate -X- _ O
poorly -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
at -X- _ O
segment -X- _ O
level -X- _ O
( -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021c -X- _ O
) -X- _ O
. -X- _ O
•Each -X- _ O
work -X- _ O
independently -X- _ O
explores -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
or -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
making -X- _ O
unclear -X- _ O
which -X- _ O
method -X- _ O
produces -X- _ O
better -X- _ O
translations -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
using -X- _ O
more -X- _ O
powerful -X- _ O
metrics -X- _ O
in -X- _ O
the -X- _ O
ranking -X- _ O
procedure -X- _ O
may -X- _ O
lead -X- _ O
to -X- _ O
better -X- _ O
quality -X- _ O
translations -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
unified -X- _ O
framework -X- _ O
for -X- _ O
ranking -X- _ O
with -X- _ O
both -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
( -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
and -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
, -X- _ O
independently -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
generation -X- _ O
procedure -X- _ O
. -X- _ O
We -X- _ O
explore -X- _ O
four -X- _ O
methods -X- _ O
with -X- _ O
different -X- _ O
computational -X- _ O
costs -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
number -X- _ O
of -X- _ O
candidates -X- _ O
, -X- _ O
N. -X- _ O
Fixed -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
Reranker -X- _ I-MethodName
. -X- _ O
AnN -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
using -X- _ O
a -X- _ O
single -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metric -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
Eq -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
The -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
this -X- _ O
ranker -X- _ O
is -X- _ O
O -X- _ O
( -X- _ O
N×C -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
Cdenotes -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
running -X- _ O
an -X- _ O
evaluation -X- _ O
with -X- _ O
a -X- _ O
metric -X- _ O
M. -X- _ O
Tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
Reranker -X- _ I-MethodName
. -X- _ O
AnN -X- _ O
- -X- _ O
best -X- _ O
reranker -X- _ O
using -X- _ O
as -X- _ O
features -X- _ O
allthe -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
logp -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
weights -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
3 -X- _ O
are -X- _ O
optimized -X- _ O
to -X- _ O
maximize -X- _ O
a -X- _ O
given -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
Musing -X- _ O
MERT -X- _ O
( -X- _ O
Och -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
coordinate -X- _ O
- -X- _ O
ascent -X- _ O
optimization -X- _ O
algorithm -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
Mis -X- _ O
used -X- _ O
for -X- _ O
tuning -X- _ O
only -X- _ O
; -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
, -X- _ O
only -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
are -X- _ O
used -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
decoding -X- _ O
cost -X- _ O
is -X- _ O
O -X- _ O
( -X- _ O
N× -X- _ O
/ -X- _ O
summationtextC -X- _ O
) -X- _ O
. -X- _ O
MBR -X- _ B-MethodName
Decoding -X- _ I-MethodName
. -X- _ O
Choosing -X- _ O
as -X- _ O
the -X- _ O
utility -X- _ O
function -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
M -X- _ O
( -X- _ O
§3.1 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
estimate -X- _ O
the -X- _ O
utility -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
Monte -X- _ O
Carlo -X- _ O
sum -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O
The -X- _ O
estimation -X- _ O
requires -X- _ O
computing -X- _ O
pairwise -X- _ O
comparisons -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
running -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
is -X- _ O
O -X- _ O
( -X- _ O
N×C -X- _ O
) -X- _ O
. -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
Reranker -X- _ I-MethodName
→MBR -X- _ B-MethodName
. -X- _ O
Using -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
in -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
is -X- _ O
expensive -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
quadratic -X- _ O
cost -X- _ O
. -X- _ O
To -X- _ O
circumvent -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
ranking -X- _ O
approach -X- _ O
: -X- _ O
we -X- _ O
first -X- _ O
rank -X- _ O
all -X- _ O
the -X- _ O
candidates -X- _ O
using -X- _ O
a -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
, -X- _ O
followed -X- _ O
by -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
using -X- _ O
the -X- _ O
top -X- _ O
Mcandidates -X- _ O
. -X- _ O
The -X- _ O
computational -X- _ O
cost -X- _ O
becomes -X- _ O
O -X- _ O
( -X- _ O
N× -X- _ O
/ -X- _ O
summationtextC+M×C -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
ranking -X- _ O
stage -X- _ O
prunes -X- _ O
the -X- _ O
candidate -X- _ O
list -X- _ O
to -X- _ O
a -X- _ O
smaller -X- _ O
, -X- _ O
higher -X- _ O
quality -X- _ O
subset -X- _ O
, -X- _ O
making -X- _ O
possible -X- _ O
a -X- _ O
more -X- _ O
accurate -X- _ O
estimation -X- _ O
of -X- _ O
the -X- _ O
utility -X- _ O
with -X- _ O
less -X- _ O
samples -X- _ O
, -X- _ O
and -X- _ O
potentially -X- _ O
allowing -X- _ O
a -X- _ O
better -X- _ O
ranker -X- _ O
than -X- _ O
plain -X- _ O
MBR -X- _ B-MethodName
for -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
computational -X- _ O
budget.13983.1 -X- _ O
Reference -X- _ O
- -X- _ O
based -X- _ O
Metrics -X- _ O
Reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
are -X- _ O
the -X- _ O
standard -X- _ O
way -X- _ O
to -X- _ O
evaluate -X- _ O
MT -X- _ O
systems -X- _ O
; -X- _ O
the -X- _ O
most -X- _ O
used -X- _ O
ones -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
lexical -X- _ O
overlap -X- _ O
between -X- _ O
hypotheses -X- _ O
and -X- _ O
reference -X- _ O
translations -X- _ O
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
; -X- _ O
Lavie -X- _ O
and -X- _ O
Denkowski -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Popovi -X- _ O
´ -X- _ O
c -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
lexical -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
have -X- _ O
important -X- _ O
limitations -X- _ O
: -X- _ O
they -X- _ O
have -X- _ O
difficulties -X- _ O
recognizing -X- _ O
correct -X- _ O
translations -X- _ O
that -X- _ O
are -X- _ O
paraphrases -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
; -X- _ O
they -X- _ O
ignore -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
, -X- _ O
an -X- _ O
important -X- _ O
indicator -X- _ O
of -X- _ O
meaning -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
; -X- _ O
and -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
always -X- _ O
correlate -X- _ O
well -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
, -X- _ O
particularly -X- _ O
at -X- _ O
segment -X- _ O
- -X- _ O
level -X- _ O
( -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021c -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
apart -X- _ O
from -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
computed -X- _ O
using -X- _ O
SacreBLEU -X- _ O
( -X- _ O
Post -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
and -X- _ O
chrF -X- _ B-MetricName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
trainable -X- _ O
referencebased -X- _ O
metrics -X- _ O
for -X- _ O
both -X- _ O
ranking -X- _ O
and -X- _ O
performance -X- _ O
evaluation -X- _ O
of -X- _ O
MT -X- _ B-TaskName
systems -X- _ O
: -X- _ O
•BLEURT -X- _ B-MetricName
( -X- _ O
Sellam -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Pu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
to -X- _ O
regress -X- _ O
on -X- _ O
human -X- _ O
direct -X- _ O
assessments -X- _ O
( -X- _ O
DA -X- _ O
; -X- _ O
Graham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
largest -X- _ O
multilingual -X- _ O
version -X- _ O
, -X- _ O
BLEURT-20 -X- _ B-MetricName
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
RemBERT -X- _ O
model -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
•COMET -X- _ B-MetricName
( -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
to -X- _ O
regress -X- _ O
on -X- _ O
quality -X- _ O
assessments -X- _ O
such -X- _ O
as -X- _ O
DA -X- _ O
using -X- _ O
both -X- _ O
the -X- _ O
reference -X- _ O
and -X- _ O
the -X- _ O
source -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
translation -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
model -X- _ O
developed -X- _ O
for -X- _ O
the -X- _ O
WMT20 -X- _ O
metrics -X- _ O
shared -X- _ O
task -X- _ O
( -X- _ O
wmt20 -X- _ O
- -X- _ O
comet -X- _ O
- -X- _ O
da -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
metrics -X- _ O
have -X- _ O
shown -X- _ O
much -X- _ O
better -X- _ O
correlation -X- _ O
at -X- _ O
segment -X- _ O
- -X- _ O
level -X- _ O
than -X- _ O
previous -X- _ O
lexical -X- _ O
metrics -X- _ O
in -X- _ O
WMT -X- _ O
metrics -X- _ O
shared -X- _ O
tasks -X- _ O
( -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
; -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021c -X- _ O
) -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
2.2 -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
good -X- _ O
candidates -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
either -X- _ O
indirectly -X- _ O
as -X- _ O
an -X- _ O
optimization -X- _ O
objective -X- _ O
for -X- _ O
learning -X- _ O
the -X- _ O
tuned -X- _ O
reranker -X- _ O
’s -X- _ O
feature -X- _ O
weights -X- _ O
, -X- _ O
or -X- _ O
directly -X- _ O
as -X- _ O
a -X- _ O
utility -X- _ O
function -X- _ O
in -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
former -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
the -X- _ O
metric -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgment -X- _ O
, -X- _ O
the -X- _ O
better -X- _ O
the -X- _ O
translation -X- _ O
picked -X- _ O
by -X- _ O
the -X- _ O
tuned -X- _ O
reranker -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
latter -X- _ O
, -X- _ O
we -X- _ O
approximate -X- _ O
the -X- _ O
expected -X- _ O
utility -X- _ O
in -X- _ O
Eq -X- _ O
. -X- _ O
4 -X- _ O
by -X- _ O
letting -X- _ O
a -X- _ O
candidate -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
be -X- _ O
a -X- _ O
reference -X- _ O
translation -X- _ O
– -X- _ O
a -X- _ O
suitable -X- _ O
premise -X- _ O
ifthe -X- _ O
model -X- _ O
is -X- _ O
good -X- _ O
in -X- _ O
expectation -X- _ O
. -X- _ O
3.2 -X- _ O
Reference -X- _ O
- -X- _ O
free -X- _ O
Metrics -X- _ O
MT -X- _ O
evaluation -X- _ O
metrics -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
developed -X- _ O
for -X- _ O
the -X- _ O
case -X- _ O
where -X- _ O
references -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
– -X- _ O
they -X- _ O
are -X- _ O
called -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
orquality -X- _ O
estimation -X- _ O
( -X- _ O
QE -X- _ O
) -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
last -X- _ O
years -X- _ O
, -X- _ O
considerable -X- _ O
improvements -X- _ O
have -X- _ O
been -X- _ O
made -X- _ O
to -X- _ O
such -X- _ O
metrics -X- _ O
, -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
having -X- _ O
increasing -X- _ O
correlations -X- _ O
with -X- _ O
human -X- _ O
annotators -X- _ O
( -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021c -X- _ O
; -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
improvements -X- _ O
enable -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
such -X- _ O
models -X- _ O
for -X- _ O
ranking -X- _ O
translation -X- _ O
hypotheses -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
reliable -X- _ O
way -X- _ O
than -X- _ O
before -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
four -X- _ O
recently -X- _ O
proposed -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
as -X- _ O
features -X- _ O
for -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
all -X- _ O
at -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
: -X- _ O
•COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
( -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
version -X- _ O
of -X- _ O
COMET -X- _ B-MetricName
( -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
was -X- _ O
the -X- _ O
winning -X- _ O
submission -X- _ O
for -X- _ O
the -X- _ O
QE -X- _ O
- -X- _ O
as -X- _ O
- -X- _ O
a -X- _ O
- -X- _ O
metric -X- _ O
subtask -X- _ O
of -X- _ O
the -X- _ O
WMT20 -X- _ O
shared -X- _ O
task -X- _ O
( -X- _ O
Mathur -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
•TransQuest -X- _ B-MetricName
( -X- _ O
Ranasinghe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
winning -X- _ O
submission -X- _ O
for -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
DA -X- _ O
prediction -X- _ O
subtask -X- _ O
of -X- _ O
the -X- _ O
WMT20 -X- _ O
QE -X- _ O
shared -X- _ O
task -X- _ O
( -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Similarly -X- _ O
to -X- _ O
COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
this -X- _ O
metric -X- _ O
predicts -X- _ O
a -X- _ O
DA -X- _ O
score -X- _ O
. -X- _ O
•MBART -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
( -X- _ O
Zerva -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
mBART -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
model -X- _ O
, -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
both -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
the -X- _ O
variance -X- _ O
of -X- _ O
DA -X- _ O
scores -X- _ O
. -X- _ O
It -X- _ O
was -X- _ O
a -X- _ O
top -X- _ O
performer -X- _ O
in -X- _ O
the -X- _ O
WMT21 -X- _ O
QE -X- _ O
shared -X- _ O
task -X- _ O
( -X- _ O
Specia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
• -X- _ O
OpenKiwi -X- _ B-MetricName
- -X- _ I-MetricName
MQM -X- _ I-MetricName
( -X- _ O
Kepler -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
XLM -X- _ O
- -X- _ O
R -X- _ O
, -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
multidimensional -X- _ O
quality -X- _ O
metric -X- _ O
( -X- _ O
MQM -X- _ O
; -X- _ O
Lommel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2014 -X- _ O
) -X- _ O
.This -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metric -X- _ O
was -X- _ O
ranked -X- _ O
second -X- _ O
on -X- _ O
the -X- _ O
QE -X- _ O
- -X- _ O
as -X- _ O
- -X- _ O
a -X- _ O
- -X- _ O
metric -X- _ O
subtask -X- _ O
from -X- _ O
the -X- _ O
WMT -X- _ O
2021 -X- _ O
metrics -X- _ O
shared -X- _ O
task -X- _ O
. -X- _ O
4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Setup -X- _ O
We -X- _ O
study -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
over -X- _ O
MAP -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
decoding -X- _ I-MethodName
in -X- _ O
two -X- _ O
regimes -X- _ O
: -X- _ O
•A -X- _ O
high -X- _ O
- -X- _ O
resource -X- _ O
, -X- _ O
unconstrained -X- _ O
, -X- _ O
setting -X- _ O
with -X- _ O
large -X- _ O
transformer -X- _ O
models -X- _ O
( -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
16 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
1024 -X- _ B-HyperparameterValue
embedding -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
8192 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
) -X- _ O
trained -X- _ O
by -X- _ O
Ng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
WMT19 -X- _ O
news -X- _ O
translation -X- _ O
task -X- _ O
( -X- _ O
Barrault -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
using -X- _ O
English -X- _ O
to -X- _ O
German -X- _ O
( -X- _ O
EN→DE -X- _ O
) -X- _ O
and -X- _ O
English -X- _ O
to -X- _ O
Russian -X- _ O
( -X- _ O
EN→RU -X- _ O
) -X- _ O
language -X- _ O
pairs -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
on1399 -X- _ O
over -X- _ O
20 -X- _ O
million -X- _ O
parallel -X- _ O
and -X- _ O
100 -X- _ O
million -X- _ O
backtranslated -X- _ O
sentences -X- _ O
, -X- _ O
being -X- _ O
the -X- _ O
winning -X- _ O
submissions -X- _ O
of -X- _ O
that -X- _ O
year -X- _ O
’s -X- _ O
shared -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
ensembled -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
use -X- _ O
newstest19 -X- _ B-DatasetName
for -X- _ O
validation -X- _ O
and -X- _ O
newstest20 -X- _ B-DatasetName
for -X- _ O
testing -X- _ O
. -X- _ O
•A -X- _ O
more -X- _ O
constrained -X- _ O
scenario -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
transformer -X- _ O
model -X- _ O
( -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
4 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
512 -X- _ B-HyperparameterValue
embedding -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
1024 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
) -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
in -X- _ O
Fairseq -X- _ O
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
smaller -X- _ O
IWSLT17 -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
Cettolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
for -X- _ O
English -X- _ O
to -X- _ O
German -X- _ O
( -X- _ O
EN→DE -X- _ O
) -X- _ O
and -X- _ O
English -X- _ O
to -X- _ O
French -X- _ O
( -X- _ O
EN→FR -X- _ O
) -X- _ O
, -X- _ O
each -X- _ O
with -X- _ O
a -X- _ O
little -X- _ O
over -X- _ O
200k -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O
We -X- _ O
chose -X- _ O
these -X- _ O
datasets -X- _ O
because -X- _ O
they -X- _ O
have -X- _ O
been -X- _ O
extensively -X- _ O
used -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Bhattacharyya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
smaller -X- _ O
model -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
about -X- _ O
how -X- _ O
the -X- _ O
training -X- _ O
methodology -X- _ O
affects -X- _ O
ranking -X- _ O
performance -X- _ O
( -X- _ O
see -X- _ O
§ -X- _ O
4.2.2 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
training -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
We -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
5 -X- _ B-HyperparameterValue
as -X- _ O
our -X- _ O
decoding -X- _ O
baseline -X- _ O
because -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
it -X- _ O
resulted -X- _ O
in -X- _ O
better -X- _ O
or -X- _ O
similar -X- _ O
translations -X- _ O
than -X- _ O
larger -X- _ O
beam -X- _ O
sizes -X- _ O
. -X- _ O
For -X- _ O
tuned -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
Travatar -X- _ O
’s -X- _ O
( -X- _ O
Neubig -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
implementation -X- _ O
of -X- _ O
MERT -X- _ O
( -X- _ O
Och -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
weight -X- _ O
of -X- _ O
each -X- _ O
feature -X- _ O
, -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
each -X- _ O
system -X- _ O
using -X- _ O
the -X- _ O
metrics -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
3.1 -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
chrF -X- _ B-MetricName
( -X- _ O
Popovi -X- _ O
´ -X- _ O
c -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
4.2 -X- _ O
Results -X- _ O
Overall -X- _ O
, -X- _ O
given -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
, -X- _ O
candidate -X- _ O
generation -X- _ O
, -X- _ O
and -X- _ O
ranking -X- _ O
procedures -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
over -X- _ O
150 -X- _ O
systems -X- _ O
per -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
subsets -X- _ O
of -X- _ O
this -X- _ O
data -X- _ O
separately -X- _ O
to -X- _ O
answer -X- _ O
specific -X- _ O
research -X- _ O
questions -X- _ O
, -X- _ O
and -X- _ O
defer -X- _ O
to -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
additional -X- _ O
results.4.2.1 -X- _ O
Impact -X- _ O
of -X- _ O
Candidate -X- _ O
Generation -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
generation -X- _ O
procedure -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidates -X- _ O
. -X- _ O
Which -X- _ O
candidate -X- _ O
generation -X- _ O
method -X- _ O
works -X- _ O
best -X- _ O
, -X- _ O
beam -X- _ O
search -X- _ O
or -X- _ O
sampling -X- _ O
? -X- _ O
We -X- _ O
generate -X- _ O
candidates -X- _ O
with -X- _ O
beam -X- _ O
search -X- _ O
, -X- _ O
vanilla -X- _ O
sampling -X- _ O
, -X- _ O
and -X- _ O
nucleus -X- _ O
sampling -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
latter -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
p= -X- _ B-HyperparameterName
0.6 -X- _ B-HyperparameterValue
based -X- _ O
on -X- _ O
early -X- _ O
results -X- _ O
showing -X- _ O
improved -X- _ O
performance -X- _ O
for -X- _ O
all -X- _ O
metrics -X- _ O
. -X- _ O
ForN -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
up -X- _ O
to -X- _ O
200 -X- _ B-HyperparameterValue
samples -X- _ B-HyperparameterName
; -X- _ O
for -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
quadratic -X- _ O
computational -X- _ O
cost -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
up -X- _ O
to -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
COMET -X- _ B-MetricName
for -X- _ O
different -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
ranking -X- _ O
methods -X- _ O
for -X- _ O
theEN→DEWMT20 -X- _ B-DatasetName
and -X- _ O
IWSLT17 -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
with -X- _ O
increasing -X- _ O
number -X- _ O
of -X- _ O
candidates -X- _ O
. -X- _ O
The -X- _ O
baseline -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
the -X- _ O
dashed -X- _ O
line -X- _ O
. -X- _ O
To -X- _ O
assess -X- _ O
the -X- _ O
performance -X- _ O
ceiling -X- _ O
of -X- _ O
the -X- _ O
rankers -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
results -X- _ O
with -X- _ O
an -X- _ O
oracle -X- _ O
ranker -X- _ O
for -X- _ O
the -X- _ O
reported -X- _ O
metrics -X- _ O
, -X- _ O
picking -X- _ O
the -X- _ O
candidate -X- _ O
that -X- _ O
maximizes -X- _ O
it -X- _ O
. -X- _ O
For -X- _ O
thefixed -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
as -X- _ O
a -X- _ O
metric -X- _ O
, -X- _ O
albeit -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
other -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
are -X- _ O
similar -X- _ O
. -X- _ O
Performance -X- _ O
seems -X- _ O
to -X- _ O
scale -X- _ O
well -X- _ O
with -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
candidates -X- _ O
, -X- _ O
particularly -X- _ O
for -X- _ O
vanilla -X- _ O
sampling -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
and -X- _ O
MBR -X- _ B-MethodName
decoder -X- _ I-MethodName
. -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Müller -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
rankers -X- _ O
using -X- _ O
vanilla -X- _ O
sampling -X- _ O
severely -X- _ O
under -X- _ O
- -X- _ O
perform -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
( -X- _ O
see -X- _ O
also -X- _ O
§ -X- _ O
4.2.2 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
rankers -X- _ O
using -X- _ O
beam -X- _ O
search -X- _ O
or -X- _ O
nucleus -X- _ O
sampling -X- _ O
are -X- _ O
competitive -X- _ O
or -X- _ O
outperform -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
and -X- _ O
greatly -X- _ O
outperform -X- _ O
it -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
COMET -X- _ B-MetricName
. -X- _ O
For -X- _ O
the -X- _ O
larger -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
lexical -X- _ O
metrics -X- _ O
degrades -X- _ O
with -X- _ O
more -X- _ O
candidates -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
scenario -X- _ O
, -X- _ O
rankers -X- _ O
us-1400 -X- _ O
ing -X- _ O
nucleus -X- _ O
sampling -X- _ O
seem -X- _ O
to -X- _ O
have -X- _ O
an -X- _ O
edge -X- _ O
over -X- _ O
the -X- _ O
ones -X- _ O
that -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
for -X- _ O
COMET -X- _ B-MetricName
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
findings -X- _ O
above -X- _ O
, -X- _ O
and -X- _ O
due -X- _ O
to -X- _ O
generally -X- _ O
better -X- _ O
performance -X- _ O
of -X- _ O
COMET -X- _ B-MetricName
over -X- _ O
BLEU -X- _ B-MetricName
for -X- _ O
MT -X- _ O
evaluation -X- _ O
( -X- _ O
Kocmi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
following -X- _ O
experiments -X- _ O
we -X- _ O
use -X- _ O
nucleus -X- _ O
sampling -X- _ O
with -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
and -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
the -X- _ O
small -X- _ O
model -X- _ O
. -X- _ O
4.2.2 -X- _ O
Impact -X- _ O
of -X- _ O
Label -X- _ O
Smoothing -X- _ O
How -X- _ O
does -X- _ O
label -X- _ O
smoothing -X- _ O
affect -X- _ O
candidate -X- _ O
generation -X- _ O
? -X- _ O
Label -X- _ O
smoothing -X- _ O
( -X- _ O
Szegedy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
regularization -X- _ O
technique -X- _ O
that -X- _ O
redistributes -X- _ O
probability -X- _ O
mass -X- _ O
from -X- _ O
the -X- _ O
gold -X- _ O
label -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
target -X- _ O
labels -X- _ O
, -X- _ O
typically -X- _ O
preventing -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
becoming -X- _ O
overconfident -X- _ O
( -X- _ O
Müller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
found -X- _ O
that -X- _ O
label -X- _ O
smoothing -X- _ O
negatively -X- _ O
impacts -X- _ O
model -X- _ O
fit -X- _ O
, -X- _ O
compromising -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
( -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
small -X- _ O
transformer -X- _ O
model -X- _ O
without -X- _ O
label -X- _ O
smoothing -X- _ O
to -X- _ O
verify -X- _ O
its -X- _ O
impact -X- _ O
in -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
and -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
disabling -X- _ O
label -X- _ O
smoothing -X- _ O
really -X- _ O
helps -X- _ O
when -X- _ O
generating -X- _ O
candidates -X- _ O
using -X- _ O
vanilla -X- _ O
sampling -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
degrades -X- _ O
for -X- _ O
candidates -X- _ O
generated -X- _ O
using -X- _ O
nucleus -X- _ O
sampling -X- _ O
when -X- _ O
we -X- _ O
disable -X- _ O
label -X- _ O
smoothing -X- _ O
, -X- _ O
hinting -X- _ O
that -X- _ O
the -X- _ O
pruning -X- _ O
mechanism -X- _ O
of -X- _ O
nucleus -X- _ O
sampling -X- _ O
may -X- _ O
help -X- _ O
mitigate -X- _ O
the -X- _ O
negative -X- _ O
impact -X- _ O
of -X- _ O
label -X- _ O
smoothing -X- _ O
in -X- _ O
sampling -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O
Even -X- _ O
without -X- _ O
label -X- _ O
smoothing -X- _ O
, -X- _ O
vanilla -X- _ O
sampling -X- _ O
is -X- _ O
not -X- _ O
competitive -X- _ O
with -X- _ O
nucleus -X- _ O
sampling -X- _ O
or -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
label -X- _ O
smoothing -X- _ O
, -X- _ O
thus -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
experiment -X- _ O
further -X- _ O
with -X- _ O
it -X- _ O
. -X- _ O
4.2.3 -X- _ O
Impact -X- _ O
of -X- _ O
Ranking -X- _ O
and -X- _ O
Metrics -X- _ O
We -X- _ O
now -X- _ O
investigate -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
the -X- _ O
metrics -X- _ O
presented -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
as -X- _ O
features -X- _ O
and -X- _ O
objectives -X- _ O
for -X- _ O
ranking -X- _ O
. -X- _ O
For -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
all -X- _ O
the -X- _ O
available -X- _ O
candidates -X- _ B-HyperparameterName
( -X- _ O
200 -X- _ B-HyperparameterValue
) -X- _ O
while -X- _ O
, -X- _ O
for -X- _ O
MBR -X- _ B-MethodName
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
computational -X- _ O
cost -X- _ O
of -X- _ O
using -X- _ O
100 -X- _ B-HyperparameterValue
candidates -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
with -X- _ O
50 -X- _ B-HyperparameterValue
candidates -X- _ B-HyperparameterName
only -X- _ O
( -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
ranking -X- _ O
with -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
with -X- _ O
N= -X- _ B-HyperparameterName
100 -X- _ B-HyperparameterValue
and -X- _ O
MBR -X- _ B-MethodName
with -X- _ O
N= -X- _ B-HyperparameterName
50 -X- _ B-HyperparameterValue
takes -X- _ O
about -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
answersome -X- _ O
specific -X- _ O
research -X- _ O
questions -X- _ O
. -X- _ O
Which -X- _ O
QE -X- _ O
metric -X- _ O
works -X- _ O
best -X- _ O
in -X- _ O
a -X- _ O
fixed -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
? -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
fixed -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
with -X- _ O
a -X- _ O
single -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metric -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
second -X- _ O
group -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
metrics -X- _ O
allows -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
baseline -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
lexical -X- _ O
metrics -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
chrF -X- _ B-MetricName
) -X- _ O
, -X- _ O
rerankers -X- _ O
using -X- _ O
COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
or -X- _ O
MBART -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
outperform -X- _ O
the -X- _ O
baseline -X- _ O
according -X- _ O
to -X- _ O
BLEURT -X- _ B-MetricName
and -X- _ O
COMET -X- _ B-MetricName
, -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
large -X- _ O
andsmall -X- _ O
models -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
aforementioned -X- _ O
better -X- _ O
performance -X- _ O
of -X- _ O
these -X- _ O
metrics -X- _ O
for -X- _ O
translation -X- _ O
quality -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
these -X- _ O
rankers -X- _ O
produce -X- _ O
better -X- _ O
translations -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
sharp -X- _ O
drop -X- _ O
in -X- _ O
the -X- _ O
lexical -X- _ O
metrics -X- _ O
is -X- _ O
concerning -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
verify -X- _ O
this -X- _ O
hypothesis -X- _ O
in -X- _ O
a -X- _ O
human -X- _ O
study -X- _ O
, -X- _ O
in -X- _ O
§ -X- _ O
4.2.4 -X- _ O
. -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
vary -X- _ O
when -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
optimization -X- _ O
objective -X- _ O
? -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
using -X- _ O
as -X- _ O
features -X- _ O
allthe -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
metrics -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
, -X- _ O
and -X- _ O
optimized -X- _ O
using -X- _ O
MERT -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
( -X- _ O
3 -X- _ O
group -X- _ O
) -X- _ O
shows -X- _ O
results -X- _ O
for -X- _ O
EN→DE -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
small -X- _ O
model -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
rankers -X- _ O
show -X- _ O
improved -X- _ O
results -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
optimizing -X- _ O
for -X- _ O
BLEU -X- _ B-MetricName
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
lexical -X- _ O
metrics -X- _ O
, -X- _ O
while -X- _ O
optimizing -X- _ O
for -X- _ O
BLEURT -X- _ B-MetricName
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
optimizing -X- _ O
for -X- _ O
COMET -X- _ B-MetricName
leads -X- _ O
to -X- _ O
similar -X- _ O
performance -X- _ O
than -X- _ O
optimizing -X- _ O
for -X- _ O
BLEURT -X- _ B-MetricName
. -X- _ O
For -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
, -X- _ O
although -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
rerankers -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
outperform -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
the -X- _ O
lexical -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
similar -X- _ O
trends -X- _ O
as -X- _ O
before -X- _ O
for -X- _ O
BLEURT -X- _ B-MetricName
and -X- _ O
COMET -X- _ B-MetricName
. -X- _ O
How -X- _ O
does -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
vary -X- _ O
when -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
utility -X- _ O
function -X- _ O
? -X- _ O
Table -X- _ O
1 -X- _ O
( -X- _ O
4group -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
utility -X- _ O
function -X- _ O
( -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
BLEURT -X- _ B-MetricName
, -X- _ O
or -X- _ O
COMET -X- _ B-MetricName
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
small -X- _ O
model -X- _ O
, -X- _ O
using -X- _ O
COMET -X- _ B-MetricName
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
according -X- _ O
to -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
except -X- _ O
BLEURT -X- _ B-MetricName
( -X- _ O
for -X- _ O
which -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
is -X- _ O
attained -X- _ O
when -X- _ O
optimizing -X- _ O
itself -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
metric -X- _ O
is -X- _ O
obtained -X- _ O
when -X- _ O
using -X- _ O
that -X- _ O
metric -X- _ O
as -X- _ O
the -X- _ O
utility -X- _ O
function -X- _ O
. -X- _ O
How -X- _ O
do -X- _ O
( -X- _ O
tuned -X- _ B-MethodName
) -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
and -X- _ O
MBR -X- _ B-MethodName
compare -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
? -X- _ O
Looking -X- _ O
at -X- _ O
Table -X- _ O
1 -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
small -X- _ O
model -X- _ O
, -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
seems -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
in -X- _ O
all -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
one -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
utility -X- _ O
function -X- _ O
in -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
The -X- _ O
picture -X- _ O
is -X- _ O
less -X- _ O
clear -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
, -X- _ O
with -X- _ O
MBR -X- _ B-MethodName
decoding1401 -X- _ I-MethodName
achieving -X- _ O
best -X- _ O
values -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
metric -X- _ O
when -X- _ O
using -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
utility -X- _ O
; -X- _ O
this -X- _ O
comes -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
worse -X- _ O
performance -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
metrics -X- _ O
, -X- _ O
hinting -X- _ O
at -X- _ O
a -X- _ O
potential -X- _ O
“ -X- _ O
overfitting -X- _ O
” -X- _ O
effect -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
seems -X- _ O
to -X- _ O
have -X- _ O
an -X- _ O
edge -X- _ O
over -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
We -X- _ O
will -X- _ O
further -X- _ O
clarify -X- _ O
this -X- _ O
question -X- _ O
with -X- _ O
human -X- _ O
evaluation -X- _ O
in -X- _ O
§ -X- _ O
4.2.4 -X- _ O
. -X- _ O
Can -X- _ O
we -X- _ O
improve -X- _ O
performance -X- _ O
by -X- _ O
combining -X- _ O
Nbest -X- _ B-MethodName
reranking -X- _ I-MethodName
with -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
? -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
that -X- _ O
, -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
large -X- _ O
and -X- _ O
the -X- _ O
small -X- _ O
model -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
ranking -X- _ O
approach -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
leads -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
metrics -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
is -X- _ O
obtained -X- _ O
when -X- _ O
the -X- _ O
utility -X- _ O
function -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
a -X- _ O
promising -X- _ O
research -X- _ O
direction -X- _ O
is -X- _ O
to -X- _ O
seek -X- _ O
more -X- _ O
sophisticated -X- _ O
pruning -X- _ O
strategies -X- _ O
for -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
. -X- _ O
4.2.4 -X- _ O
Human -X- _ O
Evaluation -X- _ O
Which -X- _ O
metric -X- _ O
correlates -X- _ O
more -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
? -X- _ O
How -X- _ O
risky -X- _ O
is -X- _ O
it -X- _ O
to -X- _ O
optimize -X- _ O
a -X- _ O
metric -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
a -X- _ O
related -X- _ O
metric -X- _ O
? -X- _ O
Our -X- _ O
experiments -X- _ O
suggest -X- _ O
that -X- _ O
, -X- _ O
overall -X- _ O
, -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
produces -X- _ O
translations -X- _ O
with -X- _ O
better -X- _ O
performance -X- _ O
across -X- _ O
most -X- _ O
metrics -X- _ O
than -X- _ O
MAP -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
decoding -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
some -X- _ O
cases -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
fixed -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
and -X- _ O
most -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
concerning -X- _ O
“ -X- _ O
metric -X- _ O
gap -X- _ O
” -X- _ O
between -X- _ O
lexical -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
metrics -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
latter -X- _ O
have -X- _ O
shown -X- _ O
to -X- _ O
correlate -X- _ O
better -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
, -X- _ O
previous -X- _ O
work -X- _ O
has -X- _ O
not -X- _ O
attempted -X- _ O
to -X- _ O
explicitly -X- _ O
optimize -X- _ O
these -X- _ O
metrics -X- _ O
, -X- _ O
and -X- _ O
doing -X- _ O
so -X- _ O
could -X- _ O
lead -X- _ O
to -X- _ O
ranking -X- _ O
systemsthat -X- _ O
learn -X- _ O
to -X- _ O
exploit -X- _ O
“ -X- _ O
pathologies -X- _ O
” -X- _ O
in -X- _ O
these -X- _ O
metrics -X- _ O
rather -X- _ O
than -X- _ O
improving -X- _ O
translation -X- _ O
quality -X- _ O
. -X- _ O
To -X- _ O
investigate -X- _ O
this -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
human -X- _ O
study -X- _ O
across -X- _ O
all -X- _ O
four -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
ask -X- _ O
annotators -X- _ O
to -X- _ O
rate -X- _ O
, -X- _ O
from -X- _ O
1 -X- _ O
( -X- _ O
no -X- _ O
overlap -X- _ O
in -X- _ O
meaning -X- _ O
) -X- _ O
to -X- _ O
5 -X- _ O
( -X- _ O
perfect -X- _ O
translation -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
translations -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
4 -X- _ O
ranking -X- _ O
systems -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
baseline -X- _ O
translation -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
. -X- _ O
Further -X- _ O
details -X- _ O
are -X- _ O
in -X- _ O
App -X- _ O
. -X- _ O
C. -X- _ O
We -X- _ O
choose -X- _ O
COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
as -X- _ O
the -X- _ O
feature -X- _ O
for -X- _ O
the -X- _ O
fixed -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
ranker -X- _ I-MethodName
and -X- _ O
COMET -X- _ B-MetricName
as -X- _ O
the -X- _ O
optimization -X- _ O
metric -X- _ O
and -X- _ O
utility -X- _ O
function -X- _ O
for -X- _ O
the -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
and -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
reasons -X- _ O
for -X- _ O
this -X- _ O
are -X- _ O
two -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
they -X- _ O
are -X- _ O
currently -X- _ O
the -X- _ O
reference -X- _ O
- -X- _ O
free -X- _ O
and -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
with -X- _ O
highest -X- _ O
reported -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
( -X- _ O
Kocmi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
saw -X- _ O
the -X- _ O
largest -X- _ O
“ -X- _ O
metric -X- _ O
gap -X- _ O
” -X- _ O
for -X- _ O
systems -X- _ O
based -X- _ O
on -X- _ O
these -X- _ O
metrics -X- _ O
, -X- _ O
hinting -X- _ O
of -X- _ O
a -X- _ O
potential -X- _ O
“ -X- _ O
overfitting -X- _ O
” -X- _ O
problem -X- _ O
( -X- _ O
specially -X- _ O
since -X- _ O
COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
and -X- _ O
COMET -X- _ B-MetricName
are -X- _ O
similar -X- _ O
models -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
automatic -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
that -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
T -X- _ B-MethodName
- -X- _ I-MethodName
RR -X- _ I-MethodName
w -X- _ I-MethodName
/ -X- _ I-MethodName
COMET -X- _ I-MethodName
, -X- _ O
when -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
metrics -X- _ O
are -X- _ O
explicitly -X- _ O
optimized -X- _ O
for -X- _ O
, -X- _ O
their -X- _ O
correlation -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
decreases -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
no -X- _ O
longer -X- _ O
reliable -X- _ O
indicators -X- _ O
of -X- _ O
systemlevel -X- _ O
ranking -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
notable -X- _ O
for -X- _ O
the -X- _ O
fixed -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranker -X- _ I-MethodName
with -X- _ O
COMET -X- _ B-MetricName
- -X- _ I-MetricName
QE -X- _ I-MetricName
, -X- _ O
which -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
COMET -X- _ B-MetricName
for -X- _ O
every -X- _ O
single -X- _ O
scenario -X- _ O
, -X- _ O
but -X- _ O
leads -X- _ O
to -X- _ O
markedly -X- _ O
lower -X- _ O
quality -X- _ O
translations -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
despite -X- _ O
the -X- _ O
potential -X- _ O
for -X- _ O
overfitting -X- _ O
these -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
tuned -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
, -X- _ O
MBR -X- _ B-MethodName
, -X- _ O
and -X- _ O
their -X- _ O
combination -X- _ O
consistently -X- _ O
achieve -X- _ O
better1402 -X- _ O
translation -X- _ O
quality -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
specially -X- _ O
with -X- _ O
the -X- _ O
small -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
reranking -X- _ I-MethodName
results -X- _ O
in -X- _ O
better -X- _ O
translations -X- _ O
than -X- _ O
MBR -X- _ B-MethodName
, -X- _ O
and -X- _ O
their -X- _ O
combination -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
system -X- _ O
in -X- _ O
2 -X- _ O
of -X- _ O
4 -X- _ O
LPs -X- _ O
. -X- _ O
4.2.5 -X- _ O
Improved -X- _ O
Human -X- _ O
Evaluation -X- _ O
To -X- _ O
further -X- _ O
investigate -X- _ O
how -X- _ O
quality -X- _ O
- -X- _ O
aware -X- _ O
decoding -X- _ O
performs -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
MAP -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
decoding -X- _ I-MethodName
, -X- _ O
we -X- _ O
perform -X- _ O
another -X- _ O
human -X- _ O
study -X- _ O
, -X- _ O
this -X- _ O
time -X- _ O
based -X- _ O
on -X- _ O
expert -X- _ O
- -X- _ O
level -X- _ O
multidimensional -X- _ B-MetricName
quality -X- _ I-MetricName
metrics -X- _ I-MetricName
( -X- _ O
MQM -X- _ B-MetricName
) -X- _ O
annotations -X- _ O
( -X- _ O
Lommel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
asked -X- _ O
the -X- _ O
annotators -X- _ O
to -X- _ O
identify -X- _ O
all -X- _ O
errors -X- _ O
and -X- _ O
independently -X- _ O
label -X- _ O
them -X- _ O
with -X- _ O
an -X- _ O
error -X- _ O
category -X- _ O
( -X- _ O
accuracy -X- _ B-MetricName
, -X- _ O
fluency -X- _ B-MetricName
, -X- _ O
and -X- _ O
style -X- _ B-MetricName
, -X- _ O
each -X- _ O
with -X- _ O
a -X- _ O
specific -X- _ O
set -X- _ O
of -X- _ O
subcategories -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
severity -X- _ B-MetricName
level -X- _ I-MetricName
( -X- _ O
minor -X- _ O
, -X- _ O
major -X- _ O
, -X- _ O
andcritical -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
sentencelevel -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
require -X- _ O
a -X- _ O
weighting -X- _ O
scheme -X- _ O
on -X- _ O
error -X- _ O
severities -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
weights -X- _ B-HyperparameterName
of -X- _ O
1,5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
tominor -X- _ O
, -X- _ O
major -X- _ O
, -X- _ O
and -X- _ O
critical -X- _ O
errors -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
independently -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
category -X- _ O
. -X- _ O
Further -X- _ O
details -X- _ O
are -X- _ O
in -X- _ O
App -X- _ O
. -X- _ O
D. -X- _ O
Given -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
performing -X- _ O
a -X- _ O
human -X- _ O
study -X- _ O
like -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
restrict -X- _ O
our -X- _ O
analysis -X- _ O
to -X- _ O
the -X- _ O
translations -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
large -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
WMT20 -X- _ O
( -X- _ O
EN -X- _ O
→DE -X- _ O
and -X- _ O
EN -X- _ O
→RU -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
human -X- _ O
evaluation -X- _ O
using -X- _ O
MQM -X- _ O
annotations -X- _ O
, -X- _ O
including -X- _ O
both -X- _ O
error -X- _ O
severity -X- _ O
counts -X- _ O
and -X- _ O
final -X- _ O
MQM -X- _ B-MetricName
scores -X- _ O
. -X- _ O
As -X- _ O
hinted -X- _ O
in -X- _ O
§ -X- _ O
4.2.4 -X- _ O
, -X- _ O
despite -X- _ O
the -X- _ O
remarkable -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
F -X- _ B-MethodName
- -X- _ I-MethodName
RR -X- _ I-MethodName
with -X- _ I-MethodName
COMET -X- _ I-MethodName
- -X- _ I-MethodName
QE -X- _ I-MethodName
in -X- _ O
terms -X- _ O
of -X- _ O
COMET -X- _ B-MetricName
( -X- _ O
see -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
translations -X- _ O
decreases -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
suggesting -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
metric -X- _ O
overfitting -X- _ O
when -X- _ O
evaluating -X- _ O
systems -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
automatic -X- _ O
metric -X- _ O
that -X- _ O
was -X- _ O
directly -X- _ O
optimized -X- _ O
for -X- _ O
( -X- _ O
or -X- _ O
a -X- _ O
similar -X- _ O
one -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
both -X- _ O
language -X- _ O
pairs -X- _ O
, -X- _ O
the -X- _ O
T -X- _ B-MethodName
- -X- _ I-MethodName
RR -X- _ I-MethodName
with -X- _ I-MethodName
COMET -X- _ I-MethodName
and -X- _ O
the -X- _ O
two -X- _ O
stage -X- _ O
approach -X- _ O
( -X- _ O
T -X- _ B-MethodName
- -X- _ I-MethodName
RR -X- _ I-MethodName
+ -X- _ I-MethodName
MBR -X- _ I-MethodName
withCOMET -X- _ I-MethodName
) -X- _ O
achieve -X- _ O
the -X- _ O
highest -X- _ O
MQM -X- _ B-MetricName
score -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
these -X- _ O
systems -X- _ O
present -X- _ O
the -X- _ O
smallest -X- _ O
number -X- _ O
of -X- _ O
errors -X- _ O
when -X- _ O
combining -X- _ O
both -X- _ O
major -X- _ O
and -X- _ O
critical -X- _ O
errors -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
systems -X- _ O
is -X- _ O
comparable -X- _ O
for -X- _ O
EN -X- _ O
→DE -X- _ O
, -X- _ O
both -X- _ O
the -X- _ O
T -X- _ B-MethodName
- -X- _ I-MethodName
RR -X- _ I-MethodName
and -X- _ O
the -X- _ O
TRR+MBR -X- _ B-MethodName
decoding -X- _ O
markedly -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
grammatical -X- _ O
register -X- _ O
errors -X- _ O
related -X- _ O
to -X- _ O
using -X- _ O
pronouns -X- _ O
and -X- _ O
verb -X- _ O
forms -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
compliant -X- _ O
with -X- _ O
the -X- _ O
register -X- _ O
required -X- _ O
for -X- _ O
that -X- _ O
translation -X- _ O
, -X- _ O
at -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
lexical -X- _ O
selection -X- _ O
errors -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
EN -X- _ O
→RU -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
lexical -X- _ O
selection -X- _ O
errors -X- _ O
produced -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
T -X- _ B-MethodName
- -X- _ I-MethodName
RR -X- _ I-MethodName
or -X- _ O
the -X- _ O
T -X- _ B-MethodName
- -X- _ I-MethodName
RR+MBR -X- _ I-MethodName
decoding -X- _ O
is -X- _ O
approximately -X- _ O
a -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
ones -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
baseline -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
this -X- _ O
comes -X- _ O
at -X- _ O
apparently -X- _ O
almost -X- _ O
no -X- _ O
cost -X- _ O
in -X- _ O
other -X- _ O
error -X- _ O
types -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
significantly -X- _ O
better -X- _ O
results -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
5 -X- _ O
Related -X- _ O
Work -X- _ O
Reranking -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2004 -X- _ O
) -X- _ O
on -X- _ O
discriminative -X- _ O
reranking -X- _ O
for -X- _ O
SMT -X- _ O
, -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
trained -X- _ O
a -X- _ O
large -X- _ O
transformer -X- _ O
model -X- _ O
using -X- _ O
a -X- _ O
reranking -X- _ O
objective -X- _ O
to -X- _ O
optimize -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O
Our -X- _ O
work -X- _ O
differs -X- _ O
in -X- _ O
which -X- _ O
our -X- _ O
rerankers -X- _ O
are -X- _ O
much -X- _ O
simpler -X- _ O
and -X- _ O
therefore -X- _ O
can -X- _ O
be -X- _ O
tuned -X- _ O
on -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
; -X- _ O
and -X- _ O
we -X- _ O
use -X- _ O
more -X- _ O
powerful -X- _ O
quality -X- _ O
metrics -X- _ O
instead -X- _ O
of -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O
Similarly -X- _ O
, -X- _ O
Bhattacharyya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
learned -X- _ O
an -X- _ O
energy -X- _ O
- -X- _ O
based -X- _ O
reranker -X- _ O
to -X- _ O
assign -X- _ O
lower -X- _ O
energy -X- _ O
to -X- _ O
the -X- _ O
samples -X- _ O
with -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
energy -X- _ O
model -X- _ O
plays -X- _ O
a -X- _ O
similar -X- _ O
role -X- _ O
to -X- _ O
a -X- _ O
QE -X- _ O
system -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
differs -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
: -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
existing -X- _ O
, -X- _ O
pretrained -X- _ O
QE -X- _ O
model -X- _ O
instead -X- _ O
of -X- _ O
training -X- _ O
a -X- _ O
dedicated -X- _ O
reranker -X- _ O
, -X- _ O
making -X- _ O
our -X- _ O
approach -X- _ O
applicable -X- _ O
to -X- _ O
any -X- _ O
MT -X- _ O
system -X- _ O
without -X- _ O
further -X- _ O
training -X- _ O
; -X- _ O
and -X- _ O
the -X- _ O
QE -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
human -X- _ O
as-1403 -X- _ O
sessments -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
. -X- _ O
Leblond -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
compare -X- _ O
a -X- _ O
reinforcement -X- _ O
learning -X- _ O
approach -X- _ O
to -X- _ O
reranking -X- _ O
approaches -X- _ O
( -X- _ O
but -X- _ O
not -X- _ O
MBR -X- _ O
decoding -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
do -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
investigate -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
and -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
reward -X- _ O
function -X- _ O
, -X- _ O
a -X- _ O
referencefree -X- _ O
metric -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
modified -X- _ O
BERTScore -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
new -X- _ O
multilingual -X- _ O
BERTScore -X- _ O
is -X- _ O
not -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
human -X- _ O
judgments -X- _ O
as -X- _ O
COMET -X- _ B-MetricName
and -X- _ O
BLEURT -X- _ B-MetricName
and -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
what -X- _ O
its -X- _ O
level -X- _ O
of -X- _ O
agreement -X- _ O
with -X- _ O
human -X- _ O
judgments -X- _ O
is -X- _ O
. -X- _ O
Another -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
is -X- _ O
generative -X- _ O
reranking -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
reranker -X- _ O
is -X- _ O
not -X- _ O
trained -X- _ O
to -X- _ O
optimize -X- _ O
a -X- _ O
metric -X- _ O
, -X- _ O
but -X- _ O
rather -X- _ O
as -X- _ O
a -X- _ O
generative -X- _ O
noisy -X- _ O
- -X- _ O
channel -X- _ O
model -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Yee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Ng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Minimum -X- _ B-MethodName
Bayes -X- _ I-MethodName
Risk -X- _ I-MethodName
Decoding -X- _ I-MethodName
. -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
( -X- _ O
Kumar -X- _ O
and -X- _ O
Byrne -X- _ O
, -X- _ O
2002 -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
has -X- _ O
recently -X- _ O
been -X- _ O
revived -X- _ O
for -X- _ O
NMT -X- _ B-TaskName
using -X- _ O
candidates -X- _ O
generated -X- _ O
with -X- _ O
beam -X- _ O
search -X- _ O
( -X- _ O
Stahlberg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Shu -X- _ O
and -X- _ O
Nakayama -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
sampling -X- _ O
( -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Müller -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Eikema -X- _ O
and -X- _ O
Aziz -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
also -X- _ O
explore -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
approach -X- _ O
for -X- _ O
MBR -X- _ O
decoding -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
concurrent -X- _ O
work -X- _ O
by -X- _ O
Freitag -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021b -X- _ O
) -X- _ O
on -X- _ O
using -X- _ O
neural -X- _ O
metrics -X- _ O
as -X- _ O
utility -X- _ O
functions -X- _ O
during -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
: -X- _ O
however -X- _ O
they -X- _ O
limit -X- _ O
their -X- _ O
scope -X- _ O
to -X- _ O
MBR -X- _ B-MethodName
with -X- _ O
reference -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
more -X- _ O
extensive -X- _ O
evaluation -X- _ O
over -X- _ O
ranking -X- _ O
methods -X- _ O
and -X- _ O
metrics -X- _ O
. -X- _ O
Amrhein -X- _ O
and -X- _ O
Sennrich -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
also -X- _ O
concurrently -X- _ O
explored -X- _ O
using -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
with -X- _ O
neural -X- _ O
metrics -X- _ O
, -X- _ O
but -X- _ O
with -X- _ O
the -X- _ O
purposes -X- _ O
of -X- _ O
identifying -X- _ O
weaknesses -X- _ O
in -X- _ O
the -X- _ O
metric -X- _ O
( -X- _ O
in -X- _ O
their -X- _ O
case -X- _ O
COMET -X- _ B-MetricName
) -X- _ O
, -X- _ O
similarly -X- _ O
to -X- _ O
the -X- _ O
metric -X- _ O
overfitting -X- _ O
problem -X- _ O
we -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
4.2.4 -X- _ O
. -X- _ O
A -X- _ O
comparison -X- _ O
with -X- _ O
N -X- _ B-MethodName
- -X- _ I-MethodName
best -X- _ I-MethodName
re -X- _ I-MethodName
- -X- _ I-MethodName
ranking -X- _ I-MethodName
was -X- _ O
missing -X- _ O
in -X- _ O
these -X- _ O
works -X- _ O
, -X- _ O
a -X- _ O
gap -X- _ O
our -X- _ O
paper -X- _ O
fills -X- _ O
. -X- _ O
A -X- _ O
related -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
is -X- _ O
minimum -X- _ O
risk -X- _ O
training -X- _ O
( -X- _ O
MRT -X- _ O
; -X- _ O
Smith -X- _ O
and -X- _ O
Eisner -X- _ O
2006 -X- _ O
; -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
trains -X- _ O
models -X- _ O
to -X- _ O
minimize -X- _ O
risk -X- _ O
, -X- _ O
allowing -X- _ O
arbitrary -X- _ O
non -X- _ O
- -X- _ O
differentiable -X- _ O
loss -X- _ O
functions -X- _ O
( -X- _ O
Edunov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wieting -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
avoiding -X- _ O
exposure -X- _ O
bias -X- _ O
( -X- _ O
Wang -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Kiegelandand -X- _ O
Kreutzer -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
MRT -X- _ O
is -X- _ O
considerably -X- _ O
more -X- _ O
expensive -X- _ O
and -X- _ O
difficult -X- _ O
to -X- _ O
train -X- _ O
and -X- _ O
the -X- _ O
gains -X- _ O
are -X- _ O
often -X- _ O
small -X- _ O
. -X- _ O
Incorporating -X- _ O
our -X- _ O
quality -X- _ O
metrics -X- _ O
in -X- _ O
MRT -X- _ O
is -X- _ O
an -X- _ O
exciting -X- _ O
research -X- _ O
direction -X- _ O
. -X- _ O
6 -X- _ O
Conclusions -X- _ O
and -X- _ O
Future -X- _ O
Work -X- _ O
We -X- _ O
leverage -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
MT -X- _ O
quality -X- _ O
estimation -X- _ O
and -X- _ O
evaluation -X- _ O
and -X- _ O
propose -X- _ O
quality -X- _ O
- -X- _ O
aware -X- _ O
decoding -X- _ O
for -X- _ O
NMT -X- _ B-TaskName
. -X- _ O
We -X- _ O
explore -X- _ O
different -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
ranking -X- _ O
methods -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
comprehensive -X- _ O
empirical -X- _ O
analysis -X- _ O
across -X- _ O
four -X- _ O
datasets -X- _ O
and -X- _ O
two -X- _ O
model -X- _ O
classes -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
MAPbased -X- _ B-MethodName
decoding -X- _ I-MethodName
, -X- _ O
quality -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
decoding -X- _ I-MethodName
leads -X- _ O
to -X- _ O
better -X- _ O
translations -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
powerful -X- _ O
automatic -X- _ O
evaluation -X- _ O
metrics -X- _ O
and -X- _ O
human -X- _ O
judgments -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
several -X- _ O
directions -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
ranking -X- _ O
strategies -X- _ O
increase -X- _ O
accuracy -X- _ O
but -X- _ O
are -X- _ O
substantially -X- _ O
more -X- _ O
expensive -X- _ O
, -X- _ O
particularly -X- _ O
when -X- _ O
used -X- _ O
with -X- _ O
costly -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
BLEURT -X- _ B-MetricName
and -X- _ O
COMET -X- _ B-MetricName
. -X- _ O
While -X- _ O
reranking -X- _ O
- -X- _ O
based -X- _ O
pruning -X- _ O
before -X- _ O
MBR -X- _ B-MethodName
decoding -X- _ I-MethodName
was -X- _ O
found -X- _ O
helpful -X- _ O
, -X- _ O
additional -X- _ O
strategies -X- _ O
such -X- _ O
as -X- _ O
caching -X- _ O
encoder -X- _ O
representations -X- _ O
( -X- _ O
Amrhein -X- _ O
and -X- _ O
Sennrich -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
distillation -X- _ O
( -X- _ O
Pu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
are -X- _ O
promising -X- _ O
directions -X- _ O
. -X- _ O
Acknowledgments -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Ben -X- _ O
Peters -X- _ O
, -X- _ O
Wilker -X- _ O
Aziz -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
useful -X- _ O
feedback -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
P2020 -X- _ O
program -X- _ O
MAIA -X- _ O
( -X- _ O
LISBOA-01 -X- _ O
- -X- _ O
0247- -X- _ O
FEDER-045909 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
European -X- _ O
Research -X- _ O
Council -X- _ O
( -X- _ O
ERC -X- _ O
StG -X- _ O
DeepSPIN -X- _ O
758969 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
European -X- _ O
Union -X- _ O
’s -X- _ O
Horizon -X- _ O
2020 -X- _ O
research -X- _ O
and -X- _ O
innovation -X- _ O
program -X- _ O
( -X- _ O
QUARTZ -X- _ O
grant -X- _ O
agreement -X- _ O
951847 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
Fundação -X- _ O
para -X- _ O
a -X- _ O
Ciência -X- _ O
e -X- _ O
Tecnologia -X- _ O
through -X- _ O
UIDB -X- _ O
/ -X- _ O
50008 -X- _ O
/ -X- _ O
2020 -X- _ O
. -X- _ O
References14041405140614071408 -X- _ O
A -X- _ O
Training -X- _ O
Details -X- _ O
For -X- _ O
the -X- _ O
experiments -X- _ O
using -X- _ O
IWSLT17 -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
small -X- _ O
transformer -X- _ O
model -X- _ O
( -X- _ O
6 -X- _ O
layers -X- _ O
, -X- _ O
4 -X- _ O
attention -X- _ O
heads -X- _ O
, -X- _ O
512 -X- _ O
embedding -X- _ O
dimensions -X- _ O
, -X- _ O
and -X- _ O
1024 -X- _ O
hidden -X- _ O
dimensions -X- _ O
) -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
using -X- _ O
Fairseq -X- _ O
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
tokenize -X- _ O
the -X- _ O
data -X- _ O
using -X- _ O
SentencePiece -X- _ O
( -X- _ O
Kudo -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
joint -X- _ O
vocabulary -X- _ O
with -X- _ O
20000 -X- _ O
units -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
with -X- _ O
β= -X- _ B-HyperparameterName
0.9andβ= -X- _ B-HyperparameterValue
0.98and -X- _ B-HyperparameterValue
use -X- _ O
an -X- _ O
inverse -X- _ O
square -X- _ O
root -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
scheduler -X- _ I-HyperparameterName
, -X- _ O
with -X- _ O
an -X- _ O
initial -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5×10and -X- _ B-HyperparameterValue
with -X- _ O
a -X- _ O
linear -X- _ O
warm -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
up -X- _ I-HyperparameterName
in -X- _ O
the -X- _ O
first -X- _ O
4000 -X- _ B-HyperparameterValue
steps -X- _ O
. -X- _ O
For -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
label -X- _ O
smoothing -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
default -X- _ O
value -X- _ O
of -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
B -X- _ O
Additional -X- _ O
Results -X- _ O
For -X- _ O
completeness -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
results -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
metrics -X- _ O
presented -X- _ O
in -X- _ O
§ -X- _ O
3 -X- _ O
as -X- _ O
features -X- _ O
and -X- _ O
objectives -X- _ O
for -X- _ O
ranking -X- _ O
using -X- _ O
the -X- _ O
other -X- _ O
language -X- _ O
pairs -X- _ O
: -X- _ O
EN→RU -X- _ O
( -X- _ O
large -X- _ O
model -X- _ O
) -X- _ O
and -X- _ O
EN→FR -X- _ O
( -X- _ O
small -X- _ O
model -X- _ O
) -X- _ O
. -X- _ O
C -X- _ O
Human -X- _ O
Study -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
perform -X- _ O
human -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
recruited -X- _ O
professional -X- _ O
translators -X- _ O
who -X- _ O
were -X- _ O
native -X- _ O
speakers -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
on -X- _ O
the -X- _ O
freelancing -X- _ O
site -X- _ O
Upwork.300 -X- _ O
sentences -X- _ O
were -X- _ O
evaluated -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
pair -X- _ O
, -X- _ O
sampled -X- _ O
randomly -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
after -X- _ O
a -X- _ O
restriction -X- _ O
that -X- _ O
sentences -X- _ O
were -X- _ O
no -X- _ O
longer -X- _ O
than -X- _ O
30 -X- _ O
words -X- _ O
. -X- _ O
All -X- _ O
translation -X- _ O
hypotheses -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
source -X- _ O
sentence -X- _ O
were -X- _ O
first -X- _ O
deduplicated -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
shown -X- _ O
to -X- _ O
the -X- _ O
translator -X- _ O
side -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
side -X- _ O
in -X- _ O
randomized -X- _ O
order -X- _ O
to -X- _ O
avoid -X- _ O
any -X- _ O
ordering -X- _ O
biases -X- _ O
. -X- _ O
Sentences -X- _ O
were -X- _ O
evaluated -X- _ O
according -X- _ O
to -X- _ O
a -X- _ O
1 -X- _ O
- -X- _ O
5 -X- _ O
rubric -X- _ O
slightly -X- _ O
adapted -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
Wieting -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
no -X- _ O
overlap -X- _ O
in -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
whatsoever -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
Some -X- _ O
content -X- _ O
is -X- _ O
similar -X- _ O
but -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
different -X- _ O
. -X- _ O
3 -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
but -X- _ O
the -X- _ O
details -X- _ O
differ -X- _ O
. -X- _ O
4 -X- _ O
. -X- _ O
Meaning -X- _ O
is -X- _ O
essentially -X- _ O
equal -X- _ O
but -X- _ O
some -X- _ O
expressions -X- _ O
are -X- _ O
unnatural -X- _ O
. -X- _ O
5 -X- _ O
. -X- _ O
Meaning -X- _ O
is -X- _ O
essentially -X- _ O
equal -X- _ O
and -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
natural.1409D -X- _ O
MQM -X- _ O
Framework -X- _ O
Human -X- _ O
evaluations -X- _ O
were -X- _ O
performed -X- _ O
by -X- _ O
Unbabel -X- _ O
’s -X- _ O
PRO -X- _ O
Community -X- _ O
, -X- _ O
made -X- _ O
of -X- _ O
professional -X- _ O
translators -X- _ O
and -X- _ O
linguists -X- _ O
with -X- _ O
relevant -X- _ O
experience -X- _ O
in -X- _ O
linguistic -X- _ O
annotations -X- _ O
and -X- _ O
translation -X- _ O
errors -X- _ O
annotations -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
properly -X- _ O
assess -X- _ O
translations -X- _ O
quality -X- _ O
, -X- _ O
annotators -X- _ O
must -X- _ O
be -X- _ O
native -X- _ O
speakers -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
and -X- _ O
with -X- _ O
a -X- _ O
proven -X- _ O
high -X- _ O
proficiency -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
they -X- _ O
can -X- _ O
properly -X- _ O
capture -X- _ O
errors -X- _ O
and -X- _ O
their -X- _ O
nuances -X- _ O
. -X- _ O
The -X- _ O
systems -X- _ O
’ -X- _ O
outputs -X- _ O
were -X- _ O
evaluated -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
annotation -X- _ O
framework -X- _ O
adopted -X- _ O
internally -X- _ O
at -X- _ O
Unbabel -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
adaptation -X- _ O
of -X- _ O
the -X- _ O
MQM -X- _ O
Framework -X- _ O
( -X- _ O
Lommel -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
asked -X- _ O
the -X- _ O
annotators -X- _ O
to -X- _ O
identify -X- _ O
all -X- _ O
errors -X- _ O
and -X- _ O
independently -X- _ O
label -X- _ O
them -X- _ O
with -X- _ O
an -X- _ O
error -X- _ O
category -X- _ O
and -X- _ O
a -X- _ O
severity -X- _ O
level -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
three -X- _ O
categories -X- _ O
( -X- _ O
each -X- _ O
of -X- _ O
them -X- _ O
containing -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
different -X- _ O
subcategories -X- _ O
) -X- _ O
that -X- _ O
may -X- _ O
affect -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
translations -X- _ O
: -X- _ O
•Accuracy -X- _ B-MetricName
, -X- _ O
if -X- _ O
the -X- _ O
target -X- _ O
text -X- _ O
does -X- _ O
not -X- _ O
accurately -X- _ O
reflect -X- _ O
the -X- _ O
source -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
changes -X- _ O
in -X- _ O
the -X- _ O
meaning -X- _ O
, -X- _ O
addition -X- _ O
/ -X- _ O
omission -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
untranslated -X- _ O
text -X- _ O
, -X- _ O
MT -X- _ O
hallucinations -X- _ O
) -X- _ O
; -X- _ O
•Fluency -X- _ B-MetricName
, -X- _ O
if -X- _ O
there -X- _ O
are -X- _ O
issues -X- _ O
that -X- _ O
affect -X- _ O
the -X- _ O
reading -X- _ O
and -X- _ O
the -X- _ O
comprehension -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
grammar -X- _ O
and -X- _ O
spelling -X- _ O
errors -X- _ O
) -X- _ O
; -X- _ O
•Style -X- _ B-MetricName
, -X- _ O
if -X- _ O
the -X- _ O
text -X- _ O
has -X- _ O
stylistic -X- _ O
problems -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
gramatical -X- _ O
and -X- _ O
lexical -X- _ O
register -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
each -X- _ O
error -X- _ O
is -X- _ O
labeled -X- _ O
according -X- _ O
to -X- _ O
three -X- _ O
severity -X- _ O
levels -X- _ O
( -X- _ O
minor -X- _ O
, -X- _ O
major -X- _ O
, -X- _ O
and -X- _ O
critical -X- _ O
) -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
way -X- _ O
they -X- _ O
affect -X- _ O
the -X- _ O
accuracy -X- _ O
, -X- _ O
the -X- _ O
fluency -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
style -X- _ O
of -X- _ O
the -X- _ O
translation -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
score -X- _ O
is -X- _ O
obtained -X- _ O
using -X- _ O
a -X- _ O
weighting -X- _ O
scheme -X- _ O
where -X- _ O
minor -X- _ O
, -X- _ O
major -X- _ O
, -X- _ O
and -X- _ O
critical -X- _ O
errors -X- _ O
are -X- _ O
weighted -X- _ B-HyperparameterName
as -X- _ O
1,5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
Figures -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
show -X- _ O
the -X- _ O
counts -X- _ O
of -X- _ O
errors -X- _ O
breakdown -X- _ O
by -X- _ O
typology -X- _ O
and -X- _ O
severity -X- _ O
level -X- _ O
for -X- _ O
EN -X- _ O
→DE -X- _ O
and -X- _ O
EN→RU -X- _ O
, -X- _ O
respectively.141014111412 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
This -X- _ SUMMARY
paper -X- _ SUMMARY
presents -X- _ SUMMARY
a -X- _ SUMMARY
proposition -X- _ SUMMARY
- -X- _ SUMMARY
level -X- _ SUMMARY
pipeline -X- _ SUMMARY
for -X- _ SUMMARY
multi -X- _ SUMMARY
- -X- _ SUMMARY
document -X- _ SUMMARY
summarization -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
includes -X- _ SUMMARY
a -X- _ SUMMARY
salience -X- _ SUMMARY
model -X- _ SUMMARY
, -X- _ SUMMARY
clustering -X- _ SUMMARY
of -X- _ SUMMARY
propositions -X- _ SUMMARY
, -X- _ SUMMARY
fusion -X- _ SUMMARY
of -X- _ SUMMARY
cluster -X- _ SUMMARY
propositions -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
generation -X- _ SUMMARY
of -X- _ SUMMARY
summary -X- _ SUMMARY
sentences -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
method -X- _ SUMMARY
outperforms -X- _ SUMMARY
state -X- _ SUMMARY
- -X- _ SUMMARY
of -X- _ SUMMARY
- -X- _ SUMMARY
the -X- _ SUMMARY
- -X- _ SUMMARY
art -X- _ SUMMARY
baselines -X- _ SUMMARY
in -X- _ SUMMARY
terms -X- _ SUMMARY
of -X- _ SUMMARY
ROUGE -X- _ SUMMARY
scores -X- _ SUMMARY
and -X- _ SUMMARY
human -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
DUC -X- _ SUMMARY
2004 -X- _ SUMMARY
and -X- _ SUMMARY
TAC -X- _ SUMMARY
2011 -X- _ SUMMARY
datasets -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
approach -X- _ SUMMARY
also -X- _ SUMMARY
provides -X- _ SUMMARY
" -X- _ SUMMARY
explanations -X- _ SUMMARY
" -X- _ SUMMARY
for -X- _ SUMMARY
each -X- _ SUMMARY
generated -X- _ SUMMARY
sentence -X- _ SUMMARY
by -X- _ SUMMARY
linking -X- _ SUMMARY
them -X- _ SUMMARY
to -X- _ SUMMARY
groups -X- _ SUMMARY
of -X- _ SUMMARY
propositions -X- _ SUMMARY
from -X- _ SUMMARY
which -X- _ SUMMARY
they -X- _ SUMMARY
were -X- _ SUMMARY
derived -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
results -X- _ SUMMARY
show -X- _ SUMMARY
that -X- _ SUMMARY
the -X- _ SUMMARY
generated -X- _ SUMMARY
summary -X- _ SUMMARY
sentences -X- _ SUMMARY
are -X- _ SUMMARY
faithful -X- _ SUMMARY
to -X- _ SUMMARY
their -X- _ SUMMARY
corresponding -X- _ SUMMARY
clusters -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
highlights -X- _ SUMMARY
the -X- _ SUMMARY
potential -X- _ SUMMARY
of -X- _ SUMMARY
proposition -X- _ SUMMARY
- -X- _ SUMMARY
level -X- _ SUMMARY
units -X- _ SUMMARY
for -X- _ SUMMARY
cleaner -X- _ SUMMARY
and -X- _ SUMMARY
more -X- _ SUMMARY
accurate -X- _ SUMMARY
summarization -X- _ SUMMARY
. -X- _ SUMMARY
Ethical -X- _ SUMMARY
considerations -X- _ SUMMARY
were -X- _ SUMMARY
taken -X- _ SUMMARY
into -X- _ SUMMARY
account -X- _ SUMMARY
, -X- _ SUMMARY
such -X- _ SUMMARY
as -X- _ SUMMARY
fair -X- _ SUMMARY
compensation -X- _ SUMMARY
for -X- _ SUMMARY
crowdworkers -X- _ SUMMARY
and -X- _ SUMMARY
adherence -X- _ SUMMARY
to -X- _ SUMMARY
NIST -X- _ SUMMARY
guidelines -X- _ SUMMARY
for -X- _ SUMMARY
acquiring -X- _ SUMMARY
datasets -X- _ SUMMARY
. -X- _ SUMMARY
2022.naacl-main.128.txt -X- _ O
Ori -X- _ O
Ernst -X- _ O
, -X- _ O
Avi -X- _ O
Caciularu -X- _ O
, -X- _ O
Ori -X- _ O
Shapira -X- _ O
, -X- _ O
Ramakanth -X- _ O
Pasunuru -X- _ O
, -X- _ O
Mohit -X- _ O
Bansal -X- _ O
, -X- _ O
Jacob -X- _ O
Goldberger -X- _ O
, -X- _ O
and -X- _ O
Ido -X- _ O
DaganBar -X- _ O
- -X- _ O
Ilan -X- _ O
UniversityUNC -X- _ O
Chapel -X- _ O
Hill -X- _ O
{ -X- _ O
oriern -X- _ O
, -X- _ O
avi.c33 -X- _ O
, -X- _ O
obspp18 -X- _ O
} -X- _ O
@ -X- _ O
gmail.com -X- _ O
{ -X- _ O
ram -X- _ O
, -X- _ O
mbansal -X- _ O
} -X- _ O
@ -X- _ O
cs.unc.edu -X- _ O
{ -X- _ O
jacob.goldberger -X- _ O
@ -X- _ O
, -X- _ O
dagan -X- _ O
@ -X- _ O
cs. -X- _ O
} -X- _ O
biu.ac.il -X- _ O
Abstract -X- _ O
Text -X- _ O
clustering -X- _ O
methods -X- _ O
were -X- _ O
traditionally -X- _ O
incorporated -X- _ O
into -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
document -X- _ I-TaskName
summarization -X- _ I-TaskName
( -X- _ O
MDS -X- _ B-TaskName
) -X- _ O
as -X- _ O
a -X- _ O
means -X- _ O
for -X- _ O
coping -X- _ O
with -X- _ O
considerable -X- _ O
information -X- _ O
repetition -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
clusters -X- _ O
were -X- _ O
leveraged -X- _ O
to -X- _ O
indicate -X- _ O
information -X- _ O
saliency -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
to -X- _ O
avoid -X- _ O
redundancy -X- _ O
. -X- _ O
Such -X- _ O
prior -X- _ O
methods -X- _ O
focused -X- _ O
on -X- _ O
clustering -X- _ O
sentences -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
closely -X- _ O
related -X- _ O
sentences -X- _ O
usually -X- _ O
contain -X- _ O
also -X- _ O
non -X- _ O
- -X- _ O
aligned -X- _ O
parts -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
revisit -X- _ O
the -X- _ O
clustering -X- _ O
approach -X- _ O
, -X- _ O
grouping -X- _ O
together -X- _ O
sub -X- _ O
- -X- _ O
sentential -X- _ O
propositions -X- _ O
, -X- _ O
aiming -X- _ O
at -X- _ O
more -X- _ O
precise -X- _ O
information -X- _ O
alignment -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
detects -X- _ O
salient -X- _ O
propositions -X- _ O
, -X- _ O
clusters -X- _ O
them -X- _ O
into -X- _ O
paraphrastic -X- _ O
clusters -X- _ O
, -X- _ O
and -X- _ O
generates -X- _ O
a -X- _ O
representative -X- _ O
sentence -X- _ O
for -X- _ O
each -X- _ O
cluster -X- _ O
via -X- _ O
text -X- _ O
fusion -X- _ O
. -X- _ O
Our -X- _ O
summarization -X- _ B-TaskName
method -X- _ O
improves -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
MDS -X- _ B-TaskName
method -X- _ O
in -X- _ O
the -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ O
and -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ O
datasets -X- _ O
, -X- _ O
both -X- _ O
in -X- _ O
automatic -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
and -X- _ O
human -X- _ B-MetricName
preference -X- _ I-MetricName
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Common -X- _ O
information -X- _ O
needs -X- _ O
are -X- _ O
most -X- _ O
often -X- _ O
satisﬁed -X- _ O
by -X- _ O
multiple -X- _ O
texts -X- _ O
rather -X- _ O
than -X- _ O
by -X- _ O
a -X- _ O
single -X- _ O
one -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
rising -X- _ O
interest -X- _ O
in -X- _ O
MultiDocument -X- _ B-TaskName
Summarization -X- _ I-TaskName
( -X- _ O
MDS -X- _ B-TaskName
) -X- _ O
— -X- _ O
generating -X- _ O
a -X- _ O
summary -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
topically -X- _ O
- -X- _ O
related -X- _ O
documents -X- _ O
. -X- _ O
Inherently -X- _ O
, -X- _ O
MDS -X- _ B-TaskName
needs -X- _ O
to -X- _ O
address -X- _ O
, -X- _ O
either -X- _ O
explicitly -X- _ O
or -X- _ O
implicitly -X- _ O
, -X- _ O
several -X- _ O
subtasks -X- _ O
embedded -X- _ O
in -X- _ O
this -X- _ O
summarization -X- _ B-TaskName
setting -X- _ O
. -X- _ O
These -X- _ O
include -X- _ O
salience -X- _ O
detection -X- _ O
, -X- _ O
redundancy -X- _ O
removal -X- _ O
, -X- _ O
and -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O
While -X- _ O
all -X- _ O
these -X- _ O
subtasks -X- _ O
are -X- _ O
embedded -X- _ O
in -X- _ O
SingleDocument -X- _ O
Summarization -X- _ B-TaskName
( -X- _ O
SDS -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
, -X- _ O
the -X- _ O
challenges -X- _ O
are -X- _ O
much -X- _ O
greater -X- _ O
in -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
document -X- _ O
setting -X- _ O
, -X- _ O
where -X- _ O
information -X- _ O
is -X- _ O
heterogeneous -X- _ O
and -X- _ O
dispersed -X- _ O
, -X- _ O
while -X- _ O
exhibiting -X- _ O
substantial -X- _ O
redundancy -X- _ O
across -X- _ O
linguistically -X- _ O
divergent -X- _ O
utterances -X- _ O
. -X- _ O
An -X- _ O
appealing -X- _ O
summarization -X- _ B-TaskName
approach -X- _ O
that -X- _ O
copes -X- _ O
with -X- _ O
these -X- _ O
challenges -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
especially -X- _ O
rele -X- _ O
- -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
cluster -X- _ O
of -X- _ O
propositions -X- _ O
, -X- _ O
shown -X- _ O
within -X- _ O
their -X- _ O
source -X- _ O
sentence -X- _ O
context -X- _ O
, -X- _ O
from -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
( -X- _ O
topic -X- _ O
D1103 -X- _ O
) -X- _ O
. -X- _ O
Clustering -X- _ O
these -X- _ O
as -X- _ O
sentences -X- _ O
would -X- _ O
yield -X- _ O
noisy -X- _ O
unaligned -X- _ O
information -X- _ O
, -X- _ O
however -X- _ O
grouping -X- _ O
together -X- _ O
only -X- _ O
the -X- _ O
marked -X- _ O
propositions -X- _ O
keeps -X- _ O
information -X- _ O
alignment -X- _ O
clean -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
sentence -X- _ O
is -X- _ O
illustratively -X- _ O
divided -X- _ O
into -X- _ O
propositions -X- _ O
, -X- _ O
where -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
them -X- _ O
is -X- _ O
aligned -X- _ O
to -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
other -X- _ O
sentences -X- _ O
. -X- _ O
vant -X- _ O
for -X- _ O
MDS -X- _ B-TaskName
, -X- _ O
is -X- _ O
clustering -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
summarization -X- _ I-TaskName
. -X- _ O
In -X- _ O
such -X- _ O
an -X- _ O
approach -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
cluster -X- _ O
redundant -X- _ O
paraphrastic -X- _ O
pieces -X- _ O
of -X- _ O
information -X- _ O
across -X- _ O
the -X- _ O
texts -X- _ O
, -X- _ O
which -X- _ O
roughly -X- _ O
convey -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
. -X- _ O
Repetition -X- _ O
of -X- _ O
information -X- _ O
across -X- _ O
texts -X- _ O
, -X- _ O
as -X- _ O
captured -X- _ O
by -X- _ O
paraphrastic -X- _ O
clustering -X- _ O
, -X- _ O
typically -X- _ O
indicates -X- _ O
its -X- _ O
importance -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
leveraged -X- _ O
for -X- _ O
salience -X- _ O
detection -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
representing -X- _ O
a -X- _ O
paraphrastic -X- _ O
cluster -X- _ O
may -X- _ O
facilitate -X- _ O
generating -X- _ O
a -X- _ O
corresponding -X- _ O
summary -X- _ O
that -X- _ O
eliminates -X- _ O
repetitions -X- _ O
while -X- _ O
fusing -X- _ O
together -X- _ O
complementary -X- _ O
details -X- _ O
within -X- _ O
the -X- _ O
cluster -X- _ O
. -X- _ O
Traditionally -X- _ O
, -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
were -X- _ O
widely -X- _ O
used -X- _ O
for -X- _ O
summarization -X- _ O
, -X- _ O
mostly -X- _ O
in -X- _ O
extractive -X- _ O
and -X- _ O
unsupervised -X- _ O
settings -X- _ O
( -X- _ O
Radev -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Nayeem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
these -X- _ O
works -X- _ O
generated -X- _ O
sentence -X- _ O
- -X- _ O
based -X- _ O
clusters -X- _ O
, -X- _ O
which -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
noisy -X- _ O
since -X- _ O
a -X- _ O
sentence -X- _ O
typically -X- _ O
consists -X- _ O
of -X- _ O
several -X- _ O
units -X- _ O
of -X- _ O
information -X- _ O
that -X- _ O
only -X- _ O
partially -X- _ O
overlap -X- _ O
with -X- _ O
other -X- _ O
cluster -X- _ O
sentences -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
such -X- _ O
clusters -X- _ O
often -X- _ O
capture -X- _ O
topically -X- _ O
related -X- _ O
sentences -X- _ O
rather -X- _ O
than -X- _ O
paraphrases -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
exempliﬁes -X- _ O
such -X- _ O
a -X- _ O
noisy -X- _ O
cluster -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
contain -X- _ O
paraphrastic -X- _ O
propositions -X- _ O
( -X- _ O
marked -X- _ O
in -X- _ O
blue -X- _ O
) -X- _ O
within -X- _ O
their -X- _ O
full -X- _ O
sentences -X- _ O
( -X- _ O
marked -X- _ O
in -X- _ O
black -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
in -X- _ O
summarization -X- _ O
coped -X- _ O
with1765such -X- _ O
noisy -X- _ O
sentence -X- _ O
- -X- _ O
based -X- _ O
setting -X- _ O
, -X- _ O
and -X- _ O
looked -X- _ O
into -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
sentential -X- _ O
units -X- _ O
for -X- _ O
summarization -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
summarizes -X- _ O
with -X- _ O
Elementary -X- _ O
Discourse -X- _ O
Units -X- _ O
( -X- _ O
EDUs -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
Ernst -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
endorse -X- _ O
using -X- _ O
Open -X- _ O
Information -X- _ O
Extraction -X- _ O
( -X- _ O
OpenIE -X- _ O
) -X- _ O
-based -X- _ O
propositions -X- _ O
( -X- _ O
Stanovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
summarization -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
revisit -X- _ O
and -X- _ O
combine -X- _ O
the -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
along -X- _ O
with -X- _ O
subsentential -X- _ O
setting -X- _ O
, -X- _ O
two -X- _ O
research -X- _ O
lines -X- _ O
that -X- _ O
were -X- _ O
explored -X- _ O
only -X- _ O
individually -X- _ O
and -X- _ O
rather -X- _ O
scarcely -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
clustering -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
summarization -X- _ I-TaskName
at -X- _ O
the -X- _ O
more -X- _ O
ﬁne -X- _ O
- -X- _ O
grained -X- _ O
propositional -X- _ O
level -X- _ O
, -X- _ O
which -X- _ O
avoids -X- _ O
grouping -X- _ O
non -X- _ O
- -X- _ O
aligned -X- _ O
texts -X- _ O
, -X- _ O
yielding -X- _ O
accurate -X- _ O
paraphrastic -X- _ O
clusters -X- _ O
. -X- _ O
These -X- _ O
clusters -X- _ O
also -X- _ O
provide -X- _ O
better -X- _ O
control -X- _ O
over -X- _ O
the -X- _ O
generated -X- _ O
summary -X- _ O
sentences -X- _ O
– -X- _ O
as -X- _ O
the -X- _ O
generation -X- _ O
component -X- _ O
is -X- _ O
only -X- _ O
required -X- _ O
to -X- _ O
fuse -X- _ O
similar -X- _ O
propositions -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
3 -X- _ O
) -X- _ O
leverages -X- _ O
gold -X- _ O
reference -X- _ O
summaries -X- _ O
to -X- _ O
derive -X- _ O
training -X- _ O
datasets -X- _ O
for -X- _ O
several -X- _ O
summarization -X- _ B-TaskName
sub -X- _ O
- -X- _ O
tasks -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
salient -X- _ O
document -X- _ O
propositions -X- _ O
were -X- _ O
extracted -X- _ O
, -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
salience -X- _ O
model -X- _ O
, -X- _ O
by -X- _ O
greedily -X- _ O
maximizing -X- _ O
alignment -X- _ O
with -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
an -X- _ O
available -X- _ O
proposition -X- _ O
similarity -X- _ O
model -X- _ O
, -X- _ O
trained -X- _ O
from -X- _ O
summarysource -X- _ O
alignments -X- _ O
( -X- _ O
Ernst -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
provides -X- _ O
the -X- _ O
basis -X- _ O
for -X- _ O
agglomerative -X- _ O
clustering -X- _ O
( -X- _ O
Ward -X- _ O
, -X- _ O
1963 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
created -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
BART -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
for -X- _ O
sentence -X- _ O
fusion -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
by -X- _ O
aligning -X- _ O
reference -X- _ O
summary -X- _ O
propositions -X- _ O
with -X- _ O
source -X- _ O
proposition -X- _ O
clusters -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
many -X- _ O
other -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
leave -X- _ O
inter -X- _ O
- -X- _ O
sentence -X- _ O
coherence -X- _ O
and -X- _ O
sentence -X- _ O
planning -X- _ O
and -X- _ O
ordering -X- _ O
outside -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
paper -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
our -X- _ O
process -X- _ O
produces -X- _ O
a -X- _ O
bullet -X- _ O
- -X- _ O
style -X- _ O
summary -X- _ O
of -X- _ O
individual -X- _ O
concise -X- _ O
and -X- _ O
coherent -X- _ O
sentences -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
experiments -X- _ O
( -X- _ O
§ -X- _ O
4 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
this -X- _ O
multi -X- _ O
- -X- _ O
step -X- _ O
model -X- _ O
outperforms -X- _ O
strong -X- _ O
recent -X- _ O
end -X- _ O
- -X- _ O
toend -X- _ O
solutions -X- _ O
, -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
include -X- _ O
explicit -X- _ O
modeling -X- _ O
of -X- _ O
propositions -X- _ O
and -X- _ O
information -X- _ O
redundancy -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
our -X- _ O
setting -X- _ O
on -X- _ O
the -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
and -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
datasets -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
1.5 -X- _ B-MetricValue
and -X- _ O
4 -X- _ B-MetricValue
ROUGE-1 -X- _ B-MetricName
F1 -X- _ B-MetricName
points -X- _ O
respectively -X- _ O
, -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
approach -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
suggest -X- _ O
( -X- _ O
§ -X- _ O
5 -X- _ O
) -X- _ O
that -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
provide -X- _ O
“ -X- _ O
explanations -X- _ O
" -X- _ O
, -X- _ O
or -X- _ O
supporting -X- _ O
evidence -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
generated -X- _ O
sentence -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
cluster -X- _ O
propositions -X- _ O
( -X- _ O
see -X- _ O
an -X- _ O
example -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
.2 -X- _ O
Background -X- _ O
and -X- _ O
Related -X- _ O
Work -X- _ O
Clustering -X- _ O
- -X- _ O
based -X- _ O
summarization -X- _ O
. -X- _ O
Clusteringbased -X- _ B-TaskName
summarization -X- _ I-TaskName
approaches -X- _ O
typically -X- _ O
involve -X- _ O
salience -X- _ O
detection -X- _ O
while -X- _ O
avoiding -X- _ O
redundancy -X- _ O
. -X- _ O
One -X- _ O
such -X- _ O
approach -X- _ O
clustered -X- _ O
topically -X- _ O
- -X- _ O
related -X- _ O
sentences -X- _ O
, -X- _ O
after -X- _ O
which -X- _ O
cluster -X- _ O
properties -X- _ O
were -X- _ O
leveraged -X- _ O
for -X- _ O
rating -X- _ O
sentence -X- _ O
salience -X- _ O
( -X- _ O
Radev -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
; -X- _ O
Wan -X- _ O
and -X- _ O
Yang -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
Another -X- _ O
approach -X- _ O
rated -X- _ O
sentence -X- _ O
salience -X- _ O
and -X- _ O
clustered -X- _ O
sentences -X- _ O
simultaneously -X- _ O
, -X- _ O
iteratively -X- _ O
improving -X- _ O
the -X- _ O
two -X- _ O
objectives -X- _ O
( -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Cai -X- _ O
and -X- _ O
Li -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
clustering -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
gradually -X- _ O
marginalized -X- _ O
out -X- _ O
, -X- _ O
being -X- _ O
replaced -X- _ O
by -X- _ O
neural -X- _ O
techniques -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
though -X- _ O
, -X- _ O
some -X- _ O
approaches -X- _ O
( -X- _ O
Nayeem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Fuad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
presented -X- _ O
abstractive -X- _ O
clustering -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
summarization -X- _ I-TaskName
, -X- _ O
where -X- _ O
topically -X- _ O
- -X- _ O
related -X- _ O
sentences -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
are -X- _ O
fused -X- _ O
together -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
summary -X- _ O
sentence -X- _ O
candidate -X- _ O
. -X- _ O
While -X- _ O
most -X- _ O
of -X- _ O
previous -X- _ O
clustering -X- _ O
approaches -X- _ O
operated -X- _ O
at -X- _ O
the -X- _ O
noisy -X- _ O
sentence -X- _ O
level -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
work -X- _ O
we -X- _ O
present -X- _ O
more -X- _ O
accurate -X- _ O
proposition -X- _ O
- -X- _ O
level -X- _ O
clustering -X- _ O
that -X- _ O
eventually -X- _ O
enhances -X- _ O
summarization -X- _ B-TaskName
. -X- _ O
Sub -X- _ O
- -X- _ O
sentence -X- _ O
units -X- _ O
in -X- _ O
summarization -X- _ O
. -X- _ O
While -X- _ O
many -X- _ O
summarization -X- _ B-TaskName
approaches -X- _ O
extract -X- _ O
full -X- _ O
document -X- _ O
sentences -X- _ O
, -X- _ O
either -X- _ O
for -X- _ O
extractive -X- _ B-TaskName
summarization -X- _ I-TaskName
or -X- _ O
as -X- _ O
an -X- _ O
intermediate -X- _ O
step -X- _ O
for -X- _ O
abstractive -X- _ B-TaskName
summarization -X- _ I-TaskName
, -X- _ O
there -X- _ O
are -X- _ O
methods -X- _ O
that -X- _ O
operated -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
sentential -X- _ O
level -X- _ O
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
Liu -X- _ O
and -X- _ O
Chen -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
produced -X- _ O
extractive -X- _ O
summaries -X- _ O
consisting -X- _ O
of -X- _ O
Elementary -X- _ O
Discourse -X- _ O
Units -X- _ O
( -X- _ O
EDUs -X- _ O
) -X- _ O
– -X- _ O
clauses -X- _ O
comprising -X- _ O
a -X- _ O
discourse -X- _ O
unit -X- _ O
according -X- _ O
to -X- _ O
Rhetorical -X- _ O
Structure -X- _ O
Theory -X- _ O
( -X- _ O
RST -X- _ O
) -X- _ O
( -X- _ O
Mann -X- _ O
and -X- _ O
Thompson -X- _ O
, -X- _ O
1988 -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
extractive -X- _ O
approaches -X- _ O
usually -X- _ O
focus -X- _ O
on -X- _ O
content -X- _ O
selection -X- _ O
, -X- _ O
possibly -X- _ O
disregarding -X- _ O
the -X- _ O
inferior -X- _ O
coherence -X- _ O
arising -X- _ O
from -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
sub -X- _ O
- -X- _ O
sentence -X- _ O
units -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
Arumae -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
established -X- _ O
the -X- _ O
highlighting -X- _ O
task -X- _ O
, -X- _ O
where -X- _ O
salient -X- _ O
sub -X- _ O
- -X- _ O
sentence -X- _ O
units -X- _ O
are -X- _ O
marked -X- _ O
within -X- _ O
their -X- _ O
document -X- _ O
to -X- _ O
provide -X- _ O
surrounding -X- _ O
context -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
identifying -X- _ O
heuristically -X- _ O
self -X- _ O
- -X- _ O
contained -X- _ O
subsentence -X- _ O
units -X- _ O
for -X- _ O
the -X- _ O
highlighting -X- _ O
task -X- _ O
. -X- _ O
Abstractive -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
extracting -X- _ O
subsentence -X- _ O
units -X- _ O
as -X- _ O
a -X- _ O
preliminary -X- _ O
step -X- _ O
for -X- _ O
generation -X- _ O
. -X- _ O
Such -X- _ O
units -X- _ O
range -X- _ O
from -X- _ O
words -X- _ O
( -X- _ O
Lebanoff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Gehrmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
noun -X- _ O
or -X- _ O
verb -X- _ O
phrases -X- _ O
( -X- _ O
Bing -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
OpenIE -X- _ O
propositions -X- _ O
( -X- _ O
Pasunuru -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
extract -X- _ O
- -X- _ O
then -X- _ O
- -X- _ O
generate -X- _ O
pipeline -X- _ O
, -X- _ O
using -X- _ O
Ope-1766 -X- _ O
nIEs -X- _ O
( -X- _ O
Stanovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
as -X- _ O
propositions -X- _ O
. -X- _ O
Since -X- _ O
propositions -X- _ O
are -X- _ O
meant -X- _ O
to -X- _ O
contain -X- _ O
single -X- _ O
standalone -X- _ O
facts -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
main -X- _ O
predicate -X- _ O
and -X- _ O
its -X- _ O
arguments -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
beneﬁcial -X- _ O
for -X- _ O
grouping -X- _ O
mostly -X- _ O
overlapping -X- _ O
paraphrases -X- _ O
( -X- _ O
unlike -X- _ O
sentential -X- _ O
paraphrases -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
propositions -X- _ O
extracted -X- _ O
with -X- _ O
OpenIE -X- _ O
can -X- _ O
be -X- _ O
noncontiguous -X- _ O
, -X- _ O
while -X- _ O
alternative -X- _ O
options -X- _ O
, -X- _ O
like -X- _ O
EDUs -X- _ O
, -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
contiguous -X- _ O
sequences -X- _ O
. -X- _ O
3 -X- _ O
Method -X- _ O
This -X- _ O
section -X- _ O
ﬁrst -X- _ O
provides -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
subsections -X- _ O
describing -X- _ O
its -X- _ O
components -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
previous -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
, -X- _ O
where -X- _ O
text -X- _ O
segments -X- _ O
are -X- _ O
ﬁrst -X- _ O
clustered -X- _ O
into -X- _ O
semantically -X- _ O
similar -X- _ O
groups -X- _ O
, -X- _ O
exploiting -X- _ O
redundancy -X- _ O
as -X- _ O
a -X- _ O
salience -X- _ O
signal -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
each -X- _ O
group -X- _ O
is -X- _ O
fused -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
merged -X- _ O
sentence -X- _ O
, -X- _ O
while -X- _ O
avoiding -X- _ O
redundancy -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
operate -X- _ O
at -X- _ O
the -X- _ O
propositionlevel -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
extract -X- _ O
all -X- _ O
propositions -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
documents -X- _ O
( -X- _ O
§ -X- _ O
3.1 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
clustering -X- _ O
step -X- _ O
, -X- _ O
we -X- _ O
ﬁlter -X- _ O
out -X- _ O
non -X- _ O
- -X- _ O
salient -X- _ O
propositions -X- _ O
using -X- _ O
a -X- _ O
salience -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
salient -X- _ O
propositions -X- _ O
are -X- _ O
clustered -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
semantic -X- _ O
similarity -X- _ O
( -X- _ O
§ -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
largest -X- _ O
clusters -X- _ O
, -X- _ O
whose -X- _ O
information -X- _ O
was -X- _ O
most -X- _ O
repeated -X- _ O
, -X- _ O
are -X- _ O
selected -X- _ O
to -X- _ O
be -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
summary -X- _ O
( -X- _ O
§ -X- _ O
3.4 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
each -X- _ O
cluster -X- _ O
is -X- _ O
fused -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
sentence -X- _ O
for -X- _ O
a -X- _ O
bullet -X- _ O
- -X- _ O
style -X- _ O
abstractive -X- _ O
summary -X- _ O
( -X- _ O
§ -X- _ O
3.5 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
an -X- _ O
extractive -X- _ O
version -X- _ O
where -X- _ O
a -X- _ O
representative -X- _ O
( -X- _ O
source -X- _ O
) -X- _ O
propositionis -X- _ O
selected -X- _ O
from -X- _ O
each -X- _ O
cluster -X- _ O
( -X- _ O
3.6 -X- _ O
) -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
clustering -X- _ O
explicit -X- _ O
propositions -X- _ O
induces -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
step -X- _ O
process -X- _ O
that -X- _ O
requires -X- _ O
dedicated -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
certain -X- _ O
steps -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
new -X- _ O
training -X- _ O
datasets -X- _ O
for -X- _ O
the -X- _ O
salience -X- _ O
detection -X- _ O
and -X- _ O
the -X- _ O
fusion -X- _ O
models -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
gold -X- _ O
summaries -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
pipeline -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
where -X- _ O
additional -X- _ O
implementation -X- _ O
details -X- _ O
are -X- _ O
in -X- _ O
§ -X- _ O
B -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
3.1 -X- _ O
Proposition -X- _ O
Extraction -X- _ O
Aiming -X- _ O
to -X- _ O
generate -X- _ O
proposition -X- _ O
- -X- _ O
based -X- _ O
summaries -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
extract -X- _ O
all -X- _ O
propositions -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
documents -X- _ O
using -X- _ O
Open -X- _ O
Information -X- _ O
Extraction -X- _ O
( -X- _ O
OpenIE -X- _ O
) -X- _ O
( -X- _ O
Stanovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
following -X- _ O
Ernst -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
convert -X- _ O
an -X- _ O
OpenIE -X- _ O
tuple -X- _ O
containing -X- _ O
a -X- _ O
predicate -X- _ O
and -X- _ O
its -X- _ O
arguments -X- _ O
into -X- _ O
a -X- _ O
proposition -X- _ O
string -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
concatenate -X- _ O
them -X- _ O
by -X- _ O
their -X- _ O
original -X- _ O
order -X- _ O
, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
3.2 -X- _ O
Proposition -X- _ O
Salience -X- _ O
Model -X- _ O
To -X- _ O
facilitate -X- _ O
the -X- _ O
clustering -X- _ O
stage -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
aim -X- _ O
to -X- _ O
ﬁlter -X- _ O
non -X- _ O
- -X- _ O
salient -X- _ O
propositions -X- _ O
by -X- _ O
a -X- _ O
supervised -X- _ O
model -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
derive -X- _ O
gold -X- _ O
labels -X- _ O
for -X- _ O
proposition -X- _ O
salience -X- _ O
from -X- _ O
the -X- _ O
existing -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
select -X- _ O
greedily -X- _ O
propositions -X- _ O
that -X- _ O
maximize -X- _ O
ROUGE-1 -X- _ B-MetricName
+ -X- _ O
ROUGE-2against -X- _ B-MetricName
their -X- _ O
reference -X- _ O
summaries -X- _ O
( -X- _ O
Nallapati -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Liu -X- _ O
and -X- _ O
Lapata -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
marked -X- _ O
them -X- _ O
as -X- _ O
salient.1767 -X- _ O
Using -X- _ O
this -X- _ O
derived -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
the -X- _ O
Cross -X- _ O
- -X- _ O
Document -X- _ O
Language -X- _ O
Model -X- _ O
( -X- _ O
CDLM -X- _ O
) -X- _ O
( -X- _ O
Caciularu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
classiﬁer -X- _ O
for -X- _ O
predicting -X- _ O
whether -X- _ O
a -X- _ O
proposition -X- _ O
is -X- _ O
salient -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
Propositions -X- _ O
with -X- _ O
a -X- _ O
salience -X- _ O
score -X- _ O
below -X- _ O
a -X- _ O
certain -X- _ O
threshold -X- _ O
were -X- _ O
ﬁltered -X- _ O
out -X- _ O
. -X- _ O
The -X- _ O
threshold -X- _ O
was -X- _ O
optimized -X- _ O
with -X- _ O
the -X- _ O
full -X- _ O
pipeline -X- _ O
against -X- _ O
the -X- _ O
ﬁnal -X- _ O
ROUGE -X- _ B-MetricName
score -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
All -X- _ O
propositions -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
clusters -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
are -X- _ O
examples -X- _ O
of -X- _ O
predicted -X- _ O
salient -X- _ O
propositions -X- _ O
. -X- _ O
We -X- _ O
chose -X- _ O
to -X- _ O
use -X- _ O
CDLM -X- _ O
as -X- _ O
it -X- _ O
was -X- _ O
pretrained -X- _ O
with -X- _ O
sets -X- _ O
of -X- _ O
related -X- _ O
documents -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
hence -X- _ O
shown -X- _ O
to -X- _ O
operate -X- _ O
well -X- _ O
over -X- _ O
several -X- _ O
downstream -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
multidocument -X- _ O
setting -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
cross -X- _ O
- -X- _ O
document -X- _ O
coreference -X- _ O
resolution -X- _ O
and -X- _ O
multi -X- _ O
- -X- _ O
document -X- _ O
classiﬁcation -X- _ O
) -X- _ O
. -X- _ O
3.3 -X- _ O
Clustering -X- _ O
Next -X- _ O
, -X- _ O
all -X- _ O
salient -X- _ O
propositions -X- _ O
are -X- _ O
clustered -X- _ O
to -X- _ O
semanticly -X- _ O
similar -X- _ O
groups -X- _ O
. -X- _ O
Clusters -X- _ O
of -X- _ O
paraphrasticpropositions -X- _ O
are -X- _ O
advantageous -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
as -X- _ O
they -X- _ O
can -X- _ O
assist -X- _ O
in -X- _ O
avoiding -X- _ O
redundant -X- _ O
information -X- _ O
in -X- _ O
an -X- _ O
output -X- _ O
summary -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
paraphrastic -X- _ O
clustering -X- _ O
offers -X- _ O
redundancy -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
indicator -X- _ O
for -X- _ O
saliency -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
former -X- _ O
salience -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
does -X- _ O
not -X- _ O
utilize -X- _ O
repetitions -X- _ O
explicitly -X- _ O
. -X- _ O
To -X- _ O
cluster -X- _ O
propositions -X- _ O
we -X- _ O
utilize -X- _ O
SuperPAL -X- _ O
( -X- _ O
Ernst -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
binary -X- _ O
classiﬁer -X- _ O
that -X- _ O
measures -X- _ O
paraphrastic -X- _ O
similarity -X- _ O
between -X- _ O
two -X- _ O
propositions -X- _ O
. -X- _ O
All -X- _ O
pairs -X- _ O
of -X- _ O
salient -X- _ O
propositions -X- _ O
are -X- _ O
scored -X- _ O
with -X- _ O
SuperPAL -X- _ O
, -X- _ O
over -X- _ O
which -X- _ O
standard -X- _ O
agglomerative -X- _ O
clustering -X- _ O
( -X- _ O
Ward -X- _ O
, -X- _ O
1963 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
. -X- _ O
Examples -X- _ O
of -X- _ O
generated -X- _ O
clusters -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
3.4 -X- _ O
Cluster -X- _ O
Ranking -X- _ O
The -X- _ O
resulting -X- _ O
proposition -X- _ O
clusters -X- _ O
are -X- _ O
next -X- _ O
ranked -X- _ O
according -X- _ O
to -X- _ O
cluster -X- _ O
- -X- _ O
based -X- _ O
properties -X- _ O
. -X- _ O
We -X- _ O
examined -X- _ O
various -X- _ O
features -X- _ O
, -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
on -X- _ O
our -X- _ O
validation -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
features -X- _ O
examined -X- _ O
include -X- _ O
: -X- _ O
aver-1768age -X- _ O
of -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
between -X- _ O
all -X- _ O
propositions -X- _ O
in -X- _ O
a -X- _ O
cluster -X- _ O
( -X- _ O
‘ -X- _ O
Avg -X- _ O
. -X- _ O
ROUGE -X- _ B-MetricName
’ -X- _ O
) -X- _ O
, -X- _ O
average -X- _ O
of -X- _ O
SuperPAL -X- _ O
scores -X- _ O
between -X- _ O
all -X- _ O
propositions -X- _ O
in -X- _ O
a -X- _ O
cluster -X- _ O
( -X- _ O
‘ -X- _ O
Avg -X- _ O
. -X- _ O
SuperPAL -X- _ O
’ -X- _ O
) -X- _ O
, -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
salience -X- _ O
model -X- _ O
scores -X- _ O
of -X- _ O
cluster -X- _ O
propositions -X- _ O
( -X- _ O
‘ -X- _ O
Avg -X- _ O
. -X- _ O
salience -X- _ O
’ -X- _ O
) -X- _ O
, -X- _ O
minimal -X- _ O
position -X- _ O
( -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
) -X- _ O
of -X- _ O
cluster -X- _ O
propositions -X- _ O
( -X- _ O
‘ -X- _ O
Min -X- _ O
. -X- _ O
position -X- _ O
’ -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
cluster -X- _ O
size -X- _ O
( -X- _ O
‘ -X- _ O
Cluster -X- _ O
size -X- _ O
’ -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
feature -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
clusters -X- _ O
were -X- _ O
ranked -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
feature -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
proposition -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
salience -X- _ O
model -X- _ O
score -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
was -X- _ O
selected -X- _ O
from -X- _ O
each -X- _ O
cluster -X- _ O
as -X- _ O
a -X- _ O
cluster -X- _ O
representative -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
the -X- _ O
representatives -X- _ O
from -X- _ O
the -X- _ O
highest -X- _ O
ranked -X- _ O
clusters -X- _ O
were -X- _ O
concatenated -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
system -X- _ O
summary -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
measured -X- _ O
combinations -X- _ O
of -X- _ O
two -X- _ O
features -X- _ O
( -X- _ O
‘ -X- _ O
Cluster -X- _ O
size -X- _ O
+ -X- _ O
Min -X- _ O
. -X- _ O
position -X- _ O
’ -X- _ O
for -X- _ O
example -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
ﬁrst -X- _ O
feature -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
primary -X- _ O
ranking -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
feature -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
secondary -X- _ O
ranking -X- _ O
in -X- _ O
case -X- _ O
of -X- _ O
a -X- _ O
tie -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
options -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
tie -X- _ O
is -X- _ O
still -X- _ O
remained -X- _ O
, -X- _ O
further -X- _ O
ranking -X- _ O
between -X- _ O
clusters -X- _ O
is -X- _ O
resolved -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
maximal -X- _ O
proposition -X- _ O
salience -X- _ O
score -X- _ O
of -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
of -X- _ O
these -X- _ O
summaries -X- _ O
on -X- _ O
validation -X- _ O
sets -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
2.We -X- _ O
found -X- _ O
that -X- _ O
‘ -X- _ O
Cluster -X- _ O
size -X- _ O
’ -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
ROUGE -X- _ B-MetricName
scores -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
feature -X- _ O
, -X- _ O
and -X- _ O
‘ -X- _ O
Min -X- _ O
. -X- _ O
position -X- _ O
’ -X- _ O
further -X- _ O
improves -X- _ O
results -X- _ O
as -X- _ O
a -X- _ O
secondary -X- _ O
tie -X- _ O
breaking -X- _ O
ranking -X- _ O
feature -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
cluster -X- _ O
represents -X- _ O
redundancy -X- _ O
of -X- _ O
information -X- _ O
across -X- _ O
documents -X- _ O
thus -X- _ O
likely -X- _ O
to -X- _ O
indicate -X- _ O
higher -X- _ O
importance -X- _ O
. -X- _ O
3.5 -X- _ O
Cluster -X- _ O
Fusion -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
merge -X- _ O
the -X- _ O
paraphrastic -X- _ O
propositions -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
, -X- _ O
while -X- _ O
consolidating -X- _ O
complementary -X- _ O
details -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
new -X- _ O
coherent -X- _ O
summary -X- _ O
sentence -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
helps -X- _ O
avoiding -X- _ O
redundancy -X- _ O
, -X- _ O
since -X- _ O
redundant -X- _ O
information -X- _ O
is -X- _ O
concentrated -X- _ O
separately -X- _ O
in -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
a -X- _ O
cluster -X- _ O
fusion -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
derived -X- _ O
training -X- _ O
data -X- _ O
automatically -X- _ O
from -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
, -X- _ O
by -X- _ O
leveraging -X- _ O
the -X- _ O
SuperPAL -X- _ O
model -X- _ O
( -X- _ O
Ernst -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
( -X- _ O
which -X- _ O
was -X- _ O
also -X- _ O
employed -X- _ O
in -X- _ O
§ -X- _ O
3.3 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
measuring -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
cluster -X- _ O
propositions -X- _ O
( -X- _ O
that -X- _ O
were -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
documents -X- _ O
) -X- _ O
and -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
propositions -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
The -X- _ O
reference -X- _ O
summary -X- _ O
proposition -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
average -X- _ O
similarity -X- _ O
score -X- _ O
to -X- _ O
all -X- _ O
cluster -X- _ O
propositions -X- _ O
was -X- _ O
selected -X- _ O
as -X- _ O
the -X- _ O
aligned -X- _ O
summary -X- _ O
proposition -X- _ O
of -X- _ O
the -X- _ O
cluster -X- _ O
. -X- _ O
This -X- _ O
summary -X- _ O
proposition -X- _ O
was -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
target -X- _ O
output -X- _ O
for -X- _ O
training -X- _ O
the -X- _ O
generation -X- _ O
model -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
target -X- _ O
OpenIE -X- _ O
propositions -X- _ O
may -X- _ O
be -X- _ O
ungrammatical -X- _ O
or -X- _ O
non-ﬂuent -X- _ O
, -X- _ O
a -X- _ O
human -X- _ O
examination -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
BART -X- _ O
tends -X- _ O
to -X- _ O
produce -X- _ O
full -X- _ O
coherent -X- _ O
sentences -X- _ O
( -X- _ O
mostly -X- _ O
containing -X- _ O
only -X- _ O
a -X- _ O
single -X- _ O
proposition -X- _ O
) -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
was -X- _ O
ﬁnetuned -X- _ O
over -X- _ O
OpenIE -X- _ O
extractions -X- _ O
as -X- _ O
target -X- _ O
. -X- _ O
Examples -X- _ O
of -X- _ O
coherent -X- _ O
generated -X- _ O
sentences -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
we -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
a -X- _ O
BART -X- _ O
generation -X- _ O
model -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
this -X- _ O
dedicated -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
As -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
receives -X- _ O
cluster -X- _ O
propositions -X- _ O
, -X- _ O
ordered -X- _ O
by -X- _ O
their -X- _ O
predicted -X- _ O
salience -X- _ O
score -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
separated -X- _ O
with -X- _ O
special -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
ﬁnal -X- _ O
bullet -X- _ O
- -X- _ O
style -X- _ O
summary -X- _ O
is -X- _ O
produced -X- _ O
by -X- _ O
appending -X- _ O
generated -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
ranked -X- _ O
clusters -X- _ O
until -X- _ O
the -X- _ O
desired -X- _ O
word -X- _ O
- -X- _ O
limit -X- _ O
is -X- _ O
reached -X- _ O
. -X- _ O
3.6 -X- _ O
Extractive -X- _ B-TaskName
Summarization -X- _ I-TaskName
Version -X- _ O
To -X- _ O
support -X- _ O
extractive -X- _ B-TaskName
summarization -X- _ I-TaskName
settings -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
when -X- _ O
hallucination -X- _ O
is -X- _ O
forbidden -X- _ O
, -X- _ O
we -X- _ O
created -X- _ O
a -X- _ O
corresponding -X- _ O
extractive -X- _ O
version -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
version -X- _ O
, -X- _ O
we -X- _ O
extracted -X- _ O
a -X- _ O
representative -X- _ O
proposition -X- _ O
for -X- _ O
each -X- _ O
cluster -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
chosen -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
highest -X- _ O
word -X- _ O
overlap -X- _ O
with -X- _ O
the -X- _ O
sentence -X- _ O
that -X- _ O
was -X- _ O
fused -X- _ O
from -X- _ O
this -X- _ O
cluster -X- _ O
by -X- _ O
our -X- _ O
abstractive -X- _ O
version -X- _ O
. -X- _ O
4 -X- _ O
Evaluation -X- _ O
4.1 -X- _ O
Experimental -X- _ O
Setup -X- _ O
Datasets -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
our -X- _ O
summarizer -X- _ O
with -X- _ O
the -X- _ O
challenging -X- _ O
DUC -X- _ B-DatasetName
and -X- _ O
TAC -X- _ B-DatasetName
MDS -X- _ B-TaskName
benchmarks.1769 -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
following -X- _ O
standard -X- _ O
convention -X- _ O
( -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
on -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
using -X- _ O
DUC -X- _ O
2003 -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
on -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
using -X- _ O
TAC -X- _ O
2008 -X- _ O
/ -X- _ O
2009 -X- _ O
/ -X- _ O
2010 -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
These -X- _ O
sets -X- _ O
contain -X- _ O
between -X- _ O
30 -X- _ O
and -X- _ O
50 -X- _ O
topics -X- _ O
each -X- _ O
. -X- _ O
For -X- _ O
validation -X- _ O
sets -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
for -X- _ O
the -X- _ O
TAC -X- _ B-DatasetName
benchmark -X- _ O
and -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
for -X- _ O
the -X- _ O
DUC -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
Automatic -X- _ O
evaluation -X- _ O
metric -X- _ O
. -X- _ O
Following -X- _ O
common -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
and -X- _ O
compare -X- _ O
our -X- _ O
summarization -X- _ B-TaskName
system -X- _ O
with -X- _ O
ROUGE-1 -X- _ B-MetricName
/ -X- _ I-MetricName
2 -X- _ I-MetricName
/ -X- _ I-MetricName
SU4 -X- _ I-MetricName
F1 -X- _ I-MetricName
measures -X- _ O
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
Stopwords -X- _ O
are -X- _ O
not -X- _ O
removed -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
summary -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
100 -X- _ O
words -X- _ O
. -X- _ O
4.2 -X- _ O
Automatic -X- _ O
Evaluation -X- _ O
As -X- _ O
seen -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
our -X- _ O
abstractive -X- _ O
model -X- _ O
, -X- _ O
denoted -X- _ O
ProClusterfor -X- _ B-MethodName
Propositional -X- _ B-MethodName
Clustering -X- _ I-MethodName
, -X- _ O
surpasses -X- _ O
all -X- _ O
abstractive -X- _ O
baselines -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
in -X- _ O
all -X- _ O
measures -X- _ O
on -X- _ O
both -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
and -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
. -X- _ O
Moreover -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
abstractive -X- _ O
system -X- _ O
scores -X- _ O
were -X- _ O
typically -X- _ O
inferior -X- _ O
to -X- _ O
extractive -X- _ O
system -X- _ O
scores -X- _ O
, -X- _ O
ProClusternotably -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
extractive -X- _ O
baselines -X- _ O
in -X- _ O
both -X- _ O
benchmarks -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
ProClusterprovides -X- _ B-MethodName
the -X- _ O
new -X- _ O
abstractive -X- _ B-TaskName
MDS -X- _ I-TaskName
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
score -X- _ O
in -X- _ O
this -X- _ O
setting -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
4 -X- _ O
we -X- _ O
present -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
ProClustersystem -X- _ B-MethodName
summary -X- _ O
along -X- _ O
with -X- _ O
previous -X- _ O
abstractive -X- _ O
and -X- _ O
ex -X- _ O
- -X- _ O
tractive -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
system -X- _ O
summaries -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
summary -X- _ O
. -X- _ O
As -X- _ O
said -X- _ O
in -X- _ O
§ -X- _ O
3.6 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
developed -X- _ O
an -X- _ O
extractive -X- _ O
version -X- _ O
, -X- _ O
denoted -X- _ O
ProCluster -X- _ B-MethodName
. -X- _ O
As -X- _ O
ProCluster -X- _ B-MethodName
selects -X- _ O
document -X- _ O
propositions -X- _ O
that -X- _ O
have -X- _ O
the -X- _ O
highest -X- _ O
overlap -X- _ O
with -X- _ O
ProClustersentences -X- _ B-MethodName
, -X- _ O
ProCluster -X- _ B-MethodName
achieves -X- _ O
similar -X- _ O
scores -X- _ O
to -X- _ O
ProCluster -X- _ B-MethodName
, -X- _ O
yielding -X- _ O
the -X- _ O
new -X- _ O
extractive -X- _ B-TaskName
MDS -X- _ I-TaskName
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
comparison -X- _ O
we -X- _ O
selected -X- _ O
strong -X- _ O
baselines -X- _ O
, -X- _ O
including -X- _ O
previous -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
in -X- _ O
this -X- _ O
setup -X- _ O
, -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
extractive -X- _ O
and -X- _ O
abstractive -X- _ O
settings -X- _ O
. -X- _ O
See -X- _ O
in -X- _ O
Appendix -X- _ O
§ -X- _ O
C -X- _ O
for -X- _ O
more -X- _ O
concise -X- _ O
details -X- _ O
over -X- _ O
each -X- _ O
baseline -X- _ O
. -X- _ O
For -X- _ O
reference -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
present -X- _ O
a -X- _ O
proposition -X- _ O
- -X- _ O
based -X- _ O
extractive -X- _ O
upperbound -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
( -X- _ O
Oracle -X- _ B-MethodName
) -X- _ O
, -X- _ O
where -X- _ O
document -X- _ O
propositions -X- _ O
were -X- _ O
selected -X- _ O
greedily -X- _ O
to -X- _ O
maximize -X- _ O
ROUGE-1 -X- _ B-MetricName
+ -X- _ O
ROUGE-2with -X- _ B-MetricName
respect -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
4.3 -X- _ O
Ablation -X- _ O
Analysis -X- _ O
To -X- _ O
better -X- _ O
apprehend -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
steps -X- _ O
in -X- _ O
our -X- _ O
pipeline -X- _ O
, -X- _ O
Table -X- _ O
5 -X- _ O
presents -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
system -X- _ O
when -X- _ O
applying -X- _ O
partial -X- _ O
pipelines -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
Saliencegenerates -X- _ O
summaries -X- _ O
simply -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
highest -X- _ O
scoring -X- _ O
document -X- _ O
propositions -X- _ O
, -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
CDLM -X- _ O
- -X- _ O
based -X- _ O
salience -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
trained -X- _ O
the -X- _ O
salience -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
sentence- -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
proposition -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
and -X- _ O
similarly -X- _ O
generated -X- _ O
summaries -X- _ O
of -X- _ O
salient -X- _ O
sentences -X- _ O
, -X- _ O
denoted -X- _ O
Salience -X- _ O
. -X- _ O
The -X- _ O
notable -X- _ O
improvement -X- _ O
of -X- _ O
Salienceover -X- _ O
Saliencein -X- _ O
both1770 -X- _ O
datasets -X- _ O
reveals -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
working -X- _ O
at -X- _ O
the -X- _ O
proposition -X- _ O
level -X- _ O
for -X- _ O
exposing -X- _ O
salient -X- _ O
information -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
is -X- _ O
also -X- _ O
apparent -X- _ O
when -X- _ O
comparing -X- _ O
the -X- _ O
proposition -X- _ O
- -X- _ O
based -X- _ O
oracle -X- _ O
( -X- _ O
Oracle -X- _ B-MethodName
) -X- _ O
to -X- _ O
the -X- _ O
sentence -X- _ O
- -X- _ O
based -X- _ O
oracle -X- _ O
method -X- _ O
( -X- _ O
Oracle -X- _ B-MethodName
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
proposition -X- _ O
- -X- _ O
based -X- _ O
systems -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
ROUGE -X- _ B-MetricName
upperbound -X- _ O
across -X- _ O
the -X- _ O
board -X- _ O
, -X- _ O
supporting -X- _ O
its -X- _ O
merit -X- _ O
for -X- _ O
use -X- _ O
in -X- _ O
summarization -X- _ B-TaskName
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
the -X- _ O
clustering -X- _ O
step -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
applied -X- _ O
Saliencefollowed -X- _ O
by -X- _ O
clustering -X- _ O
and -X- _ O
ranking -X- _ O
of -X- _ O
clusters -X- _ O
( -X- _ O
Sections -X- _ O
3.2 -X- _ O
, -X- _ O
3.3 -X- _ O
and -X- _ O
3.4 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
leaving -X- _ O
the -X- _ O
fusion -X- _ O
step -X- _ O
aside -X- _ O
. -X- _ O
From -X- _ O
each -X- _ O
cluster -X- _ O
we -X- _ O
then -X- _ O
select -X- _ O
the -X- _ O
proposition -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
salience -X- _ O
score -X- _ O
to -X- _ O
be -X- _ O
in -X- _ O
the -X- _ O
system -X- _ O
summary -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
clustering -X- _ O
stage -X- _ O
provides -X- _ O
added -X- _ O
improvement -X- _ O
, -X- _ O
suggesting -X- _ O
its -X- _ O
contribution -X- _ O
to -X- _ O
our -X- _ O
pipeline -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
demonstrate -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
present -X- _ O
two -X- _ O
additional -X- _ O
oracle -X- _ O
scores -X- _ O
for -X- _ O
extractive -X- _ O
upperbound -X- _ O
analysis -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
examine -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
optimally -X- _ O
selecting -X- _ O
cluster -X- _ O
representatives -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
. -X- _ O
We -X- _ O
greedily -X- _ O
select -X- _ O
a -X- _ O
single -X- _ O
representative -X- _ O
per -X- _ O
cluster -X- _ O
following -X- _ O
the -X- _ O
original -X- _ O
cluster -X- _ O
ranking -X- _ O
( -X- _ O
§ -X- _ O
3.4 -X- _ O
) -X- _ O
that -X- _ O
optimizes -X- _ O
the -X- _ O
overall -X- _ O
ROUGE-1 -X- _ B-MetricName
+ -X- _ O
ROUGE-2score -X- _ B-MetricName
of -X- _ O
all -X- _ O
selected -X- _ O
representatives -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
summaries -X- _ O
( -X- _ O
Oracle -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
express -X- _ O
the -X- _ O
improvement -X- _ O
comparing -X- _ O
to -X- _ O
our -X- _ O
ﬁnal -X- _ O
model -X- _ O
( -X- _ O
ProCluster -X- _ B-MethodName
) -X- _ O
, -X- _ O
that -X- _ O
a -X- _ O
better -X- _ O
cluster -X- _ O
repre -X- _ O
- -X- _ O
sentative -X- _ O
choice -X- _ O
could -X- _ O
produce -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
up -X- _ O
to -X- _ O
~2 -X- _ B-MetricValue
R-2 -X- _ B-MetricName
points -X- _ O
in -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
and -X- _ O
~1 -X- _ B-MetricValue
point -X- _ O
in -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
. -X- _ O
Another -X- _ O
aspect -X- _ O
to -X- _ O
examine -X- _ O
is -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
enhanced -X- _ O
cluster -X- _ O
ranking -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
ﬁrst -X- _ O
selected -X- _ O
the -X- _ O
highest -X- _ O
salience -X- _ O
- -X- _ O
scoring -X- _ O
proposition -X- _ O
as -X- _ O
a -X- _ O
representative -X- _ O
from -X- _ O
each -X- _ O
cluster -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
greedily -X- _ O
selected -X- _ O
representatives -X- _ O
, -X- _ O
one -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
that -X- _ O
maximized -X- _ O
the -X- _ O
overall -X- _ O
ROUGE-1 -X- _ B-MetricName
+ -X- _ O
ROUGE2against -X- _ B-MetricName
the -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
Effectively -X- _ O
, -X- _ O
this -X- _ O
points -X- _ O
to -X- _ O
a -X- _ O
greedily -X- _ O
optimized -X- _ O
cluster -X- _ O
choice -X- _ O
( -X- _ O
Oracle -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
potential -X- _ O
improvement -X- _ O
of -X- _ O
better -X- _ O
cluster -X- _ O
ranking -X- _ O
compared -X- _ O
to -X- _ O
our -X- _ O
ﬁnal -X- _ O
model -X- _ O
( -X- _ O
ProCluster -X- _ B-MethodName
) -X- _ O
is -X- _ O
hence -X- _ O
up -X- _ O
to -X- _ O
~5 -X- _ B-MetricValue
R-2 -X- _ B-MetricName
points -X- _ O
in -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
and -X- _ O
~3 -X- _ B-MetricValue
points -X- _ O
in -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
. -X- _ O
Indeed -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
leaves -X- _ O
cluster -X- _ O
ranking -X- _ O
improvement -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
all -X- _ O
components -X- _ O
of -X- _ O
our -X- _ O
multi -X- _ O
- -X- _ O
step -X- _ O
approach -X- _ O
are -X- _ O
indeed -X- _ O
effective -X- _ O
for -X- _ O
MDS -X- _ B-TaskName
, -X- _ O
and -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
great -X- _ O
potential -X- _ O
for -X- _ O
further -X- _ O
improvements -X- _ O
within -X- _ O
this -X- _ O
architecture -X- _ O
. -X- _ O
4.4 -X- _ O
Human -X- _ O
Evaluation -X- _ O
We -X- _ O
further -X- _ O
assessed -X- _ O
our -X- _ O
primary -X- _ O
system -X- _ O
, -X- _ O
ProCluster -X- _ B-MethodName
, -X- _ O
through -X- _ O
manual -X- _ O
comparison -X- _ O
against -X- _ O
PG -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
and -X- _ O
RL -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
, -X- _ O
which -X- _ O
are -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
MDS -X- _ B-TaskName
systems -X- _ O
in -X- _ O
the -X- _ O
abstractive -X- _ O
and -X- _ O
extractive -X- _ O
settings -X- _ O
( -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O
Crowdworkers -X- _ O
on -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turkwere -X- _ O
shown -X- _ O
the1771 -X- _ O
summaries -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
topic -X- _ O
from -X- _ O
the -X- _ O
three -X- _ O
systems -X- _ O
in -X- _ O
arbitrary -X- _ O
order -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
corresponding -X- _ O
reference -X- _ O
summary -X- _ O
. -X- _ O
They -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
systems -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
Content -X- _ O
( -X- _ O
content -X- _ O
overlap -X- _ O
with -X- _ O
the -X- _ O
reference -X- _ O
) -X- _ O
, -X- _ O
Readability -X- _ O
( -X- _ O
the -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
a -X- _ O
summary -X- _ O
is -X- _ O
readable -X- _ O
and -X- _ O
well -X- _ O
- -X- _ O
understood -X- _ O
) -X- _ O
, -X- _ O
Grammaticality -X- _ O
( -X- _ O
avoiding -X- _ O
grammar -X- _ O
errors -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Non -X- _ O
- -X- _ O
Redundancy -X- _ O
( -X- _ O
avoiding -X- _ O
information -X- _ O
repetition -X- _ O
) -X- _ O
. -X- _ O
Focusing -X- _ O
on -X- _ O
evaluating -X- _ O
our -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
from -X- _ O
this -X- _ O
ranking -X- _ O
a -X- _ O
pairwise -X- _ O
comparison -X- _ O
between -X- _ O
our -X- _ O
ProClusterand -X- _ B-MethodName
each -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
baseline -X- _ O
systems -X- _ O
, -X- _ O
separately -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
topic -X- _ O
, -X- _ O
this -X- _ O
procedure -X- _ O
was -X- _ O
repeated -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
available -X- _ O
reference -X- _ O
summaries -X- _ O
. -X- _ O
Each -X- _ O
such -X- _ O
evaluation -X- _ O
instance -X- _ O
was -X- _ O
judged -X- _ O
independently -X- _ O
by -X- _ O
three -X- _ O
workers -X- _ O
, -X- _ O
taking -X- _ O
their -X- _ O
majority -X- _ O
vote -X- _ O
for -X- _ O
each -X- _ O
pairwise -X- _ O
comparison -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
these -X- _ O
pairwise -X- _ O
comparisons -X- _ O
, -X- _ O
showing -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
cases -X- _ O
in -X- _ O
which -X- _ O
our -X- _ O
system -X- _ O
was -X- _ O
preferred -X- _ O
over -X- _ O
each -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
baselines -X- _ O
, -X- _ O
under -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
evaluation -X- _ O
criteria -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
was -X- _ O
favored -X- _ O
in -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
for -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
preference -X- _ O
is -X- _ O
almost -X- _ O
always -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
Non -X- _ O
- -X- _ O
Redundancy -X- _ O
against -X- _ O
RL -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
, -X- _ O
which -X- _ O
avoids -X- _ O
redundancy -X- _ O
at -X- _ O
a -X- _ O
similar -X- _ O
success -X- _ O
level -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
as -X- _ O
our -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
method -X- _ O
is -X- _ O
focused -X- _ O
on -X- _ O
improving -X- _ O
content -X- _ O
selection -X- _ O
, -X- _ O
the -X- _ O
large -X- _ O
gap -X- _ O
in -X- _ O
favor -X- _ O
of -X- _ O
ProClusterin -X- _ B-MethodName
the -X- _ O
content -X- _ O
criterion -X- _ O
supports -X- _ O
its -X- _ O
advantage -X- _ O
, -X- _ O
consistently -X- _ O
with -X- _ O
our -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ O
score -X- _ O
advantage -X- _ O
in -X- _ O
the -X- _ O
automatic -X- _ O
evaluation -X- _ O
( -X- _ O
§ -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
our -X- _ O
summaries -X- _ O
are -X- _ O
( -X- _ O
somewhat -X- _ O
nonconventionally -X- _ O
) -X- _ O
structured -X- _ O
as -X- _ O
bullet -X- _ O
- -X- _ O
style -X- _ O
lists -X- _ O
of -X- _ O
propositions -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
coherent -X- _ O
paragraph -X- _ O
, -X- _ O
evaluators -X- _ O
preferred -X- _ O
our -X- _ O
style -X- _ O
of -X- _ O
summarization -X- _ B-TaskName
in -X- _ O
terms -X- _ O
of -X- _ O
readability -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
as -X- _ O
Table -X- _ O
7 -X- _ O
points -X- _ O
out -X- _ O
, -X- _ O
ProClusterappears -X- _ B-MethodName
to -X- _ O
be -X- _ O
more -X- _ O
abstractive -X- _ O
than -X- _ O
PG -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
, -X- _ O
as -X- _ O
suggested -X- _ O
by -X- _ O
the -X- _ O
reduced -X- _ O
ngram -X- _ O
and -X- _ O
sentence -X- _ O
overlap -X- _ O
with -X- _ O
source -X- _ O
documents -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
about -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
system -X- _ O
summary -X- _ O
sentences -X- _ O
of -X- _ O
PG -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
are -X- _ O
fully -X- _ O
copied -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
about -X- _ O
a -X- _ O
quarter -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
intensiﬁed -X- _ O
abstractiveness -X- _ O
of -X- _ O
our -X- _ O
summaries -X- _ O
could -X- _ O
have -X- _ O
potentially -X- _ O
hindered -X- _ O
readability -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
was -X- _ O
nevertheless -X- _ O
preferred -X- _ O
along -X- _ O
this -X- _ O
aspect -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
leaves -X- _ O
fertile -X- _ O
ground -X- _ O
for -X- _ O
further -X- _ O
improving -X- _ O
readability -X- _ O
by -X- _ O
fusing -X- _ O
several -X- _ O
clusters -X- _ O
together -X- _ O
to -X- _ O
generate -X- _ O
sentences -X- _ O
containing -X- _ O
multiple -X- _ O
propositions -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
developing -X- _ O
sentence -X- _ O
planning -X- _ O
and -X- _ O
ordering -X- _ O
models -X- _ O
. -X- _ O
Compatible -X- _ O
training -X- _ O
datasets -X- _ O
for -X- _ O
these -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
derived -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
gold -X- _ O
reference -X- _ O
summaries -X- _ O
, -X- _ O
as -X- _ O
was -X- _ O
done -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
for -X- _ O
the -X- _ O
salience -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
and -X- _ O
fusion -X- _ O
( -X- _ O
§ -X- _ O
3.5 -X- _ O
) -X- _ O
models.17725 -X- _ O
Paraphrastic -X- _ O
Clusters -X- _ O
as -X- _ O
Summary -X- _ O
Evidence -X- _ O
A -X- _ O
unique -X- _ O
advantage -X- _ O
of -X- _ O
a -X- _ O
cluster -X- _ O
- -X- _ O
based -X- _ O
summary -X- _ O
is -X- _ O
that -X- _ O
each -X- _ O
summary -X- _ O
sentence -X- _ O
is -X- _ O
linked -X- _ O
explicitly -X- _ O
to -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
propositions -X- _ O
from -X- _ O
which -X- _ O
the -X- _ O
sentence -X- _ O
was -X- _ O
generated -X- _ O
, -X- _ O
in -X- _ O
so -X- _ O
providing -X- _ O
an -X- _ O
“ -X- _ O
explanation -X- _ O
” -X- _ O
, -X- _ O
or -X- _ O
support -X- _ O
evidence -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
These -X- _ O
cluster -X- _ O
explanations -X- _ O
can -X- _ O
expand -X- _ O
the -X- _ O
reader -X- _ O
’s -X- _ O
knowledge -X- _ O
and -X- _ O
provide -X- _ O
complementary -X- _ O
facts -X- _ O
from -X- _ O
the -X- _ O
nearby -X- _ O
source -X- _ O
context -X- _ O
regarding -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
generated -X- _ O
sentence -X- _ O
. -X- _ O
Such -X- _ O
a -X- _ O
feature -X- _ O
may -X- _ O
be -X- _ O
incorporated -X- _ O
in -X- _ O
interactive -X- _ O
summarization -X- _ B-TaskName
systems -X- _ O
, -X- _ O
as -X- _ O
applied -X- _ O
in -X- _ O
( -X- _ O
Shapira -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
user -X- _ O
can -X- _ O
choose -X- _ O
to -X- _ O
expand -X- _ O
on -X- _ O
the -X- _ O
facts -X- _ O
within -X- _ O
a -X- _ O
sentence -X- _ O
of -X- _ O
the -X- _ O
presented -X- _ O
summary -X- _ O
. -X- _ O
To -X- _ O
assess -X- _ O
the -X- _ O
reliability -X- _ O
of -X- _ O
such -X- _ O
feature -X- _ O
, -X- _ O
we -X- _ O
veriﬁed -X- _ O
that -X- _ O
clusters -X- _ O
indeed -X- _ O
“ -X- _ O
explain -X- _ O
” -X- _ O
their -X- _ O
generated -X- _ O
sentences -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
a -X- _ O
crowdsourced -X- _ O
annotation -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
worker -X- _ O
marked -X- _ O
whether -X- _ O
a -X- _ O
cluster -X- _ O
proposition -X- _ O
mentions -X- _ O
the -X- _ O
main -X- _ O
idea -X- _ O
of -X- _ O
its -X- _ O
corresponding -X- _ O
generated -X- _ O
sentence -X- _ O
. -X- _ O
Each -X- _ O
pair -X- _ O
was -X- _ O
examined -X- _ O
by -X- _ O
three -X- _ O
workers -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
majority -X- _ O
vote -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
ﬁnal -X- _ O
decision -X- _ O
. -X- _ O
On -X- _ O
a -X- _ O
random -X- _ O
selection -X- _ O
of -X- _ O
25 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
clusters -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
, -X- _ O
on -X- _ O
average -X- _ O
, -X- _ O
89 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
84 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
a -X- _ O
cluster -X- _ O
’s -X- _ O
propositions -X- _ O
in -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
and -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
support -X- _ O
their -X- _ O
corresponding -X- _ O
generated -X- _ O
sentence -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
cluster -X- _ O
size -X- _ O
of -X- _ O
3.4 -X- _ O
and -X- _ O
4.8 -X- _ O
propositions -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
given -X- _ O
this -X- _ O
strong -X- _ O
alignment -X- _ O
of -X- _ O
a -X- _ O
cluster -X- _ O
to -X- _ O
its -X- _ O
generated -X- _ O
sentence -X- _ O
, -X- _ O
a -X- _ O
cluster -X- _ O
facilitates -X- _ O
effective -X- _ O
veriﬁcation -X- _ O
of -X- _ O
faithfulness -X- _ O
of -X- _ O
its -X- _ O
corresponding -X- _ O
generated -X- _ O
abstractive -X- _ O
sentence -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
output -X- _ O
sentence -X- _ O
is -X- _ O
based -X- _ O
solely -X- _ O
on -X- _ O
its -X- _ O
cluster -X- _ O
propositions -X- _ O
, -X- _ O
the -X- _ O
sentence -X- _ O
’s -X- _ O
correctness -X- _ O
can -X- _ O
be -X- _ O
veriﬁed -X- _ O
against -X- _ O
the -X- _ O
“ -X- _ O
explaining -X- _ O
" -X- _ O
cluster -X- _ O
instead -X- _ O
of -X- _ O
against -X- _ O
the -X- _ O
full -X- _ O
document -X- _ O
set -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
of -X- _ O
an -X- _ O
unfaithful -X- _ O
abstraction -X- _ O
is -X- _ O
marked -X- _ O
in -X- _ O
red -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
ﬁrst -X- _ O
attempt -X- _ O
for -X- _ O
efﬁcient -X- _ O
manual -X- _ O
assessment -X- _ O
of -X- _ O
faithfulness -X- _ O
in -X- _ O
MDS -X- _ B-MethodName
. -X- _ O
We -X- _ O
conducted -X- _ O
a -X- _ O
respective -X- _ O
evaluation -X- _ O
process -X- _ O
, -X- _ O
through -X- _ O
crowdsourcing -X- _ O
, -X- _ O
to -X- _ O
assess -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
summaries -X- _ O
. -X- _ O
A -X- _ O
worker -X- _ O
saw -X- _ O
a -X- _ O
cluster -X- _ O
and -X- _ O
its -X- _ O
generated -X- _ O
sentence -X- _ O
and -X- _ O
marked -X- _ O
whether -X- _ O
the -X- _ O
sentence -X- _ O
was -X- _ O
faithful -X- _ O
to -X- _ O
its -X- _ O
origin -X- _ O
cluster -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
this -X- _ O
task -X- _ O
cost -X- _ O
a -X- _ O
reasonable -X- _ O
price -X- _ O
of -X- _ O
240 -X- _ O
$ -X- _ O
for -X- _ O
both -X- _ O
the -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
and -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
datasets -X- _ O
together -X- _ O
. -X- _ O
Over -X- _ O
the -X- _ O
full -X- _ O
test -X- _ O
sets -X- _ O
, -X- _ O
the -X- _ O
annotations -X- _ O
showed -X- _ O
that -X- _ O
80 -X- _ O
% -X- _ O
and -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
and -X- _ O
TAC -X- _ B-DatasetName
2011 -X- _ I-DatasetName
summary -X- _ O
sentences -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
were -X- _ O
faithful -X- _ O
to -X- _ O
their -X- _ O
corresponding -X- _ O
clusters.6 -X- _ O
Conclusion -X- _ O
We -X- _ O
advocate -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
proposition -X- _ O
- -X- _ O
level -X- _ O
units -X- _ O
as -X- _ O
a -X- _ O
cleaner -X- _ O
and -X- _ O
more -X- _ O
accurate -X- _ O
unit -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
new -X- _ O
propositionlevel -X- _ O
pipeline -X- _ O
for -X- _ O
summarization -X- _ B-TaskName
that -X- _ O
includes -X- _ O
an -X- _ O
accurate -X- _ O
paraphrastic -X- _ O
propositional -X- _ O
clustering -X- _ O
component -X- _ O
followed -X- _ O
by -X- _ O
fusion -X- _ O
of -X- _ O
cluster -X- _ O
propositions -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
concise -X- _ O
and -X- _ O
coherent -X- _ O
summary -X- _ O
sentences -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
method -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
ofthe -X- _ O
- -X- _ O
art -X- _ O
baselines -X- _ O
in -X- _ O
both -X- _ O
automatic -X- _ O
and -X- _ O
human -X- _ O
evaluation -X- _ O
on -X- _ O
the -X- _ O
DUC -X- _ B-DatasetName
and -X- _ O
TAC -X- _ B-DatasetName
MDS -X- _ B-TaskName
benchmarks -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
that -X- _ O
indicates -X- _ O
the -X- _ O
beneﬁt -X- _ O
of -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
pipeline -X- _ O
steps -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
potential -X- _ O
for -X- _ O
future -X- _ O
improvement -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
demonstrate -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
the -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
for -X- _ O
providing -X- _ O
source -X- _ O
documents -X- _ O
explanations -X- _ O
and -X- _ O
for -X- _ O
manually -X- _ O
validating -X- _ O
summary -X- _ O
faithfulness -X- _ O
. -X- _ O
Acknowledgments -X- _ O
The -X- _ O
work -X- _ O
described -X- _ O
herein -X- _ O
was -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
PBC -X- _ O
fellowship -X- _ O
for -X- _ O
outstanding -X- _ O
PhD -X- _ O
candidates -X- _ O
in -X- _ O
data -X- _ O
science -X- _ O
, -X- _ O
Intel -X- _ O
Labs -X- _ O
, -X- _ O
the -X- _ O
Israel -X- _ O
Science -X- _ O
Foundation -X- _ O
grant -X- _ O
2827 -X- _ O
/ -X- _ O
21 -X- _ O
, -X- _ O
and -X- _ O
by -X- _ O
a -X- _ O
grant -X- _ O
from -X- _ O
the -X- _ O
Israel -X- _ O
Ministry -X- _ O
of -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
. -X- _ O
Ethical -X- _ O
Considerations -X- _ O
Computation -X- _ O
. -X- _ O
We -X- _ O
ran -X- _ O
on -X- _ O
3 -X- _ O
GPUs -X- _ O
for -X- _ O
20 -X- _ O
minutes -X- _ O
to -X- _ O
ﬁnteune -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
salience -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
fusion -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
summarization -X- _ B-TaskName
model -X- _ O
runs -X- _ O
10 -X- _ O
minutes -X- _ O
on -X- _ O
4 -X- _ O
GPUs -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
summary -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
is -X- _ O
spent -X- _ O
on -X- _ O
the -X- _ O
clustering -X- _ O
step -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
SuperPAL -X- _ O
similarity -X- _ O
score -X- _ O
between -X- _ O
all -X- _ O
salient -X- _ O
proposition -X- _ O
pairs -X- _ O
. -X- _ O
Dataset -X- _ O
. -X- _ O
The -X- _ O
DUC -X- _ B-DatasetName
2003 -X- _ O
and -X- _ O
2004 -X- _ O
and -X- _ O
TAC -X- _ B-DatasetName
2008 -X- _ O
- -X- _ O
2011 -X- _ O
datasets -X- _ O
were -X- _ O
acquired -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
required -X- _ O
NIST -X- _ O
guidelines -X- _ O
( -X- _ O
) -X- _ O
. -X- _ O
Crowdsourcing -X- _ O
. -X- _ O
All -X- _ O
human -X- _ O
annotations -X- _ O
and -X- _ O
evaluations -X- _ O
conducted -X- _ O
with -X- _ O
crowdsourcing -X- _ O
were -X- _ O
compensated -X- _ O
as -X- _ O
a -X- _ O
12 -X- _ O
$ -X- _ O
per -X- _ O
hour -X- _ O
wage -X- _ O
. -X- _ O
We -X- _ O
estimated -X- _ O
the -X- _ O
task -X- _ O
payment -X- _ O
by -X- _ O
completing -X- _ O
sample -X- _ O
assignments -X- _ O
and -X- _ O
obtaining -X- _ O
the -X- _ O
average -X- _ O
assignment -X- _ O
time -X- _ O
. -X- _ O
References177317741775 -X- _ O
A -X- _ O
Data -X- _ O
Statistics -X- _ O
B -X- _ O
Implementation -X- _ O
Details -X- _ O
B.1 -X- _ O
Proposition -X- _ O
Salience -X- _ O
Model -X- _ O
Datasets -X- _ O
. -X- _ O
For -X- _ O
many -X- _ O
previous -X- _ O
summarization -X- _ B-TaskName
systems -X- _ O
these -X- _ O
benchmarks -X- _ O
were -X- _ O
insufﬁciently -X- _ O
large -X- _ O
enough -X- _ O
for -X- _ O
training -X- _ O
their -X- _ O
models -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
they -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
scale -X- _ O
summarizationdataset -X- _ B-TaskName
, -X- _ O
such -X- _ O
as -X- _ O
CNN -X- _ O
/ -X- _ O
DailyMail -X- _ O
( -X- _ O
Hermann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
ﬁnetuned -X- _ O
on -X- _ O
DUC -X- _ B-DatasetName
/ -X- _ O
TAC -X- _ B-DatasetName
datasets -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Lebanoff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
avoid -X- _ O
external -X- _ O
sources -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
DUC -X- _ B-DatasetName
training -X- _ O
data -X- _ O
is -X- _ O
much -X- _ O
smaller -X- _ O
than -X- _ O
TAC -X- _ B-DatasetName
’s -X- _ O
( -X- _ O
30 -X- _ O
topics -X- _ O
vs. -X- _ O
138 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
was -X- _ O
apparently -X- _ O
too -X- _ O
small -X- _ O
for -X- _ O
the -X- _ O
salience -X- _ O
model -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
adopted -X- _ O
the -X- _ O
trained -X- _ O
salience -X- _ O
model -X- _ O
for -X- _ O
TAC -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
that -X- _ O
was -X- _ O
trained -X- _ O
with -X- _ O
TAC -X- _ O
2008 -X- _ O
- -X- _ O
2010 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
pretrained -X- _ O
model -X- _ O
and -X- _ O
then -X- _ O
ﬁnetuned -X- _ O
it -X- _ O
with -X- _ O
DUC -X- _ O
2003 -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
validating -X- _ O
the -X- _ O
TAC -X- _ B-DatasetName
benchmark -X- _ O
using -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
during -X- _ O
the -X- _ O
salience -X- _ O
model -X- _ O
training -X- _ O
causes -X- _ O
data -X- _ O
leakage -X- _ O
since -X- _ O
this -X- _ O
model -X- _ O
is -X- _ O
later -X- _ O
ﬁnetuned -X- _ O
to -X- _ O
test -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
. -X- _ O
To -X- _ O
avoid -X- _ O
that -X- _ O
, -X- _ O
during -X- _ O
the -X- _ O
salience -X- _ O
model -X- _ O
training -X- _ O
we -X- _ O
used -X- _ O
part -X- _ O
of -X- _ O
TAC -X- _ O
2010 -X- _ O
that -X- _ O
was -X- _ O
omitted -X- _ O
from -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
( -X- _ O
instead -X- _ O
of -X- _ O
DUC -X- _ B-DatasetName
2004 -X- _ I-DatasetName
) -X- _ O
. -X- _ O
Training -X- _ O
Parameters -X- _ O
. -X- _ O
We -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
10 -X- _ O
epochs -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-HyperparameterValue
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
6 -X- _ B-HyperparameterValue
instances -X- _ O
on -X- _ O
3 -X- _ O
V100 -X- _ O
GPUs -X- _ O
( -X- _ O
meaning -X- _ O
effective -X- _ O
batch -X- _ O
size -X- _ O
was -X- _ O
18 -X- _ O
) -X- _ O
. -X- _ O
Training -X- _ O
. -X- _ O
The -X- _ O
CDLM -X- _ O
model -X- _ O
is -X- _ O
fed -X- _ O
with -X- _ O
a -X- _ O
proposition -X- _ O
within -X- _ O
its -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
documents -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
since -X- _ O
CDLM -X- _ O
’s -X- _ O
input -X- _ O
size -X- _ O
is -X- _ O
limited -X- _ O
to -X- _ O
4,096 -X- _ O
tokens -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
infeasible -X- _ O
to -X- _ O
feed -X- _ O
the -X- _ O
full -X- _ O
document -X- _ O
set -X- _ O
as -X- _ O
a -X- _ O
long -X- _ O
sequence -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
following -X- _ O
Lebanoff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
only -X- _ O
the -X- _ O
ﬁrst -X- _ O
20 -X- _ O
sentences -X- _ O
of -X- _ O
each -X- _ O
document -X- _ O
are -X- _ O
considered -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
a -X- _ O
candidate -X- _ O
proposition -X- _ O
is -X- _ O
input -X- _ O
within -X- _ O
its -X- _ O
full -X- _ O
document -X- _ O
( -X- _ O
up -X- _ O
to -X- _ O
20 -X- _ O
sentences -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
other -X- _ O
documents -X- _ O
, -X- _ O
ordered -X- _ O
by -X- _ O
their -X- _ O
date -X- _ O
, -X- _ O
are -X- _ O
truncated -X- _ O
evenly -X- _ O
and -X- _ O
concatenated -X- _ O
to -X- _ O
ﬁll -X- _ O
the -X- _ O
remaining -X- _ O
space -X- _ O
( -X- _ O
9 -X- _ O
sentences -X- _ O
per -X- _ O
document -X- _ O
on -X- _ O
average -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
instance -X- _ O
contains -X- _ O
a -X- _ O
proposition -X- _ O
marked -X- _ O
with -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
special -X- _ O
tokens -X- _ O
, -X- _ O
within -X- _ O
its -X- _ O
multiple -X- _ O
document -X- _ O
context -X- _ O
. -X- _ O
A -X- _ O
discontinuous -X- _ O
proposition -X- _ O
is -X- _ O
marked -X- _ O
with -X- _ O
special -X- _ O
tokens -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
each -X- _ O
of -X- _ O
its -X- _ O
parts -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
sentence -X- _ O
special -X- _ O
token -X- _ O
separators -X- _ O
and -X- _ O
document -X- _ O
special -X- _ O
token -X- _ O
separators -X- _ O
are -X- _ O
used -X- _ O
, -X- _ O
as -X- _ O
required -X- _ O
for -X- _ O
CDLM -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
reduce -X- _ O
computation -X- _ O
complexity -X- _ O
, -X- _ O
CDLM -X- _ O
uses -X- _ O
“ -X- _ O
local -X- _ O
attention -X- _ O
" -X- _ O
( -X- _ O
of -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ O
) -X- _ O
for -X- _ O
all -X- _ O
tokens -X- _ O
, -X- _ O
while -X- _ O
speciﬁc -X- _ O
tokens -X- _ O
are -X- _ O
attended -X- _ O
to -X- _ O
all -X- _ O
4096 -X- _ B-HyperparameterValue
tokens -X- _ O
( -X- _ O
“ -X- _ O
global -X- _ O
attention -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
assigned -X- _ O
global -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
CLS -X- _ O
token -X- _ O
and -X- _ O
to -X- _ O
the -X- _ O
candidate -X- _ O
proposition -X- _ O
tokens -X- _ O
, -X- _ O
including -X- _ O
their -X- _ O
special -X- _ O
tokens -X- _ O
. -X- _ O
For -X- _ O
classiﬁcation -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
added -X- _ O
a -X- _ O
binary -X- _ O
classiﬁer -X- _ O
layer -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
our -X- _ O
CDLM -X- _ O
. -X- _ O
The -X- _ O
classiﬁcation -X- _ O
layer -X- _ O
gets -X- _ O
the -X- _ O
CDLM -X- _ O
’s -X- _ O
CLS -X- _ O
output -X- _ O
representation1776 -X- _ O
concatenated -X- _ O
to -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
CDLM -X- _ O
output -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
proposition -X- _ O
tokens -X- _ O
: -X- _ O
CLS⊙ -X- _ O
/ -X- _ O
summationdisplayT -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
where -X- _ O
Tis -X- _ O
the -X- _ O
CDLM -X- _ O
output -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
Prop -X- _ O
contains -X- _ O
the -X- _ O
token -X- _ O
indices -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
proposition -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
proposition -X- _ O
salience -X- _ O
training -X- _ O
dataset -X- _ O
contains -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
positive -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
salient -X- _ O
) -X- _ O
propositions -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
all -X- _ O
propositions -X- _ O
, -X- _ O
it -X- _ O
creates -X- _ O
an -X- _ O
unbalanced -X- _ O
dataset -X- _ O
that -X- _ O
may -X- _ O
strongly -X- _ O
bias -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
give -X- _ O
a -X- _ O
negative -X- _ O
prediction -X- _ O
. -X- _ O
To -X- _ O
cope -X- _ O
with -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
ﬁlter -X- _ O
out -X- _ O
60 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
salient -X- _ O
propositions -X- _ O
, -X- _ O
while -X- _ O
over -X- _ O
sampling -X- _ O
salient -X- _ O
propositions -X- _ O
until -X- _ O
the -X- _ O
dataset -X- _ O
becomes -X- _ O
balanced -X- _ O
. -X- _ O
B.2 -X- _ O
SuperPAL -X- _ O
Usage -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
SuperPAL -X- _ O
model -X- _ O
( -X- _ O
Ernst -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
similarity -X- _ O
metric -X- _ O
between -X- _ O
propositions -X- _ O
for -X- _ O
the -X- _ O
clustering -X- _ O
step -X- _ O
( -X- _ O
§ -X- _ O
3.3 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
create -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
fusion -X- _ O
model -X- _ O
( -X- _ O
§ -X- _ O
3.5 -X- _ O
) -X- _ O
. -X- _ O
Originally -X- _ O
, -X- _ O
SuperPAL -X- _ O
was -X- _ O
tuned -X- _ O
with -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
that -X- _ O
contains -X- _ O
three -X- _ O
topics -X- _ O
from -X- _ O
DUC -X- _ O
2004 -X- _ O
( -X- _ O
taken -X- _ O
from -X- _ O
the -X- _ O
full -X- _ O
validation -X- _ O
set -X- _ O
which -X- _ O
also -X- _ O
contains -X- _ O
7 -X- _ O
additional -X- _ O
topics -X- _ O
, -X- _ O
not -X- _ O
from -X- _ O
DUC -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
setting -X- _ O
, -X- _ O
it -X- _ O
may -X- _ O
cause -X- _ O
leakage -X- _ O
since -X- _ O
DUC -X- _ O
2004 -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
such -X- _ O
leakage -X- _ O
, -X- _ O
we -X- _ O
tuned -X- _ O
SuperPAL -X- _ O
again -X- _ O
without -X- _ O
using -X- _ O
DUC -X- _ O
2004 -X- _ O
topics -X- _ O
at -X- _ O
all -X- _ O
( -X- _ O
using -X- _ O
the -X- _ O
other -X- _ O
7 -X- _ O
topics -X- _ O
as -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
) -X- _ O
. -X- _ O
B.3 -X- _ O
Cluster -X- _ O
Ranking -X- _ O
For -X- _ O
computation -X- _ O
time -X- _ O
consideration -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
a -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
clusters -X- _ O
to -X- _ O
be -X- _ O
selected -X- _ O
for -X- _ O
each -X- _ O
topic -X- _ O
. -X- _ O
Since -X- _ O
in -X- _ O
most -X- _ O
topics -X- _ O
the -X- _ O
100 -X- _ O
- -X- _ O
word -X- _ O
limit -X- _ O
isexceeded -X- _ O
after -X- _ O
8 -X- _ O
- -X- _ O
10 -X- _ O
propositional -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
clusters -X- _ I-HyperparameterName
to -X- _ O
10 -X- _ B-HyperparameterValue
. -X- _ O
Accordingly -X- _ O
, -X- _ O
the -X- _ O
10 -X- _ B-HyperparameterValue
( -X- _ O
or -X- _ O
fewer -X- _ O
) -X- _ O
highest -X- _ O
ranked -X- _ O
clusters -X- _ O
are -X- _ O
selected -X- _ O
for -X- _ O
the -X- _ O
summary -X- _ O
of -X- _ O
each -X- _ O
topic -X- _ O
. -X- _ O
B.4 -X- _ O
Fusion -X- _ O
Model -X- _ O
Training -X- _ O
Parameters -X- _ O
. -X- _ O
We -X- _ O
trained -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e-5 -X- _ B-HyperparameterValue
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
instances -X- _ O
on -X- _ O
3 -X- _ O
V100 -X- _ O
GPUs -X- _ O
( -X- _ O
meaning -X- _ O
effective -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
30 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
C -X- _ O
Compared -X- _ O
Methods -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
several -X- _ O
strong -X- _ O
abstractivebaselines -X- _ O
: -X- _ O
Opinosis -X- _ B-MethodName
( -X- _ O
Ganesan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
generates -X- _ O
abstracts -X- _ O
from -X- _ O
salient -X- _ O
paths -X- _ O
in -X- _ O
a -X- _ O
word -X- _ O
cooccurrence -X- _ O
graph -X- _ O
; -X- _ O
Extract+Rewrite -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
selects -X- _ O
sentences -X- _ O
using -X- _ O
LexRank -X- _ O
and -X- _ O
generates -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
a -X- _ O
title -X- _ O
- -X- _ O
like -X- _ O
summary -X- _ O
; -X- _ O
PG -X- _ B-MethodName
( -X- _ O
See -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
runs -X- _ O
a -X- _ O
Pointer -X- _ B-MethodName
- -X- _ I-MethodName
Generator -X- _ I-MethodName
model -X- _ O
that -X- _ O
includes -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
network -X- _ O
with -X- _ O
a -X- _ O
copy -X- _ O
- -X- _ O
mechanism -X- _ O
; -X- _ O
PG -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
( -X- _ O
Lebanoff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
selects -X- _ O
representative -X- _ O
sentences -X- _ O
with -X- _ O
MMR -X- _ O
( -X- _ O
Carbonell -X- _ O
and -X- _ O
Goldstein -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
and -X- _ O
fuses -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
PG -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
; -X- _ O
Hi -X- _ B-MethodName
- -X- _ I-MethodName
MAP -X- _ I-MethodName
( -X- _ O
Fabbri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
hierarchical -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
PG -X- _ O
model -X- _ O
that -X- _ O
allows -X- _ O
calculating -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
MMR -X- _ O
scores -X- _ O
; -X- _ O
MDS -X- _ B-MethodName
- -X- _ I-MethodName
Joint -X- _ I-MethodName
- -X- _ I-MethodName
SDS -X- _ I-MethodName
( -X- _ O
Jin -X- _ O
and -X- _ O
Wan -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
hierarchical -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
architecture -X- _ O
that -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
SDS -X- _ O
and -X- _ O
MDS -X- _ O
datasets -X- _ O
while -X- _ O
preserving -X- _ O
document -X- _ O
boundaries -X- _ O
. -X- _ O
We -X- _ O
additionally -X- _ O
compare -X- _ O
to -X- _ O
several -X- _ O
strong -X- _ O
extractive -X- _ O
baselines -X- _ O
: -X- _ O
SumBasic -X- _ B-MethodName
( -X- _ O
Vanderwende -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
extracts -X- _ O
phrases -X- _ O
with -X- _ O
words -X- _ O
that -X- _ O
appear -X- _ O
frequently -X- _ O
in -X- _ O
the -X- _ O
documents -X- _ O
; -X- _ O
KLSumm -X- _ B-MethodName
( -X- _ O
Haghighi -X- _ O
and -X- _ O
Vanderwende -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
extracts -X- _ O
sentences -X- _ O
that -X- _ O
opti-1777mize -X- _ O
KL -X- _ O
- -X- _ O
divergence -X- _ O
; -X- _ O
LexRank -X- _ B-MethodName
( -X- _ O
Erkan -X- _ O
and -X- _ O
Radev -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
where -X- _ O
vertices -X- _ O
represent -X- _ O
sentences -X- _ O
, -X- _ O
the -X- _ O
edges -X- _ O
stand -X- _ O
for -X- _ O
word -X- _ O
overlap -X- _ O
between -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
sentence -X- _ O
importance -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
eigenvector -X- _ O
centrality -X- _ O
; -X- _ O
DPP -X- _ B-MethodName
- -X- _ I-MethodName
CapsComb -X- _ I-MethodName
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
balances -X- _ O
between -X- _ O
salient -X- _ O
sentence -X- _ O
extraction -X- _ O
and -X- _ O
redundancy -X- _ O
avoidance -X- _ O
by -X- _ O
optimizing -X- _ O
determinantal -X- _ O
point -X- _ O
processes -X- _ O
( -X- _ O
DPP -X- _ O
) -X- _ O
; -X- _ O
HL -X- _ B-MethodName
- -X- _ I-MethodName
XLNetSegs -X- _ I-MethodName
andHL -X- _ B-MethodName
- -X- _ I-MethodName
TreeSegs -X- _ I-MethodName
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
are -X- _ O
two -X- _ O
versions -X- _ O
of -X- _ O
a -X- _ O
DPP -X- _ O
- -X- _ O
based -X- _ O
span -X- _ O
highlighting -X- _ O
approach -X- _ O
that -X- _ O
heuristically -X- _ O
extracts -X- _ O
candidate -X- _ O
spans -X- _ O
by -X- _ O
their -X- _ O
probability -X- _ O
to -X- _ O
begin -X- _ O
and -X- _ O
end -X- _ O
with -X- _ O
an -X- _ O
EOS -X- _ O
token -X- _ O
; -X- _ O
RL -X- _ B-MethodName
- -X- _ I-MethodName
MMR -X- _ I-MethodName
( -X- _ O
Mao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
adapts -X- _ O
a -X- _ O
neural -X- _ O
reinforcement -X- _ O
learning -X- _ O
single -X- _ O
document -X- _ O
summarization -X- _ B-TaskName
( -X- _ O
SDS -X- _ O
) -X- _ O
approach -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
document -X- _ O
setup -X- _ O
and -X- _ O
integrates -X- _ O
Maximal -X- _ O
Margin -X- _ O
Relevance -X- _ O
( -X- _ O
MMR -X- _ O
) -X- _ O
to -X- _ O
avoid -X- _ O
redundancy -X- _ O
. -X- _ O
D -X- _ O
Annotation -X- _ O
Guidelines -X- _ O
We -X- _ O
used -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turkfor -X- _ O
all -X- _ O
three -X- _ O
crowdsource -X- _ O
tasks -X- _ O
with -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
90 -X- _ O
pre -X- _ O
- -X- _ O
selected -X- _ O
workers -X- _ O
from -X- _ O
English -X- _ O
speaking -X- _ O
countries -X- _ O
. -X- _ O
These -X- _ O
workers -X- _ O
accomplished -X- _ O
high -X- _ O
quality -X- _ O
work -X- _ O
in -X- _ O
other -X- _ O
NLP -X- _ O
- -X- _ O
related -X- _ O
tasks -X- _ O
we -X- _ O
have -X- _ O
conducted -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
. -X- _ O
The -X- _ O
crowdsourcing -X- _ O
instructions -X- _ O
of -X- _ O
the -X- _ O
tasks -X- _ O
mentioned -X- _ O
in -X- _ O
§ -X- _ O
4.4 -X- _ O
& -X- _ O
5 -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
D.1 -X- _ O
General -X- _ O
Summarization -X- _ B-TaskName
System -X- _ O
Evaluation -X- _ O
. -X- _ O
Read -X- _ O
the -X- _ O
following -X- _ O
four -X- _ O
texts -X- _ O
( -X- _ O
Text -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
D -X- _ O
) -X- _ O
and -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
questions -X- _ O
. -X- _ O
Text -X- _ O
A -X- _ O
: -X- _ O
< -X- _ O
Reference -X- _ O
summary -X- _ O
> -X- _ O
Text -X- _ O
B -X- _ O
: -X- _ O
< -X- _ O
System -X- _ O
summary -X- _ O
1 -X- _ O
> -X- _ O
Text -X- _ O
C -X- _ O
: -X- _ O
< -X- _ O
System -X- _ O
summary -X- _ O
2 -X- _ O
> -X- _ O
Text -X- _ O
D -X- _ O
: -X- _ O
< -X- _ O
System -X- _ O
summary -X- _ O
3 -X- _ O
> -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
content -X- _ O
overlap -X- _ O
with -X- _ O
text -X- _ O
A -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
has -X- _ O
the -X- _ O
2nd -X- _ O
highest -X- _ O
content -X- _ O
overlap -X- _ O
with -X- _ O
text -X- _ O
A -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
readable -X- _ O
and -X- _ O
well -X- _ O
- -X- _ O
understood -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
is -X- _ O
the -X- _ O
2nd -X- _ O
most -X- _ O
readable -X- _ O
and -X- _ O
well -X- _ O
- -X- _ O
understood -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
avoids -X- _ O
grammar -X- _ O
mistakes -X- _ O
the -X- _ O
best -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
avoids -X- _ O
grammar -X- _ O
mistakes -X- _ O
the -X- _ O
2nd -X- _ O
best -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
avoids -X- _ O
information -X- _ O
repetition -X- _ O
the -X- _ O
best -X- _ O
? -X- _ O
•Which -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
or -X- _ O
D -X- _ O
avoids -X- _ O
information -X- _ O
repetition -X- _ O
the -X- _ O
2nd -X- _ O
best -X- _ O
? -X- _ O
D.2 -X- _ O
Supporting -X- _ O
Cluster -X- _ O
Evaluation -X- _ O
. -X- _ O
Read -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
text -X- _ O
spans -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
below -X- _ O
. -X- _ O
Span -X- _ O
Text -X- _ O
A -X- _ O
: -X- _ O
< -X- _ O
The -X- _ O
generated -X- _ O
sentence -X- _ O
> -X- _ O
Span -X- _ O
Text -X- _ O
B -X- _ O
: -X- _ O
< -X- _ O
A -X- _ O
proposition -X- _ O
from -X- _ O
the -X- _ O
cluster -X- _ O
> -X- _ O
Is -X- _ O
the -X- _ O
main -X- _ O
fact -X- _ O
of -X- _ O
Span -X- _ O
Text -X- _ O
A -X- _ O
mentioned -X- _ O
in -X- _ O
Span -X- _ O
Text -X- _ O
B -X- _ O
? -X- _ O
( -X- _ O
ignoring -X- _ O
additional -X- _ O
details -X- _ O
) -X- _ O
Yes -X- _ O
/ -X- _ O
No -X- _ O
D.3 -X- _ O
Faithfulness -X- _ O
Evaluation -X- _ O
. -X- _ O
Read -X- _ O
the -X- _ O
following -X- _ O
group -X- _ O
of -X- _ O
text -X- _ O
spans -X- _ O
A -X- _ O
and -X- _ O
text -X- _ O
span -X- _ O
B -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
the -X- _ O
questions -X- _ O
below -X- _ O
. -X- _ O
You -X- _ O
can -X- _ O
assume -X- _ O
that -X- _ O
all -X- _ O
text -X- _ O
spans -X- _ O
in -X- _ O
group -X- _ O
A -X- _ O
describe -X- _ O
the -X- _ O
same -X- _ O
event -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
can -X- _ O
be -X- _ O
consolidated -X- _ O
together -X- _ O
to -X- _ O
imply -X- _ O
Text -X- _ O
Span -X- _ O
B. -X- _ O
Examples -X- _ O
: -X- _ O
1.Group -X- _ O
of -X- _ O
Text -X- _ O
Spans -X- _ O
A -X- _ O
: -X- _ O
•They -X- _ O
arrested -X- _ O
John -X- _ O
. -X- _ O
•John -X- _ O
was -X- _ O
arrested -X- _ O
. -X- _ O
Text -X- _ O
Span -X- _ O
B -X- _ O
: -X- _ O
The -X- _ O
FBI -X- _ O
arrested -X- _ O
John -X- _ O
Is -X- _ O
the -X- _ O
Group -X- _ O
of -X- _ O
Text -X- _ O
Spans -X- _ O
A -X- _ O
implies -X- _ O
the -X- _ O
fact -X- _ O
in -X- _ O
Text -X- _ O
Span -X- _ O
B -X- _ O
? -X- _ O
Text -X- _ O
Span -X- _ O
B -X- _ O
add -X- _ O
a -X- _ O
detail -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
mentioned -X- _ O
in -X- _ O
A. -X- _ O
Therefore -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
No -X- _ O
. -X- _ O
2.Group -X- _ O
of -X- _ O
Text -X- _ O
Spans -X- _ O
A -X- _ O
: -X- _ O
•there -X- _ O
were -X- _ O
10 -X- _ O
- -X- _ O
12 -X- _ O
girls -X- _ O
and -X- _ O
15 -X- _ O
boys -X- _ O
in -X- _ O
the -X- _ O
schoolhouse -X- _ O
•there -X- _ O
were -X- _ O
boys -X- _ O
and -X- _ O
girls -X- _ O
in -X- _ O
the -X- _ O
schoolhouse -X- _ O
Text -X- _ O
Span -X- _ O
B -X- _ O
: -X- _ O
there -X- _ O
were -X- _ O
1012 -X- _ O
girls -X- _ O
and -X- _ O
15 -X- _ O
boys -X- _ O
in -X- _ O
the -X- _ O
schoolhouse1778Is -X- _ O
the -X- _ O
Group -X- _ O
of -X- _ O
Text -X- _ O
Spans -X- _ O
A -X- _ O
implies -X- _ O
the -X- _ O
fact -X- _ O
in -X- _ O
Text -X- _ O
Span -X- _ O
B -X- _ O
? -X- _ O
Text -X- _ O
Span -X- _ O
B -X- _ O
contradicts -X- _ O
Group -X- _ O
A -X- _ O
( -X- _ O
instead -X- _ O
of -X- _ O
10 -X- _ O
- -X- _ O
12 -X- _ O
girls -X- _ O
it -X- _ O
says -X- _ O
1012 -X- _ O
girls -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
No.1779 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
In -X- _ SUMMARY
this -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
, -X- _ SUMMARY
the -X- _ SUMMARY
authors -X- _ SUMMARY
propose -X- _ SUMMARY
a -X- _ SUMMARY
method -X- _ SUMMARY
called -X- _ SUMMARY
" -X- _ SUMMARY
Subset -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
" -X- _ SUMMARY
to -X- _ SUMMARY
improve -X- _ SUMMARY
the -X- _ SUMMARY
decoding -X- _ SUMMARY
speed -X- _ SUMMARY
of -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
, -X- _ SUMMARY
a -X- _ SUMMARY
machine -X- _ SUMMARY
translation -X- _ SUMMARY
model -X- _ SUMMARY
that -X- _ SUMMARY
incorporates -X- _ SUMMARY
example -X- _ SUMMARY
- -X- _ SUMMARY
search -X- _ SUMMARY
into -X- _ SUMMARY
the -X- _ SUMMARY
decoding -X- _ SUMMARY
algorithm -X- _ SUMMARY
. -X- _ SUMMARY
Subset -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
retrieves -X- _ SUMMARY
neighbor -X- _ SUMMARY
target -X- _ SUMMARY
tokens -X- _ SUMMARY
from -X- _ SUMMARY
a -X- _ SUMMARY
subset -X- _ SUMMARY
of -X- _ SUMMARY
neighbor -X- _ SUMMARY
sentences -X- _ SUMMARY
, -X- _ SUMMARY
rather -X- _ SUMMARY
than -X- _ SUMMARY
from -X- _ SUMMARY
all -X- _ SUMMARY
sentences -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
uses -X- _ SUMMARY
an -X- _ SUMMARY
efficient -X- _ SUMMARY
distance -X- _ SUMMARY
computation -X- _ SUMMARY
technique -X- _ SUMMARY
using -X- _ SUMMARY
lookup -X- _ SUMMARY
tables -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
evaluate -X- _ SUMMARY
Subset -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
WMT'19 -X- _ SUMMARY
De -X- _ SUMMARY
- -X- _ SUMMARY
En -X- _ SUMMARY
translation -X- _ SUMMARY
task -X- _ SUMMARY
and -X- _ SUMMARY
domain -X- _ SUMMARY
adaptation -X- _ SUMMARY
tasks -X- _ SUMMARY
in -X- _ SUMMARY
De -X- _ SUMMARY
- -X- _ SUMMARY
En -X- _ SUMMARY
and -X- _ SUMMARY
En -X- _ SUMMARY
- -X- _ SUMMARY
Ja -X- _ SUMMARY
. -X- _ SUMMARY
They -X- _ SUMMARY
find -X- _ SUMMARY
that -X- _ SUMMARY
Subset -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
achieves -X- _ SUMMARY
a -X- _ SUMMARY
significant -X- _ SUMMARY
speed -X- _ SUMMARY
- -X- _ SUMMARY
up -X- _ SUMMARY
of -X- _ SUMMARY
up -X- _ SUMMARY
to -X- _ SUMMARY
132.2 -X- _ SUMMARY
times -X- _ SUMMARY
and -X- _ SUMMARY
an -X- _ SUMMARY
improvement -X- _ SUMMARY
in -X- _ SUMMARY
BLEU -X- _ SUMMARY
score -X- _ SUMMARY
of -X- _ SUMMARY
up -X- _ SUMMARY
to -X- _ SUMMARY
1.6 -X- _ SUMMARY
compared -X- _ SUMMARY
to -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
is -X- _ SUMMARY
evaluated -X- _ SUMMARY
using -X- _ SUMMARY
the -X- _ SUMMARY
LaBSE -X- _ SUMMARY
, -X- _ SUMMARY
AvgEnc -X- _ SUMMARY
, -X- _ SUMMARY
TF -X- _ SUMMARY
- -X- _ SUMMARY
IDF -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
BM25 -X- _ SUMMARY
sentence -X- _ SUMMARY
encoders -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
authors -X- _ SUMMARY
discuss -X- _ SUMMARY
the -X- _ SUMMARY
limitations -X- _ SUMMARY
of -X- _ SUMMARY
their -X- _ SUMMARY
work -X- _ SUMMARY
and -X- _ SUMMARY
ethical -X- _ SUMMARY
considerations -X- _ SUMMARY
related -X- _ SUMMARY
to -X- _ SUMMARY
the -X- _ SUMMARY
use -X- _ SUMMARY
of -X- _ SUMMARY
open -X- _ SUMMARY
datasets -X- _ SUMMARY
. -X- _ SUMMARY
Overall -X- _ SUMMARY
, -X- _ SUMMARY
Subset -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
offers -X- _ SUMMARY
a -X- _ SUMMARY
faster -X- _ SUMMARY
and -X- _ SUMMARY
improved -X- _ SUMMARY
alternative -X- _ SUMMARY
to -X- _ SUMMARY
kNN -X- _ SUMMARY
- -X- _ SUMMARY
MT -X- _ SUMMARY
for -X- _ SUMMARY
machine -X- _ SUMMARY
translation -X- _ SUMMARY
tasks -X- _ SUMMARY
. -X- _ SUMMARY
( -X- _ SUMMARY
198 -X- _ SUMMARY
words -X- _ SUMMARY
) -X- _ SUMMARY
2023.acl-long.10.txt -X- _ O
Hiroyuki -X- _ O
DeguchiTaro -X- _ O
WatanabeYusuke -X- _ O
Matsui -X- _ O
Masao -X- _ O
UtiyamaHideki -X- _ O
TanakaEiichiro -X- _ O
SumitaNara -X- _ O
Institute -X- _ O
of -X- _ O
Science -X- _ O
and -X- _ O
TechnologyThe -X- _ O
University -X- _ O
of -X- _ O
TokyoNational -X- _ O
Institute -X- _ O
of -X- _ O
Information -X- _ O
and -X- _ O
Communications -X- _ O
Technology -X- _ O
{ -X- _ O
deguchi.hiroyuki.db0 -X- _ O
, -X- _ O
taro -X- _ O
} -X- _ O
@ -X- _ O
is.naist.jp -X- _ O
matsui -X- _ O
@ -X- _ O
hal.t.u-tokyo.ac.jp -X- _ O
{ -X- _ O
mutiyama -X- _ O
, -X- _ O
hideki.tanaka -X- _ O
, -X- _ O
eiichiro.sumita -X- _ O
} -X- _ O
@ -X- _ O
nict.go.jp -X- _ O
Abstract -X- _ O
k -X- _ B-MethodName
- -X- _ I-MethodName
nearest -X- _ I-MethodName
- -X- _ I-MethodName
neighbor -X- _ I-MethodName
machine -X- _ I-MethodName
translation -X- _ I-MethodName
( -X- _ O
kNNMT -X- _ B-MethodName
) -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
boosts -X- _ O
the -X- _ O
translation -X- _ O
performance -X- _ O
of -X- _ O
trained -X- _ O
neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
NMT -X- _ B-TaskName
) -X- _ O
models -X- _ O
by -X- _ O
incorporating -X- _ O
example -X- _ O
- -X- _ O
search -X- _ O
into -X- _ O
the -X- _ O
decoding -X- _ O
algorithm -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
decoding -X- _ O
is -X- _ O
seriously -X- _ O
timeconsuming -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
roughly -X- _ O
100 -X- _ O
to -X- _ O
1,000 -X- _ O
times -X- _ O
slower -X- _ O
than -X- _ O
standard -X- _ O
NMT -X- _ B-TaskName
, -X- _ O
because -X- _ O
neighbor -X- _ O
tokens -X- _ O
are -X- _ O
retrieved -X- _ O
from -X- _ O
all -X- _ O
target -X- _ O
tokens -X- _ O
of -X- _ O
parallel -X- _ O
data -X- _ O
in -X- _ O
each -X- _ O
timestep -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
“ -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
” -X- _ O
, -X- _ O
which -X- _ O
improves -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
of -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
by -X- _ O
two -X- _ O
methods -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
retrieving -X- _ O
neighbor -X- _ O
target -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
subset -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
neighbor -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
not -X- _ O
from -X- _ O
all -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
efﬁcient -X- _ O
distance -X- _ O
computation -X- _ O
technique -X- _ O
that -X- _ O
is -X- _ O
suitable -X- _ O
for -X- _ O
subset -X- _ O
neighbor -X- _ O
search -X- _ O
using -X- _ O
a -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
table -X- _ O
. -X- _ O
Our -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
achieved -X- _ O
a -X- _ O
speed -X- _ B-MetricName
- -X- _ I-MetricName
up -X- _ I-MetricName
of -X- _ O
up -X- _ O
to -X- _ O
132.2 -X- _ B-MetricValue
times -X- _ O
and -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
1.6 -X- _ B-MetricValue
compared -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
in -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ O
- -X- _ O
En -X- _ O
translation -X- _ B-TaskName
task -X- _ O
and -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
and -X- _ O
En -X- _ O
- -X- _ O
Ja -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Neural -X- _ B-TaskName
machine -X- _ I-TaskName
translation -X- _ I-TaskName
( -X- _ O
NMT -X- _ B-TaskName
) -X- _ O
( -X- _ O
Sutskever -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Bahdanau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
has -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
and -X- _ O
become -X- _ O
the -X- _ O
focus -X- _ O
of -X- _ O
many -X- _ O
studies -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
kNNMT -X- _ B-MethodName
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
proposed -X- _ O
, -X- _ O
which -X- _ O
addresses -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
performance -X- _ O
degradation -X- _ O
in -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
by -X- _ O
incorporating -X- _ O
example -X- _ O
- -X- _ O
search -X- _ O
into -X- _ O
the -X- _ O
decoding -X- _ O
algorithm -X- _ O
. -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
stores -X- _ O
translation -X- _ O
examples -X- _ O
as -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
key -X- _ O
– -X- _ O
value -X- _ O
pairs -X- _ O
called -X- _ O
“ -X- _ O
datastore -X- _ O
” -X- _ O
and -X- _ O
retrieves -X- _ O
k -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
target -X- _ O
tokens -X- _ O
in -X- _ O
decoding -X- _ O
. -X- _ O
The -X- _ O
method -X- _ O
improves -X- _ O
the -X- _ O
translation -X- _ O
performance -X- _ O
of -X- _ O
NMT -X- _ B-TaskName
models -X- _ O
without -X- _ O
additional -X- _ O
training -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
decoding -X- _ O
is -X- _ O
seriously -X- _ O
timeconsuming -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
roughly -X- _ O
100 -X- _ O
to -X- _ O
1,000 -X- _ O
times -X- _ O
slower -X- _ O
than -X- _ O
standard -X- _ O
NMT -X- _ B-TaskName
, -X- _ O
because -X- _ O
neighbor -X- _ O
tokens -X- _ O
areretrieved -X- _ O
from -X- _ O
all -X- _ O
target -X- _ O
tokens -X- _ O
of -X- _ O
parallel -X- _ O
data -X- _ O
in -X- _ O
each -X- _ O
timestep -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
realistic -X- _ O
opendomain -X- _ O
setting -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
may -X- _ O
be -X- _ O
signiﬁcantly -X- _ O
slower -X- _ O
because -X- _ O
it -X- _ O
needs -X- _ O
to -X- _ O
retrieve -X- _ O
neighbor -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
datastore -X- _ O
that -X- _ O
covers -X- _ O
various -X- _ O
domains -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
“ -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
” -X- _ O
, -X- _ O
which -X- _ O
improves -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
of -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
by -X- _ O
two -X- _ O
methods -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
retrieving -X- _ O
neighbor -X- _ O
target -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
subset -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
neighbor -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
not -X- _ O
from -X- _ O
all -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
efﬁcient -X- _ O
distance -X- _ O
computation -X- _ O
technique -X- _ O
that -X- _ O
is -X- _ O
suitable -X- _ O
for -X- _ O
subset -X- _ O
neighbor -X- _ O
search -X- _ O
using -X- _ O
a -X- _ O
lookup -X- _ O
table -X- _ O
. -X- _ O
When -X- _ O
retrieving -X- _ O
neighbor -X- _ O
sentences -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
employ -X- _ O
arbitrary -X- _ O
sentence -X- _ O
representations -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
neural -X- _ O
encoders -X- _ O
or -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
vectors -X- _ O
, -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
kNN -X- _ O
search -X- _ O
space -X- _ O
. -X- _ O
When -X- _ O
retrieving -X- _ O
target -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
decoding -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
in -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
varies -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
the -X- _ O
clustering -X- _ O
- -X- _ O
based -X- _ O
search -X- _ O
methods -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
originalkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
can -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
asymmetric -X- _ O
distance -X- _ O
computation -X- _ O
( -X- _ O
ADC -X- _ O
) -X- _ O
( -X- _ O
Jégou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
in -X- _ O
subset -X- _ O
neighbor -X- _ O
search -X- _ O
. -X- _ O
Our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
achieved -X- _ O
a -X- _ O
speed -X- _ B-MetricName
- -X- _ I-MetricName
up -X- _ I-MetricName
of -X- _ O
up -X- _ O
to -X- _ O
132.2 -X- _ B-MetricValue
times -X- _ I-MetricValue
and -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
1.6 -X- _ B-MetricValue
compared -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
in -X- _ O
the -X- _ O
WMT’19 -X- _ O
German -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
general -X- _ O
domain -X- _ O
translation -X- _ B-TaskName
task -X- _ O
and -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
tasks -X- _ O
in -X- _ O
German -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
and -X- _ O
English -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Japanese -X- _ O
with -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
. -X- _ O
2kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
retrieves -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
target -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
timestep -X- _ O
, -X- _ O
computes -X- _ O
the -X- _ O
kNN -X- _ O
probability -X- _ O
from -X- _ O
the -X- _ O
distances -X- _ O
of -X- _ O
retrieved -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
interpolates -X- _ O
the -X- _ O
probability -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
prediction -X- _ O
probability -X- _ O
. -X- _ O
The -X- _ O
method -X- _ O
consists -X- _ O
of -X- _ O
two -X- _ O
steps -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
datastore -X- _ O
creation -X- _ O
, -X- _ O
which -X- _ O
creates -X- _ O
key -X- _ O
– -X- _ O
value -X- _ O
translation -X- _ O
memory -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
calculates -X- _ O
an -X- _ O
output -X- _ O
probability -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
nearest -X- _ O
neighbors174 -X- _ O
of -X- _ O
the -X- _ O
cached -X- _ O
translation -X- _ O
memory -X- _ O
. -X- _ O
Datastore -X- _ O
Construction -X- _ O
A -X- _ O
typical -X- _ O
NMT -X- _ B-TaskName
model -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
an -X- _ O
encoder -X- _ O
that -X- _ O
encodes -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
x= -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
x -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
) -X- _ O
∈ -X- _ O
Vand -X- _ O
a -X- _ O
decoder -X- _ O
that -X- _ O
generates -X- _ O
target -X- _ O
tokens -X- _ O
y= -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈Vwhere|x|and|y|are -X- _ O
the -X- _ O
lengths -X- _ O
of -X- _ O
sentences -X- _ O
xandy -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
andV -X- _ O
andVare -X- _ O
the -X- _ O
vocabularies -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
and -X- _ O
target -X- _ O
language -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
t -X- _ O
- -X- _ O
th -X- _ O
target -X- _ O
token -X- _ O
yis -X- _ O
generated -X- _ O
according -X- _ O
to -X- _ O
its -X- _ O
output -X- _ O
probability -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
over -X- _ O
the -X- _ O
target -X- _ O
vocabulary -X- _ O
, -X- _ O
calculated -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
xand -X- _ O
generated -X- _ O
target -X- _ O
tokens -X- _ O
y.kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
stores -X- _ O
pairs -X- _ O
of -X- _ O
Ddimensional -X- _ O
vectors -X- _ O
and -X- _ O
tokens -X- _ O
in -X- _ O
a -X- _ O
datastore -X- _ O
, -X- _ O
represented -X- _ O
as -X- _ O
key -X- _ O
– -X- _ O
value -X- _ O
memory -X- _ O
M⊆ -X- _ O
R×V. -X- _ O
The -X- _ O
key -X- _ O
( -X- _ O
∈R -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
intermediate -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
ﬁnal -X- _ O
decoder -X- _ O
layer -X- _ O
obtained -X- _ O
by -X- _ O
teacher -X- _ O
forcing -X- _ O
a -X- _ O
parallel -X- _ O
sentence -X- _ O
pair -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
NMT -X- _ B-TaskName
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
value -X- _ O
is -X- _ O
a -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
target -X- _ O
token -X- _ O
y. -X- _ O
The -X- _ O
datastore -X- _ O
is -X- _ O
formally -X- _ O
deﬁned -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
M= -X- _ O
{ -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D,1≤t≤|y| -X- _ O
} -X- _ O
, -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
whereDis -X- _ O
parallel -X- _ O
data -X- _ O
and -X- _ O
f -X- _ O
: -X- _ O
V×V→ -X- _ O
Ris -X- _ O
a -X- _ O
function -X- _ O
that -X- _ O
returns -X- _ O
the -X- _ O
D -X- _ O
- -X- _ O
dimensional -X- _ O
intermediate -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
ﬁnal -X- _ O
decoder -X- _ O
layer -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
and -X- _ O
generated -X- _ O
target -X- _ O
tokens -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
key -X- _ O
is -X- _ O
the -X- _ O
intermediate -X- _ O
representation -X- _ O
before -X- _ O
it -X- _ O
is -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
ﬁnal -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
network -X- _ O
. -X- _ O
Generation -X- _ O
During -X- _ O
decoding -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
generates -X- _ O
output -X- _ O
probabilities -X- _ O
by -X- _ O
computing -X- _ O
the -X- _ O
linear -X- _ O
interpolation -X- _ O
between -X- _ O
the -X- _ O
kNN -X- _ O
and -X- _ O
MT -X- _ O
probabili -X- _ O
- -X- _ O
ties -X- _ O
, -X- _ O
pandp -X- _ O
, -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
λp -X- _ O
( -X- _ O
y|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1−λ -X- _ O
) -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
where -X- _ O
λis -X- _ O
a -X- _ O
hyperparameter -X- _ O
for -X- _ O
weighting -X- _ O
the -X- _ O
kNN -X- _ O
probability -X- _ O
. -X- _ O
Let -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
be -X- _ O
the -X- _ O
query -X- _ O
vector -X- _ O
at -X- _ O
timestep -X- _ O
t. -X- _ O
The -X- _ O
top -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
key -X- _ O
and -X- _ O
value -X- _ O
in -X- _ O
thek -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
are -X- _ O
k∈Randv∈V -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Then -X- _ O
pis -X- _ O
deﬁned -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
p -X- _ O
( -X- _ O
y|x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∝∑ -X- _ O
/ -X- _ O
x31exp -X- _ O
( -X- _ O
−∥k−f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∥ -X- _ O
τ -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
where -X- _ O
τis -X- _ O
the -X- _ O
temperature -X- _ O
for -X- _ O
p -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
τ= -X- _ O
100 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
this -X- _ O
kNN -X- _ O
search -X- _ O
is -X- _ O
seriously -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
3 -X- _ O
Proposed -X- _ O
Model -X- _ O
: -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
Our -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
drastically -X- _ O
accelerates -X- _ O
vanilla -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
by -X- _ O
reducing -X- _ O
the -X- _ O
kNN -X- _ O
search -X- _ O
space -X- _ O
by -X- _ O
using -X- _ O
sentence -X- _ O
information -X- _ O
( -X- _ O
Section3.1 -X- _ O
) -X- _ O
and -X- _ O
efﬁciently -X- _ O
computing -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
and -X- _ O
key -X- _ O
by -X- _ O
performing -X- _ O
table -X- _ O
lookup -X- _ O
( -X- _ O
Section -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O
3.1 -X- _ O
Subset -X- _ O
Retrieval -X- _ O
Sentence -X- _ O
Datastore -X- _ O
Construction -X- _ O
In -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
sentence -X- _ O
datastore -X- _ O
that -X- _ O
stores -X- _ O
pairs -X- _ O
comprising -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
vector175 -X- _ O
and -X- _ O
a -X- _ O
target -X- _ O
sentence -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
a -X- _ O
sentence -X- _ O
datastoreSis -X- _ O
deﬁned -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
S= -X- _ O
{ -X- _ O
( -X- _ O
h -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈D -X- _ O
} -X- _ O
, -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
where -X- _ O
h -X- _ O
: -X- _ O
V→Rrepresents -X- _ O
a -X- _ O
sentence -X- _ O
encoder -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
that -X- _ O
returns -X- _ O
a -X- _ O
Ddimensional -X- _ O
vector -X- _ O
representation -X- _ O
of -X- _ O
a -X- _ O
source -X- _ O
sentence -X- _ O
. -X- _ O
Decoding -X- _ O
At -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
decoding -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
retrieves -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
input -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
sentence -X- _ O
datastoreS. -X- _ O
Let -X- _ O
ˆS⊂S -X- _ O
be -X- _ O
the -X- _ O
subset -X- _ O
comprising -X- _ O
nnearest -X- _ O
- -X- _ O
neighbor -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
nearest -X- _ O
neighbor -X- _ O
search -X- _ O
space -X- _ O
for -X- _ O
target -X- _ O
tokens -X- _ O
in -X- _ O
kNN -X- _ O
- -X- _ O
MT -X- _ O
is -X- _ O
then -X- _ O
drastically -X- _ O
reduced -X- _ O
by -X- _ O
constructing -X- _ O
the -X- _ O
datastore -X- _ O
corresponding -X- _ O
to -X- _ O
ˆSas -X- _ O
follows -X- _ O
: -X- _ O
ˆM= -X- _ O
{ -X- _ O
( -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
| -X- _ O
( -X- _ O
h -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
∈ˆS,1≤t≤|y| -X- _ O
} -X- _ O
, -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
where -X- _ O
ˆM⊂M -X- _ O
is -X- _ O
the -X- _ O
reduced -X- _ O
datastore -X- _ O
for -X- _ O
the -X- _ O
translation -X- _ O
examples -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
nearestneighbor -X- _ O
sentences -X- _ O
. -X- _ O
During -X- _ O
decoding -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
algorithm -X- _ O
as -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
except -X- _ O
that -X- _ O
ˆMis -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
datastore -X- _ O
instead -X- _ O
of -X- _ O
M. -X- _ O
The -X- _ O
proposed -X- _ O
method -X- _ O
reduces -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
search -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
tokens -X- _ O
from -X- _ O
|D|ton -X- _ O
( -X- _ O
≪|D| -X- _ O
) -X- _ O
sentences -X- _ O
. -X- _ O
3.2 -X- _ O
Efﬁcient -X- _ O
Distance -X- _ O
Computation -X- _ O
Using -X- _ O
Lookup -X- _ O
Table -X- _ O
Subset -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
retrieves -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
target -X- _ O
tokens -X- _ O
by -X- _ O
an -X- _ O
efﬁcient -X- _ O
distance -X- _ O
computation -X- _ O
method -X- _ O
that -X- _ O
uses -X- _ O
a -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
table -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
originalkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
inverted -X- _ O
ﬁle -X- _ O
index -X- _ O
( -X- _ O
IVF -X- _ O
) -X- _ O
is -X- _ O
usedfor -X- _ O
retrieving -X- _ O
kNN -X- _ O
tokens -X- _ O
. -X- _ O
IVF -X- _ O
divides -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
into -X- _ O
Nclusters -X- _ O
and -X- _ O
retrieves -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
neighbor -X- _ O
clusters -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
in -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
, -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
varies -X- _ O
dynamically -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
clusteringbased -X- _ O
search -X- _ O
methods -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
; -X- _ O
instead -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
distance -X- _ O
for -X- _ O
each -X- _ O
key -X- _ O
in -X- _ O
the -X- _ O
subset -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
purpose -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
asymmetric -X- _ O
distance -X- _ O
computation -X- _ O
( -X- _ O
ADC -X- _ O
) -X- _ O
( -X- _ O
Jégou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
usual -X- _ O
distance -X- _ O
computation -X- _ O
between -X- _ O
ﬂoating -X- _ O
- -X- _ O
point -X- _ O
vectors -X- _ O
. -X- _ O
In -X- _ O
ADC -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
table -X- _ O
lookup -X- _ O
is -X- _ O
linearly -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
keys -X- _ O
Nin -X- _ O
the -X- _ O
subset -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
suitable -X- _ O
for -X- _ O
searching -X- _ O
in -X- _ O
large -X- _ O
datastore -X- _ O
M -X- _ O
, -X- _ O
but -X- _ O
in -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
ˆM -X- _ O
, -X- _ O
the -X- _ O
search -X- _ O
is -X- _ O
faster -X- _ O
than -X- _ O
the -X- _ O
direct -X- _ O
calculation -X- _ O
of -X- _ O
the -X- _ O
L2 -X- _ O
distance -X- _ O
. -X- _ O
Product -X- _ O
Quantization -X- _ O
( -X- _ O
PQ -X- _ O
) -X- _ O
The -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
datastoreMmay -X- _ O
become -X- _ O
too -X- _ O
large -X- _ O
because -X- _ O
it -X- _ O
stores -X- _ O
high -X- _ O
- -X- _ O
dimensional -X- _ O
intermediate -X- _ O
representations -X- _ O
of -X- _ O
all -X- _ O
target -X- _ O
tokens -X- _ O
of -X- _ O
parallel -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
German -X- _ I-DatasetName
- -X- _ I-DatasetName
to -X- _ I-DatasetName
- -X- _ I-DatasetName
English -X- _ I-DatasetName
parallel -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
contains -X- _ O
862 -X- _ O
M -X- _ O
tokens -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
side -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
if -X- _ O
vectors -X- _ O
were -X- _ O
stored -X- _ O
directly -X- _ O
, -X- _ O
the -X- _ O
datastore -X- _ O
would -X- _ O
occupy -X- _ O
3.2 -X- _ O
TiB -X- _ O
when -X- _ O
a -X- _ O
1024 -X- _ O
- -X- _ O
dimensional -X- _ O
vector -X- _ O
as -X- _ O
a -X- _ O
key -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
would -X- _ O
be -X- _ O
hard -X- _ O
to -X- _ O
load -X- _ O
into -X- _ O
RAM -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
this -X- _ O
memory -X- _ O
problem -X- _ O
, -X- _ O
product -X- _ O
quantization -X- _ O
( -X- _ O
PQ -X- _ O
) -X- _ O
( -X- _ O
Jégou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
is -X- _ O
used -X- _ O
in -X- _ O
both -X- _ O
kNNMT -X- _ B-MethodName
and -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
which -X- _ O
includes -X- _ O
both -X- _ O
source -X- _ O
sentence -X- _ O
and -X- _ O
target -X- _ O
token -X- _ O
search -X- _ O
. -X- _ O
PQ -X- _ O
splits -X- _ O
a -X- _ O
D -X- _ O
- -X- _ O
dimensional -X- _ O
vector -X- _ O
into -X- _ O
Msubvectors -X- _ O
and -X- _ O
quantizes -X- _ O
for -X- _ O
each -X- _ O
- -X- _ O
dimensional -X- _ O
sub -X- _ O
- -X- _ O
vector -X- _ O
. -X- _ O
Codebooks -X- _ O
are -X- _ O
learned -X- _ O
by -X- _ O
k -X- _ O
- -X- _ O
means -X- _ O
clustering -X- _ O
of -X- _ O
key -X- _ O
vectors -X- _ O
in -X- _ O
each -X- _ O
subspace -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
computed -X- _ O
iteratively -X- _ O
by -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
assigning -X- _ O
the -X- _ O
code -X- _ O
of -X- _ O
a -X- _ O
key -X- _ O
to -X- _ O
its -X- _ O
nearest -X- _ O
neighbor -X- _ O
centroid -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
and -X- _ O
updating -X- _ O
the -X- _ O
centroid -X- _ O
of -X- _ O
keys -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
code -X- _ O
. -X- _ O
Them -X- _ O
- -X- _ O
th -X- _ O
sub -X- _ O
- -X- _ O
space -X- _ O
’s -X- _ O
codebook -X- _ O
Cis -X- _ O
formulated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
C= -X- _ O
{ -X- _ O
c -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
c -X- _ O
} -X- _ O
, -X- _ O
c∈R. -X- _ O
( -X- _ O
6 -X- _ O
) -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
each -X- _ O
codebook -X- _ O
size -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
L= -X- _ O
256 -X- _ O
. -X- _ O
A -X- _ O
vector -X- _ O
q∈Ris -X- _ O
quantized -X- _ O
and -X- _ O
its -X- _ O
code -X- _ O
vector -X- _ O
¯qis -X- _ O
calculated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
¯q= -X- _ O
[ -X- _ O
¯q -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
¯q -X- _ O
] -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
L -X- _ O
} -X- _ O
, -X- _ O
( -X- _ O
7 -X- _ O
) -X- _ O
¯q= -X- _ O
argmin∥q−c∥ -X- _ O
, -X- _ O
q∈R. -X- _ O
( -X- _ O
8 -X- _ O
) -X- _ O
176Asymmetric -X- _ O
Distance -X- _ O
Computation -X- _ O
( -X- _ O
ADC -X- _ O
) -X- _ O
Our -X- _ O
method -X- _ O
efﬁciently -X- _ O
computes -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
vector -X- _ O
and -X- _ O
quantized -X- _ O
key -X- _ O
vectors -X- _ O
using -X- _ O
ADC -X- _ O
( -X- _ O
Jégou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
ADC -X- _ O
computes -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
vector -X- _ O
q∈RandNkey -X- _ O
codes -X- _ O
¯K= -X- _ O
{ -X- _ O
¯k -X- _ O
} -X- _ O
⊆ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
L -X- _ O
} -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
distance -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
table -X- _ O
A∈Ris -X- _ O
computed -X- _ O
by -X- _ O
calculating -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
qand -X- _ O
the -X- _ O
codes -X- _ O
c∈Cin -X- _ O
each -X- _ O
sub -X- _ O
- -X- _ O
space -X- _ O
m -X- _ O
, -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
A=∥q−c∥. -X- _ O
( -X- _ O
9 -X- _ O
) -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
and -X- _ O
each -X- _ O
key -X- _ O
d -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
¯k -X- _ O
) -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
looking -X- _ O
up -X- _ O
the -X- _ O
distance -X- _ O
table -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
d -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
¯k -X- _ O
) -X- _ O
= -X- _ O
∑d -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
¯k -X- _ O
) -X- _ O
= -X- _ O
∑A. -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
A -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
table -X- _ O
in -X- _ O
each -X- _ O
subspace -X- _ O
, -X- _ O
A∈R -X- _ O
, -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
and -X- _ O
codes -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
codes -X- _ O
in -X- _ O
each -X- _ O
subspace -X- _ O
is -X- _ O
Land -X- _ O
a -X- _ O
distance -X- _ O
is -X- _ O
a -X- _ O
scalar -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
AhasLdistances -X- _ O
. -X- _ O
And -X- _ O
the -X- _ O
table -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
key -X- _ O
is -X- _ O
the -X- _ O
code -X- _ O
of -X- _ O
a -X- _ O
key -X- _ O
itself -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
m -X- _ O
- -X- _ O
th -X- _ O
subspace -X- _ O
’s -X- _ O
code -X- _ O
of -X- _ O
a -X- _ O
key -X- _ O
is -X- _ O
5 -X- _ O
, -X- _ O
ADC -X- _ O
looks -X- _ O
- -X- _ O
up -X- _ O
A. -X- _ O
By -X- _ O
using -X- _ O
ADC -X- _ O
, -X- _ O
the -X- _ O
distance -X- _ O
is -X- _ O
computed -X- _ O
only -X- _ O
once -X- _ O
( -X- _ O
Equation -X- _ O
9 -X- _ O
) -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
decode -X- _ O
PQ -X- _ O
codes -X- _ O
into -X- _ O
D -X- _ O
- -X- _ O
dimensional -X- _ O
key -X- _ O
vectors -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
compute -X- _ O
the -X- _ O
distance -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
key -X- _ O
in -X- _ O
the -X- _ O
quantization -X- _ O
code -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
tokens -X- _ O
are -X- _ O
efﬁciently -X- _ O
retrieved -X- _ O
from -X- _ O
ˆM. -X- _ O
3.3 -X- _ O
Sentence -X- _ O
Encoder -X- _ O
In -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
sentence -X- _ O
encoder -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
employed -X- _ O
. -X- _ O
The -X- _ O
more -X- _ O
similar -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
M -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
likely -X- _ O
the -X- _ O
subset -X- _ O
ˆMcomprises -X- _ O
the -X- _ O
target -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
useful -X- _ O
for -X- _ O
translation -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
sentence -X- _ O
encoders -X- _ O
that -X- _ O
compute -X- _ O
vector -X- _ O
representations -X- _ O
whose -X- _ O
distances -X- _ O
are -X- _ O
close -X- _ O
for -X- _ O
similar -X- _ O
sentences -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
representations -X- _ O
: -X- _ O
neural -X- _ O
andnon -X- _ O
- -X- _ O
neural -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
employ -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
. -X- _ O
While -X- _ O
they -X- _ O
require -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
expect -X- _ O
that -X- _ O
the -X- _ O
retrieved -X- _ O
sentences -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
than -X- _ O
other -X- _ O
encoders -X- _ O
because -X- _ O
we -X- _ O
can -X- _ O
use -X- _ O
models -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
trained -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
vectordistance -X- _ O
between -X- _ O
similar -X- _ O
sentences -X- _ O
( -X- _ O
Reimers -X- _ O
and -X- _ O
Gurevych -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
NMT -X- _ B-TaskName
encoder -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
sentence -X- _ O
encoder -X- _ O
by -X- _ O
applying -X- _ O
average -X- _ O
pooling -X- _ O
to -X- _ O
its -X- _ O
intermediate -X- _ O
representations -X- _ O
. -X- _ O
This -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
any -X- _ O
external -X- _ O
resources -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
trained -X- _ O
from -X- _ O
the -X- _ O
supervision -X- _ O
of -X- _ O
sentence -X- _ O
representations -X- _ O
. -X- _ O
Alternatively -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
use -X- _ O
nonneural -X- _ O
models -X- _ O
like -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
whether -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
based -X- _ O
similarity -X- _ O
is -X- _ O
suitable -X- _ O
for -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
even -X- _ O
if -X- _ O
sentences -X- _ O
with -X- _ O
close -X- _ O
surface -X- _ O
expressions -X- _ O
are -X- _ O
retrieved -X- _ O
, -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
necessarily -X- _ O
have -X- _ O
similar -X- _ O
meanings -X- _ O
and -X- _ O
may -X- _ O
not -X- _ O
yield -X- _ O
the -X- _ O
candidate -X- _ O
tokens -X- _ O
needed -X- _ O
for -X- _ O
translation -X- _ O
. -X- _ O
4 -X- _ O
Experiments -X- _ O
4.1 -X- _ O
Setup -X- _ O
We -X- _ O
compared -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
and -X- _ O
speed -X- _ O
of -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
with -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
conventional -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
in -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
that -X- _ O
assume -X- _ O
a -X- _ O
domain -X- _ O
of -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
is -X- _ O
unknown -X- _ O
. -X- _ O
The -X- _ O
translation -X- _ O
quality -X- _ O
was -X- _ O
measured -X- _ O
by -X- _ O
sacreBLEU -X- _ B-MetricName
( -X- _ O
Post,2018 -X- _ O
) -X- _ O
and -X- _ O
COMET -X- _ B-MetricName
( -X- _ O
Rei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
speed -X- _ O
was -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
NVIDIA -X- _ O
V100 -X- _ O
GPU -X- _ O
. -X- _ O
We -X- _ O
varied -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
settings -X- _ O
: -X- _ O
either -X- _ O
12,000 -X- _ B-HyperparameterValue
tokens -X- _ O
( -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
simulate -X- _ O
the -X- _ O
document -X- _ O
translation -X- _ O
scenario -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
( -X- _ O
B -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
simulate -X- _ O
the -X- _ O
online -X- _ O
translation -X- _ O
scenario -X- _ O
. -X- _ O
The -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
1.0 -X- _ B-HyperparameterValue
. -X- _ O
k -X- _ O
- -X- _ O
Nearest -X- _ O
- -X- _ O
Neighbor -X- _ O
Search -X- _ O
InkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
nearest -X- _ O
neighbor -X- _ O
tokens -X- _ O
to -X- _ O
k= -X- _ B-HyperparameterName
16 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
used -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
kNN -X- _ O
tokens -X- _ O
in -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
for -X- _ O
neighbor -X- _ O
sentence -X- _ O
search -X- _ O
in -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
. -X- _ O
The -X- _ O
subset -X- _ O
search -X- _ O
and -X- _ O
ADC -X- _ O
were -X- _ O
implemented -X- _ O
in -X- _ O
PT -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
approximate -X- _ O
distance -X- _ O
computed -X- _ O
from -X- _ O
quantized -X- _ O
keys -X- _ O
instead -X- _ O
of -X- _ O
full -X- _ O
- -X- _ O
precision -X- _ O
keys -X- _ O
in -X- _ O
Equation -X- _ O
3 -X- _ O
, -X- _ O
following -X- _ O
the -X- _ O
original -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
implementation -X- _ O
. -X- _ O
The -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
datastore -X- _ O
and -X- _ O
our -X- _ O
sentence -X- _ O
datastore -X- _ O
used -X- _ O
IVF -X- _ O
and -X- _ O
optimized -X- _ O
PQ -X- _ O
( -X- _ O
OPQ -X- _ O
) -X- _ O
( -X- _ O
Ge -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
OPQ -X- _ O
rotates -X- _ O
vectors -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
quantization -X- _ O
error -X- _ O
of -X- _ O
PQ -X- _ O
. -X- _ O
The -X- _ O
subsetkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
datastore -X- _ O
is -X- _ O
not -X- _ O
applied -X- _ O
clustering -X- _ O
since -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
extract -X- _ O
subset -X- _ O
tokens -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
datastore -X- _ O
, -X- _ O
the -X- _ O
1024 -X- _ O
- -X- _ O
dimensional -X- _ O
vector -X- _ O
representation -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
D= -X- _ O
1024 -X- _ O
, -X- _ O
was -X- _ O
reduced -X- _ O
in -X- _ O
dimensionality -X- _ O
to -X- _ O
256 -X- _ O
- -X- _ O
dimensions -X- _ O
by -X- _ O
principal -X- _ O
component -X- _ O
analysis -X- _ O
( -X- _ O
PCA -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
these -X- _ O
vectors -X- _ O
were -X- _ O
then177quantized -X- _ O
by -X- _ O
PQ -X- _ O
. -X- _ O
At -X- _ O
search -X- _ O
time -X- _ O
, -X- _ O
a -X- _ O
query -X- _ O
vector -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
transformed -X- _ O
to -X- _ O
256 -X- _ O
- -X- _ O
dimensions -X- _ O
by -X- _ O
multiplying -X- _ O
the -X- _ O
PCA -X- _ O
matrix -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
kNN -X- _ O
target -X- _ O
tokens -X- _ O
are -X- _ O
searched -X- _ O
by -X- _ O
ADC -X- _ O
. -X- _ O
The -X- _ O
subset -X- _ O
of -X- _ O
a -X- _ O
datastore -X- _ O
can -X- _ O
be -X- _ O
loaded -X- _ O
into -X- _ O
GPU -X- _ O
memory -X- _ O
since -X- _ O
it -X- _ O
is -X- _ O
signiﬁcantly -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
kNNMT -X- _ B-MethodName
datastore -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
retrieved -X- _ O
k -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
subset -X- _ O
on -X- _ O
a -X- _ O
GPU -X- _ O
. -X- _ O
Sentence -X- _ O
Encoder -X- _ O
We -X- _ O
compared -X- _ O
4 -X- _ O
different -X- _ O
sentence -X- _ O
encoders -X- _ O
: -X- _ O
LaBSE -X- _ O
, -X- _ O
AvgEnc -X- _ O
, -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
, -X- _ O
and -X- _ O
BM25 -X- _ O
. -X- _ O
LaBSE -X- _ O
( -X- _ O
Feng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
sentence -X- _ O
encoder -X- _ O
, -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
from -X- _ O
multilingual -X- _ O
BERT -X- _ O
. -X- _ O
AvgEnc -X- _ O
is -X- _ O
an -X- _ O
average -X- _ O
pooled -X- _ O
encoder -X- _ O
hidden -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ O
NMT -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
used -X- _ O
for -X- _ O
translation -X- _ O
. -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
( -X- _ O
Jones -X- _ O
, -X- _ O
1972 -X- _ O
) -X- _ O
and -X- _ O
BM25 -X- _ O
( -X- _ O
Jones -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
compute -X- _ O
vectors -X- _ O
weighted -X- _ O
the -X- _ O
important -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
raw -X- _ O
count -X- _ O
of -X- _ O
tokens -X- _ O
as -X- _ O
the -X- _ O
term -X- _ O
frequency -X- _ O
and -X- _ O
applied -X- _ O
add -X- _ O
- -X- _ O
one -X- _ O
smoothing -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
inverse -X- _ O
document -X- _ O
frequency -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
sentence -X- _ O
was -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
document -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
k= -X- _ B-HyperparameterName
2.0 -X- _ B-HyperparameterValue
, -X- _ O
b= -X- _ B-HyperparameterName
0.75 -X- _ B-HyperparameterValue
in -X- _ O
BM25 -X- _ O
( -X- _ O
Jones -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
. -X- _ O
Both -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
and -X- _ O
BM25 -X- _ O
vectors -X- _ O
were -X- _ O
normalized -X- _ O
by -X- _ O
their -X- _ O
L2norm -X- _ O
and -X- _ O
their -X- _ O
dimensionality -X- _ O
was -X- _ O
reduced -X- _ O
to -X- _ O
256dimensions -X- _ O
by -X- _ O
singular -X- _ O
value -X- _ O
decomposition -X- _ O
. -X- _ O
4.2 -X- _ O
In -X- _ O
- -X- _ O
Domain -X- _ O
Translation -X- _ O
We -X- _ O
evaluated -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
and -X- _ O
speed -X- _ O
of -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
in -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
translation -X- _ B-TaskName
task -X- _ O
( -X- _ O
newstest2019 -X- _ B-DatasetName
; -X- _ O
2,000 -X- _ O
sentences -X- _ O
) -X- _ O
and -X- _ O
compared -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
baselines -X- _ O
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
; -X- _ O
Meng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
trained -X- _ O
Transformer -X- _ O
big -X- _ O
implemented -X- _ O
in -X- _ O
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
MT -X- _ B-TaskName
model -X- _ O
. -X- _ O
We -X- _ O
constructed -X- _ O
the -X- _ O
datastore -X- _ O
from -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
news -X- _ I-DatasetName
translation -X- _ B-TaskName
task -X- _ O
with -X- _ O
subword -X- _ B-HyperparameterName
lengths -X- _ I-HyperparameterName
of -X- _ O
250 -X- _ B-HyperparameterValue
or -X- _ O
less -X- _ O
and -X- _ O
a -X- _ O
sentence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
ratio -X- _ I-HyperparameterName
of -X- _ O
1.5 -X- _ B-HyperparameterValue
or -X- _ O
less -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
datastore -X- _ O
contained -X- _ O
862.6 -X- _ O
M -X- _ O
target -X- _ O
tokens -X- _ O
obtained -X- _ O
from -X- _ O
29.5 -X- _ O
M -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
The -X- _ O
subset -X- _ O
size -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
n= -X- _ B-HyperparameterName
512 -X- _ B-HyperparameterValue
. -X- _ O
Table -X- _ O
1shows -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
“ -X- _ O
tok -X- _ O
/ -X- _ O
s -X- _ O
” -X- _ O
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
generated -X- _ O
per -X- _ O
second -X- _ O
. -X- _ O
The -X- _ O
table -X- _ O
shows -X- _ O
that -X- _ O
, -X- _ O
although -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
improves -X- _ O
0.9 -X- _ O
BLEU -X- _ B-MetricName
point -X- _ O
from -X- _ O
the -X- _ O
base -X- _ O
MT -X- _ B-TaskName
without -X- _ O
additional -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
is -X- _ O
326.1 -X- _ B-MetricValue
times -X- _ I-MetricValue
and -X- _ O
51.7 -X- _ B-MetricValue
times -X- _ I-MetricValue
slower -X- _ B-MetricName
with -X- _ O
the -X- _ O
Band -X- _ O
Bsettings -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
h -X- _ O
: -X- _ O
LaBSE -X- _ O
) -X- _ O
is -X- _ O
111.8 -X- _ B-MetricValue
times -X- _ I-MetricValue
( -X- _ O
with -X- _ O
B -X- _ O
) -X- _ O
and -X- _ O
47.4 -X- _ B-MetricValue
times -X- _ I-MetricValue
( -X- _ O
with -X- _ O
B -X- _ O
) -X- _ O
faster -X- _ B-MetricName
thankNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
with -X- _ O
no -X- _ O
degradation -X- _ O
in -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
h -X- _ O
: -X- _ O
AvgEnc -X- _ O
) -X- _ O
achieved -X- _ O
speed -X- _ B-MetricName
- -X- _ I-MetricName
ups -X- _ I-MetricName
of -X- _ O
92.7 -X- _ B-MetricValue
times -X- _ I-MetricValue
( -X- _ O
with -X- _ O
B -X- _ O
) -X- _ O
and -X- _ O
38.9 -X- _ B-MetricValue
times -X- _ I-MetricValue
( -X- _ O
with -X- _ O
B -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
slight -X- _ O
quality -X- _ B-MetricName
degradation -X- _ O
( -X- _ O
−0.2 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
and−0.05 -X- _ B-MetricValue
COMET -X- _ B-MetricName
) -X- _ O
, -X- _ O
despite -X- _ O
using -X- _ O
no -X- _ O
external -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
evaluated -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
when -X- _ O
using -X- _ O
non -X- _ O
- -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
( -X- _ O
h -X- _ O
: -X- _ O
TF -X- _ O
- -X- _ O
IDF -X- _ O
, -X- _ O
BM25 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
both -X- _ O
TFIDF -X- _ O
and -X- _ O
BM25 -X- _ O
can -X- _ O
generate -X- _ O
translations -X- _ O
with -X- _ O
almost -X- _ O
the -X- _ O
same -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
and -X- _ O
speed -X- _ O
as -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
this -X- _ O
experiment -X- _ O
showed -X- _ O
that -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
two -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
faster -X- _ O
than -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
translation -X- _ O
performance -X- _ O
. -X- _ O
4.3 -X- _ O
Domain -X- _ O
Adaptation -X- _ O
German -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
We -X- _ O
evaluated -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
on -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
translation -X- _ O
in -X- _ O
the -X- _ O
IT -X- _ O
, -X- _ O
Koran -X- _ O
, -X- _ O
Law -X- _ O
, -X- _ O
Medical -X- _ O
, -X- _ O
and -X- _ O
Subtitles -X- _ O
domains -X- _ O
( -X- _ O
Koehn -X- _ O
and -X- _ O
Knowles -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Aharoni -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
. -X- _ O
The -X- _ O
datastore -X- _ O
was -X- _ O
constructed -X- _ O
from -X- _ O
parallel -X- _ O
data -X- _ O
by -X- _ O
merging -X- _ O
all -X- _ O
target -X- _ O
domains -X- _ O
and -X- _ O
the -X- _ O
general -X- _ O
domain -X- _ O
( -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
) -X- _ O
assuming -X- _ O
that -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
is -X- _ O
unknown -X- _ O
. -X- _ O
The -X- _ O
datastore -X- _ O
contained -X- _ O
895.9 -X- _ O
M -X- _ O
tokens -X- _ O
obtained -X- _ O
from -X- _ O
30.8 -X- _ O
M -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
The -X- _ O
NMT -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
used -X- _ O
in -X- _ O
Section -X- _ O
4.2trained -X- _ O
from -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
. -X- _ O
The -X- _ O
subset -X- _ O
size -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
n= -X- _ B-HyperparameterName
256 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
12,000 -X- _ B-HyperparameterValue
tokens -X- _ O
. -X- _ O
Table -X- _ O
2shows -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
improves -X- _ O
the -X- _ O
translation -X- _ O
performance -X- _ O
in -X- _ O
all -X- _ O
domains -X- _ O
but -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
is -X- _ O
much -X- _ O
slower -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
generates -X- _ O
translations -X- _ O
faster -X- _ O
than -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
task -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
differences -X- _ O
in -X- _ O
translation -X- _ O
quality -X- _ O
between -X- _ O
those -X- _ O
using -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
and -X- _ O
those -X- _ O
using -X- _ O
non -X- _ O
- -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
. -X- _ O
The -X- _ O
table -X- _ O
shows178 -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
( -X- _ O
TFIDF -X- _ O
and -X- _ O
BM25 -X- _ O
) -X- _ O
causes -X- _ O
drop -X- _ O
in -X- _ O
translation -X- _ O
quality -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
( -X- _ O
LaBSE -X- _ O
and -X- _ O
AvgEnc -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
with -X- _ O
neural -X- _ O
encoders -X- _ O
achieves -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
1.6 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
points -X- _ O
on -X- _ O
some -X- _ O
datasets -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
neural -X- _ O
sentence -X- _ O
encoders -X- _ O
are -X- _ O
effective -X- _ O
in -X- _ O
retrieving -X- _ O
domain -X- _ O
- -X- _ O
speciﬁc -X- _ O
nearest -X- _ O
neighbor -X- _ O
sentences -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
datastore -X- _ O
. -X- _ O
English -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Japanese -X- _ O
We -X- _ O
also -X- _ O
evaluated -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
English -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Japanese -X- _ O
translation -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
big -X- _ O
model -X- _ O
trained -X- _ O
from -X- _ O
JParaCrawl -X- _ B-DatasetName
v3 -X- _ I-DatasetName
( -X- _ O
Morishita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
evaluated -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
Asian -X- _ B-DatasetName
Scientiﬁc -X- _ I-DatasetName
Paper -X- _ I-DatasetName
Excerpt -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
ASPEC -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Nakazawa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
Kyoto -X- _ B-DatasetName
Free -X- _ I-DatasetName
Translation -X- _ I-DatasetName
Task -X- _ I-DatasetName
( -X- _ O
KFTT -X- _ B-DatasetName
; -X- _ O
created -X- _ O
from -X- _ O
Wikipedia -X- _ O
’s -X- _ O
Kyoto -X- _ O
articles -X- _ O
) -X- _ O
( -X- _ O
Neubig -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
datastore -X- _ O
was -X- _ O
constructed -X- _ O
from -X- _ O
parallel -X- _ O
data -X- _ O
by -X- _ O
merging -X- _ O
ASPEC -X- _ B-DatasetName
, -X- _ O
KFTT -X- _ B-DatasetName
, -X- _ O
and -X- _ O
the -X- _ O
general -X- _ O
domain -X- _ O
( -X- _ O
JParaCrawl -X- _ B-DatasetName
v3 -X- _ I-DatasetName
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
ASPEC -X- _ B-DatasetName
contains -X- _ O
3 -X- _ O
M -X- _ O
sentence -X- _ O
pairs -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
used -X- _ O
only -X- _ O
the -X- _ O
ﬁrst -X- _ O
2 -X- _ O
M -X- _ O
pairs -X- _ O
for -X- _ O
the -X- _ O
datastore -X- _ O
to -X- _ O
remove -X- _ O
noisy -X- _ O
data -X- _ O
, -X- _ O
following -X- _ O
Neubig -X- _ O
( -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
datastore -X- _ O
contained -X- _ O
735.9 -X- _ O
M -X- _ O
tokens -X- _ O
obtained -X- _ O
from -X- _ O
24.4 -X- _ O
M -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
The -X- _ O
subset -X- _ O
size -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
n= -X- _ O
512 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
12,000 -X- _ O
tokens -X- _ O
. -X- _ O
Table -X- _ O
3shows -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
These -X- _ O
show -X- _ O
that -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
improves -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
translation -X- _ O
performance -X- _ O
compared -X- _ O
with -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
on -X- _ O
other -X- _ O
language -X- _ O
pairs -X- _ O
other -X- _ O
than -X- _ O
German -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
. -X- _ O
On -X- _ O
English -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Japanese -X- _ O
, -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
improves -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
, -X- _ O
but -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
with -X- _ O
TFIDF -X- _ O
and -X- _ O
BM25 -X- _ O
degrades -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
compared -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
subset -X- _ B-MethodName
kNNMT -X- _ I-MethodName
still -X- _ O
achieves -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
than -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
without -X- _ O
any -X- _ O
additional -X- _ O
training -X- _ O
steps -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
two -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
faster -X- _ O
than -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT.In -X- _ I-MethodName
summary -X- _ O
, -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
can -X- _ O
achieve -X- _ O
better -X- _ O
translation -X- _ O
performance -X- _ O
than -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
in -X- _ O
exchange -X- _ O
for -X- _ O
a -X- _ O
small -X- _ O
slowdown -X- _ O
in -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
. -X- _ O
5 -X- _ O
Discussion -X- _ O
5.1 -X- _ O
Case -X- _ O
Study -X- _ O
: -X- _ O
Effects -X- _ O
of -X- _ O
Subset -X- _ O
Search -X- _ O
Translation -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
medical -X- _ O
domain -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4and -X- _ O
the -X- _ O
search -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
top3 -X- _ O
nearest -X- _ O
neighbor -X- _ O
sentences -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
the -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
results -X- _ O
are -X- _ O
obtained -X- _ O
using -X- _ O
a -X- _ O
LaBSE -X- _ O
encoder -X- _ O
. -X- _ O
Table -X- _ O
4shows -X- _ O
that -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
correctly -X- _ O
generates -X- _ O
the -X- _ O
medical -X- _ O
term -X- _ O
“ -X- _ O
Co -X- _ O
- -X- _ O
administration -X- _ O
” -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
sentence -X- _ O
search -X- _ O
( -X- _ O
Table -X- _ O
5 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
“ -X- _ O
Co -X- _ O
- -X- _ O
administration -X- _ O
” -X- _ O
is -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
subset -X- _ O
. -X- _ O
In -X- _ O
detail -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
30 -X- _ O
cases -X- _ O
of -X- _ O
“ -X- _ O
Co -X- _ O
- -X- _ O
administration -X- _ O
” -X- _ O
and -X- _ O
no -X- _ O
case -X- _ O
of -X- _ O
“ -X- _ O
A -X- _ O
joint -X- _ O
use -X- _ O
” -X- _ O
in -X- _ O
the -X- _ O
whole -X- _ O
subset -X- _ O
consisting -X- _ O
of -X- _ O
k= -X- _ B-HyperparameterName
256 -X- _ B-HyperparameterValue
neighbor -X- _ O
sentences -X- _ O
. -X- _ O
Base -X- _ B-MethodName
MT -X- _ I-MethodName
and -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
have -X- _ O
the -X- _ O
subwords -X- _ O
of -X- _ O
“ -X- _ O
Coadministration -X- _ O
” -X- _ O
in -X- _ O
the -X- _ O
candidates -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
subwords -X- _ O
of -X- _ O
“ -X- _ O
A -X- _ O
joint -X- _ O
use -X- _ O
” -X- _ O
have -X- _ O
higher -X- _ O
scores -X- _ O
. -X- _ O
Table6shows -X- _ O
the -X- _ O
negative -X- _ B-MetricName
log -X- _ I-MetricName
- -X- _ I-MetricName
likelihood -X- _ I-MetricName
( -X- _ O
NLL -X- _ B-MetricName
) -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
three -X- _ O
tokens -X- _ O
and -X- _ O
their -X- _ O
average -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
token -X- _ O
of -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
“ -X- _ O
” -X- _ O
( -X- _ O
hyphen -X- _ O
) -X- _ O
, -X- _ O
has -X- _ O
a -X- _ O
signiﬁcantly -X- _ O
lower -X- _ O
NLL -X- _ B-MetricName
than -X- _ O
the -X- _ O
other -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
of -X- _ O
“ -X- _ O
joint -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
” -X- _ O
in -X- _ O
the -X- _ O
subset -X- _ O
were -X- _ O
0 -X- _ O
and -X- _ O
101 -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
thek -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
tokens -X- _ O
were -X- _ O
all -X- _ O
“ -X- _ O
- -X- _ O
” -X- _ O
in -X- _ O
subsetkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
NLL -X- _ B-MetricName
was -X- _ O
low -X- _ O
because -X- _ O
p -X- _ O
( -X- _ O
“- -X- _ O
” -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
.0 -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
joint -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
beam -X- _ O
that -X- _ O
generates -X- _ O
the -X- _ O
sequence -X- _ O
“ -X- _ O
Coadministration -X- _ O
” -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
“ -X- _ O
A -X- _ O
joint -X- _ O
use -X- _ O
” -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
can -X- _ O
retrieve -X- _ O
more -X- _ O
appropriate -X- _ O
words -X- _ O
by -X- _ O
searching -X- _ O
a -X- _ O
subset -X- _ O
that -X- _ O
consists -X- _ O
only -X- _ O
of -X- _ O
neighboring -X- _ O
cases.179 -X- _ O
5.2 -X- _ O
Diversity -X- _ O
of -X- _ O
Subset -X- _ O
Sentences -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
noise -X- _ O
introduced -X- _ O
by -X- _ O
sentence -X- _ O
encoders -X- _ O
causes -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
whether -X- _ O
a -X- _ O
better -X- _ O
sentence -X- _ O
encoder -X- _ O
would -X- _ O
reduce -X- _ O
the -X- _ O
noise -X- _ O
injected -X- _ O
into -X- _ O
the -X- _ O
subset -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
investigated -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
vocabulary -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
subset -X- _ O
and -X- _ O
translation -X- _ O
quality -X- _ O
in -X- _ O
the -X- _ O
medical -X- _ O
domain -X- _ O
. -X- _ O
Because -X- _ O
an -X- _ O
output -X- _ O
sentence -X- _ O
is -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
subset -X- _ O
, -X- _ O
we -X- _ O
measured -X- _ O
the -X- _ O
unique -X- _ O
token -X- _ O
ratio -X- _ O
of -X- _ O
both -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
subset -X- _ O
as -X- _ O
the -X- _ O
diversity -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
tokens -X- _ O
number -X- _ O
of -X- _ O
subset -X- _ O
tokens -X- _ O
. -X- _ O
( -X- _ O
11 -X- _ O
) -X- _ O
Table -X- _ O
7shows -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
and -X- _ O
unique -X- _ O
token -X- _ O
ratio -X- _ O
for -X- _ O
the -X- _ O
various -X- _ O
sentence -X- _ O
encoders -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
“ -X- _ O
source -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
target -X- _ O
” -X- _ O
indicate -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
neighbor -X- _ O
sentences -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
- -X- _ O
side -X- _ O
and -X- _ O
target -X- _ O
- -X- _ O
side -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
more -X- _ O
diverse -X- _ O
the -X- _ O
source -X- _ O
- -X- _ O
side -X- _ O
is -X- _ O
, -X- _ O
the -X- _ O
more -X- _ O
diverse -X- _ O
the -X- _ O
target -X- _ O
- -X- _ O
side -X- _ O
is -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
less -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
subset -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
investigated -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
sentence -X- _ O
encoder -X- _ O
representation -X- _ O
and -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
using -X- _ O
a -X- _ O
model -X- _ O
more -X- _ O
accurately -X- _ O
represents -X- _ O
sentence -X- _ O
similarity -X- _ O
improves -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
translation -X- _ O
quality -X- _ O
when -X- _ O
noise -X- _ O
was -X- _ O
injected -X- _ O
into -X- _ O
the -X- _ O
subset -X- _ O
by -X- _ O
retrieving -X- _ O
nsentences -X- _ O
from -X- _ O
outside -X- _ O
the -X- _ O
nearest -X- _ O
neighbor -X- _ O
. -X- _ O
Table -X- _ O
8shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
variousn -X- _ O
- -X- _ O
selection -X- _ O
methods -X- _ O
when -X- _ O
LaBSE -X- _ O
was -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
sentence -X- _ O
encoder -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
“ -X- _ O
Top -X- _ O
” -X- _ O
indicates -X- _ O
the -X- _ O
n -X- _ O
- -X- _ O
nearest -X- _ O
- -X- _ O
neighbor -X- _ O
sentences -X- _ O
, -X- _ O
“ -X- _ O
Bottom180 -X- _ O
of2n -X- _ O
” -X- _ O
the -X- _ O
nfurthest -X- _ O
sentences -X- _ O
of -X- _ O
2nneighbor -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
“ -X- _ O
Random -X- _ O
of -X- _ O
2n”nsentences -X- _ O
randomly -X- _ O
selected -X- _ O
from -X- _ O
2nneighbor -X- _ O
sentences -X- _ O
. -X- _ O
The -X- _ O
“ -X- _ O
Bottom -X- _ O
of -X- _ O
2n -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
Random -X- _ O
of -X- _ O
2n -X- _ O
” -X- _ O
have -X- _ O
higher -X- _ O
diversity -X- _ O
than -X- _ O
the -X- _ O
“ -X- _ O
Top -X- _ O
” -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
source- -X- _ O
and -X- _ O
target -X- _ O
- -X- _ O
sides -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
are -X- _ O
correspondingly -X- _ O
lower -X- _ O
. -X- _ O
These -X- _ O
experiments -X- _ O
showed -X- _ O
that -X- _ O
a -X- _ O
sentence -X- _ O
encoder -X- _ O
that -X- _ O
calculates -X- _ O
similarity -X- _ O
appropriately -X- _ O
can -X- _ O
reduce -X- _ O
noise -X- _ O
and -X- _ O
prevent -X- _ O
the -X- _ O
degradation -X- _ O
of -X- _ O
translation -X- _ O
performance -X- _ O
because -X- _ O
the -X- _ O
subset -X- _ O
consists -X- _ O
only -X- _ O
of -X- _ O
similar -X- _ O
sentences -X- _ O
. -X- _ O
5.3 -X- _ O
Analysis -X- _ O
of -X- _ O
Decoding -X- _ O
Speed -X- _ O
Efﬁciency -X- _ O
of -X- _ O
ADC -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
computes -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
vector -X- _ O
and -X- _ O
key -X- _ O
vectors -X- _ O
using -X- _ O
ADC -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O
The -X- _ O
efﬁciency -X- _ O
of -X- _ O
ADC -X- _ O
in -X- _ O
WMT’19 -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
is -X- _ O
demonstrated -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
“ -X- _ O
w -X- _ O
/ -X- _ O
ADC -X- _ O
” -X- _ O
is -X- _ O
roughly -X- _ O
4 -X- _ B-MetricValue
to -X- _ O
5 -X- _ B-MetricValue
times -X- _ O
faster -X- _ B-MetricName
than -X- _ O
“ -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
ADC -X- _ O
” -X- _ O
. -X- _ O
Effect -X- _ O
of -X- _ O
Parallelization -X- _ O
The -X- _ O
method -X- _ O
and -X- _ O
implementation -X- _ O
of -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
are -X- _ O
designed -X- _ O
for -X- _ O
parallel -X- _ O
computing -X- _ O
. -X- _ O
We -X- _ O
measured -X- _ O
the -X- _ O
translation -X- _ O
speed -X- _ O
for -X- _ O
different -X- _ O
batch -X- _ O
sizes -X- _ O
in -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
. -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
h -X- _ O
: -X- _ O
LaBSE -X- _ O
) -X- _ O
is -X- _ O
two -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
faster -X- _ O
than -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
even -X- _ O
when -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
increased -X- _ O
. -X- _ O
Subset -X- _ O
Size -X- _ O
We -X- _ O
measured -X- _ O
the -X- _ O
translation -X- _ O
speed -X- _ O
for -X- _ O
different -X- _ O
subset -X- _ O
sizes -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
nnearest -X- _ O
- -X- _ O
neighbor -X- _ O
sentences -X- _ O
in -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
. -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
translation -X- _ O
speed -X- _ O
of -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
h -X- _ O
: -X- _ O
LaBSE -X- _ O
) -X- _ O
. -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
two -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
faster -X- _ O
than -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
even -X- _ O
whenthe -X- _ O
subset -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
increased -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
speed -X- _ O
becomes -X- _ O
slower -X- _ O
from -X- _ O
n= -X- _ B-HyperparameterName
256 -X- _ B-HyperparameterValue
compared -X- _ O
with -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
found -X- _ O
that -X- _ O
71.7 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
was -X- _ O
spent -X- _ O
searching -X- _ O
for -X- _ O
the -X- _ O
kNN -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
subset -X- _ O
when -X- _ O
n= -X- _ B-HyperparameterName
2048 -X- _ B-HyperparameterValue
. -X- _ O
Although -X- _ O
ADC -X- _ O
lookup -X- _ O
search -X- _ O
is -X- _ O
slow -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
datastore -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
fast -X- _ O
for -X- _ O
kNN -X- _ O
search -X- _ O
when -X- _ O
the -X- _ O
subset -X- _ O
size -X- _ O
nis -X- _ O
not -X- _ O
large -X- _ O
( -X- _ O
Matsui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
n= -X- _ B-HyperparameterName
512 -X- _ B-HyperparameterValue
. -X- _ O
Figure -X- _ O
3 -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
translation -X- _ O
quality -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
( -X- _ O
newstest2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
larger -X- _ O
nimproves -X- _ B-HyperparameterName
BLEU -X- _ B-MetricName
up -X- _ O
to -X- _ O
n= -X- _ B-HyperparameterName
512 -X- _ B-HyperparameterValue
, -X- _ O
but -X- _ O
decreases -X- _ O
for -X- _ O
greater -X- _ O
values -X- _ O
ofn -X- _ B-HyperparameterName
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
the -X- _ O
translation -X- _ O
quality -X- _ O
and -X- _ O
translation -X- _ O
speed -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
n= -X- _ B-HyperparameterName
512 -X- _ B-HyperparameterValue
for -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
. -X- _ O
6 -X- _ O
Related -X- _ O
Work -X- _ O
The -X- _ O
ﬁrst -X- _ O
type -X- _ O
of -X- _ O
example -X- _ O
- -X- _ O
based -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
method -X- _ O
was -X- _ O
analogy -X- _ O
- -X- _ O
based -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
Nagao -X- _ O
, -X- _ O
1984 -X- _ O
) -X- _ O
.Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
incorporated -X- _ O
example -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
into -X- _ O
NMT -X- _ B-TaskName
models -X- _ O
, -X- _ O
which -X- _ O
retrieve -X- _ O
examples -X- _ O
according -X- _ O
to -X- _ O
edit -X- _ O
distance -X- _ O
. -X- _ O
Bulte -X- _ O
and -X- _ O
Tezcan -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Xu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
concatenated -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
and -X- _ O
translations -X- _ O
of -X- _ O
sentences -X- _ O
similar -X- _ O
to -X- _ O
it -X- _ O
. -X- _ O
Both -X- _ O
kNNMT -X- _ B-MethodName
and -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
retrieve -X- _ O
kNN -X- _ O
tokens -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
distance -X- _ O
of -X- _ O
intermediate -X- _ O
representations -X- _ O
and -X- _ O
interpolate -X- _ O
the -X- _ O
output -X- _ O
probability -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
of -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
fastkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
( -X- _ O
Meng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
constructs -X- _ O
additional -X- _ O
datastores -X- _ O
for -X- _ O
each -X- _ O
source -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
reduces -X- _ O
the -X- _ O
kNN -X- _ O
search -X- _ O
space -X- _ O
using -X- _ O
their -X- _ O
datastores -X- _ O
and -X- _ O
word -X- _ O
alignment -X- _ O
. -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
requires -X- _ O
a -X- _ O
sentence -X- _ O
datastore -X- _ O
that -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
source -X- _ O
token -X- _ O
datastores -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
word -X- _ O
alignment -X- _ O
. -X- _ O
Martins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
decreased -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
query -X- _ O
times -X- _ O
by -X- _ O
retrieving -X- _ O
chunked -X- _ O
text -X- _ O
; -X- _ O
their -X- _ O
model -X- _ O
led -X- _ O
to -X- _ O
a -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
4 -X- _ O
times -X- _ O
, -X- _ O
compared -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
reduces -X- _ O
the -X- _ O
search -X- _ O
space -X- _ O
. -X- _ O
Dai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2023 -X- _ O
) -X- _ O
reduced -X- _ O
thekNN -X- _ O
search -X- _ O
space -X- _ O
by -X- _ O
retrieving -X- _ O
the -X- _ O
neighbor -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
. -X- _ O
They -X- _ O
searched -X- _ O
for -X- _ O
neighboring -X- _ O
sentences -X- _ O
by -X- _ O
BM25 -X- _ O
scores -X- _ O
with -X- _ O
ElasticSearch -X- _ O
, -X- _ O
so -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
with -X- _ O
BM25 -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
an -X- _ O
approximation -X- _ O
of -X- _ O
their -X- _ O
method -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
proposed -X- _ O
“ -X- _ O
adaptive -X- _ O
lambda -X- _ O
” -X- _ O
, -X- _ O
which -X- _ O
dynamically -X- _ O
computes -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
lambda -X- _ O
of -X- _ O
linear -X- _ O
interpolation -X- _ O
in -X- _ O
Equation -X- _ O
2from -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
query -X- _ O
and -X- _ O
the -X- _ O
nearest -X- _ O
neighbor181 -X- _ O
key -X- _ O
vectors -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
adaptive -X- _ O
lambda -X- _ O
requires -X- _ O
an -X- _ O
exact -X- _ O
distance -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
employ -X- _ O
datastore -X- _ O
quantization -X- _ O
and -X- _ O
the -X- _ O
ADC -X- _ O
lookup -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
translation -X- _ O
performance -X- _ O
of -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
computed -X- _ O
the -X- _ O
weighted -X- _ O
average -X- _ O
of -X- _ O
kNN -X- _ O
probabilities -X- _ O
pover -X- _ O
multiple -X- _ O
values -X- _ O
of -X- _ O
k. -X- _ O
Each -X- _ O
weight -X- _ O
is -X- _ O
predicted -X- _ O
by -X- _ O
“ -X- _ O
meta- -X- _ O
knetwork -X- _ O
” -X- _ O
, -X- _ O
trained -X- _ O
to -X- _ O
minimize -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
other -X- _ O
tasks -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
LM -X- _ I-MethodName
( -X- _ O
Khandelwal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Efﬁcient -X- _ O
kNN -X- _ O
- -X- _ O
LM -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
RETRO -X- _ O
( -X- _ O
Borgeaud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
used -X- _ O
kNN -X- _ O
search -X- _ O
for -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
subset -X- _ O
search -X- _ O
method -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
LM -X- _ O
because -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
obtained -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
ﬁeld -X- _ O
of -X- _ O
kNN -X- _ O
search -X- _ O
, -X- _ O
Matsui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
allowed -X- _ O
search -X- _ O
in -X- _ O
dynamically -X- _ O
created -X- _ O
subsets -X- _ O
, -X- _ O
whereas -X- _ O
conventional -X- _ O
search -X- _ O
methods -X- _ O
assume -X- _ O
only -X- _ O
full -X- _ O
search -X- _ O
. -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
retrieves -X- _ O
kNN -X- _ O
tokens -X- _ O
from -X- _ O
a -X- _ O
subset -X- _ O
depending -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
, -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
is -X- _ O
slow -X- _ O
when -X- _ O
the -X- _ O
subset -X- _ O
size -X- _ O
nis -X- _ O
large -X- _ O
. -X- _ O
The -X- _ O
bottleneck -X- _ O
is -X- _ O
the -X- _ O
lookup -X- _ O
in -X- _ O
the -X- _ O
distance -X- _ O
table -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
efﬁcient -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
methods -X- _ O
that -X- _ O
uses -X- _ O
SIMD -X- _ O
( -X- _ O
André -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Matsui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
7 -X- _ O
Conclusion -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
“ -X- _ O
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
” -X- _ O
, -X- _ O
which -X- _ O
improves -X- _ O
the -X- _ O
decoding -X- _ O
speed -X- _ O
of -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
by -X- _ O
two -X- _ O
methods -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
retrieving -X- _ O
neighbor -X- _ O
tokens -X- _ O
from -X- _ O
only -X- _ O
the -X- _ O
neighbor -X- _ O
sentences -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
not -X- _ O
from -X- _ O
all -X- _ O
sentences -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
efﬁcient -X- _ O
distance -X- _ O
computation -X- _ O
technique -X- _ O
that -X- _ O
is -X- _ O
suitable -X- _ O
for -X- _ O
subset -X- _ O
neighbor -X- _ O
search -X- _ O
using -X- _ O
a -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
table -X- _ O
. -X- _ O
Our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
achieved -X- _ O
a -X- _ O
speed -X- _ B-MetricName
- -X- _ I-MetricName
up -X- _ I-MetricName
of -X- _ O
up -X- _ O
to -X- _ O
132.2 -X- _ B-MetricValue
times -X- _ I-MetricValue
and -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
BLEU -X- _ B-MetricName
of -X- _ O
up -X- _ O
to -X- _ O
1.6 -X- _ B-MetricValue
compared -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
in -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
translation -X- _ B-TaskName
task -X- _ O
and -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptationtasks -X- _ I-TaskName
in -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
and -X- _ O
En -X- _ O
- -X- _ O
Ja -X- _ O
. -X- _ O
For -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
apply -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O
Limitations -X- _ O
This -X- _ O
study -X- _ O
focuses -X- _ O
only -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
speed -X- _ O
of -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
during -X- _ O
decoding -X- _ O
; -X- _ O
other -X- _ O
problems -X- _ O
with -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
remain -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
still -X- _ O
demands -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
memory -X- _ O
and -X- _ O
disk -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
datastore -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
requires -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
sentence -X- _ O
datastore -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
the -X- _ O
memory -X- _ O
and -X- _ O
disk -X- _ O
requirements -X- _ O
are -X- _ O
increased -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
quantized -X- _ O
target -X- _ O
token -X- _ O
datastore -X- _ O
has -X- _ O
52 -X- _ O
GB -X- _ O
( -X- _ O
|M| -X- _ O
= -X- _ O
862 -X- _ O
, -X- _ O
648,422 -X- _ O
) -X- _ O
and -X- _ O
our -X- _ O
sentence -X- _ O
datastore -X- _ O
has -X- _ O
2 -X- _ O
GB -X- _ O
( -X- _ O
|S|= -X- _ O
29,540,337 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
experiment -X- _ O
of -X- _ O
WMT’19 -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
( -X- _ O
Section -X- _ O
4.2 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
faster -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
in -X- _ O
inference -X- _ O
, -X- _ O
datastore -X- _ O
construction -X- _ O
is -X- _ O
still -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
. -X- _ O
The -X- _ O
decoding -X- _ O
latency -X- _ O
of -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
still -X- _ O
several -X- _ O
times -X- _ O
slower -X- _ O
than -X- _ O
base -X- _ B-MethodName
MT -X- _ I-MethodName
for -X- _ O
large -X- _ O
batch -X- _ O
sizes -X- _ O
. -X- _ O
The -X- _ O
experiments -X- _ O
reported -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
evaluated -X- _ O
the -X- _ O
inference -X- _ O
speed -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
computer -X- _ O
and -X- _ O
single -X- _ O
run -X- _ O
only -X- _ O
; -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
speed -X- _ O
improvement -X- _ O
may -X- _ O
differ -X- _ O
when -X- _ O
different -X- _ O
computer -X- _ O
architectures -X- _ O
are -X- _ O
used -X- _ O
. -X- _ O
Ethical -X- _ O
Consideration -X- _ O
We -X- _ O
construct -X- _ O
both -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
datastores -X- _ O
from -X- _ O
open -X- _ O
datasets -X- _ O
; -X- _ O
therefore -X- _ O
, -X- _ O
if -X- _ O
their -X- _ O
datasets -X- _ O
have -X- _ O
toxic -X- _ O
text -X- _ O
, -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
and -X- _ O
our -X- _ O
subsetkNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
may -X- _ O
have -X- _ O
the -X- _ O
risk -X- _ O
of -X- _ O
generating -X- _ O
toxic -X- _ O
contents -X- _ O
. -X- _ O
Acknowledgements -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
partially -X- _ O
supported -X- _ O
by -X- _ O
JSPS -X- _ O
KAKENHI -X- _ O
Grant -X- _ O
Number -X- _ O
JP22J1127 -X- _ O
and -X- _ O
JP22KJ2286.182References183184 -X- _ O
A -X- _ O
Datasets -X- _ O
, -X- _ O
Tools -X- _ O
, -X- _ O
Models -X- _ O
Datasets -X- _ O
Parallel -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
translation -X- _ B-TaskName
task -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.statmt.org -X- _ O
/ -X- _ O
wmt19 -X- _ O
/ -X- _ O
translation -X- _ O
- -X- _ O
task.html -X- _ O
. -X- _ O
The -X- _ O
ﬁve -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
datasets -X- _ O
in -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
( -X- _ O
Aharoni -X- _ O
and -X- _ O
Goldberg -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
ASPEC -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
jipsti.jst.go.jp -X- _ O
/ -X- _ O
aspec -X- _ O
/ -X- _ O
. -X- _ O
KFTT -X- _ O
is -X- _ O
licensed -X- _ O
by -X- _ O
Creative -X- _ O
Commons -X- _ O
Attribution -X- _ O
- -X- _ O
Share -X- _ O
- -X- _ O
Alike -X- _ O
License -X- _ O
3.0 -X- _ O
. -X- _ O
Tools -X- _ O
and -X- _ O
are -X- _ O
MIT -X- _ O
- -X- _ O
licensed -X- _ O
. -X- _ O
Models -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
following -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
NMT -X- _ O
models -X- _ O
implemented -X- _ O
in -X- _ O
. -X- _ O
•De -X- _ O
- -X- _ O
En -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
dl -X- _ O
. -X- _ O
fbaipublicfiles.com -X- _ O
/ -X- _ O
fairseq -X- _ O
/ -X- _ O
models -X- _ O
/ -X- _ O
wmt19.de -X- _ O
- -X- _ O
en.ffn8192 -X- _ O
. -X- _ O
tar.gz -X- _ O
•En -X- _ O
- -X- _ O
Ja -X- _ O
: -X- _ O
http -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.kecl.ntt -X- _ O
. -X- _ O
co.jp -X- _ O
/ -X- _ O
icl -X- _ O
/ -X- _ O
lirg -X- _ O
/ -X- _ O
jparacrawl -X- _ O
/ -X- _ O
release -X- _ O
/ -X- _ O
3.0 -X- _ O
/ -X- _ O
pretrained_models -X- _ O
/ -X- _ O
en -X- _ O
- -X- _ O
ja -X- _ O
/ -X- _ O
big.tar.gz -X- _ O
The -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
model -X- _ O
is -X- _ O
included -X- _ O
in -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
MIT -X- _ O
- -X- _ O
licensed -X- _ O
. -X- _ O
The -X- _ O
Ja -X- _ O
- -X- _ O
En -X- _ O
model -X- _ O
is -X- _ O
licensed -X- _ O
by -X- _ O
Nippon -X- _ O
Telegraph -X- _ O
and -X- _ O
Telephone -X- _ O
Corporation -X- _ O
( -X- _ O
NTT -X- _ O
) -X- _ O
for -X- _ O
research -X- _ O
use -X- _ O
only -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
http -X- _ O
: -X- _ O
/ -X- _ O
/ -X- _ O
www.kecl.ntt.co.jp -X- _ O
/ -X- _ O
icl -X- _ O
/ -X- _ O
lirg -X- _ O
/ -X- _ O
jparacrawl -X- _ O
/ -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LaBSE -X- _ O
model -X- _ O
licensed -X- _ O
by -X- _ O
Apache-2.0 -X- _ O
. -X- _ O
B -X- _ O
Pseudo -X- _ O
Code -X- _ O
for -X- _ O
ADC -X- _ O
lookup -X- _ O
Algorithm -X- _ O
1shows -X- _ O
the -X- _ O
pseudo -X- _ O
code -X- _ O
for -X- _ O
the -X- _ O
ADC -X- _ O
lookup -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O
The -X- _ O
function -X- _ O
_ -X- _ O
calculates -X- _ O
the -X- _ O
squared -X- _ O
Euclidean -X- _ O
distances -X- _ O
between -X- _ O
a -X- _ O
query -X- _ O
vector -X- _ O
and -X- _ O
each -X- _ O
quantized -X- _ O
key -X- _ O
vector -X- _ O
by -X- _ O
looking -X- _ O
up -X- _ O
the -X- _ O
distance -X- _ O
table -X- _ O
. -X- _ O
C -X- _ O
Tuning -X- _ O
of -X- _ O
the -X- _ O
Subset -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
in -X- _ O
Domain -X- _ B-TaskName
Adaptation -X- _ I-TaskName
Section -X- _ O
5.3showed -X- _ O
that -X- _ O
n= -X- _ B-HyperparameterName
256 -X- _ B-HyperparameterValue
and512are -X- _ B-HyperparameterValue
in -X- _ O
balance -X- _ O
between -X- _ O
speed -X- _ O
and -X- _ O
quality -X- _ O
. -X- _ O
To -X- _ O
tune -X- _ O
theAlgorithm -X- _ O
1 -X- _ O
ADC -X- _ O
lookup -X- _ O
Require -X- _ O
: -X- _ O
query -X- _ O
; -X- _ O
q∈R -X- _ O
quantized -X- _ O
keys -X- _ O
; -X- _ O
¯K= -X- _ O
{ -X- _ O
¯k -X- _ O
} -X- _ O
⊆ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
L -X- _ O
} -X- _ O
codebook -X- _ O
; -X- _ O
C= -X- _ O
{ -X- _ O
C -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
C -X- _ O
} -X- _ O
, -X- _ O
whereC= -X- _ O
{ -X- _ O
c -X- _ O
} -X- _ O
⊆R -X- _ O
Ensure -X- _ O
: -X- _ O
distances -X- _ O
; -X- _ O
d∈Rfunction -X- _ O
_ -X- _ O
( -X- _ O
q -X- _ O
, -X- _ O
¯K -X- _ O
, -X- _ O
C -X- _ O
) -X- _ O
form= -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
M -X- _ O
do -X- _ O
forl= -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
L -X- _ O
do -X- _ O
A←∥q−c∥ -X- _ O
end -X- _ O
for -X- _ O
end -X- _ O
for -X- _ O
fori= -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
N -X- _ O
do -X- _ O
d←∑A -X- _ O
end -X- _ O
for -X- _ O
return -X- _ O
dend -X- _ O
function -X- _ O
subset -X- _ O
size -X- _ O
nin -X- _ O
the -X- _ O
domain -X- _ O
adaptation -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
evaluated -X- _ O
for -X- _ O
n= -X- _ B-HyperparameterName
256 -X- _ B-HyperparameterValue
and512on -X- _ B-HyperparameterValue
the -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
domain -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
nwas -X- _ O
judged -X- _ O
by -X- _ O
the -X- _ O
averaged -X- _ O
BLEU -X- _ B-MetricName
. -X- _ O
Table -X- _ O
10and11 -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ O
adaptation -X- _ O
translation -X- _ O
on -X- _ O
each -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
tuned -X- _ O
the -X- _ O
subset -X- _ O
size -X- _ O
by -X- _ O
using -X- _ O
LaBSE -X- _ O
for -X- _ O
the -X- _ O
sentence -X- _ O
encoder -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
n= -X- _ B-HyperparameterName
256 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
German -X- _ O
- -X- _ O
toEnglish -X- _ O
and -X- _ O
n= -X- _ B-HyperparameterName
512 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
English -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Japanese -X- _ O
domain -X- _ O
adaptation -X- _ O
tasks -X- _ O
. -X- _ O
D -X- _ O
Details -X- _ O
of -X- _ O
Translation -X- _ O
Quality -X- _ O
We -X- _ O
evaluated -X- _ O
all -X- _ O
experiments -X- _ O
by -X- _ O
BLEU -X- _ B-MetricName
, -X- _ O
COMET -X- _ B-MetricName
, -X- _ O
and -X- _ O
chrF -X- _ B-MetricName
scores -X- _ O
. -X- _ O
Table -X- _ O
12,13 -X- _ O
, -X- _ O
and -X- _ O
14show -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
translation -X- _ B-TaskName
task -X- _ O
, -X- _ O
the -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
task -X- _ O
in -X- _ O
De -X- _ O
- -X- _ O
En -X- _ O
, -X- _ O
and -X- _ O
En -X- _ O
- -X- _ O
Ja -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
Table -X- _ O
13only -X- _ O
shows -X- _ O
COMET -X- _ B-MetricName
and -X- _ O
chrF -X- _ B-MetricName
scores -X- _ O
and -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
due -X- _ O
to -X- _ O
space -X- _ O
limitations -X- _ O
. -X- _ O
E -X- _ O
Details -X- _ O
of -X- _ O
kNN -X- _ O
Indexes -X- _ O
. -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
kNN -X- _ O
indexes -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table15.185n -X- _ O
ASPEC -X- _ O
KFTT -X- _ O
Avg -X- _ O
. -X- _ O
256 -X- _ O
31.7 -X- _ O
24.5 -X- _ O
28.1 -X- _ O
512 -X- _ O
32.0 -X- _ O
25.5 -X- _ O
28.8 -X- _ O
F -X- _ O
Domain -X- _ O
Adaptation -X- _ O
with -X- _ O
Closed -X- _ O
Domain -X- _ O
Settings -X- _ O
We -X- _ O
carried -X- _ O
out -X- _ O
the -X- _ O
German -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
experiments -X- _ O
faithful -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
settings -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
the -X- _ O
datastore -X- _ O
for -X- _ O
each -X- _ O
domain -X- _ O
was -X- _ O
created -X- _ O
only -X- _ O
from -X- _ O
the -X- _ O
parallel -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
assuming -X- _ O
a -X- _ O
scenario -X- _ O
where -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
is -X- _ O
known -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
general -X- _ O
domain -X- _ O
data -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
WMT’19 -X- _ B-DatasetName
De -X- _ I-DatasetName
- -X- _ I-DatasetName
En -X- _ I-DatasetName
translation -X- _ B-TaskName
task -X- _ O
, -X- _ O
is -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
datastores -X- _ O
. -X- _ O
Table -X- _ O
16shows -X- _ O
the -X- _ O
German -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
English -X- _ O
domain -X- _ B-TaskName
adaptation -X- _ I-TaskName
translation -X- _ B-TaskName
results -X- _ O
in -X- _ O
closed -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
faster -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
settings -X- _ O
because -X- _ O
the -X- _ O
datastore -X- _ O
is -X- _ O
smaller -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
our -X- _ O
subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
is -X- _ O
still -X- _ O
10 -X- _ B-MetricValue
times -X- _ I-MetricValue
faster -X- _ B-MetricName
than -X- _ O
the -X- _ O
original -X- _ O
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT.186 -X- _ I-MethodName
kNN -X- _ B-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
Subset -X- _ B-MethodName
kNN -X- _ I-MethodName
- -X- _ I-MethodName
MT -X- _ I-MethodName
DS -X- _ O
; -X- _ O
M -X- _ O
Sentence -X- _ O
DS -X- _ O
; -X- _ O
SDS -X- _ O
; -X- _ O
ˆM -X- _ O
Search -X- _ O
Method -X- _ O
IVF -X- _ O
IVF -X- _ O
Linear -X- _ O
ADC -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
Vector -X- _ O
Transform -X- _ O
OPQ -X- _ O
OPQ -X- _ O
PCA -X- _ O
: -X- _ O
( -X- _ O
Ge -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
( -X- _ O
Ge -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
1024→256dim -X- _ O
# -X- _ O
of -X- _ O
PQ -X- _ O
Sub -X- _ O
- -X- _ O
vectors -X- _ O
; -X- _ O
M -X- _ O
64 -X- _ O
64 -X- _ O
64 -X- _ O
# -X- _ O
of -X- _ O
Centroids -X- _ O
; -X- _ O
N -X- _ O
131,072 -X- _ O
32,768 -X- _ O
— -X- _ O
# -X- _ O
of -X- _ O
Probed -X- _ O
Clusters -X- _ O
64 -X- _ O
clusters -X- _ O
64 -X- _ O
clusters -X- _ O
— -X- _ O
Size -X- _ O
of -X- _ O
Search -X- _ O
Target∑|y||D|∑|y|187ACL -X- _ O
2023 -X- _ O
Responsible -X- _ O
NLP -X- _ O
Checklist -X- _ O
A -X- _ O
For -X- _ O
every -X- _ O
submission -X- _ O
: -X- _ O
/ -X- _ O
squareA1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
describe -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
After -X- _ O
Conclusion -X- _ O
( -X- _ O
" -X- _ O
Limitations -X- _ O
" -X- _ O
section -X- _ O
) -X- _ O
/ -X- _ O
squareA2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
any -X- _ O
potential -X- _ O
risks -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
After -X- _ O
Limitations -X- _ O
( -X- _ O
" -X- _ O
Ethical -X- _ O
Consideration -X- _ O
" -X- _ O
section -X- _ O
) -X- _ O
/ -X- _ O
squareA3 -X- _ O
. -X- _ O
Do -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
introduction -X- _ O
summarize -X- _ O
the -X- _ O
paper -X- _ O
’s -X- _ O
main -X- _ O
claims -X- _ O
? -X- _ O
Section -X- _ O
1 -X- _ O
/ -X- _ O
squareA4 -X- _ O
. -X- _ O
Have -X- _ O
you -X- _ O
used -X- _ O
AI -X- _ O
writing -X- _ O
assistants -X- _ O
when -X- _ O
working -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
? -X- _ O
We -X- _ O
use -X- _ O
tools -X- _ O
that -X- _ O
only -X- _ O
assist -X- _ O
with -X- _ O
language -X- _ O
: -X- _ O
deepl -X- _ O
, -X- _ O
grammarly -X- _ O
. -X- _ O
B -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
or -X- _ O
create -X- _ O
scientiﬁc -X- _ O
artifacts -X- _ O
? -X- _ O
Section -X- _ O
4 -X- _ O
/ -X- _ O
squareB1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
cite -X- _ O
the -X- _ O
creators -X- _ O
of -X- _ O
artifacts -X- _ O
you -X- _ O
used -X- _ O
? -X- _ O
Section -X- _ O
4 -X- _ O
/ -X- _ O
squareB2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
license -X- _ O
or -X- _ O
terms -X- _ O
for -X- _ O
use -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
distribution -X- _ O
of -X- _ O
any -X- _ O
artifacts -X- _ O
? -X- _ O
Appendix -X- _ O
( -X- _ O
Section -X- _ O
A -X- _ O
: -X- _ O
Dataset -X- _ O
, -X- _ O
Tools -X- _ O
, -X- _ O
Models -X- _ O
) -X- _ O
/ -X- _ O
squareB3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
speciﬁed -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
Appendix -X- _ O
( -X- _ O
Section -X- _ O
A -X- _ O
: -X- _ O
Datasets -X- _ O
, -X- _ O
Tools -X- _ O
, -X- _ O
Models -X- _ O
) -X- _ O
/ -X- _ O
squareB4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identiﬁes -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
We -X- _ O
noted -X- _ O
in -X- _ O
the -X- _ O
Ethical -X- _ O
Consideration -X- _ O
section -X- _ O
that -X- _ O
our -X- _ O
used -X- _ O
data -X- _ O
may -X- _ O
contain -X- _ O
toxic -X- _ O
contents -X- _ O
. -X- _ O
/ -X- _ O
squareB5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
provide -X- _ O
documentation -X- _ O
of -X- _ O
the -X- _ O
artifacts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
coverage -X- _ O
of -X- _ O
domains -X- _ O
, -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
linguistic -X- _ O
phenomena -X- _ O
, -X- _ O
demographic -X- _ O
groups -X- _ O
represented -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
Section -X- _ O
4 -X- _ O
/ -X- _ O
squareB6 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
relevant -X- _ O
statistics -X- _ O
like -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
, -X- _ O
details -X- _ O
of -X- _ O
train -X- _ O
/ -X- _ O
test -X- _ O
/ -X- _ O
dev -X- _ O
splits -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
for -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
you -X- _ O
used -X- _ O
/ -X- _ O
created -X- _ O
? -X- _ O
Even -X- _ O
for -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
include -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
train -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
provide -X- _ O
necessary -X- _ O
context -X- _ O
for -X- _ O
a -X- _ O
reader -X- _ O
to -X- _ O
understand -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
small -X- _ O
differences -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
large -X- _ O
test -X- _ O
sets -X- _ O
may -X- _ O
be -X- _ O
signiﬁcant -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
small -X- _ O
test -X- _ O
sets -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
. -X- _ O
Section -X- _ O
4 -X- _ O
C -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
run -X- _ O
computational -X- _ O
experiments -X- _ O
? -X- _ O
Section -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
/ -X- _ O
squareC1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
computational -X- _ O
budget -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPU -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
infrastructure -X- _ O
used -X- _ O
? -X- _ O
Section -X- _ O
4188 -X- _ O
/ -X- _ O
squareC2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
including -X- _ O
hyperparameter -X- _ O
search -X- _ O
and -X- _ O
best -X- _ O
- -X- _ O
found -X- _ O
hyperparameter -X- _ O
values -X- _ O
? -X- _ O
Section -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
/ -X- _ O
squareC3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
descriptive -X- _ O
statistics -X- _ O
about -X- _ O
your -X- _ O
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
error -X- _ O
bars -X- _ O
around -X- _ O
results -X- _ O
, -X- _ O
summary -X- _ O
statistics -X- _ O
from -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
it -X- _ O
transparent -X- _ O
whether -X- _ O
you -X- _ O
are -X- _ O
reporting -X- _ O
the -X- _ O
max -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
or -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
? -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
of -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
and -X- _ O
that -X- _ O
is -X- _ O
noted -X- _ O
in -X- _ O
Limitations -X- _ O
section -X- _ O
. -X- _ O
/ -X- _ O
squareC4 -X- _ O
. -X- _ O
If -X- _ O
you -X- _ O
used -X- _ O
existing -X- _ O
packages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
preprocessing -X- _ O
, -X- _ O
for -X- _ O
normalization -X- _ O
, -X- _ O
or -X- _ O
for -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
implementation -X- _ O
, -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
parameter -X- _ O
settings -X- _ O
used -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
NLTK -X- _ O
, -X- _ O
Spacy -X- _ O
, -X- _ O
ROUGE -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
? -X- _ O
Section -X- _ O
4 -X- _ O
D -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
human -X- _ O
annotators -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdworkers -X- _ O
) -X- _ O
or -X- _ O
research -X- _ O
with -X- _ O
human -X- _ O
participants -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
of -X- _ O
instructions -X- _ O
given -X- _ O
to -X- _ O
participants -X- _ O
, -X- _ O
including -X- _ O
e.g. -X- _ O
, -X- _ O
screenshots -X- _ O
, -X- _ O
disclaimers -X- _ O
of -X- _ O
any -X- _ O
risks -X- _ O
to -X- _ O
participants -X- _ O
or -X- _ O
annotators -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
you -X- _ O
recruited -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdsourcing -X- _ O
platform -X- _ O
, -X- _ O
students -X- _ O
) -X- _ O
and -X- _ O
paid -X- _ O
participants -X- _ O
, -X- _ O
and -X- _ O
discuss -X- _ O
if -X- _ O
such -X- _ O
payment -X- _ O
is -X- _ O
adequate -X- _ O
given -X- _ O
the -X- _ O
participants -X- _ O
’ -X- _ O
demographic -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
country -X- _ O
of -X- _ O
residence -X- _ O
) -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
whether -X- _ O
and -X- _ O
how -X- _ O
consent -X- _ O
was -X- _ O
obtained -X- _ O
from -X- _ O
people -X- _ O
whose -X- _ O
data -X- _ O
you -X- _ O
’re -X- _ O
using -X- _ O
/ -X- _ O
curating -X- _ O
? -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
collected -X- _ O
data -X- _ O
via -X- _ O
crowdsourcing -X- _ O
, -X- _ O
did -X- _ O
your -X- _ O
instructions -X- _ O
to -X- _ O
crowdworkers -X- _ O
explain -X- _ O
how -X- _ O
the -X- _ O
data -X- _ O
would -X- _ O
be -X- _ O
used -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD4 -X- _ O
. -X- _ O
Was -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
protocol -X- _ O
approved -X- _ O
( -X- _ O
or -X- _ O
determined -X- _ O
exempt -X- _ O
) -X- _ O
by -X- _ O
an -X- _ O
ethics -X- _ O
review -X- _ O
board -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
basic -X- _ O
demographic -X- _ O
and -X- _ O
geographic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
annotator -X- _ O
population -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
? -X- _ O
No -X- _ O
response.189 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
proposes -X- _ SUMMARY
a -X- _ SUMMARY
novel -X- _ SUMMARY
Graph -X- _ SUMMARY
Propagated -X- _ SUMMARY
Data -X- _ SUMMARY
Augmentation -X- _ SUMMARY
( -X- _ SUMMARY
GPDA -X- _ SUMMARY
) -X- _ SUMMARY
framework -X- _ SUMMARY
for -X- _ SUMMARY
Named -X- _ SUMMARY
Entity -X- _ SUMMARY
Recognition -X- _ SUMMARY
( -X- _ SUMMARY
NER -X- _ SUMMARY
) -X- _ SUMMARY
to -X- _ SUMMARY
improve -X- _ SUMMARY
model -X- _ SUMMARY
performance -X- _ SUMMARY
and -X- _ SUMMARY
robustness -X- _ SUMMARY
for -X- _ SUMMARY
low -X- _ SUMMARY
- -X- _ SUMMARY
resource -X- _ SUMMARY
NER -X- _ SUMMARY
. -X- _ SUMMARY
GPDA -X- _ SUMMARY
leverages -X- _ SUMMARY
graph -X- _ SUMMARY
propagation -X- _ SUMMARY
to -X- _ SUMMARY
build -X- _ SUMMARY
relationships -X- _ SUMMARY
between -X- _ SUMMARY
labeled -X- _ SUMMARY
and -X- _ SUMMARY
unlabeled -X- _ SUMMARY
natural -X- _ SUMMARY
texts -X- _ SUMMARY
. -X- _ SUMMARY
A -X- _ SUMMARY
search -X- _ SUMMARY
engine -X- _ SUMMARY
built -X- _ SUMMARY
on -X- _ SUMMARY
Wikipedia -X- _ SUMMARY
is -X- _ SUMMARY
utilized -X- _ SUMMARY
to -X- _ SUMMARY
fetch -X- _ SUMMARY
related -X- _ SUMMARY
texts -X- _ SUMMARY
and -X- _ SUMMARY
propagate -X- _ SUMMARY
entity -X- _ SUMMARY
labels -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
conducts -X- _ SUMMARY
experiments -X- _ SUMMARY
on -X- _ SUMMARY
real -X- _ SUMMARY
- -X- _ SUMMARY
world -X- _ SUMMARY
low -X- _ SUMMARY
- -X- _ SUMMARY
resource -X- _ SUMMARY
datasets -X- _ SUMMARY
and -X- _ SUMMARY
shows -X- _ SUMMARY
that -X- _ SUMMARY
GPDA -X- _ SUMMARY
outperforms -X- _ SUMMARY
previous -X- _ SUMMARY
data -X- _ SUMMARY
augmentation -X- _ SUMMARY
methods -X- _ SUMMARY
on -X- _ SUMMARY
multiple -X- _ SUMMARY
low -X- _ SUMMARY
- -X- _ SUMMARY
resource -X- _ SUMMARY
NER -X- _ SUMMARY
datasets -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metric -X- _ SUMMARY
used -X- _ SUMMARY
is -X- _ SUMMARY
F1 -X- _ SUMMARY
score -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
paper -X- _ SUMMARY
focuses -X- _ SUMMARY
on -X- _ SUMMARY
NER -X- _ SUMMARY
tasks -X- _ SUMMARY
and -X- _ SUMMARY
provides -X- _ SUMMARY
a -X- _ SUMMARY
publicly -X- _ SUMMARY
available -X- _ SUMMARY
low -X- _ SUMMARY
- -X- _ SUMMARY
resource -X- _ SUMMARY
NER -X- _ SUMMARY
dataset -X- _ SUMMARY
. -X- _ SUMMARY
2023.acl-short.11.txt -X- _ O
Jiong -X- _ O
Cai -X- _ O
, -X- _ O
Shen -X- _ O
Huang -X- _ O
, -X- _ O
Yong -X- _ O
Jiang -X- _ O
, -X- _ O
Zeqi -X- _ O
Tan -X- _ O
, -X- _ O
Pengjun -X- _ O
Xie -X- _ O
, -X- _ O
Kewei -X- _ O
TuSchool -X- _ O
of -X- _ O
Information -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
, -X- _ O
ShanghaiTech -X- _ O
University -X- _ O
Shanghai -X- _ O
Engineering -X- _ O
Research -X- _ O
Center -X- _ O
of -X- _ O
Intelligent -X- _ O
Vision -X- _ O
and -X- _ O
Imaging -X- _ O
Shanghai -X- _ O
Institute -X- _ O
of -X- _ O
Microsystem -X- _ O
and -X- _ O
Information -X- _ O
Technology -X- _ O
, -X- _ O
Chinese -X- _ O
Academy -X- _ O
of -X- _ O
Sciences -X- _ O
University -X- _ O
of -X- _ O
Chinese -X- _ O
Academy -X- _ O
of -X- _ O
SciencesCollege -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
, -X- _ O
Zhejiang -X- _ O
UniversityDAMO -X- _ O
Academy -X- _ O
, -X- _ O
Alibaba -X- _ O
Group -X- _ O
Abstract -X- _ O
Data -X- _ O
augmentation -X- _ O
is -X- _ O
an -X- _ O
effective -X- _ O
solution -X- _ O
to -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
and -X- _ O
robustness -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
synthetic -X- _ O
data -X- _ O
often -X- _ O
suffer -X- _ O
from -X- _ O
poor -X- _ O
diversity -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
performance -X- _ O
limitations -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Graph -X- _ B-MethodName
Propagated -X- _ I-MethodName
Data -X- _ I-MethodName
Augmentation -X- _ I-MethodName
( -X- _ O
GPDA -X- _ B-MethodName
) -X- _ O
framework -X- _ O
for -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-TaskName
) -X- _ O
, -X- _ O
leveraging -X- _ O
graph -X- _ O
propagation -X- _ O
to -X- _ O
build -X- _ O
relationships -X- _ O
between -X- _ O
labeled -X- _ O
data -X- _ O
and -X- _ O
unlabeled -X- _ O
natural -X- _ O
texts -X- _ O
. -X- _ O
By -X- _ O
projecting -X- _ O
the -X- _ O
annotations -X- _ O
from -X- _ O
the -X- _ O
labeled -X- _ O
text -X- _ O
to -X- _ O
the -X- _ O
unlabeled -X- _ O
text -X- _ O
, -X- _ O
the -X- _ O
unlabeled -X- _ O
texts -X- _ O
are -X- _ O
partially -X- _ O
labeled -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
more -X- _ O
diversity -X- _ O
rather -X- _ O
than -X- _ O
synthetic -X- _ O
annotated -X- _ O
data -X- _ O
. -X- _ O
To -X- _ O
strengthen -X- _ O
the -X- _ O
propagation -X- _ O
precision -X- _ O
, -X- _ O
a -X- _ O
simple -X- _ O
search -X- _ O
engine -X- _ O
built -X- _ O
on -X- _ O
Wikipedia -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
fetch -X- _ O
related -X- _ O
texts -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
and -X- _ O
to -X- _ O
propagate -X- _ O
the -X- _ O
entity -X- _ O
labels -X- _ O
to -X- _ O
them -X- _ O
in -X- _ O
the -X- _ O
light -X- _ O
of -X- _ O
the -X- _ O
anchor -X- _ O
links -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
and -X- _ O
perform -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
lowresource -X- _ O
dataset -X- _ O
of -X- _ O
the -X- _ O
E -X- _ O
- -X- _ O
commerce -X- _ O
domain -X- _ O
, -X- _ O
which -X- _ O
will -X- _ O
be -X- _ O
publicly -X- _ O
available -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
research -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
GPDA -X- _ B-MethodName
presents -X- _ O
substantial -X- _ O
improvements -X- _ O
over -X- _ O
previous -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
on -X- _ O
multiple -X- _ O
low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
datasets -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Data -X- _ O
augmentation -X- _ O
is -X- _ O
an -X- _ O
effective -X- _ O
solution -X- _ O
to -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
and -X- _ O
robustness -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
especially -X- _ O
useful -X- _ O
when -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
is -X- _ O
scarce -X- _ O
. -X- _ O
In -X- _ O
computer -X- _ O
vision -X- _ O
and -X- _ O
speech -X- _ O
, -X- _ O
simple -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
manipulations -X- _ O
( -X- _ O
Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
are -X- _ O
widely -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
synthetic -X- _ O
data -X- _ O
that -X- _ O
preserve -X- _ O
the -X- _ O
original -X- _ O
information -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
when -X- _ O
applied -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
challenging -X- _ O
to -X- _ O
edit -X- _ O
a -X- _ O
sentence -X- _ O
without -X- _ O
changing -X- _ O
its -X- _ O
syntax -X- _ O
or -X- _ O
semantics -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
successful -X- _ O
attempts -X- _ O
of -X- _ O
applying -X- _ O
data -X- _ O
augmentation -X- _ O
on -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
One -X- _ O
is -X- _ O
manipulating -X- _ O
a -X- _ O
few -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
based -X- _ O
on -X- _ O
synonym -X- _ O
replacement -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Kobayashi -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Wei -X- _ O
and -X- _ O
Zou -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
random -X- _ O
insertion -X- _ O
or -X- _ O
deletion -X- _ O
( -X- _ O
Wei -X- _ O
and -X- _ O
Zou -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
random -X- _ O
swap -X- _ O
( -X- _ O
¸ -X- _ O
Sahin -X- _ O
and -X- _ O
Steedman -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wei -X- _ O
and -X- _ O
Zou -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Min -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
other -X- _ O
is -X- _ O
generating -X- _ O
the -X- _ O
whole -X- _ O
sentence -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
backtranslation -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Iyyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
models -X- _ O
( -X- _ O
Kurata -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
Hou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Kumar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
when -X- _ O
applied -X- _ O
to -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
NER -X- _ B-TaskName
, -X- _ O
these -X- _ O
methods -X- _ O
suffer -X- _ O
heavily -X- _ O
from -X- _ O
token -X- _ O
- -X- _ O
label -X- _ O
misalignment -X- _ O
or -X- _ O
erroneous -X- _ O
label -X- _ O
propagation -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
issue -X- _ O
of -X- _ O
token -X- _ O
- -X- _ O
label -X- _ O
misalignment -X- _ O
, -X- _ O
Dai -X- _ O
and -X- _ O
Adel -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
extend -X- _ O
the -X- _ O
replacement -X- _ O
from -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
to -X- _ O
entity -X- _ O
- -X- _ O
level -X- _ O
with -X- _ O
entities -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
class -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
simple -X- _ O
but -X- _ O
strong -X- _ O
augmentation -X- _ O
method -X- _ O
for -X- _ O
NER -X- _ B-TaskName
. -X- _ O
Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
adopt -X- _ O
a -X- _ O
seq2seq -X- _ O
model -X- _ O
to -X- _ O
conditionally -X- _ O
generate -X- _ O
contexts -X- _ O
while -X- _ O
leaving -X- _ O
entities -X- _ O
/ -X- _ O
aspect -X- _ O
terms -X- _ O
unchanged -X- _ O
. -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
exploit -X- _ O
an -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
annotate -X- _ O
entities -X- _ O
while -X- _ O
treating -X- _ O
NER -X- _ B-TaskName
as -X- _ O
a -X- _ O
text -X- _ O
tagging -X- _ O
task -X- _ O
. -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
utilize -X- _ O
labeled -X- _ O
sequence -X- _ O
linearization -X- _ O
to -X- _ O
enable -X- _ O
masked -X- _ O
entity -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
explicitly -X- _ O
condition -X- _ O
on -X- _ O
label -X- _ O
information -X- _ O
when -X- _ O
predicting -X- _ O
masked -X- _ O
entity -X- _ O
tokens -X- _ O
. -X- _ O
Still -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
generate -X- _ O
synthetic -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
inevitably -X- _ O
introduces -X- _ O
incoherence -X- _ O
, -X- _ O
semantic -X- _ O
errors -X- _ O
and -X- _ O
lacking -X- _ O
in -X- _ O
diversity -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
data -X- _ O
augmentation -X- _ O
with -X- _ O
natural -X- _ O
texts -X- _ O
instead -X- _ O
of -X- _ O
synthetic -X- _ O
ones -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
professional -X- _ O
annotators -X- _ O
usually -X- _ O
understand -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
through -X- _ O
its -X- _ O
rich -X- _ O
context -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource110NER -X- _ B-TaskName
, -X- _ O
the -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
entity -X- _ O
is -X- _ O
relatively -X- _ O
limited -X- _ O
due -X- _ O
to -X- _ O
fewer -X- _ O
annotations -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
NER -X- _ B-TaskName
models -X- _ O
by -X- _ O
mining -X- _ O
richer -X- _ O
contexts -X- _ O
for -X- _ O
the -X- _ O
existing -X- _ O
labeled -X- _ O
entities -X- _ O
. -X- _ O
More -X- _ O
particularly -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Graph -X- _ B-MethodName
Propagation -X- _ I-MethodName
based -X- _ I-MethodName
Data -X- _ I-MethodName
Augmentation -X- _ I-MethodName
( -X- _ O
GPDA -X- _ B-MethodName
) -X- _ O
framework -X- _ O
for -X- _ O
NER -X- _ B-TaskName
, -X- _ O
leveraging -X- _ O
graph -X- _ O
propagation -X- _ O
to -X- _ O
build -X- _ O
relationships -X- _ O
between -X- _ O
labeled -X- _ O
data -X- _ O
and -X- _ O
unlabeled -X- _ O
natural -X- _ O
texts -X- _ O
. -X- _ O
The -X- _ O
unlabeled -X- _ O
texts -X- _ O
are -X- _ O
accurately -X- _ O
and -X- _ O
partially -X- _ O
labeled -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
connected -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
more -X- _ O
diversity -X- _ O
rather -X- _ O
than -X- _ O
synthetic -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
annotations -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
not -X- _ O
restricted -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
annotated -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
external -X- _ O
entities -X- _ O
from -X- _ O
the -X- _ O
unlabeled -X- _ O
text -X- _ O
by -X- _ O
leveraging -X- _ O
consistency -X- _ O
- -X- _ O
restricted -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
GPDA -X- _ B-MethodName
can -X- _ O
be -X- _ O
concluded -X- _ O
: -X- _ O
•We -X- _ O
propose -X- _ O
a -X- _ O
data -X- _ O
augmentation -X- _ O
framework -X- _ O
that -X- _ O
utilizes -X- _ O
graph -X- _ O
propagation -X- _ O
with -X- _ O
natural -X- _ O
texts -X- _ O
for -X- _ O
augmentation -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
rarely -X- _ O
investigated -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Section -X- _ O
2 -X- _ O
) -X- _ O
; -X- _ O
•We -X- _ O
utilize -X- _ O
a -X- _ O
simple -X- _ O
Wikipedia -X- _ O
- -X- _ O
based -X- _ O
search -X- _ O
engine -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
graph -X- _ O
with -X- _ O
two -X- _ O
retrieval -X- _ O
methods -X- _ O
( -X- _ O
Section -X- _ O
2.2 -X- _ O
) -X- _ O
; -X- _ O
•With -X- _ O
consistency -X- _ O
- -X- _ O
restricted -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
make -X- _ O
the -X- _ O
most -X- _ O
efficient -X- _ O
utilization -X- _ O
of -X- _ O
externally -X- _ O
explored -X- _ O
unlabeled -X- _ O
text -X- _ O
( -X- _ O
Section -X- _ O
2.3 -X- _ O
) -X- _ O
; -X- _ O
•By -X- _ O
conducting -X- _ O
experiments -X- _ O
on -X- _ O
both -X- _ O
public -X- _ O
datasets -X- _ O
and -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
multilingual -X- _ O
lowresource -X- _ O
dataset -X- _ O
, -X- _ O
GPDA -X- _ B-MethodName
achieves -X- _ O
substantial -X- _ O
improvements -X- _ O
over -X- _ O
previous -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
( -X- _ O
Section -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
Method -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
presents -X- _ O
the -X- _ O
workflow -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
data -X- _ O
augmentation -X- _ O
framework -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
a -X- _ O
graph -X- _ O
between -X- _ O
labeled -X- _ O
data -X- _ O
nodes -X- _ O
and -X- _ O
unlabeled -X- _ O
text -X- _ O
nodes -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
textual -X- _ O
similarity -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
entity -X- _ O
annotations -X- _ O
are -X- _ O
propagated -X- _ O
to -X- _ O
obtain -X- _ O
augmented -X- _ O
data -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
marginalized -X- _ O
likelihood -X- _ O
for -X- _ O
conditional -X- _ O
random -X- _ O
field -X- _ O
( -X- _ O
CRF -X- _ O
) -X- _ O
( -X- _ O
Tsuboi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
phase -X- _ O
as -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
are -X- _ O
partially -X- _ O
labeled -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
consistency -X- _ O
- -X- _ O
restricted -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
strategy -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
2.1 -X- _ O
NER -X- _ B-TaskName
with -X- _ O
Pure -X- _ O
Labeled -X- _ O
Data -X- _ O
We -X- _ O
take -X- _ O
NER -X- _ B-TaskName
as -X- _ O
a -X- _ O
sequence -X- _ O
labeling -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
predicts -X- _ O
a -X- _ O
label -X- _ O
sequence -X- _ O
y= -X- _ O
{ -X- _ O
y -X- _ O
, -X- _ O
· -X- _ O
· -X- _ O
· -X- _ O
, -X- _ O
y|y∈Y -X- _ O
} -X- _ O
at -X- _ O
each -X- _ O
position -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
x= -X- _ O
{ -X- _ O
x -X- _ O
, -X- _ O
· -X- _ O
· -X- _ O
· -X- _ O
, -X- _ O
x -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
Ydenotes -X- _ O
the -X- _ O
label -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
sequence -X- _ O
labeling -X- _ O
model -X- _ O
feeds -X- _ O
the -X- _ O
input -X- _ O
xinto -X- _ O
a -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
encoder -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
which -X- _ O
creates -X- _ O
contextualized -X- _ O
embeddings -X- _ O
rfor -X- _ O
each -X- _ O
token -X- _ O
. -X- _ O
Then -X- _ O
a -X- _ O
linear -X- _ O
- -X- _ O
chain -X- _ O
CRF -X- _ O
layer -X- _ O
that -X- _ O
captures -X- _ O
dependencies -X- _ O
between -X- _ O
neighboring -X- _ O
labels -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
: -X- _ O
ψ -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
= -X- _ O
exp -X- _ O
( -X- _ O
Wr+b -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
/ -X- _ O
producttextψ -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
/ -X- _ O
summationtext -X- _ O
/ -X- _ O
producttextψ -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
Unified -X- _ O
Training -X- _ O
Objective -X- _ O
Instead -X- _ O
of -X- _ O
directly -X- _ O
minimizing -X- _ O
the -X- _ O
negative -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
, -X- _ O
we -X- _ O
unify -X- _ O
the -X- _ O
training -X- _ O
objectives -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
, -X- _ O
2.2 -X- _ O
and -X- _ O
2.3 -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
marginal -X- _ O
probability -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
forward -X- _ O
- -X- _ O
backward -X- _ O
algorithm -X- _ O
. -X- _ O
α -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
/ -X- _ O
summationdisplay -X- _ O
/ -X- _ O
productdisplayψ -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
β -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
/ -X- _ O
summationdisplay -X- _ O
/ -X- _ O
productdisplayψ -X- _ O
( -X- _ O
y -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
r -X- _ O
) -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
∝α -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
×β -X- _ O
( -X- _ O
y -X- _ O
) -X- _ O
The -X- _ O
marginal -X- _ O
distributions -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
efficiently -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
partially -X- _ O
annotated -X- _ O
label -X- _ O
sequence -X- _ O
y= -X- _ O
{ -X- _ O
∗ -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
∗ -X- _ O
} -X- _ O
that∗denotes -X- _ O
the -X- _ O
label -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
observed -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
probability -X- _ O
. -X- _ O
Q -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
/ -X- _ O
productdisplayQ -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
111Method -X- _ O
AI -X- _ O
Literature -X- _ O
Music -X- _ O
Politics -X- _ O
Science -X- _ O
Average -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
Approaches -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
63.28 -X- _ O
70.76 -X- _ O
76.83 -X- _ O
73.25 -X- _ O
70.07 -X- _ O
70.84 -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
65.79 -X- _ O
71.11 -X- _ O
78.78 -X- _ O
74.06 -X- _ O
71.83 -X- _ O
72.31 -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
66.03 -X- _ O
68.59 -X- _ O
73.1 -X- _ O
71.69 -X- _ O
75.52 -X- _ O
70.99 -X- _ O
Baseline -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
Data -X- _ O
Augmentation -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
CRF -X- _ I-MethodName
65.06 -X- _ O
71.39 -X- _ O
78.18 -X- _ O
74.46 -X- _ O
73.95 -X- _ O
72.61 -X- _ O
Data -X- _ O
Augmentation -X- _ O
Approaches -X- _ O
DAGA -X- _ O
( -X- _ O
Ding -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
66.77 -X- _ O
71.15 -X- _ O
78.48 -X- _ O
73.30 -X- _ O
73.07 -X- _ O
72.55 -X- _ O
NERDA -X- _ B-MethodName
( -X- _ O
Dai -X- _ O
and -X- _ O
Adel -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
70.20 -X- _ O
71.28 -X- _ O
79.56 -X- _ O
75.30 -X- _ O
74.37 -X- _ O
74.14 -X- _ O
GPDA -X- _ B-MethodName
( -X- _ O
sparse -X- _ O
retrieval -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
EEA -X- _ O
) -X- _ O
67.14 -X- _ O
72.20 -X- _ O
79.55 -X- _ O
74.96 -X- _ O
74.69 -X- _ O
73.71 -X- _ O
GPDA -X- _ O
( -X- _ O
dense -X- _ O
retrieval -X- _ O
w -X- _ O
/ -X- _ O
o -X- _ O
EEA -X- _ O
) -X- _ O
67.76 -X- _ O
72.11 -X- _ O
77.54 -X- _ O
74.86 -X- _ O
73.07 -X- _ O
73.07 -X- _ O
GPDA -X- _ O
( -X- _ O
sparse -X- _ O
retrieval -X- _ O
w -X- _ O
/ -X- _ O
EEA -X- _ O
) -X- _ O
70.05 -X- _ O
72.3480.1675.9575.5574.81 -X- _ O
where -X- _ O
Q -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
P -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
ifyis -X- _ O
observed -X- _ O
, -X- _ O
otherwise -X- _ O
Q -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
= -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
model -X- _ O
parameters -X- _ O
can -X- _ O
be -X- _ O
optimized -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
following -X- _ O
objective -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
−logQ -X- _ O
( -X- _ O
y|x -X- _ O
) -X- _ O
For -X- _ O
the -X- _ O
pure -X- _ O
labeled -X- _ O
data -X- _ O
D= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
} -X- _ O
, -X- _ O
we -X- _ O
direct -X- _ O
set -X- _ O
y -X- _ O
= -X- _ O
yand -X- _ O
obtain -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
. -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
/ -X- _ O
summationdisplaylogQ -X- _ O
( -X- _ O
y -X- _ O
= -X- _ O
y|x -X- _ O
) -X- _ O
2.2 -X- _ O
NER -X- _ B-TaskName
with -X- _ O
Propagated -X- _ O
Unlabeled -X- _ O
Data -X- _ O
Building -X- _ O
Propagating -X- _ O
Graph -X- _ O
Compared -X- _ O
to -X- _ O
labeled -X- _ O
data -X- _ O
, -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
unlabeled -X- _ O
natural -X- _ O
texts -X- _ O
can -X- _ O
be -X- _ O
acquired -X- _ O
much -X- _ O
more -X- _ O
easily -X- _ O
. -X- _ O
We -X- _ O
attempt -X- _ O
to -X- _ O
utilize -X- _ O
these -X- _ O
natural -X- _ O
texts -X- _ O
for -X- _ O
augmentation -X- _ O
by -X- _ O
building -X- _ O
a -X- _ O
graph -X- _ O
between -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
nodes -X- _ O
and -X- _ O
the -X- _ O
unlabeled -X- _ O
text -X- _ O
nodes -X- _ O
according -X- _ O
to -X- _ O
their -X- _ O
textual -X- _ O
similarity -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
labeled -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
retrieve -X- _ O
its -X- _ O
corresponding -X- _ O
augmented -X- _ O
sentences -X- _ O
{ -X- _ O
x -X- _ O
} -X- _ O
via -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
. -X- _ O
For -X- _ O
common -X- _ O
NER -X- _ B-TaskName
datasets -X- _ O
, -X- _ O
the -X- _ O
search -X- _ O
engine -X- _ O
is -X- _ O
built -X- _ O
on -X- _ O
the -X- _ O
Wikipedia -X- _ O
corpus -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
we -X- _ O
explore -X- _ O
: -X- _ O
sparse -X- _ O
retrieval -X- _ O
based -X- _ O
on -X- _ O
BM25or -X- _ O
dense -X- _ O
retrieval -X- _ O
based -X- _ O
on -X- _ O
L2 -X- _ O
similarity -X- _ O
. -X- _ O
The -X- _ O
top -X- _ O
related -X- _ O
sentences -X- _ O
will -X- _ O
be -X- _ O
treated -X- _ O
connected -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
labeled -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
. -X- _ O
Label -X- _ O
Propagation -X- _ O
While -X- _ O
building -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
label -X- _ O
propagation -X- _ O
is -X- _ O
conducted -X- _ O
from -X- _ O
labeled -X- _ O
data -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
to -X- _ O
unlabeled -X- _ O
data -X- _ O
{ -X- _ O
x -X- _ O
} -X- _ O
to -X- _ O
generate -X- _ O
partially -X- _ O
annotated -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O
To -X- _ O
strengthen -X- _ O
the -X- _ O
precision -X- _ O
, -X- _ O
propagation -X- _ O
will -X- _ O
not -X- _ O
happen -X- _ O
unless -X- _ O
the -X- _ O
anchor -X- _ O
text -X- _ O
in -X- _ O
Wikipedia -X- _ O
matches -X- _ O
the -X- _ O
labeled -X- _ O
entity -X- _ O
. -X- _ O
By -X- _ O
graph -X- _ O
propagation -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
D= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
} -X- _ O
sharing -X- _ O
the -X- _ O
same -X- _ O
entities -X- _ O
but -X- _ O
with -X- _ O
more -X- _ O
diverse -X- _ O
contexts -X- _ O
. -X- _ O
Along -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
labeled -X- _ O
data -X- _ O
D -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
NER -X- _ O
model -X- _ O
following -X- _ O
the -X- _ O
same -X- _ O
objective -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
/ -X- _ O
summationdisplaylogQ -X- _ O
( -X- _ O
y -X- _ O
= -X- _ O
y|x -X- _ O
) -X- _ O
2.3 -X- _ O
NER -X- _ O
with -X- _ O
Explored -X- _ O
Entity -X- _ O
Annotations -X- _ O
To -X- _ O
make -X- _ O
the -X- _ O
most -X- _ O
efficient -X- _ O
utilization -X- _ O
of -X- _ O
the -X- _ O
explored -X- _ O
annotations -X- _ O
in -X- _ O
D -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
consistencyrestricted -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
A -X- _ O
well -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
from -X- _ O
Section -X- _ O
2.2 -X- _ O
will -X- _ O
be -X- _ O
utilized -X- _ O
to -X- _ O
re -X- _ O
- -X- _ O
annotate -X- _ O
the -X- _ O
partially -X- _ O
labeled -X- _ O
augmented -X- _ O
data -X- _ O
under -X- _ O
consistency -X- _ O
restriction -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
an -X- _ O
augmented -X- _ O
sample -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
re -X- _ O
- -X- _ O
annotated -X- _ O
to -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
ˆy -X- _ O
) -X- _ O
. -X- _ O
Now -X- _ O
we -X- _ O
have -X- _ O
ˆD= -X- _ O
{ -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
ˆy -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O
Along -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
labeled -X- _ O
data -X- _ O
D -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
better -X- _ O
NER -X- _ O
model -X- _ O
following -X- _ O
the -X- _ O
objective -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
: -X- _ O
L -X- _ O
( -X- _ O
θ -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
/ -X- _ O
summationdisplaylogQ -X- _ O
( -X- _ O
y -X- _ O
= -X- _ O
y|x -X- _ O
) -X- _ O
1123 -X- _ O
Experiments -X- _ O
3.1 -X- _ O
Dataset -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
CrossNER -X- _ B-DatasetName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
dataset -X- _ O
of -X- _ O
5 -X- _ O
genres -X- _ O
( -X- _ O
AI -X- _ O
, -X- _ O
Literature -X- _ O
, -X- _ O
Music -X- _ O
, -X- _ O
Politics -X- _ O
, -X- _ O
Science -X- _ O
) -X- _ O
and -X- _ O
an -X- _ O
anonymous -X- _ B-DatasetName
multi -X- _ I-DatasetName
- -X- _ I-DatasetName
lingual -X- _ I-DatasetName
E -X- _ I-DatasetName
- -X- _ I-DatasetName
commerce -X- _ I-DatasetName
query -X- _ I-DatasetName
NER -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Ecom -X- _ B-DatasetName
) -X- _ O
consisting -X- _ O
of -X- _ O
3 -X- _ O
languages -X- _ O
( -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
French -X- _ O
) -X- _ O
Detailed -X- _ O
statistics -X- _ O
about -X- _ O
these -X- _ O
two -X- _ O
datasets -X- _ O
is -X- _ O
provided -X- _ O
in -X- _ O
the -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
For -X- _ O
CrossNER -X- _ B-DatasetName
, -X- _ O
the -X- _ O
search -X- _ O
engine -X- _ O
is -X- _ O
manually -X- _ O
built -X- _ O
on -X- _ O
the -X- _ O
Wikipedia -X- _ O
corpus -X- _ O
. -X- _ O
While -X- _ O
for -X- _ O
Ecom -X- _ B-DatasetName
, -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
E -X- _ O
- -X- _ O
commerce -X- _ O
search -X- _ O
engine -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
build -X- _ O
the -X- _ O
augmentation -X- _ O
graph -X- _ O
. -X- _ O
3.2 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O
Low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
Tasks -X- _ O
As -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
GPDA -X- _ B-MethodName
consistently -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
across -X- _ O
the -X- _ O
five -X- _ O
genres -X- _ O
of -X- _ O
CrossNER -X- _ B-DatasetName
and -X- _ O
gains -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
2.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
the -X- _ O
baseline -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
CRF -X- _ I-MethodName
model -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
outperforms -X- _ O
other -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
, -X- _ O
demonstrating -X- _ O
its -X- _ O
effectiveness -X- _ O
on -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
. -X- _ O
Furthermore -X- _ O
, -X- _ O
GPDA -X- _ B-MethodName
with -X- _ I-MethodName
Explored -X- _ I-MethodName
Entity -X- _ I-MethodName
Annotation -X- _ I-MethodName
( -X- _ O
EEA -X- _ O
) -X- _ O
strategy -X- _ O
achieves -X- _ O
1.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
higher -X- _ O
F1 -X- _ B-MetricName
than -X- _ O
GPDA -X- _ B-MethodName
without -X- _ I-MethodName
EEA -X- _ I-MethodName
, -X- _ O
suggesting -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
also -X- _ O
crucial -X- _ O
to -X- _ O
extend -X- _ O
unique -X- _ O
entities -X- _ O
rather -X- _ O
then -X- _ O
only -X- _ O
diversifying -X- _ O
entity -X- _ O
contexts -X- _ O
in -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
noticed -X- _ O
that -X- _ O
GPDA -X- _ B-MethodName
with -X- _ O
dense -X- _ O
retrieval -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
with -X- _ O
sparse -X- _ O
retrieval -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
intuitive -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
dense -X- _ O
retrieval -X- _ O
requires -X- _ O
careful -X- _ O
supervised -X- _ O
training -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
domain -X- _ O
, -X- _ O
but -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
matching -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
finetuned -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
leave -X- _ O
this -X- _ O
part -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Real -X- _ O
- -X- _ O
world -X- _ O
Low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
Scenarios -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
results -X- _ O
on -X- _ O
three -X- _ O
languages -X- _ O
from -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
Ecom -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
The -X- _ O
augmented -X- _ O
data -X- _ O
generated -X- _ O
by -X- _ O
GPDA -X- _ B-MethodName
improves -X- _ O
model -X- _ O
performances -X- _ O
for -X- _ O
multilingual -X- _ B-TaskName
NER -X- _ I-TaskName
. -X- _ O
For -X- _ O
specific -X- _ O
domain -X- _ O
datasets -X- _ O
where -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
knowledge -X- _ O
or -X- _ O
texts -X- _ O
can -X- _ O
be -X- _ O
fetched -X- _ O
easily -X- _ O
, -X- _ O
GPDA -X- _ B-MethodName
are -X- _ O
indeed -X- _ O
helpful -X- _ O
. -X- _ O
Size -X- _ O
of -X- _ O
Gold -X- _ O
Samples -X- _ O
We -X- _ O
study -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
GDPA -X- _ B-MethodName
on -X- _ O
different -X- _ O
size -X- _ O
of -X- _ O
gold -X- _ O
samples -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
where -X- _ O
10 -X- _ O
% -X- _ O
-25 -X- _ O
% -X- _ O
gold -X- _ O
samples -X- _ O
are -X- _ O
available -X- _ O
, -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
striking -X- _ O
which -X- _ O
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
by -X- _ O
at -X- _ O
most -X- _ O
37 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Case -X- _ O
Study -X- _ O
Taking -X- _ O
a -X- _ O
closer -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
augmented -X- _ O
cases -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
notice -X- _ O
that -X- _ O
GPDA -X- _ B-MethodName
generates -X- _ O
different -X- _ O
contexts -X- _ O
concerning -X- _ O
the -X- _ O
entity -X- _ O
" -X- _ O
Adobe -X- _ O
Creative -X- _ O
Suite -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
augmented -X- _ O
data -X- _ O
generated -X- _ O
by -X- _ O
GPDA -X- _ B-MethodName
introduces -X- _ O
more -X- _ O
diversity -X- _ O
to -X- _ O
help -X- _ O
reduce -X- _ O
overfitting -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
synthetic -X- _ O
data -X- _ O
, -X- _ O
these -X- _ O
generated -X- _ O
data -X- _ O
are -X- _ O
all -X- _ O
from -X- _ O
natural -X- _ O
texts -X- _ O
so -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
need -X- _ O
to -X- _ O
worry -X- _ O
about -X- _ O
the -X- _ O
coherence -X- _ O
in -X- _ O
syntax -X- _ O
or -X- _ O
semantics -X- _ O
. -X- _ O
4 -X- _ O
Discussion -X- _ O
Retrieving -X- _ O
relevant -X- _ O
texts -X- _ O
from -X- _ O
databases -X- _ O
has -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
in -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
RaNER -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
retrieves -X- _ O
context -X- _ O
using -X- _ O
a -X- _ O
search -X- _ O
system -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
token -X- _ O
representation -X- _ O
for -X- _ O
NER -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
To -X- _ O
help -X- _ O
entity -X- _ O
disambiguation -X- _ O
in -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
NER -X- _ B-TaskName
, -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
retrieves -X- _ O
the -X- _ O
domainspecific -X- _ O
database -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
correlated -X- _ O
sample -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
extensive -X- _ O
information -X- _ O
about -X- _ O
entities -X- _ O
in -X- _ O
Wikipedia -X- _ O
and -X- _ O
Wikidata -X- _ O
, -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
and -X- _ O
Tan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2023 -X- _ O
) -X- _ O
construct -X- _ O
databases -X- _ O
and -X- _ O
retrieve -X- _ O
context -X- _ O
to -X- _ O
enhance -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
utilization -X- _ O
of -X- _ O
retrieval -X- _ O
techniques -X- _ O
for -X- _ O
data -X- _ O
augmentation -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
while -X- _ O
they -X- _ O
perform -X- _ O
retrieval -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
small -X- _ O
seed -X- _ O
training -X- _ O
dataset -X- _ O
for -X- _ O
retrieval -X- _ O
. -X- _ O
It -X- _ O
’s -X- _ O
noteworthy -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
theirs -X- _ O
to -X- _ O
further -X- _ O
enhance -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
NER -X- _ B-TaskName
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
settings -X- _ O
. -X- _ O
5 -X- _ O
Conclusion -X- _ O
We -X- _ O
present -X- _ O
GPDA -X- _ B-MethodName
as -X- _ O
a -X- _ O
data -X- _ O
augmentation -X- _ O
framework -X- _ O
for -X- _ O
low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
, -X- _ O
which -X- _ O
utilizes -X- _ O
graph -X- _ O
propagation -X- _ O
with -X- _ O
natural -X- _ O
texts -X- _ O
for -X- _ O
augmentation -X- _ O
. -X- _ O
To -X- _ O
make -X- _ O
the -X- _ O
most -X- _ O
efficient -X- _ O
utilization -X- _ O
of -X- _ O
the -X- _ O
explored -X- _ O
partially -X- _ O
labeled -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
consistencyrestricted -X- _ O
self -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Experiment -X- _ O
results -X- _ O
show113 -X- _ O
Method -X- _ O
en -X- _ O
es -X- _ O
fr -X- _ O
Avg -X- _ O
Baseline -X- _ O
76.54 -X- _ O
85.50 -X- _ O
72.78 -X- _ O
78.27 -X- _ O
DAGA -X- _ B-MethodName
77.11 -X- _ O
86.51 -X- _ O
81.32 -X- _ O
81.65 -X- _ O
NERDA -X- _ O
77.10 -X- _ O
87.05 -X- _ O
81.64 -X- _ O
81.93 -X- _ O
GPDA -X- _ O
77.83 -X- _ O
87.23 -X- _ O
82.48 -X- _ O
82.51 -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
GPDA -X- _ B-MethodName
achieves -X- _ O
substantial -X- _ O
improvements -X- _ O
over -X- _ O
previous -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
on -X- _ O
multiple -X- _ O
low -X- _ B-TaskName
- -X- _ I-TaskName
resource -X- _ I-TaskName
NER -X- _ I-TaskName
datasets -X- _ O
. -X- _ O
Acknowledgements -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
61976139 -X- _ O
) -X- _ O
and -X- _ O
by -X- _ O
Alibaba -X- _ O
Group -X- _ O
through -X- _ O
Alibaba -X- _ O
Innovative -X- _ O
Research -X- _ O
Program -X- _ O
. -X- _ O
6 -X- _ O
Limitations -X- _ O
There -X- _ O
are -X- _ O
some -X- _ O
limitations -X- _ O
in -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
GPDA -X- _ B-MethodName
. -X- _ O
•The -X- _ O
label -X- _ O
propagation -X- _ O
procedure -X- _ O
requires -X- _ O
anchor -X- _ O
matching -X- _ O
in -X- _ O
the -X- _ O
light -X- _ O
of -X- _ O
annotation -X- _ O
precision -X- _ O
, -X- _ O
which -X- _ O
limits -X- _ O
the -X- _ O
unlabeled -X- _ O
data -X- _ O
source -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Wikipedia -X- _ O
is -X- _ O
a -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
easyto -X- _ O
- -X- _ O
fetch -X- _ O
corpus -X- _ O
with -X- _ O
anchor -X- _ O
links -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
somehow -X- _ O
mitigate -X- _ O
the -X- _ O
issue.•Augmented -X- _ O
Data -X- _ O
generated -X- _ O
by -X- _ O
GPDA -X- _ B-MethodName
provide -X- _ O
more -X- _ O
diversity -X- _ O
. -X- _ O
But -X- _ O
for -X- _ O
some -X- _ O
datasets -X- _ O
, -X- _ O
simple -X- _ O
modifications -X- _ O
( -X- _ O
NERDA -X- _ B-MethodName
) -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
words -X- _ O
performs -X- _ O
better -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
investigating -X- _ O
a -X- _ O
hybrid -X- _ O
approach -X- _ O
to -X- _ O
apply -X- _ O
GPDA -X- _ B-MethodName
and -X- _ O
NERDA -X- _ B-MethodName
in -X- _ O
the -X- _ O
same -X- _ O
framework -X- _ O
. -X- _ O
References114115116ACL -X- _ O
2023 -X- _ O
Responsible -X- _ O
NLP -X- _ O
Checklist -X- _ O
A -X- _ O
For -X- _ O
every -X- _ O
submission -X- _ O
: -X- _ O
/ -X- _ O
squareA1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
describe -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
Section -X- _ O
5 -X- _ O
/ -X- _ O
squareA2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
any -X- _ O
potential -X- _ O
risks -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
Section -X- _ O
5 -X- _ O
/ -X- _ O
squareA3 -X- _ O
. -X- _ O
Do -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
introduction -X- _ O
summarize -X- _ O
the -X- _ O
paper -X- _ O
’s -X- _ O
main -X- _ O
claims -X- _ O
? -X- _ O
Section -X- _ O
1 -X- _ O
/ -X- _ O
squareA4 -X- _ O
. -X- _ O
Have -X- _ O
you -X- _ O
used -X- _ O
AI -X- _ O
writing -X- _ O
assistants -X- _ O
when -X- _ O
working -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
B -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
or -X- _ O
create -X- _ O
scientiﬁc -X- _ O
artifacts -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
cite -X- _ O
the -X- _ O
creators -X- _ O
of -X- _ O
artifacts -X- _ O
you -X- _ O
used -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareB2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
license -X- _ O
or -X- _ O
terms -X- _ O
for -X- _ O
use -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
distribution -X- _ O
of -X- _ O
any -X- _ O
artifacts -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareB3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
speciﬁed -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareB4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identiﬁes -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareB5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
provide -X- _ O
documentation -X- _ O
of -X- _ O
the -X- _ O
artifacts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
coverage -X- _ O
of -X- _ O
domains -X- _ O
, -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
linguistic -X- _ O
phenomena -X- _ O
, -X- _ O
demographic -X- _ O
groups -X- _ O
represented -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareB6 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
relevant -X- _ O
statistics -X- _ O
like -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
, -X- _ O
details -X- _ O
of -X- _ O
train -X- _ O
/ -X- _ O
test -X- _ O
/ -X- _ O
dev -X- _ O
splits -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
for -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
you -X- _ O
used -X- _ O
/ -X- _ O
created -X- _ O
? -X- _ O
Even -X- _ O
for -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
include -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
train -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
provide -X- _ O
necessary -X- _ O
context -X- _ O
for -X- _ O
a -X- _ O
reader -X- _ O
to -X- _ O
understand -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
small -X- _ O
differences -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
large -X- _ O
test -X- _ O
sets -X- _ O
may -X- _ O
be -X- _ O
signiﬁcant -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
small -X- _ O
test -X- _ O
sets -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
. -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
C -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
run -X- _ O
computational -X- _ O
experiments -X- _ O
? -X- _ O
Section -X- _ O
3 -X- _ O
/ -X- _ O
squareC1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
computational -X- _ O
budget -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPU -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
infrastructure -X- _ O
used -X- _ O
? -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
limitation -X- _ O
of -X- _ O
page -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
n’t -X- _ O
report -X- _ O
these.117 -X- _ O
/ -X- _ O
squareC2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
including -X- _ O
hyperparameter -X- _ O
search -X- _ O
and -X- _ O
best -X- _ O
- -X- _ O
found -X- _ O
hyperparameter -X- _ O
values -X- _ O
? -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
limitation -X- _ O
of -X- _ O
page -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
n’t -X- _ O
report -X- _ O
these -X- _ O
. -X- _ O
/ -X- _ O
squareC3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
descriptive -X- _ O
statistics -X- _ O
about -X- _ O
your -X- _ O
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
error -X- _ O
bars -X- _ O
around -X- _ O
results -X- _ O
, -X- _ O
summary -X- _ O
statistics -X- _ O
from -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
it -X- _ O
transparent -X- _ O
whether -X- _ O
you -X- _ O
are -X- _ O
reporting -X- _ O
the -X- _ O
max -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
or -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
? -X- _ O
Section -X- _ O
3 -X- _ O
/ -X- _ O
squareC4 -X- _ O
. -X- _ O
If -X- _ O
you -X- _ O
used -X- _ O
existing -X- _ O
packages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
preprocessing -X- _ O
, -X- _ O
for -X- _ O
normalization -X- _ O
, -X- _ O
or -X- _ O
for -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
implementation -X- _ O
, -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
parameter -X- _ O
settings -X- _ O
used -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
NLTK -X- _ O
, -X- _ O
Spacy -X- _ O
, -X- _ O
ROUGE -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
? -X- _ O
Section -X- _ O
2 -X- _ O
D -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
human -X- _ O
annotators -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdworkers -X- _ O
) -X- _ O
or -X- _ O
research -X- _ O
with -X- _ O
human -X- _ O
participants -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
of -X- _ O
instructions -X- _ O
given -X- _ O
to -X- _ O
participants -X- _ O
, -X- _ O
including -X- _ O
e.g. -X- _ O
, -X- _ O
screenshots -X- _ O
, -X- _ O
disclaimers -X- _ O
of -X- _ O
any -X- _ O
risks -X- _ O
to -X- _ O
participants -X- _ O
or -X- _ O
annotators -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
you -X- _ O
recruited -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdsourcing -X- _ O
platform -X- _ O
, -X- _ O
students -X- _ O
) -X- _ O
and -X- _ O
paid -X- _ O
participants -X- _ O
, -X- _ O
and -X- _ O
discuss -X- _ O
if -X- _ O
such -X- _ O
payment -X- _ O
is -X- _ O
adequate -X- _ O
given -X- _ O
the -X- _ O
participants -X- _ O
’ -X- _ O
demographic -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
country -X- _ O
of -X- _ O
residence -X- _ O
) -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
whether -X- _ O
and -X- _ O
how -X- _ O
consent -X- _ O
was -X- _ O
obtained -X- _ O
from -X- _ O
people -X- _ O
whose -X- _ O
data -X- _ O
you -X- _ O
’re -X- _ O
using -X- _ O
/ -X- _ O
curating -X- _ O
? -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
collected -X- _ O
data -X- _ O
via -X- _ O
crowdsourcing -X- _ O
, -X- _ O
did -X- _ O
your -X- _ O
instructions -X- _ O
to -X- _ O
crowdworkers -X- _ O
explain -X- _ O
how -X- _ O
the -X- _ O
data -X- _ O
would -X- _ O
be -X- _ O
used -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD4 -X- _ O
. -X- _ O
Was -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
protocol -X- _ O
approved -X- _ O
( -X- _ O
or -X- _ O
determined -X- _ O
exempt -X- _ O
) -X- _ O
by -X- _ O
an -X- _ O
ethics -X- _ O
review -X- _ O
board -X- _ O
? -X- _ O
No -X- _ O
response -X- _ O
. -X- _ O
/ -X- _ O
squareD5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
basic -X- _ O
demographic -X- _ O
and -X- _ O
geographic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
annotator -X- _ O
population -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
? -X- _ O
No -X- _ O
response.118 -X- _ O

Summary -X- _ SUMMARY
: -X- _ SUMMARY
  -X- _ SUMMARY
The -X- _ SUMMARY
research -X- _ SUMMARY
paper -X- _ SUMMARY
presents -X- _ SUMMARY
a -X- _ SUMMARY
novel -X- _ SUMMARY
unsupervised -X- _ SUMMARY
approach -X- _ SUMMARY
to -X- _ SUMMARY
subtitle -X- _ SUMMARY
segmentation -X- _ SUMMARY
using -X- _ SUMMARY
pretrained -X- _ SUMMARY
masked -X- _ SUMMARY
language -X- _ SUMMARY
models -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
approach -X- _ SUMMARY
predicts -X- _ SUMMARY
line -X- _ SUMMARY
endings -X- _ SUMMARY
and -X- _ SUMMARY
subtitle -X- _ SUMMARY
breaks -X- _ SUMMARY
based -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
likelihood -X- _ SUMMARY
of -X- _ SUMMARY
punctuation -X- _ SUMMARY
marks -X- _ SUMMARY
occurring -X- _ SUMMARY
at -X- _ SUMMARY
candidate -X- _ SUMMARY
segmentation -X- _ SUMMARY
points -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
achieved -X- _ SUMMARY
competitive -X- _ SUMMARY
segmentation -X- _ SUMMARY
accuracy -X- _ SUMMARY
across -X- _ SUMMARY
metrics -X- _ SUMMARY
and -X- _ SUMMARY
fully -X- _ SUMMARY
preserved -X- _ SUMMARY
the -X- _ SUMMARY
original -X- _ SUMMARY
text -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
was -X- _ SUMMARY
conducted -X- _ SUMMARY
on -X- _ SUMMARY
the -X- _ SUMMARY
MuST -X- _ SUMMARY
- -X- _ SUMMARY
Cinema -X- _ SUMMARY
corpus -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
the -X- _ SUMMARY
results -X- _ SUMMARY
were -X- _ SUMMARY
compared -X- _ SUMMARY
with -X- _ SUMMARY
baseline -X- _ SUMMARY
models -X- _ SUMMARY
and -X- _ SUMMARY
supervised -X- _ SUMMARY
approaches -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
metrics -X- _ SUMMARY
used -X- _ SUMMARY
were -X- _ SUMMARY
Sigma -X- _ SUMMARY
( -X- _ SUMMARY
ratio -X- _ SUMMARY
of -X- _ SUMMARY
achieved -X- _ SUMMARY
BLEU -X- _ SUMMARY
over -X- _ SUMMARY
an -X- _ SUMMARY
upper -X- _ SUMMARY
- -X- _ SUMMARY
bound -X- _ SUMMARY
BLEU -X- _ SUMMARY
score -X- _ SUMMARY
) -X- _ SUMMARY
, -X- _ SUMMARY
break -X- _ SUMMARY
coverage -X- _ SUMMARY
, -X- _ SUMMARY
and -X- _ SUMMARY
length -X- _ SUMMARY
conformity -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
proposed -X- _ SUMMARY
method -X- _ SUMMARY
outperformed -X- _ SUMMARY
the -X- _ SUMMARY
baseline -X- _ SUMMARY
model -X- _ SUMMARY
and -X- _ SUMMARY
provided -X- _ SUMMARY
a -X- _ SUMMARY
robust -X- _ SUMMARY
off -X- _ SUMMARY
- -X- _ SUMMARY
the -X- _ SUMMARY
- -X- _ SUMMARY
shelf -X- _ SUMMARY
solution -X- _ SUMMARY
for -X- _ SUMMARY
subtitle -X- _ SUMMARY
segmentation -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
limitations -X- _ SUMMARY
of -X- _ SUMMARY
the -X- _ SUMMARY
approach -X- _ SUMMARY
and -X- _ SUMMARY
potential -X- _ SUMMARY
future -X- _ SUMMARY
directions -X- _ SUMMARY
are -X- _ SUMMARY
discussed -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
evaluation -X- _ SUMMARY
results -X- _ SUMMARY
, -X- _ SUMMARY
including -X- _ SUMMARY
BLEU -X- _ SUMMARY
scores -X- _ SUMMARY
and -X- _ SUMMARY
break -X- _ SUMMARY
coverage -X- _ SUMMARY
, -X- _ SUMMARY
are -X- _ SUMMARY
provided -X- _ SUMMARY
for -X- _ SUMMARY
different -X- _ SUMMARY
languages -X- _ SUMMARY
and -X- _ SUMMARY
hyperparameter -X- _ SUMMARY
settings -X- _ SUMMARY
. -X- _ SUMMARY
The -X- _ SUMMARY
ethical -X- _ SUMMARY
considerations -X- _ SUMMARY
regarding -X- _ SUMMARY
energy -X- _ SUMMARY
consumption -X- _ SUMMARY
and -X- _ SUMMARY
training -X- _ SUMMARY
costs -X- _ SUMMARY
are -X- _ SUMMARY
also -X- _ SUMMARY
addressed -X- _ SUMMARY
. -X- _ SUMMARY
  -X- _ SUMMARY
NOTE -X- _ SUMMARY
: -X- _ SUMMARY
The -X- _ SUMMARY
summary -X- _ SUMMARY
has -X- _ SUMMARY
been -X- _ SUMMARY
shortened -X- _ SUMMARY
and -X- _ SUMMARY
does -X- _ SUMMARY
not -X- _ SUMMARY
include -X- _ SUMMARY
all -X- _ SUMMARY
the -X- _ SUMMARY
specified -X- _ SUMMARY
details -X- _ SUMMARY
. -X- _ SUMMARY
2023.acl-short.67.txt -X- _ O
David -X- _ O
PonceandThierry -X- _ O
EtchegoyhenandVictor -X- _ O
RuizVicomtech -X- _ O
Foundation -X- _ O
, -X- _ O
Basque -X- _ O
Research -X- _ O
and -X- _ O
Technology -X- _ O
Alliance -X- _ O
( -X- _ O
BRTA -X- _ O
) -X- _ O
University -X- _ O
of -X- _ O
the -X- _ O
Basque -X- _ O
Country -X- _ O
UPV -X- _ O
/ -X- _ O
EHU -X- _ O
{ -X- _ O
adponce -X- _ O
, -X- _ O
tetchegoyhen -X- _ O
, -X- _ O
vruiz -X- _ O
} -X- _ O
@ -X- _ O
vicomtech.org -X- _ O
Abstract -X- _ O
We -X- _ O
describe -X- _ O
a -X- _ O
novel -X- _ O
unsupervised -X- _ O
approach -X- _ O
to -X- _ O
subtitle -X- _ B-TaskName
segmentation -X- _ I-TaskName
, -X- _ O
based -X- _ O
on -X- _ O
pretrained -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
line -X- _ O
endings -X- _ O
and -X- _ O
subtitle -X- _ O
breaks -X- _ O
are -X- _ O
predicted -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
punctuation -X- _ O
to -X- _ O
occur -X- _ O
at -X- _ O
candidate -X- _ O
segmentation -X- _ O
points -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
obtained -X- _ O
competitive -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
segmentation -X- _ B-MetricName
accuracy -X- _ I-MetricName
across -X- _ O
metrics -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
fully -X- _ O
preserving -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
and -X- _ O
complying -X- _ O
with -X- _ O
length -X- _ O
constraints -X- _ O
. -X- _ O
Although -X- _ O
supervised -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
and -X- _ O
with -X- _ O
access -X- _ O
to -X- _ O
source -X- _ O
audio -X- _ O
information -X- _ O
can -X- _ O
provide -X- _ O
better -X- _ O
segmentation -X- _ B-MetricName
accuracy -X- _ I-MetricName
, -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
highly -X- _ O
portable -X- _ O
across -X- _ O
languages -X- _ O
and -X- _ O
domains -X- _ O
and -X- _ O
may -X- _ O
constitute -X- _ O
a -X- _ O
robust -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
solution -X- _ O
for -X- _ O
subtitle -X- _ B-TaskName
segmentation -X- _ I-TaskName
. -X- _ O
1 -X- _ O
Introduction -X- _ O
Subtitling -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
principal -X- _ O
means -X- _ O
of -X- _ O
providing -X- _ O
accessible -X- _ O
audiovisual -X- _ O
content -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
ever -X- _ O
increasing -X- _ O
production -X- _ O
of -X- _ O
audiovisual -X- _ O
content -X- _ O
in -X- _ O
multiple -X- _ O
domains -X- _ O
and -X- _ O
languages -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
digital -X- _ O
era -X- _ O
, -X- _ O
subtitle -X- _ O
provision -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
automation -X- _ O
support -X- _ O
, -X- _ O
via -X- _ O
Automatic -X- _ O
Speech -X- _ O
Recognition -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
Machine -X- _ O
Translation -X- _ O
( -X- _ O
V -X- _ O
olk -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Aliprandi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Etchegoyhen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
; -X- _ O
Tardel -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
Bojar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Subtitles -X- _ O
are -X- _ O
subject -X- _ O
to -X- _ O
specific -X- _ O
constraints -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
achieve -X- _ O
adequate -X- _ O
readability -X- _ O
, -X- _ O
including -X- _ O
layout -X- _ O
, -X- _ O
on -X- _ O
- -X- _ O
screen -X- _ O
duration -X- _ O
and -X- _ O
text -X- _ O
editing -X- _ O
. -X- _ O
Among -X- _ O
these -X- _ O
constraints -X- _ O
, -X- _ O
segmentation -X- _ O
addresses -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
per -X- _ O
line -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
lines -X- _ O
per -X- _ O
subtitle -X- _ O
, -X- _ O
and -X- _ O
breaks -X- _ O
at -X- _ O
natural -X- _ O
linguistic -X- _ O
frontiers -X- _ O
. -X- _ O
Segmentation -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
important -X- _ O
readability -X- _ O
factor -X- _ O
( -X- _ O
Perego -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
; -X- _ O
Rajendran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
improperly -X- _ O
segmented -X- _ O
subtitles -X- _ O
resulting -X- _ O
in -X- _ O
increased -X- _ O
cognitive -X- _ O
effort -X- _ O
and -X- _ O
reading -X- _ O
times -X- _ O
for -X- _ O
users -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
automated -X- _ O
subtitling -X- _ O
systems -X- _ O
need -X- _ O
to -X- _ O
generate -X- _ O
properly -X- _ O
segmented -X- _ O
subtitles -X- _ O
to -X- _ O
achieve -X- _ O
readability -X- _ O
. -X- _ O
A -X- _ O
typical -X- _ O
baseline -X- _ O
for -X- _ O
subtitle -X- _ B-TaskName
segmentation -X- _ I-TaskName
, -X- _ O
still -X- _ O
used -X- _ O
in -X- _ O
some -X- _ O
production -X- _ O
systems -X- _ O
, -X- _ O
is -X- _ O
simple -X- _ O
character -X- _ O
counting -X- _ O
, -X- _ O
whereby -X- _ O
line -X- _ O
breaks -X- _ O
are -X- _ O
inserted -X- _ O
before -X- _ O
reaching -X- _ O
the -X- _ O
maximum -X- _ O
allowed -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
per -X- _ O
line -X- _ O
. -X- _ O
Although -X- _ O
simple -X- _ O
and -X- _ O
fast -X- _ O
, -X- _ O
this -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
address -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
linguistically -X- _ O
correct -X- _ O
segments -X- _ O
and -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
falls -X- _ O
short -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
readability -X- _ O
. -X- _ O
Several -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
improve -X- _ O
segmentation -X- _ O
by -X- _ O
automated -X- _ O
means -X- _ O
. -X- _ O
Álvarez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2014 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
machine -X- _ O
learning -X- _ O
method -X- _ O
where -X- _ O
subtitle -X- _ O
breaks -X- _ O
are -X- _ O
predicted -X- _ O
by -X- _ O
Support -X- _ O
Vector -X- _ O
Machine -X- _ O
and -X- _ O
Linear -X- _ O
Regression -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
professionally -X- _ O
- -X- _ O
created -X- _ O
subtitles -X- _ O
. -X- _ O
A -X- _ O
similar -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
Conditional -X- _ O
Random -X- _ O
Fields -X- _ O
was -X- _ O
then -X- _ O
shown -X- _ O
to -X- _ O
improve -X- _ O
over -X- _ O
these -X- _ O
results -X- _ O
( -X- _ O
Alvarez -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Approaches -X- _ O
that -X- _ O
directly -X- _ O
generate -X- _ O
subtitle -X- _ O
breaks -X- _ O
within -X- _ O
Neural -X- _ O
Machine -X- _ O
Translation -X- _ O
have -X- _ O
also -X- _ O
been -X- _ O
proposed -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
Matusov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Karakanta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
Papi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
developed -X- _ O
a -X- _ O
multilingual -X- _ O
segmenter -X- _ O
which -X- _ O
generates -X- _ O
both -X- _ O
text -X- _ O
and -X- _ O
breaks -X- _ O
and -X- _ O
may -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
textual -X- _ O
input -X- _ O
only -X- _ O
, -X- _ O
or -X- _ O
on -X- _ O
joint -X- _ O
text -X- _ O
and -X- _ O
audio -X- _ O
data -X- _ O
. -X- _ O
Although -X- _ O
quality -X- _ O
subtitle -X- _ B-TaskName
segmentation -X- _ I-TaskName
may -X- _ O
be -X- _ O
achieved -X- _ O
with -X- _ O
the -X- _ O
aforementioned -X- _ O
approaches -X- _ O
, -X- _ O
they -X- _ O
require -X- _ O
supervised -X- _ O
training -X- _ O
on -X- _ O
segmented -X- _ O
subtitle -X- _ O
corpora -X- _ O
. -X- _ O
At -X- _ O
present -X- _ O
, -X- _ O
the -X- _ O
largest -X- _ O
subtitle -X- _ O
corpus -X- _ O
is -X- _ O
Open -X- _ O
Subtitles -X- _ O
( -X- _ O
Lison -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
mainly -X- _ O
covers -X- _ O
entertainment -X- _ O
material -X- _ O
, -X- _ O
contains -X- _ O
subtitles -X- _ O
mostly -X- _ O
created -X- _ O
by -X- _ O
non -X- _ O
- -X- _ O
professionals -X- _ O
or -X- _ O
automatically -X- _ O
translated -X- _ O
, -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
include -X- _ O
line -X- _ O
breaks -X- _ O
. -X- _ O
The -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
Cinema -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
Karakanta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
multilingual -X- _ O
speech -X- _ O
translation -X- _ O
corpus -X- _ O
that -X- _ O
includes -X- _ O
subtitles -X- _ O
breaks -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
only -X- _ O
available -X- _ O
for -X- _ O
8 -X- _ O
languages -X- _ O
at -X- _ O
the -X- _ O
moment -X- _ O
. -X- _ O
Considering -X- _ O
the -X- _ O
vast -X- _ O
amount -X- _ O
of -X- _ O
languages -X- _ O
and -X- _ O
domains -X- _ O
in -X- _ O
audiovisual -X- _ O
content -X- _ O
, -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
segmented -X- _ O
training -X- _ O
data -X- _ O
hinders -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
robust -X- _ O
automated -X- _ B-TaskName
subtitling -X- _ I-TaskName
systems -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
a -X- _ O
novel -X- _ O
unsupervised -X- _ O
method -X- _ O
based -X- _ O
on -X- _ O
pretrained -X- _ O
masked -X- _ O
language -X- _ O
mod-771els -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
line -X- _ O
and -X- _ O
subtitle -X- _ O
breaks -X- _ O
are -X- _ O
inserted -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
a -X- _ O
segment -X- _ O
acting -X- _ O
as -X- _ O
an -X- _ O
isolated -X- _ O
unit -X- _ O
, -X- _ O
as -X- _ O
approximated -X- _ O
by -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
punctuation -X- _ O
mark -X- _ O
occurring -X- _ O
at -X- _ O
a -X- _ O
given -X- _ O
segmentation -X- _ O
point -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
this -X- _ O
novel -X- _ O
approach -X- _ O
obtained -X- _ O
competitive -X- _ O
results -X- _ O
on -X- _ O
most -X- _ O
metrics -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
fully -X- _ O
preserving -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
and -X- _ O
complying -X- _ O
with -X- _ O
length -X- _ O
constraints -X- _ O
. -X- _ O
Our -X- _ O
system -X- _ O
may -X- _ O
thus -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
simple -X- _ O
yet -X- _ O
efficient -X- _ O
subtitle -X- _ O
segmenter -X- _ O
with -X- _ O
any -X- _ O
pretrained -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
for -X- _ O
any -X- _ O
language -X- _ O
covered -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
2 -X- _ O
Approach -X- _ O
Our -X- _ O
approach -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
standard -X- _ O
view -X- _ O
that -X- _ O
the -X- _ O
more -X- _ O
appropriate -X- _ O
subtitle -X- _ O
segments -X- _ O
are -X- _ O
those -X- _ O
that -X- _ O
may -X- _ O
function -X- _ O
as -X- _ O
isolated -X- _ O
grammatical -X- _ O
chunks -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
hypothesise -X- _ O
that -X- _ O
a -X- _ O
relevant -X- _ O
approximation -X- _ O
for -X- _ O
the -X- _ O
identification -X- _ O
of -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
unit -X- _ O
is -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
a -X- _ O
punctuation -X- _ O
mark -X- _ O
being -X- _ O
inserted -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
segment -X- _ O
, -X- _ O
as -X- _ O
punctuation -X- _ O
may -X- _ O
mark -X- _ O
the -X- _ O
closure -X- _ O
of -X- _ O
a -X- _ O
syntactic -X- _ O
unit -X- _ O
and -X- _ O
is -X- _ O
often -X- _ O
associated -X- _ O
with -X- _ O
discursive -X- _ O
pauses -X- _ O
. -X- _ O
To -X- _ O
test -X- _ O
this -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
punctuation -X- _ O
marks -X- _ O
at -X- _ O
different -X- _ O
segmentation -X- _ O
points -X- _ O
, -X- _ O
as -X- _ O
predicted -X- _ O
by -X- _ O
a -X- _ O
pretrained -X- _ O
MLM -X- _ O
, -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
insertion -X- _ O
point -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
likelihood -X- _ O
. -X- _ O
The -X- _ O
segmentation -X- _ O
candidates -X- _ O
are -X- _ O
determined -X- _ O
under -X- _ O
a -X- _ O
sliding -X- _ O
- -X- _ O
window -X- _ O
approach -X- _ O
over -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
generate -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
all -X- _ O
pairs -X- _ O
< -X- _ O
α -X- _ O
, -X- _ O
β -X- _ O
> -X- _ O
over -X- _ O
the -X- _ O
unprocessed -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
where -X- _ O
αis -X- _ O
a -X- _ O
segmentation -X- _ O
candidate -X- _ O
of -X- _ O
length -X- _ O
under -X- _ O
a -X- _ O
specified -X- _ O
limit -X- _ O
K -X- _ O
, -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
per -X- _ O
line -X- _ O
, -X- _ O
and -X- _ O
βis -X- _ O
the -X- _ O
remaining -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
be -X- _ O
segmented -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
score -X- _ O
all -X- _ O
segmentation -X- _ O
candidates -X- _ O
α -X- _ O
with -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
LM -X- _ O
scoring -X- _ O
variants -X- _ O
described -X- _ O
below -X- _ O
. -X- _ O
A -X- _ O
segmentation -X- _ O
marker -X- _ O
, -X- _ O
either -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
line -X- _ O
( -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
block -X- _ O
indicating -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
subtitle -X- _ O
( -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
then -X- _ O
appended -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
scoring -X- _ O
candidate -X- _ O
, -X- _ O
and -X- _ O
βbecomes -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
to -X- _ O
be -X- _ O
segmented -X- _ O
in -X- _ O
a -X- _ O
recursive -X- _ O
iteration -X- _ O
of -X- _ O
the -X- _ O
process -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
method -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
any -X- _ O
additional -X- _ O
information -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
an -X- _ O
audio -X- _ O
source -X- _ O
, -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
segmentation -X- _ O
type -X- _ O
, -X- _ O
an -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
tag -X- _ O
is -X- _ O
inserted -X- _ O
every -X- _ O
even -X- _ O
segment -X- _ O
or -X- _ O
when -X- _ O
βis -X- _ O
empty -X- _ O
; -X- _ O
otherwise -X- _ O
, -X- _ O
an -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
tag -X- _ O
is -X- _ O
inserted -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
generate -X- _ O
subtitles -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
two -X- _ O
lines -X- _ O
, -X- _ O
following -X- _ O
a -X- _ O
standard -X- _ O
recommendation -X- _ O
in -X- _ O
subtitling -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
define -X- _ O
a -X- _ O
minimal -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
( -X- _ O
min -X- _ O
) -X- _ O
inαfor -X- _ O
thesegmentation -X- _ O
process -X- _ O
to -X- _ O
apply -X- _ O
, -X- _ O
and -X- _ O
do -X- _ O
not -X- _ O
segment -X- _ O
lines -X- _ O
that -X- _ O
are -X- _ O
under -X- _ O
the -X- _ O
specified -X- _ O
character -X- _ O
limit -X- _ O
. -X- _ O
We -X- _ O
evaluated -X- _ O
three -X- _ O
approaches -X- _ O
to -X- _ O
compute -X- _ O
segmentation -X- _ O
scores -X- _ O
over -X- _ O
each -X- _ O
candidate -X- _ O
pair -X- _ O
< -X- _ O
α -X- _ O
, -X- _ O
β -X- _ O
> -X- _ O
: -X- _ O
•Substitution -X- _ B-MethodName
: -X- _ O
The -X- _ O
last -X- _ O
token -X- _ O
of -X- _ O
αis -X- _ O
masked -X- _ O
and -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
highest -X- _ O
MLM -X- _ O
probability -X- _ O
among -X- _ O
punctuation -X- _ O
marks -X- _ O
on -X- _ O
this -X- _ O
mask -X- _ O
. -X- _ O
•Insertion -X- _ B-MethodName
: -X- _ O
A -X- _ O
mask -X- _ O
is -X- _ O
appended -X- _ O
to -X- _ O
αand -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
highest -X- _ O
MLM -X- _ O
probability -X- _ O
among -X- _ O
punctuation -X- _ O
marks -X- _ O
on -X- _ O
this -X- _ O
mask -X- _ O
. -X- _ O
•LM -X- _ B-MethodName
- -X- _ I-MethodName
Score -X- _ I-MethodName
: -X- _ O
The -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
the -X- _ O
perplexity -X- _ O
of -X- _ O
αandβ -X- _ O
, -X- _ O
as -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
MLM -X- _ O
probabilities -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
sequence -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
two -X- _ O
methods -X- _ O
are -X- _ O
variants -X- _ O
of -X- _ O
our -X- _ O
core -X- _ O
approach -X- _ O
. -X- _ O
The -X- _ O
third -X- _ O
method -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
pretrained -X- _ O
MLM -X- _ O
, -X- _ O
relies -X- _ O
instead -X- _ O
on -X- _ O
the -X- _ O
pseudoperplexity -X- _ O
of -X- _ O
the -X- _ O
sequences -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
MLM -X- _ O
, -X- _ O
computed -X- _ O
following -X- _ O
Salazar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
included -X- _ O
this -X- _ O
latter -X- _ O
variant -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
using -X- _ O
LM -X- _ O
scoring -X- _ O
directly -X- _ O
, -X- _ O
without -X- _ O
resorting -X- _ O
to -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
punctuation -X- _ O
marks -X- _ O
. -X- _ O
3 -X- _ O
Experimental -X- _ O
Setup -X- _ O
Corpora -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
MustST -X- _ B-DatasetName
- -X- _ I-DatasetName
Cinema -X- _ I-DatasetName
corpus -X- _ O
( -X- _ O
Karakanta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
derived -X- _ O
from -X- _ O
TED -X- _ O
talks -X- _ O
and -X- _ O
contains -X- _ O
both -X- _ O
line -X- _ O
and -X- _ O
subtitle -X- _ O
break -X- _ O
markers -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
being -X- _ O
publicly -X- _ O
available -X- _ O
, -X- _ O
it -X- _ O
also -X- _ O
allows -X- _ O
for -X- _ O
a -X- _ O
direct -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
supervised -X- _ O
models -X- _ O
of -X- _ O
Papi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
6 -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
Cinema -X- _ I-DatasetName
datasets -X- _ O
for -X- _ O
which -X- _ O
comparative -X- _ O
results -X- _ O
were -X- _ O
available -X- _ O
, -X- _ O
directly -X- _ O
predicting -X- _ O
segmentation -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
without -X- _ O
any -X- _ O
training -X- _ O
. -X- _ O
Methods -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
tested -X- _ O
the -X- _ O
three -X- _ O
variants -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
MLM -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
.. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
included -X- _ O
a -X- _ O
variant -X- _ O
called -X- _ O
overt -X- _ B-MethodName
clueing -X- _ I-MethodName
( -X- _ O
OC -X- _ B-MethodName
) -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
overt -X- _ O
punctuation -X- _ O
mark -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
segment -X- _ O
increments -X- _ O
the -X- _ O
mask -X- _ O
score -X- _ O
by -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
compared -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
LM -X- _ O
- -X- _ O
based -X- _ O
variant -X- _ O
with -X- _ O
those -X- _ O
obtained -X- _ O
by -X- _ O
alternative -X- _ O
approaches -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
were -X- _ O
computed -X- _ O
with -X- _ O
min -X- _ O
= -X- _ O
15 -X- _ O
, -X- _ O
as -X- _ O
this -X- _ O
value -X- _ O
obtained -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
overall -X- _ O
over -X- _ O
the -X- _ O
development772English -X- _ O
Spanish -X- _ O
German -X- _ O
Method -X- _ O
Sigma -X- _ B-MetricName
EOL -X- _ O
EOB -X- _ O
Sigma -X- _ B-MetricName
EOL -X- _ O
EOB -X- _ O
Sigma -X- _ B-MetricName
EOL -X- _ O
EOB -X- _ O
Substitution -X- _ O
71.65 -X- _ O
+19.86 -X- _ O
-10.96 -X- _ O
69.34 -X- _ O
+12.36 -X- _ O
-5.74 -X- _ O
69.31 -X- _ O
+19.05 -X- _ O
-7.05 -X- _ O
Insertion -X- _ O
76.77 -X- _ O
+19.18 -X- _ O
-9.91 -X- _ O
73.47 -X- _ O
+12.98 -X- _ O
-4.91 -X- _ O
70.85 -X- _ O
+18.53 -X- _ O
-7.96 -X- _ O
LM -X- _ O
- -X- _ O
Score -X- _ O
69.97 -X- _ O
+21.40 -X- _ O
-8.66 -X- _ O
67.70 -X- _ O
+13.29 -X- _ O
-5.37 -X- _ O
64.07 -X- _ O
+16.45 -X- _ O
-6.51 -X- _ O
sets -X- _ O
, -X- _ O
although -X- _ O
the -X- _ O
differences -X- _ O
were -X- _ O
minor -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
values -X- _ O
we -X- _ O
tested -X- _ O
( -X- _ O
1 -X- _ O
, -X- _ O
10 -X- _ O
and -X- _ O
20 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
simple -X- _ O
character -X- _ O
counting -X- _ O
approach -X- _ O
( -X- _ O
hereafter -X- _ O
, -X- _ O
CountChars -X- _ B-MethodName
) -X- _ O
as -X- _ O
baseline -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
as -X- _ O
representative -X- _ O
supervised -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
selected -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
described -X- _ O
by -X- _ O
( -X- _ O
Papi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
. -X- _ O
Their -X- _ O
core -X- _ O
supervised -X- _ O
approach -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
architecture -X- _ O
with -X- _ O
3 -X- _ O
encoder -X- _ O
layers -X- _ O
and -X- _ O
3 -X- _ O
decoder -X- _ O
layers -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
textual -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
Cinema -X- _ I-DatasetName
input -X- _ O
only -X- _ O
( -X- _ O
MC.Text -X- _ B-DatasetName
) -X- _ O
, -X- _ O
or -X- _ O
on -X- _ O
complementary -X- _ O
audio -X- _ O
data -X- _ O
as -X- _ O
well -X- _ O
via -X- _ O
an -X- _ O
additional -X- _ O
speech -X- _ O
encoder -X- _ O
with -X- _ O
12 -X- _ O
encoder -X- _ O
layers -X- _ O
( -X- _ O
MC.Multi -X- _ B-DatasetName
) -X- _ O
. -X- _ O
They -X- _ O
trained -X- _ O
each -X- _ O
variant -X- _ O
on -X- _ O
either -X- _ O
monolingual -X- _ O
data -X- _ O
alone -X- _ O
( -X- _ O
mono -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
in -X- _ O
a -X- _ O
multilingual -X- _ O
setting -X- _ O
( -X- _ O
multi -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
they -X- _ O
also -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
a -X- _ O
variant -X- _ O
( -X- _ O
OS.Text -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
Open -X- _ O
Subtitles -X- _ O
corpus -X- _ O
( -X- _ O
Lison -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
their -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
experiments -X- _ O
. -X- _ O
Evaluation -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
subtitle -X- _ O
- -X- _ O
oriented -X- _ O
metric -X- _ O
Sigma -X- _ B-MetricName
( -X- _ O
Karakanta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
computes -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
achieved -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
over -X- _ O
an -X- _ O
approximated -X- _ O
upper -X- _ O
- -X- _ O
bound -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
, -X- _ O
on -X- _ O
text -X- _ O
that -X- _ O
includes -X- _ O
line -X- _ O
and -X- _ O
subtitle -X- _ O
breaks -X- _ O
. -X- _ O
Sigma -X- _ B-MetricName
is -X- _ O
meant -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
imperfect -X- _ O
texts -X- _ O
, -X- _ O
i.e. -X- _ O
text -X- _ O
that -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
reference -X- _ O
when -X- _ O
breaks -X- _ O
are -X- _ O
omitted -X- _ O
. -X- _ O
Although -X- _ O
our -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
produce -X- _ O
imperfect -X- _ O
text -X- _ O
, -X- _ O
achieving -X- _ O
perfect -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
when -X- _ O
breaks -X- _ O
are -X- _ O
ignored -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
this -X- _ O
metric -X- _ O
for -X- _ O
comparison -X- _ O
purposes -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
break -X- _ B-MetricName
coverage -X- _ I-MetricName
results -X- _ O
( -X- _ O
Papi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2022 -X- _ O
) -X- _ O
, -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
predicted -X- _ O
breaks -X- _ O
over -X- _ O
reference -X- _ O
breaks -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
computed -X- _ O
separately -X- _ O
for -X- _ O
the -X- _ O
EOL -X- _ O
and -X- _ O
EOB -X- _ O
breaks -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
length -X- _ B-MetricName
conformity -X- _ I-MetricName
results -X- _ O
( -X- _ O
CPL -X- _ B-MetricName
) -X- _ O
, -X- _ O
measured -X- _ O
as -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
subtitle -X- _ O
lines -X- _ O
whose -X- _ O
length -X- _ O
is -X- _ O
under -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
defined -X- _ O
by -X- _ O
the -X- _ O
subtitle -X- _ O
guidelines -X- _ O
( -X- _ O
42 -X- _ O
in -X- _ O
the -X- _ O
TED -X- _ O
guidelines -X- _ O
) -X- _ O
.4 -X- _ O
LM -X- _ O
- -X- _ O
based -X- _ O
Segmentation -X- _ O
Variants -X- _ O
We -X- _ O
first -X- _ O
compared -X- _ O
the -X- _ O
three -X- _ O
methods -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
on -X- _ O
the -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
and -X- _ O
German -X- _ O
datasets -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
results -X- _ O
described -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
Sigma -X- _ B-MetricName
, -X- _ O
the -X- _ O
Insertion -X- _ O
method -X- _ O
obtained -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
obtained -X- _ O
the -X- _ O
best -X- _ O
scores -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
coverage -X- _ O
for -X- _ O
the -X- _ O
EOL -X- _ O
marker -X- _ O
, -X- _ O
except -X- _ O
in -X- _ O
Spanish -X- _ O
, -X- _ O
although -X- _ O
all -X- _ O
three -X- _ O
variants -X- _ O
tend -X- _ O
to -X- _ O
overgenerate -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
line -X- _ O
markers -X- _ O
to -X- _ O
similar -X- _ O
extents -X- _ O
. -X- _ O
The -X- _ O
LM -X- _ O
- -X- _ O
Score -X- _ O
variant -X- _ O
obtained -X- _ O
the -X- _ O
worst -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
Sigma -X- _ B-MetricName
, -X- _ O
but -X- _ O
outperformed -X- _ O
the -X- _ O
alternatives -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
EOB -X- _ B-MetricName
coverage -X- _ I-MetricName
, -X- _ O
a -X- _ O
metric -X- _ O
on -X- _ O
which -X- _ O
the -X- _ O
three -X- _ O
variants -X- _ O
performed -X- _ O
markedly -X- _ O
better -X- _ O
than -X- _ O
on -X- _ O
EOL -X- _ B-MetricName
coverage -X- _ I-MetricName
. -X- _ O
Considering -X- _ O
the -X- _ O
overall -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
Insertion -X- _ B-MethodName
variant -X- _ I-MethodName
as -X- _ O
the -X- _ O
most -X- _ O
balanced -X- _ O
one -X- _ O
for -X- _ O
all -X- _ O
remaining -X- _ O
experiments -X- _ O
reported -X- _ O
below -X- _ O
. -X- _ O
5 -X- _ O
Comparative -X- _ O
Results -X- _ O
In -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
selected -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
languages -X- _ O
for -X- _ O
which -X- _ O
results -X- _ O
were -X- _ O
available -X- _ O
with -X- _ O
supervised -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
outperformed -X- _ O
the -X- _ O
CountChars -X- _ B-MethodName
baseline -X- _ O
across -X- _ O
the -X- _ O
board -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
in -X- _ O
turn -X- _ O
outperformed -X- _ O
by -X- _ O
the -X- _ O
supervised -X- _ O
variants -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
Sigma -X- _ B-MetricName
scores -X- _ O
. -X- _ O
Although -X- _ O
it -X- _ O
is -X- _ O
clear -X- _ O
from -X- _ O
these -X- _ O
results -X- _ O
that -X- _ O
training -X- _ O
segmentation -X- _ O
models -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
data -X- _ O
, -X- _ O
with -X- _ O
or -X- _ O
without -X- _ O
audio -X- _ O
data -X- _ O
, -X- _ O
provides -X- _ O
clear -X- _ O
advantages -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
subtitle -X- _ O
segmentation -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
Sigma -X- _ B-MetricName
does -X- _ O
not -X- _ O
, -X- _ O
by -X- _ O
design -X- _ O
, -X- _ O
reflect -X- _ O
the -X- _ O
actual -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
without -X- _ O
breaks -X- _ O
, -X- _ O
i.e. -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
imperfect -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
by -X- _ O
- -X- _ O
product -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
supervised -X- _ O
approaches -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
existent -X- _ O
in -X- _ O
ours -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
CPL -X- _ B-MetricName
, -X- _ O
all -X- _ O
supervised -X- _ O
models -X- _ O
generate -X- _ O
subtitle -X- _ O
lines -X- _ O
that -X- _ O
overflow -X- _ O
the -X- _ O
limit -X- _ O
, -X- _ O
to -X- _ O
a -X- _ O
significant -X- _ O
degree -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
selected -X- _ O
unsupervised -X- _ O
models -X- _ O
trivially -X- _ O
respect -X- _ O
the -X- _ O
length -X- _ O
constraint.773English -X- _ O
French -X- _ O
German -X- _ O
Italian -X- _ O
Method -X- _ O
Training -X- _ O
Sigma -X- _ B-MetricName
CPL -X- _ B-MetricName
Sigma -X- _ B-MetricName
CPL -X- _ B-MetricName
Sigma -X- _ B-MetricName
CPL -X- _ B-MetricName
Sigma -X- _ B-MetricName
CPL -X- _ B-MetricName
CountChars -X- _ B-MethodName
N -X- _ O
/ -X- _ O
A -X- _ O
63.71 -X- _ O
100 -X- _ O
% -X- _ O
62.87 -X- _ O
100 -X- _ O
% -X- _ O
62.34 -X- _ O
100 -X- _ O
% -X- _ O
61.49 -X- _ O
100 -X- _ O
% -X- _ O
MC.Textmono -X- _ O
84.87 -X- _ O
96.6 -X- _ O
% -X- _ O
83.68 -X- _ O
96.7 -X- _ O
% -X- _ O
83.62 -X- _ O
90.9 -X- _ O
% -X- _ O
82.22 -X- _ O
90.0 -X- _ O
% -X- _ O
multi -X- _ O
85.98 -X- _ O
88.5 -X- _ O
% -X- _ O
84.56 -X- _ O
94.3 -X- _ O
% -X- _ O
84.02 -X- _ O
90.9 -X- _ O
% -X- _ O
83.04 -X- _ O
91.2 -X- _ O
% -X- _ O
MC.Multimono -X- _ O
85.76 -X- _ O
94.8 -X- _ O
% -X- _ O
84.25 -X- _ O
93.9 -X- _ O
% -X- _ O
84.22 -X- _ O
91.4 -X- _ O
% -X- _ O
82.62 -X- _ O
89.9 -X- _ O
% -X- _ O
multi -X- _ O
87.44 -X- _ O
95.0 -X- _ O
% -X- _ O
86.49 -X- _ O
94.1 -X- _ O
% -X- _ O
86.40 -X- _ O
89.9 -X- _ O
% -X- _ O
85.33 -X- _ O
90.0 -X- _ O
% -X- _ O
MLM -X- _ O
N -X- _ O
/ -X- _ O
A -X- _ O
76.77 -X- _ O
100 -X- _ O
% -X- _ O
73.78 -X- _ O
100 -X- _ O
% -X- _ O
70.85 -X- _ O
100 -X- _ O
% -X- _ O
71.38 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
N -X- _ O
/ -X- _ O
A -X- _ O
77.89 -X- _ O
100 -X- _ O
% -X- _ O
76.07 -X- _ O
100 -X- _ O
% -X- _ O
75.63 -X- _ O
100 -X- _ O
% -X- _ O
74.20 -X- _ O
100 -X- _ O
% -X- _ O
Dutch -X- _ O
Method -X- _ O
BLEU -X- _ O
Sigma -X- _ O
CPL -X- _ O
EOL -X- _ O
EOB -X- _ O
CountChars -X- _ O
100 -X- _ O
63.2 -X- _ O
100 -X- _ O
% -X- _ O
-21.2 -X- _ O
-7.1 -X- _ O
OS.Text -X- _ O
89.5 -X- _ O
64.4 -X- _ O
71.2 -X- _ O
% -X- _ O
-31.4 -X- _ O
-51.3 -X- _ O
MC.Text -X- _ O
61.3 -X- _ O
74.4 -X- _ O
77.8 -X- _ O
% -X- _ O
-23.4 -X- _ O
-9.9 -X- _ O
MC.Multi -X- _ O
99.9 -X- _ O
80.3 -X- _ O
91.4 -X- _ O
% -X- _ O
-27.2 -X- _ O
0.4 -X- _ O
MLM -X- _ O
100 -X- _ O
68.7 -X- _ O
100 -X- _ O
% -X- _ O
+20.4 -X- _ O
-10.0 -X- _ O
MLM+OC -X- _ O
100 -X- _ O
73.9 -X- _ O
100 -X- _ O
% -X- _ O
+21.2 -X- _ O
-10.0 -X- _ O
Spanish -X- _ O
Method -X- _ O
BLEU -X- _ O
Sigma -X- _ O
CPL -X- _ O
EOL -X- _ O
EOB -X- _ O
CountChars -X- _ O
100 -X- _ O
63.2 -X- _ O
100 -X- _ O
% -X- _ O
-24.6 -X- _ O
-4.4 -X- _ O
OS.Text -X- _ O
92.6 -X- _ O
64.1 -X- _ O
71.2 -X- _ O
% -X- _ O
-32.3 -X- _ O
-45.4 -X- _ O
MC.Text -X- _ O
69.6 -X- _ O
75.8 -X- _ O
70.1 -X- _ O
% -X- _ O
-47.6 -X- _ O
-19.3 -X- _ O
MC.Multi -X- _ O
99.6 -X- _ O
78.7 -X- _ O
91.8 -X- _ O
% -X- _ O
-22.4 -X- _ O
4.7 -X- _ O
MLM -X- _ O
100 -X- _ O
73.5 -X- _ O
100 -X- _ O
% -X- _ O
+13.0 -X- _ O
-4.9 -X- _ O
MLM+OC -X- _ O
100 -X- _ O
75.6 -X- _ O
100 -X- _ O
% -X- _ O
+13.4 -X- _ O
-4.6 -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
comparative -X- _ O
results -X- _ O
between -X- _ O
the -X- _ O
selected -X- _ O
unsupervised -X- _ O
methods -X- _ O
and -X- _ O
the -X- _ O
supervised -X- _ O
variants -X- _ O
, -X- _ O
in -X- _ O
languages -X- _ O
where -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
results -X- _ O
were -X- _ O
available -X- _ O
for -X- _ O
the -X- _ O
latter -X- _ O
approaches -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
scenario -X- _ O
, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
Sigma -X- _ B-MetricName
our -X- _ O
approach -X- _ O
obtained -X- _ O
results -X- _ O
on -X- _ O
a -X- _ O
par -X- _ O
with -X- _ O
the -X- _ O
supervised -X- _ O
MC.Text -X- _ B-MethodName
models -X- _ O
trained -X- _ O
on -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
Cinema -X- _ I-DatasetName
data -X- _ O
, -X- _ O
outperformed -X- _ O
the -X- _ O
OS.Text -X- _ B-MethodName
models -X- _ O
trained -X- _ O
on -X- _ O
Open -X- _ O
Subtitles -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
was -X- _ O
surpassed -X- _ O
by -X- _ O
the -X- _ O
MC.Multi -X- _ B-MethodName
model -X- _ O
, -X- _ O
which -X- _ O
exploits -X- _ O
additional -X- _ O
audio -X- _ O
information -X- _ O
, -X- _ O
by -X- _ O
3.1 -X- _ B-MetricValue
and -X- _ O
6.4 -X- _ B-MetricValue
points -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
break -X- _ O
coverage -X- _ O
, -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
our -X- _ O
unsupervised -X- _ O
method -X- _ O
outperformed -X- _ O
the -X- _ O
supervised -X- _ O
variants -X- _ O
, -X- _ O
to -X- _ O
a -X- _ O
significant -X- _ O
degree -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
OS.Text -X- _ B-MethodName
andMC.Text -X- _ B-MethodName
models -X- _ O
. -X- _ O
Regarding -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
without -X- _ O
breaks -X- _ O
, -X- _ O
only -X- _ O
theMC.Multi -X- _ B-MethodName
model -X- _ O
reaches -X- _ O
a -X- _ O
score -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
perfect -X- _ O
one -X- _ O
achieved -X- _ O
by -X- _ O
the -X- _ O
unsupervised -X- _ O
models -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
MC.Text -X- _ B-MethodName
model -X- _ O
is -X- _ O
outperformed -X- _ O
by -X- _ O
38.7 -X- _ B-MetricValue
and -X- _ O
31.4 -X- _ B-MetricValue
points -X- _ O
in -X- _ O
Dutch -X- _ O
and -X- _ O
Spanish -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
the -X- _ O
CPL -X- _ B-MetricName
scores -X- _ O
indicate -X- _ O
that -X- _ O
none -X- _ O
of -X- _ O
the -X- _ O
supervised -X- _ O
approaches -X- _ O
fully -X- _ O
meet -X- _ O
the -X- _ O
length -X- _ O
constraint -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
overflowing -X- _ O
lines -X- _ O
in -X- _ O
8.2 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
cases -X- _ O
at -X- _ O
best -X- _ O
and -X- _ O
29.9 -X- _ O
% -X- _ O
at -X- _ O
worst -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
scenario -X- _ O
as -X- _ O
well -X- _ O
, -X- _ O
the -X- _ O
unsupervised -X- _ O
approaches -X- _ O
fully -X- _ O
meet -X- _ O
the -X- _ O
length -X- _ O
constraint -X- _ O
, -X- _ O
by -X- _ O
design -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
overt -X- _ O
clueing -X- _ O
improved -X- _ O
over -X- _ O
our -X- _ O
core -X- _ O
method -X- _ O
by -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
3.12 -X- _ B-MetricValue
Sigma -X- _ B-MetricName
points -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
some -X- _ O
likely -X- _ O
punctuation -X- _ O
configurations -X- _ O
were -X- _ O
not -X- _ O
properly -X- _ O
captured -X- _ O
by -X- _ O
our -X- _ O
MLM -X- _ O
approximation -X- _ O
. -X- _ O
In -X- _ O
general -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
tends -X- _ O
to -X- _ O
overgenerate -X- _ O
EOL -X- _ O
markers -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
opposite -X- _ O
is -X- _ O
true -X- _ O
for -X- _ O
the -X- _ O
selected -X- _ O
supervised -X- _ O
models -X- _ O
. -X- _ O
Determining -X- _ O
which -X- _ O
of -X- _ O
these -X- _ O
tendencies -X- _ O
leads -X- _ O
to -X- _ O
better -X- _ O
subtitle -X- _ O
readability -X- _ O
would -X- _ O
require -X- _ O
a -X- _ O
specific -X- _ O
human -X- _ O
evaluation -X- _ O
which -X- _ O
we -X- _ O
leave -X- _ O
for -X- _ O
future -X- _ O
research -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
Sigma -X- _ B-MetricName
results -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
supervised -X- _ O
MC.Multi -X- _ B-MethodName
method -X- _ O
show -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
this -X- _ O
approach -X- _ O
to -X- _ O
provide -X- _ O
pretrained -X- _ O
models -X- _ O
applicable -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
, -X- _ O
two -X- _ O
important -X- _ O
aspects -X- _ O
are -X- _ O
worth -X- _ O
considering -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
available -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
results -X- _ O
were -X- _ O
obtained -X- _ O
on -X- _ O
datasets -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
domain -X- _ O
as -X- _ O
the -X- _ O
data -X- _ O
seen -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
supervised -X- _ O
models -X- _ O
. -X- _ O
A -X- _ O
more -X- _ O
complete -X- _ O
assessment -X- _ O
of -X- _ O
the -X- _ O
capabilities -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
in -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
settings -X- _ O
, -X- _ O
which -X- _ O
would -X- _ O
be -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
scenario -X- _ O
consid-774ering -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
across -X- _ O
domains -X- _ O
and -X- _ O
languages -X- _ O
, -X- _ O
would -X- _ O
require -X- _ O
specific -X- _ O
evaluations -X- _ O
in -X- _ O
other -X- _ O
domains -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
although -X- _ O
segmentation -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
aspect -X- _ O
for -X- _ O
subtitle -X- _ O
readability -X- _ O
, -X- _ O
length -X- _ O
conformity -X- _ O
is -X- _ O
an -X- _ O
equally -X- _ O
important -X- _ O
constraint -X- _ O
, -X- _ O
if -X- _ O
not -X- _ O
more -X- _ O
so -X- _ O
considering -X- _ O
that -X- _ O
subtitles -X- _ O
with -X- _ O
lines -X- _ O
over -X- _ O
the -X- _ O
CPL -X- _ O
limit -X- _ O
are -X- _ O
considered -X- _ O
invalid -X- _ O
in -X- _ O
subtitling -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
unsupervised -X- _ O
method -X- _ O
can -X- _ O
thus -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
pragmatic -X- _ O
approach -X- _ O
which -X- _ O
guarantees -X- _ O
valid -X- _ O
subtitles -X- _ O
while -X- _ O
also -X- _ O
providing -X- _ O
quality -X- _ O
segmentation -X- _ O
across -X- _ O
the -X- _ O
board -X- _ O
. -X- _ O
6 -X- _ O
Conclusions -X- _ O
We -X- _ O
described -X- _ O
an -X- _ O
unsupervised -X- _ O
approach -X- _ O
to -X- _ O
subtitle -X- _ O
segmentation -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
pretrained -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
line -X- _ O
or -X- _ O
subtitle -X- _ O
breaks -X- _ O
are -X- _ O
inserted -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
punctuation -X- _ O
occurring -X- _ O
at -X- _ O
candidate -X- _ O
segmentation -X- _ O
points -X- _ O
. -X- _ O
Although -X- _ O
supervised -X- _ O
models -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
indomain -X- _ O
data -X- _ O
with -X- _ O
audio -X- _ O
support -X- _ O
, -X- _ O
were -X- _ O
shown -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
that -X- _ O
this -X- _ O
simple -X- _ O
textual -X- _ O
approach -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
Sigma -X- _ B-MetricName
metric -X- _ O
, -X- _ O
they -X- _ O
tend -X- _ O
to -X- _ O
generate -X- _ O
imperfect -X- _ O
text -X- _ O
to -X- _ O
varying -X- _ O
degrees -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
failing -X- _ O
to -X- _ O
fully -X- _ O
meet -X- _ O
length -X- _ O
constraints -X- _ O
that -X- _ O
are -X- _ O
essential -X- _ O
for -X- _ O
subtitling -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
LM -X- _ O
- -X- _ O
based -X- _ O
textual -X- _ O
approach -X- _ O
outperformed -X- _ O
supervised -X- _ O
models -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
break -X- _ O
generation -X- _ O
coverage -X- _ O
, -X- _ O
while -X- _ O
also -X- _ O
fully -X- _ O
preserving -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
, -X- _ O
complying -X- _ O
with -X- _ O
length -X- _ O
constraints -X- _ O
, -X- _ O
and -X- _ O
obtaining -X- _ O
competitive -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
Sigma -X- _ B-MetricName
. -X- _ O
This -X- _ O
simple -X- _ O
approach -X- _ O
may -X- _ O
thus -X- _ O
provide -X- _ O
a -X- _ O
highly -X- _ O
portable -X- _ O
complementary -X- _ O
solution -X- _ O
for -X- _ O
subtitle -X- _ O
segmentation -X- _ O
across -X- _ O
languages -X- _ O
and -X- _ O
domains -X- _ O
. -X- _ O
7 -X- _ O
Limitations -X- _ O
The -X- _ O
first -X- _ O
clear -X- _ O
limitation -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
its -X- _ O
textbased -X- _ O
nature -X- _ O
. -X- _ O
This -X- _ O
prevents -X- _ O
important -X- _ O
audio -X- _ O
information -X- _ O
, -X- _ O
typically -X- _ O
silences -X- _ O
in -X- _ O
speech -X- _ O
patterns -X- _ O
, -X- _ O
from -X- _ O
being -X- _ O
exploited -X- _ O
to -X- _ O
generate -X- _ O
subtitle -X- _ O
breaks -X- _ O
. -X- _ O
A -X- _ O
more -X- _ O
complete -X- _ O
system -X- _ O
could -X- _ O
be -X- _ O
devised -X- _ O
though -X- _ O
, -X- _ O
for -X- _ O
instance -X- _ O
by -X- _ O
associating -X- _ O
our -X- _ O
text -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
with -X- _ O
the -X- _ O
information -X- _ O
provided -X- _ O
by -X- _ O
a -X- _ O
forced -X- _ O
alignment -X- _ O
toolkit -X- _ O
, -X- _ O
whenever -X- _ O
audio -X- _ O
information -X- _ O
is -X- _ O
available -X- _ O
. -X- _ O
A -X- _ O
simple -X- _ O
method -X- _ O
along -X- _ O
these -X- _ O
lines -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
Apply -X- _ O
our -X- _ O
MLM -X- _ O
- -X- _ O
based -X- _ O
segmentation -X- _ O
but -X- _ O
only -X- _ O
generating -X- _ O
a -X- _ O
unique -X- _ O
segmentation -X- _ O
tag -X- _ O
SEG -X- _ O
; -X- _ O
2 -X- _ O
. -X- _ O
Insert -X- _ O
EOB -X- _ O
markers -X- _ O
wherever -X- _ O
thesilence -X- _ O
between -X- _ O
two -X- _ O
aligned -X- _ O
words -X- _ O
is -X- _ O
above -X- _ O
a -X- _ O
specified -X- _ O
threshold -X- _ O
; -X- _ O
3 -X- _ O
. -X- _ O
Traverse -X- _ O
the -X- _ O
text -X- _ O
sequentially -X- _ O
and -X- _ O
replace -X- _ O
SEG -X- _ O
with -X- _ O
EOL -X- _ O
if -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
previous -X- _ O
marker -X- _ O
of -X- _ O
type -X- _ O
EOB -X- _ O
, -X- _ O
otherwise -X- _ O
replace -X- _ O
with -X- _ O
EOB -X- _ O
. -X- _ O
We -X- _ O
left -X- _ O
this -X- _ O
use -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
in -X- _ O
combination -X- _ O
with -X- _ O
audio -X- _ O
information -X- _ O
for -X- _ O
future -X- _ O
research -X- _ O
, -X- _ O
as -X- _ O
audio -X- _ O
alignment -X- _ O
for -X- _ O
subtitles -X- _ O
typically -X- _ O
involves -X- _ O
additional -X- _ O
factors -X- _ O
such -X- _ O
as -X- _ O
non -X- _ O
- -X- _ O
literal -X- _ O
transcriptions -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
limited -X- _ O
in -X- _ O
its -X- _ O
adaptability -X- _ O
to -X- _ O
specific -X- _ O
segmentation -X- _ O
guidelines -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
company -X- _ O
- -X- _ O
specific -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
adaptable -X- _ O
parameters -X- _ O
of -X- _ O
our -X- _ O
methods -X- _ O
are -X- _ O
the -X- _ O
minimum -X- _ O
and -X- _ O
maximum -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
segmentation -X- _ O
window -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
predefined -X- _ O
punctuation -X- _ O
marks -X- _ O
over -X- _ O
which -X- _ O
masking -X- _ O
is -X- _ O
computed -X- _ O
, -X- _ O
neither -X- _ O
of -X- _ O
which -X- _ O
could -X- _ O
fully -X- _ O
model -X- _ O
idiosyncratic -X- _ O
segmentation -X- _ O
guidelines -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
experience -X- _ O
at -X- _ O
least -X- _ O
, -X- _ O
segmentation -X- _ O
in -X- _ O
real -X- _ O
professional -X- _ O
data -X- _ O
tends -X- _ O
to -X- _ O
display -X- _ O
varying -X- _ O
degrees -X- _ O
of -X- _ O
consistency -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
guidelines -X- _ O
, -X- _ O
and -X- _ O
natural -X- _ O
linguistic -X- _ O
breaks -X- _ O
seem -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
dominant -X- _ O
factor -X- _ O
for -X- _ O
subtitle -X- _ B-TaskName
segmentation -X- _ I-TaskName
. -X- _ O
A -X- _ O
specific -X- _ O
evaluation -X- _ O
would -X- _ O
be -X- _ O
needed -X- _ O
on -X- _ O
data -X- _ O
from -X- _ O
varied -X- _ O
professional -X- _ O
datasets -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
our -X- _ O
method -X- _ O
might -X- _ O
deviate -X- _ O
from -X- _ O
specific -X- _ O
guidelines -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
other -X- _ O
aspects -X- _ O
of -X- _ O
subtitling -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
recommendation -X- _ O
in -X- _ O
some -X- _ O
guidelines -X- _ O
for -X- _ O
subtitles -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
a -X- _ O
pyramidal -X- _ O
view -X- _ O
, -X- _ O
i.e. -X- _ O
with -X- _ O
the -X- _ O
first -X- _ O
line -X- _ O
shorter -X- _ O
than -X- _ O
the -X- _ O
second -X- _ O
line -X- _ O
, -X- _ O
have -X- _ O
not -X- _ O
been -X- _ O
taken -X- _ O
into -X- _ O
consideration -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
aim -X- _ O
was -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
core -X- _ O
LM -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
without -X- _ O
additional -X- _ O
variables -X- _ O
that -X- _ O
can -X- _ O
vary -X- _ O
across -X- _ O
guidelines -X- _ O
and -X- _ O
may -X- _ O
also -X- _ O
have -X- _ O
led -X- _ O
to -X- _ O
results -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
difficult -X- _ O
to -X- _ O
interpret -X- _ O
overall -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
could -X- _ O
nonetheless -X- _ O
be -X- _ O
easily -X- _ O
augmented -X- _ O
with -X- _ O
constraints -X- _ O
on -X- _ O
relative -X- _ O
line -X- _ O
lengths -X- _ O
within -X- _ O
subtitles -X- _ O
, -X- _ O
by -X- _ O
incrementing -X- _ O
the -X- _ O
scores -X- _ O
of -X- _ O
segmentation -X- _ O
candidates -X- _ O
that -X- _ O
respect -X- _ O
this -X- _ O
surface -X- _ O
- -X- _ O
level -X- _ O
constraint -X- _ O
. -X- _ O
8 -X- _ O
Ethical -X- _ O
Considerations -X- _ O
Our -X- _ O
approach -X- _ O
involves -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
large -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
whose -X- _ O
computational -X- _ O
performance -X- _ O
is -X- _ O
typically -X- _ O
higher -X- _ O
when -X- _ O
deployed -X- _ O
in -X- _ O
more -X- _ O
powerful -X- _ O
environments -X- _ O
with -X- _ O
GPUs -X- _ O
. -X- _ O
Under -X- _ O
such -X- _ O
usage -X- _ O
, -X- _ O
electric -X- _ O
consumption -X- _ O
and -X- _ O
associated -X- _ O
carbon -X- _ O
footprint -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
increase -X- _ O
and -X- _ O
users -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
under -X- _ O
these -X- _ O
conditions -X- _ O
should -X- _ O
be -X- _ O
aware -X- _ O
of -X- _ O
this -X- _ O
type -X- _ O
of -X- _ O
impact -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
subtitle -X- _ B-TaskName
segmentation -X- _ I-TaskName
is -X- _ O
often -X- _ O
performed -X- _ O
offline -X- _ O
, -X- _ O
where -X- _ O
efficient -X- _ O
processing -X- _ O
is -X- _ O
less -X- _ O
of -X- _ O
a -X- _ O
concern -X- _ O
, -X- _ O
and -X- _ O
lower -X- _ O
- -X- _ O
cost -X- _ O
CPU -X- _ O
deployments -X- _ O
are -X- _ O
an -X- _ O
entirely -X- _ O
viable -X- _ O
option -X- _ O
. -X- _ O
All -X- _ O
our -X- _ O
results -X- _ O
were -X- _ O
obtained -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
large -X- _ O
LM -X- _ O
de-775ployed -X- _ O
on -X- _ O
CPU -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
aim -X- _ O
of -X- _ O
reducing -X- _ O
energy -X- _ O
consumption -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
requires -X- _ O
no -X- _ O
training -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
hand -X- _ O
and -X- _ O
thus -X- _ O
removes -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
model -X- _ O
training -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
supervised -X- _ O
methods -X- _ O
with -X- _ O
which -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Papi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2022 -X- _ O
) -X- _ O
indicate -X- _ O
that -X- _ O
they -X- _ O
use -X- _ O
four -X- _ O
K80 -X- _ O
GPUs -X- _ O
to -X- _ O
train -X- _ O
their -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
took -X- _ O
as -X- _ O
comparison -X- _ O
points -X- _ O
, -X- _ O
with -X- _ O
1 -X- _ O
day -X- _ O
of -X- _ O
training -X- _ O
for -X- _ O
their -X- _ O
text -X- _ O
- -X- _ O
only -X- _ O
models -X- _ O
and -X- _ O
1 -X- _ O
week -X- _ O
for -X- _ O
their -X- _ O
multimodal -X- _ O
segmenters -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
potential -X- _ O
language -X- _ O
pairs -X- _ O
and -X- _ O
domains -X- _ O
in -X- _ O
need -X- _ O
of -X- _ O
segmented -X- _ O
subtitle -X- _ O
content -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
provide -X- _ O
competitive -X- _ O
results -X- _ O
with -X- _ O
a -X- _ O
comparatively -X- _ O
lesser -X- _ O
impact -X- _ O
on -X- _ O
energy -X- _ O
resource -X- _ O
consumption -X- _ O
. -X- _ O
Acknowledgements -X- _ O
We -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
helpful -X- _ O
comments -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
partially -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Department -X- _ O
of -X- _ O
Economic -X- _ O
Development -X- _ O
and -X- _ O
Competitiveness -X- _ O
of -X- _ O
the -X- _ O
Basque -X- _ O
Government -X- _ O
( -X- _ O
Spri -X- _ O
Group -X- _ O
) -X- _ O
through -X- _ O
funding -X- _ O
for -X- _ O
the -X- _ O
StreAmS -X- _ O
project -X- _ O
( -X- _ O
ZL-2021 -X- _ O
/ -X- _ O
00700 -X- _ O
) -X- _ O
. -X- _ O
References776 -X- _ O
A -X- _ O
Segmentation -X- _ O
Examples -X- _ O
Table -X- _ O
4 -X- _ O
provides -X- _ O
examples -X- _ O
of -X- _ O
subtitles -X- _ O
in -X- _ O
the -X- _ O
MuSTCinema -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
segmented -X- _ O
with -X- _ O
either -X- _ O
the -X- _ O
character -X- _ O
counting -X- _ O
baseline -X- _ O
or -X- _ O
our -X- _ O
LM -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
in -X- _ O
its -X- _ O
insertion -X- _ O
variant -X- _ O
without -X- _ O
resorting -X- _ O
to -X- _ O
overt -X- _ O
punctuation -X- _ O
clueing -X- _ O
. -X- _ O
In -X- _ O
these -X- _ O
examples -X- _ O
, -X- _ O
the -X- _ O
MLM -X- _ O
approach -X- _ O
generates -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
line -X- _ O
and -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
subtitle -X- _ O
breaks -X- _ O
that -X- _ O
are -X- _ O
overall -X- _ O
in -X- _ O
line -X- _ O
with -X- _ O
natural -X- _ O
linguistic -X- _ O
breaks -X- _ O
, -X- _ O
contrary -X- _ O
to -X- _ O
the -X- _ O
character -X- _ O
counting -X- _ O
baseline -X- _ O
. -X- _ O
As -X- _ O
such -X- _ O
, -X- _ O
on -X- _ O
either -X- _ O
short -X- _ O
, -X- _ O
medium -X- _ O
or -X- _ O
longer -X- _ O
input -X- _ O
, -X- _ O
the -X- _ O
readability -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
subtitles -X- _ O
is -X- _ O
significantly -X- _ O
enhanced -X- _ O
with -X- _ O
our -X- _ O
approach -X- _ O
. -X- _ O
B -X- _ O
Extended -X- _ O
Results -X- _ O
The -X- _ O
results -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
were -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
subset -X- _ O
of -X- _ O
languages -X- _ O
and -X- _ O
metrics -X- _ O
for -X- _ O
which -X- _ O
published -X- _ O
comparative -X- _ O
results -X- _ O
were -X- _ O
available -X- _ O
on -X- _ O
the -X- _ O
MuST -X- _ B-DatasetName
- -X- _ I-DatasetName
Cinema -X- _ I-DatasetName
datasets -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
complete -X- _ O
list -X- _ O
of -X- _ O
results -X- _ O
obtained -X- _ O
with -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
and -X- _ O
metrics -X- _ O
. -X- _ O
The -X- _ O
selected -X- _ O
variant -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
the -X- _ O
insertion -X- _ O
masking -X- _ O
approach -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
selected -X- _ O
for -X- _ O
the -X- _ O
main -X- _ O
results -X- _ O
in -X- _ O
our -X- _ O
paper -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
segmentation -X- _ O
window -X- _ O
starting -X- _ O
at -X- _ O
15 -X- _ O
characters -X- _ O
and -X- _ O
ending -X- _ O
at -X- _ O
42 -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
include -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
computed -X- _ O
over -X- _ O
text -X- _ O
that -X- _ O
includes -X- _ O
segmentation -X- _ O
breaks -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
identical -X- _ O
to -X- _ O
those -X- _ O
obtained -X- _ O
with -X- _ O
the -X- _ O
Sigma -X- _ B-MetricName
metric -X- _ O
for -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
generate -X- _ O
imperfect -X- _ O
text -X- _ O
. -X- _ O
Across -X- _ O
languages -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
relatively -X- _ O
uniform -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
Sigma -X- _ B-MetricName
scores -X- _ O
obtained -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
the -X- _ O
lowest -X- _ O
in -X- _ O
Dutch -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
difference -X- _ O
of -X- _ O
4.1 -X- _ B-MetricValue
points -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
break -X- _ O
coverage -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
were -X- _ O
obtained -X- _ O
for -X- _ O
Spanish -X- _ O
and -X- _ O
the -X- _ O
worst -X- _ O
for -X- _ O
Romanian -X- _ O
, -X- _ O
although -X- _ O
results -X- _ O
were -X- _ O
also -X- _ O
relatively -X- _ O
uniform -X- _ O
across -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
overt -X- _ O
clueing -X- _ O
, -X- _ O
where -X- _ O
overt -X- _ O
punctuation -X- _ O
marks -X- _ O
raised -X- _ O
the -X- _ O
LM -X- _ O
score -X- _ O
by -X- _ O
1 -X- _ B-MetricValue
, -X- _ O
improved -X- _ O
Sigma -X- _ B-MetricName
scores -X- _ O
, -X- _ O
although -X- _ O
it -X- _ O
had -X- _ O
less -X- _ O
of -X- _ O
an -X- _ O
impact -X- _ O
on -X- _ O
break -X- _ O
coverage -X- _ O
results -X- _ O
, -X- _ O
where -X- _ O
both -X- _ O
variants -X- _ O
performed -X- _ O
similarly -X- _ O
overall -X- _ O
. -X- _ O
CResults -X- _ O
With -X- _ O
Different -X- _ O
minParameters -X- _ O
As -X- _ O
noted -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
considering -X- _ O
preliminary -X- _ O
results -X- _ O
over -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
we -X- _ O
selected -X- _ O
a -X- _ O
default -X- _ O
value -X- _ O
of -X- _ O
15 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
minparameter -X- _ B-HyperparameterName
, -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
after -X- _ O
which -X- _ O
the -X- _ O
segmentation -X- _ O
process -X- _ O
applies -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
comparative -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
with -X- _ O
different -X- _ O
min -X- _ O
values -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
Sigma -X- _ B-MetricName
, -X- _ O
values -X- _ O
of -X- _ O
15 -X- _ B-HyperparameterValue
and -X- _ O
20 -X- _ B-HyperparameterValue
led -X- _ O
to -X- _ O
rather -X- _ O
similar -X- _ O
results -X- _ O
; -X- _ O
values -X- _ O
of -X- _ O
1 -X- _ B-HyperparameterValue
and -X- _ O
10 -X- _ B-HyperparameterValue
resulted -X- _ O
in -X- _ O
slightly -X- _ O
lower -X- _ O
results -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
results -X- _ O
achieved -X- _ O
with -X- _ O
the -X- _ O
former -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
coverage -X- _ O
, -X- _ O
the -X- _ O
former -X- _ O
increases -X- _ O
with -X- _ O
larger -X- _ O
minvalues -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
expected -X- _ O
given -X- _ O
the -X- _ O
more -X- _ O
restricted -X- _ O
space -X- _ O
to -X- _ O
insert -X- _ O
these -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
line -X- _ O
markers -X- _ O
as -X- _ O
the -X- _ O
value -X- _ O
increases -X- _ O
; -X- _ O
for -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
, -X- _ O
the -X- _ O
restricted -X- _ O
insertion -X- _ O
space -X- _ O
results -X- _ O
in -X- _ O
increased -X- _ O
under -X- _ O
- -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
turn -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
scores -X- _ O
for -X- _ O
lower -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
minparameter.777CountChars -X- _ O
MLM -X- _ O
They -X- _ O
’re -X- _ O
things -X- _ O
you -X- _ O
access -X- _ O
through -X- _ O
your -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
They -X- _ O
’re -X- _ O
things -X- _ O
you -X- _ O
access -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
computer -X- _ O
. -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
through -X- _ O
your -X- _ O
computer -X- _ O
. -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
Every -X- _ O
row -X- _ O
of -X- _ O
data -X- _ O
is -X- _ O
a -X- _ O
life -X- _ O
whose -X- _ O
story -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
Every -X- _ O
row -X- _ O
of -X- _ O
data -X- _ O
is -X- _ O
a -X- _ O
life -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
deserves -X- _ O
to -X- _ O
be -X- _ O
told -X- _ O
with -X- _ O
dignity -X- _ O
. -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
whose -X- _ O
story -X- _ O
deserves -X- _ O
to -X- _ O
be -X- _ O
told -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
with -X- _ O
dignity -X- _ O
. -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
During -X- _ O
the -X- _ O
winter -X- _ O
, -X- _ O
struggling -X- _ O
to -X- _ O
get -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
During -X- _ O
the -X- _ O
winter -X- _ O
, -X- _ O
struggling -X- _ O
to -X- _ O
get -X- _ O
warm -X- _ O
, -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
warm -X- _ O
, -X- _ O
my -X- _ O
neighbors -X- _ O
would -X- _ O
have -X- _ O
no -X- _ O
choice -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
my -X- _ O
neighbors -X- _ O
would -X- _ O
have -X- _ O
no -X- _ O
choice -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
but -X- _ O
to -X- _ O
bypass -X- _ O
the -X- _ O
meter -X- _ O
after -X- _ O
their -X- _ O
heat -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
but -X- _ O
to -X- _ O
bypass -X- _ O
the -X- _ O
meter -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
was -X- _ O
shut -X- _ O
off -X- _ O
, -X- _ O
just -X- _ O
to -X- _ O
keep -X- _ O
their -X- _ O
family -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
after -X- _ O
their -X- _ O
heat -X- _ O
was -X- _ O
shut -X- _ O
off -X- _ O
, -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
comfortable -X- _ O
for -X- _ O
one -X- _ O
more -X- _ O
day -X- _ O
. -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
just -X- _ O
to -X- _ O
keep -X- _ O
their -X- _ O
family -X- _ O
comfortable -X- _ O
< -X- _ O
eol -X- _ O
> -X- _ O
for -X- _ O
one -X- _ O
more -X- _ O
day -X- _ O
. -X- _ O
< -X- _ O
eob -X- _ O
> -X- _ O
Language -X- _ O
Method -X- _ O
BLEU -X- _ O
Sigma -X- _ O
EOL -X- _ O
EOB -X- _ O
CPL -X- _ O
DEMLM -X- _ O
100 -X- _ O
70.85 -X- _ O
18.53 -X- _ O
-7.96 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
75.63 -X- _ O
19.81 -X- _ O
-7.78 -X- _ O
100 -X- _ O
% -X- _ O
ENMLM -X- _ O
100 -X- _ O
76.77 -X- _ O
19.18 -X- _ O
-9.91 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
77.89 -X- _ O
19.86 -X- _ O
-9.73 -X- _ O
100 -X- _ O
% -X- _ O
ESMLM -X- _ O
100 -X- _ O
73.47 -X- _ O
12.98 -X- _ O
-4.91 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
75.59 -X- _ O
13.45 -X- _ O
-4.63 -X- _ O
100 -X- _ O
% -X- _ O
FRMLM -X- _ O
100 -X- _ O
73.78 -X- _ O
16.51 -X- _ O
-6.58 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
76.07 -X- _ O
17.47 -X- _ O
-6.12 -X- _ O
100 -X- _ O
% -X- _ O
ITMLM -X- _ O
100 -X- _ O
71.38 -X- _ O
18.49 -X- _ O
-9.55 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
74.20 -X- _ O
20.34 -X- _ O
-8.57 -X- _ O
100 -X- _ O
% -X- _ O
NLMLM -X- _ O
100 -X- _ O
68.71 -X- _ O
20.37 -X- _ O
-9.96 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
73.88 -X- _ O
21.22 -X- _ O
-9.96 -X- _ O
100 -X- _ O
% -X- _ O
PTMLM -X- _ O
100 -X- _ O
71.59 -X- _ O
20.03 -X- _ O
-10.81 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
75.50 -X- _ O
19.87 -X- _ O
-10.02 -X- _ O
100 -X- _ O
% -X- _ O
ROMLM -X- _ O
100 -X- _ O
69.45 -X- _ O
23.37 -X- _ O
-10.44 -X- _ O
100 -X- _ O
% -X- _ O
MLM+OC -X- _ O
100 -X- _ O
74.13 -X- _ O
23.37 -X- _ O
-10.09 -X- _ O
100 -X- _ O
% -X- _ O
778Language -X- _ O
min -X- _ O
BLEU -X- _ O
Sigma -X- _ O
EOL -X- _ O
EOB -X- _ O
DE1 -X- _ O
100 -X- _ O
72.31 -X- _ O
28.75 -X- _ O
-0.18 -X- _ O
10 -X- _ O
100 -X- _ O
73.96 -X- _ O
22.68 -X- _ O
-4.43 -X- _ O
15 -X- _ O
100 -X- _ O
75.63 -X- _ O
19.81 -X- _ O
-7.78 -X- _ O
20 -X- _ O
100 -X- _ O
75.28 -X- _ O
14.54 -X- _ O
-11.21 -X- _ O
EN1 -X- _ O
100 -X- _ O
74.30 -X- _ O
37.33 -X- _ O
-0.98 -X- _ O
10 -X- _ O
100 -X- _ O
77.14 -X- _ O
24.49 -X- _ O
-7.77 -X- _ O
15 -X- _ O
100 -X- _ O
77.89 -X- _ O
19.86 -X- _ O
-9.73 -X- _ O
20 -X- _ O
100 -X- _ O
77.16 -X- _ O
15.24 -X- _ O
-12.68 -X- _ O
ES1 -X- _ O
100 -X- _ O
73.00 -X- _ O
20.87 -X- _ O
0.28 -X- _ O
10 -X- _ O
100 -X- _ O
74.32 -X- _ O
18.24 -X- _ O
-2.04 -X- _ O
15 -X- _ O
100 -X- _ O
75.59 -X- _ O
13.45 -X- _ O
-4.63 -X- _ O
20 -X- _ O
100 -X- _ O
75.83 -X- _ O
8.66 -X- _ O
-7.87 -X- _ O
FR1 -X- _ O
100 -X- _ O
73.89 -X- _ O
24.68 -X- _ O
-0.73 -X- _ O
10 -X- _ O
100 -X- _ O
75.26 -X- _ O
20.83 -X- _ O
-3.93 -X- _ O
15 -X- _ O
100 -X- _ O
76.07 -X- _ O
17.47 -X- _ O
-6.12 -X- _ O
20 -X- _ O
100 -X- _ O
76.75 -X- _ O
12.5 -X- _ O
-10.05 -X- _ O
IT1 -X- _ O
100 -X- _ O
72.01 -X- _ O
29.75 -X- _ O
-3.66 -X- _ O
10 -X- _ O
100 -X- _ O
73.75 -X- _ O
24.71 -X- _ O
-6.61 -X- _ O
15 -X- _ O
100 -X- _ O
74.20 -X- _ O
20.34 -X- _ O
-8.57 -X- _ O
20 -X- _ O
100 -X- _ O
73.66 -X- _ O
14.62 -X- _ O
-11.61 -X- _ O
NL1 -X- _ O
100 -X- _ O
72.16 -X- _ O
26.83 -X- _ O
-5.47 -X- _ O
10 -X- _ O
100 -X- _ O
73.56 -X- _ O
23.26 -X- _ O
-8.47 -X- _ O
15 -X- _ O
100 -X- _ O
73.88 -X- _ O
21.22 -X- _ O
-9.96 -X- _ O
20 -X- _ O
100 -X- _ O
74.40 -X- _ O
16.81 -X- _ O
-12.43 -X- _ O
PT1 -X- _ O
100 -X- _ O
72.87 -X- _ O
26.38 -X- _ O
-6.24 -X- _ O
10 -X- _ O
100 -X- _ O
74.53 -X- _ O
22.15 -X- _ O
-8.08 -X- _ O
15 -X- _ O
100 -X- _ O
75.50 -X- _ O
19.87 -X- _ O
-10.02 -X- _ O
20 -X- _ O
100 -X- _ O
74.98 -X- _ O
14.17 -X- _ O
-13.36 -X- _ O
RO1 -X- _ O
100 -X- _ O
72.05 -X- _ O
32.3 -X- _ O
-4.51 -X- _ O
10 -X- _ O
100 -X- _ O
73.76 -X- _ O
26.98 -X- _ O
-7.52 -X- _ O
15 -X- _ O
100 -X- _ O
74.13 -X- _ O
23.37 -X- _ O
-10.09 -X- _ O
20 -X- _ O
100 -X- _ O
74.89 -X- _ O
17.53 -X- _ O
-12.83779ACL -X- _ O
2023 -X- _ O
Responsible -X- _ O
NLP -X- _ O
Checklist -X- _ O
A -X- _ O
For -X- _ O
every -X- _ O
submission -X- _ O
: -X- _ O
/ -X- _ O
squareA1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
describe -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
7 -X- _ O
/ -X- _ O
squareA2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
any -X- _ O
potential -X- _ O
risks -X- _ O
of -X- _ O
your -X- _ O
work -X- _ O
? -X- _ O
8 -X- _ O
/ -X- _ O
squareA3 -X- _ O
. -X- _ O
Do -X- _ O
the -X- _ O
abstract -X- _ O
and -X- _ O
introduction -X- _ O
summarize -X- _ O
the -X- _ O
paper -X- _ O
’s -X- _ O
main -X- _ O
claims -X- _ O
? -X- _ O
1 -X- _ O
/ -X- _ O
squareA4 -X- _ O
. -X- _ O
Have -X- _ O
you -X- _ O
used -X- _ O
AI -X- _ O
writing -X- _ O
assistants -X- _ O
when -X- _ O
working -X- _ O
on -X- _ O
this -X- _ O
paper -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
B -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
or -X- _ O
create -X- _ O
scientiﬁc -X- _ O
artifacts -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
cite -X- _ O
the -X- _ O
creators -X- _ O
of -X- _ O
artifacts -X- _ O
you -X- _ O
used -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
license -X- _ O
or -X- _ O
terms -X- _ O
for -X- _ O
use -X- _ O
and -X- _ O
/ -X- _ O
or -X- _ O
distribution -X- _ O
of -X- _ O
any -X- _ O
artifacts -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
if -X- _ O
your -X- _ O
use -X- _ O
of -X- _ O
existing -X- _ O
artifact -X- _ O
( -X- _ O
s -X- _ O
) -X- _ O
was -X- _ O
consistent -X- _ O
with -X- _ O
their -X- _ O
intended -X- _ O
use -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
it -X- _ O
was -X- _ O
speciﬁed -X- _ O
? -X- _ O
For -X- _ O
the -X- _ O
artifacts -X- _ O
you -X- _ O
create -X- _ O
, -X- _ O
do -X- _ O
you -X- _ O
specify -X- _ O
intended -X- _ O
use -X- _ O
and -X- _ O
whether -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
access -X- _ O
conditions -X- _ O
( -X- _ O
in -X- _ O
particular -X- _ O
, -X- _ O
derivatives -X- _ O
of -X- _ O
data -X- _ O
accessed -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
outside -X- _ O
of -X- _ O
research -X- _ O
contexts -X- _ O
) -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB4 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
was -X- _ O
collected -X- _ O
/ -X- _ O
used -X- _ O
contains -X- _ O
any -X- _ O
information -X- _ O
that -X- _ O
names -X- _ O
or -X- _ O
uniquely -X- _ O
identiﬁes -X- _ O
individual -X- _ O
people -X- _ O
or -X- _ O
offensive -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
steps -X- _ O
taken -X- _ O
to -X- _ O
protect -X- _ O
/ -X- _ O
anonymize -X- _ O
it -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
provide -X- _ O
documentation -X- _ O
of -X- _ O
the -X- _ O
artifacts -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
coverage -X- _ O
of -X- _ O
domains -X- _ O
, -X- _ O
languages -X- _ O
, -X- _ O
and -X- _ O
linguistic -X- _ O
phenomena -X- _ O
, -X- _ O
demographic -X- _ O
groups -X- _ O
represented -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareB6 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
relevant -X- _ O
statistics -X- _ O
like -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
, -X- _ O
details -X- _ O
of -X- _ O
train -X- _ O
/ -X- _ O
test -X- _ O
/ -X- _ O
dev -X- _ O
splits -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
for -X- _ O
the -X- _ O
data -X- _ O
that -X- _ O
you -X- _ O
used -X- _ O
/ -X- _ O
created -X- _ O
? -X- _ O
Even -X- _ O
for -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
include -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
train -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
, -X- _ O
as -X- _ O
these -X- _ O
provide -X- _ O
necessary -X- _ O
context -X- _ O
for -X- _ O
a -X- _ O
reader -X- _ O
to -X- _ O
understand -X- _ O
experimental -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
small -X- _ O
differences -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
large -X- _ O
test -X- _ O
sets -X- _ O
may -X- _ O
be -X- _ O
signiﬁcant -X- _ O
, -X- _ O
while -X- _ O
on -X- _ O
small -X- _ O
test -X- _ O
sets -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
. -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
C -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
run -X- _ O
computational -X- _ O
experiments -X- _ O
? -X- _ O
3 -X- _ O
/ -X- _ O
squareC1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
models -X- _ O
used -X- _ O
, -X- _ O
the -X- _ O
total -X- _ O
computational -X- _ O
budget -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
GPU -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
infrastructure -X- _ O
used -X- _ O
? -X- _ O
We -X- _ O
did -X- _ O
n’t -X- _ O
trained -X- _ O
any -X- _ O
models -X- _ O
for -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
and -X- _ O
inference -X- _ O
was -X- _ O
performed -X- _ O
on -X- _ O
CPU.780 -X- _ O
/ -X- _ O
squareC2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
, -X- _ O
including -X- _ O
hyperparameter -X- _ O
search -X- _ O
and -X- _ O
best -X- _ O
- -X- _ O
found -X- _ O
hyperparameter -X- _ O
values -X- _ O
? -X- _ O
3 -X- _ O
/ -X- _ O
squareC3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
descriptive -X- _ O
statistics -X- _ O
about -X- _ O
your -X- _ O
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
error -X- _ O
bars -X- _ O
around -X- _ O
results -X- _ O
, -X- _ O
summary -X- _ O
statistics -X- _ O
from -X- _ O
sets -X- _ O
of -X- _ O
experiments -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
it -X- _ O
transparent -X- _ O
whether -X- _ O
you -X- _ O
are -X- _ O
reporting -X- _ O
the -X- _ O
max -X- _ O
, -X- _ O
mean -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
or -X- _ O
just -X- _ O
a -X- _ O
single -X- _ O
run -X- _ O
? -X- _ O
5 -X- _ O
/ -X- _ O
squareC4 -X- _ O
. -X- _ O
If -X- _ O
you -X- _ O
used -X- _ O
existing -X- _ O
packages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
preprocessing -X- _ O
, -X- _ O
for -X- _ O
normalization -X- _ O
, -X- _ O
or -X- _ O
for -X- _ O
evaluation -X- _ O
) -X- _ O
, -X- _ O
did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
implementation -X- _ O
, -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
parameter -X- _ O
settings -X- _ O
used -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
NLTK -X- _ O
, -X- _ O
Spacy -X- _ O
, -X- _ O
ROUGE -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
? -X- _ O
3 -X- _ O
D -X- _ O
/ -X- _ O
squareDid -X- _ O
you -X- _ O
use -X- _ O
human -X- _ O
annotators -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdworkers -X- _ O
) -X- _ O
or -X- _ O
research -X- _ O
with -X- _ O
human -X- _ O
participants -X- _ O
? -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD1 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
full -X- _ O
text -X- _ O
of -X- _ O
instructions -X- _ O
given -X- _ O
to -X- _ O
participants -X- _ O
, -X- _ O
including -X- _ O
e.g. -X- _ O
, -X- _ O
screenshots -X- _ O
, -X- _ O
disclaimers -X- _ O
of -X- _ O
any -X- _ O
risks -X- _ O
to -X- _ O
participants -X- _ O
or -X- _ O
annotators -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD2 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
information -X- _ O
about -X- _ O
how -X- _ O
you -X- _ O
recruited -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
crowdsourcing -X- _ O
platform -X- _ O
, -X- _ O
students -X- _ O
) -X- _ O
and -X- _ O
paid -X- _ O
participants -X- _ O
, -X- _ O
and -X- _ O
discuss -X- _ O
if -X- _ O
such -X- _ O
payment -X- _ O
is -X- _ O
adequate -X- _ O
given -X- _ O
the -X- _ O
participants -X- _ O
’ -X- _ O
demographic -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
country -X- _ O
of -X- _ O
residence -X- _ O
) -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD3 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
discuss -X- _ O
whether -X- _ O
and -X- _ O
how -X- _ O
consent -X- _ O
was -X- _ O
obtained -X- _ O
from -X- _ O
people -X- _ O
whose -X- _ O
data -X- _ O
you -X- _ O
’re -X- _ O
using -X- _ O
/ -X- _ O
curating -X- _ O
? -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
you -X- _ O
collected -X- _ O
data -X- _ O
via -X- _ O
crowdsourcing -X- _ O
, -X- _ O
did -X- _ O
your -X- _ O
instructions -X- _ O
to -X- _ O
crowdworkers -X- _ O
explain -X- _ O
how -X- _ O
the -X- _ O
data -X- _ O
would -X- _ O
be -X- _ O
used -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD4 -X- _ O
. -X- _ O
Was -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
protocol -X- _ O
approved -X- _ O
( -X- _ O
or -X- _ O
determined -X- _ O
exempt -X- _ O
) -X- _ O
by -X- _ O
an -X- _ O
ethics -X- _ O
review -X- _ O
board -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank -X- _ O
. -X- _ O
/ -X- _ O
squareD5 -X- _ O
. -X- _ O
Did -X- _ O
you -X- _ O
report -X- _ O
the -X- _ O
basic -X- _ O
demographic -X- _ O
and -X- _ O
geographic -X- _ O
characteristics -X- _ O
of -X- _ O
the -X- _ O
annotator -X- _ O
population -X- _ O
that -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
? -X- _ O
Not -X- _ O
applicable -X- _ O
. -X- _ O
Left -X- _ O
blank.781 -X- _ O

