  Yi Chen , Jiayang Cheng , Haiyun Jiang , Lemao Liu   Haisong Zhang , Shuming Shi , Ruifeng XuSchool of Computer Science and Technology ,   Harbin Institute of Technology , Shenzhen , ChinaDepartment of Computer Science and Engineering , HKUSTJoint Lab of HITSZ and China Merchants Securities , Shenzhen , ChinaPeng Cheng Laboratory , Shenzhen , China   yichennlp@gmail.com,jchengaj@cse.ust.hk   xuruifeng@hit.edu.cn   Abstract   In this paper , we ﬁrstly empirically ﬁnd that   existing models struggle to handle hard men-   tions due to their insufﬁcient contexts , which   consequently limits their overall typing perfor-   mance . To this end , we propose to exploit sib-   ling mentions for enhancing the mention rep-   resentations . Speciﬁcally , we present two dif-   ferent metrics for sibling selection and employ   an attentive graph neural network to aggre-   gate information from sibling mentions . The   proposed graph model is scalable in that un-   seen test mentions are allowed to be added as   new nodes for inference . Exhaustive experi-   ments demonstrate the effectiveness of our sib-   ling learning strategy , where our model outper-   forms ten strong baselines . Moreover , our ex-   periments indeed prove the superiority of sib-   ling mentions in helping clarify the types for   hard mentions .   1 Introduction   Fine - Grained Entity Typing ( FGET ) aims to as-   sign one or more ﬁne - grained types to an entity   mention given its context . For instance , the men-   tionSteve Jobs should be classiﬁed as Person and   Entrepreneur under the context “ Steve Jobs co-   founded Apple ... ” . Many tasks have witnessed   the importance of FGET , such as relation extrac-   tion ( Jiang et al . , 2020b ; Chu et al . , 2020 ; Jiang   et al . , 2020a ; Cheng et al . , 2021 ) , entity linking   ( Onoe and Durrett , 2020 ) , and other tasks ( Jiang   et al . , 2020c ; Zhang et al . , 2020b ; Liu et al . , 2021b ) .   It is challenging to learn effective representa-   tions for contextualized mentionsin many infor-   mation extraction tasks ( Gao et al . , 2022 ) , espe - cially in FGET , since the representations are re-   quired to well distinguish ﬁne - grained types with   similar but different semantics . Noticeable efforts   have been made to learn type - aware representa-   tions for mentions ( Ren et al . , 2016 ; Xin et al . ,   2018 ; Choi et al . , 2018 ; Zhang et al . , 2018 ; Lin and   Ji , 2019 ; Abhishek et al . , 2017 ; Xu and Barbosa ,   2018 ; Ali et al . , 2020 ; Chen et al . , 2021 ) and sig-   niﬁcant progress has been achieved . However , as   supported by our empirical experiments , existing   SOTA models perform poorly on a certain num-   ber of “ hard ” mentions , leading to limited overall   performance . The main reasons are the following   challenges . First , the structure of some contexts   surrounding the hard mentions are inherently too   complex to extract informative features for identi-   fying entity types . Second , the contexts of some   hard mentions are ambiguous and thus it is insuf-   ﬁcient to handle these mentions by learning from   their contexts only .   In this paper , we show that representation learn-   ing of such hard mentions can be well handled by   learning informative knowledge from their sibling   mentions . Sibling mentions refer to the mentions   thatpotentially share the same or semantically sim-   ilar types ( e.g. , country andnation ) with the target   mention . We illustrate how sibling mentions assist   classifying hard mentions in Figure 1 . Intuitively ,   the context of the target mention Sharp is ambigu-   ous and insufﬁcient for inferring the ground - truth   types ( i.e. , organization , company , and tech com-   pany ) , since both a person and a company can “ sign   a deal with Qualcomm ” . Fortunately , the sibling   mentions provide rich information that works as   an important supplement for the target mention   Sharp . By aggregating the supplementary informa-   tion from siblings , it is promising to learn effective   representations with less ambiguity for hard target   mentions.2076   To utilize sibling mentions , we model FGET as a   heterogeneous graph learning problem . The graph   is composed of two kinds of nodes , namely the   mentions and the types . Besides , there are three   kinds of edges connecting the nodes as shown in   the left part of Figure 1 , which represent the sibling   relationship between mentions , the hierarchical   relationship between types , and the isLabel rela-   tionship between mentions and types , respectively .   The sibling relationship is considered as the most   important part in our graph . For detecting it , we   propose two similarity metrics , based on which   we design an effective sibling selection algorithm .   Upon the constructed nodes and edges , we employ   an attentive graph neural module to learn their rep-   resentations . Particularly , the representations of   mention nodes are enriched by aggregating the in-   formation from their sibling and type neighbors .   It is also noteworthy that , during inference stage ,   our graph model is scalable to include the unseen   test mentions as new nodes and connect them with   their existing sibling mention nodes in the graph to   derive reliable representations for predictions .   Extensive experiments are conducted to verify   the effectiveness of our model . Our experimental   results demonstrate that our model outperforms   several strong baselines on the standard test sets   with a large margin . Moreover , our model is indeed   able to well handle hard mentions with the help   from sibling mentions .   We summarize our contributions as follows :   •We are the ﬁrst to point out a bottleneck issue   suffered by existing SOTA models , i.e. , they   perform poorly on a certain number of hard   mentions , and we quantitatively analyze its   inﬂuence on typing accuracy via measuring   hard mentions by entropy .   •We are the ﬁrst to exploit sibling information   for mention representation learning in FGET.We design two effective metrics for sibling   detection and propose a scalable graph model   to take advantages of sibling mentions .   2 Methodology Overview   Given a mention mand the type setY , an FGET   model needs to predict the correct types Y(Y   Y ) formbased on its context .   In this paper , mention representations are learned   and reﬁned with the help of sibling mentions and   ground - truth types . To achieve it , we propose a   heterogeneous graph model enhanced by sibling   mentions for FGET , as illustrated in Figure 1 . First ,   a mention - type graph Gis constructed from training   samples ( Sec 3 ) . Then , the features for mentions   and types are learned by an attentive graph neural   module uponG(Sec 4 ) .   During inference stage ( Sec 5 ) , we add test men-   tions into graphGby connecting them to their sib-   ling mentions in the training set . By aggregating   sibling information , the representations of test men-   tions are generated and used for type prediction .   3 Graph Construction   3.1 Graph Deﬁnition   Consider graphG= ( V;V;E;E;E ) ,   whereVandVare the set of mention nodes and   type nodes , respectively . Eis the set of edges   between the target mentions and their sibling men-   tions , whileEis the set of edges between types .   Edenotes the edges connecting the target men-   tions and the ground - truth types . E , EandE   are obtained as follows :   E = f(m;m)jm;m2V ;   isSib ( m;m ) = 1g(1 )   E = f(y;y)jy;y2V;isA(y;y ) = 1g(2)2077E = f(m;y)jm2V ; y2V ;   isLabel ( m;y ) = 1g(3 )   whereisA(y;y ) = 1 indicatesyis the parent   or child type of yin the type hierarchy , and   isLabel ( m;y ) = 1 means mention mis labeled   with the type yin the training set . Since type   hierarchy and the ground - truth types of mentions   are available in the training set , V , V , Eand   Ecan be easily derived . isSib ( m;m ) = 1   meansmis the sibling mention of m , which will   be discussed in Sec 3.2 .   3.2 Sibling Selection   The key to construct Eis to deﬁneisSib ( m;m ) ,   i.e. , the criterion for judging whether mis the   sibling ofm . We design two metrics to detect   the sibling relationships between mentions , named   ( unsupervised ) word distribution - based and ( super-   vised ) typing distribution - based metrics .   Word distribution - based metric The basic as-   sumption for this metric is that mentions sharing   more contextual words tend to have more similar   ground - truth types . We use TF - IDF to encode men-   tions as sparse feature vectors . Then the sibling   similarity between any two mentions is measured   by the cosine similarity of their vectors .   Typing distribution - based metric In this met-   ric , we ﬁrst derive the prior score distributions over   the type setYfor all the mentions in the dataset   from an extra base model ( Lin and Ji , 2019 ) trained   on the same dataset . Then the sibling mentions are   selected by their cosine similarities to the target   mention based on the score distributions .   Sibling mention selection Given one of the met-   rics above , we obtain the sibling mentions accord-   ing to Algorithm 1 . Note that for each target men-   tionm2V , we ﬁrst select a subset Vfrom   Vand only calculate the similarities between m   and the mentions m2V. The contexts of men-   tions fromVshare at least one word with that   of the target mention and jVj  jVj , which   greatly reduces time complexity . Then , based on   the similarity scores , we choose the top - K most   similar mentionsV as the siblings for mand   letisSib ( m;m ) = 1 for eachm2V. Be   aware that , by deﬁnition , the sibling relationship is   directed , i.e. , isSib ( m;m ) = 1 does not ensure   isSib ( m;m ) = 1 holds . Algorithm 1 : Sibling mention selection   Input : the set of mention nodes Vform;m2VdoisSib ( m;m ) 0endform2Vdo.select a candidate set VfromV form2Vdo.compute similarity sim(m;m ) end.select the top- Ksimilar mentions   V fromV form2V doisSib ( m;m ) 1 endend   4 Graph - based Typing Model   4.1 Attentive Graph Neural Module   We employs graph neural networks ( GNNs ) with L   layers ( Velickovic et al . , 2018 ; Xu et al . , 2019 ) to   aggregate the information of sibling mentions and   types for learning mention representations . At the   ﬁrst layer ofG , the embedding of each type y2Y   ( denoted by y2R ) is randomly initialized . In   contrast , to capture the rich features from contexts ,   the initial embeddings for mentions are derived by   a parameterized mention encoder g( ) , i.e. ,m=   g(m;)2R(details in Sec 4.2 ) . Given the   initial mention and type embeddings ( i.e. , mand   y ) , the graph module iteratively updates them to   obtain m andy .   Update of y In thel - th ( l= 1;:::;L 1 )   layer , the updating formula for type embedding   y2Ris :   y = f X  f(y ) + f(y ) !   ;   ( 4 )   wherefandfare linear layers with ReLU activa-   tion . Ydenotes the type neighbors for yin graph   G , which are the parent or child types of yin the   type hierarchy .  is the attention weight from   typeytoydeﬁned as   =(       yWy   ; yis a child type ;       yWy   ; yis a parent type ;   ( 5)2078W2Ris the weight matrix to model the   parent - child relationship . Note that Eq . ( 4)does not   involve mention embeddings and only focuses on   learning the hierarchical structure of types . The   interaction between types and mentions will be   modeled by Eq . ( 6)during the update process of   mention embeddings .   Update of m The updating formula for the   mention embedding m2Ris :   whereMandYare the sibling and type   neighborsofmin graphG.andare   the attention weights from mto mentionmand   typeyin thel - th layer , respectively . Speciﬁcally ,   =    mWm   ;   =    mWy   ; ( 7 )   W;W2Rare learnable parameters .   f , f , fare linear layers with ReLU activation .   Here , we use the attention mechanism to distin-   guish informative neighbors . Besides , the update   process of target mentions involves both the sibling   and type neighbors , whose representations are also   updated at the same . In this way , the learned rep-   resentations for both mentions and types are more   consistent and thus more reliable for prediction .   4.2 Mention Encoder g(m; )   The mention encoder uses the backbone from Lin   and Ji ( 2019 ) . Given a mention , we ﬁrst encode the   mention span and the surrounding context as the   weighted sum of their ELMo ( Peters et al . , 2018 )   word representations respectively . Then , the uni-   ﬁed feature vector for the mention is derived by   concatenating both representations .   4.3 Type Prediction   Given a mention m , the predicted score distribu-   tionp2Rover the type setYis computed as :   p=    YWm+Wm   ; ( 8)   where Y = h   y;y;:::;yi   2R ,   yandmare the type and mention embed-   dings in theL - th layer in GNN . W2RandW2Rare learnable parameters . p[k ]   ( thek - th element in p ) denotes the predicted prob-   ability for type y.   4.4 Loss Function   The loss over mis computed as :   ` =  X    logp[k]+(1  ) log(1 p[k])   ( 9 )   where2 f0;1gindicates whether yis the   ground - truth type of min the training set . The   overall loss is the average over all the mentions ,   i.e. ,L = P ` .   4.5 Dropout ofY   The representation mincorporates the infor-   mation from ground - truth type neighbors ( Eq . ( 6 ) ) .   However , it is then used for predicting the ground-   truth types in turn ( Eq . ( 8) ) . The setting that Y   contains allthe ground - truth types will inevitably   degenerate the model to just focus on the type   neighbors while totally ignore the mention neigh-   bors . To overcome this , each neighboring type in   Yis randomly discarded with a certain proba-   bility   . In this way , the prediction of discarded   type will force the model to learn from the sibling   mentions rather than directly from type neighbors .   5 Scalable Testing   In the following , we describe the prediction process   for test mentions .   Step 1 : Given a batch of ntest mentions , we   ﬁrst obtain their sibling mentions . To be speciﬁc ,   for each test mention m , we select a candidate   setVfrom the training mentions V. Then , the   cosine similarity is computed between mand each   minV , based on which the top Kmentions are   selected as siblings ( see Sec 3.2 ) .   Step 2 : We add the test mentions as nodes into   the mention - type graph G , where the test mentions   are connected to their sibling mentions selected at   Step 1 . Note that , in the new graph , test mentions   have no type neighbors since their ground - truth   types are not available . Besides , there is no edge   between any two test mentions in the new graph .   Step 3 : Following Eq . ( 6 ) , the representations of   test mentionsfmgare updated by aggregating the   embeddings for their sibling mentions . Note that   Yis empty , so no information from the ground-   truth types are involved . Through layers of updates ,   the ﬁnal representations fmgare obtained.2079Step 4 : Based on the mention embedding m   and the type embeddings Y , we predict the type   score distribution for mby Eq.(8 ) .   We conclude that , ( 1 ) our graph module is scal-   able to add arbitrary number of unseen test men-   tions as new nodes to the existing graph to derive   their representations . By contrast , many popular   graph settings ( Kipf and Welling , 2017 ; Velickovic   et al . , 2018 ; Wang et al . , 2019 ) fail to extend to new   nodes . ( 2 ) Since the embeddings for sibling men-   tions have been well learnt during training , the only   need is to compute the embeddings for test men-   tions for prediction , which are derived simultane-   ously during graph inference with high efﬁciency .   6 Experiments   6.1 Datasets   We evaluate the proposed model on two widely-   used datasets : OntoNotes and BBN .   OntoNotes The original OntoNotes dataset is   annotated by distant supervision ( Gillick et al . ,   2014 ) . The training , development and test sam-   ples in OntoNotes are about 251 K , 2 K and 9 K ,   respectively . We also conduct experiments on the   augmented version(Choi et al . , 2018 ) with 793 K   training samples . The above two versions share   the same test set and development set , as well as   the same type set of size 89 .   BBN Different from OntoNotes , BBN is manu-   ally annotated ( Weischedel and Brunstein , 2005 ) .   The training , development and test set contain   about 84 K , 2 K and 14 K samples respectively , and   the type set contains 47 type in total .   6.2 Experimental Setup   Our model is implemented based on the PyTorch   Geometric package ( Fey and Lenssen , 2019 ) . In the   main experiments ( Sec 6.4 ) , we obtain the sibling   mentions according to the typing distribution - based   metric described in Sec 3.2 . We conduct hyper-   parameter search on the development set and the   optimal settings are presented in Appendix A.   Following the previous works ( Ling and Weld ,   2012 ; Ren et al . , 2016 ; Chen et al . , 2019 ) , we re-   port the performance in terms of strict accuracy   ( Acc ) , macro - average F1 score ( Ma - F1 ) and micro-   average F1 score ( Mi - F1 ) . To guarantee the relia - bility , we repeat the experiment three times under   each setting , and report the average results .   6.3 Baselines   We compare our proposed model with several   state - of - the - art FGET models : ( 1 ) AFET ( Ren   et al . , 2016 ) ; ( 2 ) AAA ( Abhishek et al . , 2017 ) ;   ( 3 ) NFETC ( Xu and Barbosa , 2018 ) ; ( 4 ) NEURAL   ( Shimaoka et al . , 2017 ) ; ( 5 ) ACT ( Zhang et al . ,   2018 ) ; ( 6 ) Lin and Ji ( 2019 ) ; ( 7 ) Chen et al . ( 2020 ) ;   ( 8) LABELGCN ( Xiong et al . , 2019 ) ; ( 9 ) Choi et al .   ( 2018 ) ; ( 10 ) Ali et al . ( 2020 ) . Note that Lin and Ji   ( 2019 ) is considered as an important baseline in our   experiments and is marked with Fin Table 1 - 3 ,   since we use it as the base model to derive the prior   typing distributions for sibling selection ( Sec 3.2 ) .   6.4 Results and Analysis   Table 1 , 2 and 3 illustrate the experimental results   on the original and the augmented OntoNotes , as   well as the BBN dataset .   Analysis The results demonstrate that learning   from sibling mentions helps our model outperform   most baselines across the benchmarks . The detailed   analysis is presented as follows :   ( 1 ) We select sibling mentions according to the   typing distribution from Lin and Ji ( 2019 ) . We   observe that , after aggregating sibling information   through the attentive graph neural module ( Sec   4.1 ) , our model signiﬁcantly outperforms Lin and Ji   ( 2019 ) on both the original OntoNotes and the BBN   dataset . When trained on the augmented OntoNotes   of the same size , our model increases the accuracy   score by more than 5 % over Lin and Ji ( 2019 ) .   Compared with Lin and Ji ( 2019)which utilizes   the full 3 M augmented OntoNotes for training , our   model still maintains a comparable performance   and even improves the accuracy score by about 2 % .   ( 2 ) Many previous works have demonstrated the   effectiveness of modeling type hierarchy for entity   typing ( Ren et al . , 2016 ; Xu and Barbosa , 2018 ;   Xiong et al . , 2019 ; Chen et al . , 2020 ) . As a com-   parison , our model also considers the hierarchical   information of types and incorporates it in a natu-   ral way ( Sec 4.1 ) . From the results , we conclude   that learning jointly from type hierarchy and sib-   ling mentions can remarkably improve the typing   performance .   ( 3 ) The attention mechanism plays an important   role in our graph module and some of the baselines   ( Ren et al . , 2016 ; Abhishek et al . , 2017 ; Xu and2080Barbosa , 2018 ) . It not only helps identify the in-   formative features from neighbors but also helps   alleviate noise from the training data constructed   by distant supervision ( e.g. , OntoNotes ) . The re-   sults reveal that our graph - based solution is more   effective than the existing solutions .   6.5 Ablation Studies   6.5.1 Effect of the sibling selection metrics   In Sec 3.2 , we propose two similarity metrics to   discover sibling relationships in graph G , and abbre-   viate them as : “ Word - based ” and “ Typing - based ”   metrics . Here , we provide two additional metrics   for more detailed analysis : the “ Gold typing - based “   and the “ Random - based “ metrics , which are twoextreme variations of the typing - based metrics . Un-   der the gold typing - based metric , the siblings are   selected by the gold typing distribution , where each   dimension is 0 or 1 according to the ground - truth   types of the mention . In this way , candidate men-   tions that share more ground - truth types with the   target mention will have larger cosine similarity   and thus be chosen as the siblings with a higher   probability . On the contrary , under the random-   based metric , siblings are selected at random . Since   the type set is large , the siblings are more likely   to be irrelevant with the target mention and may   contain much noise .   Measuring sibling quality Intuitively , different   similarity metrics will affect the quality of sib-   lings . To quantify this effect , we measure the sib-   ling quality for the test mentions Vin the original   OntoNotes and deﬁne the metrics as follows .   For each mention m2V , denote its ground-   truth types asYand sibling mentions in graph   G(deﬁned in Sec 3.1 ) as M. Further , forM ,   we denote their ground - truth types as Y , i.e. ,   Y=[Y:(10 )   Similar to the deﬁnitions of Precision , Recall and   F1 , we deﬁne Purity , Coverage andQuality to mea-   sure the sibling quality of V :   Results The results are presented in Table 4 . In   general , the model performance is closely related   to the sibling quality . Besides , the typing - based   metric performs better than the word - based met-   ric . This indicates that the the continuous type-   level probability distribution is more reliable for   sibling selection than the discrete word - level distri-   bution . The scores from the gold typing - based and   the random - based metrics reveal the upper bound   and the lower bound of the scores for the typing-   based metric . On the one hand , the quality of the   siblings selected by the gold typing - based metric   is much higher than those by other methods , with   the Coverage up to 97:6 % . Meanwhile , its corre-   sponding model also outperforms the other three   by a large margin . Note that the typing perfor-   mance in this scenario is limited by the annotation2081   quality to some extent . Since OntoNotes is anno-   tated by distant - supervision , the scores for the gold   typing - based metric could not reach higher due to   the label noise of the siblings . On the other hand ,   a distinct drop of the scores is observed with the   random - based metric . This is reasonable since the   randomly selected siblings contain much noisy in-   formation , which is helpless and even harmful for   typing of the target mention . It can be concluded   from the above observations that there is still much   room to improve the sibling quality as well as the   typing performance of the sibling - enhanced model .   6.5.2 Effect of sibling size K   The model performance is sensitive to the size of   selected sibling mentions for a target mention in the   graphG. Denote the sibling size as K , following   the default hyper - parameter settings , we train our   model on the original OntoNotes under different   K2f0;5;10;15gusing the typing - based sibling   selection metric . The corresponding sibling quality   and model performance are reported in Table 5 . We   observe that the best scores are obtained with the   top5sibling mentions . When K= 0 , the graph   only contains the self - connections from the target   mentions to themselves . Without the additional   information from siblings , the Macro F1 score de-   creases by 2:1 % , which indicates the effectiveness   of sibling mentions for improving the typing perfor-   mance of our model . When K6= 0 , the Coverage   score goes up while the Purity and Quality scores   go down as Kranges from 5to15 . Meanwhile ,   the typing performance decreases as Kincreases .   It suggests that , for OntoNotes , a properly smaller   sibling size is a trade - off choice for the model to   use siblings with higher quality and thus achievebetter typing performance .   6.5.3 Effect of dropout probability   We randomly discard some type neighbors with   a dropout probability   during training ( Sec 4.5 ) ,   which forces the model to learn from the sibling   mentions other than the ground - truth types . Table 6   shows the results under different values of   on the   original OntoNotes dataset . Generally , the model   achieves better performance with larger   . This   indicates discarding a large proportion of ground-   truth types is beneﬁcial for learning from sibling   mentions . Besides , it also narrows the difference   between training and test settings where the test   mentions do not have ground - truth types as neigh-   bors . The best performance is achieved when   equals around 0:7 . However , dropping all the type   neighbors ( i.e. ,   = 1 ) will block the interaction   between the type and mention representations in   the graph , which may slightly damage the perfor-   mance .   6.6 How sibling mentions work in FGET   6.6.1 Quantifying the hard mentions   To select sibling mentions , we ﬁrst derive the prior   typing distribution from the base model ( Lin and   Ji , 2019 ) as described in Sec 3.2 . During experi-   ments , we observe that the contextual information2082for some mentions are insufﬁcient or too complex ,   which makes the base model confused on these   mentions . Entropy measures the uncertainty of   a probability distribution . Thus , we quantify the   difﬁculty of mentions by the entropy of their corre-   sponding prior typing distributions and deﬁne the   mentions with the top- 500highest entropy values   ashard mentions , which account for about 5 % of   thewhole mentions . Table 7 compares the perfor-   mance of our model and the base model on both   the whole mentions and the hard mentions from   the test dataset of the original OntoNotes . we see   that both models perform worse on the hard men-   tions than on the whole mentions . Besides , except   for the superiority of our model regarding the Acc ,   Ma - F1 and Mi - F1 scores , it also achieves a lower   entropy value than the base model especially on the   hard mentions . This indicates the information from   siblings makes the output type distributions more   concentrated and therefore increases the conﬁdence   for model predictions .   6.6.2 Case Study   To further provide an intuitive understanding about   how our model beneﬁts from sibling mentions , we   present an example in Table 8 . As expected , the   retrieved siblings based on the metric deﬁned in   Sec 3.2 share similar ground - truth types with the   target mention . This veriﬁes the effectiveness of   our sibling selection algorithm . Moreover , we ob-   serve that the siblings even help predict the correct   but out - of - gold - set types for the target mention in   this case . Although the annotated types for the tar-   get mention [ GM ofﬁcials ] only contains /person   in the test set . The sibling mentions still provide a   strong evidence for our model to also predict /per-   son / title as a possible type for the target mention .   7 Related Work   FGET is an important task for the downstream   NLP tasks and many efforts have been make in   improving its performance ( Zhang et al . , 2020a ;   Liu et al . , 2021a ) . Early works in FGET ( Ling and   Weld , 2012 ; Shimaoka et al . , 2016 ) mainly focus   on feature extraction for mentions , which do not   consider label noise introduced by distant supervi-   sion ( Gillick et al . , 2014 ; Choi et al . , 2018 ; Li et al . ,   2020 ) . Recent years have witnessed an increas-   ing number of researchers being dedicated to data   denoising . A popular solution ( Ren et al . , 2016 ; Ab-   hishek et al . , 2017 ; Xu and Barbosa , 2018 ; Ali et al . ,   2020 ) is to design loss functions for the clean and   noisy parts of the training data separately . Never-   theless , Zhang et al . ( 2020c ) proposes an automatic   relabeling framework to estimate the pseudo - truth   label distribution of each sample , which treats the   noisy and clean data uniformly . Besides , Chen   et al . ( 2019 ) groups mentions of the same type into   a compact cluster to improve the robustness of the   model . Ali et al . ( 2020 ) reﬁnes noisy representa-   tions by corpus - level contextual clues . Onoe and   Durrett ( 2019 ) introduces two additional models to   delete the samples that are too noisy to be useful ,   and repair noisy labels for the retained examples .   In addition , there are some notable work which   tries to build FGET with limited resources ( Qian   et al . , 2021 ) .   Modeling the type hierarchy is another impor-   tant topic in FGET . Prior solutions ( Shimaoka et al . ,   2017 ) introduce a one - hot matrix to encode the hier-   archy . Xu and Barbosa ( 2018 ) proposes a hierarchy-   aware loss function . Recently , graph - based meth-   ods have been proven to be powerful in many NLP   tasks ( Kipf and Welling , 2017 ; Liang et al . , 2021 ;   Xu et al . , 2019 ; Liang et al . , 2022 ) . Using graphs2083to model the type hierarchy in FGET is a natural   idea . Jin et al . ( 2019 ) models the potential type cor-   relations for in - knowledge - base entities via hierar-   chical multi graph convolutional networks ( GCNs ) .   Further , Xiong et al . ( 2019 ) extends GCNs to a   vast number of free - form types . Chen et al . ( 2020 )   designs a multi - level learning - to - rank loss to lever-   age hierarchical information . Recently , Onoe et al .   ( 2021 ) models the mention and type representa-   tions in a box space instead of the traditional vector   space .   8 Conclusion   In this paper , we ﬁrstly point out that SOTA typing   models suffer from a bottleneck issue , i.e. , they per-   form poorly on a certain number of hard mentions ,   which leads to their limited overall performance .   To this end , we propose to exploit sibling informa-   tion for mention representation learning and deﬁne   two metrics for detecting sibling relationship be-   tween mentions . Further , we model sibling learning   as a graph learning problem . Our model is scalable   in that , once trained , it can generate sibling - aware   representations for previously unseen mentions ef-   ﬁciently during inference stage . Extensive exper-   iments show that the proposed model indeed han-   dles hard mentions well and thereby yields better   overall performance than SOTA baseline models .   9 Acknowledgements   This work was partially supported by the National   Natural Science Foundation of China ( 61876053 ,   62006062 , 62176076 ) , the Shenzhen Foundational   Research Funding ( JCYJ20200109113441941 ,   JCYJ20210324115614039 ) , Joint Lab of Lab of   HITSZ and China Merchants Securities .   References208420852086A Hyperparameter Settings   The default hyperparameters for our model are set   as follows , where Kis mentioned in Sec 3.2 , L ,   anddare mentioned in Sec 4.2087