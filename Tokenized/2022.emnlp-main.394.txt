  Lunyiu Nie , Shulin Cao , Jiaxin Shi , Jiuding Sun ,   Qi Tian , Lei Hou , Juanzi Li , Jidong ZhaiDepartment of Computer Science and Technology , Tsinghua UniversityHuawei Cloud Computing Technologies Co. , Ltd.   { nlx20 , caosl19 , sjd22}@mails.tsinghua.edu.cn , shijx12@gmail.com ,   tian.qi1@huawei.com , { houlei,lijuanzi,zhaijidong}@tsinghua.edu.cn   Abstract   Subject to the huge semantic gap between nat-   ural and formal languages , neural semantic   parsing is typically bottlenecked by its com-   plexity of dealing with both input semantics   and output syntax . Recent works have pro-   posed several forms of supplementary super-   vision but none is generalized across multiple   formal languages . This paper proposes a uni-   fied intermediate representation ( IR ) for graph   query languages , named GraphQ IR . It has a   natural - language - like expression that bridges   the semantic gap and formally defined syntax   that maintains the graph structure . Therefore , a   neural semantic parser can more precisely con-   vert user queries into GraphQ IR , which can   be later losslessly compiled into various down-   stream graph query languages . Extensive exper-   iments on several benchmarks including K   P , O , G QAandMQA-   Cypher under standard i.i.d . , out - of - distribution   and low - resource settings validate GraphQ IR ’s   superiority over the previous state - of - the - arts   with a maximum 11 % accuracy improvement .   1 Introduction   By mapping natural language utterances to log-   ical forms , the task of semantic parsing has been   widely explored in various applications , including   database query ( Yu et al . , 2018 ; Talmor and Be-   rant , 2018 ) and general - purpose code generation   ( Yin and Neubig , 2017 ; Campagna et al . , 2019 ;   Nan et al . , 2020 ) . Although the methodology has   evolved from earlier statistical approaches ( Zettle-   moyer and Collins , 2005 ; Kwiatkowski et al . , 2010 )   to present Seq2Seq paradigm ( Zhong et al . , 2017 ;   Damonte and Monti , 2021 ) , the semantic gap be-   tween natural language and logical forms still lies   as the major challenge for semantic parsing .   As shown in Figure 1 , in graph query languages   ( e.g. , SPARQL , Cypher , Lambda - DCS , and newly   emerged KoPL , etc . ) , graph nodes , edges and their   respective properties constitute the key semanticsof the logical forms ( Pérez et al . , 2009 ) , which are   very different from the expression of natural lan-   guage utterances . Such discrepancy significantly   hinders the learning of neural semantic parsers and   therefore increases the demand for labeled data   ( Yin et al . , 2022 ) . However , due to the laborious   efforts and language - specific expertise required in   annotation , such demand can not always be satisfied   and thus becomes the bottleneck ( Li et al . , 2020b ;   Herzig et al . , 2021 ) .   To overcome these challenges , many works   adopt complementary forms of supervision , such as   the schema of database ( Hwang et al . , 2019 ) , results   of the execution ( Clarke et al . , 2010 ; Wang et al . ,   2018 , 2021 ) , and grammar - constrained decoding   algorithms ( Krishnamurthy et al . , 2017 ; Shin et al . ,   2021 ; Baranowski and Hochgeschwender , 2021 ) .   Although effective , the additional resources that   these methods rely on are not necessarily available   in practice . By normalizing the expression ( Be-   rant and Liang , 2014 ; Su and Yan , 2017 ) or enrich-   ing the structure ( Reddy et al . , 2016 ; Cheng et al . ,   2017 ; Hu et al . , 2018 ) of natural language utter-   ances , another category of works proposes various   intermediate representations like AMR ( Kapani-   pathi et al . , 2021 ) to ease the parsing of complex   queries . However , the transition from their IRs   to the downstream logical forms may incur extra   losses in precision ( Bornea et al . , 2021 ) . Besides ,   these representations are usually coupled to spe-   cific data or logical forms and thus can not be easily   transferred to other tasks or languages ( Kamath and   Das , 2019 ) .   In industry , aside from SPARQL , many other   graph query languages such as Cypher ( Francis   et al . , 2018 ) and Gremlin ( Rodriguez , 2015 ) are   equally or even more commonly used in graph   database interaction ( Angles , 2012 ; Seifer et al . ,   2019 ) . However , most graph query semantic pars-   ing works only support SPARQL ( Talmor and Be-   rant , 2018 ; Dubey et al . , 2019 ; Keysers et al . , 2020)5848   while very few works target other graph query lan-   guages . Meanwhile , no existing tools or IR can   support the data conversion among multiple graph   query languages ( Moreira and Ramalho , 2020 ;   Agrawal et al . , 2022 ) . Such lack of interoperability   has not only hindered the semantic parsing of low-   resource languages but also limited the potential   of querying heterogeneous databases ( Mami et al . ,   2019 ; Angles et al . , 2019 ) .   In this paper , we propose a unified intermediate   representation for graph query languages , namely   GraphQ IR , to resolve these issues from a novel   perspective . The designs of GraphQ IR weigh up   the semantics of both natural and formal language   by ( a ) producing the IR sequences with composi-   tion rules consistent with modern English ( Tomlin ,   2014 ) to close the semantic gap ; and ( b ) maintain-   ing the fundamental graph structures like nodes ,   edges , and properties , such that the IR can be au-   tomatically compiled into any downstream graph   query languages without any loss .   Instead of directly mapping the user query to   the logical form , we first parse natural languageinto GraphQ IR , then compile the IR into the tar-   get graph query languages ( e.g. , SPARQL , Cypher ,   Lambda - DCS , KoPL , etc . ) . Therefore , language-   specific grammar features that initially posed a   huge obstacle to semantic parsing are now explic-   itly handled by the compiler . Additionally , with the   GraphQ IR as a bridge , our implemented source-   to - source compiler can support lossless translation   among multiple graph query languages and thus   unify the annotations of different languages for   eliminating the data bottleneck .   To validate the effectiveness of GraphQ IR ,   we conducted extensive experiments on bench-   marks KP , O , G QA and   MQA - Cypher . Results show that our approach   can consistently outperform the previous works by   a significant margin . Especially under the compo-   sitional and few - shot generalization settings , our   approach with GraphQ IR can demonstrate a maxi-   mum 11 % increase in accuracy over the baselines .   The main contributions of our work include :   •We propose GraphQ IR for unifying the se-   mantic parsing of graph query languages and   present the IR design principles that are criti-   cal for bridging the semantic gap ;   •Experimental results show that our approach   can consistently achieve state - of - the - art per-   formance across multiple benchmarks under   the standard i.i.d , out - of - distribution , and low-   resource settings .   •Our implemented source - to - source compiler   unlocks data interoperability by supporting   the bi - directional translation among different   graph query languages . The code and toolkit   are publicly available at https://github .   com / Flitternie / GraphQ_IR .   2 GraphQ IR   In this section , we formalize the grammar and   the expressiveness of our GraphQ IR based on   the definition of property graph and regular path   query . Then we summarize the design principles of   GraphQ IR for bridging the semantic gap between   natural and formal language as well as unifying   different graph query languages .   2.1 Definition   As the top of Figure 1 demonstrates , a graph   database can be expressed as a collection of prop-   erty graphs that include Entity ( graph nodes , e.g. ,5849Stanley Kubrick ) , Attribute ( node properties , e.g. ,   date of birth ) , Concept ( node label , e.g. , film ) , Re-   lationship ( graph edges , e.g. , spouse ) and Quali-   fier(edge properties , e.g. , start time ) .   Therefore , to evaluate the expressiveness of   GraphQ IR , we start by giving the definition of   property graph : a directed labeled multigraph   where each node or edge can contain a set of   property - value pairs ( Angles , 2018 ) .   Definition 1 ( Property graph ) .A property graph   Gis a tuple ( N , E , ρ , λ , σ ) where :   ( 1)Nis a finite set of nodes .   ( 2)Eis a finite set of edges such that N∩E=∅.   ( 3)ρ : E→(N×N)is a total function . Specif-   ically , ρ(e ) = ( n , n)refers eis a directed edge   from node nton .   ( 4)λ : ( N∪E)→Lis a partial function where L   is a set of labels . Specifically , if λ(n ) = lthenlis   the label of node n.   ( 5)σ : ( N∪E)×P→Vis a partial function   withPa set of properties and Va set of values V.   Specifically , if σ(n , p ) = vthen the property pof   node nhas value v.   Subsequently , a graph path can be expressed   asπ= ( n , e , ... , e , n)where k≥1with   eachebeing the edge between nandn . The   spelling of path , denoted as λ(π ) , is the concate-   nation of edge labels λ(e) ... λ(e)(Mendelzon   and Wood , 1995 ; Baeza , 2013 ) .   Definition 2 ( Regular path query ) .A regular path   query has the general form Q = x− →ywhere x   denotes the start point , αis a regular expression   defined over λ(π ) , and ydenotes the endpoints of   the query .   By incorporating ρ , λ , σand their inverse func-   tionρ , λ , σ , such regular path query can be   extended to support navigational queries towards   any graph elements ψ∈(N∪E∪L∪P∪V )   ( Wood , 2012 ; van Rest et al . , 2016 ) . We can now   evaluate the expressiveness of a language .   Definition 3 ( Path query expressiveness ) .A path   query qis expressible in a language L , if there   exists an expression ε∈ L such that , for any sub-   graph G⊆G , we have ε(G ) = q(G)(Fletcher   et al . , 2015 ) .   We formalize GraphQ IR as a context - free gram-   mar(V , Σ , S , P)and present its non - terminals and   productions in Appendix Table 7 . Its VandPare   respectively defined as the superset of the terminal   set ( n , e , l , p , v ) and production set ( ρ , λ , σ , ρ , λ , σ ) of regular graph query . Therefore , all   path queries expressible in regular grammar are   also expressible in the context - free grammar of   GraphQ IR ( Hopcroft et al . , 2007 ) . Furthermore ,   GraphQ IR also supports extended operations like   Union , Difference andFilter to express complex   graph query patterns ( Angles et al . , 2017 ) .   Empirically , GraphQ IR can express all graph   query patterns that appeared in benchmarks K   P , O , G QA and MQA-   Cypher , with details elaborated in Section 4.1 .   2.2 Principles   We summarize several principles in designing   GraphQ IR in this way : present in a syntax close   to natural language while preserving the structural   semantics equivalent to formal languages .   2.2.1 Diminishing syntactical discrepancy   To facilitate the training of the neural semantic   parser , the target IR sequence should share a similar   syntax in correspondence to the input utterance .   To achieve this , the IR structure should first   match how users typically raise queries . There-   fore , we simplify the triple - based structure in   graph query languages into a more natural subject-   verb - object syntactic construction ( Tomlin , 2014 ) .   Take Figure 1 ’s task setting as an example , the   two triples ( ? e instance_of ? c ) and(?c   name “ film ” ) as the entity concept constraint   in SPARQL are simplified to the sentence subject   “ < C > film</C > ” in GraphQ IR . Multi - hop relation-   ship and attribute queries are formulated as relative   clauses similar to the English expression and thus   can be comfortably generated by a language - model-   based neural semantic parser .   Secondly , IR should also leave out the variables   ( e.g. ,?e,?cin SPARQL ) and operators ( e.g. ,   SELECT , WHERE , RETURN , etc . ) in logical forms   that can not be easily aligned to natural language   utterances . Alternatively , human - readable opera-   tors are adopted in GraphQ IR , as illustrated in   Appendix Table 7 .   2.2.2 Eliminating semantic ambiguity   In formal languages , multiple parallel implemen-   tations can achieve the same functionalities . How-   ever , such redundancy and ambiguity in semantics   may pose challenges to the neural semantic parser .   For example , in Lambda - DCS , there co - exist   three implementations for constraining one ’s con-   cept ( e.g. , Kobe is a player ) , respectively through:5850   •EventNP :( call @getProperty   ( en.player.kobe_bryant ) ( call   @reverse ( string player ) ) ) ;   •TypeNP :( call @getProperty ( call   @singleton ( en.player ) )   ( string ! type ) ) ; and   •DomainNP :( call @getProperty   ( en.player.kobe_bryant   ... ( call @domain ( string   player ) ) ) ( string player ) ) .   When designing an IR , such redundant and am-   biguous semantics should be clarified into more   definitive and orthogonal representations ( Cam-   pagna et al . , 2019 ) . Thus in GraphQ IR , we unify   all such unnecessary distinctions and prune redun-   dant structures in logical forms to distill the core   semantics . In the previous example , GraphQ IR   only requires a simple noun modifier “ < C > player   < /C > ” as the concept constraint . This not only   makes the language clearer for users and semantic   parsers to comprehend , but also facilitates the next-   step compilation from the IR to the downstream   formal language .   2.2.3 Maintaining graph structural semantics   In addition to the aforementioned designs to im-   prove alignment with natural language , the syntax   of IR also needs to maintain the key structures of   graph queries for subsequent lossless compilation .   Specifically , IR should keep track of the data   types of graph structural elements . We design   GraphQ IR to be strong - typing by explicitly stat-   ing the type of terminal nodes with respective   special tokens , e.g. ,<E > forEntity , < R > for   Relation , < A > forAttribute , etc . Values ofdifferent types are also differentiated in GraphQ IR   with our pre - defined or user custom indicators , e.g. ,   string , number , date , time , etc .   Furthermore , IR should also preserve the hierar-   chical dependencies that are critical for multi - hop   queries . We introduce < ES > as a scoping token   in GraphQ IR to explicitly indicate the underly-   ing dependencies among the clauses produced by   anEntitySet , as shown in Appendix Table 7 .   Such scoping tokens in GraphQ IR can facilitate   the compiler to recover the hierarchical structure   and finally convert the IR sequences into one of the   graph query languages deterministically .   3 Implementation   We depict the full picture of our proposed frame-   work in Figure 2 . The neural semantic parser   first maps the input natural language utterance into   GraphQ IR . Thereafter , the GraphQ IR sequence   is fed into the compiler and parsed into an abstract   syntax tree for downstream graph query language   code generation .   3.1 Neural Semantic Parser   To verify the above principles in practice , we   formulate the conversion from natural language to   our GraphQ IR as a Seq2Seq task and adopt an   encoder - decoder framework for implementing the   neural semantic parser .   As shown in the left part of Figure 2 , the encoder   module of the semantic parser first maps the input   natural language utterance Xto a high dimensional   feature space with non - linear transformations for   capturing the semantics of the input tokens . The de-   coder module subsequently then interprets the hid-   den representations and generates the IR sequence5851by factorizing the probability distribution :   p(IR ) = /productdisplayP(y|X , y , ... , y ) , ( 1 )   where yis the i - th token of IR sequence with in   total ntokens . Specifically , we implement this   encoder - decoder network with BART ( Lewis et al . ,   2020 ) , a pretrained language model that is profi-   cient in comprehending the diverse user utterances   and generating the GraphQ IR sequences that are   structured in natural - language - like expressions .   Please note that the implementation in this part is   orthogonal to our GraphQ IR and can be substituted   by other semantic parsing models .   3.2 Compiler   The implementation of GraphQ IR ’s compiler   comprises a front - end module that generates an   abstract syntax tree from the IR sequence and a   back - end module that transforms the tree structure   into the target graph query language .   The compiler front - end is responsible for per-   forming the lexical and syntax analysis on the IR   sequence . The lexer first splits the sequence into   lexical tokens , which are subsequently structured   into a parse tree with LL ( * ) parsing strategy ( Parr ,   2013 ) according to the pre - defined grammar in Sec-   tion 2.1 . As such , GraphQ IR sequence can be   automatically constructed into an abstract syntax   tree ( AST ) that contains syntactic dependencies   and hierarchical structures .   The compiler back - end will then traverse the ab-   stract syntax tree and restructure the nodes and de-   pendencies into one of the downstream graph query   languages . We formalize the code generation as   a tree mapping process , where the subtrees carry-   ing equivalent information are aligned according to   pre - defined transformation rules . To illustrate , we   present 2 examples of generating SPARQL and   Lambda - DCS queries respectively in Appendix   Figure 5 and Figure 4 .   Similarly , we also implement the compiler that   supports conversion from graph query languages to   GraphQ IR . Thus , with the IR as a middleware , our   toolkit can also achieve the transpilation between   any two graph query languages supported .   4 Experiments   In this section , we evaluate GraphQ IR on several   benchmarks under different task settings.4.1 Datasets   For evaluation , we test on benchmarks K   P , O , G QA and MQA-   Cypher that altogether cover graph query languages   SPARQL , KoPL , Lambda - DCS , and Cypher .   In all experiments , the GraphQ IR sequences   are automatically converted from the original log-   ical forms of the respective datasets by the bi-   directional compiler without extra re - annotation .   KQA Pro KP(Cao et al . , 2022a ) is a large-   scale dataset for complex question answering over   Wikidata knowledge base ( Vrandecic and Krötzsch ,   2014 ) . It is the largest KBQA corpus that contains   117,790 natural language questions along with the   corresponding SPARQL and KoPL logical forms ,   covering complex graph queries involving multi-   hop inference , logical union and intersection , etc .   In our experiment , it is divided into 94,376 train ,   11,797 validation , and 11,797 test cases .   Overnight O ( Wang et al . , 2015 ) is   a semantic parsing dataset with 13,682 examples   across 8 sub - domains extracted from Freebase ( Bol-   lacker et al . , 2008 ) . Each domain has natural lan-   guage questions and pairwise Lambda - DCS queries   executable on SEMPRE ( Berant et al . , 2013 ) . It ex-   hibits diverse linguistic phenomena and semantic   structures across domains , e.g. , temporal knowl-   edge in C domain and spatial knowledge   inB domain . We use the same train / val / test   splits as in the previous work ( Wang et al . , 2015 ) .   GrailQA G QA(Gu et al . , 2021 ) is a knowl-   edge base question answering dataset with 64k   questions grounded on Freebase ( Bollacker et al . ,   2008 ) that evaluate generalizability at three levels ,   i.e. , i.i.d , compositional generalization and zero-   shot . To focus on the sole task of semantic pars-   ing , we replace the entity IDs ( e.g. ,m.06mn7 )   with their respective names ( e.g. ,Stanley   Kubrick ) in G QA ’s logical forms , thus   eliminating the need for an explicit entity linking   module as in previous works ( Chen et al . , 2021 ; Ye   et al . , 2022 ) . Since G QA ’s test set is not pub-   licly available for such transformation , we report   the validation set results for our evaluation , which   have been studied to show consistent trends with   the test set ( Gu and Su , 2022 ) .   MetaQA - Cypher MQA(Zhang et al . , 2018 )   contains more than 400k multi - hop QA pairs   over WikiMovies knowledge base ( Miller et al . ,5852   2016 ) . Many studies have previously worked on   its SPARQL annotation ( Huang et al . , 2021 ) . In-   stead , we reconstruct MQAinto Cypher as a   few - shot learning benchmark to evaluate the inter-   operability achieved by GraphQ IR . To the best of   our knowledge , this is also the first Cypher dataset   in the community of semantic parsing .   4.2 Metric   We adopt execution accuracy as our metric based   on whether the generated logical form queries can   return correct answers . For queries with multiple   legal answers , we require the execution results to   exactly match allground - truth answers .   4.3 Results   I.I.D. Generalization As Table 1 illustrates , on   KP , our proposed approach with GraphQ IR   consistently outperforms the previous approaches   on all query categories . In particular , GraphQ IR   exhibits good generalization under the complex   M -,Q andZ- settings   with even larger margins over the baselines . We   attribute this to its natural - language - like represen-   tations that effectively close the semantic gap and   its formally - defined syntax that can be losslessly   converted into downstream languages .   As for O , our methods also signifi-   cantly surpass the baselines as shown in Table 2 .   Previous works usually train separate parsers for   each of the eight domains due to their distinct vo-   cabularies and grammars ( Wang et al . , 2015 ; Chen   et al . , 2018a ) . With an extra layer of GraphQ IR   for unification , domain - specific data are now con-   solidated into one universal representation , and the   training of one domain can thereby benefit from   the others . Consequently , GraphQ IR * that gets   trained on the aggregate data of all eight domains   demonstrates the best results .   OOD Generalization Current neural seman-   tic parsers often fail in generalizing to out - of-   distribution ( OOD ) data ( Pasupat and Liang , 2015 ;   Keysers et al . , 2020 ; Furrer et al . , 2020 ) . There-   fore , we experiment on G QA , a dataset that5853   specifically stresses non - i.i.d . generalization .   We present the results in Table 3 . Among the   models without explicit entity linking modules ,   compared with the BART baseline that directly   maps to the logical forms and the CFQ IR ( Herzig   et al . , 2021 ) that particularly aims at SPARQL com-   positional generalization , GraphQ IR achieves the   best overall performance and performs remarkably   well also in compositional generalization and zero-   shot data splits . This can be credited to our IR de-   signs that clarify the redundant semantics and main-   tain the key hierarchical structure where its com-   ponents can be flexibly combined or decomposed   according to the pre - defined production rules .   Low - resource Generalization To verify whether   GraphQ IR can aid the semantic parsing of low-   resource languages , we reconstruct the MQA   dataset into Cypher , a graph query language com-   monly used in the industry but rarely studied in pre-   vious semantic parsing works ( Seifer et al . , 2019 ) .   To simulate the low - resource scenario , we adjust   the data split to ensure that only 1 , 3 , and 5 sam-   ples of each question type appear in the training set   under the 1- , 3- , and 5 - shot settings .   The results in Table 4 indicate that our meth-   ods can remain robust under a low - resource setting   with strong few - shot generalization . Specifically ,   the GraphQ IR * model that has in advance trained   onKP(a dataset annotated in SPARQL and   KoPL ) demonstrates the most outstanding perfor-   mance on MQA - Cypher , especially under the   most challenging 1 - shot setting . Previous works in   semantic parsing usually target a specified type of   logical form and neglect the data interoperability   across languages . With the GraphQ IR as a bridge ,   low - resource query languages can now leverage   data from other languages . A universal semantic   parser that can end - to - end support different lan-   guages also becomes possible .   5 Discussion   To further explore the reasons behind the supe-   rior performance of our methods , we compute and   visualize the semantic distance between the natural   language utterances and their corresponding logical   forms or GraphQ IR .   Specifically , to simulate how a neural semantic   parser processes the sequences in the above ex-   periments , we use a pretrained BART - base model   without fine - tuning to obtain the contextualized em-   beddings ( Li et al . , 2020a ) . For each sequence , we5854   take the average of the encoder outputs across all   word tokens to obtain a 768 - dimensional vector as   its sentence embedding ( Ni et al . , 2022 ) . Thereafter ,   we measure the semantic distance between two se-   quences by computing the Euclidean distance ( L2-   norm ) of their embeddings ( Chandrasekaran and   Mago , 2021 ) .   We randomly sampled 1000 queries respectively   from KPandO ’s validation set .   We compare the semantic distance between natural   language utterances and the GraphQ IRs ( i.e. , NL   ⇔IR ) , as well as the distance between natural   language utterances and their corresponding logical   forms ( e.g. , NL⇔SPARQL ) .   The results are listed in Table 5 . The seman-   tic distance from natural language utterances to   GraphQ IR is significantly closer than that to differ-   ent logical forms by at most 25.28 % . We also use   t - SNE ( Van der Maaten and Hinton , 2008 ) to re-   duce the dimension and visualize the embeddings .   Figure 3 ( a ) and ( b ) respectively shows the visual-   ized feature space on KPandO   datasets . The computation and visualization results   affirm our hypothesis that GraphQ IR can effec-   tively close the semantic gap and ease the learning   of neural semantic parser.5.1 Error Analysis   To investigate GraphQ IR ’s potentials and bot-   tlenecks , we look into the failures of our approach   when incorrect logical forms are generated . Out   of the total 979 errors in KP ’s test set , we   randomly sampled 100 cases and categorized them   into 4 types as shown in Table 6 .   Inaccurate data annotation ( 28 % ) . The ref-   erence logical form ( e.g. ,v_1 ! = " 110 " ) may   contain inconsistent or misinterpreted information   that contradicts to the corresponding natural lan-   guage utterance ( e.g. ,last 110 minutes ) . We at-   tribute this type of error to the dataset rather than   the failure of our approach .   Ambiguous query expression ( 27 % ) . The se-   mantics of the user utterance may be present in   more than one way ( e.g. ,kid film orchildren ’s film )   due to the ambiguity in natural language , whereas   the schema of the knowledge base is pre - defined   ( e.g. , only children ’s film is considered a   valid entity ) . This category of error can be fixed   by incorporating explicit schema linking modules ,   which are orthogonal to the implementation of our   GraphQ IR and semantic parser .   Unspecified graph structure ( 13 % ) . Logical   forms of different structures ( e.g. ,(Uzbekistan5855capital Tashkent ) and ( Tashkent   capital_of Uzbekistan ) ) can convey the   same semantics in a directed cycle graph , but some   of them contain structures that are absent in a   knowledge base . This type of error is due to the   incompleteness of the knowledge base .   Nonequivalent semantics ( 32 % ) . The output   includes incorrect query element ( e.g. , string and   numerical values ) or structure ( e.g. , edges and prop-   erties ) that conveys nonequivalent semantics , such   as misinterpreting graduate tostart_time .   Overall , 89 % of the sampled errors can be sim-   ply fixed by the revision of annotation or one - step   correction on the IR element , demonstrating that   our proposed method with GraphQ IR can generate   high - quality logical forms that are easy to debug .   6 Related Work   6.1 Semantic Parsing   Semantic parsing aims to translate natural lan-   guage utterances into executable logical forms ,   such as CCG ( Zettlemoyer and Collins , 2005 ) ,   Lambda - DCS ( Liang , 2013 ; Pasupat and Liang ,   2015 ) , SQL ( Zhong et al . , 2017 ; Yu et al . , 2021 ) ,   AMR ( Banarescu et al . , 2013 ) , SPARQL ( Sun et al . ,   2020 ) and KoPL ( Cao et al . , 2022a , b ) .   Most recent works take semantic parsing as a   Seq2Seq translation task via an encoder - decoder   framework , which is challenging due to the seman-   tic and structural gaps between natural utterances   and logical forms . To overcome such issues , cur-   rent semantic parsers usually ( 1 ) rely on a large   amount of labeled data ( Cao et al . , 2022a ) ; or ( 2 )   leverage external resources for mini the structural   mismatch , e.g. , injecting grammar rules during de-   coding ( Wu et al . , 2021 ; Shin et al . , 2021 ) ; or ( 3 )   employ synthetic data to diminish the semantic   mismatch ( Xu et al . , 2020 ; Wu et al . , 2021 ) .   Compared with previous works , our proposed   GraphQ IR allows the semantic parser to adapt   to different downstream formal query languages   without extra efforts and demonstrates promising   performance under the compositional generaliza-   tion and few - shot settings .   6.2 Intermediate Representation   Intermediate representations ( IR ) are usually   generated for the internal use of compilers and rep-   resent the code structure of input programs ( Aho   et al . , 1986 ) . Good IR designs with informativeand distinctive mid - level features can provide huge   benefits for optimization , translation , and down-   stream code generation ( Lattner and Adve , 2004 ) ,   especially in areas like deep learning ( Chen et al . ,   2018b ; Cyphers et al . , 2018 ) and heterogeneous   computing ( Lattner et al . , 2020 ) .   Recently , IR has also become common in many   semantic parsing works that include an auxiliary   representation between natural language and logi-   cal form . Most of them take a top - down approach   and adopt IR similar to natural language ( Su and   Yan , 2017 ; Herzig and Berant , 2019 ; Shin et al . ,   2021 ) . In contrast , another category of works con-   structs IR based on the key structure of target log-   ical forms in a bottom - up manner ( Wolfson et al . ,   2020 ; Marion et al . , 2021 ) . For example , Herzig   et al . designed CFQ IR that rewrites SPARQL by   grouping the triples of identical elements ( 2021 ) .   Although these works partially mitigate the mis-   match between natural and formal language , they   either failed in removing the formal representa-   tions that are unnatural to the language models or   neglected the structural information requisite for   downstream compilation . In this work , we omit   those IRs that can not be losslessly converted into   downstream logical forms .   7 Conclusion and Future Work   This paper proposes a novel intermediate rep-   resentation , namely GraphQ IR , for bridging the   semantic gap between natural language and graph   query languages . Evaluation results show that our   approach with GraphQ IR consistently surpasses   the baselines on several benchmarks covering   multiple formal languages , i.e. , SPARQL , KoPL ,   Lambda - DCS , and Cypher . Moreover , GraphQ IR   also demonstrates superior generalization ability   and robustness under the out - of - distribution and   low - resource settings .   As an early step towards the unification of se-   mantic parsing , our work opens up several future   directions . For example , many code optimization   techniques ( e.g. , common subexpression elimina-   tion ) can be incorporated into IR to improve per-   formance further . By bringing in multiple levels   of IR , our framework may also be extended to sup-   port relational database query languages like SQL .   Moreover , since the current designs of GraphQ   IR still require non - trivial manual efforts , the au-   tomation of such procedure , e.g. , in prompt - like   manners , is worth future exploration.5856Limitations   The major limitations of this work include : ( a )   the composition rules of GraphQ IR are closely   aligned with interrogative sentences . Therefore ,   our current formalism may not be applicable to   general - domain semantic parsing ; ( b ) for the se-   mantic parsing of an input language whose syntax   significantly differs from English ( e.g. , Arabic , Chi-   nese , Hindi , etc . ) , the benefits of GraphQ IR may   be limited ; ( c ) our experiments fine - tuned a neural   semantic parser on top of a pretrained model with   ∼139 million parameters , thus can not be easily   reproduced without adequate GPU resources .   Acknowledgements   We would like to thank the anonymous review-   ers for their valuable comments . This work is par-   tially supported by the National Key R&D Program   of China ( 2021ZD0110104 ) , the National Natural   Science Foundation of China ( U20A20226 ) , the   NSFC Youth Project ( 62006136 ) , and a grant from   the Institute for Guo Qiang , Tsinghua University   ( 2019GQB0003 ) . Jidong Zhai is the corresponding   author of this paper .   References58575858585958605861A GraphQ IR Grammar   We present GraphQ IR ’s non - terminals and pro-   duction rules in Table 7 .   B Implementation Details   B.1 Model Hyperparameters   For the neural semantic parser , we used the   BART - base model ( Lewis et al . , 2020 ) released   by Facebook on HuggingFace . 12 special tokens   ( e.g. ,<E > ) were added to the tokenizer vocabu-   lary as the structure indicators for GraphQ IR . We   used the AdamW optimizer ( Loshchilov and Hutter ,   2017 ) with the learning rate set to 3eand weight   decay set to 1efollowing the default settings .   B.2 Environmental Configurations   In our implementation of the compiler , we used   ANTLR ( Parr , 2013 ) version 4.9.2 for analyzing   our specified grammar rules and building up the   corresponding lexer and parser toolkit . For evalua-   tion , we used Virtuoso 7.20 , SEMPRE 2.4 , Neo4j   4.4and KoPL 0.3as the back - ends respectively   for executing the SPARQL , Lambda - DCS , Cypher ,   and KoPL queries .   Our whole experiments were performed on a   single machine with 8 NVIDIA Tesla V100 ( 32 GB   memory ) GPUs on CUDA 11 .   C Supplementary Study   C.1 KPCompositional Generalization   Compositional generalization refers to a model ’s   capability of generalizing from the known com-   ponents to produce novel combinations ( Pasupat   and Liang , 2015 ; Keysers et al . , 2020 ; Furrer et al . ,   2020 ) . To measure our IR ’s compositional gener-   alization ability , we also create a new KP   data split based on the logical form length and test   the parsers to generate long queries ( KoPL queries   with>7 functions ) based on the short query com-   ponents seen in the training data ( KoPL queries   with≤7 functions ) .   The results are listed in Table 8 . Compared with   the plain - BART baseline and the CFQ IR ( Herzig   et al . , 2021 ) that is specially designed for improv-   ing the compositional generalization on SPARQL,5862   GraphQ IR achieves the best performance in over-   all data as well as in complex task settings , which   can be again credited to our IR designs that sim-   plify the redundant semantics and preserve the key   structural features.586358645865