  Bin Sun , Yitong Li , Fei Mi , FanHu Bie , Yiwei Li , Kan LiSchool of Computer Science & Technology , Beijing Institute of TechnologyHuawei Noah ’s Ark LabHuawei Technologies Ltd.   Abstract   Existing knowledge - grounded open - domain di-   alogue generation models often face the hallu-   cination problem , i.e. the dialogue generative   model will persist in an inappropriate knowl-   edge and generate responses that inconsistent   with the facts . We argue that this problem   mainly stems from the polarized optimization   objectives and weak knowledge generation abil-   ity . To mitigate the hallucination , we take in-   spiration from human communicating that peo-   ple will replay euphemistic responses for the   unclear or unrecognizable knowledge , and pro-   pose an Augmentative and Contrastive Knowl-   edge Dialogue Expansion Framework ( ACK-   DEF ) . ACK - DEF constructs the augmentative   and contrastive knowledge dialogue samples ,   which consist of the knowledge of different   degrees of errors and the response of manual   design , to expand the original training set and   smooth the polarized optimization objective   that enables models to generate ground - truth   with or without gold knowledge . Not only the   knowledge , ACK - DEF also provides the tactful   responses of manual design corresponding to   the incomplete correct knowledge . Experimen-   tal results on the Wikipedia of Wizard dataset   show that employing the ACK - DEF is effective   to alleviate the hallucination problem .   1 Introduction   Recently , Knowledge - Grounded Dialogue Gener-   ation draws dramatic attentions in artificial intelli-   gence community . Many efforts incorporate knowl-   edge information to improve the performance of   dialogue generation models ( Zhou et al . , 2018 ; Di-   nan et al . , 2019 ; Gopalakrishnan et al . , 2019 ; Kim   et al . , 2020 ; Zhao et al . , 2020a ; Zheng et al . , 2021 ;   Zhao et al . , 2022a ; Bao et al . , 2022 ) . However ,   these methods always face the hallucination prob-   lem , that is , the dialogue generation model may   insist on an inappropriate knowledge and generate   responses that inconsistent with the facts ( Rashkin   et al . , 2021 ; Zhao et al . , 2022a ; Dziri et al . , 2022).We argue that the hallucination problem primar-   ily caused by two aspects : ( 1 ) The optimization ob-   jective is usually polarized by the gold knowledge-   dialogue samples and general dialogue samples   without knowledge in current knowledge - grounded   dialogue datasets ( Zhou et al . , 2018 ; Gopalakrish-   nan et al . , 2019 ; Dinan et al . , 2019 ; Wu et al . ,   2019 ; Komeili et al . , 2022 ) . Few datasets consider   teaching models how to respond when dealing with   incomplete correct knowledge , which makes the   models tend to believe in the given knowledge ,   regardless of whether the knowledge is appropri-   ate or not , resulting in hallucination problems . In   addition , the knowledge retrieval system tends to   extract irrelevant knowledge rather than relevant   knowledge when the database is large , aggravating   the hallucinations ( Reimers and Gurevych , 2021 ;   Liu et al . , 2022 ) . ( 2 ) The generation of knowledge   may also face the hallucination problem and obtain   the inappropriate knowledge , leading the genera-   tion of hallucination responses ( Kim et al . , 2020 ;   Zhao et al . , 2020a ; Liu et al . , 2022 ; Adolphs et al . ,   2021 ; Bao et al . , 2022 ) .   To mitigate the hallucination problem , we pro-   pose an Augmentative and Contrastive Knowl-   edge Dialogue Expansion Framework ( ACK - DEF ) ,   which is inspirited by human communicating that   people will replay euphemistic response for the un-   recognizable knowledge . ACK - DEF is proposed   to smooth the polarized optimization objective by   augmenting training set with augmentative and con-   trastive knowledge - dialogue samples . Not only the   knowledge , we also designed the reply patterns for   the knowledge with different level of errors . For   this , we propose the augmentative knowledge dia-   logue expansion ( AK ) , and contrastive knowledge   dialogue expansion ( CK ) . AK is proposed to boost   the generalization ability of models on knowledge   with minor noise . On the contrary , inspired from   thecontrastive learning paradigm ( Cai et al . , 2020 ;   Chen et al . , 2020a , b ; Sun et al . , 2021 , 2022 ) , CK1741   reconstructs incorrect knowledge and designs eu-   phemistic responses , which aims to push the model   learn the reply pattern of incorrect knowledge and   a better boundary between correct and incorrect   knowledge .   Contributions : We propose an ACK - DEF to   construct new knowledge - dialogue samples that   consist of knowledge with different level of errors   and manual responses , to soften the training opti-   mization objectives of models , which will mitigate   the hallucination . Finally , we conduct extension   experiments to show the superior performance of   ACK - DEF on alleviating the hallucination .   2 Methodology   To mitigate the hallucination problem that caused   by the polarized optimization objectives in knowl-   edge grounded dialogue generation , we take in-   spiration from human communicating , and pro-   pose the Augmentative and Contrastive Knowl-   edge Dialogue Expansion Framework ( ACK - DEF ) .   Our ACK - DEF aims to soften the polarized train-   ing optimization objectives of current knowledge-   grounded dialogue generation methods , and guide   the dialogue system reply patterns for the knowl-   edge with different level of errors . To achieve this   end , we design two effective expansion method ,   which will be detailed in below .   2.1 Augmentative Knowledge Dialogue   We propose the Augmentative Knowledge ( AK ) dia-   logue expansion to boost the generalization ability   of the dialogue model on the knowledge with simi-   lar semantics but different expressions , which can   prevent the model from being interfered by partial-   relevant knowledge retrieved by the retrieval sys-   tems ( Lian et al . , 2019 ; Zhao et al . , 2020b ; He-   dayatnia et al . , 2020 ; Zheng et al . , 2021 ; Shuster   et al . , 2021 ; Komeili et al . , 2022 ) . As shown in Fig-   ure 1 , we employ the synonym data augmentation   tool , which replaces words in the original knowl-   edge with synonyms , to reconstruct the knowledge   information ( Miller , 1995 ) . Considering that the   synonym may disrupt the original semantics of new   constructed knowledge , we constrain the replace   possibility within [ 0.1,0.2 ] . Hence , we can ob-   tain the approximate knowledge . Combining this   knowledge and the original dialogue , we obtain the   “ ak - less sample ” . In addition , we also replace 30 %   to 50 % words with their synonyms to construct   the less similar knowledge . Inspired from prompt   learning paradigm ( Yao et al . , 2022 ; Valvoda et al . ,   2022 ; Zhao et al . , 2022b ) , we manually produce   some Prefix - prompts and Post - prompts ( see Ap-   pendix ) to ( 1 ) make the new response more tactful   for the less similar knowledge ; ( 2 ) regulate and   guide the dialogue generation process of the model .   We call the sample consist of less - similar knowl-   edge and designed response as “ ak - more sample ” .   2.2 Contrastive Knowledge Dialogue   We propose the Contrastive Knowledge ( CK ) di-   alogue expansion , inspired from the contrastive   learning paradigm ( Chen et al . , 2020b ; Cai et al . ,   2020 ) , not only construct the incorrect knowledge   as negative samples for original knowledge , but   also build the euphemistic responses as positive1742samples for the original response with incorrect   knowledge . To help the model learn a boundary   between correct and incorrect knowledge , we em-   ploy the antonym to make up new incorrect knowl-   edge . For example , given the knowledge “ nin-   tendo was founded on 23 september 1889 ... ” , the   “ founded ” will be replaced with “ abolish ” , which   greatly changes the semantics but little changes the   expression . After that , we random choose an eu-   phemistic response to replace the original response   of the dialogue . Finally , The incorrect knowledge   and the replaced euphemistic response are com-   bined as the “ ck - sample ” .   3 Experiment and Results   3.1 Experiment Settings   3.1.1 Dataset   We use the Wikipedia of Wizard ( WoW ) data ,   a well - established knowledge - grounded open-   domain dialogue dataset , for our experiment . We   pre - precess the WoW dataset and extract the single-   turn knowledge dialogue samples . To evaluate the   performance of our method in detail , we perform   four test sets : normal , ak - less , ak - more andck .   The normal set is the original test set . And the   ak - less , ak - more andckare the sets consist of   ak - less , ak - more and ck samples , respectively . We   also follow the settings of WoW data and divide   the test set into two groups ( seen test and unseen   test ): the topic of the knowledge in the unseen test   set is missing in the training set .   3.1.2 Baseline   We employ the released PLATO - v1 ( Bao et al . ,   2020 ) model , a pre - trained dialogue generation   model based on UniLM , for our experiment .   Fine - tuning We directly finetune a model on the   original WoW training set . By this , the model can   only see gold knowledge dialogue samples and gen-   eral dialogue samples without knowledge . Hence ,   we call the fine - tuned model PLATO+GOLD .   Fine - tuning with ACK - DEF We finetune the   model with the original set and the expansion sam-   ples that obtained through ACK - DEF . Thence , we   call it PLATO+ACK - DEF.3.1.3 AutoEvaluation Metrics   Dialogue Metrics Our primary metrics of inter-   est are Distinct - n ( Li et al . , 2016 ) , Response Length   ( Len . ) ( Csaky et al . , 2019 ) , BLEU ( Papineni et al . ,   2002 ) , Embedding - based ( Greedy ( GRE ) , Average   ( A VG ) , Extrema ( EXT ) ) ( Liu et al . , 2016 ) , and Co-   herence ( COH ) ( Xu et al . , 2018 ) . Distinct - n evalu-   ates the diversity of generated responses , which is   calculated through the ratio of distinct n - grams and   all generated n - grams . Len . is the average number   of words of all generated responses . BLEU vali-   dates the degree of the word - overlap between the   generated response and the ground - truth , which de-   notes the consistence between generated response   and ground - truth . Embedding - based metrics ( GRE ,   A VG and EXT ) are introduced to evaluate the se-   mantic relationship of generated responses and   ground - truth responses , illustrating the consistence   in semantic level . COH . mainly assesses the rele-   vance between contexts and generated responses .   Knowledge Metrics We follow the PLATO(Bao   et al . , 2020 ) and use the knowledge precision , recall   and f1 scores . These metrics are used to calculate   the ratio of tokens that exist in common in ground-   truth knowledge and generated responses to tokens   in generated responses . “ Recall ” is the average   ratio of the number of overlapping tokens in re-   sponse and knowledge to the number of tokens in   knowledge . And “ Precision ” is the average ratio   of the number of overlapping tokens to the num-   ber of tokens in response . In other words , “ Recall ”   indicates how much knowledge information is con-   tained in the response , while “ Precision ” indicates   the proportion of knowledge information in the re-   sponse . Even we involve the negative and incorrect   knowledge in response generation , we still use the   ground - truth knowledge to calculate the metrics in   Table 3,4 .   3.2 Dialogue Performance Analysis   Table 1 and Table 2 report the automatic results   on four test sets and four unseen test sets , respec-   tively . In these Tables , it can be observed that   ( 1 ) the PLATO+ACK - DEF has a competitive per-   formance with PLATO+GOLD on the normal set ,   which means that the PLATO+ACK - DEF can rec-   ognize the golden knowledge and produce appro-   priate responses . ( 2 ) the PLATO+GOLD perform   worse than PLATO+ACK - DEF on ak - less , which   means that the robustness of the dialogue model   only trained with golden knowledge is very weak.1743   Even if the knowledge information only changes   by 10 % to 20 % , the performance of the model willsignificantly decline , especially consistency met-   rics ( i.e. BLEU , GRE , A VG and EXT ) . ( 3 ) the   PLATO+GOLD achieve better Distinct scores but   weaker BLEU and embedding - based scores , which   means that the PLATO+GOLD is easy to generate   responses that are very different from ground - truth   responses , that is , the hallucinations .   3.3 Knowledge Correlation Analysis   Table 3 and Table 4 report the knowledge correla-   tion result of PLATO+GOLD and PLATO+ACK-   DEF on four test sets and four test unseen sets ,   respectively . From these table , we can observe   that the performance of PLATO+GOLD is reduced   when the given knowledge changed , which illus-   trates the danger that the model generate responses   based on incorrect knowledge . In addition to the   above findings , we also observed that the recall , pre-   cision and f1 scores of PLATO+ACK - DEF are bet-   ter than PLATO+GOLD on ak - less andak - more   sets , which demonstrates that using ACK - DEF ef-   fectively enhance the model ’s capability for the   similar knowledge information . Moreover , the re-   sult of PLATO+ACK - DEF on the ckset is signif-   icantly reduced , which shows that the model dis-   tinguishes the wrong knowledge constructed with   antonyms and gives an appropriate response with-1744   out knowledge ( see Table 1 and Table 2 for the   effect ) . These results are inline with our exception   that incorporating noised knowledge dialogue sam-   ples in training stages can smooth the polarized   optimization objective , and mitigate the hallucina-   tion problem .   According to the results of test seen sets and   unseen sets ) , we can notice that the PLATO+ACK-   DEF achieves a good performance on ground-   truth seen knowledge and a weak performance on   ground - truth unseen knowledge . This illustrates   that the PLATO+ACK - DEF may doubt the authen-   ticity of unseen given knowledge ( even if the knowl-   edge is the ground - truth ) , and will not fully use   it to generate responses . This may alleviate the   hallucination , and we believe it is caused by ( 1 )   the Augmentative knowledge dialogue introduce   similar knowledge to improve the generalization   of the model ; ( 2 ) the Contrastive knowledge dia-   logue introduce knowledge independent responses ,   which tell the model to generate responses without   knowledge ; ( 3 ) the ACK - DEF smooths the polar-   ized optimization , which ensure the model not to   directly use the given knowledge .   3.4 Human Evaluation   To further evaluation the ability of our ACK - DEF   on reducing the hallucination problem , we ran-   domly select 400 samples form four test sets , and   hire three annotators to do human evaluations by as-   sessing whether the responses generated by PLATO   + GOLD and + ACK - DEL have hallucinations . Ta-   ble 5 reports the results of human evaluation , from   which we can notice that the PLATO+ACK - DEF   generate less hallucinations than PLATO+GOLD .   This shows the effectiveness of our ACK - DEF .   3.5 Case Study   Table 6 shows a generated case of PLATO+GOLD   ( GOLD ) and PLATO+ACK - DEF ( ACK - DEF )   based on different knowledge information . We can   observed that the GOLD is convinced of the given   knowledge , regardless of whether the knowledge   is appropriate or not , and more easily to copy the   knowledge information into responses . Even the   GOLD has seen the knowledge topic , it could not   remember the knowledge in their parameters . On   the contrary , the ACK - DEF has good resistance to   incomplete correct knowledge .   4 Conclusion   This paper focuses on the hallucinations caused   by polarized optimization objective in knowledge-   grounded dialogue generation ( KGDG ) , and pro-   poses an augmentative and contrastive knowledge   dialogue expansion framework ( ACK - DEF ) to mit-   igate it . The optimization objective of KGDG is to   train the model could generate proper response with   or without knowledge , which inevitably weaken   the model ’s ability on unrecognized knowledge   and lead hallucinations . Therefore , ACK - DEF con-   structs multiple level knowledge - dialogue samples   to soften the optimization objective of KGDG . Ex-   tension experimental results show the superior per-   formance of using our methods on dialogue metrics   and knowledge correlations.1745Limitations   Our limitations are as follow :   •Data Scale : This paper only employ the   Wikipedia of Wizard dataset , a small scale   and well - established knowledge conversation   dataset , and lack of the validation on large-   scale dataset .   •Backbones : This paper lacks the evaluat-   ing of other knowledge dialogue model on   the proposed method . Actually , we have   two reasons to employ the PLATO . First , the   PLATO can better handle the one - to - many   phenomenon , which is suitable for learning   our expansion samples . Second , the PLATO   is a pre - trained dialogue model , and its perfor-   mance on knowledge dialogue generation task   has been proved . We will evaluating the per-   formance of other knowledge dialogue model   on our method for our future work .   •Knowledge Expansion Methods : This pa-   per only use the synonym and antonym to   construct the noised knowledge , which lacks   of the comparison of using other data aug-   ment method . Indeed , we use two token-   level data augmentation methods ( synonym   and antonym augmentation ) to prove our state-   ments on hallucination problem in knowledge-   dialogue generation task . Based on this study ,   we believe that incorporating other data aug-   mentation methods will also mitigate the hal-   lucinations .   •Manual Prompts and Responses : This   paper designed five prefix prompts , four   post - prompts and nineteen euphemistic re-   sponses . For AK - More method , we simply   randomly choose one prefix - prompt and one   post - prompt and concatenate them with the   ground - truth response . This leads to some   irregular responses . As for CKmethod , we   randomly select one euphemistic response for   the incorrect knowledge . However , we found   that the response may not coherent with the   query . We will design more smooth expansion   ways to construct more human - like training   samples for our future work .   Ethics Statement   We acknowledge and ensure that our study is   compatible with the provided Code of Ethics . Knowledge - grounded open - domain dialogue gen-   eration is crucial for building a knowledgeable dia-   logue system , which is beyond the wildest dreams   in natural language process field . All our experi-   ments are conducted on public available datasets   to avoid ethical concerns . All terms for using these   datasets are strictly followed in our study . There   are no direct ethical concerns in our research .   Acknowledgments   We would like to thank the anonymous reviewers   for their constructive comments . This research   is supported by Beijing Natural Science Foun-   dation ( No.4222037 and L181010 ) and BIT Re-   search and Innovation Promoting Project ( Grant   No.2022YCXY021 ) . Kan Li is the corresponding   author .   References17461747   A Prefix and Post Prompts   We manually design five prefix prompts and four   post prompts , which are shown in Table 7 . We   discuss below about the prefixes and posts .   We designed the prefixes and posts based on the   WoW dataset and our daily conversation habits . In   WoW dataset , one role is “ 0_Wizard ” , and the otheris “ 1_Apprentice ” . We noticed that the 1_Appren-   tice will give the sentences such as “ correct my   if I am wrong . . . ” , which is also easy to appear   in our daily conversation . Taking inspiration of   this , we manually designed the prefixes and posts .   Moreover , since the PLATO is pre - trained on con-   versation datasets , these prefixes may introduce the   pre - knowledge that the model learned during the   pre - training process .   In fact , we declare the weakness of our man-   ual prefixes and posts , i.e. direct connections of   prefixes , responses , and posts do not fit all con-   texts . Therefore , we are exploring a new way of   constructing replies , such as passing the design   prefix , response , post , and context into the large-   language - model to rewrite the appropriate response .   We believe that better prefixes and posts will lead to   more benefits in solving the hallucination problem .   B Euphemistic Responses   We manually design nineteen euphemistic re-   sponses , which are shown in Table 8 .   C Dissuasion about the boundary   between ak - less and ak - more   Below we provide an example in our dataset :   •Ground - truth Knowledge : laziness | tesis ( "   thesis " ) is a 1996 spanish thriller film .   •AK - Less Knowledge : acedia | tesis ( " thesis " )   is a 1996 spanish thriller film .   •AK_More Knowledge : laziness | tesis ( " the-   sis " ) personate a 1996 spanish thriller picture   show .   It can be noted that the more synonyms are intro-   duced into a sentence , the semantics of the sentence   will become more and more different from the orig-   inal semantics . Therefore , we suppose that replac-   ing at least 30 % of words at once will make a big   difference in sentence semantics . Then , we decided   the boundary between ak - less and ak - more.1748ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   We provide a section of Limitations after the Conclusion and before the Ethics Statement   /squareA2 . Did you discuss any potential risks of your work ?   Not applicable . Left blank .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   1   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   Left blank .   /squareB1 . Did you cite the creators of artifacts you used ?   Not applicable . Left blank .   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   Not applicable . Left blank .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   Not applicable . Left blank .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   We use a publicly well - established dataset .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Not applicable . Left blank .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   Left blank .   C / squareDid you run computational experiments ?   3   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   We use the released code and checkpoints . We cite the source of our model.1749 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   Not applicable . Left blank .   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   Not applicable . Left blank .   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   3   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   3   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   Not applicable . Left blank .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   Not applicable . Left blank .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   2   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   Not applicable . Left blank .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   Not applicable . Left blank.1750