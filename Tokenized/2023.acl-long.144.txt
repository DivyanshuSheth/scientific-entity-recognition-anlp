  Heyan Chai , Jinhao Cui , Ye Wang , Min Zhang , Binxing Fangand Qing LiaoHarbin Institute of Technology , Shenzhen , ChinaNational University of Defense Technology , ChinaPeng Cheng Laboratory , Shenzhen , China   { chaiheyan,cuijinhao}@stu.hit.edu.cn , ye.wang@nudt.edu.cn   zhangmin2021@hit.edu.cn , fangbx@cae.cn , liaoqing@hit.edu.cn   Abstract   Multi - task learning ( MTL ) has emerged as   a promising approach for sharing inductive   bias across multiple tasks to enable more ef-   ﬁcient learning in text classiﬁcation . How-   ever , training all tasks simultaneously often   yields degraded performance of each task than   learning them independently , since different   tasks might conﬂict with each other . Exist-   ing MTL methods for alleviating this issue is   to leverage heuristics or gradient - based algo-   rithm to achieve an arbitrary Pareto optimal   trade - off among different tasks . In this paper ,   we present a novel gradient trade - off approach   to mitigate the task conﬂict problem , dubbed   GetMTL , which can achieve a speciﬁc trade-   off among different tasks nearby the main ob-   jective of multi - task text classiﬁcation ( MTC ) ,   so as to improve the performance of each task   simultaneously . The results of extensive exper-   iments on two benchmark datasets back up our   theoretical analysis and validate the superior-   ity of our proposed GetMTL .   1 Introduction   Multi - task Learning ( MTL ) , which aims to learn   a single model that can tackle multiple correlated   but different tasks simultaneously , makes multi-   ple tasks beneﬁt from each other and obtain supe-   rior performance over learning each task indepen-   dently ( Caruana , 1997 ; Ruder , 2017 ; Liu et al . ,   2015 ; Mao et al . , 2020 ) . By discovering shared   information / structure across the tasks , it has gained   attention in many areas of research and industrial   communities , such as computer vision ( Misra et al . ,   2016 ; Gao et al . , 2019 ; Yogamani et al . , 2019 ; Sun   et al . , 2020 ) and text classiﬁcation ( Liu et al . , 2017 ;   Xiao et al . , 2018 ; Mao et al . , 2021 , 2022 ) .   However , it is observed in multi - task text clas-   siﬁcation ( MTC ) scenarios that some tasks could   conﬂict with each other , which may be reﬂected via   conﬂicting gradients or dominating gradients ( Yu   Figure 1 : Graphical interpretation of existing Pareto   multi - task learning methods for a two - task learning   problem . ( a ) Pareto optimal solutions are arbitrary and   uncontrollable . ( b ) Our GetMTL can ﬁnd the speciﬁc   solutions nearby the main objective ( Average loss ) .   et al . , 2020 ; Vandenhende et al . , 2022 ) , leading   to the degraded performance of MTL due to poor   training . How to make a proper trade - off among   jointing different tasks in MTC is a difﬁcult prob-   lem . Recently , several methods have been proposed   to mitigate gradient conﬂicts issue via both loss   balance ( linear weighted scalarization ) such as ho-   moscedastic uncertainty ( Kendall et al . , 2018 ) and   task variance regularization ( Mao et al . , 2021 ) , and   gradient balance like Pareto optimality ( Sener and   Koltun , 2018 ; Mao et al . , 2020 ) . Existing meth-   ods devote to ﬁnding an arbitrary Pareto optimality   solution in the Pareto set , which achieve a single   arbitrary trade - off among all tasks . However , they   can only satisfy the improved performance on part   of tasks , not all tasks simultaneously . This means   that these methods can not converge to a minimum   average loss of all objectives .   To illustrate our idea , we give a two - task learn-   ing example shown in Figure 1 . As shown in Fig-   ure ( 1a ) , it is observed that Pareto optimality - based   methods can generate a set of Pareto solutions for   a given two - task learning problem . However , some   of Pareto solutions can increase the task 1 error   while decreasing task 2 error , leading to unsatisfac-   tory overall performance for MTL model . This im-2565plies that not all Pareto solutions always satisfy the   goal of mitigating the tasks conﬂicts in MTL , and   thus failing to achieve a better trade - off between   tasks . Therefore , it is necessary to ﬁnd a speciﬁc   trade - off between tasks that is beyond what only   using Pareto optimality can achieve .   To address this issue , inspired by multi - objective   optimization ( Sener and Koltun , 2018 ) , we argue   that a more efﬁcient way to mitigate task conﬂicts   is to ﬁnd a gradient trade - off between tasks in the   neighborhood of the average loss rather than ex-   haustively searching for a proper solution from the   set of Pareto solutions . As shown in Figure 1b ,   the Pareto solutions nearby the average loss can   achieve a better trade - off between task 1 andtask 2 ,   leading to better performance on both tasks at the   same time . Based on it , in this paper , we propose   a novel gradient trade - off multi - task learning ap-   proach , named GetMTL , to mitigate task conﬂicts   in multi - task text classiﬁcation . Speciﬁcally , the   gradients of each task are utilized to derive an up-   date vector that can minimize the conﬂicts among   task gradients in the neighborhood of the average   gradient , so as to achieve a better trade - off perfor-   mance among joint training tasks . In summary , the   main contributions of our work are as follows :   •A novel multi - task learning approach based   on gradient trade - off between different tasks   ( GetMTL ) is proposed to deal with task con-   ﬂict in multi - task text classiﬁcation problems ,   so as to improve the performance of all tasks   simultaneously .   •We give in - depth theoretical proofs and ex-   perimental analyses on establishing converge   guarantees of our GetMTL .   •We extensively verify the effectiveness of our   GetMTL on two real - world text classiﬁca-   tion datasets , and the results show that our   GetMTL performs competitively with a vari-   ety of state - of - the - art methods under a differ-   ent number of task sets .   2 Related Works   Multi - task Learning methods jointly minimize all   task losses based on either loss balance meth-   ods ( Kendall et al . , 2018 ; Chen et al . , 2018 ;   Mao et al . , 2021 , 2022 ) or gradient balance meth-   ods ( Sener and Koltun , 2018 ; Mao et al . , 2020 ) .   The loss balance methods adaptively adjust the   tasks weights during training based on various   heuristic approaches , such as task uncertainty quan - tiﬁcation ( Kendall et al . , 2018 ) , gradient normal-   ization ( Chen et al . , 2018 ) , task difﬁculty pri-   oritization ( Guo et al . , 2018 ) , dynamic weight   average ( Liu et al . , 2019 ) , random loss weight-   ing ( Lin et al . , 2021 ) , task variance regulariza-   tion ( Mao et al . , 2021 ) , and meta learning - based   approach ( Mao et al . , 2022 ) . These methods are   mostly heuristic and can have unstable performance   while ignoring the task conﬂicts among all tasks ,   leading to the bad generalization performance of   MTL models .   Recently , some gradient balance based methods   have been proposed to mitigate task conﬂicts for im-   proving task performance . For example , Désidéri   ( 2012 ) leverages multiple - gradient descent algo-   rithm ( MGDA ) to optimize multiple objectives .   Due to the guarantee of convergence to Pareto sta-   tionary point , this is an appealing approach . Sener   and Koltun ( 2018 ) cast the multi - objective problem   as a multi - task problem and devote to ﬁnding an   arbitrary Pareto optimal solution . Mao et al . ( 2020 )   propose a novel MTL method based Tchebycheff   procedure for achieving Pareto optimal without any   convex assumption . However , these methods only   consider achieving an arbitrary Pareto optimal solu-   tion while it is not the main objective . Unlike these   methods , we propose an MTL approach based on   multi - objective optimization and seek to ﬁnd a set   of solutions that are Pareto optimality and nearby   the main MTC objective L.   3 Preliminaries   Consider a multi - task learning problem with T   tasks over an input space Xand a collection of   task spaces{Y } , where each task contains a   set of i.i.d . training samples D={x , y } ,   Tis the number of tasks , and nis the num-   ber of training samples of task t. The goal of   MTL is to ﬁnd parameters { θ , θ, ... ,θ}of a   modelFthat can achieve high average perfor-   mance across all training tasks over X , deﬁned   asF(X , θ,···,θ ) :X → Y , whereθde-   notes the parameters shared between tasks and θ   denotes the task - speciﬁc parameters of task t. In   particular , we further consider a parametric task-   speciﬁc map as f(·,θ , θ ) :X → Y. We   also consider task - speciﬁc loss functions /lscript ( · , · ) :   Y×Y→R. We also denote the multi - task loss   asL(θ ) = /summationtext / lscript(θ ) , and the gradients of each task2566asg=∇/lscript(θ)for the particular θ . In this paper ,   we choose the average loss as main objective of   MTC problem , deﬁned as L(θ ) = /summationtext / lscript(θ ) .   3.1 MTL as Multi - objective Optimization   MTL can be formulated as a speciﬁc case of   multiple - objective optimization ( MOO ) , which   optimizes a set of potentially conﬂicting objec-   tives ( Sener and Koltun , 2018 ; Mao et al . , 2020 ) .   Given objective functions of Ttasks,/lscript, ... ,/lscript ,   we formulate the optimization objective of MTL as   the vectors of objective values :   min / parenleftBig   /lscript(θ , θ), ... ,/lscript ( θ , θ)/parenrightBig   ( 1 )   Since there is no natural linear ordering on vectors ,   it is not possible to compare solutions and thus no   single solution can optimize all objectives simulta-   neously . In other words , there is no clear optimal   value . Alternatively , we can achieve Pareto opti-   mality to obtain different optimal trade - offs among   all objectives to solve MOO problem .   Deﬁnition 1 ( Pareto dominance ) .Given two points   { θ , θ}inΩ , a pointθPareto dominates θ(θ / precedesorcurlyθ )   for MTL if two conditions are satisﬁed :   ( i)No one strictly prefers θtoθ , that is,∀i∈   { 1, ... ,T},/lscript(θ , θ)≤/lscript(θ , θ ) .   ( ii)At least one point strictly prefers θtoθ , that   is,∃j∈{1, ... ,T},/lscript(θ , θ)</lscript(θ , θ ) .   Deﬁnition 2 ( Pareto optimality ) .θis a Pareto op-   timal point and /lscript(θ)is a Pareto optimal objective   vector if it does not exist ˆθ∈Ωsuch that ˆθ / precedesorcurlyθ .   That is , a solution that is not dominated by any   other is called Pareto optimal .   The set of all Pareto optimal solutions is called   the Pareto set , and the image of Pareto set in the   loss space is called Pareto front ( Lin et al . , 2019 ) .   In this paper , we focus on gradient - based multi-   objective optimization to achieve an appropriate   Pareto trade - off among all tasks , which can approx-   imate the Pareto front that minimizes the average   loss .   3.2 Gradient - based Multi - Objective   Optimization   Gradient - based MOO ( Sener and Koltun , 2018 )   aims to ﬁnd a direction dthat we can iteratively   ﬁnd the next solution θthat dominates the   previous one θ(/lscript(θ)≤/lscript(θ ) ) by movingagainstdwith step size η , i.e.θ = θ−ηd .   Désidéri ( 2012 ) ; Sener and Koltun ( 2018 ) propose   to use multiple gradient descent algorithm ( MGDA )   that converges to a local Pareto optimal by itera-   tively using the descent direction d , which can be   obtained as follows :   d= arg minα+1   2 / bardbld / bardbl   s.t.∇/lscript(θ)d≤α , i = 1, ... ,T.(2 )   wheredis the direction that can improve all tasks .   Essentially , gradient - based MOO methods mini-   mize the loss by combining gradients with adaptive   weights , and obtaining an arbitrary Pareto optimal-   ity solution , ignoring the true objective ( the average   loss ) ( Liu et al . , 2021 ) . In this paper , we generalize   this method and propose a novel gradient - based   approach to achieve a gradient trade - off among   tasks for mitigating task conﬂicts , as well as con-   strain the solution that can minimize the average   loss ( L(θ ) ) .   4 Gradient Trade - offs for Multi - task   Text Classiﬁcation   Following most MTL methods , as shown in Fig-   ure 2 , we employ the hard parameter sharing MTL   architecture , which includes fparameterized by   heavy - weight task - shared parameters θandfpa-   rameterized by light - weight task - speciﬁc parame-   tersθ . All tasks take the same shared intermediate   featurez = f(x;θ)as input , and the t - th task-   speciﬁc network outputs the prediction as f(z;θ ) .   Since task - shared parameters θare shared by all   tasks , the different tasks may conﬂict with each   other , leading to the degraded performance of MTL   model . In this paper , we hypothesize that one of the   main reasons for task conﬂicts arises from gradi-   ents from different tasks competing with each other   in a way that is detrimental to making progress .   We propose a novel gradient - based MOO optimiza-   tion to ﬁnd a gradient trade - off among tasks in the   neighborhood of the average loss , so as to mitigate   task conﬂicts . Note that , we omit the subscript   shof task - shared parameters θfor the ease of   notation .   4.1 GetMTL   Given a task i , we deﬁne its gradient as g=   ∇/lscript(θ)via back - propagation from the raw loss /lscript ,   andgrepresents the optimal update direction for   taski . However , due to the inconsistency of the2567   optimal update direction of task - shared parameters   for each task , different task gradients may conﬂict   with each other , leading to the training of networks   being stuck in the over - training of some tasks and   the under - training of other tasks . Intuitively , it is de-   sirable to ﬁnd a direction that can minimize the task   conﬂicts among different tasks as well as achieve   Pareto optimality to improve the performance of   MTL model .   We ﬁrst achieve an arbitrary Pareto optimal via   ﬁnding a descent direction dby searching for   a minimum - norm point in the Convex HullCHof   gradients , deﬁned by ,   CH:={Gβ|β∈S } , ( 3 )   s.t . S=/braceleftbigg   β∈R / vextendsingle / vextendsingle / summationdisplayβ= 1 / bracerightbigg   ( 4 )   whereG∈R={g, ... ,g}is the matrix   of task gradient , Sis theT - dimensional regular   simplex . We use the multiple gradient descent algo-   rithm ( MGDA ) ( Sener and Koltun , 2018 ) to obtain   an arbitrary Pareto optimal by iteratively using the   descent direction , deﬁned by ,   d= arg min / bardbld / bardbl ( 5 )   In addition , the dcan be reformulated as a linear   combination of all task gradients , deﬁned by ,   d=/summationdisplayβg ( 6 )   whereg=∇/lscript(θ)is thei - th task gradient . It   implies that , when converges to an arbitrary Pareto   optimal , the optimal gradient value of each task via   back - propagation is βg , deﬁned asg = βg . However , moving against ddoes not guar-   antee that the solution meets the requirements of   multi - task text classiﬁcation task ( MTC ) , that is , to   alleviate the gradient conﬂict among tasks in MTC ,   so as to improve the performance of all tasks . To   address this issue , we seek a direction that enables   us to move from a solution θtoθsuch that   bothθdominatesθ(L(θ)≤L(θ ) )   and alleviate the gradient conﬂict among all tasks .   Based on it , as shown in Figure 2(b ) , we propose   to search for an update direction din the Convex   HullCHof back - propagation gradients such that   it can improve any worst objective and converge   to an optimum of MTC objective L(θ ) . We ﬁrst   ﬁnd the worst task gradient with respect to the up-   date direction d , that is , it has a maximum angle   withd , which can be formulated via the following   optimization problem ,   min / angbracketleftg , d / angbracketright , s.t.−gd≤0,i= 1, ... ,T ( 7 )   wheregis thei - task gradient after optimizing by   MGDA algorithm .   To improve the worst gradient of any task and   achieve a trade - off between all task gradients in   a neighborhood of the average gradient ( deﬁned   asg=/summationtextg ) , we formulate this gradient   trade - off optimization problem via the following   Maximin Optimization Problem ( dual problem ) .   Problem 1 .   maxmin / angbracketleftg , d / angbracketright   s.t./bardbld−g / bardbl≤εgd ,   −gd≤0(8 )   whereg = βgis the back - propagation gradient   value ofi - th task via solving Eq . ( 5 ) , ε∈(0,1]is a   hyper - parameter that controls the stability of MTC   model .   4.2 Solving Maximin Problem   Since the optimal direction dcan also be deﬁned in   the convex hullCHofg , we can get   CH:={Gw|w∈W } , ( 9 )   whereG∈R={g, ... ,g}is task gradi-   ent matrix , W={w∈R / vextendsingle / vextendsingle / summationtextw= 1}is   theT - dimensional probability simplex , and w=   ( w, ... ,w ) . Therefore , we can get min / angbracketleftg , d / angbracketright=   min / angbracketleft / summationtextwg , d / angbracketrightand Problem 1 can be   transformed into the following form.2568Algorithm 1 : GetMTL Algorithm .   Input : The number of task T , loss functions   { /lscript } , network parameters θattstep , the   pre - speciﬁed hyper - parameter ε∈(0,1]and   step sizeµ∈R.Task Gradients : g=∇/lscript(θ),i∈[T]Main Objective : g=/summationtextgObtain{β, ... β}by solving Eq.(5).Computeg=/summationtextwg , whereg = βgObtain{w, ... ,w}by solving Eq.(14)Find direction dby using Eq.(13 )   Output : θ=   θ−µ/parenleftBig+/parenrightBig   .   Problem 2 .   maxmin / angbracketleftg , d / angbracketright   s.t./bardbld−g / bardbl≤εgd,(10 )   whereg=/summationtextwgis the convex combina-   tion inCH . For a given vector λ∈Rwith   non - negative components , the corresponding La-   grangian associated with the Eq.(10 ) is deﬁned as   maxmingd−λ(/bardbld−g / bardbl−ε(gd))/2   ( 11 )   Since the objective for dis concave with linear con-   straints andw∈Wis a compact set , according   to the Sion ’s minimax theorem ( Kindler , 2005 ) , we   can switch the max andminwithout changing the   solution of Problem 2 . Formally ,   minmaxgd−λ / bardbld−g / bardbl/2+λε(gd)/2   ( 12 )   We get the optimal solution of primal problem   ( Problem 1 ) by solving the dual problem of Eq.(12 )   ( See the Appendix A for a detailed derivation pro-   cedure ) . Then we have   d = g+λg   ( 1−εg)λ , whereλ=/bardblg / bardbl   ε / bardblg / bardbl(13 )   whereλis the optimal Lagrange multiplier , dis   the optimal update direction of MTC model . We   can reformulate the problem of Eq.(12 ) as follow-   ing optimization problem w.r.t . w.   minJ(w ) = gg+ε / bardblg / bardbl / bardblg / bardbl   1−ε / bardblg / bardbl(14 )   wheregis deﬁned as g=/summationtextwg . The   detailed derivation is provided in Appendix A. Al-   gorithm 1 shows all the steps of GetMTL algorithm   in each iteration .   4.3 Theoretical Analysis   In this section , we analyze the equivalence of so-   lutions to dual problem and then give a theoretical   analysis about convergence of GetMTL algorithm .   We deﬁne the Lagrangian of problem in Eq.(10 ) ,   L(d , λ , w ) = gd−λ   2(/bardbld−g / bardbl−ε(gd ) )   Theorem 4.1 ( Equivalence of Optimal Value   of Dual Problem ) .Assume that both pri-   mal problem and dual problem have optimal   values , let p= maxminL(d , λ , w )   andq= minmaxL(d , λ , w ) .   Then , p= maxminL(d , λ , w ) ≤   minmaxL(d , λ , w ) = q.   Proof . The proof is provided in Appendix B. /squaresolid   Theorem 4.2 ( Convergence of GetMTL ) .Assume   loss functions /lscriptare convex and differential , and   ∇/lscript(θ)is L - lipschitz continuous with L>0 . The   update rule is θ = θ−µd , wheredis   deﬁned in Eq.(13 ) and µ= min . All   the loss functions / parenleftbig   /lscript(θ)···/lscript(θ)/parenrightbig   converges   to(/lscript(θ)···/lscript(θ ) ) .   Proof . The proof is provided in Appendix C. /squaresolid   5 Experimental Setup   5.1 Experimental Datasets   We conduct experiments on two MTC benchmarks   to evaluate the proposed GetMTL . 1 ) Amazon Re-   view dataset ( Blitzer et al . , 2007 ) contains prod-   uct reviews from 14 domains ( See Details in Ap-   pendix D ) , including apparel , video , books , elec-   tronics , DVDs and so on . Each domain gives rise to   a binary classiﬁcation task and we follow Mao et al.2569   ( 2021 ) to treat 14 domains in the dataset as distinct   tasks , creating a dataset with 14 tasks , with 22180   training instances and 5600 test instances in to-   tal . 2 ) Topic classiﬁcation dataset , 20 Newsgroup ,   consists of approximately 20,000 newsgroup docu-   ments , partitioned evenly across 20 different news-   groups . We follow Mao et al . ( 2021 ) to select 16   newsgroups from 20 Newsgroup dataset shown in   Table 1 and then divide them into four groups . Each   group gives rise to a 4 - way classiﬁcation task , cre-   ating a dataset with four 4 - way classiﬁcation tasks ,   which is a more challenging dataset than amazon   review dataset.5.2 Experimental Implementation   We follow the standard MTC setting and adopt the   same network architectures with the most recent   baselines for fair comparisons ( Mao et al . , 2021 ) .   We adopt the hard parameter sharing MTL frame-   work shown in Figure 2 , where task - shared network   is a TextCNN with kernel size of 3,5,7 and task-   speciﬁc network is a fully connected layer with a   softmax function . Adam is utilized as the optimizer   to train the model over 3000 epochs with a learning   rate of 1e-3 for both sentiment analysis and topic   classiﬁcation . We set the batch size to 256.2570   5.3 Comparison Models   We compare the proposed GetMTL with a series of   MTC baselines , including   Single - Task Learning ( STL ): learning each   task independently .   Uniform Scaling : learning tasks simultaneously   with uniform task weights .   Uncertainty : using the uncertainty weighting   method ( Kendall et al . , 2018 ) .   GradNorm : learning tasks simultaneously with   gradient normalization method ( Chen et al . , 2018 ) .   TchebycheffAdv : using adversarial Tcheby-   cheff procedure ( Mao et al . , 2020 ) .   MGDA : using gradient - based multi - objective   optimization method ( Sener and Koltun , 2018 ) .   BanditMTL : learning tasks simultaneously   with multi - armed bandit method ( Mao et al . , 2021 ) .   MetaWeighting : using adaptive task weighting   method ( Mao et al . , 2022).6 Experimental Results   6.1 Main Results   The main comparison results of GetMTL on two   benchmark datasets are shown in Figure 3 and 4 . It   is clear that ( See detailed numerical comparison re-   sults in Appendix D ) , our proposed GetMTL model   performs consistently better than the all compar-   ison methods on all tasks of both amazon review   and topic classiﬁcation datasets , and its average per-   formance is superior to that of all baselines . This   veriﬁes the effectiveness of our GetMTL method   in MTC problem . More concretely , in compar-   ison with the gradient - based MOO optimization   model ( MGDA ) , our GetMTL achieves signiﬁcant   improvement across all datasets . This indicates   that achieving a gradient trade - off nearby average   loss to mitigate task conﬂicts can better improve   all task performance and generalization ability of   MTC model.2571   6.2 Empirical Analysis on Convergence   In Section 4.3 , we theoretically prove the con-   vergence of our proposed GetMTL . Furthermore ,   we conduct extensive experiments about the con-   vergence to better demonstrate the advantages of   GetMTL shown in Figure 5 . It is clear that the   learning curve of GetMTL is constantly decreasing   as the number of iterations increases and converges   to the lowest loss value compared with other base-   lines . It indicates that GetMTL can guarantee the   convergence of the objective value and obtain better   performance of all learning tasks .   In addition , we also conduct extensive experi-   ments to investigate how GetMTL mitigates task   conﬂict during training . We plot the task variance   ( variance between the task - speciﬁc losses ) of all   baselines on both amazon review and topic clas-   siﬁcation datasets shown in Figure 6 . It can be   observed that all MTL baselines have lower task   variance than STL method , which illustrates that   MTL methods can indeed boost the learning of   all tasks compared with STL method . Moreover ,   GetMTL has the lowest task variance and smoother   evolution during training than other MTL baselines .   This implies that our proposed GetMTL indeed   mitigates task conﬂicts compared with other MTL   methods.6.3 The Evolution of Task Weight w   In this section , we visualize the task weights of   our GetMTL and two weight adaptive MTL meth-   ods ( MGDA and BanditMTL ) throughout the train-   ing process using the topic classiﬁcation dataset   shown in Figure 7 . It can be observed from these   four ﬁgures that the weight adaption process of our   GetMTL is different from that of MGDA and Ban-   ditMTL . GetMTL can automatically learn the task   weights without pre - deﬁned heuristic constraints .   The weights adaption process of GetMTL is more   stable and the search space is more compact com-   pared with other MTL baselines .   6.4 Impact of the Values of ε   To investigate the impact of using different values   ofεon the performance of our GetMTL , we con-   duct experiments on two datasets , and the results   are shown in Figure 8 . Noting that model with   ε= 0.0075 andε= 0.025perform overall better   than other values on these two datasets , respec-   tively . The model with larger value of εperforms   unsatisfactorily overall all tasks on two datasets ,   one possible reason is that larger εmakesdpull far   away from the average loss g(see the conditions   in Eq . ( 9 ) ) . That is , Pareto optimality found by   GetMTL is getting further and further away from   MTC objectiveL , which can be quite detrimental   to some tasks ’ performance , leading to degraded   average performance .   7 Conclusion   In this paper , we propose a novel gradient trade-   off multi - task learning approach to mitigate the   task conﬂict problem , which can achieve a speciﬁc   trade - off among different tasks nearby the main   objective of multi - task text classiﬁcation problem .   Moreover , we present a series of theoretical proofs   to illustrate the effectiveness and superiority of our   GetMTL . Experimental results on two benchmark2572datasets show that our GetMTL achieves state - of-   the - art performance in Multi - task Text Classiﬁca-   tion problem .   Limitations   Our GetMTL needs to compute the gfor each   taskiat each iteration and requires a backward-   propagation procedure over the model parameters .   Every iteration requires one forward - propagation   followed by Tbackward - propagation procedure   and computation of backward - propagation is typi-   cally more expensive than the forward - propagation .   Here , we deﬁne the time of one forward pass and   one backward pass as EandE , respectively .   The time of optimization process is deﬁned as E.   Therefore , the total time Eof GetMTL is deﬁned ,   E = E+TE+E   ≈TE+E   For few - task learning scenario ( T < 100 ) , usually   E / lessmuchEand GetMTL still works ﬁne . How-   ever , for large - scale task set ( like T / greatermuch100 ) , usu-   allyE / greatermuchEorE / greatermuchTE . Consequently , our   GetMTL may get stuck in the optimization and   backward - propagation process at each iteration .   Therefore , the major limitation of our work is that   it can not be applied to scenarios with large - scale   task sets .   Acknowledgements   This work was supported by the National Natu-   ral Science Foundation of China ( No . 62076079 ) ,   Guangdong Major Project of Basic and Applied   Basic Research ( No.2019B030302002 ) , The Ma-   jor Key Project of PCL(Grant No . PCL2022A03 ) ,   and Guangdong Provincial Key Laboratory   of Novel Security Intelligence Technologies   ( 2022B1212010005 ) .   References25732574A Derivations of GetMTL Algorithm   Lemma A.1 . Letdbe the solution of   maxmin / angbracketleftg , d / angbracketright , s.t./bardbld−g / bardbl≤εgd,(15 )   whereε∈(0,1],{g∈R|∀i∈{0,1, ... ,T } } ,   andg = βg∈R. Then we have   d=/parenleftbiggg   1−ε / bardblg / bardbl+ε / bardblg / bardblg   ( 1−ε / bardblg / bardbl)/bardblg / bardbl / parenrightbigg   ,   ( 16 )   whereg=/summationtextg , andg=/summationtextwg .   Thewis the solution of   minJ(w ) = gg+ε / bardblg / bardbl / bardblg / bardbl   1−ε / bardblg / bardbl,(17 )   whereW={w∈R / vextendsingle / vextendsingle / summationtextw= 1 } . We   have ,   mingd = gg+ε / bardblg / bardbl / bardblg / bardbl   1−ε / bardblg / bardbl . ( 18 )   Proof . We ﬁrst construct Lagrange function of the   objective in Eq.(10 ) ,   L(d , λ , w ) = gd−λ(/bardbld−g / bardbl−ε(gd))/2   ( 19 )   According the Lagrange duality and Sion ’s mini-   max theorem ( Kindler , 2005 ) , we can switch the   max andminwithout changing the solution and   then the primal problem can be reformulated as   following form ,   minmaxgd−λ(/bardbld−g / bardbl−ε(gd))/2   ( 20 )   Withλ , w ﬁxing , we ﬁrst solve the max of   L(d , λ , w ) w.r.t.d ,   maxL(d , λ , w ) = gd−λ   2(/bardbld−g / bardbl−ε(gd ) )   ( 21 )   We set the gradient of L(d , λ , w ) with respect to d   equal to zero ,   ∇L(d , λ , w ) = g−λ(d−g)+λε / bardblg / bardbld= 0 ,   ( 22 )   We can get the optimal d ,   d = g+λg   ( 1−εg)λ , ( 23 )   and we plug the solution dinL(d , w , λ ) to obtain   ˆL(d , λ , w ) ,   minˆL(λ , w ) =( /bardblg / bardbl+λ / bardblg / bardbl )   2λ(1−ε / bardblg / bardbl)−λ   2 / bardblg / bardbl ,   ( 24)Then , we set the gradient of ˆL(λ , w)with respect   toλequal to zero ,   ∇ˆL(λ , w ) = −/bardblg / bardbl   2λ(1−ε / bardblg / bardbl)−/bardblg / bardbl   2   + /bardblg / bardbl   2(1−ε / bardblg / bardbl)= 0   ( 25 )   We can get the optimal λ ,   λ=/bardblg / bardbl   ε / bardblg / bardbl . ( 26 )   We then plug the λindto obtain ,   d=/parenleftbiggg   1−ε / bardblg / bardbl+ε / bardblg / bardblg   ( 1−ε / bardblg / bardbl)/bardblg / bardbl / parenrightbigg   ,   ( 27 )   Finally , plugging dandλinto the objective in   Eq.(20 ) , we can obtain the following optimization   problemJ(w ) ,   minJ(w ) = gg+ε / bardblg / bardbl / bardblg / bardbl   1−ε / bardblg / bardbl,(28 )   We can obtain wby solving following optimiza-   tion problemJ(w)w.r.t.w , formally ,   w= arg minJ(w ) = gg+ε / bardblg / bardbl / bardblg / bardbl   1−ε / bardblg / bardbl ,   ( 29 )   /squaresolid   B Proof of Theorem 4.1   Following the proof of Lemma A , we use same   Lagrangian function in Eq.(19 ) for simplicity ,   L(d , w , λ ) = gd−λ(/bardbld−g / bardbl−ε(gd))/2   ( 30 )   Proof . LetP(λ , w ) = maxL(d , λ , w ) and   P(d ) = minL(d , λ , w ) . Then we can get ,   minL(d , λ , w ) ≤L(d , λ , w ) ≤maxL(d , λ , w )   ( 31 )   Thus , we have ,   P(d)≤P(λ , w ) ( 32 )   Since both primal problem and dual problem have   optimal solutions , we have ,   maxP(d)≤minP(λ , w ) ( 33)2575Finally , we get   Since the dual problem is a convex programming   and the solutions d , λ , andwmeet Karush - Kuhn-   Tucker ( KKT ) ( Bertsekas , 1997 ; Désidéri , 2012 )   conditions , we can get ,   p = q = L(d , λ , w ) ( 35 )   That is , the optimal value deﬁned by Eq . ( 14 ) is   equal to optimal value deﬁned by Eq . ( 9 ) . There-   fore , we can solve complex Maximin Optimization   Problem in Eq.(9 ) by solving its dual problem . /squaresolid   C Proof of Theorem 4.2   Lemma C.1 . If / lscriptis differential and L - smooth , ∇/lscript   is L - Lipschitz continuous , then   /lscript(θ)≤/lscript(θ)+∇/lscript(θ)(θ−θ)+L   2 / bardblθ−θ / bardbl(36 )   Proof . Using the fundamental theorem of calculus   with the continuous function ∇/lscript , we can get ,   /lscript(θ ) = /lscript(θ ) + /integraldisplay∇/lscript(θ+t(θ−θ))(θ−θ)dt   = /lscript(θ ) + ∇/lscript(θ)(θ−θ )   + /integraldisplay(∇/lscript(θ+t(θ−θ))−∇/lscript(θ))(θ−θ)dt   ≤/lscript(θ ) + ∇/lscript(θ)(θ−θ )   + /integraldisplay / bardbl∇/lscript(θ+t(θ−θ))−∇/lscript(θ)/bardbl / bardblθ−θ / bardbldt   ( Using the deﬁnition of Lipschitz - continuous )   ≤/lscript(θ ) + ∇/lscript(θ)(θ−θ)+/integraldisplaytL / bardblθ−θ / bardbldt   = /lscript(θ ) + ∇/lscript(θ)(θ−θ ) + L   2 / bardblθ−θ / bardbl   ( 37 )   /squaresolid   Proof of Theorem 4.2   Proof . Let{θ}be model parameters se-   quence generated by using update rule θ=   θ−µdwheredis deﬁned in Eq . ( 13 ) . Since   all∇/lscriptare Lipschitz continuous , for each loss{/lscript } , we have using Lemma C.1 ,   /lscript(θ)≤/lscript(θ)+∇/lscript(θ)(θ−θ )   + L   2 / bardblθ−θ||   = /lscript(θ)−µ∇/lscript(θ)d+L   2 / bardblµd / bardbl   ( Using the constraint /bardbld−g / bardbl≤εgd )   ≤/lscript(θ)−µ/bardbld−g / bardbl   ε+(µ )   2L / bardbld / bardbl   = /lscript(θ)−µ/bardbld−g / bardbl   ε+µ   2min / bardbld−g / bardbl   ε   ≤/lscript(θ)−µ/bardbld−g / bardbl   2ε≤/lscript(θ )   ( 38 )   This inequality implies that the objective function   value of all tasks strictly decreases with each it-   eration when using the GetMTL algorithm . We   next analyze the rationality of step size µin   Lemma C.2 .   /squaresolid   Lemma C.2 . The convergence of Gradient De-   scent with step size µis guaranteed only if the   step sizeµ > 0is carefully chosen such that   µ<1 / L(Nesterov , 1998 ; Ward et al . , 2020 ) where   L>0is the e Lipschitz smoothness constant . Then   we have ,   0<µ < 1 / L ( 39 )   Proof . ( 1 ) Proof of left part of inequality .   µ= min / bardbld−g / bardbl   ε·L·d , s.t.ε∈(0,1],L > 0(40 )   Therefore , we can get µ>0 .   ( 2 ) Proof of right part of inequality .   µ= min / bardbld−g / bardbl   ε·L·/bardbld / bardbl(using / bardbld−g / bardbl≤ε·gd )   ≤minεgd   ε·L·/bardbld / bardbl = g·d   L·/bardbld / bardbl   = /bardblg / bardbl·/bardbld / bardblcosϕ   L·/bardbld / bardbl=/bardblg / bardblcosϕ   /bardbld / bardbl·1   L   whereϕ∈[0,90)denotes the angle of dand   g. In general , we all penalize gradient norm for   improving the generalization and stability . We thus   can get / bardbld / bardbl−/bardblg / bardbl>0whenε∈(0,1 ] . Then ,   µ≤/bardblg / bardbl / bardbld / bardblcosϕ   L·/bardbld / bardbl=|g|cosϕ   /bardbld / bardbl·1   L<1   L ,   Then , we can get 0<µ < 1 / L.   /squaresolid2576Tasks   COMP 87.36 86.84 86.76 86.26 87.88 87.36 88.06 87.99 89.67   REC 94.48 96.21 96.02 95.63 96.25 95.84 96.16 95.9 96.39   SCI 94.45 96.26 96.35 96.08 95.78 95.82 95.66 96.08 96.56   TALK 85.04 86.08 86.27 85.94 86.56 85.96 85.93 85.82 86.84   A VG 90.43 90.93 90.87 90.7 91.2 90.87 91.26 91.25 92.09   Tasks   Apparel 87.57 89.18 89.59 88.69 88.63 87.98 88.95 89.83 90.03   Baby 87.14 89.91 89.96 89.33 89.05 88.65 90.02 90.01 90.32   Books 87.02 87.64 87.09 87.14 85.66 86.65 87.09 86.82 87.77   Camera 90.54 91.49 91.54 90.84 91.05 91.44 91.54 91.54 92.26   Dvd 84.61 88.17 87.35 87.32 87.65 87.24 87.08 88.02 89.30   Electronics 85.42 88.09 88.68 88.88 87.94 86.80 87.60 86.99 89.49   Health 89.07 90.82 91.50 90.59 90.86 90.55 91.81 91.85 91.85   Kitchen 85.16 89.51 89.65 89.33 88.69 87.67 90.07 89.25 90.81   Magazines 93.32 93.61 92.54 93.35 93.21 93.40 93.36 94.30 94.43   Music 83.92 84.27 86.25 84.97 85.01 83.90 86.37 86.88 87.04   Software 89.97 92.44 92.59 93.24 92.82 92.77 92.95 92.71 93.93   Sports 87.52 90.52 90.42 90.88 90.65 89.85 89.72 89.96 91.81   Toys 87.02 88.73 89.89 88.10 88.30 88.49 88.47 89.11 90.62   Video 88.8 89.65 89.28 88.92 89.33 89.06 89.62 89.88 89.55   Avg 86.52 88.47 88.74 88.01 88.30 87.71 88.78 89.14 89.80   D Complete Performance of Each Task   for Amazon Dataset   Amazon review dataset includes 14 domains , such   asApparel , Baby , Books , Camera , Dvd , Electron-   ics , Health , Kitchen , Magazines , Music , Software ,   Sports , Toys , and Video . Each domain is treated as   a 14 binary classiﬁcation task .   We provide the full comparison on the amazon   review and topic classiﬁcation datasets in Table 3   and Table 2 respectively . Table 2 shows that our   GetMTL can achieve the best average classiﬁcation   accuracy of 92.09 % , outperforming the second - best   model BanditMTL by a margin of 0.83 % . More-   over , our GetMTL can also beat other baselines on   each individual tasks . Table 3 reports the perfor-   mance of all 14 tasks on amazon review dataset .   Our proposed GetMTL achieves the best perfor-   mance on 13 out of 14 tasks and obtain best average   classiﬁcation accuracy.2577ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Section of Limitations   /squareA2 . Did you discuss any potential risks of your work ?   Not applicable . Left blank .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract and Introduction   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   Section of GetMTL , Experimental datasets   /squareB1 . Did you cite the creators of artifacts you used ?   Experimental datasets   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   It is published by the authors .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   Section of Experimental Implementation   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Not applicable . Left blank .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Not applicable . Left blank .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   Left blank .   C / squareDid you run computational experiments ?   Left blank .   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   No response.2578 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   No response .   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   No response .   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   No response .   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   No response .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   No response .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   No response .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   No response .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   No response.2579