  Zheng Fang , Ruiqing Zhang , Zhongjun He , Hua Wu , Yanan CaoInstitute of Information Engineering , Chinese Academy of SciencesSchool of Cyber Security , University of Chinese Academy of SciencesBaidu Inc. No . 10 , Shangdi 10th Street , Beijing , 100085 , China{fangzheng , caoyanan}@iie.ac.cn{zhangruiqing01 , hezhongjun , wu_hua}@baidu.com   Abstract   Automatic Speech Recognition ( ASR ) is an   efﬁcient and widely used input method that   transcribes speech signals into text . As the er-   rors introduced by ASR systems will impair   the performance of downstream tasks , we intro-   duce a post - processing error correction method ,   PhVEC , to correct errors in text space . For   the errors in ASR result , existing works mainly   focus on ﬁxed - length corrections , modifying   each wrong token to a correct one ( one - to - one   correction ) , but rarely consider the variable-   length correction ( one - to - many or many - to - one   correction ) . In this paper , we propose an ef-   ﬁcient non - autoregressive ( NAR ) method for   Chinese ASR error correction for both cases .   Instead of conventionally predicting the sen-   tence length in NAR methods , we propose a   novel approach that uses phonological tokens to   extend the source sentence for variable - length   correction , enabling our model to generate pho-   netically similar corrections . Experimental re-   sults on datasets of different domains show that   our method achieves signiﬁcant improvement   in word error rate reduction and speeds up the   inference by 6.2 times compared with the au-   toregressive model .   1 Introduction   Errors introduced by automatic speech recognition   ( ASR ) usually affect the performance of down-   stream tasks such as phonetic search , speech trans-   lation , etc . In recent years , ASR error correction   techniques have been proposed ( Anantaram et al . ,   2018 ; Mani et al . , 2020 ; Zhao et al . , 2021 ; Leng   et al . , 2021 ) to reﬁne the ASR output and correct   errors in text space . Without loss of generality , we   study Chinese ASR error correction in this paper .   Given the ASR result of an utterance , the goal   of error correction is to generate a sentence with   the wrongly recognized words corrected . Thus theASR error correction can be modeled as a machine   translation problem under conventional autoregres-   sive sequence - to - sequence ( Seq2Seq ) framework   ( Guo et al . , 2019 ; Hrinchuk et al . , 2020 ; Mani et al . ,   2020 ) . However , the autoregressive models suffer   from inefﬁcient decoding since the generation of   each target token depends on previously generated   characters ( Figure 1 ( a ) ) . Furthermore , without   considering the phonetic similarities , the method is   prone to generate corrections with totally different   pronunciation , as for the example , the error char-   acter ( “ /uni8868”,biao ) should be corrected into ( “ /uni4E0D   /uni8981”,bu yao ) but the Seq2Seq model ignores phono-   logical features and corrects it to a phonetically   different correction ( “ /uni4E0D / uni8BB8”,bu xu ) .   To speed up prediction , recent studies propose to   take non - autoregressive ( NAR ) methods ( Gu et al . ,   2018 ; Ren et al . , 2020 ) for error correction , which   generates target tokens in parallel . Most NAR ap-   proaches make ﬁxed - length predictions that gen-   erate same - length output as the source input by   directly tagging on the source text ( Zhang et al . ,   2020 ) . Some works further leverage phonological   features to correct the ASR errors caused by sim-   ilar pronounced characters ( Zhang et al . , 2021a ;   Cheng et al . , 2020 ) . Such methods have made   great improvements in correcting simple errors , but   can not handle samples with different lengths of   source and target , referred to as variable - length er-   ror correction . See Figure 1 ( b ) for illustration . The   method successfully ﬁnds out the erroneous charac-   ter ( “ /uni8868”,biao ) , and substitutes it with its phonolog-   ical feature “ biao ” for error correction . However ,   it eventually generates a wrong correction ( “ /uni6807 ” ,   biao ) under the constraint of ﬁxed length predic-   tion .   To overcome above constraint while preserving   efﬁcient prediction , NAR solutions for variable-   length prediction are proposed ( Leng et al . , 2021 ;   Gu et al . , 2019 ) . They ﬁrst build a length predictor   to estimate fertility , i.e. , the number of target tokens5907   aligned to each source token , then up - sampling   or dropping some source tokens accordingly for   parallel correction . However , the method is fragile   because incorrect length prediction will distort the   meaning of the sentence and may directly lead to   false prediction . See Figure 1 ( c ) for example , the   length predictor produces a wrong alignment ( 0 2   1 1 ) , indicating that the decoder will drop the ﬁrst   source character and generate two target characters   for the second source character . According to the   alignment , the intermediate result turns to be a   meaningless sentence ( “ /uni8868 / uni8868 / uni96BE / uni8FC7 ” , means “ watch   watch sad ” ) and leads to a wrong correction .   To address the issues mentioned above , we   propose a novel NAR model named PhVEC   ( Phonology - based Variable - length Error Correc-   tion ) . The model incorporates the phonological fea-   tures of error characters to enable variable - length   prediction . Concretely , PhVEC contains a detec-   tion network and a correction network based on a   pre - trained language model ( Devlin et al . , 2019 ;   Sun et al . , 2020 ) . The detection network predicts   the correctness of each token , and the correction   network generates correction result . Instead of us-   ing a length predictor to predict the fertility for   each source token , we insert the phonological to-   kens ( Chinese Pinyin ) to the source sequence as   placeholders after each detected erroneous charac-   ter . During prediction , each source token ( eitherthe character token or pinyin token ) can generate   zero or one target token . With the guidance of   the phonological token , the model will generate   characters with similar pronunciations . As Figure   1 ( d ) shows , the pinyin token “ b ” produces target   character ( “ /uni4E0D”,bu ) with the same consonant let-   ter , and “ a o ” produces target character ( “ /uni8981”,yao )   with the same vowel letter . We delete the repeated   characters in the ﬁnal sequence .   We evaluate our methods on multiple datasets   with varying degrees of ASR word error rates . Ex-   perimental results show that our PhVEC obtains   signiﬁcant improvement ( over 10 % word error rate   reduction ) on standard benchmarks compared with   existing NAR - based ASR error correction meth-   ods at comparable speed . Even compared with the   AR baseline Transformer and BART ( Lewis et al . ,   2020 ) models , PhVEC can still have an 8.55 % and   2.39 % word error rate reduction while keeping a   6.2x speed - up .   2 Method   Chinese ASR error correction can be formalized   as the following task . Given a speech recognition   sequenceX= ( x , x, ... ,x)ofnChinese char-   acters , the goal is to correct it into another sequence   ofmcharactersY= ( y , y, ... ,y ) . Note that the   target sequence length mdoes not have to be equal   to the source sequence length n. There exist three   types of ASR errors in transforming from XtoY :   substitution , deletion , and insertion .   As illustrated in Figure 1(d ) , our proposed ASR5908error correction model is composed of an error de-   tector and an error corrector , both perform a NAR   tagging . The error detector takes Xas input to   predict the correctness of each token . The error   corrector takes the combination of the source to-   kens and the phonological features of problematic   tokens as input for correction . During error cor-   rection , each token of the extended input can be   tagged to a Chinese character or a blank token “ /epsilon1 ” ,   so that the model can support variable - length cor-   rection . Since different pinyin letters may generate   the same character , we eliminate continuous repeti-   tive characters in the ﬁnal result . In this paper , we   use Chinese pinyin as the phonological feature . The   learning of PhVEC is conducted end - to - end , with   the error detector and corrector optimized jointly .   2.1 Error Detection Network   The goal of the error detector is to check whether   a characterx(1≤i≤n ) is correct or not . We   model this task as sequence labeling . We build a   sequential binary classiﬁer and use class 1 and 0 to   label the problematic characters and correct charac-   ters , respectively . The ground - truth detection label   C= ( c , c, ... ,c)is pre - calculated by matching   XandYwith edit distance , in which c∈{0,1 } .   The prediction result of the error detector is repre-   sented by a sequence C= ( c , c, ... ,c ) , and we   usepto denote the probability of token xbeing   predicted to class 1 , which can be formalized as   follows :   p = p(c= 1|X ) = softmax ( f(E(e ) ) )   ( 1 )   where e= ( e , e, ... ,e)is the token embed-   ding ofX , Eis a Transformer - based encoder and   fis a fully - connected layer that maps the sen-   tence representation to a binary sequence . To train   the model , we adopt the following cross entropy   loss function :   L=−1   n / summationdisplay[clnp+ ( 1−c ) ln(1−p ) ]   ( 2 )   2.2 Error Correction Network   After identifying the errors , we introduce the pinyin   features of the incorrect characters and feed them   into the correction network . Concretely , we use   the tool PyPinyinto generate pinyin for each er-   roneous Chinese character and insert pinyin to-   kens after the problematic token . The original   sentenceX= ( x , x, ... ,x)is thus rewritten as   X= ( x , x, ... ,x ) , wheret≥n , andt−nis   the number of pinyin tokens .   GivenX , the error corrector performs se-   quence labeling to predict the correction result   Y= ( y , y, ... ,y)as follows :   p(y = V|X ) = softmax ( fE(e))(3 )   wherep(y = V|X)is the conditional prob-   ability thatxis corrected toV , the token with   indexjin the vocabularyV.eis the token em-   bedding ofXandfis a fully - connected layer   that maps the hidden states of source tokens to their   predicted logit vector of length |V| . Note that , the   parameters of the token embedding , the encoder E   and the correction network fare initialized by   pre - trained language models ( Devlin et al . , 2019 ;   Sun et al . , 2020 ) . We share the pre - training model   parameters in the error detector and corrector to   encode the Chinese characters and pinyin tokens in   a shared space , which not only reduces the model   size , but also makes the model yield better semantic   representation .   The learning objective of the error corrector is   to correctXto the golden correction Y. How-   ever , it is not an easy task because the lengths of   XandYmay not be the same . Therefore , we   rewriteYtoˆY= ( ˆy,ˆy, ... ,ˆy)which has the   same length as X. Concretely , ˆYis constructed   fromYwith some tokens repeated and inserted ac-   cording to pronunciation alignment . We compare   the pinyin of the incorrect tokens of Xwith their5909   correct counterparts of Y , and align according to   the longest common substring ( LCS ) algorithm , as   illustrated by the dashed arrows in the bottom of   Figure 2 . Then we rewrite YtoˆYaccording to the   alignment .   The loss of the error corrector can be deﬁned as   follows :   L=−/summationdisplaylog(p(y= ˆy|X ) ) ( 4 )   Our proposed pinyin alignment provides an ex-   plicit clue for the model to learn the correlation be-   tween pinyin and Chinese characters . As an alterna-   tive , we can also learn the alignment through Con-   nectionist Temporal Classiﬁcation ( CTC ) ( Graves   et al . , 2006 ) , which is widely used for variable-   length alignments , such as in ASR ( Audhkhasi   et al . , 2019 ) , handwriting recognition ( Bluche et al . ,   2014 ) , etc . But we do n’t use CTC in our model   because we assume that aligning according to the   phonological features is reliable for ASR error cor-   rection , which will reduce the learning difﬁculty   compared with learning a global alignment . We   conﬁrm our assumption in experiments .   2.3 Joint Learning and Inference   For each training sample ( X , Y ) , we construct its   golden detection result Cand correction target ˆY   ﬁrst , then jointly optimize the two modules as fol-   lows :   L = λ·L+ ( 1−λ)·L ( 5 )   whereλis a trade - off parameter .   During the inference stage , we ﬁrst detect the   problematic characters and insert their pinyin into   the original sentence , then predict the correction   sequenceYby maximizing the probability of   p(y|X)for eachi . The ﬁnal correction resultis generated by removing the blank tokens /epsilon1and   merging adjacent duplicate characters from the pre-   diction of the error corrector , as shown at the top   of Figure 1(d ) . Note that such post - processing is   conducted only at locations where Xis modi-   ﬁed relative to X , while the characters predicted as   correct by the error detector are kept unchanged in   the ﬁnal prediction .   3 Training Data Generation   We follow the common practice in error correction   ( Zhang et al . , 2020 ; Takahashi et al . , 2020 ; Leng   et al . , 2021 ) to synthesize the training corpus with   simulated ASR errors . The simulated ASR results   are generated by replacing the Chinese characters   or words of clean sentences into problematic ones .   Speciﬁcally , we generate the noisy text in three   steps : ( i ) sampling some candidate characters and   replace them with pinyin . ( ii ) adding noise to the   original pinyin and generate new valid ones ( iii )   producing new Chinese characters or words based   on the updated pinyin .   In the ﬁrst step , the candidate words are obtained   from a confusion set ( Wang et al . , 2019 ) that con-   tains words prone to be mis - recognized . In the   second step , we design three strategies of pinyin   perturbation for simulating substitution errors , dele-   tion errors and insertion errors , as shown in Figure   3 . Note that when generating deletion and insertion   errors , some random letters may be inserted to con-   struct valid pinyin sequence . In the last step , we   replace the noisy pinyin with corresponding word   candidates , and select the sentence ranked highest   by a n - gram language model as the ﬁnal simulated   ASR result.59104 Experiments   We carry out experiments on two Chinese ASR   error correction datasets . We use word error rate   ( WER ) and word error reduction rate ( WERR ) to   evaluate our error correction performance .   4.1 Data Settings   We ﬁrst train an ASR model on AISHELL-1 ( Bu   et al . , 2017 ) . The training set contains 150 hours of   Mandarin speech , along with corresponding tran-   scripts , mainly including news in Finance , Tech-   nology , Sports , etc . The trained ASR model then   transcribes the speech to generate the paired data   for evaluation , as listed in Table 1 . AISHELL-1   dev and test sets contain 15 hours of speech , cor-   responding to 21 K sentence pairs . MAGICDATA   contains 43 hours of Mandarin speech , including   interactive Q&A , daily instructions , etc .   The training set of ASR error correction is con-   structed from 3 million web - crawled sentences ,   along with their noisy version with simulated er-   rors . For the methods that only support ﬁxed - length   correction , the pseudo ASR input is generated with   similar - pronounced substitution errors only . For   the training data of methods that support variable-   length correction , we sample 2.7 million samples   from the ﬁxed - length training data and generate   simulated insertion and deletion errors for the re-   maining 0.3 M sentences .   4.2 Training Details   Consistent with previous work ( Leng et al . , 2021 ) ,   we use the ESPnet ( Watanabe et al . , 2018 ) toolkit   to train an ASR model on AISHELL-1 training set .   Conformer architecture ( Gulati et al . , 2020 ) and   SpecAugment ( Park et al . , 2019 ) are also used to   improve the ASR performance . For the ASR error   correction network , we take “ chinese - bert - wwm "   ( Cui et al . , 2019 ) as a pre - trained model to initialize   the encoders of our PhVEC and other pretraining-   based methods . We set the learning rate to 5e-5   and the probability of dropout to 0.1 . The loss   balancing parameter λin joint learning is set to 0.5 ,   and the AdamW ( Loshchilov and Hutter , 2019 ) is   utilized as optimizer . More details can be found in   the Appendix A.   4.3 Baselines   We compare our PhVEC with the autoregres-   sive Transformer ( Vaswani et al . , 2017 ) , BART   ( Lewis et al . , 2020 ) and recent state - of - the - art non-   autoregressive methods as follows : Levenshtein   Transformer ( LevT ) ( Gu et al . , 2019 ) supports   variable - length correction by iteratively perform-   ing deletion , insertion and substitution under NAR   framework . FastCorrect ( Leng et al . , 2021 ) im-   plements variable - length correction with a length   predictor that estimates the number of target to-   kens each source token should be converted to ,   then repeating / droping the source tokens to gen-   erate a variable length sequence as the input of   error correction . MLM - phonetics ( Zhang et al . ,   2021a ) implements a ﬁxed - length error correction   by pre - training a language model with phonologi-   cal features integrated . BERT directly ﬁne - tunes   the standard masked language model to generate   ﬁxed - length corrections . BERT+CTC implements   variable - length error correction with a CTC layer   built on top of BERT , which upsamples each source   token twice and learns the source - target alignments   automatically with a CTC loss .   4.4 Overall Results   The comparison results on two benchmark datasets   are shown in Table 2 . We observe that :   •Our proposed PhVEC outperforms all the   other methods on the evaluation datasets .   It achieves about 20 % WERR for the four   datasets with varying levels of ASR perfor-   mance . PhVEC greatly exceeds the two exist-   ing methods supporting variable - length cor-   rection , LevT , and FastCorrect , and become   the ﬁrst method that surpasses the autoregres-   sive Transformer and BART models , with the   WERR improved by 8.55 % and 2.39 % on av-   erage , respectively.5911   •Both PhVEC and MLM - phonetics introduce   phonological features into the model but   PhVEC performs better . We attribute this im-   provement to two aspects : one is its effec-   tive solution to variable - length errors , and the   other is the effective use of pinyin splitting   strategy . Different from Zhang et al . ( 2021a ) ,   we use pinyin features in letter granularity ,   instead of treating each pinyin as one token .   This facilitates ﬂexible insertion and enhances   the correlation between similar pronounced   characters and their corresponding phonologi-   cal features .   •Pre - training signiﬁcantly promotes correction   performance . For the autoregressive mod-   els , the pre - trained BART has lower WER   compared to the vanilla Transformer model .   Moreover , the ﬁne - tuned BERT achieves com-   parable performance with Transformer , in-   dicating that strong language modeling will   greatly facilitate NAR methods for error cor-   rection . Among the pretraining - based meth-   ods , PhVEC still performs the best , demon-   strating the effectiveness of leveraging pinyin   tokens for variable - length correction .   •Adding the CTC layer does not bring obvious   advantages for error correction . In particular ,   BERT+CTC is inferior to BERT , and prones   to generate incorrect alignments for the ﬁxed-   length correction samples . This might be be-   cause , for ASR error correction , the alignmentbetween most words of the source and tar-   get is deﬁnite . BERT+CTC upsamples each   source token twice and dictates the model to   learn the alignment , which actually increases   the difﬁculty of learning . It is worth not-   ing that BERT+ CTC outperforms BERT on   thevariable - length error correction samples ,   which will be introduced later in Table 3 .   •PhVEC accelerates to 6.2 times that of Trans-   former , and further reduces the WER by 8-   10 % . Even compared with the BART model ,   we still have 2 - 3 % WER reduction and speed   up the inference by 7.5 times , which proves   the efﬁciency and effectiveness of PhVEC .   Moreover , we want to emphasize that the orig-   inal FastCorrect used NVIDIA V100 and P40   GPU to test the model delay respectively . To   ensure the consistency of the results , we reim-   plement all baseline methods and test the in-   ference speed on NVIDIA V100 GPU .   It is also notable that the training data of our   method PhVEC includes 3 M sentence pairs , which   is consistent with that of Transformer , BART ,   LevT , BERT , and BERT+CTC , but FastCorrect and   MLM - phonetics use additional 400 M and 300 M   pairs sentences for pre - training , respectively .   4.5 Analyses   We further analyze the performance of our model   onvariable - length datasets and conduct ablation5912   studies to dissect the factors affecting the effective-   ness of our method .   4.5.1 Variable - length scenario   To evaluate the effectiveness of our model in deal-   ing with variable - length errors , we extract the sam-   ples containing insertion and deletion errors from   the test sets of AISHELL-1 and MAGICDATA ,   and evaluate the above methods on this subset . As   shown in Table 3 , PhVEC shows signiﬁcant ad-   vantages over other methods , achieving over 20 %   WERR on both datasets . Both ﬁned - tuned BERT   and MLM - phonetics perform weakly because of   the inherent ﬁxed - length limitation of their gener-   ation . The CTC layer brings signiﬁcant improve-   ment to BERT by enabling it with variable - length   prediction , but there is still a large gap between its   performance and that of PhVEC . The correction   generated by LevT is not stable , even degrades the   WERR by 8.1 % WERR in the MAGICDATA sub-   set . This might be because its length prediction   result is inaccurate . The average length difference   between the input and the golden correction is only   1.08 , while the average length gap between the pre-   diction of LevT and the golden correction is 1.42 .   This indicates that the prediction of LevT will pro-   duce more length differences than the original ASR   input , resulting in its performance degradation .   4.5.2 Different manners of leveraging   phonological features   In our model , we split the pinyin of each Chi-   nese character into tokens letter by letter and add   them after each detected problematic character , e.g. ,   rewrite the detected error character “ [ /uni8868 ] ” ( biao )   to 5 tokens [ /uni8868][b][i][a][o ] in the intermediate   variable - length result . Here we explore the im-   pact of leveraging pinyin with different strategies :   1)OneToken : taking the pinyin of each character   as one token as in Zhang et al . ( 2021a ) ; 2 ) Ini-   tial&Final : divide each pinyin into an initial ( [ b ] )   and a ﬁnal ( [ iao ] ) , according to the phonological   portion of Chinese ; 3 ) Letters - only : remove the   original problematic character from the rewritten   sentence and use its pinyin for substitution . The   ﬁrst two settings focus on different pinyin granular-5913ities , and the third one wants to check whether the   original characters detected as errors are useful for   error correction .   Table 4 shows that : ( 1 ) Compared with Letters ,   both OneToken andInitial&Final degrades the per-   formance . This is because the granularity of the   phonological features used in the two methods are   coarser than that of Letters , which reduces the prob-   ability of aligning each phonological feature to   more Chinese characters . ( 2 ) The Letters - only per-   forms inferior to Letters , demonstrating the effec-   tiveness of keeping the original characters in X.   This might be because , some wrong detection re-   sults tag “ C ” to some correct words . Removing   these original words when adding pinyin tokens   makes the model almost impossible to recover the   correct ones . This always happens to rare words in   some named entities .   4.5.3 Characters Embedding and Alignment   To qualitatively examine whether PhVEC learns   meaningful representations , we dive into the   learned embedding and encoder for visualization .   We ﬁrst investigate whether the model learns the   relationship between pinyin letters and Chinese   characters . Concretely , we visualize the learned   embedding of pinyin letter and Chinese character   in a two - dimensional space by applying the t - SNE   algorithm ( van der Maaten and Hinton , 2008 ) . Fig-   ure 4b shows that the embedding of Chinese char-   acters and their corresponding pinyin letters get   closer after training with PhVEC . Then we visu-   alize the self - attention of the encoder in the error   corrector . Figure 4c shows that the corrected words   in the output pay much attention to their corre-   sponding pinyin tokens , for example , “ /uni4E0D(bu ) " is   highly aligned to “ b ” , and “ /uni8981(yao ) " paid much   attention to “ a ” and “ o ” , which indicates that the   phonological features provide an obvious prompt   for error correction .   5 Related Work   5.1 Chinese Spelling Error Correction ( CSC )   As a close related area to ASR error correction ,   CSC has been widely explored in recent years .   Zhang et al . ( 2020 ) proposes a soft - masked BERT   model that ﬁrst predicts the error probability of   each character , and then uses the probabilities to   perform a soft - masked word embedding for correc-   tion . As a remedy of soft - masked BERT , Zhang   et al . ( 2021a ) incorporates phonological knowl - edge into pre - training and proposes to fuse phono-   logical feature in error correction . Cheng et al .   ( 2020 ) builds a Graph Convolution Network on   top of BERT , which reﬂects the phonological sim-   ilarity among Chinese tokens . However , these   methods are designed to produce corrections of the   same length as the input , but incapable of handling   variable - length correction that includes errors of   substitution , deletion and insertion .   5.2 Autoregressive ( AR ) Error Correction   To correct variable - length errors , a large num-   ber of Seq2Seq AR models have been proposed .   Zhang et al . ( 2019 ) uses a Transformer - based   model for Chinese ASR error correction . Wang   et al . ( 2019 ) incorporates a copy mechanism into   Seq2Seq framework to copy the corrections di-   rectly from a prepared confusion set for the er-   roneous words . With the popularity of pre - training ,   Zhao et al . ( 2021 ) uses a pre - trained BART ( Lewis   et al . , 2020 ) to initialize the correction network .   Although these AR models are able to deal with   various types of errors in ASR , they can not sat-   isfy the latency requirements for online services ,   especially for some real - time scenarios like simul-   taneous translation ( Zhang et al . , 2021b ) .   5.3 Non - Autoregressive ( NAR ) Error   Correction   NAR models are designed for fast generation speed   compared with their AR counterpart by producing   all tokens in a target sequence in parallel , which is   widely explored in machine translation ( Gu et al . ,   2019 ; Xu and Carpuat , 2021 ) , ASR ( Fan et al . ,   2021 ) , TTS ( Ren et al . , 2019 ) etc . Recently , some   studies ( Gu et al . , 2019 ; Leng et al . , 2021 ) propose   to apply NAR models to variable - length ASR error   correction based on a length predictor , which ﬁrst   estimates the length of the target correction , then   rewrites the input sentence by dropping or repeat-   ing some tokens according to the length estimated ,   ﬁnally performs a sequence labeling on the rewrit-   ten sentence to achieve correction . However , it is   difﬁcult to predict the target length of an incorrect   sentence directly , even for humans , while the accu-   racy of length prediction is closely related to the   performance of error correction .   6 Conclusion   In this paper , we propose a non - autoregressive Chi-   nese ASR error correction network with phonolog-5914ical training . Our method ﬁrst detects the problem-   atic characters , then adds the phonological features   of them to adjust the input length , thus generat-   ing a variable - length sequence for error correction .   The phonological features enable our model to pro-   duce similar - pronounced corrections , and support   variable - length correction in a non - autoregressive   mode . Experiments show that our method is su-   perior to the autoregressive method while main-   taining a 6.2x speed - up . As a future work , we   plan to extend PhVEC to other languages and use   corresponding phonological tokens to correct the   variable length errors caused by pronunciation .   Acknowledgements   This research is supported by the National Key   Research and Development Program of China   ( NO.2017YFC0820700 ) and National Natural Sci-   ence Foundation of China ( No.61902394 ) . We   thank all authors for their contributions and all   anonymous reviewers for their constructive com-   ments .   References59155916   A Experimental Details   A.1 Structure and parameters of ASR model   The ASR model is an end - to - end encoder - attention-   decoder model with a 12 - layer conformer encoder   and a 6 - layer conformer decoder , which is trained   with cross - entropy loss on decoder output and an   auxiliary CTC loss on encoder output . For the   hyper - parameters of the ASR model , we take the   beam search decoding with beam size to be 10 ,   conformer kernel size to be 15 , ctc weight to be   0.6 , lm weight to be 0.3 .   A.2 Balance the objective of detection and   correction   We explore the impact of the weighting strategy   that balances the two objectives in ﬁne - tuning . Ta-   ble 5 presents the results of PhVEC in different   values of hyper - parameter λ . Speciﬁcally , a larger   λvalue means a higher weight on error detection ,   and the highest F1 score is obtained when λis 0.5.5917