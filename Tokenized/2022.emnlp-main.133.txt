  Cristina España - Bonet   DFKI GmbH , Saarland Informatics Campus   Saarbrüken , Germany   cristinae@dfki.deAlberto Barrón - Cedeño   Universitá di Bologna   Forlì , Italy   a.barron@unibo.it   Abstract   Some human preferences are universal . The   odor of vanilla is perceived as pleasant all   around the world . We expect neural models   trained on human texts to exhibit these kind of   preferences , i.e. biases , but we show that this is   not always the case . We explore 16 static and   contextual embedding models in 9 languages   and , when possible , compare them under sim-   ilar training conditions . We introduce and re-   lease CA - WEAT , multilingual cultural aware   tests to quantify biases , and compare them   to previous English - centric tests . Our experi-   ments conﬁrm that monolingual static embed-   dings do exhibit human biases , but values dif-   fer across languages , being far from universal .   Biases are less evident in contextual models ,   to the point that the original human associa-   tion might be reversed . Multilinguality proves   to be another variable that attenuates and even   reverses the effect of the bias , specially in   contextual multilingual models . In order to   explain this variance among models and lan-   guages , we examine the effect of asymmetries   in the training corpus , departures from isomor-   phism in multilingual embedding spaces and   discrepancies in the testing measures between   languages .   1 Introduction   The perception of odor pleasantness has been   shown to be universal . Even if variations across   individuals exist , they do not depend on culture ( Ar-   shamian et al . , 2022 ) . We call this is a human bias :   judging a phenomenon in terms of values that are   inherent in human beings , regardless of their socio-   cultural background . On the contrary , a cultural   biasis “ the tendency to interpret and judge phenom-   ena in terms of the distinctive values , beliefs , and   other characteristics of the society or community   to which one belongs” . Racism , sexism , ageism , etc . are all social cultural biases and can be more   or less present in distinct communities .   As long as neural systems are trained on general-   domain texts written by humans , one would expect   and desire human biases to be present in embed-   ding models for all languages . One would also   expect ( but not always desire ) cultural biases , but   these would depend on the language or the culture   behind it . Lots of work has been done on detect-   ing social cultural biases and trying to mitigate   them ( Bolukbasi et al . , 2016 ; Zhao et al . , 2018 ;   Gonen and Goldberg , 2019 ; Ravfogel et al . , 2020 ;   Dev et al . , 2020 ; Schick et al . , 2021 ; Zhou et al . ,   2022 ) . Also recent work has investigated the pres-   ence of human biases in static word embeddings ;   ﬁrst in English ( Caliskan et al . , 2017 ) and later   in other languages ( Lauscher and Glavaš , 2019 ;   Lauscher et al . , 2020a , b ) . These works make use   of the Word Embedding Association Test ( WEAT )   for English — lists of concepts and attributes that   hide implicit human associations as described in   Section 2 — and X - WEAT , WEAT ’s translations ,   for other languages . To the best of our knowledge ,   research on language models and contextualised   embeddings , has been done only in English , us-   ing extensions or variations of WEAT ( May et al . ,   2019 ; Kurita et al . , 2019 ; Guo and Caliskan , 2021 ) .   Natural language processing aspires to multi-   linguality . When talking about embeddings , one   achieves multilinguality by mapping two or more   spaces into a single one , or by joint training with   text in two or more languages . These are the   two main approaches to crosslingual word embed-   dings ( Ruder et al . , 2019 ) and the approaches used   to train language models ( Devlin et al . , 2019 ; Lin   et al . , 2021 ; Conneau et al . , 2020b ) .   We go deeper into the understanding of multilin-   gual embedding models and the effect , if any , of   the different approaches used to build them . For   this purpose , we ﬁrst review results and some of   the implicit assumptions made in previous works2056by investigating ( i ) whether translations from the   original WEAT English lists ( X - WEAT ) are fair   tests for other languages and ( ii ) whether a single   list , either original or translated , is representative   for a language . Second , for the ﬁrst time we de-   ﬁne and collect cultural aware WEAT lists ( CA-   WEAT ) to enable multilingual analyses completely   independent of English . Third , we use WEAT , X-   WEAT and CA - WEAT to study the effect of cross-   and multilinguality in embedding models ; that is ,   how they differ with respect to the monolingual En-   glish . Since differences do exist , we try to explain   them in terms of the testing measure ( * -WEAT ) ,   the nature of the training corpora , the method to   achieve multilinguality and the ﬁnal differences   in the topology of the embedding spaces between   languages . We perform a systematic study over 9   languages of 3 families in word embeddings from   16 static and contextual models . Our premise is   that biases should be equally present , and we anal-   yse departures from this premise with the focus on   multilinguality .   2 Quantifying Bias with WEAT   The Word Embedding Association Test   ( WEAT ) ( Caliskan et al . , 2017 ) is a bias   measurement method for word embeddings .   WEAT is inspired by the Implicit Association   Test ( IAT ) for humans ( Greenwald et al . , 1998 ) ,   which measures differences in response time   when subjects are requested to pair items and   attributes that they ﬁnd similar and when pairing   items and attributes that they ﬁnd different . To   give an example , subjects would be ﬁrst asked   to label the item orchid asﬂower - pleasant or   insect - unpleasant . This would be repeated for   several ﬂowers and insects . In a second part ,   subjects would be asked to label the same list   of items as insect - pleasant orﬂower - unpleasant .   Experiments show that the response time for the   ﬁrst part is lower than for the second one . The   cognitive effort for the latter is higher because the   association ﬂower - unpleasant is less expected than   ﬂower - pleasant . These results expose a human   bias : ﬂowers are more pleasant than insects and   insects are more unpleasant than ﬂowers . If this   is a universal human bias , one would expect it   to be present also in embeddings created from   human texts . Flowers in a semantic space should   be closer to pleasant attributes than insects , and   insects closer to unpleasant attributes than ﬂowers . Many WEAT ( and IAT ) tests exist ; most of   them are designed to measure biases ( implicit   associations ) towards racial groups , gender , sex-   uality , age , and religion . Only two are non-   social and therefore we expect them to be culture-   and language - independent : ﬂowers / insects vs.   pleasant / unpleasant ( WEAT1 ) and musical instru-   ments / weapons vs. pleasant / unpleasant ( WEAT2 ) .   These are considered “ universally accepted stereo-   types ” ( Greenwald et al . , 1998 ; Toney and Caliskan ,   2021 ) . Each attribute and concept in these tests has   associated a list of 25 English terms , collected as   described in Section 3 ( listed in Appendix C ) .   The original WEAT measure ( Caliskan et al . ,   2017 ) deﬁnes the association of each term t(e.g .   orchid ) as its average cosine similarity to the list of   target attributes A(e.g . pleasant concepts ):   assoc ( t , A ) = /summationtextsim(t , a )   |A| , ( 1 )   where tis the embedding for tandais the em-   bedding for an element a∈A.The association   difference ∆ for a termtbetween attributes A   ( pleasant ) andB(unpleasant ) is then   ∆(t , A , B ) = assoc ( t , A)−assoc ( t , B ) .   ( 2 )   Given two sets of target terms XandYwith   nelements each ( e.g. , ﬂowers andinsects ) , the   statisticsis the difference in average similarity of   their terms with elements from AandB :   s(X , Y , A , B ) = /summationdisplay∆(x , A , B ) −   /summationdisplay∆(y , A , B ) .(3 )   We use Cohen ’s dto estimate the effect size ( i.e.   the strength of the bias ) . Cohen ’s dis a standard-   ised measure of the effect deﬁned as the difference   between the two means divided by the standard   deviation for all instances in XandY :   Sawilowsky ( 2009 ) deﬁned the scale of magni-   tude fordas very small ( < 0.01 ) , small ( < 0.20 ) ,   medium ( < 0.50 ) , large ( < 0.80 ) , very large   ( < 1.20 ) , and huge ( < 2.00).20573 Multilingual Aspects and CA - WEAT   Both IAT and WEAT have been traditionally cre-   ated in the north east of the US and performed in   English . The pleasant and unpleasant words used   in WEAT1 and WEAT2 were selected from norms   in Bellezza et al . ( 1986 ) , where college students in   Ohio rated a list of words for pleasantness . From   this list , 25 elements were taken as pleasant words   and 25 as unpleasant words by Greenwald et al .   ( 1998 ) . The lists for ﬂowers , insects , musical in-   struments , and weapons were extracted from Battig   and Montague ( 1969 ) , where college students from   Maryland and Illinois were given 30 seconds to   write down as many objects within each category   as possible . Greenwald et al . ( 1998 ) selected 25   unambiguous items that they thought their students   would be familiar with . These two requests are   relevant : they ensure taking frequent words in the   language that have a single meaning .   The ﬁrst experiment with word embeddings was   done by Caliskan et al . ( 2017 ) who used pre-   trained English GloVe embeddings ( Pennington   et al . , 2014 ) . They observed that , according to   their results on social biases , the training corpus   “ may be disproportionately American ” . Subse-   quent studies used crosslingual WEAT ( X - WEAT )   to go beyond analyses in English ( Lauscher and   Glavaš , 2019 ; Lauscher et al . , 2020a ) . The orig-   inal lists were translated into several languages   and biases estimated using the translated items and   attributes . They found differences in the biases   obtained across languages and connected them to   differences in the size of the training corpora . They   also explored bilingual spaces and observed that   the bias effects were in the middle of the two corre-   sponding biases in the monolingual spaces .   As discussed , WEAT1 and WEAT2 originate in   the US . Even if a concept ( ﬂower ) might be consid-   ered pleasant in every culture , the items themselves   ( orchid , broom , etc . ) can be different across cul-   tures . This is most evident for elements that depend   on geography ( a ﬂower that grows in the US or an   insect that lives there might not be present in other   locations ) , but it could happen for all the other   items in WEAT1 and WEAT2 . As a result , the rep-   resentation of the original translated items in the   training data in other languages might be smaller   or , even worse , the distribution of the opposite at-   tributes asymmetric . As we will show , there is   already a variation in the terms and attributes used   by different people within a common culture , buttesting the existence of human biases with transla-   tions from American English might be inducing an   additional cultural bias in the results . There is a sec-   ond argument to avoid X - WEAT : translations are   not perfect and one can not assure that the require-   ments in Greenwald et al . ( 1998 ) ( unambiguous   and frequent words ) hold . For example , the Span-   ish X - WEAT translates blade ashoja ( the edge of   a knife , but also a sheet of paper ) and turns both   ﬁddle andviolin intoviolín . Whereas correct , trans-   lation introduces an ambiguous word lacking any   association to ( un)pleasant attributes in the former   case , and reduces the size of the list in the latter .   To mitigate the problems introduced by transla-   tions and to estimate their impact in the analysis ,   we create CA - WEAT : a new collection of cultural-   aware lists written by native speakers of different   languages . We asked volunteers to create lists of   ﬂowers , insects , weapons and musical instruments ,   as well as both pleasant and unpleasant concepts   with 25 elements each without any time constraint .   The only requirement was that words needed to   be common in their culture . Lists from different   volunteers are semantically equivalent , since they   characterise the same concepts , and can be seen as   perturbations on a prototypical ( or average ) set .   We ﬁrst conducted a pilot study with 14 volun-   teers from 11 nationalities to survey the difﬁculty   of the task and prepare the guidelines of the exper-   iment . Five of them failed to complete the task .   After the pilot , we set up an online form with de-   tailed instructions ( see Appendix A ) and distributed   it to contacts in different countries .   We collected 112 CA - WEAT lists in 26 lan-   guages from which we discarded 9 after a quality   check . For the current experiments , we selected   9 of the 26 languages , for a total of 82 lists . The   lists in the remaining 17 languages are provided in   the CA - WEAT dataset but we do not use them in   the subsequent analysis ; statistics for all of them   are reported in Appendix B. The languages consid-   ered here are chosen according to 3 criteria : high-   quality embeddings could be obtained , the equiva-   lent X - WEAT exists or could be created by a native   speaker at hand , and different language families are   covered . These constraints led to considering Ara-   bic ( ar ) , Catalan ( ca ) , Croatian ( hr ) , English ( en ) ,   German ( de ) , Italian ( it ) , Russian ( ru ) , Spanish ( es )   and Turkish ( tr ) . The distribution among languages2058is not even : we collected 24 lists in Italian and Ger-   man , 12 in Croatian , 10 in Spanish , 5 in English , 2   in Catalan , Romanian and Turkish , and 1 in Arabic .   Instead of aggregating the highest ranked / most fre-   quent words per concept into a single list as WEAT   does , CA - WEAT uses all the words and provides a   list per subject . This allows us to study statistically   the variations and the relevance of the test sets .   For X - WEAT , we use the translations provided   by Lauscher and Glavaš ( 2019 ) and Lauscher et al .   ( 2020b ) , after revising the Spanish ones and adding   the Catalan translations .   4 Embedding Models   We consider 16 embedding models for the 9 se-   lected languages . We select two kinds of models .   On the left - hand side , widely - used out - of - the - box   pre - trained models . On the right - hand side , models   trained in - house . For the latter , we control both the   amount and domain of the training data , as well as   the approach used to reach multilinguality .   For static embeddings , we use pre - trained fast-   Text word embeddings :   WP : Monolingual models trained on Wikipedia us-   ing the skip - gram architecture with subword infor-   mation , as described by Bojanowski et al . ( 2017 ) .   WPali : WPaligned to English with the RCSLS   method as described by Joulin et al . ( 2018 ) .   CCWP : Models trained on Common Crawl and   Wikipedia using CBOW with position weights and   subword information ( Grave et al . , 2018 ) .   We also build 5 static in - house word embeddings   on Common Crawl using a subset of the CC-100   corpus ( Conneau et al . , 2020a ; Wenzek et al . , 2020 ) .   We enforce to have the same number of words for   all 9 languages under study ( CCe ) by ceiling the   size to that of the language with the smallest corpus :   Catalan , with 1.7·10words ( see Appendix D ) . For   comparison purposes , the training of the 5 models   is done with the same architecture and hyperparam-   eters as in CCWP : CBOW with position - weights ,   300 dimensions , character 5 - grams , a window of   size 5 and 10 negatives . The ﬁve in - house embed-   dings are :   CCe Monolingual embeddings trained on CCe .   CCeVMuns CCe aligned to the English space us-   ing unsupervised VecMap ( Artetxe et al . , 2018b).CCeVMsup Supervised VecMap ( Artetxe et al . ,   2018a ) using the test part of the cross - lingual dic-   tionaries in MUSE .   CCe2langs Bilingual embeddings trained on the   concatenation of CCe - en and CCe- Lfor one of   the other 8Llanguages .   CCe9langs Multilingual embeddings trained on   the concatenation of the 9 CCe- L.   Purely static embeddings are compared to word   embeddings extracted from 3 pre - trained contex-   tual models :   mBERTStatic embeddings ( layer 0 ) in multilin-   gual BERT ( Devlin et al . , 2019 ) ; trained on 104   languages including the ones we analyse with a   BPE vocabulary of 110k .   mBERTEmbeddings in the next - to - last layer   ( layer 11 ) of multilingual BERT .   BERTWe use monolingual BERT for Arabic   ( Antoun et al . , 2020 ) , German , Italian ( Schweter ,   2020b ) , Spanish ( Cañete et al . , 2020 ) , Turk-   ish ( Schweter , 2020a ) and English ( Devlin et al . ,   2019 ) . For the other languages , the model is not   available or it ﬁnetunes mBERT .   BERTEmbeddings in the 11th layer of the same   models as in BERT .   XLM - RStatic embeddings in XLM-   RoBERTa ( Conneau et al . , 2020a ) ; trained   on 100 languages with a BPE vocabulary of 250k .   XLM - REmbeddings in the next - to - last layer of   XLM - RoBERTa .   XGLMStatic embeddings in XGLM ( Lin et al . ,   2021 ) ; trained on 30 languages with a BPE vocabu-   lary of 250k , excluding Croatian .   XGLMEmbeddings in the next - to - last layer   ( layer 47 in this case ) of XGLM .   While static word2vec - like embeddings have   300 dimensions , BERT embeddings have 768 ,   XLM - RoBERTa 1024 and XGLM 2048 .   5 Experiments and Results   We calculate the statistic and the effect size ( Co-   hen’sd ) for the 16 types of embeddings in the 9 lan-   guages for WEAT1 , WEAT2 , the 82 CA - WEAT12059   and CA - WEAT2 and the 8 translated X - WEAT1   and X - WEAT2 lists .   For the statistical analysis of the results , we esti-   mate the uncertainty on the statistic and the effect   size by ( i ) averaging the results with multiple lists   for CA - WEAT and ( ii ) creating bootstrapped ver-   sions of a single instance in all cases : WEAT , X-   WEAT and CA - WEAT . For the average version , we   provide the median and 95 % conﬁdence intervals   ( CI ) using order statistics given that the distribu-   tions are non - normal and contain few elements .   For the bootstrapped version , we resample with re-   placement the four lists involved in an experiment   to generate 5,000 synthetic sets per test . Tables 6 ,   7 , 8 and 9 in Appendix E show the detailed results . WEAT vs X - WEAT vs CA - WEAT . First , we   compare the conclusions one gets using each of   the three testing alternatives . Figure 1 depicts the   effect size estimations for X - WEAT and the me-   dian of the CA - WEAT tests . Biases measured with   X - WEAT are in general higher than those with CA-   WEAT , specially for pure static embeddings , but   differences are not statistically signiﬁcant at 95 %   level . The dispersion within a model and across lan-   guages is smaller for CA - WEAT than for X - WEAT ;   an indication that a single list is not representative   for a language and the average of several lists helps   to get closer to a universal effect size value .   The variation across lists of the same language   is big . The top - row plots in Figure 2 compare the   effect size of the original WEAT1 test and 5 CA-   WEAT1 lists created by native speakers of Amer-   ican English , taking 3 models as representatives .   The bottom part of each plot shows the effect size   for the CA - WEAT1 tests ( grey and red ) and the   WEAT1 test ( blue ) . The top part shows the his-   togram of the CA - WEAT1 tests and reports the2060   numbers displayed in Figure 1 . The ﬁve lists show   very different behaviours across models , but also   within a single model . For the monolingual model   CCe , we see that for three of the lists the effect is   compatible with no bias at 95 % level . One would   expect the average of the English CA - WEAT lists   to be close to WEAT , as the latter was obtained by   combining inputs from several subjects . However ,   the variation is huge and depends on the model .   In order to be able to substitute WEAT with CA-   WEAT , one needs multiple samples . X - WEAT can   be considered as just one of these samples and thiscan explain why the variation across languages is   larger with X - WEAT than with CA - WEAT .   The remaining plots in Figure 2 compare X- and   CA - WEAT1 by looking at the variation in more   samples , the Italian lists . The variation among   CA - WEATs is large for all models , and X - WEAT   results are within the CIs of CA - WEAT . According   to Sawilowsky ( 2009 ) ’s scale , the magnitude of   the biases ranges from medium ( d<0.5 ) to very   large ( < 1.2 ) for X - WEAT and from small ( < 0.2 )   to large ( < 0.8 ) for CA - WEAT . Similar trends are   seen for German , also with 24 CA - WEATs.2061   Comparable experiments with CCe . We com-   pare the effect size dacross languages and multi-   lingual methods in the setting where all the embed-   ding models are trained in a similar domain , using   the same amount of data . The size of the corpus is   not the only deciding factor though , as the number   of times that the items in the lists appear in the   corpus might also have an effect . Words in the lists   are frequent enough ( billions of occurrences ) to   get high quality embeddings , but an asymmetry be-   tween the number of positive and negative concepts   might create an artiﬁcial bias .   We test this hypothesis by studying the correla-   tion between the bias effect size and the difference   between the counts of the positive ( pleasant ) and   the negative ( unpleasant ) attributes . Figure 3   shows the relation for the monolingual CCe em-   bedding models . The correlation seems important   for X - WEAT1 ( top plot ) , which shows a positive   trend with half of the variation in the effect size be-   ing explained by the number of counts R=0.493 .   However , this might be an effect of either having   only 9 data points or X - WEAT and CA - WEAT   coming from two different distributions . When   we consider the 82 CA - WEAT1 tests and the 9   X - WEAT1 ( bottom plot ) , we observe a ﬂat slopewhere the variance is not explained by the counts   ( R=0.001 ) . Results for X-/CA - WEAT2 are equiv-   alent , withR=0.334andR=0.008respectively .   CA - WEAT lists allow to see that the lack of trend   is language independent . The average effect size   for Spanish is higher than for German , the count   difference is larger for English than for Croatian ,   but in none of the cases can the asymmetry counts   explain the effect size variance .   Multilinguality changes the distribution of effect   sizes and also the attribute counts in the training   corpus of some models . While CCeVMuns and   CCeVMsup project the pre - trained spaces into a   common one , CCe2langs andCCe9langs train the   joint embeddings on the concatenated corpus . In   this case , the counts change as different languages   can share the same surface token for some words .   This might be a reason why differences in biases   with respect to English in languages with different   scripts are more relevant than differences with lan-   guages in different families . But it is not the only   reason , as we observe the same trend in the pro-   jection methods . In general , the 4 multilingual ap-   proaches share the same conclusions as their mono-   lingual counterparts : for X - WEAT one observes a   positive correlation between dand the difference   of counts but , when inspecting all the CA - WEAT   lists , the correlation disappears . CCe9langs with   the widest differences of counts shows almost no   correlation for X - WEAT as well .   Multilingual models and isomorphism . Going   from monolingual CCe to bilingual CCeVMuns im-   plies a mitigation of the bias for CA - WEAT but   biases remain close to constant for X - WEAT ( see   Figure 1 ) . Contrary to the ﬁndings by Lauscher   and Glavaš ( 2019 ) , the bilingual embeddings do   not show a bias halfway between that of the 2 lan-   guages . The effect of supervision ( CCeVMuns vs   CCeVMsup ) is not consistent and results are in gen-   eral equivalent . With few exceptions , the effect of   CCe2langs and especially of CCe9langs is also a   mitigation of the bias with respect to the one ob-   served in the corresponding monolingual model   CCe , but this is not statistically signiﬁcant at 95 %   level . Arabic and Russian , both with non - Latin   alphabets , have the lowest d(together at times   with Turkish , the only other non - Indo - European   language ) , but we can not attribute it to multilin-   guality , because their effect size is also low for the   monolingual embeddings .   To further investigate what is behind the variance2062   in the multilingual setting , we evaluate the isomor-   phism between spaces . Intuitively , if spaces are iso-   morphic , multilinguality should not alter the prop-   erties of the monolingual embeddings ; if spaces are   far from being isomorphic , a joint training might   distort semantics and translations could lie further   apart in projected spaces . Some differences in d   could be therefore explained if spaces are not ( close   to ) isomorphic . We use two well known mea-   sures : the Eigenvector similarity ( EV ) ( Søgaard   et al . , 2018 ) and the Gromov - Hausdorff distance   ( GH ) ( Patra et al . , 2019).In both cases , lower   values indicate more isomorphic spaces . For WP ,   WPali , CCWP , CCe , CCeVMuns andCCeVMsup ,   we calculate the values between English and each   one of the other 8 languages L. For CCe2langs ,   CCe9langs , mBERT , XLM - RandXGLM , we   extract the subspaces for English and Lusing the   vocabulary in the English CCe and in the LCCe   and calculate the distance between the subspaces .   Table 1 compiles the results . As noted by Patra   et al . ( 2019 ) and Dutta Chowdhury et al . ( 2021 ) ,   the metrics do not produce equivalent results ; the   correlation between EV and GH is ρ= 0.47 in our   case . Interestingly , there is a systematic decrease   of the effect size with increasing distances , both for   EV and GH . The trend is more evident for GH and   applies both to X - WEAT and CA - WEAT . Figure 4   shows the trend for * -WEAT1 . The correlation be-   tween GH and the effect size is in this case −0.29   and GH describes only a 10 % of the variance . Sim-   ilar results are obtained for EV , GH , X - WEAT2   and CA - WEAT2 , as detailed in Appendix F.   Static embeddings in contextualised models .   Previous work focused on simple English sen-   tences . May et al . ( 2019 ) introduced the Sentence   Encoder Association Test ( SEAT ) . They generate   templates such as " This is [ TARGET ] . " or " [ TAR-   GET ] are things . " , were [ TARGET ] is substituted   by words in WEAT tests . Kurita et al . ( 2019 ) also   use templates ( " [ TARGET ] is a [ ATTRIBUTE ] " )   for social biases and WEAT1 and compare the   results from the standard WEAT measure and a   new log probability bias score . Finally , Guo and   Caliskan ( 2021 ) deﬁne yet another metric : the Con-   textualized Embedding Association Test ( CEAT )   which , instead of using a single template , collects   sentences where WEAT terms appear in different   contexts . The three methods have been evaluated   on WEAT1 with BERT with May et al . ( 2019 ) ob-2063taining an effect size of 0.22 , Kurita et al . ( 2019 )   of 0.67 and Guo and Caliskan ( 2021 ) of 0.64 .   When we move to the multilingual setting in   our experiments , we do not consider sentences , but   single words for which we extract the correspond-   ing embedding . Words are built from the subunits   in the language model vocabulary but , other than   that , no context is considered . This allows a fair   comparison across languages . As Figure 1 shows ,   static embeddings in contextual models show al-   most no bias and even negative effect sizes . The   trend is specially conﬁrmed for the languages for   which more CA - WEAT lists are available ( it , de , hr ,   es ) . Also notice that multilinguality further blurs   the biases . In general , monolingual BERT models   present less ( desired ) biases than WP , WPali and   CCWP for all languages but more biases than the   multilingual language models . This is not a conse-   quence of a lower isomorphism between language   subspaces , as Table 1 shows . We conjecture that   building word vectors from subunits might have an   impact in semantics at the word level . Differences   observed on models coming from different layers   are neither consistent nor signiﬁcant .   6 Summary and Conclusions   Non - social human biases in embeddings are usually   measured through WEAT association tests built in   English , in the US . We hypothesise that this can   be an issue when analysing embeddings in other   languages or cultures . In order to address the ques-   tion , we collected WEAT1 and WEAT2 lists written   by natives of 9 languages , which we call cultural   aware tests : CA - WEAT . We showed that different   CA - WEATs produce a large variation in the biases   and their effect size d. The values for WEAT and   X - WEAT always lie within the CA - WEAT conﬁ-   dence intervals . This supports the idea that a single   list ( test ) is not suitable for the analysis . Since we   do not have a gold standard for the real bias we   should expect in embeddings , one could argue that   thecorrect bias is the one given by the WEAT test ,   as it has been carefully designed . However , this   argument only holds for ( American ) English . For   any other language , X - WEAT can not assure the   same properties as WEAT . CA - WEAT , the multi-   lingual crowdsourced versions of WEAT , are the   alternative to X - WEAT   We extend previous work to multilingual and lan-   guage models taking this observation into account   and perform in parallel the analysis for WEAT , X - WEAT and CA - WEAT . We conﬁrm that mono-   lingual static embeddings show signs of non - social   human biases in all languages under study . When   using the average CA - WEAT , the dispersion of d   among languages for each model is smaller than   the dispersion with X - WEAT . This is an indication   that the average of several lists helps to get closer   to the expected universal results across languages .   Multilinguality has the effect of mitigating bi-   ases . This is seen in static word embeddings but   it is more evident in embeddings extracted from   language models . On the other hand , word embed-   dings in language models already produce a huge   mitigation with respect to their static counterparts ,   up to the point that effect sizes in multilingual lan-   guage models can be negative . As a result , the   trend can be inverse to the one observed in humans ,   being insects more pleasant than ﬂowers in some   languages .   Unexpectedly , the asymmetry between the   amount of pleasant and unpleasant attributes in the   training corpus is not responsible for the variance   in the embeddings biases . Since CA - WEAT in-   cludes only frequent words in our training corpora ,   reliable representations are obtained , irrespective   of any asymmetry . Differences in departures from   isomorphism between languages in multilingual   models describe up to a 10 % of the variance . Even   the trend is clear , this alone can not explain the   mitigation of the biases in either multilingual or   contextualised models .   In the light of these outcomes , we expect to   broaden the analysis to a more diverse set of lan-   guages extending the CA - WEAT tests , and design   a fair multilingual setting for language models at   sentence level .   Limitations   To the best of our knowledge , only 2 IAT tests   are non - social , the other ones relate to other kinds   of biases , such as gender or race , which are not   pertinent for our study . We observe a large variabil-   ity in the results between models but sometimes   also between * -WEAT1 and * -WEAT2 . More non-   social psychologically - motivated IAT tests would   be relevant to strengthen our conclusions .   When we deﬁned CA - WEAT , we chose not to   constrain the list of items and attributes to single   words , multi - word terms were allowed for a wider   coverage and also for a future reusability of the   tests for sentence embeddings . As a result , some2064items in the lists can be out - of - vocabularies ( OOV )   in static word embeddings . This is relevant for   Arabic , with 14 OOVs in both the WPembeddings   and the CCe variants for X - WEAT1 , and 6 and 7   OOVs for X - WEAT2 respectively . Turkish follows   with 11 and 7 OOVs for X - WEAT1 , and 5 and 3 for   X - WEAT2 . There are no OOVs in contextualised   embeddings , where we sum the embeddings for all   the subword units in a term .   Ethayarajh et al . ( 2019 ) showed that WEAT and   the way how the effect size dis calculated causes   a systematic overestimation of the biases . They   also showed that in word embedding models that   do some kind of matrix factorisation , such as skip-   gram with negative sampling ( it factorises a shifted   word - context PMI matrix ( Levy and Goldberg ,   2014 ) ) or GloVe ( it factorises a logarithmic co-   occurrence count matrix ( Pennington et al . , 2014 ) )   having no bias is only possible if the positive ( pleas-   antin our case ) and negative ( unpleasant ) attributes   occur with equal frequency in the corpus . Since   the main motivation of our work is to study the ef-   fect of multilinguality and not the base models , we   dodge the limitation for static embeddings by us-   ing CBOW , and we empirically show in Section 5   that the bias in our CBOW experiments does not   correlate with the differences between pleasant and   unpleasant counts in the corpus . However , the pre-   trained WPandWPali used skip - gram and might   be affected .   Acknowledgements   We thank the students of the Department of Inter-   preting and Translation at Università di Bologna ,   colleagues at Universität des Saarlandes , DFKI and   several other locations around the world for pro-   ducing the CA - WEAT dataset . CEB was supported   by the German Research Foundation ( Deutsche   Forschungsgemeinschaft ) under grant SFB 1102 :   Information Density and Linguistic Encoding .   References206520662067A CA - WEAT Data Collection2068B The CA - WEAT Dataset   C WEAT1 and WEAT2 Original Lists2069D The CCe Corpus207020712072E Bias Statistic and Effect Size2073207420752076F Isomorphism Analysis2077