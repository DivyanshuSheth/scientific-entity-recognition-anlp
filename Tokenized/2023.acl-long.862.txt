  Jiang Li , Xiangdong Su , Guanglai GaoCollege of Computer Science , Inner Mongolia University , Hohhot , ChinaNational & Local Joint Engineering Research Center of Intelligent Information   Processing Technology for Mongolian , Hohhot , China   lijiangimu@gmail.com , cssxd@imu.edu.cn , csggl@imu.edu.cn   Abstract   Temporal knowledge graph embedding   ( TKGE ) models are commonly utilized to   infer the missing facts and facilitate reasoning   and decision - making in temporal knowledge   graph based systems . However , existing   methods fuse temporal information into   entities , potentially leading to the evolution   of entity information and limiting the link   prediction performance of TKG . Meanwhile ,   current TKGE models often lack the ability   to simultaneously model important relation   patterns and provide interpretability , which   hinders their effectiveness and potential   applications . To address these limitations , we   propose a novel TKGE model which encodes   Temporal knowledge graph embeddings   viaArchimedean Spiral Timeline ( TeAST ) ,   which maps relations onto the corresponding   Archimedean spiral timeline and transforms the   quadruples completion to 3th - order tensor com-   pletion problem . Speciﬁcally , the Archimedean   spiral timeline ensures that relations that   occur simultaneously are placed on the same   timeline , and all relations evolve over time .   Meanwhile , we present a novel temporal spiral   regularizer to make the spiral timeline orderly .   In addition , we provide mathematical proofs to   demonstrate the ability of TeAST to encode   various relation patterns . Experimental results   show that our proposed model signiﬁcantly   outperforms existing TKGE methods . Our   code is available at https://github.com/   IMU - MachineLearningSXD / TeAST .   1 Introduction   Knowledge graph ( KG ) expresses the relations of   real - world entities and allows for reasoning new   facts , which enables a wide range of applications   in natural language processing ( Chen et al . , 2019 ;   Junior et al . , 2020 ; Hu et al . , 2021 ) . It stores a   vast amount of knowledge in the form of triplets .   These triplets are typically denoted as ( s , r , o ) , Figure 1 : A brief illustration of mapping relations to   Archimedean spiral timeline . Three facts are ( Guido   van Rossum , r1 , Google , 2010 - 12 ) , ( Guido van Rossum ,   r2 , Google , 2012 - 12 ) and ( Messi , r3 , FCB , 2010 - 12 ) .   wheres , randorepresent the subject , the rela-   tion , and the object . Since knowledge changes   over time , researchers introduced timestamps into   knowledge graphs to create temporal knowledge   graphs ( TKGs ) . In TKGs , each knowledge fact   is represented as a quadruple ( s , r , o , τ ) , whereτ   denotes the timestamp at which the fact was true .   This allows for more precise representation and   querying of information in knowledge graphs , en-   abling applications that require an understanding   of the evolution of knowledge over time . Given the   inherent incompleteness of most KGs and TKGs ,   knowledge graph embedding ( KGE ) and temporal   knowledge graph embedding ( TKGE ) have been   widely investigated to infer the missing facts using   the existing ones . In particular , TKGE has gained   signiﬁcant attention for its ability to represent and   analyze knowledge over time . This work focuses   on TKGE .   With the advancement of deep learning , re-   searchers have proposed a number of KGE ap-   proaches . These approaches typically involve learn-   ing low - dimensional embeddings of entities and re-   lations , and then using a score function to measure15460the plausibility of triplets ( Ji et al . , 2022 ) . While   existing KGE approaches have been shown to be   effective on static knowledge graphs , they can not   be directly applied to TKGs due to the fact that   real - world knowledge is dynamic and changes over   time . To address this issue , researchers have de-   signed TKGE models that are capable of capturing   the temporal information and dynamic nature of   real - world facts . Recent TKGE models ( Lacroix   et al . , 2020 ; Xu et al . , 2020a , 2021 ; Chen et al . ,   2022 ) have shown very impressive completion per-   formance on TKGs .   Nevertheless , there are two problems with these   TKGE models . Firstly , the fusion of temporal in-   formation into entities led to a potential evolution   of entity information , thus limiting the link predic-   tion performance on TKG . In fact , the meaning of   entities in quadruples does not change over time ,   whereas the relations between connected entities   do . Secondly , existing TKGE models are not capa-   ble of simultaneously encoding important relation   patterns and providing interpretability , which hin-   ders their effectiveness and potential applications .   To tackle these issues , we draw inspiration   from the Archimedean spiral and design Temporal   knowledge graph embeddings via Archimedean   Spiral Timeline ( TeAST ) . Speciﬁcally , we ﬁrst map   relations onto the corresponding Archimedean spi-   ral timeline and form a uniﬁed representation for   the timestamp and the relation . As shown in Fig-   ure 1 , we expect relations at the same time to be on   the same timeline and relations evolve over time .   That is , we simplify the quadruples ( s , r , o , τ ) to a   triplet ( s , r / circleringτ , o ) , where /circleringdenotes Archimedean   spiral operation . As a result , we transform the TKG   embedding as 3th - order tensor completion problem   in the complex space . Next , we optimize the graph   embeddings through tensor factorization . In addi-   tion , we propose a new temporal spiral regularizer   to constrain the time representation and make the   spiral timeline orderly . We further provide mathe-   matical proofs to demonstrate the ability of TeAST   to encode various relation patterns . Experiments   show that our method signiﬁcantly outperforms the   existing methods on TKGE benchmarks .   Different from the existing TKGE models , we   map relations onto the Archimedean spiral timeline   and avoid incorporating temporal information into   the entities . It ensures that the relations can evolve   over time and the entities remain unchanged in   TKGs . This is consistent with real - world facts.2 Related Work   2.1 Static Knowledge Graph Embedding   Motivated by the translation invariance principle in   word2vec ( Mikolov et al . , 2013 ) , TransE deﬁnes   the distance between e+eandewith thelor   lnorm constraint , where e , edenote entity em-   bedding vectors and edenote relation embedding   vectors . The score function of TransE is deﬁned as   φ(s , r , o ) = ||e+e−e|| . Following TransE ,   TransH ( Wang et al . , 2014 ) , TransR ( Lin et al . ,   2015 ) and TransD ( Ji et al . , 2015 ) employ different   projection strategies to adjust graph embeddings .   Different from the above distance based models ,   RESCAL ( Nickel et al . , 2011 ) , DistMult ( Yang   et al . , 2015 ) , ComplEx ( Trouillon et al . , 2016 ) and   SimplE ( Kazemi and Poole , 2018 ) employ tensor   factorization based to model knowledge graphs , in   which each relation ris mapped into a latent se-   mantic matrix M. In addition , RotatE ( Sun et al . ,   2019 ) and QuatE ( Zhang et al . , 2019 ) treat each   relation as a rotation in complex space and in the   quaternion space , respectively .   2.2 Temporal Knowledge Graph Embedding   Analogously to KGE models , TKGE models add   the temporal information and calculates the score   function for the quadruples to evaluate its rea-   sonableness . Therefore , most TKGE models are   based on existing KGE models . TTransE ( Leblay   and Chekol , 2018 ) extends TransE and encodes   time stamps τas translations same as relations .   Hence , the score function of TTransE is denoted   asφ(s , r , o , τ ) = ||e+e+e−e|| . Fur-   thermore , TA - TransE ( García - Durán et al . , 2018 )   and TA - DistMult ( García - Durán et al . , 2018 ) en-   code timestamps based on TransE and DistMult ,   respectively . TComplEx ( Lacroix et al . , 2020 ) and   TNTComplEx ( Lacroix et al . , 2020 ) build on Com-   plEx and perform a 4th - order tensor decomposition   of a TKG . DE - SimplE ( Goel et al . , 2020 ) adds   a diachronic entity ( DE ) embedding function to   learn the temporal entities . ChronoR ( Sadeghian   et al . , 2021 ) is based on RotatE and learns a k-   dimensional rotation transformation parametrized   by relation - time pairs . Next , each subject entity   is transformed with the rotation . TeLM ( Xu et al . ,   2021 ) performs more expressive multivector repre-   sentations to encode a temporal KG and utilizes the   asymmetric geometric product . In addition , Rotate-   QVS ( Chen et al . , 2022 ) builds on QuatE and en-   codes both entities and relations as quaternion em-15461   beddings , in which the temporal entity embeddings   are represented as rotations in the quaternion space .   Recently , BoxTE ( Messner et al . , 2022 ) models the   TKGE based on a box embedding model BoxE ( Ab-   boud et al . , 2020 ) .   3 Background and Notation   3.1 Archimedean Spiral   As mentioned , we expect the relations with the   same timestamp to be on the same timeline and   all relations evolve over time . We choose the   Archimedean spiral to model TKGs in the proposed   method . Through the angle of rotation around the   origin , Archimedean spiral provides the possibility   of distinguishing the relations on the same timeline .   In mathematics , Archimedean spiral ( also known   as the arithmetic spiral ) was named in honor of   the Greek mathematician Archimedes . As shown   in Figure 2 , it is the locus corresponding to the   locations over time of a point moving away from a   ﬁxed point with a constant speed along a line that   rotates with constant angular velocity . Equivalently ,   in polar coordinates ( ξ , θ)it can be described by   the equation :   ξ = a+b·θ , ( 1 )   whereacontrols the distance from the starting   point of the spiral to the origin , bcontrols the dis-   tance between loops , and θis the angle of rotation   of the spiral . The distance between each loop is   2πb .   3.2 Relation Patterns   LetEdenote the set of entities , Rdenote the set   of relations , andTdenote the set of the timestamp . Given a temporal knowledge graph G , it can be   deﬁned as a collection of quadruples ( s , r , o , τ ) ,   wheres∈E , r∈R , o∈Eandτ∈T denote the   subject entity , relation , object entity and timestamp ,   respectively .   As previous studies ( Sun et al . , 2019 ; Chen et al . ,   2022 ) highlighted , TKGE has focused on several   key relations patterns , including :   Deﬁnition 1 . A relationris symmetric , if∀s , o , τ ,   r(s , o , τ ) ∧r(o , s , τ ) holds True .   Deﬁnition 2 . A relationris asymmetric , if∀s , o , τ ,   r(s , o , τ ) ∧¬r(o , s , τ ) holds True .   Deﬁnition 3 . Relationris the inverse of r , if   ∀s , o , τ , r(s , o , τ ) ∧r(o , s , τ ) holds True .   Deﬁnition 4 . Relationrandrare evolving over   time from timestamp τto timestamp τ , if∀s , o , τ ,   r(s , o , τ)∧r(s , o , τ)holds True .   4 Methodology   4.1 TeAST Model   In this section , we introduce the novel TeAST   model , which represents the relations on   Archimedean spiral timelines . Since many   previous works ( Trouillon et al . , 2016 ; Sun et al . ,   2019 ; Lacroix et al . , 2020 ; Xu et al . , 2020a ) have   demonstrated that encoding knowledge graphs in   complex space can better capture potential links   between entities , we also model TKGs in the   complex space . For a quadruple ( s , r , o , τ ) , we   also usee , e , eandeto denote the subject   embedding , relation embedding , object embedding   and timestamp embedding respectively in the   complex space . We have   e = Re(s ) + iIm(s),e = Re(r ) + iIm(r ) ,   e = Re(o ) + iIm(o),e = Re(τ ) + iIm(τ ) ,   ( 2 )   wheree , e , e , e∈C , andRe(∗)is the real   vector component and Im(∗)is an imaginary vec-   tor component .   We ﬁrst map relations onto the corresponding   Archimedean spiral timeline . Speciﬁcally , we re-   gard each relation as different the angle of rota-   tionθin Eq . 1 , and regard each timestamp as   distance control parameter bin Eq . 1 . Therefore ,   the range of embedding values for each relation is   e∈(0,2π ) . To prevent crossover between spirals ,   we set the starting point of all spirals to the origin .   That is , we set a= 0for TeAST in Eq . 1 . On this   basis , we map all relations to the matching spiral   timeline , denoted as:15462ξ = e ◦ e , ( 3 )   where ◦ denotes the Hadamard product . Since   TeAST is modeled in complex space , we employ   the Hadamard product to do spiral timeline map-   ping for the relations accordingly . Further , we have   ξ = Re(τ)Re(r)−Im(τ)Im(r )   + iRe(τ)Im(r ) + iIm(τ)Re(r),(4 )   whereRe(r)∈(0,2π)andIm(r)∈(0,2π ) . All   relation embeddings are all constrained between 0   and2π . This ensures that the relations can be ef-   fectively mapped to the corresponding spiral time-   lines .   Following previous tensor factorization mod-   els ( Trouillon et al . , 2016 ; Lacroix et al . , 2020 ) ,   the score function of TeAST is denoted as :   φ(s , r , o , τ ) = Re(<e , ξ,¯e>).(5 )   Then , we optimize the graph embeddings through   the score function .   Furthermore , since Archimedean spiral is based   on the polar coordinate system , we can regard ξ   as a modulus part . During the model training pro-   cess , we note that there are inevitably equal mod-   ulus cases on different spiral timelines , leading   to confusion between semantic relations . There-   fore , we employ timestamp phase information   e = Re(τ ) + iIm(τ)to avoid the bad cases ,   whereRe(τ),Im(τ)∈R. Additionally , we use   absolute values to constrain the temporal phase in-   formation to be isotropic over time . This is done   to enforce consistency and avoid any directional   bias . As phases have periodic characteristics , we   employ a sine function to measure the timestamp   phase embeddings similar to HAKE ( Zhang et al . ,   2020 ) . Combining the modulus part and the phase   part , we get   ξ= ( Re(τ)Re(r ) + sin(Re(τ ) )   −(Im(τ)Im(r ) + sin(Im(τ ) )   + i(Re(τ)Im(r ) + sin(Re(τ ) )   + i(Im(τ)Re(r ) + sin(Im(τ)).(6 )   The improved score function of TeAST is given   by   φ(s , r , o , τ ) = Re(<e , ξ,¯e>).(7)It is worth noting that the number of parameters   of TeAST increases linearly with embedding di-   mensionk . Hence , the space complexity of TeAST   model isO(k ) , similar to TNTComplEx ( Lacroix   et al . , 2020 ) . In addition , we calculate the score   function of TeAST with Hadamard product be-   tween k - dimensional complex vector embeddings   as TNTComplEx . The time complexity of TeAST   and TNTComplEx equals to O(k ) .   4.2 Loss Function   Following TNTComplEx ( Lacroix et al . , 2020 ) and   TeLM ( Xu et al . , 2021 ) , we use reciprocal learn-   ing to simplify the training process , and the loss   function is deﬁned as follows :   L=−log(exp(φ(s , r , o , τ ) ) /summationtextexp(φ(s , r , o , τ ) ) )   −log(exp(φ(o , r , s , τ))/summationtextexp(φ(o , r , s , τ ) ) )   + λ / summationdisplay(/bardble / bardbl+/bardblξ / bardbl+/bardble / bardbl),(8 )   whereλdenotes N3 regularization weight and r   is the inverse relation . According to several studies ,   N3 regularization improves the performance of the   KGE models ( Lacroix et al . , 2018 ; Xu et al . , 2020b )   and TKGE models ( Lacroix et al . , 2020 ; Xu et al . ,   2021 ) based on tensor factorization .   4.3 Temporal Regularization   The temporal regularization can constrain the tem-   poral embedding information and thus better model   TKGs . TNTComplEx ( Lacroix et al . , 2020 ) expects   neighboring timestamps to have close representa-   tions . Hence , the smoothing temporal regularizer   is deﬁned as :   Λ=1   N−1 / summationdisplay / bardble−e / bardbl,(9 )   whereNis the number of time steps .   Recently , TeLM ( Xu et al . , 2021 ) introduces the   linear temporal regularizer by adding a bias com-   ponent between the neighboring temporal embed-   dings , which can be deﬁned as :   Ω=1   N−1 / summationdisplay / bardble−e−e / bardbl ,   ( 10)15463whereedenotes the randomly initialized biased   embedding , which is then learned from the training   process .   In this work , we employ the Archimedean spiral   to model TKGs . The previous temporal regular-   ization methods expect the adjacent timestamps   to be close to each other . For our model TeAST ,   this leads to the spiral timeline overlapping sce-   narios . To avoid these bad scenarios , we develop   a novel temporal spiral regularizer by adding the   phase timestamp embedding eto the smoothing   temporal regularizer . The temporal regularization   function is deﬁned as :   L=1   N−1 / summationdisplay / bardbl(e−e )   + ( e−e)/bardbl.(11 )   The total loss function of TeAST is deﬁned as :   L = L+λL , ( 12 )   whereλis the weight of the temporal regularizer .   4.4 Modeling Various Relation Patterns   TeAST can model important relation patterns , in-   cluding symmetric , asymmetric , inverse and tempo-   ral evolution patterns . We list all the propositions   here and provide the proofs in Appendix .   Proposition 1 . TeAST can model the symmetric   relation pattern . ( See proof in Appendix A )   Proposition 2 . TeAST can model the asymmetric   relation pattern . ( See proof in Appendix B )   Proposition 3 . TeAST can model the inverse rela-   tion pattern . ( See proof in Appendix C )   Proposition 4 . TeAST can model the temporal evo-   lution pattern . ( See proof in Appendix D )   5 Experiments   5.1 Datasets   We evaluate TeAST on three TKGE benchmark   datasets . ICEWS14 andICEWS05 - 15 ( García-   Durán et al . , 2018 ) are both extracted from the   Integrated Crisis Early Warning System ( ICEWS )   dataset ( Lautenschlager et al . , 2015 ) , which con-   sists of temporal sociopolitical facts starting from   1995 . ICEWS14 consists of sociopolitical events   in 2014 and ICEWS05 - 15 involves events occur-   ring from 2005 to 2015 . GDELT is a subset of the   larger Global Database of Events , Language , and   Tone ( GDELT ) TKG dataset ( Leetaru and Schrodt ,   2013 ) . The GDELT contains facts with daily times-   tamps between April 1 , 2015 and March 31 , 2016 ,   and only contains 500 most common entities and   20 most frequent relations . It is worth noting that   GDELT holds a large number of quadruples ( 2 M )   but does not describe enough entities ( 500 ) . Hence ,   The GDELT requires a strong temporal inductive   capacity .   5.2 Evaluation Protocol   In this paper , we evaluate our TKGE model using   the benchmarks mentioned above . Following the   strong baselines ( Lacroix et al . , 2020 ; Xu et al . ,   2021 ; Chen et al . , 2022 ) , the quality of the rank-   ing of each test triplet is evaluated by calculating   all possible substitutions of subject entity and ob-   ject entity : ( s , r , o , τ ) and(s , r , o , τ ) , where s ,   o∈ E. And then , we sort the score of candi-   date quadruples under the timewise ﬁltered set-   tings ( Lacroix et al . , 2020 ; Xu et al . , 2021 ; Chen   et al . , 2022 ) . The performance is evaluated using   standard evaluation metrics , including Mean Recip-   rocal Rank ( MRR ) and Hits@ n. Hits@nmeasures   the percentage of correct entities in the top npredic-   tions . Higher values of MRR and Hits@ nindicate   better performance . Hits ratio with cut - off values   n= 1,3,10 . In this paper , we utilize H@ nto   denote Hits@ nfor convenience .   5.3 Baselines   We compare our model with the state - of - the-   art TKGE models , including TTransE ( Leblay   and Chekol , 2018 ) , DE - SimplE ( Goel et al . ,   2020 ) , TA - DistMult ( García - Durán et al . , 2018 ) ,   ChronoR ( Sadeghian et al . , 2021 ) , TCom-   plEx ( Lacroix et al . , 2020 ) , TNTComplEx ( Lacroix   et al . , 2020 ) , TeLM ( Xu et al . , 2021 ) , BoxTE ( Mess-   ner et al . , 2022 ) and RotateQVS ( Chen et al . , 2022).15464   Note that TComplEx and TNTComplEx are also   based on tensor factorization TKGE methods in the   complex space , and thus we consider TComplEx   and TNTComplEx as the main baselines . Further-   more , TeLM performs multivector tensor factoriza-   tion for a TKG . Hence , TeLM has twice the space   complexity of TeAST , TComplEx and TNTCom-   plEx . Among the existing TKGE methods , TeLM   obtains SOTA results on ICEWS14 and ICEWS05-   15 and BoxTE achieves SOTA results on GDELT   dataset .   5.4 Experimental Setup   We implement our proposed model TeAST via py-   torch based on TNTComplEx ( Lacroix et al . , 2020 )   training framework . All experiments are trained   on a single NVIDIA Tesla V100 with 32 GB mem-   ory . We use Adagrad ( Duchi et al . , 2011 ) optimizer   and employ grid search to ﬁnd the best hyperparam-   eters based on the performance on the validation   datasets . The learning rate is set to 0.1and the em-   bedding dimension kis set to 2000 in all cases . The   best models are selected by early stopping on the   validation datasets , and the max epoch is 200 . The   optimal hyperparameters for TeAST are as follows :   •ICEWS14 : λ= 0.0025,λ= 0.01   •ICEWS05 - 15 : λ= 0.002,λ= 0.1   •GDELT : λ= 0.003,λ= 0.003   We report the average results on the test set   for ﬁve runs . We omit the variance as it is gen - erally low . The training processes of TeAST on   ICEWS14 , ICEWS05 - 15 and GDELT cost less   than half an hour , less than an hour and ﬁve hours ,   respectively .   6 Results and Analysis   6.1 Main Results   The link prediction results on ICEWS14 ,   ICEWS05 - 15 and GDELT are shown in Table 2 .   We observe that TeAST surpasses all baselines on   ICEWS14 , ICEWS05 - 15 and GDELT regarding   all metrics . Since TeAST employs the temporal   Archimedean spiral to encode relation embeddings ,   this allows relations that occur at the same moment   to be mapped onto the same spiral timeline and   all relations evolve over time . It builds a close   connection between the relation and timestamp   and avoids incorporating temporal information   into the entities for TKG . It proves that mapping   the relations to Archimedean spiral timeline   is an effective way to learn graph embeddings .   TeAST can better encode temporal knowledge   graphs and captures the latent information between   subject entities and object entities . Meanwhile ,   the temporal spiral regularizer in TeAST avoids   spiral timeline overlapping scenarios and further   improves the performance . BoxTE ( Messner et al . ,   2022 ) has shown that GDELT requires a high   level of temporal inductive capacity for effective   encoding . This is because GDELT exhibits a   signiﬁcant degree of temporal variability , with   some facts lasting across multiple consecutive time   stamps while others are momentary and sparse.15465   In comparison to the SOTA method BoxTE on   GDELT , TeAST achieves superior results on all   metrics .   6.2 Effect of Temporal Regularizer   We study the effect of temporal regularization on   ICEWS14 , and compare the performance of TeAST   with the previously proposed temporal regularizers ,   including the smoothing temporal regularizer Λin   Eq . 9 , the linear temporal regularizer Ωin Eq . 10   and our proposed temporal spiral regularizer Lin   Eq . 11 . We set the temporal regularization weight   λ∈{0.0001,0.001,0.005,0.01,0.1 } . Detailed   results of the effect of temporal regularization on   ICEWS14 are given in Figure 3 . The blue line de-   notes the temporal spiral regularizer . Compared   with the previously proposed temporal regularizers ,   the temporal spiral regularizer improved MRR by   0.8 points , Hits@10 by 0.3 points , and Hits@1 by   1.2 points , respectively . Since the temporal spiral   regularizer adds a phase timestamp embedding to   avoid the overlap of Archimedean spiral timelines   and thus can better discriminate timestamp infor - mation .   Furthermore , we utilize t - SNE ( Van der Maaten   and Hinton , 2008 ) to visualize the trained times-   tamp embeddings of TeAST , which with and with-   out the temporal spiral regularizer . The visualiza-   tion results are shown in Figure 4 . We observe   that the distribution of adjacent temporal embed-   dings of TeAST without temporal spiral regular-   ization trained is scattered . There are only a few   months that come together , such as January , Octo-   ber and November . In addition , we observe some   overlapping scenarios of the learned time embed-   dings , suggesting that the learned time embedding   is not inaccurate . It will further hinder the effective-   ness of learning the facts associated with a speciﬁc   timestamp .   On the contrary , using the temporal spiral regu-   larizer in TeAST can learn time embedding infor-   mation effectively , resulting in orderly time clus-   ters . This demonstrates the effectiveness of the   temporal spiral regularizer in improving the abil-   ity of the model to accurately capture and retain   information about speciﬁc timestamps . In addition,15466   we notice a very interesting phenomenon : TeAST   also learned deep information about the order be-   tween months with the temporal spiral regularizer   and the temporal embedding of the same month   presented on the same line . The results further sug-   gest a good ﬁt with our initial motivation that each   relation should be mapped onto a temporal spiral   and the relations with the same timestamp should   be on the same timeline .   6.3 Analysis on Relation Embeddings   As for TeAST , we employ the Archimedean spiral   to map relations into the polar coordinate system .   Therefore , we map the learned relation embedding   of the same time to the corresponding timeline   in the polar coordinate system . The results are   shown in Figure 5 . The mapping algorithm is   based on the implementation of Eq . 3 . The Fig-   ure 5 shows the relation embedding projection for   four different times . We can see that the relation   embeddings of the same timestamp are ﬁtted as an   Archimedean spiral timeline . This is further evi-   dence that TeAST can effectively encode relations   onto the corresponding spiral timeline .   6.4 Ablation Studies   In this part , we conduct ablation studies on map-   ping entities and mapping relations of TeAST andthe phase item . Table 3 shows the results on   ICEWS14 and ICEWS05 - 15 benchmark datasets .   The results of the comparison of mapping entities   and mapping relations on the spiral timeline in-   dicate that mapping relations on the spiral time-   line is more effective than mapping entities on the   spiral timeline for TeAST . This is further proof   that the design motivation of TeAST is the mean-   ings of the entities in quadruples do not change   as time evolves , while the relations between enti-   ties change in TKGs . In addition , we also observe   that TeAST achieves better link prediction results   with phase vectors , because it can well distinguish   relations at the same level of semantic hierarchy .   It is worth noting that TeAST also obtains better   or more competitive results without phase vectors   than TComplEx and TNTComplEx on ICEWS14   and ICEWS05 - 15 . The results show that TeAST   maps relations on the corresponding Archimedean   spiral timelines , which can effectively model tem-   poral knowledge graphs .   7 Conclusion   This paper proposes a novel and interesting TKGE   method TeAST , which maps relations onto the cor-   responding Archimedean spiral timeline . The ex-   perimental results fully illustrate that TeAST can   better model TKG than previous methods and learn15467the relation information over time . We also pro-   vide formal mathematical proofs to demonstrate   that TeAST can encode the key relation patterns .   In addition , the temporal spiral regularizer learns   the latent information about the order between   months better and improves the link prediction per-   formances . This work will hopefully stimulate fur-   ther research on TKGE models and provide a novel   perspective on the subject .   Limitations   As previously mentioned , TeAST maps relations   onto the corresponding Archimedean spiral time-   line and transforms the quadruples completion to   3th - order tensor factorization . It is required to   store the values and this slightly increase the space   requirement and training time in the embedding   learning process . Among all the baselines , TCom-   plEx , TNTComplEx and TeLM are all tensor fac-   torization based models . Table 4 compares training   time and space requirement between our model and   baselines on ICEWS14 . TComplEx is the smallest   model and takes the minimum training time . Com-   pared with TComplEx , our model is about 4.6 %   bigger than TComplEx , and takes 21.4%more   training time .   Acknowledgement   This work was funded by National Natural Science   Foundation of China ( Grant No . 61762069 ) , Key   Technology Research Program of Inner Mongolia   Autonomous Region ( Grant No . 2021GG0165 ) ,   Key R&D and Achievement Transformation Pro-   gram of Inner Mongolia Autonomous Region   ( Grant No . 2022YFHH0077 ) , The Central Govern-   ment Fund for Promoting Local Scientiﬁc and Tech-   nological Development ( Grant No . 2022ZY0198 ) ,   Big Data Lab of Inner Mongolia Discipline Inspec - tion and Supervision Committee ( Grant No . 21500-   5206043 ) .   References1546815469A Proof of Propositions 1   The score function of TeAST is deﬁned as :   φ(s , r , o , τ ) = Re(<e , ξ,¯e > )   = Re(/summationdisplayeξ¯e )   = < Re ( e),Re(ξ),Re(e ) >   + < I m ( e),Re(ξ),Im(e ) >   + < Re ( e),Im(ξ),Im(e ) >   −<Im ( e),Im(ξ),Re(e ) > .   ( 13 )   Following ComplEx ( Trouillon et al . , 2016 ) ,   we employ the standard componentwise multi-   linear dot product < a , b , c > : = /summationtextabcin   Eq . 13 . For symmetric pattern , we have r(s , o , τ ) ∧   r(o , s , τ ) according to Deﬁnition 1 . Hence , we get   φ(s , r , o , τ ) = φ(o , r , s , τ ) . ( 14 )   One can easily check that Eq . 14 meet the sym-   metric pattern conditions when ξis real ( i.e. its   imaginary part is zero ) . We have   φ(s , r , o , τ ) = < Re ( e),Re(ξ),Re(e ) >   + < I m ( e),Re(ξ),Im(e ) >   = < Re ( e),Re(ξ),Re(e ) >   + < I m ( e),Re(ξ),Im(e ) >   = φ(o , r , s , τ ) .   ( 15 )   Therefore , a sufﬁcient necessary condition for   TeAST to be able to model symmetric pattern is   Im(ξ ) = 0 .   B Proof of Propositions 2   For asymmetric pattern , we have r(s , o , τ ) ∧   ¬r(o , s , τ ) according to Deﬁnition 2 . Hence , we   get   φ(s , r , o , τ ) /negationslash = φ(o , r , s , τ ) . ( 16 )   One can easily check that Eq . 16 meet the asymmet-   ric pattern conditions when ξis purely imagi-15470nary ( i.e. its real part is zero ) . We have   φ(s , r , o , τ ) = < Re ( e),Im(ξ),Im(e ) >   −<Im ( e),Im(ξ),Re(e ) > ,   φ(o , r , s , τ ) = < Re ( e),Im(ξ),Im(e ) >   −<Im ( e),Im(ξ),Re(e ) > .   ( 17 )   We can get φ(s , r , o , τ ) /negationslash = φ(o , r , s , τ ) . There-   fore , a sufﬁcient necessary condition for TeAST   to be able to model asymmetric pattern is   Re(ξ ) = 0 .   C Proof of Propositions 3   For inverse pattern , we have r(s , o , τ ) ∧r(o , s , τ )   according to Deﬁnition 3 . Hence , we get   φ(s , r , o , τ ) = φ(o , r , s , τ)⇔   e=¯e⇔   Re(r ) + Re(r ) = 0∧Im(r)−Im(r ) = 0 ,   ( 18 )   where ¯eis the conjugate of e.   D Proof of Propositions 4   For temporal evolution pattern , we have   r(s , o , τ)∧r(s , o , τ)according to Deﬁnition 4 .   Hence , we have   φ(s , r , o , τ ) = φ(s , r , o , τ)⇔   ξ = ξ.(19 )   It is worth noting that ξ = ξjust   means the values of their modulus part add phase   part are equal . The relations at the same time are   mapped on the corresponding Archimedean spiral   timeline in the polar spatial representation .   E Analysis and Case Study for Several   Key Relation Patterns   To illustrate the learned relation patterns that con-   tain symmetric , asymmetric , inverse and tempo-   ral evolution patterns , we visualize some exam-   ples by visualizing the histograms of the learned   embeddings . All cases are from ICEWS14   dataset ( García - Durán et al . , 2018 ) .   E.1 Symmetric Pattern   As shown the proof of Propositions 1 ( see Ap-   pendix A ) , TeAST can encode symmetric pattern   whenIm(ξ ) = 0 is satisﬁed . As shown in Fig-   ure 6 , tow facts ( Kazakhstan , Consult , Afghanistan ,   2014 - 04 - 11 ) and ( Afghanistan , Consult , Kaza-   khstan , 2014 - 04 - 11 ) from ICEWS14 , and Consult   is a symmetric relation . We observe that the learned   Im(ξ)in Figure 6(c ) is close to 0 . The result   demonstrates that TeAST can model the symmetric   pattern .   E.2 Asymmetric Pattern   Opposite to symmetric pattern , TeAST can encode   asymmetric pattern when Re(ξ ) = 0 is satis-   ﬁed . Figure 7 shows an example of asymmetric   pattern and Make statement is taken an asymmetric   relation . Figure 7(c ) shows that our TeAST can   model the asymmetric pattern .   E.3 Inverse Pattern   As shown the proof of Propositions 3 ( see Ap-   pendix C ) , if ris the inverse of the r , and we have   Re(r ) + Re(r ) = 0∧Im(r)−Im(r ) = 0 .   Two existing facts ( Iraq , Host a visit , Nuri al-   Maliki , 2014 - 06 - 13 ) and(Nuri al - Maliki , Make15471   a visit , Iraq , 2014 - 06 - 13 ) from ICEWS14 , which   the relation Host a visit is the inverse of the relation   Make a visit . Figure 8 shows that TeAST satisﬁes   the above conditions .   E.4 Temporal Evolution Pattern   As shown in Proof of Propositions 4 ( see Ap-   pendix D ) , if a relation rand a relation rare   evolving over time from τfromτ , we have   ξ = ξ . To verify that TeAST can model   the temporal evolution pattern , we randomly se - lect ﬁve facts , including ( Nuri al - Maliki , Make a   visit , Iraq , 2014 - 06 - 13 ) , ( Nuri al - Maliki , Consult ,   Iraq , 2014 - 06 - 23 ) , ( Nuri al - Maliki , Make state-   ment , Iraq , 2014 - 06 - 29 ) , ( Nuri al - Maliki , Mobilize   or increase police power , Iraq , 2014 - 08 - 11 ) and   ( Nuri al - Maliki , Praise or endorse , Iraq , 2014 - 11-   10 ) . The ﬁve quadruples above belong to the tem-   poral evaluation pattern . As shown in Figure 9 , we   mutually calculate the cosine similarity between   ξof the ﬁve quadruples . We can observe that   theξof the corresponding quadruples are all   close . Results further demonstrate that TeAST can   effectively model the temporal evolution pattern.15472ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   8   /squareA2 . Did you discuss any potential risks of your work ?   Not applicable . Left blank .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   1   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   1   /squareB1 . Did you cite the creators of artifacts you used ?   5   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   The code repository is governed by Apache-2.0 license .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   Not applicable . Left blank .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Not applicable . Left blank .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Not applicable . Left blank .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   Left blank .   C / squareDid you run computational experiments ?   Left blank .   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   No response.15473 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   No response .   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   No response .   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   No response .   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   No response .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   No response .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   No response .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   No response .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   No response.15474