  Maksim Eremeev   Elemental Cognition   New York University   eremeev@nyu.eduIlya Valmianski   AuxHealthXavier Amatriain   Curai HealthAnitha Kannan   Curai Health   Abstract   Factual correctness is often the limiting fac-   tor in practical applications of natural lan-   guage generation in high - stakes domains such   as healthcare . An essential requirement for   maintaining factuality is the ability to deal with   rare tokens . This paper focuses on rare tokens   that appear in both the source and the refer-   ence sequences , and which , when missed dur-   ing generation , decrease the factual correctness   of the output text . For high - stake domains that   are also knowledge - rich , we show how to use   knowledge to ( a ) identify which rare tokens that   appear in both source and reference are impor-   tant and ( b ) uplift their conditional probability .   We introduce the “ utilization rate ” that encodes   knowledge and serves as a regularizer by max-   imizing the marginal probability of selected   tokens . We present a study in a knowledge-   rich domain of healthcare , where we tackle the   problem of generating after - visit care instruc-   tions based on patient - doctor dialogues . We   verify that , in our dataset , specific medical con-   cepts with high utilization rates are underesti-   mated by conventionally trained sequence - to-   sequence models . We observe that correcting   this with our approach to knowledge injection   reduces the uncertainty of the model as well   as improves factuality and coherence without   negatively impacting fluency .   1 Introduction   Recent advances in language modeling ( c.f . Dong et al .   ( 2021 ) ; Erdem et al . ( 2022 ) for survey ) have enabled   applications across multiple domains including educa-   tion ( Shen et al . , 2021 ) , jurisprudence ( Bell et al . , 2021 ) ,   e - commerce ( Zhang et al . , 2020 ; Xiao et al . , 2021 ) ,   and healthcare ( Valmianski et al . , 2021 ; Compton et al . ,   2021 ; Alambo et al . , 2022 ; Krishna et al . , 2020 ) .   One of the central challenges in deploying these mod-   els in - the - wild is that rare words tend to have underesti-   mated conditional probability during generation ( Luonget al . , 2014 ; Chintagunta et al . , 2021 ; Holtzman et al . ,   2020 ) . However , in high - stakes applications , many of   these rare words are semantically important and need   to be preserved . For example , some symptoms , dis-   eases , and medications can be both rare and important   ( Mottaghi et al . , 2020 ) ( e.g.knowing that the patient is   taking warfarin is extremely important , even if the word   “ warfarin ” occurs infrequently ) .   Prior approaches for handling rare word generation   utilize a copy mechanism ( See et al . , 2017 ; Joshi et al . ,   2020 ; Xu et al . , 2020 ; Choi et al . , 2021 ) . This facilitates   copying from the source text using a probabilistic switch   to decide if the next output token is generated or copied   from the input ( See et al . , 2017 ) . However , it does n’t   properly resolve the main challenge : not all rare tokens   are important . Only specific rare tokens ( e.g.warfarin )   have a high probability of appearing in the reference   sequence when found in the source sequence . In cases   where the training data does not have enough structure   to disambiguate which rare words are essential , the copy   mechanism becomes overly extractive ( Gehrmann et al . ,   2018 ; See et al . , 2017 ) .   Also relevant to this paper are previous works that   integrate knowledge into language models ( Duan et al . ,   2020 ; Liu et al . , 2022 ) . In entity - centric summariza-   tion , Keskar et al . ( 2019 ) ; Liu and Chen ( 2021 ) add key   phrases to the prompt , which through the self - attention   mechanism influence the output distribution . However ,   for prompts containing rare tokens , self - attention strug-   gles to capture the prompt - reference dependency , and   the marginal probability of rare tokens remains under-   estimated . Joshi et al . ( 2020 ) extends this approach by   not only explicitly including the medical concepts in the   input sequence , but also adding a related term to the loss   function . However , they still find that for rare tokens the   model underestimates the conditional probability during   generation .   Finally , dictionary look - up of rare and out - of-   vocabulary words has been studied in Yu et al . ( 2022 ) ;   Ruzzetti et al . ( 2022 ) . However , these papers focus on   finding good representations of specific tokens . In this   paper , we tackle the problem of uplifting important rare   tokens even when a good representation is not available .   We base our work on the premise that specific rare   tokens ( e.g.warfarin ) have a high probability of appear-   ing in the reference sequence if they also appear in the2373   2 Approach2374   3 After - visit care instruction generation :   task and data description237523764 Experimental setup   5 Results23772378   6 Conclusion23797 Limitations   References238023812382A Semantic relative errors   B Human evaluation   C Qualitative examples   D Identifying source dialogue turns23832384238523862387References2388ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Yes , Section 7 .   /squareA2 . Did you discuss any potential risks of your work ?   Our method is generally applicable to a wide range of sequence models including those which   may generate harmful content . However , our method does not aim to mitigate these risks explicitly .   Nevertheless , we discuss privacy concerns after Section 6 .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract and section 1 discuss main contributions .   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   Section 4 .   /squareB1 . Did you cite the creators of artifacts you used ?   Section 4 cites code base we have used in our work .   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   We used open source tools . The code of our method will be open sourced and free to use .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   Not applicable . Left blank .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Collected data contains sensitive patient information . We discuss this in the Ethics Statement after   Section 6 .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Data is described in Section 3 .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   Section 3 , " Dataset construction”.2389C / squareDid you run computational experiments ?   Sections 4 - 5 .   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   Section 4 .   /squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   Sections 4 and 5.1 discuss hyperparameters of the model , give overview of the model performance   w.r.t . different hyperparameter values , and highlight the best - performing ones .   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   We show descriptive statistics by running experiments with multiple random initializations .   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   We used the main fairseq branch as the code base .   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Section 3 , Appendix Section B.   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   See appendix section B.   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   Medical experts are full - time workers and the requested information can not be disclosed due to the   company NDA .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   Medical experts are full - time employees of the company and signed the agreement which contains   the consent . Details of the agreement can not be disclosed due to the NDA .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   See Ethics statement after Section 6 .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   Can not be disclosed since workers are full - time employees.2390