  Abhinav Ramesh Kashyap , Devamanyu Hazarika ,   Min - Yen Kan , Roger Zimmermann , Soujanya PoriaNational University of Singapore , Singapore   DeCLaRe Lab , Singapore University of Technology and Design , Singapore   { abhinav , hazarika , kanmy , rogerz}@comp.nus.edu.sg   sporia@sutd.edu.sg   Abstract   Automatic transfer of text between domains   has become popular in recent times . One of   its aims is to preserve the semantic content of   text being translated from source to target do-   main . However , it does not explicitly main-   tain other attributes between the source and   translated text , for e.g. , text length and descrip-   tiveness . Maintaining constraints in transfer   has several downstream applications , includ-   ing data augmentation and de - biasing . We   introduce a method for such constrained un-   supervised text style transfer by introducing   two complementary losses to the generative   adversarial network ( GAN ) family of mod-   els . Unlike the competing losses used in   GANs , we introduce cooperative losses where   the discriminator and the generator cooper-   ate and reduce the same loss . The ﬁrst is   acontrastive loss and the second is a clas-   siﬁcation loss — aiming to regularize the la-   tent space further and bring similar sentences   across domains closer together . We demon-   strate that such training retains lexical , syntac-   tic , and domain - speciﬁc constraints between   domains for multiple benchmark datasets , in-   cluding ones where more than one attribute   change . We show that the complementary co-   operative losses improve text quality , accord-   ing to both automated and human evaluation   measures .   1 Introduction   Modern neural networks methods are capable of   mapping data from one domain to another . Promi-   nent examples include translation of text between   languages ( Vaswani et al . , 2017 ; Artetxe et al . ,   2018 ; Lample et al . , 2017 ) , emoji creation from   human faces ( Taigman et al . , 2017 ) , and stylistic   transfer of speech ( Yuan et al . , 2021 ) . In Natu-   ral Language Processing ( NLP ) , the umbrella term   attribute transfer ( Jin et al . , 2020b ) ( or domainFigure 1 :   transfer ) refers to similar methods . The aim is   to maximally preserve the semantics of the source   sentence ( “ content ” ) but change other properties   ( “ attributes ” ) , such as sentiment ( Jin et al . , 2020b ) ,   expertise ( Cao et al . , 2020 ) , formality ( Rao and   Tetreault , 2018 ) or a combination of them ( Subra-   manian et al . , 2018 ) .   Text style transfer , a popular form of attribute   transfer , regards “ style ” as any attribute that   changes between datasets ( Jin et al . , 2020a ) . Build-   ing on the progress of supervised transfer models ,   recent works have focused on unsupervised style   transfer that avoids costly annotation of parallel   sentences . However , models built using unsuper-   vised methods perform poorly when compared to   supervised ( parallel ) training ( Artetxe et al . , 2020 ) .   These methods , while capable of achieving the tar-   get domain characteristics , often fail to maintain   the invariant content . Figure 1 illustrates one such   example , where a sentence from the B do-   main is translated to the M domain . While   the translated sentence “ Loved the movie ” has cor-   rectly transferred the attribute ( style ) , it does not   have the same length , does not retain the personal   noun ( “ I ” ) , nor use a domain - appropriate proper   noun . Comparatively , the higher-ﬁdelity transfer   “ I absolutely enjoyed Spielberg ’s direction ” , main-   tains such constraints of identity , in addition to   being apt .   This problem setting is an important application416of text transfer , as enforcing constraints of iden-   tity can help maintain the brand identity when the   product descriptions are mapped from one com-   mercial product to another . They can also help in   data augmentation for downstream domain adapta-   tion NLP applications ( § 5 ) . Constraints of identity   are explored extensively in the computer vision   task of cross - domain image generation . ( Taigman   et al . , 2017 ) , but these issues — to the best of our   knowledge — are unexplored in NLP .   In this paper , we improve unsupervised attribute   transfer by enforcing invariances via explicit con-   straints . Current methods in text attribute transfer   lack mechanisms to explicitly enforce such con-   straints between the source and the transferred sen-   tence . To this end , we build upon unsupervised text   style transfer work by introducing an additional ex-   plicit regularization component in the latent space   of a GAN - based seq2seq network through two com-   plementary losses ( § 3 ) . Unlike the adversarial   losses in the GAN framework , our proposed losses   cooperatively reduce the same objective . The ﬁrst   loss is a contrastive loss ( Le - Khac et al . , 2020 )   that brings sentences that have similar constraints   closer and pushes sentences that are dissimilar far-   ther away . The second loss is a classiﬁcation loss   that helps maintain the sentence identity via con-   straints from the latent vectors ( Odena et al . , 2017 ) .   Our approach , while simple and aimed at main-   taining constraints , improves the overall perfor-   mance of the generation . We demonstrate these   gains over three datasets : ( Zhao et al . ,   2018b ) , ( Dai et al . , 2019 ) and   ( Prabhumoye et al . , 2018 ) , generating six con-   straints including lexical , syntactic and domain-   speciﬁc constraints . The introduced cooperative   losses satisfy the constraints more effectively com-   pared against strong baselines . Since multiple at-   tributes can change between two domains ( Subra-   manian et al . , 2018 ) , we test our method on one   such dataset and show that the constraints of iden-   tity are maintained more effectively ( § 4.4.2 ) . To   the best of our knowledge , our approach is the ﬁrst   to introduce cooperative losses in a GAN - like setup   for NLG .   2 Preliminaries   Task Setup : We consider two sets of sentences   ( or corpora)S = fx;x;:::xgandT=   fx;x;:::xg , as the source andtarget do-   mains , respectively . Each corpus — which we in-   terpret as domains — contain discernable attributes , ranging from sentiment ( e.g. , positive vs. negative ) ,   topics , political slant ( e.g. , democratic vs. republi-   can ) , or some combination ( Li et al . , 2018 ; Lample   et al . , 2019 ) . The overall task is to rewrite a piece   of texts2S tot2 T , such that the transla-   tion changes the attributes varying across the two   domains but retains the remaining content . While   content retention is not explicitly deﬁned in the   literature , we design this new task of constrained   unsupervised attribute transfer that assigns explicit   constraintsC = fc;c;:::;cg , to be retained .   These constraints can be deﬁned at various levels of   a sentence : lexical , syntactic and domain - speciﬁc .   Adversarially Regularized Autoencoder   ( ): To perform unsupervised attribute trans-   fer , we consider seq2seq models that encode source   sentences to a latent space and then decodes them   to the target sentences . s ( Zhao et al . , 2018b )   are the auto - encoder variants of the Generative   Adversarial Network ( GAN ) ( Goodfellow et al . ,   2014 ) framework . They learn smooth latent spaces   ( by imposing implicit priors ) to ease the sampling   of latent sentences . s have been widely   adopted in tasks like unsupervised text generation   ( Huang et al . , 2020 ) , topic modeling ( Hu et al . ,   2020 ) , among others , and form the backbone of   our proposed model . consists of an auto - encoder with a deter-   ministic encoder enc : X!Z that encodes sen-   tences into a latent space ; i.e. , z = enc(x)P ,   and a conditional decoder p(xjz)that generates   a sentence given a latent code . regularizes   this latent space utilizing a GAN - like setup that   includes an implicit prior obtained from a param-   eterized generator network enc : N(0;I)!Z .   Here , encmaps a noise sample sN ( 0;I)to   the corresponding prior latent code  z = enc(s)   P.   A criticcrc : Z!Rthen learns to distinguish   between real and generated samples , whereas both   encandencare adversarially trained to fool   the critic . This results in a minimax optimization   which implicitly minimizes the JS - Divergence be-   tween the two distributions PandP :   minmaxE[crc(z)] E[crc( z)](1 )   The training involves three optimizations : i)re-   ducing the auto - encoder loss L , which tries to   reconstruct the input and encourages copying be-417   havior and maintain semantics similar to the orig-   inal text ( Eq . 2 ) ; ii)optimizing the critic ’s loss   Lto distinguish between real and fake samples   ( Eq . 3)iii)training the encoder and generator L   to fool the critic ( Eq . 4 ):   L( ;  ) = E[ logp(xjz)](2 )   L( ) =  E[crc(z ) ] + E[crc( z)](3 )   L( ; ) = E[crc(z)] E[crc( z)](4 )   3 Proposed Method   3.1 Base Model ( )   While is an auto - encoder that recreates input   x!^ x , our requirement is to translate sentences   from one domain to another . Given this , we modify   the to a seq2seq variant such that we can   translate input sentences between source and target   domains ; i.e. , x!^ xandx!^ x.   To achieve this , we utilize encto encode x   and repurpose encto encode x. We obtain their   latent codes ( z; z)which we name as ( z;z ) , i.e. ,   z = enc(x)andz = enc(x ) .   Next , to generate sentences , we consider two de-   coders ^ xp(xjz)and^ xp(xjz ) . Here ,   zcan be either zorzbased on whether we auto-   encode ( e.g. , p(xjz = enc(x ) ) ) or translate   ( e.g. ,p    xjz = enc(x)   ) . Unlike ’s sin-   gle decoder , we incorporate two decoders to enable   bi - directional translation .   In the above process , instead of sampling sfrom   a noise distribution like N(0;I)and passing it   through a generator enc , we feed it text from the   target domainTand a decoder decthat decodes   text inT. This is inspired from Cycle - GAN ( Zhuet al . , 2017 ) , where instead of matching the noise   distributionN , we match the distribution of T.   In addition , we tie the weights of the encoders   from both domains , so that the encoders learn to   encode domain - agnostic information . Tying en-   coder weights has also been used by unsupervised   machine translation ( Artetxe et al . , 2018 ; Lample   et al . , 2017 ) and multiple other works ( Mai et al . ,   2020 ; Huang et al . , 2020 ; Hu et al . , 2020 ; Artetxe   et al . , 2018 ) .   3.2 Adding Constraints via Co - op Training   While the latent space in learns to   matchSandTsentences , there is no guarantee   on translations maintaining the “ content ” . This   issue is particularly pronounced in unsupervised   attribute transfer due to lack of parallel sentences   betweenSandT.   To alleviate the issue , we propose to learn a   structured latent space which embodies notions of   our constraints in its embedded latent codes . This   ensure that instances with similar constraints are   closer in the latent space . In particular , we propose   two types of optimization — self - supervised and   discriminative — to maintain the constraints better .   3.2.1 Cooperative Contrastive Learning   We use contrastive representation learning to reg-   ularize the latent space , such that encoders bring   two sentences sharing similar constraints closer to-   gether ( positive pairs ) , and force dissimilar ones   away ( negative pairs ) . For example , sentences   of similar lengths ( irrespective of their domains )   should be closer together .   Among many self - supervised metric losses such   as Triplet Loss ( Hoffer and Ailon , 2015 ) and NT-418Algorithm 1 : + + -foreach training iteration do 1 ) Train the Auto - encoders : Sample xS , xT z = enc(x);z = enc(x ) Backprop loss , L( ;  ) , L ( ;  ) 2 ) Train the Critic : Sample xS , xT z = enc(x);z = enc(x ) z = crc(z);z=   crc(z)l L( ) 2a ) Critic Co - op Training : Backprop loss ,   l+L( ) + L( ;  ) 3 ) Adversarial Training : Sample xS , xT z = enc(x);z = enc(x ) Backprop loss , L( ; ) 3a ) Encoder Co - op Training : Backprop loss ,   L( ;  ) + L( ;  ;  )   Xent loss ( Chen et al . , 2020 ) , we use one that is   amenable to multiple positive instances ( Khosla   et al . , 2020 ) . Given a sentence s2S in a mini-   batch of size B , we minePpositive sentences each   fromSandTthat share the same constraints with   s. This contrastive loss is given by :   where z ’s are representations obtained from the en-   coders inS , Tor representations obtained from the   last layer of critic crc . Care a set of constraints   for a sentence . Recently , ( Kang and Park , 2020 )   introduced the cooperative loss in the adversarial   setup where contrastive losses are added to both the   critic andgenerator for GANs . Unlike the normal   opposing losses of the generator and the critic , both   of them cooperatively reduce the contrastive loss .   We follow a similar principle and add the loss to   both the encoders and the critic ( Lines 18 ) .   3.2.2 Cooperative Classiﬁcation   Contrastive learning might be sub - optimal if we   do not mine good quality positive and negative   samples ( Tian et al . , 2020 ) . To address this , we   propose another way to regularize the latent space .   Similar to ACGAN ( Odena et al . , 2017 ) , we en-   courage the encoders and the critic to cooperatively   reduce a classiﬁcation loss . We include a classiﬁer   D : Z ! Rthat predicts the different con-   straintsCof the sentences and the binary cross   entropy loss is reduced .   wherejCjis the number of constraints per sen-   tence,is the sigmoid function and lare the logits   produced by the classiﬁer for z. As in contrastive   loss , thezcan be produced by encoders of S , T   or from the hidden layers of the critic .   The overall training process is highlighted in Al-   gorithm 1 whereLandLare weighted by    and. We choose  ; 2f0;1 g.   4 Experiments   Datasets . We use three datasets with single at-   tribute changes : i)Yelp Reviews : business reviews   listed on Yelp , labeled as either a positive or neg-   ative sentiment . ii)IMDb Movie Reviews : con-   sists of movie reviews ( Dai et al . , 2019 ) also la-   belled as positive or negative . iii)Political Slant :   consists of Facebook posts from the politicians of   the United States Senate and the House of Repre-   sentatives ( Prabhumoye et al . , 2018 ) , labeled with   either democratic / republican slant .   We provide a summary of the dataset statistics in   Table 1 . We include datasets of varied length and   complexity . Apart from having different topics , the dataset is more formal compared to the more   colloquial . We ﬁx the maximum vocabulary   size for , and at 30 K which   is also the default maximum vocab size used in   ( Zhao et al . , 2018b ) .   Constraints : We constrain every sentence along   sixdiverse dimensions that we desire to control419   between the two domains : i)Lexical : Sentence   length – The transferred sentence should maintain   a length similar to the original sentence ( binarized   to long sentences with 10 or or more words or short   otherwise ) . ii)Syntactic : Presence of personal   pronouns ( binarized to indicate the presence of a   personal pronoun ) ; number of adjectives ( categori-   cal up to 5 ) ; number of proper nouns ( categorical   up to 3 ) ; syntactic tree height ( categorical up to 10 ) .   iii)Domain speciﬁc – number of domain - speciﬁc   attributes ( Li et al . , 2018 ) ( categorical up to 5 ) .   Further , we label the sentence with a constraint-   speciﬁc , catch - all label if the bounds are beyond   what we mention above . Since the distribution of   the labels may be different , we report the F1 score   on our constraints .   4.1 Model Details   For the encoders , we use a one - layer LSTM net-   work with 300 hidden dimensions for all the   datasets . For the critics and classiﬁcation loss , we   use a two - layer multi - layer perceptron with 100   hidden units .   Training Hyper - parameters : For all our exper-   iments we set the learning rate of the auto - encoder   ( lr ) to 1e-3 and ( lr ) to 1e-4 . The number of   discriminator steps ( n ) is set to 5 . The Adam   optimizer parameters  = 0:5and  = 0:9 , which   ensures a more conservative optimization and is   known to improve stability . We also add a gradient   penalty to the loss function of the discriminator that   stabilizes training . All the suggestions for stabiliz-   ing training are mostly obtained from ( Arjovsky   and Bottou , 2017 ) .   Inference Hyper - parameters : We used nucleus   sampling with p2[0:6;0:9 ] . We tried differenttemperatures of scaling the softmax ( Guo et al . ,   2017 ) - 0.4 , 0.5 , 0.6 , 0.7 and chose the one that   produced the best result on the dev set .   4.2 Evaluation Setup   Automatic Evaluation : Our automatic evalua-   tion considers the following three prominent cri-   teria : i)Semantic Similarity ( ): Measured   between source and translated target sentences us-   ing encoders ( Wieting et al . , 2019 ) , instead of n-   gram metrics like ( Papineni et al . , 2002 )   which have weak correlations with human judg-   ments.ii)Transfer Accuracy ( ): The trans-   ferred sentence should belong to the target domain   and a classiﬁer is trained to distinguish between   the source and the target sentence . We use fastText   classiﬁers ( Joulin et al . , 2017 ) for every dataset .   We achieve accuracy of 97:9for , 96:9for and97:1for .iii)Fluency ( ):   A transferred sentence should be grammatically   correct . We ﬁne - tune a RoBERTa - large model on   the COLA ( Warstadt et al . , 2018 ) dataset to indi-   cate whether a sentence is linguistically acceptable .   Finally , we combine the three scores into an aggre-   gate , following the criteria suggested by Krishna   et al . ( 2020 ):   AGG = 1   jSjXACC ( s)SIM ( s)FL(s )   Human Evaluation : We also perform an indica-   tive human evaluation where we randomly sample   100 samples from each of the three datasets and   hire three researchers to rate every sentence for , and on a 3 - point scale ( Krishna et al . ,   2020).420   4.3 Baselines   We compare with the following base-   lines : a ) : The Delete , Retrieve , Generate   method that deletes domain speciﬁc attributes , re-   trieves a template and generates the target domain   text ( Li et al . , 2018 ) . We use the stronger , en-   tire system rather than the weaker   and baselines ; b ) : Adver-   sarially regularized autoencoders our system is   based on ( Zhao et al . , 2018b ) ; c ) : Our   model without the contrastive learning or coop-   erative classiﬁer ; d ) + : Our   model with the contrastive learning ; e )   + : Our model with the cooperative classiﬁer ;   f ) + + : Our model with   both the cooperative losses . The closest model to   ours is from ( Huang et al . , 2020 ) . However , we   were not able to reproduce the results .   4.4 Results   4.4.1 Overall Results + and + con-   sistently perform better than and on the score ( Table 2 ) . The for is 20.6   ( vs. 19.8 ) , for it is 28.1 ( vs. 19.9 ) and for 25.5 ( vs. 11.0 ) . Although cooperative   loss reduction aims to satisfy the constraints be-   tween two domains , our results show that further   regularization of the latent space not only brings   advantages in satisfying the constraints but also   improves performance ( Lavoie - Marchildon et al . ,2020 ) .   Effect of Cooperative Loss Reduction onand : Across datasets , reducing coopera-   tive losses improves andandto .   Although produces sentences with high   as most of the text from the original sentence is   retained after the delete step , there is a large trade-   off with resulting in low scores . Also ,   compared to , adding cooperative losses sig-   niﬁcantly increases the , with the highest in-   crease observed for . The reasons for   this could be two - fold : i)since we mine positive   sentences from a corpus that is grounded in real   world events , most lexically - similar sentences may   also be semantically similar ( Guu et al . , 2018 ) , and   ii)since we tie the encoders from the source and   target domain , we extract domain - agnostic infor-   mation before generation , which retains content .   Fluency ( ) also improves over all datasets . We   hypothesize that reducing cooperative losses reg-   ularizes the latent space bringing ﬂuent sentences   closer together , enabling the decoder to produce   semantically similar and linguistically acceptable   sentences . The improvement for is   less ; we ﬁnd these source sentences themselves   are less ﬂuent and contain many U.S. political   acronyms , and that our system produces many out-   of - vocabulary words affecting ﬂuency .   Nucleus Sampling : Our system achieves the   highest score with greedy decoding . We also   experiment with nucleus sampling ( Holtzman et al . ,   2019 ) with different pvalues . We report results for   onlyp=0:6 in Table 2 , as it produced the best result.421   Withp=0.6 , the results are more diverse , increasing as expected . However we ﬁnd that with higher   values ofp , there is a trade - off withresulting   in a lower score overall — similar to Krishna   et al . ( 2020 ) .   Effect of the Number of Positives : The num-   ber of positive and negative samples used for con-   trastive learning ( Eq . 5 ) have a signiﬁcant effect   on the overall performance ( Khosla et al . , 2020 ;   Chen et al . , 2020 ; Henaff , 2020 ) . Table 3 ( rows   jPj2f1;2;5;10 g ) shows the scores on   ( for one of the runs ) , for different number of pos-   itives . We ﬁnd that is the highest with 2   positives per sample as also used by Khosla et al .   ( 2020 ) . Although increasing the number of neg-   atives is beneﬁcial for contrastive learning , when   more than one positive example is available , using   them brings further improvements ( Khosla et al . ,   2020 ) .   Cooperative Losses are Important on Both   the Generator and Critic : Table 3 shows the im-   portance of adding the cooperative losses on the   generator and critic . First , we see that adding the   cooperative losses on both the generator and the   critic is crucial for the overall performance . While   adding the cooperative contrastive loss to both the   generator and critic increasesand while   maintaining similar levels of , adding the co-   operative classiﬁcation loss improveswhich   shows the complementary nature of the losses .   Human Evaluation : We average the results and   present it in Table 4 . produces marginally bet-   ter semantically similar sentences . Compared to , our model performs well except for in .   This may be because we use nucleus sampling with   0.9 which optimizes for diversity rather than simi-   larity . On other metrics we perform on par or better   than our competing systems . ( See Appendix B )   Qualitative Examples : Table 5 shows exam-   ples of the quality of transferred examples ( see Ap-   pendix A for more ) . Mistakes made by the model   can be attributed to poor understanding of the orig-   inal semantics , lack of diversity , and not producing   attribute - speciﬁc words .   4.4.2 Maintaining Constraints   Figure 3 shows that introducing the coopera-   tive losses signiﬁcantly outperform and in maintaining constraints . Speciﬁcally the + model performs better than + . One reason could be that ,   ﬁnding the appropriate positives and strong nega-   tives can be problematic for contrastive learning .   On the other hand , the classiﬁer ’s objective is sim-   pler and forces the encoder to produce represen-   tations that satisfy the different constraints effec-   tively .   A seemingly easy to maintain constraint is the   length of the sentence . However , seq2seq systems   have a difﬁculty of maintaining appropriate lengths   ( Murray and Chiang , 2018 ) . With no additional   regularization does not maintain the length   as well as + . On the other hand ,   compared to the lexical constraints , syntactic at-   tributes like descriptiveness , tree height and do-   main speciﬁc constraints present challenges , with   signiﬁcantly lower F scores . +   produces signiﬁcantly better results in maintaining   them . This shows that obtaining improvements on   the overall does not necessarily translate to   producing outputs that satisfy constraints .   maintains the proper noun for effectively , be-   cause it contains a wide variety of actor and movie   names . They are retained verbatim after the delete   operation .   Multiple Attribute Datasets : To test whether   our model can satisfy constraints across domains   where multiple attributes change , we use the multi-   attribute dataset released by ( Lample et al . , 2019).422   We chose the A andM as two do-   mains . Each of these domains can have multiple   attributes like positive and negative sentiment text ,   different gender attributions to sentences , etc . We   compare our + model with the and in Figure 4 . The results are   more pronounced in this case with + having clear advantage over . This   shows that even with multiple attributes changing   between domains , cooperatively reducing losses   can satisfy different constraints more effectively .   Qualitative Examples : Table 6 shows exam-   ples of our model maintaining constraints com-   pared to . Sometimes , hallucinates and   adds personal pronouns like “ my ” to the text even   when there are no personal pronouns ( row1 ) . Also ,   our model produces sentences where the number of   proper nouns are retained ( Chris Klein vs. Robert   De Niro ) , whereas does not.5 Discussion and Limitations   Cycle Consistency Loss : a)In Latent Spaces -   Cycle consistency in latent spaces has been shown   to improve word - level tasks , such as cross - lingual   dictionary construction ( Mohiuddin and Joty , 2019 )   and topic modeling ( Hu et al . , 2020 ) . A recent work   from ( Huang et al . , 2020 ) claims to improve un-   supervised style transfer using such losses . In our   experiments , however , it did not result in any no-   ticeable performance improvement . Given this ,   we hypothesize that cycle consistency might be   too restrictive for sentence - level tasks . b ) Using   Back - Translation - Back - translation is another al-   ternative to ensure semantic consistency between   source and the target sentence ( Prabhumoye et al . ,   2018 ; Artetxe et al . , 2018 ; Lample et al . , 2017 ) .   However , in our case , since we are training an , it would involve an additional inference and   auto - encoder training step which is expensive and   we defer exploring this .   Using Transformers : We also replace our   LSTM auto - encoders with both pre - trained and   randomly initialized transformer encoder – decoders   ( Rothe et al . , 2020 ) . Although we found an increase   in the , it was mostly because of very high   and very low . Reducing the number of layers ,   attention heads would still result in a large model   that is still prone to copying text . This reveals the   potential limitations of our method and training   using transformers is a future work .   Transferred sentences as Adversarial Exam-   ples : We demonstrate an important application of   our proposed constrained transfer by considering   them as adversarial examples for domain adapta-   tion . Domain Adversarial Neural Network ( DANN )   ( Ganin et al . , 2017 ) is an unsupervised domain   adaptation method that improves performance of   an end - task ( e.g , sentiment analysis ) on a target do-   main considering only supervised data from source   domain . We train DANN for sentiment analysis on   amazon reviews dataset ( He and McAuley , 2016 )   with DVD as source and E as the tar-423get domain – achieving an accuracy of 83.75 % on .   Next , we train the best variant of to   transfer a separate set DVD reviews to E -reviews and use them as adversarial examples   to test the DANN model . We ﬁnd that the ac-   curacy of DANN on the domain   reduces by3 points . This shows the potential   application of domain transferred sentences as ad-   versarial examples . Similar ideas have been tried   for image style transfer ( Xu et al . , 2020 ) , but needs   more investigation in NLP .   6 Related Work   Text attribute transfer has a vast literature ( Jin et al . ,   2020a ) with deep learning methods becoming pop-   ular . The methods are either supervised ( requiring   parallel data ) or unsupervised . Supervised meth-   ods re - purpose Sequence to Sequence models used   in machine translation to achieve the goals ( Rao   and Tetreault , 2018 ) . However , obtaining parallel   data is cumbersome and thus unsupervised meth-   ods that consider pseudo - parallel data have become   popular .   Disentanglement approaches are the prevalent   approach to tackle unsupervised attribute transfer :   attributes andcontent are separated in latent dimen-   sion . To disentangle the attributes adversarial meth-   ods maximize the loss of a pre - trained attribute   classiﬁer ( Li et al . , 2020 ; Fu et al . , 2018 ; Zhao et al . ,   2018a ; John et al . , 2019 ) . However , the literature   has paid little attention in deﬁning and preserv-   ing content . Cycle consistency losses – imposing   that reconstruction from the target style sentence   should resemble the source sentence – is the most   prevalent ( Prabhumoye et al . , 2018 ; Logeswaran   et al . , 2018 ; Dai et al . , 2019 ; Huang et al . , 2020 ; Yi   et al . , 2020 ) . However , this is expensive and non-   differentiable , thus requiring reinforcement learn-   ing techniques to enforce it . Our work deﬁnes   the different constraints that should be preserved   and adds simple differentiable contrastive learning   losses to preserve them .   In recent times , text style transfer models are   moving away from disentanglement approaches   ( Subramanian et al . , 2018 ) . Recent works that use   transformers for style transfer also have adopted   this ( Dai et al . , 2019 ; Krishna et al . , 2020 ) . How - ever , these methods do not explicitly maintain the   constraints between the two styles which is the   main aim of our work .   7 Conclusion   Text style transfer works focuses on retaining con-   tent and changing the style of sentences but does   not maintain other desirable constraints . We ad-   dress this by introducing two cooperative losses to   the GAN - inspired Adversarially Regularized Au-   toencoder ( ARAE ) that further regularizes the la-   tent space . While satisfying the constraints our   methods brings signiﬁcant improvements in over-   all score . While we focus on simple constraints   at the sentence- and word - level , future work can   add phrase - level and more ﬁne - grained constraints .   Potential future work may explore reinforcement   learning losses to directly optimize the constraints .   Acknowledgments   We would like to thank the anonymous reviewers   for their useful suggestions . We would also like   to acknowledge the support of the NExT research   grant funds , supported by the National Research   Foundation , Prime Ministers Ofﬁce , Singapore un-   der its IRC@ SG Funding Initiative , and to grate-   fully acknowledge the support of NVIDIA Cor-   poration with the donation of the GeForce GTX   Titan XGPU used in this research . The work is also   supported by the project no . T2MOE2008 titled   CSK - NLP : Leveraging Commonsense Knowledge   for NLP awarded by Singapore ’s Ministry of Edu-   cation under its Tier-2 grant scheme .   References424425426427A Transfer Results   More transfer results are mention in Table 8 . Ex-   amples where our system fails with plausible ex-   planation are given in Table 9 . Examples of trans-   lation from the multi - attribute dataset is shown in   Table 10 .   B More details on Human Evaluation   For , 0 indicates not ﬂuent at all , 1 indicates   somewhat ﬂuent and 2 is a completely ﬂuent sen-   tence . We explicitly ask the annotators to consider   semantic similarity for , irrespective of whether   the target sentence shares some phrases with the   source sentence , with 1 indicating no semantic simi-   larity and 3 indicating complete semantic similarity .   For , 1 indicates that the target sentence has   only the source sentence style while 2 indicates   good transfer to the target style .   We calculate the Krippendorff ’s alpha to assess   the inter annotator agreement . Table 7 shows the   inter - annotator agreement . An  of 0.4 is consid-   ered good agreeement ( Hedayatnia et al . , 2020 ) .   We have moderate to good agreements on all the   datasets for different measures . On more inspec-   tion we found that the disagreements in ﬂuency   mostly arrives for small phrases like " my fav " al-   though is an accepted phrase in social media text   is considered 2 by one annotator and 3 by another .   We also further note that , smaller sentences were   easier to judge and had better agreement rates oncompared to longer sentences .   Information about participants : We hire three   graduate researchers in NLP ( average age 25 ) for   the annotation task who are well versed in En-   glish . We obtained permission for their participa-   tion and compensated them appropriately accord-   ing to hourly wages in the country . The speciﬁc   instruction given to them for the evaluation are as   follows .   Consider two sentences•Source sentence : Sentence from the source   domain   •Target sentence : The transferred sentence   produced by one of the systems   For every target sentence you will be asked to   rate it according to three measures described below .   Fluency : Indicate how ﬂuent the target sentence is   ( regardless of whether the sentence is appropriately   transferred to the target sentence )   1 - Not ﬂuent at all - Does not look like an En-   glish sentence .   2 - Fluent but with some mistakes - Fluent but   with some grammatical errors   3 - Entirely ﬂuent . - A good English Sentence   Similarity : Indicate how semantically similar the   target sentence is .   1 - Does not share any words / phrases with the   source sentence and/or is not semantically similar   ( does not share high level topics of the sentence )   2 - Shares some words / phrases with the source   sentence and/or has moderate level of semantic   similarity ( talks about similar high level topics )   3 - Shares appropriate words / phrases with the   source sentence and is highly semantically simi-   lar   Accuracy : Indicate whether the target sentence is   accurately transferred to the target domain   Sentiment Transfer   1 - The target sentiment is not evident in the tar-   get sentence at all . Has words expressing opposite   sentiment   2 - Neutral Sentiment . Choose this option , if it   has both positive and negative sentiment   3 - The target sentiment is evident in the tar-   get sentiment . Has appropriate sentiment bearing   words .   If the sentence itself has no sentiment then chose   2   Political Orientation   1 - Talks about topics with the other orientation .   For example , if the target style is democratic and   the target sentence talks about conservative issues   like abortion , gun control   2 - Neutral .   3 - Talks about topics with the correct orienta-   tion . For example , if the target style is democratic   and talks about progressive issues like liberty , free   speech , Elizabeth Warren , Joe Biden , gay rights   etc.428429Dataset Source Target Explanation completely out-   dated , old hotel.completely charm-   ing and old school . The model produces mixed senti-   ments without understanding that   “ old school ” has negative conno-   tations bad service , bad   food.great food , amazing   food . Lack of diversity in the genera-   tion and the model does not pro-   duce outputs with respect to ser-   vice music is boring ,   and starts to an-   noy after 15 - 20   minutes.its an epic and very   moving ﬁlm , with-   out being preachy . The model fails to produce   semantically similar sentence .   Probably because music is not a   frequent topic in the dataset brad pitt overacts   appallingly.john woo does it . Although the the model repro-   duces a name , it does not produce   a ﬂuent sentence obamacare , no one   wants it!!al , no one cares it . Does not understand that " Oba-   macare " is an entity and halluci-   nates and uses " care " as a verb are clearly not re-   publican anymore!are not enough sen   booker . Hallucinates Sen Booker which   appears frequently in the dataset430431