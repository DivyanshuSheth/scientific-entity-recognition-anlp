  Guanghui Ma , Chunming Hu , Ling Ge , Hong ZhangSchool of Computer Science and Engineering , Beihang University , Beijing , ChinaCollege of Software , Beihang University , Beijing , ChinaDBDC , Beihang University , Beijing , ChinaCNCERT / CC , Beijing , China   { maguanghui , hucm , geling}@buaa.edu.cn , zhangh@isc.org.cn   Abstract   Current works about false information detec-   tion based on conversation graphs on social net-   works focus primarily on two research streams   from the standpoint of topic distribution : in-   topic and cross - topic techniques , which assume   that the data topic distribution is identical or   cross , respectively . This signifies that all test   data topics are seen or unseen by the model .   However , these assumptions are too harsh for   actual social networks that contain both seen   and unseen topics simultaneously , hence re-   stricting their practical application . In light   of this , this paper develops a novel open - topic   scenario that is better suited to actual social   networks . In this open - topic scenario , we em-   pirically find that the existing models suffer   from impairment in the detection performance   for seen or unseen topic data , resulting in poor   overall model performance . To address this   issue , we propose a novel Contrastive Adver-   sarial Learning Network , CALN , that employs   an unsupervised topic clustering method to   capture topic - specific features to enhance the   model ’s performance for seen topics and an un-   supervised adversarial learning method to align   data representation distributions to enhance the   model ’s generalisation to unseen topics . Ex-   periments on two benchmark datasets and a   variety of graph neural networks demonstrate   the effectiveness of our approach .   1 Introduction   The convenience and openness of social networks   allow people to quickly engage in discussions on   a wide range of topics ( e.g. the COVID-19 epi-   demic and the war in Ukraine ) , and at the same   time they also cause people to suffer from false in-   formation , the massive spread of which can affect   the political and social order of the real world ( Rao   et al . , 2021a ; Zhang et al . , 2021 ) . Therefore , the   detection of false information on social networks isFigure 1 : ( a ) Comparison of topic distribution in three   different scenarios . ( b ) The accuracy ( % ) of the in - topic   model and cross - topic model in the open - topic scenario   for seen and unseen topics , respectively .   increasingly attracting the attention of the research   community ( Ma et al . , 2018 ; Li et al . , 2019 ; Yu   et al . , 2020 ; Song et al . , 2021 ; Ma et al . , 2022 ) .   Currently , there are two main types of detec-   tion models from the perspective of topic distribu-   tion : in - topic models and cross - topic models ( Ren   et al . , 2021 ) . ( 1 ) In - topic models focus on scenarios   where topics of the training and test data are same   ( Silva et al . , 2021 ; Song et al . , 2021 ) , that is , the   topics in the test set are seen . ( 2 ) Cross - topic mod-   els focus on scenarios where topics of the training   and test data are different ( Wang et al . , 2018 ; Ren   et al . , 2021 ) , which means the topics in the test data   areunseen . However , we argue that the real so-   cial networks contain both seen and unseen topics   simultaneously , and we refer to this phenomenon   as the open - topic scenario . As shown in Figure 1   ( a ) , there is a significant difference among the three   topic distributions.2911To the best of our knowledge , there is no work   on false information detection in open - topic sce-   narios . The intuitive idea is that we could resort   to the existing models to handle detection tasks in   this scenario . To implement the above conception ,   we conduct a preliminary validation experiment .   Specifically , we train an in - topic model and a cross-   topic model with the same training data , respec-   tively . Then , we leverage an open - topic dataset ,   mixed seen and unseen topics data , as test dataset   to evaluate the performance of the above two mod-   els ( More details can be found in Appendix A . ) .   The experimental results are shown in Figure 1(b ) .   From the results , we find that the accuracy of the in-   topic model on unseen topics is significantly lower   than that of the cross - topic model . Although the   cross - topic model improves the accuracy on unseen   topics , the accuracy on seen topics is lower than   that of the in - topic model .   We argue that the reasons for the above phe-   nomenon are as follows . ( 1 ) The performance of   the in - topic model benefits from prior knowledge   of the data ( Ren et al . , 2021 ; Silva et al . , 2021 ) ,   also known as topic - specific features , such as spe-   cific topic words . This prior knowledge can not   be transferred to new topics due to differences be-   tween topic features , resulting in poor generalisa-   tion of in - topic models to unseen topics . ( 2 ) The   cross - topic model mainly learns topic - invariant fea-   tures , such as writing style , from the topics of the   train data and transfers these features to the test   data ( Wang et al . , 2018 ; Castelo et al . , 2019 ) . This   learning mechanism causes the cross - topic model   to discard prior topic knowledge of the data , reduc-   ing the performance of the cross - topic model for   seen topics . Apparently , the deficiencies of existing   methods in open topic scenarios can be alleviated   if both topic - specific and topic - invariant features   can be preserved .   To retain these two types of features , we face two   severe challenges . ( 1 ) How to learn topic - specific   features ? Some works adopt user features ( Silva   et al . , 2021 ) or pre - trained topic models ( Ren et al . ,   2021 ) to obtain topic - specific features , which are   sub - optimal since they fail to address the diver-   sity of topics on social networks . ( 2 ) How to   learn topic - invariant features ? While existing work   has achieved good results using adversarial learn-   ing ( Wang et al . , 2018 ) , it relies on the topic labels   , which is challenging for information on social   networks because topics are constantly emerging . To tackle the above problem and challenges , we   propose a novel Contrastive Adversarial Learning   Network ( CALN ) to obtain and fuse both topic-   specific features and topic - invariant features . Con-   cretely , we use the drop edge technique ( Rong   et al . , 2020 ) to generate two augmented graphs   from an original conversation graph and leverage a   graph neural network ( GNN ) to obtain their graph-   level representations . Since different topic conver-   sation graphs have different topic - specific words   and topic - specific propagation patterns ( Silva et al . ,   2021 ; Mosallanezhad et al . , 2022 ) , we design an   unsupervised topic feature ( TF ) learner based on   contrastive learning to obtain topic - specific knowl-   edge . This TF learner can learn the intrinsic invari-   ance of the data by maximizing the mutual infor-   mation between the augmented graphs , ultimately   achieving topic clustering . Then , we resort to clas-   sical adversarial learning ( Ganin and Lempitsky ,   2015 ) to design an unsupervised representation   alignment ( RA ) learner to obtain topic - invariant   features , which is achieved by reversing the gra-   dient signal of contrastive learning and aligning   the representation distribution of the data . Finally ,   we fuse the obtained topic - invariant features , topic-   specific features , and graph - level representations to   predict the authenticity of the conversation graph   of false information .   Our contributions are summarized as follows : ( 1 )   We study a new issue of false information detection   in open - topic scenarios and discover the shortcom-   ings of existing methods in such scenarios . ( 2 ) We   propose a contrastive adversarial learning network   to obtain and fuse topic - specific and topic - invariant   feature learning to improve the false information   detection in open - topic scenarios . ( 3 ) We demon-   strate the effectiveness of our method through com-   parison , ablation and visualization experiments on   two real datasets and various GNNs .   2 Related Work   2.1 False Information Detection   Existing false information detection methods can   be categorized into two types from the perspective   of data distribution : data identical distribution ( Rao   et al . , 2021b ; Song et al . , 2021 ) based approaches   and non - identical distribution ( Castelo et al . , 2019 ;   Han et al . , 2020 ) based approaches . Theoretically ,   the setting of identical data distributions leads to   training and testing data on the same topics , result-   ing in detection models that can not handle the new2912   topics , which are constantly emerging on social   networks . Consequently , some researchers have   started to study the case of non - identical data dis-   tribution , such as cross - topic models ( Wang et al . ,   2018 ; Castelo et al . , 2019 ; Han et al . , 2020 ; Ren   et al . , 2021 ) . The cross - topic model aims to learn   topic - invariant features from source topics and gen-   eralize these features to the different new topics .   However , there is a gap between the assumptions   of the above works and the real social network sce-   nario . We argue that the social networks tend to   be an open - topic scenario . That is , some topics are   persistent , such as conspiracy theories and racism ,   while some new topics are emerging , such as the   COIVD-19 epidemic and the war in Ukraine . We   have demonstrated through validation experiments   that this open topic scenarios can lead to perfor-   mance degradation of existing models .   2.2 Contrastive Learning   Contrastive learning is a representational learning   method that utilizes the relevance of data as a sig-   nal for self - supervision and has demonstrated its   powerful performance in various domains of nat-   ural language processing ( Li et al . , 2021 ; You   et al . , 2022 ; Ge et al . , 2022 ) . Generally , contrastive   learning constructs positive samples by data aug-   mentation methods and treats other data within the   mini - batch as negative samples , forcing the model   to learn the similarities or differences of the data   and thus extract the intrinsic features of the data .   In this paper , we explore the study of unsupervised   topic clustering with contrastive learning . As there   are natural differences between the conversation   graphs across topics , we use contrastive learning tolearn the invariance of the data and form clustering   effects .   2.3 Adversarial Learning   Adversarial learning has been considered a promis-   ing solution for the topic generalization problem   ( Wang et al . , 2021 ; Li et al . , 2022 ) . The basic idea   ( Ganin and Lempitsky , 2015 ) is to add an adver-   sarial learning layer to the topic classifier to learn   a topic - invariant representation ( Zou et al . , 2021 ) .   However , most existing adversarial approaches rely   on topic labels for feature alignment ( Wang et al . ,   2018 ; Han et al . , 2020 ; Li et al . , 2022 ) , which is un-   realistic for complex social networks as we have no   way to obtain labels for new topics that keep emerg-   ing continuously . Based on those mentioned above ,   this paper explores using unsupervised adversar-   ial learning to handle cross - topic generalization on   social networks .   3 Methodology   3.1 Problem Statement   For the conversation graph detection task in   open - topic scenarios , we are given nlabeled   source training examples ( { G , y})fromK=   { K , ... , K}topics where G∈ G , y∈ Yand   nunlabeled target test examples ( { G})from   K={K , ... , K}topics where K∩K̸=∅.   The goal of this paper is to learn a classification   model to predict the conversation graph labels   { y}where y∈ Yfor the test dataset . We   define the task as a binary classification task , where   y∈ { True , False } . For conversation graphs on   social networks , we follow previous work ( Wei   et al . , 2019 ; Li et al . , 2020 ) and define the conversa-2913tion graph as an undirected graph : G= ( X , A ) ,   where X∈Rdenotes the node features and   A∈Rdenotes the adjacency matrix .   3.2 Overview   We propose a contrastive adversarial learning net-   work to address the problem of false information   detection in open - topic scenarios . As shown in Fig   2 , our model consists of four components : a data   enhancement and encoder module , a TF learner , a   RA learner , and a false information classifier .   3.3 The Data Enhancement and Encoder   Module   We perform data augmentation on an original graph   G(Gfor short ) to produce two augmented graphs   ˆGandˆGas positive sample pairs . The reason   we adopt the drop edge method for data enhance-   ment is that it can mitigate the influence of the   echo chamber effect in false information propaga-   tion ( He et al . , 2021 ) . We pass the augmented view   graph to the GNN and READOUT functions to   obtain a graph - level representation .   h = READOUT ( GNN ( ˆG ) ) ( 1 )   where h∈Rand the GNN serves as the shared   conversation graph encoder . We adopt global aver-   age pooling ( GAP ) as the READOUT function .   We denote the process above as f ( · , θ ) , where   theθis the parameters to be learned . Thus , we   obtain two enhanced graph - level representations h   andhfor an original conversation graph G , where   h = f(ˆG , θ)andh = f(ˆG , θ ) .   3.4 The Topic Feature Learner   The TF learner aims to learn topic - specific fea-   tures as prior knowledge for detection in an unsu-   pervised approach . Existing methods for learning   topic - specific features rely on user information and   pre - trained topic models . However , they ignore the   propagation patterns of conversation graphs , which   are crucial for social networks . Based on the fact   that different topic conversation graphs have differ-   ent topic - specific words and topic - specific propa-   gation patterns ( Silva et al . , 2021 ; Mosallanezhad   et al . , 2022 ) , we propose an unsupervised topic   clustering method for conversation graphs with con-   trastive learning to obtain topic - specific features .   We first pass the two graph - level representations ,   handh , to a neural network to obtain two hiddenfeatures zandz . This process can be repre-   sented as follows :   z = NN(h ) ( 2 )   where z∈RandNN(·)consist of two layers   of perceptrons and an activation function .   Then , we introduce contrastive learning to maxi-   mize the mutual information between the two hid-   den features , zandz , to learn the intrinsic prop-   erties of the data . Since contrastive learning can   capture the similarities and differences among data   to form a natural clustering effect , we refer to such   clustering representations as topic - specific features .   Herein , the contrastive loss for the TF learner is   defined as follows :   L(θ , θ)=E{−ET(z , z )   + logEe}(3 )   where the θandθdenote the parameters to   be learned . PandP)are conditional and   marginal distribution of augmented graphs . T ( · , · )   is a learned score function : sim(z , z)/τ , where   thesim(·,·)is a cosine similarity function , and τ   is a temperature factor ( You et al . , 2020 ) .   The loss function L(θ , θ)can evaluate the   differences among topics . The smaller the loss is ,   the better the clustering result is . Finally , we aim at   minimizing the loss L(θ , θ)ot the TF learner :   ˆθ= arg minL(θ , θ ) ( 4 )   3.5 The Representation Alignment Learner   The RA learner seeks to align data representa-   tion distributions in an unsupervised manner to   grasp topic - invariant features . Previous works rely   on topic labels to perform topic - invariant learn-   ing ( Wang et al . , 2018 ) . Due to the diversity and   complexity of information on social networks , it   is impractical to annotate each conversation graph   with an explicit topic label . To learn topic - invariant   features , we resort to classical adversarial learning ,   which achieves data representation alignment by   adding a gradient reversal layer ( GRL ) ( Ganin and   Lempitsky , 2015 ) to fuse data features .   First , similar to the TF learner , we employ a   neural network to obtain two hidden vectors , z   andz . This process is represented as follows :   z = NN(h ) ( 5)2914where z∈RandNN(·)contains two layers   of perceptrons and an activation function .   Then , we pass zandzinto GRL to obtain   two vectors zandz . The GRL is a constant   function in forward propagation , while it reverses   the gradient signal by multiplying the parameter   −λto the previous layer gradient in backward prop-   agation :   z = GRL ( z ) ( 6 )   Finally , we again use contrastive learning to deter-   mine whether the two vectors come from the same   original conversation graph . The loss for the RA   learner is defined as follows :   L(θ , θ ) = E{−ET(z , z )   + logEe }   ( 7 )   The goal of contrastive loss is to determine the   consistency between two data through maximiz-   ing the mutual information , while the goal of the   graph encoder module is exactly the opposite due to   the GRL , thus forming an adversarial relationship .   As training converges , the RA learner is unable   to distinguish which topic the accepted features   come from . Therefore , the above loss L(θ , θ )   is used to evaluate the differences in topics . The   larger the loss , the smaller the topic difference .   The goal of the RA learner is to maximize loss   L(θ,ˆθ ):   ˆθ= arg maxL(θ , θ ) ( 8)   3.6 False Information Classifier   The false information classifier is a feed - forward   fusion network with a perceptron and an activa-   tion function , which is designed to predict whether   a conversation graph Gis true or false . We con-   catenate the augmented graph representations h (   h ) , topic - specific representations z , and topic-   invariant representations z(z ) and feed them   into this classifier to obtain the prediction results ˆy .   The cross - entropy loss is used to optimize the   classifier :   L(θ , θ ) ) = −E[ylog ˆy   + ( 1−y ) log ˆy](9 )   where θis the parameters of the classifier .   Statistics PHEME5 PHEME9   Graphs 5802 6425   False 3830 4023   True 1972 2402   Avg comments / graph 17.8 16.3   Avg words / comment 13.6 13.6   Comments 103212 105354   Topics 5 9   The parameters θcan be learned by :   ( ˆθ,ˆθ ) = arg minL(θ , θ ) ( 10 )   3.7 Training Objective and Model Analysis   Our training objective is a minimax game between   the TF learner , the RA learner and the classifier .   Thus , the total loss function is defined as follows :   L(θ , θ , θ , θ ) = L(θ , θ )   + αL(θ , θ)−λL(θ , θ)(11 )   where α∈[0,1]and−λare a trade - off factor   We analyze the difference between the in - topic   model ( Equation 12 ) , the cross - topic model based   on adversarial learning ( Equation 13 ) and our   model ( Equation 14 ) from the GNN encoder gradi-   ent update perspective . In more detail , the gradient   update for these three models is expressed as fol-   lows , respectively :   ˆθ = θ−η∂L   ∂θ(12 )   ˆθ = θ−η(∂L   ∂θ−λ∂L   ∂θ ) ( 13 )   ˆθ = θ−η(∂L   ∂θ+∂L   ∂θ+(−λ∂L   ∂θ))(14 )   where the ηis the learning rate , Lis the the   adversarial loss and Lis the cross - entropy loss .   It can be found that the cross - topic model aligns   the distinct topic representations by adding the   −λterm in an adversarial way compared to   the in - topic model . Our model adds an additionalterm compared to the cross - topic model to al-   leviate this extreme adversarial . The above compar-   ison of gradient update shows that the cross - topic2915   GNN MethodPHEME5 PHEME9   Accuracy △ F1 △ Accuracy △ F1 △   GCNN / A 72.66 - 72.35 - 67.02 - 64.28 -   EANN 71.96↓0.70 71.74↓0.61 68.37↑1.35 65.06↑0.78   RDEA 75.25↑2.59 72.08↓0.27 66.70↓0.32 63.40↓0.88   CTTM 73.71↑1.05 73.45↑1.10 69.27↑2.25 65.25↑0.97   GACL 73.00↑0.34 72.46↑0.11 67.04↑0.02 64.38↑0.10   CALN 77.01↑4.35 75.89↑3.54 71.67↑4.65 66.80↑2.52   SAGEN / A 74.70 - 73.91 - 66.51 - 63.67 -   EANN 74.41↓0.29 73.80↓0.10 67.02↑0.51 64.03↑0.36   RDEA 75.59↑0.89 74.25↑0.34 65.71↓0.80 63.15↓0.52   CTTM 75.66↑0.96 75.30↑1.40 69.28↑2.77 64.60↑0.93   GACL 73.18↓1.52 72.35↓1.56 69.10↑2.59 64.83↑1.16   CALN 77.47↑2.77 76.32↑2.41 70.94↑4.43 66.03↑2.36   GINN / A 73.20 - 72.39 - 67.36 - 63.67 -   EANN 72.61↓0.59 71.68↓0.71 65.82↓1.51 62.17↓1.50   RDEA 74.32↑1.12 70.32↓2.07 69.66↑2.30 65.74↑2.07   CTTM 74.33↑1.13 73.78↑1.39 69.13↑1.77 64.97↑1.30   GACL 73.73↑0.53 72.35↓2.65 67.69↑0.33 64.74↑1.08   CALN 76.11↑2.91 74.70↑2.30 71.38↑4.02 67.39↑3.72   model completely discards the prior topic knowl-   edge of the data due to adversarial loss . In contrast ,   our model is a compromise between the in - topic   and cross - topic models , which is consistent with   our goal of improving detection performance in   open - topic scenarios .   4 Experimental Studies   4.1 Datasets   We evaluate the effectiveness of our method   on two publicly available benchmark datasets   from the Twitter social platform . Among them ,   PHEME5 ( Zubiaga et al . , 2016a ) contains five top-   ics : the Sydney siege , the Ottawa shooting and Fer-   guson , etc . , and PHEME9 ( Zubiaga et al . , 2016b )   contains nine topics : the Germanwings plane crash   and the Ebola virus , etc . The detailed statistics of   the dataset are shown in Table 1 . We reset and split   the dataset to ensure that the test set contains topics   out of the training set to simulate the open - topic   scenario . More details on dataset pre - processing   and splitting can be found in Appendix B .   4.2 Baseline and SOTAs   We utilize the original GNN as a baseline and se-   lect some related in - topic models and cross - topic   models for comparison , including : EANN ( Wang et al . , 2018 ): A cross - topic false   information detection model with adversarial learn-   ing . To learn topic - invariant features , EANN lever-   ages a clustering algorithm to obtain soft topic la-   bels to perform topic adversarial learning .   RDEA ( He et al . , 2021 ): An in - topic false infor-   mation detection model with contrastive learning .   To enhance the model ’s generalisation , RDEA pre-   trains the GNN encoder with data augmentation   and contrastive learning .   CTTM ( Ren et al . , 2021 ): A SOTA cross - topic   false information detection model with the mixture   of experts paradigm ( MOE ) ( Jacobs et al . , 1991 ) .   CTTM leverages the pre - trained topic model to   obtain topic vectors to enhance the model ’s gener-   alisation to unseen topics .   GACL ( Sun et al . , 2022 ): A SOTA in - topic false   information detection model with supervised con-   trastive and adversarial learning . The method uti-   lizes supervised contrastive learning to improve the   model ’s generalization and introduces adversarial   learning to boost the robustness of the model .   For a fair and extensive experimental evaluation ,   we utilize various GNNs as encoders , including   GCN ( Kipf and Welling , 2017 ) , SAGE ( Hamilton   et al . , 2017 ) and GIN ( Xu et al . , 2019 ) . GCN learns   the graph ’s multi - layer embedding representation   of each node by aggregating the embeddings of2916adjacent nodes . SAGE expands GCN into an in-   ductive learning task . GIN modifies the neighbour   aggregation and graph readout functions so that the   GNN performance approximates the upper line of   the Weisfeiler - Lehman test ( Leman and Weisfeiler ,   1968 ) .   4.3 Implementation Details   We chose accuracy and macro F1 as the metrics   for performance evaluation . We use Adam as the   optimizer ( Kingma and Ba , 2015 ) . The batch size   is set to 64 , and the dropout is set to 0.2empiri-   cally . we adopt a three - layer GNN as the backbone   network for all models . During the model training   process , we use a grid search technique to choose   the best super - parameters . The trade - off factor α   are selected from { 0.1 , 0.3 , 0.5 , 0.7 , 0.9 } , the GRL   trade - off factor λis selected from { 1 , 0.5 , 0.1 , 0.05 ,   0.01 , 0.005 , 0.001 } and the learning rate is selected   from { 0.001 , 0.005 , 0.0001 , 0.0005 } . The tempera-   ture factor τis set to 0.5 . Notably , we leverage a   learning rate decay strategy with linear warm - up   for stable training . All calculations are done on   an NVIDIA Tesla V100 GPU . More details about   the super - parameter selection , baseline and SOTAs   model implementation can be found in the Ap-   pendix C .   4.4 Performance Comparison   The experimental results are shown in Table 2 ,   where N / A indicates the baseline and △ repre-   sents the performance improvement . It can be   observed that CALN achieves the best results on   several GNN encoders and datasets , such as an ac-   curacy improvement of more than 4 % on PHEME5   compared to the baseline . RDEA and GACL are   in - topic models whose performance benefits from   prior knowledge of the topic , resulting in their infe-   rior performance to CALN in open - topic scenarios .   EANN obtains soft topic labels for the data with a   clustering algorithm , and CTTM leverages a pre-   trained model to obtain the topic vector , both of   which induce additional error bias . In contrast , we   naturally perform topic mining in an unsupervised   manner , using the intrinsic relevance of the data as   the driving signal . As a result , our approach avoids   the barriers to applying the model in real - world sce-   narios due to the lack of topic labels . Moreover , the   results on different encoders and datasets demon-   strate that CALN is a model - agnostic approach .   To further evaluate the CALN performance in   open - topic scenarios , we calculate the accuracy   of various methods on the PHEME5 datasets with   GCN as the encoder for seen and unseen topics .   The experimental results are shown in Figure 3 .   We can find that CALN achieves the best results on   both seen and unseen topics for most of the metrics .   For seen topics , EANN performs the worst because   it is a cross - topic model that lacks the topic prior   knowledge of the data . For unseen topics , RDEA   performs poor because it is an in - topic model that   fails to generalize to new topics . Our model utilizes   the TF learner to enable the topic distribution to di-   rectly participate in the model decision , improving   the model ’s performance for seen topics , and uti-   lizes the RA learner to align data representations ,   improving the model ’s generalization to unseen   topics . Moreover , our contrastive clustering allows   for clustering transfer to unseen topics ( Section   4.6 ) , further enhancing the model ’s generalization   to unseen topics .   4.5 Ablation Study   To investigate the impact of each learner on model   performance , we conduct an ablation study . We   remove the TF learner or the RA learner to observe   the model ’s accuracy for seen and unseen topics   in open - topic scenarios , respectively . The exper-   imental results are shown in Table 3 . The " w/o   TF " indicates removing the TF leaner , and the " w/o   RA " indicates removing the RA leaner . Although   most metrics show degradation when any leaner is   removed , there is a significant difference between   seen and unseen topics . For seen topics , the perfor-   mance of " w/o TF " degrades more than that of " w/o   RA " . For example , " w/o TF " and " w/o RA " mod-   els drop 5.62 % and 2.24 % , respectively , compared   to CALN on the PHEME5 dataset with SAGE as   encoder , which indicates that the TF leaner is more2917   Topics MethodPHEME5 PHEME9   GCN SAGE GIN GCN SAGE GIN   acc △ acc △ acc △ acc △ acc acc △   SeenCALN 84.45 -85.76 -84.14 - 81.06 -84.80 -86.13 -   w/o TF 81.46 ↓2.99 80.14 ↓5.62 81.64 ↓2.50 80.53↓0.53 82.13 ↓2.67 82.13 ↓4.00   w/o RA 82.39 ↓2.06 83.52 ↓2.24 83.33 ↓0.81 80.80↓0.26 82.40 ↓2.40 82.13 ↓4.00   UnseenCALN 66.73 - 67.59 -64.39 - 69.17 -67.86 -69.65 -   w/o TF 67.16↑0.43 66.52 ↓1.07 64.00 ↓0.39 67.46↓1.71 67.05 ↓0.81 68.29 ↓1.36   w/o RA 65.45 ↓1.28 63.75 ↓3.84 61.83 ↓2.56 65.41↓3.76 66.12 ↓1.74 63.55 ↓6.10   ( a ) PHEME5   ( b ) PHEME9   focused on seen topics . The " w/o RA " has more   performance degradation for unseen topics , indi-   cating that the RA leaner is more favourable for   generalising unseen topics . The above experimen-   tal results illustrate the rationality of CALN .   4.6 Visualization Analysis   We perform visualization studies to explore the   TF learner ’s ability to capture topic features and   the RA learner ’s ability to align data representa-   tions . To better demonstrate the visualization re-   sults , we randomly select some test data to obtain   topic - specific features zand topic - invariant rep-   resentation z(z ) . We resort to the topic labels   of the original data and use T - SNE for visualization .   The experimental result is shown in Figure 4 . Wenotice that the topic - specific features zcan form   apparent topic clustering effects in the PHEME5   dataset , including for unseen topics ( red sample   points ) . It demonstrates that our model can capture   topic features and has a transfer clustering effect   for unseen topics . For the topic - invariant features ,   we observe that the distribution of the data repre-   sentations presents aligned results , with no clear   boundaries of distinction among different topics ,   compared with the topic - specific representations .   It indicates that the RA learner eliminates the dif-   ference among topics . Moreover , the parameter   λis significant for the RA learner . Due to space   constraints , the visualizations based on different λ   can be found in the Appendix D .   4.7 Convergence Analysis   To investigate the stability of the training process   of CALN , we collect the changes of the loss L   from the TF learner , the loss Lfrom the RA   learner and the loss Lfrom the classifier during   the training process with GCN as the GNN encoder .   The experimental results are shown in Figure 5 . We   find that the loss LandLkeep decreasing2918while the loss Lshows a slight decrease at the   beginning and then gradually increases . The de-   crease in loss Lindicates that the TF learner   gradually completes the data intrinsic feature learn-   ing and forms the clustering effect . The increase in   Lindicates that the representation distribution   of the data tends to be aligned . These three losses   progressively converge to a stable level with the   increase of the epoch .   5 Conclusion   This paper proposes a novel open - topic scenario   containing the seen and unseen topic simultane-   ously for false information detection to comple-   ment existing work . We explore the shortcomings   of existing models in the open - topic scenario and   propose a contrastive adversarial learning network   CALN , containing a topic feature learner and a rep-   resentation alignment learner . The topic feature   learner is an unsupervised topic - based clustering   method to learn topic - specific features , improving   the model ’s performance for seen topics . The rep-   resentation alignment learner is an unsupervised   adversarial learning method to learn topic - invariant   features , enhancing the model ’s generalize for un-   seen topics . Experiments on various GNN encoders   and two real datasets demonstrate the effectiveness   of our model .   6 Limitations   There are some potential limitations in this study .   First , our model is based on conversation graphs   and relies on the graph structure formed by user   comments , so it is weak for detecting early propa-   gation . Early detection of false information will be   the future direction of our work . Second , the open-   topic scenario we constructed contains at most nine   topics , which is still some gap in topic diversity   from factual scenarios . Therefore , building a more   diverse and large - scale dataset can further advance   the field of false information detection .   Acknowledgements   We sincerely thank the reviewers for their insight-   ful comments and valuable suggestions . Thanks   for the computing infrastructure provided by Bei-   jing Advanced Innovation Center for Big Data and   Brain Computing . References291929202921A Validation Experiment Supplement   This section supplements the validation experi-   ments described in the introduction .   For the experiment , we use Bian et al . ( 2020 ) , a   prominent architecture utilized by several models   for false information detection , as in - topic model ,   and select the Wang et al . ( 2018 ) , a traditional   model with adversarial learning , as the cross - topic   model . The PHEME5 is used as the dataset . We   split the dataset to ensure that the test set contains   topics out of the training set ( Section B ) . In this   manner , we construct a training and test data that   fits the open - topic scenario . We feed the test set to   the above two models and measure the accuracy of   each model for seen and unseen topics detection .   B Dataset Details Supplement   In this section , we present the additional details of   the datasets .   Topics Graphs Tweets False True   Charlie Hebdo 2079 38268 458 1621   Sydney siege 1221 23996 522 699   Ferguson 1143 24175 284 859   Ottawa shooting 890 12284 470 420   Germanwings - crash 469 4489 238 231   In the paper , we use two publicly available   datasets , PHEME5 and PHEME9 . These two   datasets derived from the real social platform Twit-   ter and contain the complete user comment text   and reply relationships , which are accessible from   https://figshare.com/articles/dataset/PHEME_datas   et _ for_Rumour_Detection_and_Veracity_Classific   ation/6392078 . As shown in Table 4 , the PHEME5   dataset contains five different topics . The PHEME9   is developed from PHEME5 and contains nine   topics . In the data pre - processing , we replace   all the user names in the text with " User " , and   the hyperlinks address with ’ URL ’ to avoid user   information leakage . To create an open - topic   dataset , we take PHEME5 as an example . We split   " Charlie Hebdo " , " Sydney siege " , " Ferguson " and   " Germanwings crash " by 8:1:1 for the training set ,   validation set and test set , respectively , ensuring   that the topics in both the training and validation   sets are seen . To guarantee that the test set has   unseen topics , we merge " Ottawa shooting " withthe above test set to create a new test set as the   open - topic scenario .   C Implementation Details Supplement   In this section , we present additional details on the   model implementation .   we adopt a three - layer GNN as the backbone   network for all models . For the Baseline imple-   mentation , we add a perceptron layer as a classifier   on top of the backbone network . We employ the   source code from the original paper to implement   EANN , RDEAand GACL . Since the original   paper of CTTM does not provide available source   code , we have reproduced it as much as possible ac-   cording to the description of the paper . Specifically ,   the CTTM contains two variants of the model , Avg   andParam . As the performance of Param is sig-   nificantly better than Avg in the original paper , we   use the Param model as our comparison model . In   addition , since EANN and CTTM are not graph   neural network - based models , we convert their en-   coders to GNN encoders . We use PyTorchand   PyTorch - geometric(Fey and Lenssen , 2019 ) to   implement all models . In the data augmentation   process , we use the standard interface of PyTorch-   geometric to drop edge . The drop probability is set   to 0.1 and 0.2 to obtain the two augmented graphs .   D Visualization Analysis Supplement   In this section , we supplement the visualization   results of topic - specific and topic - invariant features   with different λ .   We use PHEME5 as an example to illustrate   the effect of λon the model . The visualization   experiment results are shown in Figure 6 . We can   notice that when λ=1 , the excessive adversarial   effect causes the data to collapse in the RA learner   and lose their discriminability completely . When   λ=0.0005 , it causes a certain topic clustering effect   in the RA learner . We explain this phenomenon by   the following analysis .   The contrastive loss can be rewritten as follows2922(a)λ= 1 , accuracy = 74.35 % ( b ) λ= 0.5 , accuracy = 75.39 %   ( c)λ= 0.1 , accuracy = 77.00 % ( d ) λ= 0.05 , accuracy = 76.35 %   ( e)λ= 0.005 , accuracy = 76.59 % ( f ) λ= 0.0005 , accuracy = 75.37 % :   L=−logexp(z·z / τ )   exp(z·z / τ ) + /summationtextexp(z·z / τ )   ( 15 )   where zandzdenote positive sample pairs and   thezdenotes negative sample .   We notice that the contrastive loss aims to pull   closer the positive pairs from the same conversa-   tion graph , and push away the negative samples   from the different conversation graphs within the   batch . Due to adversarial learning , the GNN en-   coder would pull in all negative samples , thus form-   ing a representational alignment . When the ad-   versarial learning is strong enough ( λis large ) ,   it causes the data to shrink completely together ,   making it impossible for the data to retain enough   information for the classification task . When the   adversarial learning is small ( λis small ) , the data   shows a certain topic clustering effect due to con-   trastive learning .   As shown in the Figure 6 , we can observe that   when λ= 1 orλ= 0.5 , the topic - invariant fea - tures collapse due to excessive adversarial , which   affects the distribution of representations in the TF   learner . At this point , the accuracy of the model   is about 75 % . When λ= 0.1orλ= 0.05 , the   data representation distribution of the RA learner is   well - aligned , and the TF learner captures apparent   topic features . The model obtained better results   at this point with an accuracy of 76.5 % . When   λ= 0.0005 , the adversarial learning power is too   small , leading to the effect of topic clustering in   the RA learner , and the model ’s accuracy decreases   at this time.2923