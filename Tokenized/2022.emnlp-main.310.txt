  Yinya HuangHongming ZhangRuixin HongXiaodan Liang   Changshui ZhangDong YuShenzhen Campus of Sun Yat - sen UniversityTencent AI Lab , SeattleTsinghua UniversityPengcheng Laboratory   yinya.huang@hotmail.com , { hongmzhang , dyu}@global.tencent.com ,   hrx20@mails.tsinghua.edu.cn , zcs@mail.tsinghua.edu.cn ,   xdliang328@gmail.com   Abstract   In this paper , we propose a comprehensive   benchmark to investigate models ’ logical rea-   soning capabilities in complex real - life scenar-   ios . Current explanation datasets often employ   synthetic data with simple reasoning structures .   Therefore , it can not express more complex rea-   soning processes , such as the rebuttal to a rea-   soning step and the degree of certainty of the   evidence . To this end , we propose a comprehen-   sive logical reasoning explanation form . Based   on the multi - hop chain of reasoning , the expla-   nation form includes three main components :   ( 1 ) The condition of rebuttal that the reasoning   node can be challenged ; ( 2 ) Logical formulae   that uncover the internal texture of reasoning   nodes ; ( 3 ) Reasoning strength indicated by de-   grees of certainty . The fine - grained structure   conforms to the real logical reasoning scenario ,   better fitting the human cognitive process but ,   simultaneously , is more challenging for the cur-   rent models . We evaluate the current best mod-   els ’ performance on this new explanation form .   The experimental results show that generating   reasoning graphs remains a challenging task   for current models , even with the help of giant   pre - trained language models .   1 Introduction   Being able to generate reasonable explanations is   a crucial capability for a reliable reasoning sys-   tem . Most current works try to ask models to gen-   erate reasoning chains as profound explanations .   From simple rationales ( DeYoung et al . , 2020 ) to   more complex multi - step explanations ( Inoue et al . ,   2020 ; Jhamtani and Clark , 2020 ; Saha et al . , 2021 )   and deductive chains of reasoning ( Clark et al . ,   2020 ; Tafjord et al . , 2021 ; Dalvi et al . , 2021 ) , pre-   vious works attempt to encompass comprehensive   information . However , the current explanation de-   sign still has limitations for logical reasoning textsFigure 1 : A logical passage and the corresponding logic   metagraph in the proposed MetaLogic . Given a logi-   cal passage , the goal is to generate the full metagraph   including the chain of reasoning with conditions of re-   buttal , the node formulae , and the degrees of certainty .   in real scenarios . As current explanations lack a   fine - grained structure , three remarkable features   are not included in current explanations for the sake   of real - world logical reasoning : multiple relation   types , hierarchical structure , and certainty . As a re-   sult , we can not comprehensively evaluate models ’   reasoning capabilities in real - life scenarios .   Figure 1 shows examples of the crucial reasoning   components that are well studied by previous cog-   nitive science literature ( Toulmin , 2003 ; Garson ,   2021 ) but overlooked by previous work in the ma-   chine learning community . First , the inference re-   buttal . Previous work ( Tafjord et al . , 2021 ) mostly   only focuses on the inferences of conjunction and   entailment among different statements while ignor-   ing the rebuttal ones , which could be crucial in   real applications . For example , sent5 counters4698sent4 as a condition of exception and we can-   not construct the correct reasoning graph without   therebuttal relation . Second , there could exist in-   ternal logical relations inside each statement . For   example , sent5 contains two atomic sentences   connected by a logical implication relation . Third ,   real - life statements could have different degrees of   certainty . For example , “ He is hungry ” and “ He is   likely to be hungry ” are not identical but relevant   because of the certainty . However , most previous   work simply treats them completely separately in-   stead of considering their relevance and trying to   model the difference ( i.e. , certainty ) .   Motivated by previous cognitive science work   ( i.e. , Toulmin Model(Toulmin , 2003 ) and modal   logic theory(Garson , 2021 ) ) , we propose a new   explanation form , logic metagraphs , to address the   aforementioned limitations of previous work . As   demonstrated in Figure 1 , the logical metagraphs   are directed acyclic graphs with meta nodes con-   nected by two types of edges , support andrebut ,   representing the inferences between the statements   over a logical passage . The meta structure uncovers   the chain of reasoning from evidence to the con-   clusion , along with the challenges from the rebut-   tal sentences . Each meta node stores information   about a logically sound statement formulated as a   propositional formula in a standard modal logic S5   system ( Hughes et al . , 1996 ) , a direct extension of   first - order propositional logic with two certainty   operators . The formulae have atomic sentences   as logical variables that denote events or beliefs ,   which are modified by three unary operators on   their certainty ( negation ¬ , necessity 2 , and possi-   bility3 ) and are joined by three binary operators   on their logical relations ( implication → , conjunc-   tion∧ , disjunction ∨ ) . As a result , the logic meta-   graphs are comprehensive with multi - hop reason-   ing paths , inference rebuttal , the internal structure   of the statements , and reasoning strength denoted   by the degrees of certainty . We collect 1,000 log-   ical passages from the ReClor dataset ( Yu et al . ,2020 ) and build the MetaLogic dataset .   Based on our new explanation form , we exam-   ine the current best models ’ ability to understand   logical reasoning profoundly . The models need   to generate the logic metagraphs given a logical   passage . Performances are evaluated by matching   scores for the overall structure as well as the three   fine - grained components : ( 1 ) The inference steps   between meta nodes ; ( 2 ) The per - statement formu-   lae with multiple logical triples ; ( 3 ) The degrees of   certainty . Our evaluation results indicate that gener-   ating a comprehensive logical reasoning structure   is still challenging for existing giant models .   Our contributions are three - fold :   1.We propose a new explanation form , the logic   metagraphs , with a comprehensive logical struc-   ture and rich logical information , and the corre-   sponding metagraph generation task .   2.We build a high - quality dataset , MetaLogic , on   real - world logical passages .   3.We conduct experiments on three generative   models in different frameworks and locate the   challenges for current models .   2 Related Works   Explanations Explanation in the context of natu-   ral language understanding tasks ( e.g. , QA ) pro-   vides interpretability about how models solve the   problem . The strategies include asking the models   to generate rationales while answering the ques-   tions ( DeYoung et al . , 2020 ; Inoue et al . , 2020 ) ,   and deriving multi - hop chains of reasoning ( Jham-   tani and Clark , 2020 ; Dalvi et al . , 2021 ) . The   single - sentence rationale provides justification for   the question answering but does not uncover the   reasoning procedure . While the form of multi - hop   chains of reasoning uncovers the reasoning proce-   dure and remedies the simple justification of ra-   tionale , it still lacks critical clues about the mech-   anism within the reasoning steps . Our proposed   fine - grained explanation form extends the chain of   reasoning by unwrapping the fine - grained texture   within each reasoning step . As a result , it allows   the reasoning chains to include multiple inference   types ( e.g. , rebuttal ) and broader reasoning types   such as abductive reasoning with the hidden world-   knowledge assumption .   Logical Reasoning Machine logical reasoning re-   quires models to conduct hidden symbolic reason-   ing processes through question answering ( Yu et al . ,4699   2020 ; Liu et al . , 2020 ; Cui et al . , 2020 ) , or explicitly   perform symbolic reasoning via natural language   ( Clark et al . , 2020 ; Tafjord et al . , 2021 ; Dalvi et al . ,   2021 ) . The QA - based reasoning data is mostly col-   lected from real - life scenarios without correspond-   ing structural information . To perform reasoning ,   symbolic modules ( Huang et al . , 2021 ; Ouyang   et al . , 2021 ) or learning strategies ( Wang et al . ,   2022 ) are designed to approximate the reasoning   structure . On the other hand , explicitly generat-   ing chains of reasoning can better uncover models ’   reasoning processes . However , recent work mostly   focuses on deductive reasoning , where models with   iterative strategy ( Tafjord et al . , 2021 ) or reasoning   modules ( Hong et al . , 2022 ) show superior perfor-   mances . To encourage more advanced reasoning   capabilities , we propose a comprehensive reason-   ing structure with fine - grained factors .   Argumentation / Discourse Structures Previous   works ( Lawrence and Reed , 2019 ; Li et al . , 2022 )   such as argumentation mining ( Stab and Gurevych ,   2014b , a , 2017 ) or discourse parsing ( Carlson et al . ,   2001 ; Webber et al . , 2019 ) study document struc-   ture prediction . Given a passage , a model is re-   quired to predict the argument components or the   discourse relations between them . Instead of iden-   tifying the rhetorical structure of a passage , the   proposed logic metagraphs aim at simulating the   logical reasoning process , where the model needs   to select the relevant knowledge out of a pool to   finish the reasoning . Besides , unlike directly con - sidering a sentence or a text span as a reasoning   node , MetaLogic explores a schema with finer gran-   ularity . Each reasoning node is further decomposed   into logical variables with relations and modal op-   erators so that the inner structure as well as the   certainty are considered .   3 Task Definition   Overall Generation Task The desideratum is that   a model reconstructs the fine - grained logic expla-   nation for a given passage , which uncovers the   model ’s understanding of the logic between the   lines . The logic explanation is formatted as logic   metagraphs with support orrebut inference steps ,   per - node logical formulae , and degrees of certainty ,   as demonstrated in Figure 2 .   The input for the models is a passage with mul-   tiple statements ( S , S , ... , S)and atomic   sentences p⊆S , according to which they   generate the logic metagraph . The logic meta-   graph has three main components : ( 1 ) The meta   structure G= ( V , E ) , where E = EE , and   EandEare the two meta edge types , support   andrebut , respectively , between the meta nodes   u∈ V , n≤N. ( 2 ) The set of node formulae F ,   where u:=f∈ F. Each formula is joined by   logical triples . f = r(m(p),m(p ) ) , where   i̸=j , r∈ { → , ∧,∨ } , and mis a combination in   { ¬,2,3 } . ( 3 ) The set of degrees of certainty C ,   defined by the combination format of { ¬,2,3}.4700   4 The Logic Metagraph   In this section , we introduce the proposed logic   metagraph in details .   4.1 Meta Node and Edge   Each meta node corresponds to a logically sound   statement ( e.g. , premise , orconclusion ) . The meta   edges are either support orrebut , relating to a single   step of inference . The support edges join the meta   nodes to form a chain of reasoning to the conclu-   sion , whereas the rebut edges indicate challenges   from the condition of rebuttal to one of the meta   nodes in the chain , which are evidence or claims   about exceptional conditions . Each inference step   allows multiple premises .   4.2 Internal Structure of Meta Node   The internal structure of a statement is formulated   as a propositional logic formula . The logical vari-   ables denote the atomic sentences in the statement   that corresponds to separate events or beliefs . The   logical relations between such events or beliefs are   denoted by binary propositional operators . There   are three logical relations : logical implication , con-   junction , and disjunction ( →,∧,∨ ) . Multiple such   logical triples are joined by conjunctions ( ∧ ) . Fur-   thermore , each logical variable and the overall for-   mula are modified by negation ( ¬ ) and modal ( 2   and3 ) operators , representing the degrees of cer-   tainty of each atomic sentence as well as the whole   statement , respectively . A more detailed introduc-   tion can be found in Section 4.3.4.3 Certainty with Modal Operators   Modal logic ( Garson , 2021 ) is an extension of first-   order propositional logic with two modal operators ,   necessity ( 2 ) and possibility ( 3 ) . They are unary   operators , and Table 1 presents examples of their   senses in natural language ( Hughes et al . , 1996 ) .   For example , 2pdenotes that the proposition pis   necessary , while 3pmeans pis possible , in the   classic definition . In another sense of tense , 2p   represents that the evidence pis true at all times ,   whereas 3Prepresents that pis only true some-   times . In general , the modal operators indicate   certainty information of the propositions .   The two modal operators can define each other   with the negation operator ( ¬ ) . Multiple reduction   rules are defined . As a result , any complex formu-   lae composed of modal operators could be reduced   to one of the five degree - of - certainty forms listed   in Table 1 , which is also known as the classic S5   system ( Hughes et al . , 1996 ) and makes the logic   metagraph defined in a complete set .   5 MetaLogic   In this section , we introduce the construction de-   tails of the MetaLogic dataset . Since the logic meta-   graphs have fine - grained structures with multiple   evaluation dimensions , which are all dispensable   and supplement each other , we design a rigorous   annotation process for the construction .   5.1 Preparation   Source Data We use ReClor ( Yu et al . , 2020 ) as   the source data , where the multiple - choice ques-   tions are collected from GMAT and LSAT . As a4701pilot study on logical reasoning explanation , we   start with the standard text questions so that the   explanation form can benefit from precise and com-   prehensive logical information . Each question con-   tains a logical passage , a question , and multiple   answer options . The original dataset contains 17   reasoning types , which can be mainly categorized   into two folds : complete reasoning composed of   the logical passage and the option ( e.g. , the types   Necessary Assumptions , Sufficient Assumptions ,   Strengthen , Weaken ) ; flawed in - context reasoning   structure ( e.g. , the types Technique , Identify a Flaw ,   or Dispute ) . As we aim to study models ’ under-   standing of the complete reasoning process over   the whole passage , we consider data from the first   category , from which we randomly choose 1,000   samples . Examples of the selected questions can   be found in Appendix A.   Data Preprocessing We first filter out incoherent   options from the questions for logical structure   coherence . For ordinary questions , the incoher-   ent options are the distracting ones . Conversely ,   for the inverse questions with “ EXCEPT ” , we ran-   domly select one of the distracting options and   remove the others . We further split the passage into   sentences as the initial meta nodes and per meta   node sentence into clauses as the initial logical   variables . This follows the convention of applying   linguistic - based segments as reasoning components   in related studies ( Dalvi et al . , 2021 ; Huang et al . ,   2021 ; Wang et al . , 2022 ; Xu et al . , 2022 ) . Besides ,   considering the label hierarchy that the logical vari-   ables are conditioned on the meta nodes , the initial   segments help build the desired metagraph sketch .   Moreover , the initial delimitation is trivial with   punctuation marks and provides the least machine   guidance to the annotators , who are free to modify   the segments on their understanding of reasoning   units , which will be demonstrated in Section 5.2 .   From the experts ’ view , 27 of 30 randomly sam-   pled annotated graphs are of high quality , which   indicates the high reliability of starting with the   initial segments .   As a result , the text presented to the annotators   contains the original text with the passage , the ques-   tion , and the coherent option , along with a list of   delimited sentences .   5.2 Annotation   As all annotation tasks require a global understand-   ing of the overall passage , we recruit the same   annotator to finish all tasks in the same passage .   The annotation procedure has four steps . ( 1 ) Read   through the text and have a rough idea about the   logical role of each initial meta node ( e.g. , being a   conclusion orrebuttal ) . If an initial meta node does   not provide complete evidence , then the annotator   needs to merge it with another node to form com-   plete evidence . ( 2 ) Annotate the inference types   between the meta nodes . After this stage , we obtain   the chain of reasoning and the rebuttal steps . ( 3 )   For each meta node , annotate the logical variables   by refining the span boundaries of the given initial   logical variables . ( 4 ) Annotate the logical binary   operator between the logical variables . The annota-   tion platform is demonstrated in Appendix D.   We recruit annotators from crowd - sourcing plat-   forms . We first train annotators with a carefully   designed annotation guidelineand require them   to pass an exam before the annotation to guarantee   the annotation quality . For each passage , we invite   two annotators . On average , we pay $ 2.2 for each   logical passage .   For unary logical operators ( ¬,2,3 ) , as dis-   cussed by ( Toulmin , 2003 ) , there exist conventional   clue words for the negation and modality . Follow-   ing that , we leverage such in - context clue words   for the annotation . Given a set of conventional in-   dicators ( demonstrated in Table 13 in Appendix C ) ,   we parse each meta node sentence into a depen-   dency parsing tree , then detect those words within   3 - hops to the root node , and assign the correspond-   ing operators to the formula . The consecutive unary   operators are ordered by the distance from the indi-   cators to the parsing root node . This results in the   global unary operators . For local unary operators of   the logical variable spans , we parse the spans and   evaluate the indicator - root distance . The repeatedly   detected indicators are reduced , as a result , the op-   erators are kept by the global formula and removed4702   before the local variable . To evaluate the labels ,   the annotators check 391 unary operators from 200   randomly sampled passages . As a result , 92.6 % of   them are consistent with human cognition , which   indicates that the operators are valid and consistent .   5.3 Inter - Annotator Agreement   We evaluate the inter - annotator agreement in mul-   tiple dimensions with Cohen ’s Kappa Coeffi-   cient ( Cohen , 1960 ) .   Meta Node The IAA of meta nodes reflects one ’s   understanding of the logical role of each statement .   We evaluate the annotators ’ agreement of each meta   node of being one of the five characters : conclusion ,   rebuttal , beginning of the chain , an intermediate   conclusion in the chain , and irrelevant node .   Meta Edge We consider the exhaustive meta node   pairs except the reflexive ones . Consequently , the   agreement is calculated on the adjacency matrix of   the meta edges regarding the three labels : support ,   rebut , and without - an - edge . The diagonal elements   in the matrix are excluded .   Logical Variable As the logical variables are text   spans , the annotators vote for each token for be-   ing in a logical variable or not . The agreement is   average over the per - token agreement .   Logical Relation Similar to meta edge , we con-   sider the exhaustive logical variable pairs except   for the reflexive ones . Considering the logical vari-   ables as vertices , the agreement is calculated on the   adjacency matrix regarding the four labels : logical   implication , logical conjunction , logical disjunc-   tion , and without - a - relation . The diagonal elements   are regarded .   We present the results in Table 2 . The agreement   is consistently high , which indicates the high qual-   ity of MetaLogic . Moreover , the high IAA also   indicates that humans could easily solve the logi-   cal reasoning explanation and provide consistent   logical reasoning graphs .   5.4 Dataset Statistics   The final annotated MetaLogic contains 1,000 logic   metagraphs with over 3,609 meta nodes and 1,500   formulae . In the MetaLogic , 416 out of 1,000 logic   metagraphs have rebuttal steps . Around 40 % of   metagraphs have multi - hop reasoning chains . On   average , each logic metagraph has more than three   meta nodes , and about 40 % are mapped to formu-   lae . Moreover , each metagraph has an average of   2.19 global operators . More statistics can be found   in Table 4 . We randomly split the data with 60 %   training , 20 % development , and 20 % testing .   6 Experiment   We evaluate the performance of the following ex-   planation generative models on MetaLogic : ( 1 )   All - at - Once ( Once ) T5 ( Raffel et al . , 2020 ) , which   performs sequence - to - sequence generation via gen-   erating the whole metagraph in a linearized se-   quence given the overall passages with the sentence   and variable denotations ; ( 2 ) Multitask T5 ( Raffel4703   et al . , 2020 ) , which complete the whole generation   task with a combination of three sub - tasks : meta   structure generation , formula generation , and cer-   tainty prediction ; ( 3 ) MetGen ( Hong et al . , 2022 ) ,   which is a module - based framework for structured   explanation generation . It further introduces a rea-   soning controller and two modules for meta struc-   ture generation . To the best of our knowledge ,   MetGen is the current state - of - the - art explanation   generative model . Further model details are in Ap-   pendix E. Following Dalvi et al . ( 2021 ) , we report   the F1 and AllCorrect scores for each dimension   and the overall AllCorrect score . For certainty ,   we report the accuracy of a five - label classifica-   tion and an extra macro - F1 due to the unbalance   of the degree labels . The overall AllCorrect is the   strictest metric since any difference in the predicted   metagraph will make the prediction a wrong one .   Details can be found in Appendix F.   6.1 Implementation Details   We fine - tune Once ( large ) , Multitask ( large ) , and   MetGen ( large ) with a batch size of 32 for 300   epochs on 1 Tesla V100 GPU , and fine - tune Once   ( 11b ) , Multitask ( 11b ) , MetGen ( 11b ) with a batch   size of 4 for 300 epochs on 8 Tesla V100 GPUs .   The learning rate is 1e-5 for all models . The model   parameters are optimized by Adafactor ( Shazeer   and Stern , 2018 ) . The models are evaluated per   10 epochs on the development set , and the best   checkpoints are saved for test set evaluation .   6.2 Main Results   From the results shown in Table 3 , we can find out   that generating the comprehensive logic graph is   still a very challenging task , even for current giant   models as all models achieve low AllCorrect per-   formance . Specifically , we can make the following   observations :   1.From the experiments in certainty prediction ,   we can see that all models are struggling , which   shows that knowing certainty is still not a triv-   ial task for current models given that there are   explicit indicators in context .   2.We notice that using larger pre - trained mod-   els ( e.g. , T5 - 11B ) can help improve the per-   formance of all models , this indicates that big   models can help better model the statement se-   mantics such that they can better identify and   link statements .   3.We also notice that the module - based method   MetGen can outperform the Once and Multitask   method , which indicates that iteratively generat-   ing the explanation graph with basic modules is   a more reliable logical reasoning framework .   4.From the experiments on Component 1 , we   can see that the models could obtain high node   scores and mediocre step scores , but the step All-   Correct results are inferior . This indicates that   with the help of giant pre - trained LMs , current   models could effectively learn to identify the   nodes , but they may not know the true logical   reasoning because they can not precisely predict   the inference types among these nodes .   5.The models achieve around or over 60 % of F1   and AllCorrect scores in predicting the formula ,   showing their awareness of the inner logical4704structure . This makes sense because the major-   ity of the inner structure is triggered by connec-   tive words such as “ so . ”   In the rest of this section , we present a more   detailed inspection from different perspectives .   6.3 Performances on Metagraph Parts   We further inspect models ’ performance on de-   tailed components . The evaluation results on sepa-   rate inference types ( support andrebut ) are demon-   strated in Figure 3 . Overall , identifying rebut is   easier than support , according to the exact match   scores F1 and AllCorrect . This makes sense be-   cause most rebut nodes could contain informative   keywords such as “ however ” but the majority of   nodes in support edges do not . Besides , the average   F1 scores per operator are shown in Figure 4 . From   the results , we can see that the trend of models ’   performance are generally consistent on different   operators , which indicates that different operators   may have different intrinsic difficulty .   6.4 Data Scale for Logical Inference   To investigate how well current models can learn   to generate the reasoning graphs , We use differ-   ent ratios of training data to train the models and   present the results in Figure 5 . Overall , the model   performances show a rapid increase within 20 %   of training data , then a flat and steady increase   and do not reach a platform , indicating that the   models can still benefit from more structural rea-   soning data . Among the models , MetGen has the   most significant growth trend and performs data   efficiently with small data , showing the advantages   of the module - based learning framework in sym-   bolic reasoning . Interestingly , we find out that the   performance of multitask T5 decreases after seeing   half of the training data . A possible explanation is   that the decomposed logical structure as indepen-   dent sub - tasks prevents the models from a holistic   understanding of the logical passages . Besides that ,   the flat increasing rate after seeing 20 % of the train-   ing data also suggests that blindly increasing the   training data scale may not be the most efficient   way of teaching models to conduct such a complex   reasoning task .   6.5 Error Analysis   To better understand current models ’ errors , we ran-   domly sample 50 instances from the development   set and collect the predictions from the All - at - Once   ( T5 - 11b ) model . We manually evaluate the pre-   dictions and categorize 4 to 5 error types for each   component , as shown here in the Table 5 .   Specifically , the meta graph structure mainly has   five error types : ( G1 ) Incorrect inference type : the   model predicts the correct structure , but over one   of the inference steps has the inverse type ( i.g . , pre-   dicted support but should be rebut or vice versa ) ;   ( G2 ) Incorrect rebuttal : missing or incorrectly pre-   dict a rebuttal step ; ( G3 ) Incorrect conclusion : mis-   matched conclusion node at the end of the reason-   ing chain ; ( G4 ) Incorrect inference step : missing   or predicting redundant inference step ; ( G5 ) Other   structural mismatches : Including different chain   branches and so forth . The four error types in for-   mulae are ( F1 ) Incorrect logical variable : missing   or predicting redundant logical variable , or predict-   ing a wrong variable ; ( F2 ) Incorrect unary operator :   The variables are correct but are bound by incor-   rect unary operators ; ( F3 ) Incorrect binary operator :   The variables and unary operators are correct , but   predict incorrect binary operator . ( F4 ) Incorrect   implication direction : The variables , unary and bi-   nary operator types are correct , but the implication   operator has an inverse direction . The four error   types in certainty : ( C1 ) Incorrect polarity : Predict-   ing the certainty in an opposite polarity ; ( C2 ) Other   polarities to contingent ; ( C3 ) Contingent is pre-   dicted as other polarities ; ( C4 ) Unresolved degree   of certainty .   From the results we can see that , the model tends   to predict the operator quite well ( F2 / F3 ) , but not   the variable ( F1 ) , which suggests that even though   current deep models can identify the correct rela-   tions with some trigger words ( e.g. , “ so that ” ) , they   may not fully understand it because they can not   find the correct variable span in the context . Be-4705   sides that , we also notice that the model tends to   predict the wrong polarities , which is typically ir-   relevant towards the conclusion , as the important   certainty feature . This suggests that the model may   learn to answer questions with the wrong reason   ( i.e. , short path ( Lovering et al . , 2021 ) ) , which fur-   ther demonstrates the importance of our task for   constructing a reliable and trustworthy reasoning   system .   7 Conclusion   This paper extends the boundary of current research   on logical graph generation for reliable reasoning   systems . Specifically , we carefully design a com-   plete logic explanation form following previous   research on cognitive science . Accordingly , we   built MetaLogic with a comprehensive annotation   task design and quality examination . We also eval-   uate several recent models and show that the per-   formance of current models is still unsatisfactory ,   even with giant pre - trained language models . We   hope that this paper could motivate more future   works on reliable reasoning systems that could gen-   erate the correct logical graphs to support their rea-   soning . The MetaLogic data and implementation   code are available at https://github.com/   tencent - ailab / MetaLogic .   8 Limitation   The major limitation of MetaLogic is that we can-   not annotate a large enough dataset for data - driven   methods . However , considering that humans could   learn to conduct logical reasoning after seeing a   few examples , we argue that it is meaningful to   investigate whether machines can learn the same   level of reasoning capability with limited data.9 Ethical Considerations   During the annotation process , we follow the mini-   mum payment requirement of the united states . No   personal or confidential information is collected .   Hence , to the best of our knowledge , there is no   ethical concern .   Acknowledgements   We appreciate the anonymous reviewers for their   insightful comments . We thank Dr. Su Wu for re-   viewing the annotation manual , thank Dr. Xingchi   Su for double - checking the operator reduction ,   and thank Jianheng Tang , Zhicheng Yang , and   Xinran Zhao for their constructive advice for   the manuscript . This work was supported in   part by National Key R&D Program of China   under Grant No . 2020AAA0109700 , National   Natural Science Foundation of China ( NSFC )   under Grant No.61976233 , Guangdong Province   Basic and Applied Basic Research ( Regional   Joint Fund - Key ) Grant No.2019B1515120039 ,   Guangdong Outstanding Youth Fund ( Grant   No . 2021B1515020061 ) , Shenzhen Fun-   damental Research Program ( Project No .   JCYJ20190807154211365 ) and CAAI - Huawei   MindSpore Open Fund . We thank MindSpore for   the partial support of this work , which is a new   deep learning computing framework .   References47064707A Example Source Data from ReClor   Tables 6 , 7 , 8 , and 9 demonstrate the example   source data of different reasoning types from the   ReClor dataset .   B Guideline for Logical Relation   Annotation   Tables 20 , 21 , and 22 show mappings from natural   language patterns to binary logical operators refer-   ring to the PDTB3 senses ( Webber et al . , 2019 ) .   For the logical implication , the order of arguments   is provided . The three tables are provided to the an-   notators as their references during annotation . The   final annotation is subject to human understanding .   C Indicators of Unary Operators   Table 13 demonstrates the indicators for extracting   the unary operators .   D Annotation Interface   The annotation interface is demonstrated in Fig-   ure 6 .   E Model Details   E.1 All - at - Once T5   The input of the All - at - Once T5 is the overall log-   ical passages with sentences and variable deno-   tations . The output is the linearized metagraph   as shown in Table 10 . The linearized metagraph   consists of three parts : the meta structure , node4708   formula , and sentence certainty ( denoted with   $ graph$ , $ formula$ , and $ degree$ , respectively ) .   For the meta structure , we use the semicolon to   connect different edges . For the node formula , we   map the operator to word using the mapping { 2 :   [ necessary ] , 3 : [ possible ] , ¬ : [ negative ] , ∧ : [ and ] ,   ∨ : [ or],→ : [ entail ] } . We use the semicolon to con-   nect the triples for the same sentence . We connect   the certainties and formulae of sentences with “ |”.4709   We train the All - at - Once T5 model with a batch size   of 32 and a learning rate of 1e-5 for 300 epochs .   E.2 Multitask T5   The Multitask T5 decomposes the whole generation   task into three sub - tasks : meta structure generation ,   formula generation , and certainty prediction . We   train a single T5 model on these three sub - tasks   simultaneously . We follow Raffel et al . ( 2020 ) to   add a task - specific prefix to the input before feeding   it to the model . Table 11 shows some specific input   and output examples of each sub - task . We train the   Multitask T5 model with a batch size of 32 and a   learning rate of 1e-5 for 300 epochs . We use the   examples - proportional mixing ( Raffel et al . , 2020 )   and simply concatenate the data for all sub - tasks as   the training data for Multitask T5 .   E.3 MetGen   MetGen ( Hong et al . , 2022 ) is a module - based   framework for structured explanation generation .   Modules . We use two types of modules : the con-   clusion module and the rebuttal module . The con-   clusion module takes two sentences as input ( e.g. ,   sent1 : ... sent2 : ... ) and outputs the in-   ference relation type between them ( e.g. , sent1   - > sent2 orsent2 - > sent1 ) . If there is no   conclusive relationship between the two input sen-   tences , the module would output the word none .   The rebuttal module is defined similarly .   Controller . The controller decides the reasoning di-   rection based on the current reasoning state . Specif-   ically , given the current partially metagraph and all   the sentences , the controller predicts which com-   binations of two sentences ( e.g. , sent1 sent2 )   should be considered in the next step . If the current   proof is complete , the controller would output the   word done .   Reasoning Process . MetGen generates the meta-4710graphs in an iterative manner . It iteratively repeats   the following reasoning iteration to grow the graph   until either the controller returns done or the max-   imum number of iteration steps is reached . It takes   several iterations before completing the generation .   In each iteration , MetGen generates one step . It   first uses the controller to predict some possible   sentence combinations . Then , each combination is   sent to the reasoning modules to generate candidate   steps that indicate the detailed inference relation   type between them . The candidate step with the   highest score ( the lowest perplexity ) is picked for   the next iteration .   Implementations . To compare with other methods   under the same number of parameters , we imple-   ment MetGen using a single T5 model . Table 12   shows some input and output examples of MetGen .   The MetGen is trained on five sub - tasks simulta-   neously : controller task , conclusion module task ,   rebuttal module task , formula generation task , and   certainty prediction tasks . We train the MetGen   model with a batch size of 32 and a learning rate of   1e-5 for 300 epochs . We set the maximum number   of iteration steps as 3 .   E.4 Experimental Details   We use the pre - trained models from   HuggingFace Transformers . We   use the Adafactor optimizer ( Shazeer and Stern ,   2018 ) . We run the experiments based on T5 - large   3 times with different random seeds and report   the average performances . The experiments based   on T5 - 11b are run only once considering the   computational cost .   F Evaluation Metrics   Meta structure : Does the predicted metagraph   use the correct sentences and have the correct struc-   ture ? For meta nodes , we report a node F1 score   by comparing the set of sentences used in the pre-   dicted and gold metagraph . For meta structure , we   decompose the metagraph into one - premise steps   ( e.g. , sent1 - > sent2 ) . We compare the set   of steps in the predicted and gold metagraph and   report the step F1 score . A predicted step is correct   if its premise , conclusion , and step type match the   gold one . The AllCorrect score is 1 if the F1 is 1 , 0   otherwise .   Formula : Does the predicted metagraph have the   correct internal structure of meta nodes ? For each   sentence , we measure the formula F1 score by com-   paring all formulae in the predictions and gold an-   notations . A predicted formula is considered cor-   rect if its certainty operators , binary operators , and   variables match the gold one . For the certainty op-   erators , we reduce them to the standard form ( one   of the five degree - of - certainty forms listed in Ta-   ble 1 ) before comparison . For the binary operator ,   we consider its symmetry . For example , ¬v∧3v   is equivalent to 3v∧ ¬v , but¬v→3vis not   equivalent to 3v→ ¬ v. The AllCorrect score is   1 if the formula F1 is 1 , 0 otherwise . Since each   sample contains multiple sentences , we average the   formula F1 scores of all sentences in the sample as   the formula F1 score for this sample .   Certainty : Are the certainties of the sentence cor-   rect ? For each sample , we compute the accuracy   of the predicted certainties of the sentences . The   AllCorrect score is 1 if the accuracy is 1 , and 0   otherwise . We report the accuracy and AllCorrect   score of the testing dataset , which is the average   accuracy and AllCorrect score of all samples in4711   the dataset . Due to the unbalance of the certainty   labels , we gather the predictions for all sentences   in the dataset ( ignoring which sample the sentence   comes from ) and report the macro - F1 score .   Overall : The overall AllCorrect score of a pre-   dicted metagraph is 1 only if all of the meta struc-   ture , formulae , and certainties are correct . This is a   strict metric since any error would result in a score   of 0 .   G Detailed Analysis Results   Table 14 present the detailed performance of dif-   ferent inference steps and different operators . Ta-   ble 15 and Table 16 shows the detailed results with   different ratios of training data .   H Error Cases   Examples of each error type are shown in Ta-   bles 17 , 18 , and 19.4712471347144715471647174718471947204721472247234724