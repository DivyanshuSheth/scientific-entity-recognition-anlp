  Allen Kim , Steven Skiena   Department of Computer Science ,   Stony Brook University , NY , USA   { allekim,skiena}@cs.stonybrook.edu   Abstract   Understanding narrative flow and text coher-   ence in long - form documents ( novels ) remains   an open problem in NLP . To gain insight , we   explore the task of chapter ordering , recon-   structing the original order of chapters in novel   given a random permutation of the text . This   can be seen as extending the well - known sen-   tence ordering task to vastly larger documents :   our task deals with over 9,000 novels with an   average of twenty chapters each , versus stan-   dard sentence ordering datasets averaging only   5 - 8 sentences . We formulate the task of recon-   structing order as a constraint solving problem ,   using minimum feedback arc set andtraveling   salesman problem optimization criteria , where   the weights of the graph are generated based   on models for character occurrences and chap-   ter boundary detection , using relational chapter   scores derived from RoBERTa . Our best meth-   ods yield a Spearman correlation of 0.59 on   this novel and challenging task , substantially   above baseline .   1 Introduction   Novels are a fundamental long - form medium for   storytelling , requiring understanding of narrative   flow for full comprehension of the text . Although   neural network - based language models demon-   strate amazing performance in comprehending   short text windows , the problems of understanding   long - form narrative texts such as summarization   remain largely open .   A major challenge in research on long - form nar-   ration is the cost of annotation : the mere act of   reading a novel generally requires a 10 - 15 hour   commitment on the part of the annotator , making it   clearly cost prohibitive to obtain full annotations of   a significant corpus of novels . Although published   summaries are available for up to a few hundred   popular books , annotation cost is the rate limiting   step for work in this area ( Wu et al . , 2021).In this paper , we propose a new task that gets to   the heart of narrative flow analysis for novels , with-   out the need for human annotation . Most novels are   partitioned into chapters as a means of providing   thematic breakpoints for the reader . Randomly per-   muting the order of these chapters obviously ruins   the coherence of the narrative flow of the underly-   ing story . Here we propose the new task of chapter   ordering : reconstructing the original order of the   book given an input random chapter permutation   of the text .   This task is clearly related to the task of sen-   tence ordering ( Lapata , 2003 ; Barzilay and Lapata ,   2005 , 2008 ) , reconstructing a set of sentences in a   tiny story as to maximize their coherence . While   there is a large volume of prior work on sentence   ordering , to our knowledge , this is the first paper to   address chapter ordering . The natural approaches   for the sentence task can not be readily applied to   chapter order . First , chapters in novels usually   contain several hundred sentences , which can not   easily be encoded with the neural models applied   to sentence ordering . Second , the number of chap-   ters in a novel ( an average of 21.6 chapters / novel   in our corpus ) versus 5 to 8 sentences in popular   datasets . This matters , because the impressive per-   formances of the best sentence ordering models   show severe degradation with longer sequences . Fi-   nally , ordering sentences in a tiny story is a simpler   perceptual task for humans , whereas correctly or-   dering the chapters of even a single novel requires   hours of reading and analysis . The combination of   these factors makes chapter ordering a difficult task   that can not be tackled with standard methods . The   overview of our approach can be found in Figure 1 .   In this paper , we define the chapter ordering   problem and propose a variety of neural - based mod-   els to score the relative order of chapter - pairs . Our   main contributionsinclude:3838   •Definition of the Chapter Ordering Task , with   Associated Data Set – We define an acces-   sible new task relevant to study narrative   understanding on large texts , building on   our dataset of 9,007 text - cleaned , chapter-   permuted Project Gutenberg novels , each with   between 5 and 50 chapters per book and be-   tween five and two hundred paragraphs per   chapter . This is large enough to facilitate in-   teresting machine learning - based approaches ,   and provides a standardized resource for fu-   ture studies of chapter ordering to start with .   •Neural - based Coherent Models of Narrative   Flow – We model the task of chapter order-   ing using weighted directed graphs , where   edge(x , y)receives a coherent score predict-   ing the likelihood that chapter xappears ( im-   mediately ) before yin the published work .   We propose several natural coherence notions   implicit in long - form narratives , including :   – Character entry / exit recognition : Track-   ing the life progression of characters   through a novel is essential to under-   standing of the flow of the story . We   train effective classifiers to recognize   each character ’s introduction   – Identifying initial / concluding chapters :   There are subtle characteristics of the   start and end of a story that distinguishes   it from the middle of the narrative .   – Neighboring chapter detection : Narra-   tive flow implies that the events at the end   of one chapter are often connected to the   start of the next chapter . This direct cor-   relation provides strong reinforcement inkeeping certain chapters paired .   – Topic correlation : Generalizing beyond   chapter boundaries , the topical content in   nearby chapters is generally more closely   related than those further away .   •Optimization Techniques for Chapter Order-   ing – We present a method for finding the   chapter order that maximizes the coherence   score based on two classical problems on di-   rected weighted graphs : minimum arc feed-   back and traveling salesman problem . We   demonstrate that combining both objectives   simultaneously best exploits the variety of co-   herence constraints inherent in narrative anal-   ysis .   The paper is organized as follows . Section 2 sur-   veys related work in sentence ordering and whole   book - oriented NLP . Section 3 formalizes our task .   We present our methods for coherent scoring in   Section 4 , and in Section 5 our optimization tech-   niques . We present our experimental results in   Section 6 before concluding with future directions   for research .   2 Related Work   The sentence ordering task was first proposed to   test coherence of sentences ( Lapata , 2003 ; Barzi-   lay and Lapata , 2005 , 2008 ) . Traditionally , this   was tackled using human designed features and   classical machine learning techniques . This in-   cluded heuristics with Markov models ( Barzilay   and Lee , 2004 ; Bollegala et al . , 2005 ; Ji and Pul-   man , 2006 ) , K - means clustering ( Ji and Nie , 2008 ;   Zhang , 2011 ) , support vector machines ( Bollegala3839et al . , 2006 ; Nahnsen , 2009 ; Peng et al . , 2009 ;   Yanase et al . , 2015 ) and others like latent semantic   analysis ( Zhang et al . , 2010 ) and conditional ran-   dom fields ( Gella and Duong Thanh , 2012 ) . We   also note the representation of sentence ordering   as a graph in many past works as well ( Elsner and   Charniak , 2011 ; Li et al . , 2011 ; Guinaudeau and   Strube , 2013 ) . However , with advances in neural   modeling , other approaches have developed .   One category are pairwise ordering models ,   which deal with ordering at a pairwise level and   combines the results to get a global ordering . Tra-   ditionally , the models used in these approaches   have been GRUs and LSTMs ( Chen et al . , 2016 ;   Agrawal et al . , 2016 ; Moon et al . , 2019 ) , but   recently have moved towards Transformer - based   models like BERT ( Kumar et al . , 2020 ; Shen and   Baldwin , 2021 ) . One common approach to sen-   tence ordering considers the sentences as a graph   and optimizes the weights using algorithms such as   topological sort ( Prabhumoye et al . , 2020 ) or the   asymmetric traveling salesman problem ( Keswani   and Jhamtani , 2021 ) . The main disadvantage is that   a pair - wise ordering of two sentences is determined   in isolation from the other sentences . It may be the   case that the other sentences provide context that   make the ordering sensible .   Thus , the other main category of sentence or-   dering deal with set - to - sequence models , which   deal with end - to - end encoder - decoder frameworks .   Most common are pointer networks for sequence   prediction ( Gong et al . , 2016 ; Cui et al . , 2018 ; Yin   et al . , 2020 ) . This is often combined with other   methods such as recurrent neural networks ( Lo-   geswaran et al . , 2018 ; Oh et al . , 2019 ) . Recently ,   works have been incorporating graph - related net-   works ( Cui et al . , 2020 ; Yin et al . , 2021 ; Lai et al . ,   2021 ) as well . Additionally , the task has been   considered as a text - to - marker generation prob-   lem using BART ( Basu Roy Chowdhury et al . ,   2021 ) . These methods have the advantage that   all the sentences are taken in context , but lack the   interpretability of the previous models discussed .   We also rely heavily on literature in natural lan-   guage processing on books . Analysis of books have   been streamlined through pipelines like BookNLP   ( Bamman et al . , 2014 ) as well as datasets of entities   ( Bamman et al . , 2019 ) . We also find other book-   related works that improve the quality of books as   well as understanding aspects such as time ( Kim   et al . , 2020 , 2021 ) . In particular , we focus on chap - ters and require proper chapter segmentation ( Pethe   et al . , 2020 ) .   3 Problem Formulation   The chapter ordering task can be formulated as   follows . Given a book of Nchapters , let C=   [ c , . . . , c]be the sequence of chapters where   eachcrepresents the text content of chapter ifor   1≤i≤N. Let o= [ o , . . . , o]be a random   permutation of indices from 1 to N. Given a se-   quence of random chapters r= [ r , . . . , r ] , the   task is to find the correct order of chapter indices   o= [ o , . . . , o]such that [ r , . . . , r ] = C.   3.1 Dataset   Our dataset comes from Project Gutenberg ( Guten-   berg , n.d . ) filtered down to English fiction books of   which we collected 19,437 . We follow Pethe , Kim ,   and Skiena ( 2020 ) to clean and annotate chapters   using regular expressions on common chapter head-   ings . To filter out anomalies , we mandate that the   number of chapters have to be between 5 and 50 .   Additionally , we restrict each chapter to be at least   5 and at most 200 paragraphs . As a final restriction ,   we also require a numbering of chapters that start   from one , either in words or numeral form . This is   to avoid books that may be sequels or other parts   of a longer series . We note that the chapter title as   well as the chapter numbers are not included as part   of the input . Any books that do not follow these   requirements are filtered out of the dataset .   In total , we have 9,007 books with a mean chap-   ter length of 21.64 and standard deviation of 9.96 .   The median chapter length is 21 with the min and   max being 5 and 50 respectively due to the filtering .   These were then randomly train - test split in an 8:2   ratio .   4 Coherence Scoring   In this section , we describe our observations of   books that help us quantify relations between chap-   ters . Since the goal is to provide a benchmark on   the feasibility of the chapter ordering task and not   an exhaustive comparison on the effectiveness of   different models , we primarily use RoBERTa ( Liu   et al . , 2019 ) as our main pretrained language model   for all relevant tasks .   Implementation Details . We use the Transform-   ers ( Wolf et al . , 2019 ) library for fine - tuning   RoBERTa . All models were run on a compute   server with 2.30 GHz CPU and TeslaV100 GPU.3840Intro ( class 0 ) Middle ( class 1 ) End ( class 2 )   F1 P R F1 P R F1 P R   Only Intro 15.67 8.50 100 - - - - - -   Only Middle - - - 90.71 82.99 100 - - -   Only End - - - - - - 15.67 8.50 100   Guessing 8.56 8.54 8.54 82.97 83.00 82.93 8.55 8.51 8.60   RoBERTa 52.45 43.71 65.58 87.20 91.21 83.52 41.33 36.30 47.99   GPT2 33.29 57.96 23.35 91.28 85.58 97.80 24.31 69.17 14.75   No hyperparameter tuning was done on any mod-   els ; default values were run for all models .   4.1 Character Entry / Exit Recognition   Characters are a fundamental aspect of any story .   By tracking the life of a character through a book ,   we can greatly improve our understanding of the   underlying story . In particular , characters are typ-   ically introduced into the story with physical de-   scriptions and also end up leaving the story with   details of their departure .   We define the task as follows : given an occur-   rence of a character and the context of text it ap-   pears in , we want to predict whether this is the first   time a character is introduced , the last time it is   mentioned , or some time in the middle . This is   treated as a three - class ( intro , middle , end ) classifi-   cation problem .   Data Preparation . For each book , we apply   named entity recognition with coreference reso-   lution using Stanza ( Qi et al . , 2020 ) to identify   characters . Afterwards , we cluster the same char-   acters together using naming convention heuristics   e.g. Sherlock Holmes and Mr. Holmes . For each   character occurrence in the text , we extract a 512   sub - token window around it . The names of the   character in question were replaced with a special   < main > token and every other character in the con-   text was replaced with a special < other > token .   These context windows were then used for fine-   tuning RoBERTa with a token classification head   with three classes . Only the first occurrence was   marked as class 0 ( intro ) and only the last occur-   rence was marked as class 2 ( end ) ; the majority of   the instances were marked as class 1 ( middle).Evaluation . Table 1 shows the results of the   model on the test set for each of the predicted   classes - Intro ( first occurrence of character ) , Mid-   dle ( some middle occurrence of a character ) , End   ( last occurrence of a character ) . Each class is eval-   uated using standard metrics , where F1represents   the F1 score , Prepresents precision , and Rrep-   resents recall . In general , we see that RoBERTa   performs well in predicting introductions of charac-   ters and decently for ends as well . This is sensible   as when characters are introduced , there are more   descriptive adjectives and related signals in the text .   Typically , characters also leave the story at the end   of some event , which has its own signals as well .   4.2 Initial / Concluding Chapters   As in the case of sentence ordering , there are char-   acteristics of the start and end of a book that make   it more discernible as compared to the middle of   the book . Generally , there are " introducing " words   related to setting the scene in the beginning while   there are " concluding " words related to closing up   the story in the end , similarly to the introduction   and ends of characters .   We consider two tasks : first chapter prediction   and last chapter prediction . For first chapter predic-   tion , given text at the start of a chapter , the task is to   determine if it is the first chapter or not . Similarly ,   for last chapter prediction , given text at the end of   a chapter , the task is to determine if it is the last   chapter or not . These are treated as two separate   binary classification models .   Data Preparation . For the first chapter predic-   tion task , for each book , we take the first512 sub-   tokens of each chapter and use the first chapter as a   positive example and the others as negative . Analo-   gously , for the last chapter prediction task , for each3841Acc F1 P R   RoBERTa First 96.1 52.8 58.0 48.4   RoBERTa Last 97.2 65.7 74.6 58.7   GPT2 First 96.3 52.3 56.3 48.8   GPT2 Last 96.8 56.0 74.0 45.0   First Chapter Last Chapter   P@1 0.577 0.675   P@3 0.737 0.817   P@5 0.802 0.875   book , we take the last512 sub - tokens of each chap-   ter and use the last chapter as the positive example .   Both these tasks were fine - tuned on RoBERTa with   a token classification head with two classes .   Evaluation . Tables 2 and 3 show results for the   first and last chapter predictions . In general , we   see that the model is able to predict the correct first   chapter for more than 57 % of books and predict the   correct last chapter for more than 67 % of books .   It is interesting to note the relatively better perfor-   mance of last chapter prediction to first chapter ,   which indicates more common signals among book   endings as compared to introductions .   4.3 Boundary Scoring   The end of one chapter is typically connected to   the start of the next . This sequential correlation   provides strong reinforcement in keeping certain   chapters paired . We consider the following binary   classification task for a book : given the end of   chapter Xand the start of a different chapter Y ,   does chapter Ydirectly follow X ?   Data Preparation . As positive examples , we   concatenate the text at the end of a chapter with   the text at the start of the next chapter with a sep-   arator token . Every other combination is consid-   ered to be a negative example . Thus , a book with   Nchapters contain N−1positive examples and   N(N−1)−(N−1)negative examples . Given   an input size of 512 sub - tokens , we concatenate   the last 256 tokens of one chapter and the first 256tokens of another chapter as input to the model ( ac-   counting for special tokens ) . We again fine - tune   RoBERTa with a token classification head for two   classes .   Evaluation . Table 4 shows the results for bound-   ary detection . In general , we find that this is a   difficult task in isolation with an F1 of up to 0.32   in the macro scale , but nevertheless , this provides   valuable signal chaining chapters together when   the model is confident .   4.4 Topic Overlap   Similar to chapter boundaries , the discussion of   content in one chapter is generally more closely   related to the content of a neighboring chapter as   opposed to one further away . We capture this with   a simple lemma overlap score between chapters .   We do so by counting the number of lemmas in one   chapter that is in common with another and nor-   malizing by the number of lemmas in the smaller   chapter . Lemmatization was done using Stanza .   Stop words were filtered out using NLTK ( Loper   and Bird , 2002 ) .   Figure 2 shows the average topic score for vary-   ing distances between chapter pairs . As expected ,   we see that neighboring chapters share the most   overlap score while chapters further away decrease   in value .   5 Constraint Solving Problem   Section 4 discussed different methods of measuring   coherence between chapters . For each method , we   construct a weighted matrix that provides chapter   pairwise scores . These matrices can then be used   as weights of a directed graph that we can optimize   to find an optimal ordering.3842Micro ( Support : 1,019,744 ) Macro ( Support : 1,802 )   Accuracy F1 P R Accuracy F1 P R   Random 92.75 3.69 3.69 3.70 90.89 4.03 5.23 3.69   RoBERTa 96.574 27.86 66.74 17.61 94.81 23.78 57.17 17.03   GPT2 96.36 30.50 54.08 21.24 94.55 26.09 50.13 20.60   5.1 Computing Coherence Matrices   For each method , we describe the details in how   the weights are constructed .   Character Introductions and Exits . Given a   model that can predict the first and last occurrences   of a character in a book , for each character , we   identify the chapter where the character was most   likely introduced as well as the chapter where the   character was most likely last seen . Given the best   guess of the first chapter and last chapter a character   appears in , we add a vote to each chapter pair from   first to others and others to the last chapter . We   then count the votes among all the characters in   the book , and normalize between disagreeing votes .   For example , if there are three characters that seem   to start at chapter Xbefore chapter Y , but one   character that seems to start at chapter Ybefore   chapter X. The directed edge weight from node X   toYwould be 0.75 , while the weight from YtoX   would be 0.25 .   Boundary Scoring with First and Last Chap-   ter Prediction . For each chapter , we can directly   compute a score to every other chapter by directly   extracting the probabilities from the boundary scor-   ing model . To factor in first and last chapters , we   also consider sentinel nodes that act as the first and   last nodes and add weights from the first sentinel   node to every other non - sentinel node based on the   output from the first chapter model . Analogously ,   we add weights from every non - sentinel node to   the last sentinel node based on the output from the   last chapter model .   Topic Overlap . For each pair of chapters , we   compute a lemma intersection score as described in   Section 4.4 . As an example , a filtered chapter with   the words “ walk happy park bench ” would have   a score of 0.75 with a filtered chapter of “ walk   happy park ball play ” . This score directly defines   the weight edges between every pair of chapters.5.2 Optimization Methods   We first consider optimal ways to find orderings   for each method individually , and then consider   approaches that combine them .   •Character introductions and ends - This can   be optimized by finding the order that mini-   mizes the sum of the weights of back edges ,   i.e. edges that go from a node to an earlier   one in the given order .   •Chapter boundaries with first and last chap-   ters- This can be treated as finding a directed   path that visits each node exactly once and   maximizes the coherence scores in a weighted ,   asymmetric graph .   •Topic overlap - This is the same as above , but   for a weighted , symmetric graph .   For these optimization tasks , we consider two   classical problems , both known to be NP - hard .   Minimum feedback arc set . A feedback arc set   is a subset of edges in the graph that contains at   least one edge out of every cycle in the graph . The   edge constraints from character entries / exit scores   imply entries before exits ; the topological order   implicit after removing the feedback set minimizes   violated constraints .   Traveling salesman problem . Given a graph ,   what is the shortest possible route that visits each   node exactly once ? The weights from boundary ,   first/ last chapter , and topic overlap scores naturally   define appropriate edge weights for TSP .   Solutions . Although these problems are NP-   complete , heuristic solutions are effective . For   minimum feedback arc set , we consider a heuris-   tic approach of local minimization using random   swaps . For the traveling salesman problem , we3843   employ an off - the - shelf exact solver , Concorde   ( Applegate et al . , 2009 ) , which employs branch   and bound techniques to make our task feasible   within a short time .   To show the effectiveness of our optimization ,   we compare the scores we obtain using our methods   to the scores obtained applying the actual chapter   orders . Figure 3 shows the feedback arc set weights   as well as the TSP weights using our optimization   and the ones found through the gold standard . In   both cases , we see that our ordering generally has   lower feedback arc weight than that of the correct   order and has higher TSP scores than that of the   correct order , showing the optimality of Concorde   and our local search optimization .   The scale of TSP scores and feedback arc set   scores are quite different , so we normalize them   into z - scores before mixing them . This was done by   sampling 100 random orders and computing their   metrics to get sample mean and standard deviations .   The experiments reported in Table 5 show that em-   ploying both optimization criteria in a 50 - 50 mix   typically identifies the best order .   6 Experimental Results   6.1 Evaluation Metrics   We follow the same metrics used in works to evalu-   ate sentence ordering . For all of these metrics , let   Nbe the number of books in our test set .   Perfect Match Ratio ( PMR ) . PMR measures the   fraction of books that were predicted to be exactly   the same as the original order . This is the strictestmetric .   PMR = 1   N / summationdisplay1(o = o )   where oandorepresents the correct order and   predicted order respectively .   Chapter Accuracy ( Acc ) . Acc measures the av-   erage percentage of chapters for which the pre-   dicted absolute position was correct within each   book . This is also a strict metric .   Acc=1   N / summationdisplay   1   k / summationdisplay1(o = o)      where krepresents the number of chapters in book   i , and oandorepresents the correct and pre-   dicted chapter index for the j - th chapter in book i   respectively .   Kendall Tau ( Tau ) . Tau quantifies the distance   between the predicted order and the correct order in   terms of the number of inversions ( Lapata , 2006 ) .   τ= 1−2 ( # inversions ) /parenleftbig / parenrightbig   Spearman . Spearman measures the rank corre-   lation of the predicted order with the standard in-   creasing chapter order . The indices of the correct   order are remapped such that the indices are strictly   increasing before computing . Equation omitted as   this is a well - known metric .   Rouge - S. Rouge - S calculates the percentage of   chapter pairs for which the relative order is pre-   dicted correctly ( Chen et al . , 2016 ) . There is no   penalty for gaps between the chapter pairs .   Rouge - S = 1 / parenleftbig / parenrightbig / bracketleftbig   Pairs ( o)∩Pairs ( o)/bracketrightbig   where krepresents the number of chapters in book   i , and Pairs ( o ) represents all / parenleftbig / parenrightbig   relative ordering   pairs for order o.   Longest Common Subsequence ( LCS ) . LCS   measures the ratio of the longest common subse-   quence between the predicted order and the correct   order , computed using dynamic programming.3844Method Param PMR Acc Tau Spearman Rouge - S LCS   Random - 0.000 5.710 0.000 -0.192 50.142 33.590   Character - 0.777 18.012 10.446 55.251 72.022 49.699   Boundary Default 1.664 10.207 3.856 10.503 56.589 47.437   + First / Last chapter 3.163 18.150 11.517 28.500 63.160 52.236   c= 0.0 0.277 6.799 0.783 0.025 50.138 36.896   c= 0.25 3.219 19.994 12.990 32.452 64.662 53.102   c= 0.5 3.718 20.541 13.881 33.488 65.247 54.267c·Boundary   with(1−c ) ·   Topic   c= 0.75 3.940 20.614 13.426 32.900 65.136 54.437   c= 0.0 0.333 11.927 5.084 17.870 58.124 46.205   c= 0.25 1.332 19.909 13.041 57.290 73.505 54.155   c= 0.5 1.332 19.846 11.780 57.375 73.496 54.151c·Character   with(1−c ) ·   [ best Boundary   + Topic]c= 0.75 1.48 19.916 12.648 57.758 73.703 54.237   c= 0.0 3.885 20.581 13.402 32.844 65.105 54.402   c= 0.25 1.387 22.010 14.071 59.204 74.469 55.361   c= 0.5 1.554 22.048 14.537 59.174 74.416 55.210   c= 0.75 1.498 21.684 14.270 59.493 74.518 55.157c·Character   with(1−c ) ·   [ best Boundary   + Topic ]   initialized with   best TSP c= 1.0 1.276 21.413 14.159 58.499 73.699 51.993   6.2 Analysis   Table 5 presents our final results as an ablation   study , giving a complete breakdown of differ-   ent model variations . We note that adding ini-   tial / conclusion chapter prediction to the boundary   matrix as all the metrics improve considerably . Our   strongest results combine all methods of coherence   scoring , with top performance when the boundary   scores are weighted more heavily than the topic   coherence score .   Figure 4 show the decline in our overall metrics   as the number of chapters increases . As previously   shown in the sentence ordering task , the problem   gets harder as the number of text units increases .   7 Conclusion   In this paper , we introduce a new task of chapter   ordering as an approach to study long - form narra-   tive understanding without cost - prohibitive human   annotation . The standard approaches used in the3845smaller - scale sentence ordering tasks do not ex-   tend directly to chapter ordering , because longer   texts exceed the capacity of current neural language   models .   Future work may include incorporating efficient   transformers that incorporate longer text windows ,   although we believe that approaches which explic-   itly incorporate logical reasoning about events may   be necessary to achieve substantial progress . We   will release our full dataset on publication to en-   courage additional research on this task .   Limitations   To our knowledge , this is the first paper to intro-   duce chapter ordering , and while we present novel   methods to tackle it , we discuss limitations of our   approach .   First , our dataset is limited to English fiction   books that were generally written in the early 1900s   and earlier . This is largely due to copyright issues   involved with using more modern texts , and be-   cause of this , our models are inherently biased to   the language used in older texts . It is unclear how   well these models will perform on modern texts   given changes in writing style over time . Inher-   ently , there will also be model biases concerning   gender and race that originate from these older texts   as well .   Second , we use the base RoBERTa as our lan-   guage model of choice to produce coherence scores ,   but we do not extensively survey other models pri-   marily due to memory and time constraints . As the   main bottleneck in our approach were the coher-   ence scores as opposed to the optimization , using   larger and more efficient language models should   improve performance . In particular , efficient trans-   formers such as Longformer ( Beltagy et al . , 2020 )   that are capable of taking in longer windows of text   should show improved results for this task .   Finally , we present only one view of tackling this   problem , based on optimizing a graph generated   from coherence scores suggested by human obser-   vations on characters and story connection . All of   our relational scores were derived from analyzing   chapter pairs in isolation . However , it is possible   that certain chapter orderings make sense only with   other chapters as context , and this is not completely   captured with our approach . Scores may also show   improvement with a contrastive learning objective   that considers all chapters holistically . References384638473848