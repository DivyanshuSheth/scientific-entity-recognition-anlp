  Qing LyuHua ZhengDaoxin LiLi Zhang   Marianna ApidianakiChris Callison - BurchDepartment of Computer and Information Science , University of PennsylvaniaKey Lab of Computational Linguistics ( MOE ) , Peking UniversityDepartment of Linguistics , University of Pennsylvania   { lyuqing,zharry,marapi,ccb}@seas.upenn.edu   zhenghua@pku.edu.cn   daoxinli@sas.upenn.edu   Abstract   Recursive noun phrases ( NPs ) have interest-   ing semantic properties . For example , my fa-   vorite new movie is not necessarily my fa-   vorite movie , whereas my new favorite movie   is . This is common sense to humans , yet it is   unknown whether language models have such   knowledge . We introduce the Recursive Noun   Phrase Challenge ( RNPC ) , a dataset of three   textual inference tasks involving textual entail-   ment and event plausibility comparison , pre-   cisely targeting the understanding of recursive   NPs . When evaluated on RNPC , state - of - the-   art Transformer models only perform around   chance . Still , we show that such knowledge   is learnable with appropriate data . We further   probe the models for relevant linguistic fea-   tures that can be learned from our tasks , in-   cluding modiﬁer semantic category and mod-   iﬁer scope . Finally , models trained on RNPC   achieve strong zero - shot performance on an ex-   trinsic Harm Detection evaluation task , show-   ing the usefulness of the understanding of re-   cursive NPs in downstream applications .   1 Introduction   Recursion , the self - embedding of a linguistic struc-   ture , constitutes a fundamental property of human   language . Due to its hierarchical structure , it poses   many challenges to human language acquisition .   One such challenge occurs in the context of recur-   sive Noun Phrases ( NPs ) , i.e. , NPs with multiple   prenominal modiﬁers . For instance , in Figure 1 ,   when asked to point to the second green ball in a se-   ries of balls , children sometimes erroneously point   to the second andgreen ball ( intersective interpreta-   tion ) , instead of the second among green balls ( re-   cursive interpretation ) ( Matthei , 1982 ; Hamburger   and Crain , 1984 ; Marcilese et al . , 2013).Figure 1 : The intersective ( incorrect ) and the recursive   ( correct ) interpretation of the second green ball .   We investigate whether language models ( LMs )   make similar errors , since the understanding of   recursive NPs is also fundamental in real - world AI   applications . For example , a summarization system   should know that the former US president can not   be shortened as the president , since they are no   longer in power . Also , a self - driving car asked to   take the ﬁrst left - hand exit should not assume that   it is always the ﬁrst exit .   Previous work has studied the syntactic parsing   of recursive NPs ( Nakov and Hearst , 2005 ; Pitler   et al . , 2010 ) , as well as the semantic categorization   of modiﬁers in NPs with only one prenominal mod-   iﬁer ( Kamp and Partee , 1995 ; McCrae et al . , 2014 ) .   However , neither parsing nor modiﬁer categoriza-   tion alone can sufﬁciently capture the meaning of   recursive NPs ( § 2 ) .   In this paper , using recursive NPs with two modi-   ﬁers as our test - bed , we address the following ques-   tions about LMs ’ understanding of recursion :   ( a)Is the knowledge of how to interpret re-   cursive NPs present in LMs ( § 5 ) ? We propose5286   the Recursive Noun Phrase Challenge ( RNPC ) , a   challenge set containing three classiﬁcation tasks :   Single - Premise Textual Entailment , Multi - Premise   Textual Entailment , and Event Plausibility Compar-   ison ( § 3 ) . Table 1 provides examples for each task .   Results show that state - of - the - art ( SOTA ) LMs ﬁne-   tuned on standard benchmarks of the same format   ( e.g. , MNLI ( Williams et al . , 2018 ) ) all struggle on   our dataset , suggesting that the target knowledge is   not readily available .   ( b)Is such knowledge learnable with appro-   priate data ( § 6 ) ? We adopt the challenge set   analysis technique proposed by Liu et al . ( 2019a ) ,   which exposes models to a small amount of data   and assesses how well they can adapt . All mod-   els achieve a noticeable performance improvement   with as few as 200 examples , indicating that the   target knowledge is potentially learnable .   ( c)What can models learn from recursive   NPs ( § 7 ) ? We probe the ﬁnetuned models for two   well - studied linguistic features in previous work ,   modiﬁer semantic category and modiﬁer scope . We   show that both features can be learned from RNPC ,   with techniques including edge probing ( Tenney   et al . , 2019 ) and attention visualization ( Vig , 2019 ) .   ( d)Is such knowledge useful for downstream   tasks ( § 8) ? When evaluated on an extrinsic Harm   Detection task , models ﬁnetuned on RNPC achieve   strong zero - shot performance . This shows that the   understanding of recursive NPs can beneﬁt down-   stream language understanding tasks .   In summary , our work identiﬁes an interesting   linguistic phenomenon that is common sense tohumans but challenging for models . It contributes   to the characterization of LMs ’ limitations and ca-   pabilities in language understanding .   2 Related Work   Noun Phrases ( NPs ) have been extensively studied   in both linguistics and NLP , primarily from the   following perspectives .   Syntactic structure . A line of work focuses on   the syntactic structure of NPs , which essentially   explains the modiﬁer scope ( Campbell , 2002 ) in   NPs . One classic task is NP bracketing , i.e. , decid-   ing whether an NP is right - branching ( e.g. , [ world   [ oil prices ] ] ) or left - branching ( e.g. , [ [ crude oil ]   prices ] ) ( Lauer , 1995 ; Nakov and Hearst , 2005 ) . A   harder task is full parsing ( Vadas and Curran , 2007 ;   Pitler et al . , 2010 ) , i.e. , reconstructing the complete   dependency tree .   Modiﬁer semantics . Another line of research   revolves around the semantics of simple modiﬁer-   noun composition , starting with ways to categorize   modiﬁers based on their inference patterns ( Kamp   and Partee , 1995 ; Bouillon and Viegas , 1999 ; Chier-   chia and McConnell - Ginet , 2000 ) . With Mas the   modiﬁer and Nas the noun , a representative taxon-   omy summarized by McCrae et al . ( 2014 ) is :   ( 1)intersective : Xis aM N = ⇒XisM∧Xis   aN , e.g. , “ an American surgeon ” describes some-   one who is both American and a surgeon ;   ( 2)subsective : Xis aM N = ⇒Xis aN , but   Xis aM N / negationslash=⇒XisM , e.g. , someone who is   “ askillful surgeon ” is not necessarily skillful in all   disciplines;5287(3)privative : Xis aM N / negationslash=⇒Xis aN , e.g. ,   “ aformer surgeon ” describes someone who is no   longer a surgeon .   Despite the variationsand debateson the tax-   onomy , we follow these conventional terms in sub-   sequent sections .   With the advances in NLP , more recent works   starts modeling the semantics of simple modiﬁer-   noun constructions with ﬁrst - order logic ( McCrae   et al . , 2014 ) , linear mapping ( Baroni and Zampar-   elli , 2010 ) , and other explicit compositional op-   erations ( Boleda et al . , 2012 , 2013 ) . In particu-   lar , Pavlick and Callison - Burch ( 2016a , b ) propose   a novel contextualized inference - based approach .   They deﬁne the Add - One Entailment task with nat-   ural contexts from textual corpora , where the hy-   pothesis differs from the premise by the insertion   of one modiﬁer . For example , Thecrowd roared   entails Theenthusiastic crowd roared , though en-   thusiastic crowd denotes a subset of crowd without   context . However , natural contexts also introduce   complications from monotonicity ( Van Benthem ,   1983 ) . For instance , red apple entails apple , but He   did n’t eat any red apple does not entail He did n’t   eat any apple due to the downward entailment con-   text . In our proposed approach , we handle this   issue by controlling for context monotonicity .   Other related work explores which attributes of   the head noun are affected by the presence of mod-   iﬁers . Mullenbach et al . ( 2019 ) look at how mod-   iﬁers project from a noun to its parts ( e.g. , does a   red jeep have red tires ? ) . Emami et al . ( 2021 ) test   the likelihood change of an event when a modiﬁer   is added ( e.g. , a false key is less likely to open a   door than a key ) . Apidianaki and Garí Soler ( 2021 )   study the prototypical properties of nouns ( e.g. , a   strawberry entails a red strawberry ) . Researchers   also examine the interpretation of noun compounds   ( Shwartz and Waterson , 2018 ; Hendrickx et al . ,   2013 ) ( e.g. , olive oil is made ofolives , while baby   oil is made forbabies ) .   Summary . Neither syntactic parsing nor modiﬁer   semantics alone can fully capture the meaning of   recursive NPs . In terms of syntax , modiﬁer scope   can not always explain NPs due to the inﬂuence   from modiﬁer semantics . For instance , a [ big [ fakegun ] ] anda [ big [ black gun ] ] have the same struc-   ture but different inference patterns , i.e. only the   latter is a gun . Meanwhile , modiﬁer category itself   does not sufﬁce without taking into account modi-   ﬁer scope . For example , a so - called healthy food   anda so - called homeopathy expert start with the   same privative modiﬁer ( so - called ) . However , so-   called questions truthfulness of the second modiﬁer   ( healthy ) in the former case while that of the noun   ( expert ) in the latter . Therefore , we introduce a   dataset containing three novel and challenging tex-   tual inference tasks , which rely on the interplay of   syntax and semantics in determining the meaning   of recursive NPs .   3 Task Formulation   Our dataset contains three tasks . Let us de-   note a canonical two - modiﬁer recursive NP by   Det MMN(Determiner , Modiﬁer 1 , Modi-   ﬁer 2 , Noun ) . With this notation , the tasks are   outlined below . See Table 1 for concrete examples .   Single - Premise Textual Entailment ( SPTE )   follows the conventional TE task format . Given   a premise and a hypothesis , the model decides   whether the premise semantically entails the hy-   pothesis . The labels include entailment and   non - entailment .An SPTE example can be   represented in regular expression as :   Premise :P DetMMN   Hypothesis :P Det ( M|M)?N   Label : entailment|non - entailment   where Pis a sentence preﬁx , which can be instanti-   ated as This is / He is / She is , etc . , depending on the   NP . Intuitively , this task tests whether an NP en-   tails its various components . This holds for most   simple NPs ( e.g. , the second ball entails ball ) , but   recursive NPs offer interesting counterexamples   ( e.g. , ( 1b ) in Table 1 ) .   Multi - Premise Textual Entailment ( MPTE ) is   adapted from the attributive propagation test de-   scribed in Lalisse ( 2015 ) . The format differs from   SPTE only in that it has two premises instead of   one . Given that both are true , the task is to deter-   mine whether the hypothesis is also true . The ﬁrst   premise is of the same form as in SPTE . The sec-   ond premise contains a noun other than N , denoted5288   byN.A regular expression representation is :   Premise 1 :P DetMMN   Premise 2 :P DetN   Hypothesis :P Det ( M|M)N   Label : entailment|non - entailment   This test targets the compositionality of modiﬁers   and nouns . While most of the time a modiﬁer can   be freely “ detached ” and “ attached ” ( e.g. , ( 2a ) ) ,   sometimes it can not ( e.g. , ( 2b ) ) .   Event Plausibility Comparison ( EPC ) follows   the task formalization by Emami et al . ( 2021 ) for   single - modiﬁer NPs . Given two events , Event1   andEvent2 , a model needs to assess the plau-   sibility of Event2 compared to that of Event1 .   The two events have the same event predicate E ,   and differ only in the NP . A regular expression   representation is :   Event 1 : Det ( M|M)?N E   Event 2 : DetMMN E   Label : more|equally|less plausible   This task tests the inﬂuence of adding modiﬁer(s )   on the plausibility of different events about the   noun . Not all events are affected in the same way :   in ( 3 ) , stars in many latest movies becomes less   plausible , while is known by everyone is more so .   We choose the three tasks deﬁned above because   they allow us to study different interesting prop-   erties of recursive NPs that conventional parsing   tasks do not . For example , SPTE is convenient   for comparing the impact of modiﬁer order on the   meaning of the NP ( e.g. , ( 1a ) and ( 1b ) ) ; MPTE pre-   cisely reﬂects the property of subsective modiﬁers   ( e.g. , skillful ) ; whereas EPC is suitable for NPs   with privative modiﬁers , since the other formats   often cause ambiguity in this case .   4 Dataset Construction   Our dataset is constructed in four stages : ( a ) mod-   iﬁer lexicon construction , ( b ) NP extraction and   selection , ( c ) instance creation and review , and ( d )   label veriﬁcation . Among them , ( c ) and ( d ) involve   crowdsourcing .   Modiﬁer lexicon construction . We ﬁrst con-   struct a lexicon of modiﬁers following the taxon-   omy in Section 2 ( McCrae et al . , 2014 ) . We include   modiﬁers studied in relevant linguistics literature   ( Nayak et al . , 2014 ; Lalisse , 2015 ) and comple-   ment the list with modiﬁers that are missing or   have not been addressed before under this lens ( for   example , modiﬁers that describe material , such as   wooden , can also be viewed as privative ) . Each   entry in the lexicon contains the modiﬁer itself , its   category ( intersective , subsective , or privative ) , and   its attribute ( e.g. , green is a ) . In total , the   lexicon contains 689 modiﬁers , the largest resource   of this kind . See Table 2 for category distribution   and examples .   NP extraction and selection . Next , we collect   recursive NPs from a variety of resources : linguis-   tics literature ( Matthei , 1982 ; Abdullah and Frost ,   2005 ; Teodorescu , 2006 ; Morzycki , 2016 ) , text cor-   pora ( Penn Treebank ( Marcus et al . , 1993 ) and   the Annotated Gigaword corpus ( Napoles et al . ,   2012 ) ) , and our creation . From text corpora , we   extract all NPs with more than two consecutive   modiﬁers in our lexicon , and manually select NPs   considering a set of factors : lexical diversity , class   balance , whether there is an interaction between   the modiﬁers , etc . Finally , we complement the set   with deliberately designed challenging cases of our   invention , resulting in 1,299 NPs in total.5289   Instance creation and review . We hire college   studentsto write examples for the three tasks   based on our collection of NPs . Each student   is given a screening test containing ﬁve NPs . If   ≥75 % of their created examples across all tasks   are valid , they are qualiﬁed to continue . Each in-   stance is then reviewed and/or revised by one of   the authors , resulting in 8,260 valid instances .   Label veriﬁcation . We again hire college stu-   dents to verify instance labels via Amazon Mechan-   ical Turk . Each task has a screening test of 10 easy   instances with an unambiguous answer , and only   students with an accuracy of ≥90 % can proceed .   During the ofﬁcial annotation , a HIT contains 10   questions of a task , including one control question .   Each HIT is completed by three people , excluding   its creator . Annotations are then ﬁltered based on   the accuracy on control questions and the time used .   Only examples with ≥2people agreeing with the   gold label are retained , yielding 4,567 examples .   We then down - sample the examples in each task for   a relatively balanced ratio among classes , resulting   in 3,705 examples . See Table 3 for details .   5 Do LMs understand recursive NPs ?   To answer question ( a ) , whether the knowledge of   how to interpret recursive NPs is present in pre-   trained LMs , we use the “ behavioral test ” probing   method ( Belinkov et al . , 2020 ) . Namely , we eval-   uate SOTA models ﬁnetuned on existing bench-   mark(s ) of the same format as each RNPC task . The rationale is that LMs should acquire the ability   of textual inference in the required format during   ﬁnetuning , which allows us to elicit their potential   knowledge about recursive NPs .   Experimental setup . We consider the follow-   ing datasets that address similar phenomena as our   tasks : ( 1 ) MNLI ( Williams et al . , 2018 ) and SNLI   ( Bowman et al . , 2015 ) for our SPTE ; ( 2 ) MPE   ( Lai et al . , 2017 ) for our MPTE ; and ( 3 ) ADEPT   ( Emami et al . , 2021 ) for our EPC . We choose SOTA   and close - to - SOTA models on these benchmarks as   probing candidates , including BERT ( Devlin et al . ,   2019 ) , RoBERTa ( Liu et al . , 2019b ) , BART ( Lewis   et al . , 2020 ) , and GPT3 ( Brown et al . , 2020 ) .   Results and analysis . We evaluate the ﬁnetuned   models on each RNPC task . When the ﬁnetuning   dataset has more classes than our task does , we   map the model prediction to one of our classes   by summing probability scores . Figure 2 com-   pares the performance of the models on the relevant5290   benchmarks and our tasks . We also include human   performance , calculated by averaging the accuracy   of three college student annotators on a random   sample of 300 examples for each task .   All models struggle on RNPC with performance   around chance , while human accuracy is constantly   above 90 . On SPTE and MPTE , almost all mod-   els have a high false - positive rate . As long as all   tokens in the hypothesis ( e.g. , This is the second   ball ) appear in the premise ( e.g. , This is the second   green ball ) , they tend to predict entailment , in-   dicating that they are making the same intersective   interpretation errors as children do . On EPC , most   models over - predict equally plausible , ar-   guably due to the class imbalance during ﬁnetuning .   This also shows that our task is not trivially solv-   able by models that understand non - recursive NPs ,   which the ﬁnetuning dataset comprises .   Next , we closely examine the best - performing   models on each task , including RoBERTa - large   ﬁnetuned on MNLI , GPT3 - curie ﬁnetuned on MPE ,   and RoBERTA - large ﬁnetuned on ADEPT . On   MPTE and EPC , even the best model barely sur-   passes chance performance . On SPTE , the best   accuracy ( 61.2 ) is still unimpressive for a binary   classiﬁcation task . To understand where exactly   the models fail , we further present a qualitative   minimal - pair analysis in Table 4 . On SPTE , the two   examples differ only in the order of modiﬁers ( new   andfavorite ) in the premise , leading to opposite la-   bels . However , the model predicts entailment   for both , suggesting its insensitivity to subtle mean-   ing differences incurred by modiﬁer order changes .   On MPTE , the difference between the two exam-   ples lies in the modiﬁer in the hypothesis , an Ameri - can man vs.a short man . As basketball players are   generally tall , the second hypothesis should not be   entailed . Again , the model predicts entailment   for both cases , which shows its lack of relevant   world knowledge . Finally , on EPC , a dead dan-   gerous animal anda dangerous dead animal have   subtly different meanings – the former refers to a   dangerous animal that is dead ( e.g. , a dead lion ,   which is no longer harmful to people ) , while the   latter refers to a dead animal that has become dan-   gerous ( e.g. , a dead squirrel carrying viruses , which   is indeed harmful ) . The model fails to distinguish   between them , predicting less plausible for   both . All the above observations show that the   knowledge for interpreting recursive NPs is not   present in LM representations .   6 Can LMs Learn the Meaning of   Recursive NPs ?   We investigate the reasons behind the models ’ low   performance on RNPC , speciﬁcally whether their   failure is due to the lack of in - domain training   data or an intrinsic deﬁciency in their architecture .   Namely , we attempt to answer question ( b ): Is the   target knowledge learnable with appropriate data ?   We adopt the challenge set analysis technique   from Liu et al . ( 2019a ) , which exposes a model to   a small amount of challenge data and assesses how   well it can adapt . Speciﬁcally , we split each RNPC   task dataset into a training set of 200 examples and   a new test set containing the rest , ensuring that they   have different modiﬁers in the same position . For   example , if a modiﬁer appears as the Mof an NP   in the training set , it can not appear in the same po-   sition of any NP in the test set . Then , we ﬁnetune5291   each model from Figure 2 on an increasing num-   ber of examples ( 10 to 200 ) . The learning curves   of the best - performing models ( RoBERTa - large   ( MNLI ) , RoBERTa - base ( MPE ) , and RoBERTA-   large ( ADEPT ) ) are plotted in Figure 3 .   On SPTE , the accuracy rapidly climbs from 61.1   to 75.8 with only 10 examples , and saturates around   92 with 100 examples , approaching human perfor-   mance ( 94.1 ) . The learning curve on MPTE has   more ﬂuctuations , with a peak at 71.1 ( 150 exam-   ples ) and a ﬁnal score of 67.8 . On EPC , starting   around chance ( 39.5 ) , the accuracy progressively   increases up to 64.4 with 200 examples . These re-   sults indicate that the target knowledge is learnable   with appropriate training data . Furthermore , SPTE   may be the easiest task , since it only requires local   knowledge about the meaning of the modiﬁers and   the noun . By contrast , MPTE and EPC involve   world knowledge ( e.g. , basketball players are gen-   erally tall among the population ) , as well as global   reasoning between components in a sentence ( e.g. ,   the relationship between the event and the modi-   ﬁers ) , which may explain the remaining large gap   between model and human performance ( > 90 ) .   7 What can LMs learn from RNPC ?   Given that the target knowledge is learnable , we   now address question ( c ): What linguistic features   have the models learned from RNPC ? We probe   for two features extensively studied in the relevant   literature ( cf . § 2 ) , using different techniques .   Modiﬁer semantic category . We ﬁrst investi-   gate if models have learned the semantic category   of modiﬁers using the “ edge probing technique ”   ( Tenney et al . , 2019 ) . Namely , each modiﬁer is   categorized as intersective , subsective , or privative   ( McCrae et al . , 2014 ) . The entailment pattern of   individual modiﬁers is an important factor in deter-   mining the meaning of the entire NP .   Given a ﬁnetuned model , we take the contextu-   alized representation of each modiﬁer in the last   hidden layer . Then , we attach a linear head on top   of the token representation as an “ auxiliary classi-   ﬁer ” . We choose linear classiﬁers because more ex-   pressive ones like Multi - Layer Perceptron are more   likely to capture the target feature themselves ( He-   witt and Liang , 2019 ) . The token representations   are then frozen , while the linear head is trained to   predict the semantic category of the modiﬁers .   We probe the models ﬁnetuned on RNPC from   Section 6 , as well as the models ﬁnetuned on ex-   isting benchmarks for comparison . The results are   shown in Figure 4 . For all tasks , the probing ac-   curacy is higher for models ﬁnetuned on RNPC   than on existing benchmarks . The increase is small   for SPTE ( 3.4 ) and MPTE ( 2.8 ) , but more obvious   for EPC ( 7.1 ) . This is somewhat counter - intuitive   since modiﬁer category is deﬁned in terms of entail-   ment patterns , but models learn it better from EPC   than from TE tasks . Nonetheless , the overall trend   shows that models can learn the semantic category   of modiﬁers to some extent after being ﬁnetuned   on our datasets . Since the absolute increase is lim-   ited , we plan to explore ways to quantify the actual   amount of learned knowledge in future work .   Modiﬁer scope . We also probe for the scope   of the ﬁrst modiﬁer ( M ) in recursive NPs   ( Det MMN ) . Speciﬁcally , we focus on pri-   vative M ’s , since they can have different scopes   when interacting with different M ’s and N ’s . For   instance , in the NP a former American diplomat ,   former negates diplomat ( N ) , but the person is still   American ; while in a former beginner drummer , it   negates beginner ( M ) , but the person may still be5292   a drummer . This difference can not be captured   by the semantic category of former .   As a proxy for the scope of M , we use atten-   tion visualization , a widely adopted technique to   study token correlations ( Vig , 2019).We choose   BERT - base ﬁnetuned on 200 MPTE examples from   Section 6 as the model to be probed for a case study .   Let us denote any token in a given NP as x.   We deﬁne A , the average of the weights of all   attention heads from Mtoxin the ﬁnal layer ,   representing how much Mattends to token x. We   then calculate the ratio r = A/(A+A )   ( 0 < r < 1 ) . Ifr < 0.5 , then Mattends more   toM ; else , Mattends more to N. For each pri-   vative modiﬁer , we take all NPs containing it in   theMposition in our dataset and plot the distribu-   tion ofr . Figure 5 shows three examples ( alleged ,   counterfeit , orfraudulent ) representing different   patterns .   As shown in the ﬁrst sub-ﬁgure , alleged attends   more to either MandNdepending on the NP .   For example , it attends more to Minan alleged   antique bowl ( 0.454 ) , since the NP describes a bowlthat may not be antique . Inversely , an alleged male   criminal is on the Nside ( 0.517 ) , since they are   most likely male but may not be a criminal .   The second sub-ﬁgure indicates that counterfeit   mainly attends to M. For instance , a counterfeit   Hollywood movie ( 0.382 ) is still a movie , but is   probably not made in Hollywood . This is similar   to the cases of luxury bag , medical drugs , foreign   cigarettes , etc . On the contrary , fraudulent mainly   attends to N , as shown in the third sub-ﬁgure . The   fraudulent medical claims ( 0.559 ) are not valid   claims but still on medical grounds . The same   holds for electoral victory , medical excuse , etc .   Additionally , we notice that there are some   boundary cases close to the r=0.5division line ,   likeruthless criminal andformer thief in the al-   leged sub-ﬁgure . A plausible explanation is that   Mis questioning both MandNin these cases   ( e.g. , an alleged ruthless criminal is not necessarily   ruthless or a criminal ) . Overall , the above results   indicate that models ﬁnetuned on our tasks can   capture modiﬁer scope in recursive NPs .   8 Is RNPC useful for downstream tasks ?   We ﬁnally address question ( d ): How can such   knowledge beneﬁt downstream tasks ? We choose   the task of Harm Detection ( Banko et al . , 2020 )   for extrinsic evaluation . Concretely , we consider   the scenario where a user interacts with a task-   oriented agent like Siri or Alexa , and the agent   needs to determine whether the involved activity in   the user query is potentially harmful . The deﬁnition   of “ harm ” can be user - dependent . Here , we con-   sider an activity to be harmful if it may cause pain ,   physical injury , or be illegal for minors . We choose   this task because many false positives come from   recursive NPs . For example , how to make a home-   made bomb is obviously harmful while how to   make a homemade bath bomb isharmless .   We collect a small test set from wikiHow , a web-   site of how - to articles . Each article title is con-   sidered a query ( e.g. , how to make a cake ) . Then ,   we compile a list of 74 keywords about harmful   entities ( e.g. , bomb , ﬁre , drugs ) , only 12 of which   occur in RNPC . We then select wikiHow queries   containing at least an NP with one of the 74 key-   words as the head noun , and sample a small subset   for manual annotation . Each query is labeled as   harmful orharmless , depending on whether   it involves a harmful activity as deﬁned above . Af-   ter data cleaning and re - balancing , we obtain 170   queries , with a 1:1 positive / negative ratio.5293   We design two zero - shot harm classiﬁers using   models ﬁnetuned on our entire SPTE and EPC   dataset . They share a few pre - processing steps :   ﬁrst , all NPs are extracted from the input query ;   then , NPs containing a keyword from our list in   the head noun position are retained . For each re-   tained NP ( e.g. , a water gun ) , we check if it is   indeed a harmful entity using either the SPTE or   the EPC model . The input to the SPTE model is a   premise of the form “ This is { NP } ” ( e.g. , This is   a water gun ) and a hypothesis of the form “ This   is ( a / an ) { N } ” ( e.g. , This is a gun ) . If the output   label is entailment , we classify the query as   harmful , otherwise harmless . Likewise , us-   ing the EPC model , we form two events given the   retained NP : “ ( A / An ) { N } is harmful ” and “ { NP }   is harmful ” . If the second event is predicted as   more or equally plausible compared to the ﬁrst , the   query is considered harmful .   We compare our two classiﬁers to a simple base-   line that always predicts harmful as well as to   three GPT3 models . Both classiﬁers meaning-   fully exceed the simple baseline , and the EPC-   based classiﬁer outperforms all the other methods   by 10 + in terms of accuracy and F. This shows   that the understanding of recursive NPs is bene-   ﬁcial for downstream tasks without any training   data . To understand why EPC is more suitable than   SPTE for this task , we further examine the errors   they make . One major error type concerns poly-   semous keywords such as shot . For instance , the   SPTE model mistakenly predicts how to have a   good basketball shot to be harmful because a   good basketball shot is still a shot ( shot can mean   both “ shooting a gun ” and “ shooting a ball ” ) . There   are also some queries out of the scope of the EPC   model , e.g. , how to make a sake bomb . Since sake   bomb is a cocktail , the gold label is harmful as   our target users are minors . The EPC model cor-   rectly predicts that a sake bomb is less harmful   than a bomb , but fails to capture that it may still beharmful ( for minors ) .   9 Conclusion   We introduce RNPC , a challenge set targeting the   understanding of recursive NPs , a fundamental as-   pect of human common sense . Pretrained LMs   with SOTA performance on Natural Language Un-   derstanding benchmarks have poor mastery of this   knowledge , but can still learn it when exposed to   small amounts of data from RNPC . Using different   probing techniques , we show that models can learn   relevant linguistic features , including modiﬁer cat-   egory and scope , from RNPC . They also achieve   strong zero - shot performance on an extrinsic Harm   Detection task , indicating the transferability of this   knowledge . For future work , we hope to investi-   gate other linguistic phenomena as a step towards   comprehensively characterizing LMs ’ limitations   and capabilities in language understanding .   Acknowledgments   This research is based upon work supported in   part by the DARPA KAIROS Program ( contract   FA8750 - 19 - 2 - 1004 ) , the DARPA LwLL Program   ( contract FA8750 - 19 - 2 - 0201 ) , and the IARPA BET-   TER Program ( contract 2019 - 19051600004 ) . Ap-   proved for Public Release , Distribution Unlimited .   The views and conclusions contained herein are   those of the authors and should not be interpreted   as necessarily representing the ofﬁcial policies , ei-   ther expressed or implied , of DARPA , IARPA , or   the U.S. Government .   Special thanks go to our annotators , students   in CIS 421/521 and MCIT 521 at the Univer-   sity of Pennsylvania . We also thank Artemis   Panagopoulou for providing the extrinsic evalu-   ation data . Meanwhile , we appreciate the sup-   port from OpenAI on ﬁnetuning GPT-3 . Finally ,   we thank Haochen Zhang , Pengyuan Lu , Daniel   Deutsch , Daphne Ippolito , Lara Martin , Young-   Min Cho , Yi Zhang , Helen Jin , Siyi Liu , Eleni Milt-   sakaki , Jordan Kodner , Mingming Liu , Peng Zhou ,   Christopher Cieri , James J. Fiumara , Ellie Pavlick ,   Charles Yang , Yejin Choi , Alexander Koller , Chris   Potts , and Mitch Marcus for their valuable feed-   back .   References5294529552965297A Dataset Construction Details   A.1 RNPC Statistics   NPs . RNPC has 1,299 NPs . For an NP in the   form of Det MMN , the two modiﬁers M   andMcan each belong to one of three possi-   ble semantic categories ( intersective , subsective ,   or privative ) , resulting in nine possible combina-   tions . We plot the distribution of NPs with different   combinations in RNPC in Table 6 . Note that the   distribution is not balanced because certain cate-   gories ( e.g. , NPs containing privative modiﬁers )   yield many more minority class examples for our   three tasks ( e.g. , non - entailment in SPTE ) .   Thus , considering the ﬁnal class balance in RNPC   tasks , we include more NPs of certain categories .   Training and test sets for ﬁnetuning . In the   experiment where we ﬁnetune models on RNPC ,   described in Section 6 , we split again the dataset   for each task into a training set and a new test set ,   ensuring no overlap of modiﬁers occurring in the   same position . The training set contains 200 exam-   ples , which are gradually provided to the model .   The test set contains the remaining examples . Ta-   ble 7 shows the number of examples for each task .   A.2 Crowdsourcing Details   In the construction of RNPC , we hire college stu-   dents as crowdworkers for instance creation and   label veriﬁcation . Speciﬁcally , they are undergrad-   uate and graduate students in an Artiﬁcial Intelli-   gence class ( CIS 421/521 and MCIT 521 at the   University of Pennsylvania ) , with good English   proﬁciency . Both tasks are given as optional ex-   tra credit assignments in the class . Participation is   solely voluntary . Before participation , students can   preview the tasks , and are given a clear description   of how the data will be used at the beginning of the   instructions .   During instance creation , we provide detailed   instructions on how to write high - quality examples   for each task , which can be found in the Supple-   mentary Materials . Annotations are collected via   Google Forms . With 100 valid instances ( equiva-   lent to 2.5 - 4.75 hours of work , depending on their   proﬁciency ) , students can earn 1 % in extra credit   of the overall course grade .   During label veriﬁcation , we host our questions   on Amazon Mechanical Turk . We design a HIT   type for each RNPC task , which is also included in   the Supplementary Materials . With 600 correctly   answered questions ( equivalent to 3.5 - 4 hours of   work ) , students can earn 1 % in extra credit of   the overall course grade . We calculate the inter-   annotator agreement using Krippendorff ’s alpha .   The agreement is 0.843 for SPTE , 0.575 for MPTE ,   and 0.933 for EPC .   A.3 Debiasing and Anonymization   The collected data does not contain any informa-   tion that names or uniquely identiﬁes individual   people or offensive content . We ensure this by 1 )   manually reviewing the set of extracted NPs from   corpora , and ﬁltering out any NP that contains any   sensitive / offensive information , 2 ) not requesting   any personal information during human annotation ,   and 3 ) manually reviewing each RNPC example   written by the human participants .   B Existing Benchmarks for Finetuning   We use the following benchmark datasets for ﬁne-   tuning . Each of them has the same format as one   of our RNPC tasks . Table 8 shows the number of   examples in each dataset .   MNLI . The Multi - Genre Natural Language In-   ference corpus ( Williams et al . , 2018 ) is a dataset   of 433k textual entailment examples , labeled as   entailment , contradiction , or neutral . It covers a5298range of genres of spoken and written text . The   language in the dataset is English . The corpus is   released under the OANC ’s license , the Creative   Commons Share - Alike 3.0 Unported License , and   the Creative Commons Attribution 3.0 Unported   Licenses , depending on the portion .   SNLI . The Stanford Natural Language Inference   corpus ( Bowman et al . , 2015 ) is a crowdsourced   dataset of textual entailment examples , labeled as   entailment , contradiction , or neutral . The sentences   are written by humans doing a novel grounded task   based on image captioning . The language in the   dataset is English . The dataset is released under   the Creative Commons Attribution - ShareAlike 4.0   International License .   MPE . Lai et al . ( 2017 ) introduce a Multiple   Premise Entailment Task dataset . This is a novel   textual entailment task that requires inference over   multiple premise sentences . Each example con-   sists of four premise sentences ( captions from a   FLICKR30 K image ) , one hypothesis sentence ( a   simpliﬁed FLICKR30 K caption ) , and one label ( en-   tailment , neutral , or contradiction ) that indicates   the relationship between the set of four premises   and the hypothesis . The language in the dataset is   English . The license of the dataset is unspeciﬁed .   ADEPT . Emami et al . ( 2021 ) introduce a dataset   of the Adjective - Dependent Plausibility Task   ( ADEPT ) . Each example contains a base sentence ,   and a slightly modiﬁed sentence obtained by adding   an adjective to a noun in the base sentence . The   dataset is created to support explorations into how   certain classes of adjectives might inﬂuence the   plausibility of events depicted in natural language   sentences . The textual data come from Wikipedia ,   the Common Crawl , and ConceptNet . The lan-   guage of the dataset is English . ADEPT is released   under the CC BY - SA 3.0 license . It is intended to   be used only for research , exploratory evaluation ,   and auditing , which our use is consistent with .   C Probing Pretrained LMs   C.1 Motivation   When addressing question ( a ) , we ﬁnetune pre-   trained LMs on existing benchmarks of the same   format as each RNPC task , assuming that the ﬁne-   tuning process allows models to do textual infer-   ence in the required format . However , it is possible   that this assumption does not hold , because LMs   can overﬁt the ﬁnetuning data beyond just learning   the format . Then even if the target knowledge ispresent in pretrained LMs , catastrophic forgetting   ( Kemker et al . , 2018 ) can happen during ﬁnetuning .   C.2 Task Conversion   We complement Section 5 with another experiment ,   where we directly probe pretrained LMs using a   prompting method inspired by the line of work   on LMs as knowledge bases ( Petroni et al . , 2019 ) .   Speciﬁcally , we convert each RNPC task to a like-   lihood comparison task :   SPTE . Given the original formulation which has   a premise and a hypothesis , we deﬁne L as the   conditional likelihood that the hypothesis is nec-   essarily true given the premise , assigned by an LM .   Contrarily , L stands for the conditional   likelihood that the hypothesis is NOT necessarily   true given the premise . IfL > L ,   the model is considered to predict entailment ,   and vice versa .   MPTE . The conversion method is the same as   that for SPTE , except that in the conditional likeli-   hood computation , we now consider the concatena-   tion of two premises as the given condition .   EPC . Given the original formulation with two   events , Event 1 and Event 2 , we deﬁne Land   Las the ( unconditional ) likelihood of Event 1   and Event 2 assigned by an LM , respectively . We   then choose a threshold θ , and compare it to the   absolute difference between LandL. If the dif-   ference is smaller than θ , we consider the model   prediction as equally likely . Otherwise , the   model prediction is more likely ifLis higher ,   andless likely ifLis higher .   For Causal LMs ( e.g. , GPT ) , the likelihood   is computed with standard left - to - right language   modeling scores . For Masked LMs ( e.g. , BERT ,   RoBERTa , BART ) , the likelihood is computed with   pseudo - log - likelihood scores ( Salazar et al . , 2020 ) .   C.3 Sanity Check   Before evaluating LMs on the converted RNPC , we   perform a sanity check to see if our formalization   makes sense to LMs , i.e. , whether they understand   the meaning of necessarily andnot necessarily .5299   We write 50 sentence pairs for likelihood com-   parison , all consisting of simple commonsense   knowledge . For example , comparing A human be-   ing is necessarily female andA human being is n’t   necessarily female , the second sentence should be   more likely ; while for Humans are necessarily mor-   talandHumans are n’t necessarily mortal , the ﬁrst   sentence should be more likely . Such comparisons   do not require any knowledge about recursive NPs ,   and involve only common entities and facts . If   models understand necessarily andnot necessarily   correctly , they should ﬁnd the task easy .   To our surprise , almost all Masked LMs we test   ( BERT - base / large , RoBERTa - base / large ) fail the   sanity check , mostly performing around chance   ( 50 accuracy ) . However , most Causal LMs ( GPT-2-   base / medium / large / xl , GPT-3 - ada ) reasonably per-   form above chance , with accuracy scores rang-   ing from 70 to 80 . We suspect that pseudo - log-   likelihood scores are not entirely suitable for our   purposes ; also , the task is harder than expected due   to reporting bias , as the tested knowledge ( e.g. , not   all humans are female ) is potentially too obvious   to be explicitly stated in the pretraining data .   C.4 Results   We evaluate LMs that pass the sanity check on the   converted RNPC , and report their performance in   Table 9 . Despite the decent performance on the   sanity check examples ( 70 - 80 ) , the accuracy on   RNPC is remarkably lower . Compared to our orig-   inal results of probing the ﬁnetuned models , the   optimal performance on SPTE and MPTE slightly   improves , while accuracy on EPC decreases . How-   ever , the same patterns hold : most models perform   around or slightly above chance , with a large dif-   ference from human performance . These ﬁndings   further strengthen our answer to question ( a ) , i.e.   LMs do not inherently have the knowledge to inter-   pret recursive NPs .   D Full Results   In Section 5 , we evaluate SOTA LMs on RNPC   tasks . In addition to accuracy , we also report preci-   sion , recall , and F-1 score here . Tables 10 , 11 and   12 show the full results for each task , respectively .   E Implementation Details   E.1 Models Finetuned on Existing   Benchmarks   In Section 5 , we evaluate SOTA LMs ﬁnetuned on   existing benchmarks of the same format on RNPC .   We use four different pretrained models , BERT   ( Devlin et al . , 2019 ) , RoBERTa ( Liu et al . , 2019b ) ,   BART ( Lewis et al . , 2020 ) , and GPT3 ( Brown et al . ,   2020 ) , in different sizes . The ﬁrst three are imple-   mented with HuggingFace Transformers , and the   last is from OpenAI ’s standard API .   The pretrained model checkpoints we use   include : bert - base - uncased ( 110 M pa-   rameters ) , bert - large - uncased ( 336 M   parameters ) , roberta - base ( 125 M param-5300eters ) , roberta - large ( 335 M parameters ) ,   facebook / bart - large ( 406 M parame-   ters ) , GPT3 - ada ( 350 M parameters ) , and   GPT3 - curie ( 6.7B parameters).Their   licenses include Apache License 2.0 ( BERT   and BART ) , GNU General Public License v2.0   ( RoBERTa ) , and MIT license ( GPT3 ) .   Due to the size of MNLI and SNLI , we use   existing checkpoints available on the Hugging-   face Transformers model hub . For all other   datasets , we ﬁnetune the pretrained models using   theSequenceClassification pipeline on   Huggingface , or the standard prompt completion   ﬁnetuning API on OpenAI.The ﬁnetuning scripts   are adapted from the text - classification   example in the HuggingFace Transformers reposi-   tory . We performed hyperparameter search in the   following range :   - batch size : [ 4 , 8 , 16 , 32 ]   - learning rate : [ 1e-5 , 1e-6 ]   - number of epochs : [ 2 , 3 , 5 ]   - max sequence length : [ 64 , 128 ]   The optimal hyperparameter values and ﬁne-   tuned models are available on the HuggingFace   model hub .   We run our ﬁnetuning experiments on an   NVIDIA GeForce RTX 2080 Ti GPU , with half-   precision ﬂoating point format ( FP16 ) . The ﬁne-   tuning takes 2 to 5 hours depending on the task .   E.2 Models Finetuned on RNPC   In Section 6 , we address the question of whether   LMs can learn the meaning of recursive NPs . We   ﬁnetune each model from Section E.1 on an increas-   ing number of examples of each RNPC task . The   model architectures , the pipelines used , the range   of hyperparameter search , and the computing re-   sources used are all the same as in the previous   subsection . After being ﬁnetuned on 200 exam-   ples , the best performing models are RoBERTa-   large ( MNLI ) for SPTE , RoBERTa - base ( MPE ) for   MPTE , and RoBERTA - large ( ADEPT ) for EPC .   The optimal hyperparameter values and ﬁnetuned   models on the full 200 examples of each RNPC   task are available on the HuggingFace model hub .   E.3 The “ Edge Probing ” Method   In Section 7 , we adopt the Edge Probing technique   from Tenney et al . ( 2019 ) to investigate if the modi-   ﬁer category feature can be learned from our tasks .   To reintroduce the general idea of this method ,   consider the following setup : we have data   D = { ( x , y),(x , y), ... ,(x , y ) } , where   ( x , x, ... ,x)are the model representations to   be probed and ( y , y, ... ,y)are the labels of   a linguistic feature we are interested in probing   for . The goal is to see if ( x , x, ... ,x)encodes   ( y , y, ... ,y ) .   In our case , given an NP of the form   Det MMN,(x , x, ... ,x)are the token rep-   resentations of the best - performing models after   being ﬁnetuned on each RNPC task , as mentioned   in Section E.2 , and ( y , y, ... ,y)are the semantic   categories of MandM.   We freeze the representations ( x , x, ... ,x ) ,   and attach a simple auxiliary classiﬁer ( or probing   classiﬁer ) on top of them . The auxiliary classi-   ﬁer is trained to predict the semantic category y   corresponding to every modiﬁer token representa-   tionx . In our case , we choose a linear classiﬁer   as the probing classiﬁer . The assumption is that   the expressivity of the auxiliary classiﬁer should   be limited , or otherwise it might learn the target   feature itself . Based on this assumption , the accu-   racy of predicting yindicates the extent to which   the model representations encode the target feature .   The method is illustrated in Figure 6 .   Speciﬁcally , the linear classiﬁer is an   SGDClassifier implemented with scikit-   learn . We perform hyperparameter search in the   following range:5301- loss : [ hinge , log , modiﬁed_huber ,   squared_hinge , perceptron ]   - warm_start : [ True , False ]   - penalty : [ l2 , l1 , elasticnet ]   - alpha : [ 0.0001 , 0.001 , 0.01 , 0.1 ]   - n_jobs : [ -1 ]   - max_iter : [ 500 , 1000 , 2000 ]   - random_state : [ 0 ]   - eta0 : [ 0.1 , 0.01 , 0.001 , 0.0001 ]   - learning_rate : [ optimal , invscaling , adaptive ]   The optimal hyperparameter values for the best-   performing models of each RNPC task from Sec-   tion E.2 are available on the HuggingFace model   hub .   E.4 Models Used for Extrinsic Evaluation   In Section 8 , one of the models we compare   to is GPT3 . We exploit three versions of dif-   ferent sizes , GPT3 - ada , GPT3 - curie , and   GPT3 - davinci , using the same API described   in Section E.1 . The models are evaluated in a zero-   shot setting , where we only provide the following   task description :   Given a “ how - to ” query , determine if the   task is harmful to a teenager . The answer   should be Yes or No .   Each input question is then formatted as :   Question : Is “ { how - to query } ” harmful ?   Answer :   For every how - to query in our test set , we use the   concatenation of the task description and the in-   stantiated input question as the prompt , and let the   model generate a one - token continuation . The top   generated token is always YesorNo , implying that   GPT3 has a good understanding of the task format .   F Ethical Considerations   F.1 Limitations   Assumptions . One assumption we make in an-   swering question ( a ) is that LMs ﬁnetuned on ex-   isting benchmarks can learn the required format   without overﬁtting the speciﬁc domains of the ﬁne-   tuning data . Suppose this assumption does not hold ,   then even if the target knowledge is present in pre-   trained LMs , they can “ forget ” it during ﬁnetuning .   Therefore , the ﬁnetuning process does not allow us   to elicit the target knowledge from pretrained LMs .   To address this issue , we complement the behav-   ioral test probing method with another experimentto directly probe the pretrained LMs via likelihood   scoring . See Section C for details .   Another assumption occurs in our answer to   question ( d ) . We assume that a query is harmful   if it contains a harmful entity . However , in prac-   tice , there can be queries like How to prevent a   ﬁre , which does contain a harmful entity ( ﬁre ) but   is precautionary instead of harmful . Our model   does not take into account factors like predicates in   context , and will therefore identify all such cases   as false positives .   Scope of claims . Our ﬁrst three claims ( i.e. an-   swers to question ( a)-(c ) ) are only veriﬁed to hold   on the RNPC dataset , which 1 ) is in English and 2 )   mainly consists of NPs in the news domain . Our   last claim ( i.e. answer to question ( d ) ) is only veri-   ﬁed to hold on the harm detection dataset we col-   lect , which 1 ) is also in English , 2 ) consists of how-   to queries in the domain of human activities , and   3 ) is annotated based on a non - exhaustive keyword   list of harmful entities .   Moreover , part of our answer to question ( b ) ( i.e.   LMs have learned the feature of modiﬁer semantic   category from RNPC ) is qualitative . The absolute   increase in the probing accuracy after ﬁnetuning is   limited , so it is likely not the entire picture . Quanti-   fying to what extent LMs have learned this feature   is an interesting direction for future work .   F.2 Risks   The risks associated with the study are minimal .   Harm detection models . Our harm detection   models are intended for research purposes only .   They are designed for speciﬁc types of harmful   queries , i.e. those with harmful entities . One   should not deploy them directly in real life since   they are by no means applicable under all scenar-   ios .   Data collection . Our human participants may   experience slight discomfort due to boredom dur-   ing data collection . To minimize this , we make   sure that it is entirely voluntary to participate and   discontinue at any time .   F.3 Intended Use   Our models and data should be used for research   purposes only . They should not be deployed in   the real world as anything other than a research   prototype , especially commercially.5302