  Xin TianYingzhan LinMengfei SongSiqi Bao   Fan Wang Huang He Shuqi Sun Hua Wu   Baidu Inc. , China   { tianxin06 , linyingzhan01 , songmengfei01}@baidu.com   Abstract   Existing pipelined task - oriented dialogue sys-   tems usually have difficulties adapting to un-   seen domains , whereas end - to - end systems are   plagued by large - scale knowledge bases in prac-   tice . In this paper , we introduce a novel query-   driven task - oriented dialogue system , namely   Q - TOD . The essential information from the di-   alogue context is extracted into a query , which   is further employed to retrieve relevant knowl-   edge records for response generation . Firstly ,   as the query is in the form of natural language   and not confined to the schema of the knowl-   edge base , the issue of domain adaption is alle-   viated remarkably in Q - TOD . Secondly , as the   query enables the decoupling of knowledge re-   trieval from the generation , Q - TOD gets rid of   the issue of knowledge base scalability . To eval-   uate the effectiveness of the proposed Q - TOD ,   we collect query annotations for three publicly   available task - oriented dialogue datasets . Com-   prehensive experiments verify that Q - TOD out-   performs strong baselines and establishes a new   state - of - the - art performance on these datasets .   1 Introduction   Task - oriented dialogue systems are designed to   help users achieve their goals , such as restaurant   reservation , calendar scheduling , and movie rec-   ommendation . Typically , these systems need to   rely on external knowledge bases to retrieve nec-   essary information for response generation ( Eric   et al . , 2017 ; Wen et al . , 2017 ; Eric et al . , 2020 ) .   Some end - to - end trainable approaches try to en-   code the knowledge base into a memory module   and attend relevant knowledge records for response   generation ( Wu et al . , 2019 ; Qin et al . , 2020 ; Raghu   et al . , 2021 ) . Since these end - to - end approaches   need to continually refresh the memory module ,   a large - scale knowledge base will lead to a heavy   computation burden and difficult joint optimiza-   tion . Recently , some works leverage the power ofpre - trained language models and take the entire   linearized knowledge base as the input to assist   response generation ( Gou et al . , 2021 ; Xie et al . ,   2022 ) . However , the input sequence could easily   become too long to feed into the transformer net-   work . Considering there are thousands or millions   of records in industrial knowledge bases , the knowl-   edge base scalability becomes a critical challenge   for these end - to - end approaches .   In these circumstances , the practical deployed   systems tend to employ pipelined designs and strip   out the component of knowledge retrieval ( Wen   et al . , 2017 ; Hosseini - Asl et al . , 2020 ; Su et al . ,   2022 ) . These pipelined systems usually consist   of natural language understanding , dialogue state   tracking , dialogue policy learning , and system re-   sponse generation . In order to retrieve relevant in-   formation from the external knowledge base , these   approaches need to pre - define the schema of dia-   logue states according to the knowledge base . Due   to this kind of strong association , these pipelined   systems have difficulties adapting to unseen do-   mains , i.e. , weak ability on domain adaptation .   To tackle these issues , in this paper , we introduce   a novel Query - driven Task - oriented Dialogue ( Q-   TOD ) system . The overview of Q - TOD is shown   in Figure 1 , where three sequential modules are   included : 1 ) the query generator extracts the es-   sential information from the dialogue context into   a concise query in an unstructured format of the   natural language ; 2 ) the generated query is then uti-   lized to retrieve relevant knowledge records with an   off - the - shelf knowledge retriever ; 3 ) the response   generator produces a system response based on   the retrieved knowledge records and the dialogue   context .   The advantages brought by the query - driven task-   oriented dialogue system are two - fold . Firstly , the   query is in the unstructured format of natural lan-   guage , which is not confined to the knowledge base   and is able to mitigate the issue of domain adapta-7260   tion . Secondly , with the incorporation of the query ,   Q - TOD decouples the knowledge retrieval from   the response generation , getting rid of the issue of   theknowledge base scalability . To explore the ef-   fectiveness of the query - driven systems , we collect   query annotations for three public task - oriented   dialogue datasets : SMD ( Eric et al . , 2017 ) , Cam-   Rest ( Wen et al . , 2017 ) , and MultiWOZ-2.1 ( Eric   et al . , 2020 ) . Experimental results demonstrate   that Q - TOD achieves superior performance as com-   pared to other state - of - the - art approaches . Particu-   larly , in the few - shot settings , Q - TOD achieves a   comparable performance with the previous state-   of - the - art using only 5 % of the training data . Our   collected data , code , and models have been released   at GitHub , hoping to facilitate further research in   task - oriented dialogue systems .   2 Methodology   The goal of this paper is to explore a novel and   effective framework for task - oriented dialogue sys-   tems . As shown in Figure 1 , the proposed Q - TOD   consists of three subsequent modules : query gener-   ator , knowledge retriever , and response generator .   The detailed design of these three modules will be   discussed in the following .   2.1 Query Generator   Thequery generator aims to extract essential in-   formation from the dialogue context into a natural   language query . For a multi - turn conversation , thedialogue context at the t - th turn can be represented   asC={U , R , . . . , U } , where each turn con-   sists of user utterance Uand system response R.   With the dialogue context as input , the query at   thet - th turn is generated with a Transformer - based   language model :   Q = Transformer ( C ) ( 1 )   In the query generation , the noisy or out - of - date   information from the context is supposed to be   removed , whereas the essential and up - to - date re-   quirements raised by the user should be highlighted .   As shown in the example of Figure 1 , the query   only contains the minimal user requirements in the   current turn ( i.e. , find an east entertainment attrac-   tion ) and discards the outdated attraction type of   concert hall . In cases where no query is required ,   e.g. greetings or thanks , a special token [ NOTHING ]   is used to represent the null query at this turn .   Recently , in some knowledge - intensive con-   versations , there is a trend to employ the query   to enhance the performance of relevant knowl-   edge retrieval . In conversational question an-   swering , to deal with ellipsis and coreference , a   question rewriting task is introduced to convert a   context - dependent question into a self - contained   query ( Vakulenko et al . , 2021 ; Anantha et al . , 2021 ) .   In open - domain knowledge - grounded dialogue , to   incorporate real - time external information , some   works learn to generate a search query and leverage   search engines for response generation ( Komeili   et al . , 2022 ; Shuster et al . , 2022 ) . To the best of   our knowledge , Q - TOD is the first work that tries   to encode the natural language query into a task-7261oriented dialogue system . Distinct from the above   approaches , the query in Q - TOD is designed to ex-   tract the essential and up - to - date user requirements .   2.2 Knowledge Retriever   The knowledge retriever utilizes the generated   query to retrieve relevant knowledge records from   the external knowledge base :   K = Retriever ( Q;K ) ( 2 )   where Krefers to the entire knowledge base , and   K={k , k , . . . , k}are retrieved top- nrelevant   knowledge records . As displayed in Figure 1 , the   module of knowledge retriever is a black box in   this system . In fact , any off - the - shelf knowledge   retriever can be employed in Q - TOD , including   BM-25 or dense retrieval models . Such strong   adaptability and flexibility mainly benefit from the   preceding query generation . Firstly , the query is in   the format of natural language , which is a univer-   sal representation and adaptable to commonly used   retrievers . Secondly , although multi - turn dialogue   context typically requires elaborately designed or   tuned retrievers ( Shuster et al . , 2021 ) , by extract-   ing essential information into a concise query , the   off - the - shelf retriever can achieve relatively good   performance as well .   In fact , the module of knowledge retriever is the   key to the knowledge base scalability of Q - TOD .   Given a large - scale knowledge base , the retriever   filters out massive irrelevant knowledge records   and picks out top- nrelevant ones . In this way , the   subsequent response generation is not affected by   the size of the knowledge base and is able to pay   more attention to knowledge utilization . As sug-   gested by recent works ( Adolphs et al . , 2021 ; Shus-   ter et al . , 2022 ) and verified in our experiments , the   decoupling of knowledge retrieval and response   generation alleviates the modeling difficulty and   boosts the final performance .   2.3 Response Generator   The response generator produces the system re-   sponse given the retrieved top- nknowledge records   and dialogue context :   R = Transformer ( K;C ) ( 3 )   With the assistance of the preceding modules , the   response generator can focus more on precise   knowledge utilization and produce high - quality   replies towards the dialogue context .   In Q - TOD , we train the query generator and   response generator jointly with a shared trans-   former . To distinguish these tasks in a single model ,   two task - specific discrete prompts ZandZare   adopted and concatenated with the rest input . For   query generation , the prompt Zis “ translate   dialogue context to query : ” . For response   generation , the prompt Zis “ generate system   response based on knowledge and dialogue   context : ” . Overall , the training objective is to   minimize the following negative log - likelihood   loss :   L=−logP(Q|Z;C )   −logP(R|Z;K;C ) ( 4 )   The knowledge retrieval is a black box in this sys-   tem and thus not involved in the optimization .   3 Experiments   3.1 Datasets   To investigate the effectiveness of the proposed   query - driven dialogue system , we collect query   annotations for three publicly available multi - turn   task - oriented dialogue datasets : Stanford Multi-   Domain ( SMD ) ( Eric et al . , 2017 ) , CamRest ( Wen   et al . , 2017 ) , and MultiWOZ-2.1 ( MWOZ)(Eric   et al . , 2020 ) . The query annotations are collected   through three stages . The authors first provide ten   examples of dialogue sessions with query annota-   tions for each dataset . Then , the crowd workers   complete all query annotations on these dialogues   after reading the examples . Finally , to ensure the   quality of annotations , multiple data specialists will   review it . We will release the collected data for fur-   ther research.7262ModelSMD CamRest MWOZ   Entity F1 BLEU Entity F1 BLEU Entity F1 BLEU   DSR 51.9012.7053.6018.3030.009.10   KB - Retriever 53.70 13.90 58.60 18.50 - -   GLMP 60.7013.9058.9015.1032.406.90   DF - Net 62.70 14.40 - - 35.10 9.40   GPT-2+KE 59.78 17.35 54.85 18.00 39.58 15.05   CDNET 62.90 17.80 68.60 21.80 38.70 11.90   COMET 63.60 17.30 - - - -   UnifiedSKG ( T5 - Large ) 65.85 17.27 71.0320.3146.0413.69   UnifiedSKG ( T5 - 3B ) 67.88 15.45 72.7818.4649.6513.01   Q - TOD ( T5 - Large ) 71.11 21.33 74.22 23.75 50.61 17.62   Q - TOD ( T5 - 3B ) 73.44 21.76 76.81 24.65 53.28 18.27   In our experiments , we utilize the provided   training / validation / test partitions of all benchmark   datasets . Table 1 summarizes the statistics of the   above three datasets .   3.2 Experimental Settings   Our experiments are carried out with T5 ( Raffel   et al . , 2020 ) , in which two model sizes are used :   T5 - Large and T5 - 3B. For knowledge retriever , we   leverage an off - the - shelf retrieval model Rock-   etQA ( Ren et al . , 2021 ) . Particularly , we fine - tune   T5 with AdamW optimizer ( Loshchilov and Hutter ,   2019 ) and Noam learning rate scheduler ( Vaswani   et al . , 2017 ) . During inference , the decoding strat-   egy of beam search is employed , with a beam size   of 4 . And the number of retrieved knowledge   records top- nis set to 3 . All the models are trained   on 8 NVIDIA Tesla A100 GPU cards for 50 epochs   and early stopped according to the performance on   the validation set . More details about hyper param-   eter settings are provided in Appendix A.   3.3 Baselines   We compare Q - TOD with the following strong   baselines :   DSR ( Wen et al . , 2018 ) models dialogue state as   distributed representation to query the knowledge   base with an attention mechanism .   KB - Retriever ( Qin et al . , 2019 ) proposes an entity-   consistency augmented decoder to focus on a single   row of the knowledge base by memory network and   attention mechanism .   GLMP ( Wu et al . , 2019 ) leverages a global - to-   local pointer network to first generate a sketch re - sponse and then fill slots with entities from the   knowledge base .   DF - Net ( Qin et al . , 2020 ) applies the Mixture - of-   Experts mechanism ( MoE ) to dynamically exploit   the relevance between the target domain and all   source domains .   GPT-2+KE ( Madotto et al . , 2020 ) proposes to pack   the knowledge base into the model parameters im-   plicitly through dialogue data augmentation .   CDNET ( Raghu et al . , 2021 ) computes a distilla-   tion distribution over the knowledge records , which   is used to get the final copy distribution for entity   choosing .   COMET ( Gou et al . , 2021 ) introduces a Memory-   Masked Encoder to enforce entities interact within   the same knowledge record , aiming to avoid the   distraction from the irrelevant ones .   UnifiedSKG ( Xie et al . , 2022 ) recasts 21 structured   knowledge grounding tasks into a unified text - to-   text language model ( including task - oriented dia-   logue modeling ) and achieves state - of - the - art per-   formance on these tasks .   3.4 Results   Following the prior works ( Eric et al . , 2017 ; Wu   et al . , 2019 ; Qin et al . , 2020 ; Madotto et al . , 2020 ;   Raghu et al . , 2021 ; Gou et al . , 2021 ; Xie et al . ,   2022 ) , we evaluate the model performance with   metrics of micro Entity - F1 ( Eric et al . , 2017 ) and7263   BLEU ( Papineni et al . , 2002 ) . The Entity - F1 mea-   sures the model ’s abilities to generate relevant enti-   ties from the external knowledge base according to   the dialogue context . BLEU measures the n - gram   overlap between generated response and the oracle   response .   Table 2 summarizes the results of Q - TOD and   all baselines on three datasets . It can be observed   that our Q - TOD consistently outperforms all pre-   vious models , achieving a new state - of - the - art re-   sult . Specifically , on the Entity - F1 metric , Q - TOD   achieves the absolute improvement of 5.56 % on   SMD , 4.03 % on CamRest , and 3.36 % on MWOZ ,   respectively . On the BLEU metric , Q - TOD also ob-   tains the highest score with the increment of 3.96 % ,   2.85 % , and 3.22 % on SMD , CamRest , and MWOZ ,   respectively . These results demonstrate that the   proposed Q - TOD can generate high - quality sys-   tem responses with the relevant knowledge records .   It is worth noting that , UnifiedSKG ( Xie et al . ,   2022 ) employs a Transformer - based response gen-   erator similar to ours , but our model surpasses it on   all three datasets under both T5 - Large and T5 - 3B   sizes . This confirms the benefits of our proposed   query - driven retrieval , which helps the response   generator avoid distractions from irrelevant knowl-   edge records and focus on the utilization of relevant   ones .   4 Discussion   For further analysis of Q - TOD , we will have dis-   cussions on the following aspects : knowledge base   scalability , effect of query , performance of precise   knowledge , domain adaptation , and case study . Inthis section , unless specified , experiments are car-   ried out with T5 - Large .   4.1 Knowledge Base Scalability   In practice , the knowledge base of a specific do-   main usually contains thousands of records , such   as weather forecasts and music recommendations .   Hence , it is necessary to explore the knowledge   base scalability in task - oriented dialogue systems .   To this end , we simulate large knowledge bases by   expanding the existing ones . Specifically , we ex-   pand the original session - level knowledge bases   on the SMD dataset by injecting dataset - level   knowledge records and some crawled knowledge   records .   As shown in Figure 2 , we compare Q - TOD with   two strong baselines , CDNET ( Raghu et al . , 2021 )   and UnifiedSKG ( Xie et al . , 2022 ) . The results   show that when increasing the knowledge base size   from 2to2 , Q - TOD is able to maintain a sta-   ble performance on Entity F1 . In particular , when   the size of the knowledge base is expanded to 2   ( 128 times compared with the original SMD ) , Q-   TOD obtains 67.96 % Entity F1 , only a decrease of   3.15 % . The superior performance is owing to the   fact that Q - TOD extracts the essential information   from the dialogue context into the query . The short   query enables the knowledge retrieval to be decou-   pled from the response generation , getting rid of the   issue of the knowledge base scalability . In contrast ,   the performance of CDNET and UnifiedSKG de-   creases gradually as the size of the knowledge base   increases . This indicates that joint modeling can   barely adapt to large - scale knowledge bases , which   might result from the difficulty of a single model in   handling implicit knowledge retrieval and response   generation simultaneously . Moreover , due to the   limitation of the max input length in UnifiedSKG ,   the Entity F1 decreases sharply when the size of   the knowledge base is greater than 2 .   4.2 Effect of Query   To investigate the effectiveness of query incorpo-   ration , we would like to answer the following two   research questions ( RQ ) .   RQ1 : what would happen to Q - TOD without query   annotations?7264   Under our framework , to deal with the situation   without any query annotation , a straightforward   solution is to degrade the query generator to identi-   cal mapping . In other words , the dialogue context   itself can be regarded as a naive query to retrieve   knowledge records for response generation . This   setting with identical mapping is denoted as Q-   TOD . Experiments with Q - TOD are carried out   on SMD and results are summarized in Table 3 .   Q - TOD obtains 69.57 % Entity F1 , outperforming   the previous state - of - the - art UnifiedSKG ( 65.85 %   Entity F1 ) . This indicates that our framework can   also achieve state - of - the - art even without query an-   notations .   RQ2 : why not content with Q - TOD ?   In practical deployments , the conversations are   more complex and noisy as compared to those in   public datasets . For instance , one user might ask   for navigation after a restaurant reservation , also   known as a cross - domain conversation . Since the   context contains distractions of the noisy or out-   dated information , Q - TOD encounters difficul-   ties in retrieving relevant knowledge records . For   better comparison between Q - TOD and Q - TOD ,   we further construct two cross - domain dialogue   datasets by merging dialogue sessions from SMD ,   CamRest , and MWOZ . Detailed construction pro-   cess is described in Appendix D. As shown in Fig-   ure 3 , the gap between Q - TOD and Q - TOD be-   comes larger on cross - domain datasets , especially   more than 20 % Entity - F1 on SMD+CamRest+MWOZ .   The limited performance of knowledge retrieval of   Q - TOD results in low - quality system responses   in cross - domain scenarios . These results suggest   that the query generator is a crucial module in our   framework , which ensures that the noisy or out-   of - date information is filtered out and will not be   transmitted to the knowledge retriever .   4.3 Performance of Precise Knowledge   Although the off - the - shelf knowledge retriever is   utilized in Q - TOD , a domain - specific knowledge   retriever can be employed to obtain precise knowl-   edge when the knowledge annotation is available .   To investigate the effect of precise knowledge , we   collect turn - level knowledge annotations to fine-   tune a new knowledge retriever on the SMD dataset .   Here , the knowledge retriever is initialized with   T5 ( Raffel et al . , 2020 ) , where the model takes   the query and each linearized knowledge record   as input and outputs a relevance label : MATCHED or   MISMATCHED .   The results are summarized in Table 4 . It can   be observed that the system with fine - tuned knowl-   edge retriever achieves better Entity - F1 than the   off - the - shelf retriever . To give an idea of the per-   formance limits of knowledge retrieval , we also   evaluate it with oracle knowledge records . The per-   formance with oracle knowledge shows that there   is some headroom for Q - TOD when improving   the knowledge precision . Moreover , we note that   compared with T5 - Large , T5 - 3B achieves more   improvements using more precise knowledge , es-   pecially the improvement of Entity F1 becomes   2.76 % with oracle knowledge . From the insights of   previous works ( Thoppilan et al . , 2022 ) , this might   thank to a greater ability of knowledge utilization   in a larger model.7265   4.4 Domain Adaption   A primary advantage of our framework is its strong   ability on domain adaptation . To this end , we com-   pare Q - TOD with two strong baselines in zero / few-   shot settings , PPTOD ( Su et al . , 2022 ) and Uni-   fiedSKG ( Xie et al . , 2022 ) . PPTOD achieves the   state - of - the - art performance in pipelined dialogue   systems , which relies on the predefined schema to   train a plug - and - play model . UnifiedSKG is the   previous state - of - the - art model in end - to - end dia-   logue systems , which takes the entire knowledge   base as input for response generation .   4.4.1 Zero - Shot Setting   To investigate the performance of Q - TOD in zero-   shot settings , we train the model on SMD and   CamRest , and then evaluate the performance on   the MWOZ test set . As seen in Table 5 , Q - TOD   significantly surpasses the two baselines on both   Entity F1 and BLEU metrics . For PPTOD , since   the method depends on the predefined schema , the   performance is poor on unseen domains . With-   out any training data , Q - TOD exceeds the baseline   DSR ( Wen et al . , 2018 ) in the full - training setting   ( 31.52 % vs. 30.00 % on Entity F1 ) . These results   verify the strong ability on domain adaptation of   the proposed framework.4.4.2 Few - Shot Setting   To further explore the performance of Q - TOD with   a small number of training samples , we evaluate   it and baselines in few - shot settings . Specifically ,   the following three steps are carried out : training   on SMD and CamRest , training on partial MWOZ   training set , and evaluating on MWOZ test set . As   shown in Table 5 , our framework consistently out-   performs all baseline models . This demonstrates   that Q - TOD is capable of transferring knowledge   from other domains and achieves better perfor-   mance in low - resource scenarios . Notably , with   only 5 % of the training data , Q - TOD achieves a   comparable performance with the previous state-   of - the - art model UnifiedSKG ( Xie et al . , 2022 )   ( 45.99 % vs. 46.06 % on Entity F1 ) .   4.5 Case Study   For case study , we select and present two exam-   ples of Q - TOD , including the retrieved knowledge   records and generated system responses .   A cherry - picked case generated by Q - TOD is   shown in Table 6 . It can be observed that the gen-   erated query successfully extracts the essential and   up - to - date user requirements . With this query , the   off - the - shelf retriever outputs relevant and precise   knowledge records . Then the response generator   produces a high - quality system response based on7266   the retrieved knowledge records and the dialogue   context .   Table 7 describes a lemon case of Q - TOD . De-   spite that the retrieved knowledge records are cor-   rect , the response generator produces a factually   incorrect system response . The system provides   an option to the user , which does n’t exist in fact .   This suggests that Q - TOD also suffers from the   well - known problem of knowledge hallucination ,   where it generates plausible looking responses that   are factually incorrect .   5 Related Work   In task - oriented dialogue systems , there is a trend   to develop end - to - end trainable approaches to in-   corporate the external knowledge base for response   generation ( Wen et al . , 2018 ; Qin et al . , 2019 ; Wu   et al . , 2019 ; Qin et al . , 2020 ; Madotto et al . , 2020 ;   Raghu et al . , 2021 ; Gou et al . , 2021 ; Xie et al . ,   2022 ) . Some works encode the entire knowledge   base into a memory module and learn to attend   to the relevant knowledge entities for response   generation ( Wen et al . , 2018 ; Qin et al . , 2019 ;   Wu et al . , 2019 ; Qin et al . , 2020 ; Raghu et al . ,   2021 ) . Recently , with the advances in the pre-   trained language models , some works take the en-   tire linearized knowledge base as the transformer   input and generate the final system response di-   rectly ( Gou et al . , 2021 ; Xie et al . , 2022 ) . Addi-   tionally , Madotto et al . ( 2020 ) proposes to store the   knowledge base in the language model parameters   implicitly through dialogue augmentation . How-   ever , considering the knowledge base usually con-   tains thousands of records in practice , these end-   to - end trainable approaches face the critical chal-   lenges of knowledge base scalability .   Meanwhile , there are many pipelined task-   oriented dialogue systems , which strip out the com-   ponent of knowledge retrieval ( Young et al . , 2013 ;   Wen et al . , 2017 ; Hosseini - Asl et al . , 2020 ; Linet al . , 2020 ; Yang et al . , 2021 ; Sun et al . , 2022 ; Su   et al . , 2022 ; He et al . , 2022 ) . They usually decom-   pose a task - oriented dialogue system into several   pipelined modules : natural language understand-   ing , dialogue state tracking , dialogue policy learn-   ing , and system response generation ( Young et al . ,   2013 ; Wen et al . , 2017 ) . Some recent works formu-   late all pipelined modules as a cascaded generation   task using pre - trained language model ( Hosseini-   Asl et al . , 2020 ; Lin et al . , 2020 ; Yang et al . , 2021 ;   Peng et al . , 2021 ; Lee , 2021 ; Sun et al . , 2022 ) .   To further boost the performance , some models   attempt to introduce the pre - training strategy into   task - oriented dialogue systems ( Liu et al . , 2021 ;   Su et al . , 2022 ; He et al . , 2022 ) . However , these   pipelined systems rely on the predefined schema   to retrieve knowledge from an external knowledge   base , leading to difficulties in adapting to unseen   domains .   In other research fields , there are also some   works using a query to store essential informa-   tion or retrieve relevant knowledge . In knowledge-   grounded open - domain dialogue , to incorporate   real - time external information , recent works learn   to generate a search query based on the dialogue   context for internet searching ( Komeili et al . , 2022 ;   Adolphs et al . , 2021 ; Shuster et al . , 2022 ) . In open-   domain conversational question answering , to han-   dle the reference problem and optimize retrieval   performance , recent systems introduce a question   rewriting task to convert a context - dependent ques-   tion into a self - contained question ( Vakulenko   et al . , 2021 ; Anantha et al . , 2021 ; Wu et al . ,   2021 ) . In context - dependent text - to - SQL task ,   some works learn to reformulate multi - turn conver-   sational questions into a self - contained question ,   and then a context - independent text - to - SQL parser   follows ( Chen et al . , 2021 ; Xiao et al . , 2022 ) . To   the best of our knowledge , Q - TOD is the first frame-   work that introduces the query into task - oriented7267dialogue systems .   6 Conclusion   In this paper , we propose a novel query - driven task-   oriented dialogue system , namely Q - TOD . Q - TOD   consists of three modules : the query generator ex-   tracts the essential and up - to - date information from   the dialogue context into a concise query , the off-   the - shelf knowledge retriever utilizes the generated   query to retrieve relevant knowledge records , and   the response generator produces the final system   response using the retrieved knowledge records   and the dialogue context . Comprehensive experi-   ments show that Q - TOD consistently outperforms   all baselines on three active task - oriented dialogue   datasets , achieving a new state - of - the - art perfor-   mance .   Limitations   It is known that large - scale generation models are   hindered by inference inefficiency . In Q - TOD , the   query generator and the response generator are   invoked sequentially , which inevitably increases   the inference latency . Besides , similar to the pre-   vious works ( Roller et al . , 2021 ; Shuster et al . ,   2021 ) , Q - TOD also suffers from the knowledge   hallucination problem . These findings suggest that   further research should be undertaken to explore   more efficient inference strategy and high - fidelity   knowledge - grounded response generation .   Acknowledgements   We would like to thank the anonymous review-   ers for their insightful and constructive comments .   We also thank Wen Huang , Shiwei Huang , and   Jingzhou He for their help in resource coordina-   tion . This work was supported by the National Key   Research and Development Project of China ( No .   2018AAA0101900 ) .   References726872697270A Hyper Parameters   The settings of the hyper parameters used in our   experiments are summarized in Table 8 .   B Domain - wise Performance   For detailed analysis , we also provide the perfor-   mance of Q - TOD on each domain of SMD and   MWOZ in Table 9 .   Domain T5 - Large T5 - 3B   SMD Schedule 81.42 84.22   SMD Navigate 62.91 62.72   SMD Weather 69.18 73.17   MWOZ Hotel 45.25 46.71   MWOZ Attraction 54.81 62.68   MWOZ Restaurant 55.78 58.90   C Exploration on the Number of   Retrieved Knowledge Records   In our experiments , the knowledge retriever outputs   top - nrelevant knowledge records for response gen-   eration . To explore the effect of adjusting the num-   ber of retrieved knowledge records , we evaluate   Q - TOD in three different top- nsettings on the vali-   dation set of SMD . In Table 10 , it is observed that   the model using top-3 retrieved knowledge records   achieves the best Entity F1 on both T5 - Large and   T5 - 3B. This suggests that a small number of n   might be inadequate to cover the necessary knowl-   edge records for response generation . In contrast , a   large number of nwould inevitably introduce more   noisy knowledge records and increase the difficulty   of knowledge utilization in response generation . Model Top-1 Top-3 Top-5   Q - TOD ( T5 - Large ) 68.98 70.77 70.36   Q - TOD ( T5 - 3B ) 70.29 72.34 71.91   D Cross - domain Dataset Construction   We construct two cross - domain dialogue datasets   by merging single - domain dialogue sessions from   SMD , CamRest , and MWOZ . Table 11 describes   the construction details for these two datasets . For   instance , in SMD+CamRest , two original dialogue   sessions are merged into a cross - domain session ,   where one is from SMD and the other is from Cam-   Rest . Especially , these sessions are concatenated   in a random order . The two cross - domain datasets   both contain 600 dialogue sessions , in which the   partition of train / validation / test is 400/100/100.7271