  Yuting Zhao   Tokyo Metropolitan University   zhao - yuting@ed.tmu.ac.jpIoan Calapodescu   Naver Labs Europe   ioan.calapodescu@naverlabs.com   Abstract   In this paper , we look at the case of a   Generic text - to - text NMT model that has   to deal with data coming from various   modalities , like speech , images , or noisy   text extracted from the web . We propose   a two - step method , based on composable   adapters , todealwiththisproblemofMulti-   modal Robustness . In the first step , we sep-   arately learn domain adapters and modality   specific adapters , to deal with noisy input   comingfromvarioussources : ASR , OCR , or   noisy text ( UGC ) . In a second step , we com-   bine these components at runtime via dy-   namic routing or , when the source of noise   is unknown , via two new transfer learning   mechanisms(FastFusionandMultiFusion ) .   We show that our method provides a flex-   ible , state - of - the - art , architecture able to   deal with noisy multimodal inputs .   1 Introduction   Neural Machine Translation ( NMT ) has   achieved great performances ( Gehring et al . ,   2017 ; Vaswani et al . , 2017 ) but still suffers from   various robustness problems , as shown by many   previous works ( Koehn and Knowles , 2017 ; Be-   linkov and Bisk , 2017 ; Khayrallah and Koehn ,   2018 ) .   Specific datasets like Michel and Neubig   ( 2018 ) ; Berard et al . ( 2019a ) ; Li et al . ( 2019a ) ;   Specia et al . ( 2020a ) , consisting in noisy com-   ments from Reddit , or from Wikipedia or from   restaurant reviews , were proposed to showcase   this robustness problem .   Based on these datasets , several solutions   were proposed to deal with the problem . For   example , using synthetic noise , with data aug-   mentation Vaibhav et al . ( 2019 ) ; Karpukhin   et al . ( 2019 ) or other adversarial training meth-   ods ( Ebrahimi et al . , 2018 ; Cheng et al . , 2018,Figure 1 :   2019 , 2020 ) . But these solutions , based on   purely artificial noise do not guarantee the best   results on real noise ( Michel et al . , 2019 ) .   Another set of solutions make use of real   noisy data to fine - tune or adapt generic models ,   so that they become more robust to realistic   noise distributions ( Michel and Neubig , 2018 ;   Murakami et al . , 2019 ; Helcl et al . , 2019 ; Alam   and Anastasopoulos , 2020 ; Berard et al . , 2020 ) .   But , as shown in Specia et al . ( 2020a ) , these   noise specific methods do not generalise well   on domains or noise distributions not seen at   training time .   In this work , we want to propose an extensi-   ble robustness solution for NMT able to over-   come some of these limitations . To have a   realistic setting , we propose to build a model   able to translate several clean domains and   their respective noisy versions , coming from   various sources or modalities . As shown in   Figure 1 , we work with clean in - domain data   and noisy versions of the same data coming   from an automatic speech recognition ( ASR )   system , from an optical character recognition   ( OCR ) application , or from social media with   presence of keyboard typos or spelling errors   in the user - generated content ( UGC ) .   Our contributions are as follows:8505   •We propose a setting to explore the robust-   ness problem for NMT from the realistic   viewpoint of a generic NMT model which   has to deal with multimodal inputs , such   as ASR input , OCR input , and UGC data .   •We implement a robust multimodal NMT   model , which can handle different types of   noise ( but also clean data ) simultaneously   via composable Adapter Layers ( for noise   type and domains ) .   •We show that this model can easily be   extended to new sources of noise and new   domains .   •We also propose two new fusion mecha-   nismstodealtransparentlywiththesource   of noise ( a.k.a dealing with input when the   source of noise is unknown ) .   2 Methodology   In Figure 2 , we show the overall architecture of   our proposition , which separates domain adap-   tation(DA)andamultimodalrobustness(MR ) ,   with various noise adapters ( NA ) and an op-   tional fusion mechanism , inside a conventional   transformer encoder and decoder MT model .   2.1 Separate Domain Adaptation and   Noise Adaptation Learning   The first step in our method is to separately   learn Domain Adaptation ( DA ) and NoiseAdaptation ( NA ) .   For that , we start from a Generic NMT   model , based on a transformer encoder - decoder   architecture .   Given our training data separated into clean   and noise specific data ( as described in our   experimental settings ) , we first inject Adapter   Layers ( Houlsby et al . , 2019 ) to learn the Do-   main Adaptation task on clean in - domain data .   In a second step , these domain adapter layers   are loaded but frozen alongside the other pa-   rameters of the model . We inject new Adapter   Layers between the domain adapter layers and   the feed - forward component of the transformer   cell . We call them Noise Adapters ( NA ) and   we create one NA for each type of noise . Each   NA is trained only on his specific type of noise .   The DA and NA have the same structure , as   shown in Figure 2 , which is a down projection   to a bottleneck dimension followed by an up   projection to the initial embedding size .   Once , the DA and the various NA are sep-   arately learned , we can load them inside the   same model and recompose them at runtime   for decoding as explained in the next section .   2.2 Domain Adaptation and Noise   Adaptation composition at   Runtime   2.2.1 Dynamic Routing   The first way to recompose these various   Adapter Layers , when we know the type of8506noise , is to dynamically route their outputs at   runtime . For example , to process OCR input ,   the data is first forwarded through the multi-   head attention mechanisms ( self - attention in-   side the encoder or self - attention and cross-   attention inside the decoder ) , the feed - forward   component , the OCR NA and finally the DA .   This solution works , when we actually know   the source of noise . But , to be able to deal   with an unknown source of noise , we need an   additional component to combine what was   learned by each NA .   For that , we propose two new fusion mecha-   nisms , Fast Fusion and Multi Fusion , to com-   bine automatically all NA layers outputs . We   compare later these two solutions to the well   known Adapter Fusion method proposed by   ( Pfeiffer et al . , 2021 ) , which learns a parame-   terized mixer of the outputs from trained NAs .   2.2.2 Fast Fusion ( FF )   Fast Fusion ( FF ) is our first proposition to   combine the knowledge from the various noise   adapters . This simple solution consists in learn-   ing a linear projection Wfrom the concatena-   tion of the output of all the NAs ( H ) to the   DA embedding size ( d ) , followed by a residual   connection x.   FF(H ) = W(Concat ( H ) ) + x   H:{h , h , h. . .h }   W : R→R   This module is learned on a mix of all types   of noises . Everything , but the projection , is   frozen inside the model .   2.2.3 Multi Fusion ( MF )   Multi Fusion ( MF ) is our second proposal for   merging the knowledge from all the NAs . In-   spired by Adapter Fusion ( AF ) , we implement   an attention mechanism to learn how to com-   bine various adapters . Contrarily to AF , we use   a multi - head attention mechanism , like in the   traditional transformer ( Vaswani et al . , 2017 ) .   Several attention heads are learned on a par-   tition of the embedding space formed by the   output of the NAs , and then followed by a   residual x. MF(Q , K , V ) = Concat(head , . . . , head ) + x   head= softmax(QK   √d)V   = softmax(x·H√d)H   Where disddivided by the number of   attention heads M.   Like FF , MF is learned on a mix of all types   of noise .   3 Experiments   3.1 Initial Corpus   To build our multimodal dataset , we start   with the Multilingual TEDx ( mTEDx ) corpus   ( Salesky et al . , 2021b ) , which is a multilingual   corpus created from TEDx talks and suited   for speech recognition and machine translation   tasks . Table 1 shows the number of sentences   available for translation in the mTEDx corpus .   This corpus is composed of audio recordings   and their human provided transcriptions in 8   languagesand translations into up to 5 lan-   guages .   These translations in 12 language pairscan   be obtained from OpenSLR .   3.2 Multi - modal version   From the initial mTEDx Corpus , we create four   versions of the dataset to simulate clean data   and noisy data coming from various sources8507   ( images , speech and web ) . An example of data   from multi - modal versions is shown in Table 2 .   3.3 Clean In - domain Data   We simply use the human transcripts and their   translations as our clean , in - domain , dataset .   3.4 Noisy ASR data   To create the Noisy ASR version of the dataset ,   we use the audio files in the initial corpus and   simply transcribe them using an off - the - shelf   ASR system ( SpeechBrain ) .   We transcribe the mTEDx audio files for Fr   and It , as it was the only available pre - trained   models for Speechbrain . So in total , this Noisy   ASR dataset contains 5 language pairs : Fr →En ,   Fr→Es , Fr→Pt , It→En , It→Es .   In terms of noise , outside the usual ASR   errors , we can note that the model only outputs   lowercase text .   3.5 Noisy OCR data   To create this second noisy version of the mT-   EDx corpus , we simply print the human tran-   scriptions to images . We then use an OCR   system , using CRAFT as a segmenter ( Baek   et al . , 2019 ) and CRNN ( Shi et al . , 2015 ) as a   recognizer , trained on Latin , Greek and Korean   alphabets ( case sensitive ) , to extract back the   transcripts from the images .   3.6 Noisy UGC data   Finally , to simulate User Generated Content , as   we can find on the web , we use NL - Augmenter   ( Dhole et al . , 2021 ) to generate perturbations   in the original mTEDx transcriptions . More   specifically , we use the Butter Fingers pertur-   bation to simulate typos based on keyboard   layouts.3.7 Evaluation   For evaluation , we use SacreBLEU ( Post , 2018 )   on the test set to evaluate the translation qual-   ity and report BLEU ( Papineni et al . , 2002 )   and chrF ( Popovic , 2015 ) scores .   3.8 Setup   Generic NMT model As a baseline , we   trained a single multilingual NMT model   trained on a huge out - of - domain dataset .   We use ParaCrawl v7.1 ( Bañón et al . , 2020 )   and select the 19 highest - resource languages   paired with English . Then , like ( Freitag and   Firat , 2020 ) , we build a multi - parallel corpus   by aligning all pairs of languages through their   English side .   WetrainasharedBPEmodelwith64kmerge   operations and inline casing ( Berard et al . ,   2019b ) , by sampling from this data with tem-   perature 5 . We set the encoder / decoder to   contain N= 6layers . The embedding dimen-   sions of all the input and output layers were set   tod= 1024 . Thenumberofheadsinallmulti-   head modules was set to M= 8 . The label   smoothing was set at 0.1 , and the dropout was   0.1 . We use the Adam optimizer with β= 0.9 ,   β= 0.98 . The learning rate was 0.0005 , with   a warm - up step of 8,000 . We train the model   for 120k steps , with joint BPE vocabularies of   size 16k . The evaluation was performed every   20k steps and the best checkpoint was selected   on the average of the validation loss .   Domain Adaptation Freezing the pre-   trained multilingual NMT model , we fine - tuned   the DA layers on the clean in - domain dataset to   create a domain - adapted model for this setup .   We kept the same parameters as the pre - trained   model , and set DA to a size of 1024 . We fine-   tuned the DA for 3k steps with validation every   200 steps . The best checkpoint was saved ac-   cording to the average of validation loss .   Noise Adaptation Keeping the DA setup   fixed , we fine - tune the three types of NAs ,   with their respective noisy datasets : ASR NA   trained on the Noisy ASR data , OCR NA   trained on the Noisy OCR data and UGC NA   trained on the Noisy UGC data . We keep the   same parameters for the model and set NA   layers to have a size of 1024.8508   Multimodal Fusion This setup integrates   an additional fusion component , below the DA ,   to merge the three fine - tuned NAs . During   training , we only fine - tune the multimodal fu-   sion layer with a merge of the noisy multimodal   datasets while keeping the rest frozen . In addi-   tiontoourproposals(MultiFusionandFastFu-   sion ) , wealsotestAdapterFusion(AF)(Pfeiffer   et al . , 2021 ) as a baseline .   Joint learning of domain and noise To   compare our solution with previously proposed   jointlearningofnoiseanddomainwithAdapter   Layers , we also train a single Adapter Layer   tuned on all types of data , clean and noisy , as   in ( Berard et al . , 2020 ) .   Real vs synthetic noise To check the dif-   ferences between realistic and synthetic noise ,   we also train an Adapter layer with basic ran-   dom noise injection as in ( Berard et al . , 2020 ):   such as common spelling errors , punctuation   substitutions , letter swaps , spaces around punc-   tuation , and accent removal . Compositionality Totesttheabilitytocom-   pose our DAs and NAs , we also train a DA on   another domain Covost2 ( Wang et al . , 2020 ) ,   which is a speech translation dataset created   from Common Voice . The adapter layer is   trained only on clean Covost data . We test this   behaviorwhencomposedwithNAstrainedonly   on mTEDx noisy data . The test is performed   on noisy Covost data created in the same way   as the noisy mTEDx data . See Figure 3 .   4 Results   Tables 3 , 4 , 5 show our evaluation results ,   BLEU and chrF , on each type of noise . In the   following sections , we provide some qualitative   analysis of these metrics .   4.1 Impact of multimodal noise   As seen in Table 6 , on clean data , as expected ,   the DA model performs better than the Generic   NMT model ( +3.28 BLEU ) .   We can also easily see the impact of noisy   data on these strong baselines : both suffer   severely from noise with losses going from ( -8509   23.84 ) to ( -12.09 ) BLEU points depending on   the noise type . In our case , the ASR system   seems to be the most noisy , followed by the   OCR output and finally the UGC perturba-   tions seem to have the less impact in terms of   BLEU loss .   Finally , inthesametable , wecanalsoobserve   that the DA model is still in average better   than the Generic model when faced with noisy   multimodal data ( +4.2 BLEU in average ) .   4.2 Noise Adaptation efficiency   As seen in 3 , 4 , 5 , all the dedicated noise adap-   tation methods outperform the Generic NMT   model and the DA model .   If we look into the details , for example in   Table 3 , for the ASR noise , we can see that   the single DA trained with Synthetic Noise is   outperformed by the DA trained with the Real   Noise ( +3.4 BLEU ) . This confirms previous   observations like the ones done by ( Specia et al . ,   2020a ) . The same conclusion can be made for   the other types of noise : OCR Table 4 and   UGC Table 5 .   If we look at our proposal of learning sepa-   rately the DA and the NA , we can observe that   our method is actually competitive with the   previously proposed state - of - the - art methods ,   that jointly learn domain and noise . We have   in average the same exact quality , but with   the added benefice of easy extension ( to new   domains or types of noise ) and the ability to   handle inputs with unknown type of noise ( see   analysis in 4.3 ) .   4.3 Multimodal Fusion mechanisms   BeforelookingattheTransferLearningabilities   of our architecture , to new domains and types   of noise , let ’s look on how we deal with input   containing an unknown type of noise .   If we look in Table 3 , when we do n’t know   the exact type of noise in input , we can see   that Adapter Fusion , the current state - of - the-   art on fusing Adapter Layers , loses ( -0.5 ) BLEU   when compared with the oracle system ( where   we choose the right Adapter for the type of   input ) . Our solutions Fast Fusion and Multi8510Fusionbothobtainbetterresultswitharelative   improvement of ( +0.3 BLEU ) and ( +0.5 ) when   compared with AF . The MF solution actually is   as good as selecting the oracle Adapter Layer .   The same observation can be done on the   other types of noises : FF and MF outperform   the AF technique and bridge the gap with the   Oracle systems ( with an average of 0.16 BLEU   points difference only ) .   4.4 Transfer Learning ( new domain )   As seen in Table 7 , when we train separately a   new domain adapter , on clean data from Covost   ( Wang et al . , 2020 ) , like for the observations on   mTEDx , the Domain Adapted model suffers   from noisy input ( -13.9 BLEU ) . But , when we   combine this new DA with a previously trained   NA ( that was trained only on Noisy mTEDx   data ) , we observe that we gain back most of   the losses : to 46.6 BLEU on noisy covost data   compared to 47.8 on clean covost data ( only   -1.2 BLEU points loss ) .   It shows that our method allows to easily   extend the model to new domains while still   being able to deal with specific , already known ,   types of noises . This type of extension being a   lot more costly for all the methods doing a joint   learning of domain and noise . For example , in   case of joint learning , to handle 6 domains and   4 types of noises ( UGC , OCR , UGC and Clean )   one needs to train 6×4 = 24adapter layers ,   while our solution only necessitates 6 + 4 =   10adapter layers to provide a some level of   robustness to all domains .   4.5 Transfer Learning ( new noise )   Finally , to check the ability of our fusion mech-   anisms , FF and MF , to deal with an unknown   type of noise , we evaluate them on a synthetic   type of noise ( different from UGC , OCR and   ASR ) . This synthetic type of noise , similar to   ( Berard et al . , 2020 ) , consists of punctuationsubstitutions , letter swaps , spaces around punc-   tuation , accent removal , etc .   As seen in Table 8 , like before , the Generic   NMT model and the DA model suffer from this   new type of noise . When trying to deal with   this new type of noise , without retraining any   of our components , we observe again the FF   and MF both outperform AF .   4.6 Convergence speed   As a last observation , we can see in Figure 4 ,   that both FF and MF converge faster in terms   oftrainingstepsthanAF , givingusgoodresults   after only a few hundred steps of tuning .   5 Related Work   5.1 Robustness Task for NMT   Previous works have made several attempts to   handle noise ( Li et al . , 2019b ; Specia et al . ,   2020b ) . Data augmentation is used to generate   more noisy training sentences , by injecting syn-   thetic noise to emulate specific types of noise   ( Khayrallah and Koehn , 2018 ; Lui et al . , 2019 ;   Vaibhav et al . , 2019 ; Karpukhin et al . , 2019 ; Be-   rard et al . , 2020 ) , back - translating data is also   used to create artificial noise ( Li and Specia ,   2019 ; Zheng et al . , 2019 ; Helcl et al . , 2019 ; Post   and Duh , 2019 ) , and injecting made - up words   breaks the text naturalness ( Xu et al . , 2021 ) .   In addition to data augmentation , Berard et al .   ( 2019b ) ; Murakami et al . ( 2019 ) apply data   cleaning techniques in order to filter noisy data   in a preprocessing setup to avoid catastrophic   failures . Other works ( Sperber et al . , 2017 ;   Cheng et al . , 2018 , 2019 , 2020 ) propose adver-   sarial methods to synthesize adversarial attacks   in the training data . Michel and Neubig ( 2018 ) ;   Murakami et al . ( 2019 ) ; Helcl et al . ( 2019 ) ;   Alam and Anastasopoulos ( 2020 ) ; Berard et al .   ( 2020 ) use various fine - tuning / adaptation tech-   niques to help with specific types of noise .   5.2 Adapter Layers   Recent works has studied Adapter Layers   ( Houlsby et al . , 2019 ) for various types of   tasks . In computer vision , Rebuffi et al . ( 2017 ,   2018 ) introduce residual adapters for learning   visually - diverse domains . In NLP , Stickland   and Murray ( 2019 ) ; Pilault et al . ( 2020 ) ; Pfeif-   fer et al . ( 2021 ) mix adapters and multi - task   learning for natural language understanding8511   ( NLU ) tasks ; Lin et al . ( 2020 ) exploit adapters   to language generation tasks ; Pfeiffer et al .   ( 2020 ) propose an adapter - based framework for   cross - lingual transfer ; Ustun et al . ( 2020 ) apply   adapter to dependency parsing . In speech pro-   cessing , adapters are mostly used in ASR tasks   ( Kannan et al . , 2019 ; Lee et al . , 2021 ; Winata   et al . , 2021 ) . Recently , they have also been   explored for speech translation task ( Escolano   et al . , 2021 ; Li et al . , 2021a ) .   For NMT , Bapna et al . ( 2019 ) initially ap-   ply task specific adapter layers for multilingual   NMT.Then , Philipetal.(2020);Sticklandetal .   ( 2021 ) ; Ustun et al . ( 2021 ) train adapters with   different motivations : zero - shot NMT , cross-   lingual transfer , and unsupervised NMT .   5.3 Multimodal Translation   Many NLP tasks benefit from multimodal in-   tegration , such as spoken language translation   ( Akiba et al . , 2004 ) , visual question answer-   ing ( Agrawal et al . , 2015 ) , image captioning   ( Bernardi et al . , 2016 ) , multimodal sentimentanalysis ( Zadeh et al . , 2016 ) , image - guided   translation ( Zhao et al . , 2020 , 2022a , b ) . These   works indicate that multimodal sensory inte-   gration is an important aspect of information   processing and reasoning in NLP .   In contrast , multimodal robustness for text-   to - text NMT remains relatively less explored .   Recently , Salesky et al . ( 2021a ) transform texts   as images followed by OCR to cover some cases   of noise for the robustness of open - vocabulary   translation . Li et al . ( 2021b ) combines an ad-   versarial training on artificial noise with an   image - guided machine translation model for   translation robustness .   6 Conclusion   We propose an architecture to deal with the   robustness problem in case of multimodal data   for text - to - text NMT . Our solution is able to   deal with realistic noise coming from a speech   signal ( via ASR processing ) , from an image ( via   OCR processing ) or from noisy text as found   in UGC on the web.8512Our method proposes to first decompose   the Domain Adaptation and Noise Adaptation   learning tasks . In a second step , we show how   we can dynamically recompose the specific DA   and NA layers for handling , in the same model ,   various types of noise .   Finally , we also show how we can dynam-   ically fuse the knowledge from these various   adapters to provide robust translations , when   the source of noise is unknown , when we have a   new incoming domain or a new incoming source   of noise .   Limitations   While we show some good capacities of this   architecture to deal with unknown type of noise   and new domains , via our new FF and MF   mechanisms , we still lack a global mechanism   to actually fully integrate both DA and NA . A   question to be asked is : can we actually build   a fusion mechanism on both levels Domain and   Noise ? Current attention mechanisms , like our   multi - head attention in MF , do not support   seamlessly this stack of Adapter Layers . So for   now , wearelimitedtobuildafusionmechanism   for NAs and a separate one for DAs .   Also , on these new fusion mechanisms , while   they perform better than Adapter Fusion , we   should probably dig further to see if they gen-   eralize well to other NMT tasks ( like domain   adaptation for example ) or to other NLP tasks   ( like the ones for which the Adapter Fusion was   actually created ) .   Finally , while we believe our setting is a very   realistic one , because most of the current multi-   modalNMTsystemsworkinapipelineway , it ’s   not clear if our solutions will be of any use to   fully multimodal systems working for example   directly from the raw signal for speech .   Ethics Statement   We ensure that our work is conformant to the   ACM Code of Ethics .   References8513851485158516