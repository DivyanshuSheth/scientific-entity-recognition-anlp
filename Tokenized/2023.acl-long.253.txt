  Chen Tang , Hongbo Zhang , Tyler Loakman , Chenghua Linand Frank Guerin   Department of Computer Science , The University of Sheffield , UK   Department of Computer Science , The University of Surrey , UK   { chen.tang,f.guerin}@surrey.ac.uk   { hzhang183,tcloakman1,c.lin}@sheffield.ac.uk   Abstract   Incorporating external graph knowledge into   neural chatbot models has been proven effec-   tive for enhancing dialogue generation . How-   ever , in conventional graph neural networks   ( GNNs ) , message passing on a graph is inde-   pendent from text , resulting in the graph rep-   resentation hidden space differing from that of   the text . This training regime of existing mod-   els therefore leads to a semantic gap between   graph knowledge and text . In this study , we pro-   pose a novel framework for knowledge graph   enhanced dialogue generation . We dynamically   construct a multi - hop knowledge graph with   pseudo nodes to involve the language model   in feature aggregation within the graph at all   steps . To avoid the semantic biases caused by   learning on vanilla subgraphs , the proposed   framework applies hierarchical graph attention   to aggregate graph features on pseudo nodes   and then attains a global feature . Therefore ,   the framework can better utilise the heteroge-   neous features from both the post and exter-   nal graph knowledge . Extensive experiments   demonstrate that our framework outperforms   state - of - the - art ( SOTA ) baselines on dialogue   generation . Further analysis also shows that   our representation learning framework can fill   the semantic gap by coagulating representa-   tions of both text and graph knowledge . More-   over , the language model also learns how to   better select knowledge triples for a more in-   formative response via exploiting subgraph   patterns within our feature aggregation pro-   cess . Our code and resources are available at   https://github.com/tangg555/SaBART .   1 Introduction   Recent years have seen a surge of interest in devel-   oping chatbots with the facilitation of large - scale   knowledge ( Ni et al . , 2022 ) . As a highly expressive   data format , Knowledge Graphs ( e.g. ConceptNet   and DBpedia ) , which include world facts , are con-   sidered to be a key factor in building an effectiveFigure 1 : Conventional GNNs vs. Ours .   dialogue generation system ( Zhou et al . , 2018 ) . In   order to incorporate graph - structured knowledge , a   range of Graph Neural Networks such as Graph At-   tention Networks ( GATs ) ( Velickovic et al . , 2017 ;   Brody et al . , 2021 ) and Graph Convolutional Net-   works ( GCNs ) ( Kipf and Welling , 2016 ) have been   proposed to learn representations of the topologi-   cal structure of the knowledge graph via message   passing between entities . In open - domain dialogue   generation , these GNNs are further embedded into   generative frameworks to feed graph knowledge   features into the language models ( LMs ) .   Despite prior success in leveraging graph knowl-   edge with graph neural networks ( GNN ) ( Zhou   et al . , 2018 ; Zhang et al . , 2020 ) , current generative   frameworks are still hindered by the representa-   tion gap in the hidden space between the LMs and   GNNs , which poses significant challenges in ex-   ploiting graph knowledge in the subsequent text   decoding process . As illustrated in Figure 1 , prior   works using GNNs ( Zhu et al . , 2017 ; Ghazvinine-   jad et al . , 2018 ; Zhou et al . , 2018 ; Zhang et al . ,   2020 ) tend to fuse the graph features by transform-   ing them into text form and then feeding them into   the language model , which acts as a “ copy ” mech-   anism . In other words , these networks run as a   pipeline where the graph knowledge is firstly trans-   formed into additional text to avoid the problem4604of language model encoding brought about by the   heterogeneous graph features . However , these sepa-   rate encoding stages result in neural networks learn-   ing suboptimal representations of graph knowledge ,   which leads to information loss . With large - scale   pretrained models such as GPT-2 ( Radford et al . ,   2019 ) , BART ( Lewis et al . , 2020 ) and T5 ( Raffel   et al . , 2020 ) being widely adopted in recent ad-   vances in dialogue generation , the drawbacks that   arise from incompatibility between GNNs and LMs   becomes a more severe problem , prohibiting chat-   bot systems from leveraging graph structured data   effectively .   In order to address the aforementioned chal-   lenges , we propose a novel representation learn-   ing framework to facilitate language understanding   and generation , which permits effective incorpora-   tion of heterogeneous features via a dynamic graph   knowledge aggregation mechanism . In contrast   to existing works ( Zhu et al . , 2017 ; Ghazvinine-   jad et al . , 2018 ; Zhou et al . , 2018 ; Zhang et al . ,   2020 ) which incorporate graph knowledge with   conventional GNNs ( causing inadequacies in rep-   resentation learning ) , we propose to involve lan-   guage models in both text and graph knowledge   incorporation at all steps via hierarchically aggre-   gating knowledge on a dynamic pseudo graph . Dur-   ing the knowledge aggregation process , knowledge   triples are reorganised as shown in Figure 1 ( b ) ,   where pseudo nodes are created to learn conceptual   representations from original knowledge triples .   Conceptual semantics are forced to coagulate into   pseudo nodes , and finally merge into a condensed   feature vector to fill the semantic gap of the en-   coded text features . Our approach for incorporating   text and graph knowledge features can be adapted   to all language models with an encoder - decoder ar-   chitecture . In this study , we choose BART ( Lewis   et al . , 2020 ) , a SOTA language model for gener-   ation , as our language model in our experiments .   This framework will hereinafter be referred to as   SaBART ( Subgraph - Aggregation BART ) .   During subgraph knowledge aggregation , the   language model is involved in learning three lev-   els of features : ( 1 ) Subword - level , where concep-   tual embeddings are connected to entity mentions   within text ; ( 2 ) Knowledge - level , where original   triples are transformed by language encoding ; and   ( 3 ) Semantic - level , where the context vector en-   coded from text is involved in knowledge aggrega-   tion . This implies that the neural networks are ableto access both the text and graph features during   representation learning . The text and graph uni-   fied encoding process also avoids the information   loss caused by the representation shift in vanilla   GNNs , thus improving efficiency and efficacy . Ex-   tensive experiments demonstrate that our proposed   framework significantly outperforms current SOTA   baselines in dialogue generation . We also conduct   in - depth analysis into the underlying mechanism   of why our proposed approach better incorporates   heterogeneous features . Our contributions can be   summarised as follows :   •We propose a novel representation learning   framework where graph and text features   can be effectively aggregated via hierarchi-   cal knowledge aggregation on a dynamically   constructed pseudo graph ;   •We conduct a comprehensive set of exper-   iments to demonstrate the effectiveness of   our proposed approach , where our framework   achieves SOTA performance on the common-   sense knowledge graph enhanced dialogue   generation dataset ;   •We conduct in - depth experiments to analyse   the improvement of representation learning   on both graph and text knowledge , and inves-   tigate the mechanism to address this represen-   tation gap problem of learning heterogeneous   features .   2 Related Works   In this section , we introduce related works by sum-   marising recent advances in the knowledge en-   hanced dialogue generation task , as well as the   SOTA approaches for injecting graph knowledge   into generative frameworks .   Knowledge Enhanced Dialogue Generation As   a data - driven approach , deep learning based chat-   bots rely on access to large amounts of knowl-   edge ( Zhao et al . , 2020 ) to generate interesting   and informative dialogues like humans . In order to   realise a commonsense - aware and semantic - aware   chatbot , more and more studies ( Yu et al . , 2022 ;   Huang et al . , 2022 ; Tang et al . , 2022b ) aim to con-   sider external knowledge beyond pure dialogue ex-   changes to facilitate generation , where knowledge   graphs containing topological structural knowledge   are an important research direction to facilitate log-   ical reasoning . In this study , we aim to improve4605   the performance of neural frameworks through us-   ing additional knowledge graphs as external re-   sources . Therefore , studies with external knowl-   edge other than knowledge graphs , such as con-   tent planning ( Tang et al . , 2022c ) , retrieved docu-   ments ( Yu et al . , 2022 ) , and mixed resources ( Wu   et al . , 2022 ) , are not directly compared in this pa-   per . We believe our learning pattern for handling   heterogeneous features can provide inspiration to   other types of knowledge grounded conversational   systems as well .   Injecting Graph Knowledge into Generative   Frameworks With pre - training techniques being   widely adopted , large - scale language models such   as UniLM ( Dong et al . , 2019 ) , GPT-2 ( Radford   et al . , 2019 ) , and BART ( Lewis et al . , 2020 ) have   become the base models for various dialogue gen-   eration systems . However , these language models   generally input only sequence formatted text , and   can not directly incorporate features of graph knowl-   edge . Usually graph knowledge has to firstly be flat-   tened into a sequence of tokens ( Tang et al . , 2022a ) ,   or encoded as feature vectors ( Zhao et al . , 2020 )   before being fed into a language model . Zhou   et al . ( 2018 ) uses GRUs and two graph attention   modules to select appropriate triples to incorporate   into responses . In order to exploit the benefits of   multi - hop knowledge , Zhang et al . ( 2020 ) adds an   attention mechanism in a similar way to filter the   appropriate knowledge . Finally , Tuan et al . ( 2019 )   propose a model which selects the output from asequence - to - sequence model and a multi - hop rea-   soning model at each time step .   3 Methods   As illustrated in Figure 2 , our approach aims to   improve dialogue generation of language models   by better incorporating heterogeneous features with   an effective knowledge aggregation framework on   retrieved knowledge triples .   3.1 Task Definition   In our task , the given input includes a textual   postX={x , x , ... , x}where xdenotes the   n - th token , and a graph knowledge base G=   { τ , τ , ... , τ}.τdenotes a triple { h , r , t } , where   h , r , and trefer to the head entity , the relation ,   and the tail entity , respectively . These triples rep-   resent the entities contained in the posts and ref-   erence responses , and the relations between them .   Provided with these two kinds of input , the gen-   eration model is required to generate a response   Y={y , y , ... , y}by modeling the conditional   probability distribution P(Y|X , G ) .   3.2 Dynamic Subgraph Construction   The graph knowledge is obtained by retrieving con-   cept triples from ConceptNet , which are contained   in the posts and reference responses . Our knowl-   edge retrieval process is implemented by word   matching ( concepts in ConceptNet take the form   of single words ) and rule filtering to collect knowl-   edge triples , which resembles the strategy of Zhou4606et al . ( 2018 ) . This process involves recognising   relevant conceptual entities contained in the input   post , and retrieving directly connected concept en-   tities in the responses , with the goal of exploiting   these entities in output responses . Therefore , dur-   ing knowledge retrieval , the retrieved knowledge   triples are grouped according to the mentions of   conceptual entities from the posts . For example ,   the post given in Figure 2 has “ milk ” recognised as   an entity mention , which in turn retrieves relevant   triples , e.g. ( coffee , RelatedTo , milk ) . First of   all , we group the retrieved knowledge triples as   follows :   ent , ent , ... , ent∈X∪G ( 1 )   g={τ , τ , ... , τ}s.t.ent∈τ ( 2 )   where triples τcontaining the same conceptual   entity entare grouped as a subgraph gfor the   post . In contrast to existing works ( Zhu et al . ,   2017 ; Ghazvininejad et al . , 2018 ; Zhou et al . , 2018 ;   Zhang et al . , 2020 ) that encode knowledge and   select triples on separate subgraphs ( leading to bi-   ased and incomplete feature learning ) , we propose   to reconstruct Gwith pseudo nodes , so that pseudo   nodes can dynamically connect each gto form a   global graph :   pseu = LM(F ( τ ) ) ( 3 )   F ( τ ) = [ x , x , x , x ] ( 4 )   F ( F ( τ)|τ∈G)−→ LM ( 5 )   where F flattens the triple of ( h , r , t ) to a text   sequence , e.g. , ( coffee , RelatedTo , milk ) will be   flattened to “ coffee related to milk ” . In ConceptNet ,   handtconsist of single words , and ris the rela-   tion of the two words . These words are transformed   into BPE ( byte - pair encoding ) pieces ( Lewis et al . ,   2020 ) , and distinctively inserted into the sub - word   embedding layer of the LM . This is performed in   order to learn the semantics of both the entity men-   tions in the post , as well as the topological structure   of the graph pseu∈R(Edenotes the size   of the word embeddings ) , which constitutes the   representation of the whole triple . We replace the   original triples of Gwith the basic pseudo nodes ( in   purple ) , where Wis the word length of flattened   τ , and Cis the embedding size of the LM . On   top of the basic pseudo nodes , hierarchical pseudolayers are created to connect all subgraphs :   g={τ , τ , ... , τ}s.t . τ∈g ( 6 )   τ={pseu , r , pseu } ( 7 )   where gdenotes the subgraph rebuilt by pseudo   nodes pseu∈R. They are connected   topseuwith a relation r , whose weight is cal-   culated with an attention mechanism introduced in   Sec . 3.3 .   G={T , T , ... , T } ( 8)   T={pseu , r , pseu } ( 9 )   Here pseu∈Ris the root node represent-   ing the features of the whole graph G.pseuas   the new pseudo knowledge graph is the set of the   aforementioned pseudo triples transformed from   the original triples .   3.3 Hierarchical Knowledge Aggregation   Instead of learning graph features by message pass-   ing on graph nodes , we implement a novel repre-   sentation learning framework , where we train the   neural network to learn the global features from   the whole graph by hierarchically aggregating fea-   tures through pseudo nodes as shown in Figure 2(c ) .   Firstly , we encode features of the post to obtain a   semantic vector H∈R , and the embed-   dings of input tokens H :   LM(X ) = [ H;H ]   = [ emb;emb , emb , ... ] ( 10 )   where the context information of the post H   will be used as context from the post , and involved   in aggregating features on graph knowledge ( as   the query vector in the attention mechanism ) . Sub-   sequently , a series of feature incorporation proce-   dures will be conducted on our constructed graph   of pseudo nodes .   3.3.1 Aggregation on Static Graphs   In § 3.2 , the original retrieved triples have been   transformed into the set of pseudo nodes pseu .   To obtain the representation of the graph , we di-   rectly aggregate the node features by calculating   their mean value , which is inspired by the work of   Tang et al . ( 2021 ) in calculating global representa-   tions .   ϵ=/summationtextpseu   |G|(11)4607where ϵ∈Rdenotes the semantic represen-   tation of all triples . Because every node has the   same weight when contributing to the global rep-   resentation , ϵwill be carried into the following   dynamic graph aggregation to obtain a better graph   representation feature for response generation .   3.3.2 Aggregation on Dynamic Graphs   The aggregation process on the dynamic knowl-   edge graph has a sequential forward procedure as   follows .   First Forward Layer . In the first step , we calcu-   late the features of pseu∈g :   Update ( pseu ) = /summationdisplayapseu ( 12 )   a = exp(β )   /summationtextexp(β)(13 )   β = W[pseu;q](14 )   q = FC([H;ϵ ] ) ( 15 )   ϵ=max(ϵ ) ( 16 )   where τ∈gall include pseuas the tail node   ( cf . Equation 6 ) ; idenotes the i - th entity mention   in the post ; and jdenotes the j - th triple related to   the mention . W∈Ris a trainable pa-   rameter multiplying the concatenation of the node   representation and the context feature vector . ais   an attention score to aggregate features of pseu   into the updated pseu.q∈Ris the query   vector of the attention mechanism . FCis a fully   connected neural network , and maxis the max-   pool function transforming ϵ∈Rtoϵ∈R.   Second Forward Layer . Similarly , when our   model attends to G , we update the features with   pseuobtained in the first step :   Update ( pseu ) = /summationdisplayapseu ( 17 )   a = exp(β )   /summationtextexp(β)(18 )   β = W   [ pseu;q](19 )   whereW   ∈Ris a trainable parameter ,   and the final pseurepresents the global features   aggregated by G. The feature vector qis the same   as the one in the first forward layer , which acts   as the global context of both the post and static   knowledge graph .   3.4 Inference and Training   To auto - regressively generate responses , the lan-   guage model predicts each token yat time step   t :   Y= [ y , y , ... , y ] s.t . t > 0 ( 20 )   p = softmax ( HW ) ( 21 )   H = LM(H , Y ) ( 22 )   H= [ pseu;ϵ;H;H ] ( 23 )   whereH∈RandH∈Rare out-   puts of encoders and decoders ; and Ldenotes the   size of the concatenated feature vector . The dimen-   sion of pseuhere is transformed to R , so   thatpseu , HandHcan be concatenated at   the first dimension . W∈Ris a trainable   parameter denoting the LM head in Figure 2(d ) ;   andEdenotes the size of the word embeddings .   Finally , we train the whole framework with the loss   function as follows :   L=−1   N / summationdisplaylogP(Y|X , G ) ( 24 )   where Ndenotes the size of the test data , and Lis   the cross entropy of predicted response tokens and   those of the golden responses .   4 Experiment   4.1 Experimental Setup   Dataset . We process the dataset provided   by Zhou et al . ( 2018 ) for the following experiments ,   where the train / val / test datasets are split into sizes4608   of 3,384,185/20,000/10,000 , respectively . The   statistics of the data are shown in Table 1 . From   the table , it can be observed that the average statis-   tics of entities , subgraphs and triples in these three   splits are very close , implying that the data samples   are fully shuffled to make the experiment fair .   Baselines . We select several competitive base-   lines for comparison , including : Seq2seq   ( Sutskever et al . , 2014 ) , MemNet ( Ghazvinine-   jad et al . , 2018 ) , CopyNet ( Zhu et al . , 2017 ) ,   UniLM ( Dong et al . , 2019 ) , BART ( Lewis et al . ,   2020 ) , CCM ( Zhou et al . , 2018 ) , and Concept-   Flow ( Zhang et al . , 2020 ) . In particular , UniLM   and BART are SOTA pre - trained models for gener-   ation tasks , whilst ConceptFlow is the SOTA model   for our task .   Evaluation Metrics . We adopt the metrics of   BLEU ( Papineni et al . , 2002 ) , NIST ( Doddington ,   2002 ) , METEOR ( Lavie and Agarwal , 2007 ) , Dist ,   and Ent ( Zhang et al . , 2018 ) for evaluation . BLEU ,   NIST , and METEOR are calculated between gen-   erated responses and golden responses , whilst Dist   and Ent ( calculating word distinction by n - grams )   are calculated within generated responses . We also   conduct further experiments to evaluate the effi-   ciency and efficacy of incorporating external knowl-   edge by counting the entities from the post used in   the generated responses .   4.2 Implementation Details   Our framework is mainly implemented with   Pytorchand Pytorch - lightning , and we select   BART ( Lewis et al . , 2020 ) as the base language   model . We use a publicly available checkpoint   from Huggingface , and fine - tune it with our dy-   namic graph knowledge aggregation framework .   The random seed is fixed to 42 for ease of repro-   ducibility . Our language model has 12 attention   heads and 6 hidden layers in each encoder and de-   coder , leading to a total of 157 M parameters . The   maximum sequence length is limited to 512 ; the   batch size is set to 64 ; and the learning rate is 1e-4 .   We use Adam ( Kingma and Ba , 2014 ) as the op-   timiser and set its parameter to 1e-8 . The whole   training process lasts for 5 epochs . We train on an   Nvidia RTX A100 GPU node , which has 120 GB   of system memory and 80 GB of VRAM , and takes   two days to train.4609   4.3 Automatic Evaluation   Table 2 shows reference - based automatic evalu-   ation results , which demonstrate our proposed   framework substantially outperforms all baselines   on all referenced metrics . In comparison to the   SOTA model ConceptFlow , our model doubles   ( e.g. BLEU-2 , NIST-2 , METEOR ) or triples ( e.g.   BLEU-3 , BLEU-4 ) performance on most metrics .   Considering the performance of - w/o kg ( equiva-   lent to vanilla BART ) , it can be inferred that the   enhanced performance of our model is primarily   attributable to incorporating external knowledge .   Comparing to other GNN models ( e.g. Concept-   Flow and CCM ) , our model is superior in han-   dling the heterogeneous features from the text and   graph knowledge , leading to a better capturing of   the global context contained in both the post and   knowledge graph . In terms of unreferenced met-   rics , the results in Table 3 also show that our model   achieves a substantial improvement in diversity . It   can be observed that our model performance on   Dist-1 and Dist-2 are more than twice that of the   SOTA model ConceptFlow . Our improvement on   both unreferenced and referenced metrics further   demonstrates that the gain comes from incorporat - ing knowledge to generate human - like responses ,   rather than metric - oriented training ( i.e. , no metric-   oriented reward is used here ) . In addition , the ab-   lation results of - w/o dy - agg and- w/o st - agg also   prove the hierarchical layers of graph knowledge   aggregation benefit the semantic understanding of   graph knowledge . The aggregation of static graph   features forms the representation learning of lower-   level semantics , whilst the dynamic aggregation   contributes to the representation of higher - level se-   mantics . Therefore , combining the two kinds of   semantics leads to a substantial performance im-   provement on both referenced and unreferenced   metrics .   4.4 In - Depth Analysis   Furthermore , we present two experiments to anal-   yse whether the external knowledge is better ex-   ploited in our framework than the SOTA model   ( ConceptFlow ) , as well as why our framework   learns representations more efficiently and effec-   tively .   Performance of Knowledge Incorporation .   The experimental results concerning the amount   of knowledge used to generate responses are il-   lustrated in Figure 3 . Firstly , we group the test   set by the number of post entities retrieved in the   given post . The target is to analyse the robust-   ness and efficiency of models as the knowledge   content increases . Figure 3(a ) indicates the proba-   bility distribution of the knowledge amount in each   conversation pair , 3(b ) shows the statistics of the   grouped test set , 3(c ) gives the curve illustrating   how many retrieved knowledge items are finally   used in generated responses , and 3(d ) indicates   that our model substantially outperforms the SOTA   model by a large margin with respect to knowledge   incorporation on the whole test set . It can be ob-4610served that with the proposed dynamic knowledge   aggregation framework , the model tends to use   more retrieved entities when generating a response .   As the number of retrieved entities increases , the   curve in ( c ) maintains a steady slope to incorporate   entities , indicating that our model maintains the   incorporation efficacy even with large amounts of   knowledge as input . We argue that the robustness   and efficiency of knowledge incorporation result   from the globally aggregated features from the dy-   namically constructed graph with pseudo nodes ,   which avoids the information loss that the vanilla   GNN models typically suffer . This also leads to   our model outperforming other baseline models in   generating high - quality responses .   Representations of Text and Graph Knowledge .   Figure 4 shows the representations of text and en-   tities from the knowledge graph . We project the   embeddings of the vanilla GNN models used in the   baselines into two - dimensional points for visuali-   sation . To compare the difference in embeddings   from text and the knowledge graph , we normalise   by mapping both embeddings to the range of [ 0,1 ] .   It can be observed that the entity embeddings of   the baselines ( shown in Figure 4(a ) ) are concen-   trated in a circle no matter what post is given ( i.e.   blue points ) . This suggests that the GNN - learned   embeddings present a biased representation for ex-   ternal knowledge , which may lead to difficulty in   incorporating graph knowledge with the language   model ( which is trained on text corpora ) . In com-   parison , our framework unifies the representation   hidden space of both text and graph knowledge ,   which makes the heterogeneous features have more   shared space to fit the dataset . This mechanism   makes the entity embeddings in our framework   evenly spread among text words , thus it can be   easily exploited by neural networks .   4.5 Human Evaluation   We present manual pair - wise comparisons to ex-   amine the appropriateness ( whether the response   is appropriate in the context ) and informativeness   ( whether the response contains much information )   of the most competitive baseline ( ConceptFlow ) ,   our model ( SaBART ) , as well as two ablation mod-   els ( - w/o dy - agg and- w/o st - agg ) . Three human   evaluators are instructed to give their preferred re-   sponse on 100 randomly sampled conversational   pairs between each compared model . The results   are reported in Table 4 .   When summarising the human annotation re-   sults , the final results are counted by majority vot-   ing . The ablated static aggregation and dynamic   aggregation play different roles in feature incorpo-   ration , so the results of the corresponding ablation   models are slightly lower than that of SaBART . On   the other hand , the comparison with ConceptFlow   demonstrates that our proposed model significantly   outperforms the SOTA in terms of both appropri-   ateness and informativeness , which is consistent   with our observations in automatic evaluation .   4.6 Case Study   In Table 5 , we show the generated responses of the   most competitive models ( i.e. , two ablated mod-   els and ConceptFlow ) . We select a short post and   a long post that includes more graph knowledge   to validate performance . It can be observed that   in both cases , the models containing aggregation   frameworks tend to compose their responses with   more unique and relevant entities . When a short   post is given , the knowledge can effectively help   avoid generating overly simplistic utterances , re-   sulting in a more appropriate , informative , and en-   gaging response output . Given a long input , all   models seem good at generating a long response .   However , compared to SaBART , the responses   generated by the baseline models are less expres-   sive due to the sub - optimal incorporation of graph   knowledge . For example , ConceptFlow uses four   instances of “ play ” in the response , diluting the4611   information it conveys , in addition to the content   not being coherent or related to the post . In con-   trast , SaBART is able to better exploit the retrieved   knowledge ( e.g. “ frustrating ” in relation to “ prob-   lem ” ) , which thus results in composing a more   appropriate and informative response .   5 Conclusion   In this study , we propose a novel dynamic graph   aggregation framework for the task of knowledge   graph enhanced dialogue generation . We dynami-   cally construct a graph with created pseudo nodes ,   and hierarchically aggregate graph knowledge to   attain a global feature which better represents the   topological structure and semantics contained in   the knowledge graph . Due to the superior ability   in leveraging the heterogeneous features of input   text and graph knowledge , our framework can fill   the semantic gap between the language model and   knowledge graph and consequently generate an   informative response . The extensive experiments   demonstrate that our model significantly outper - forms all baseline models , and can generate more   appropriate and informative responses utilising ex-   ternal graph knowledge .   Limitations   This paper aims to investigate a more efficient and   effective framework to incorporate the heteroge-   neous features of both text and graph knowledge .   The extensive experiments demonstrate our frame-   work has a superior performance in capturing se-   mantics of input knowledge , thus beating all SOTA   models . However , due to the time and resource   limit , we could not conduct further experimenta-   tion to compare with promising frameworks in sim-   ilar areas . In fact , we have observed some other   techniques ( Tang et al . , 2022c ; Yu et al . , 2022 ; Wu   et al . , 2022 ) may be beneficial to our study , but   when considering the difficulty in applying them   here ( due to additional annotation and knowledge   being required ) , we have to leave them to future   work . We also can not exclude some other factors   which may affect performance . For example , we   select BART as the base language model in this   paper . In practical use , the latest language models   ( e.g. ChatGPT ) may have better performance in   this task . We have to leave the analysis of these   factors to future study .   Ethics Statement   We conduct the experiments based on an existing   publicly available dataset from Zhou et al . ( 2018 )   which is a large - scale dataset widely used to study   commonsense dialogue generation , and we strictly   follow the license and instructions . We also read   and acknowledge the ACM Code of Ethnics and   Professional Conduct . We take our professional re-   sponsibilities very seriously , and our study did not   violate any ethical principles . Additionally , whilst   our work concerns the incorporation of knowledge   from knowledge graphs in dialogue systems , we   acknowledge that the veracity and validity of the   knowledge in such resources should be assessed in   production , in order to avoid the perpetuation of   misinformation .   Acknowledgements   Chen Tang is supported by the China Scholar-   ship Council ( CSC ) for his doctoral study ( File   No.202006120039 ) . Tyler Loakman is supported4612by the Centre for Doctoral Training in Speech and   Language Technologies ( SLT ) and their Applica-   tions funded by UK Research and Innovation [ grant   number EP / S023062/1 ] .   References46134614ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Line 547 to 567   /squareA2 . Did you discuss any potential risks of your work ?   Line 568 to 582   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract ( all ) and Introduction ( Lines 082 - 145 )   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   The commonsense dialogue generation dataset from https://github.com/thu-coai/ccm .   /squareB1 . Did you cite the creators of artifacts you used ?   Sec . 4.1   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   Section of " Ethnical Statement "   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   Section of " Ethnical Statement "   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Not applicable . Left blank .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Not applicable . Left blank .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   Section 4.1   C / squareDid you run computational experiments ?   Section 4   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   Section 4.24615 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   Section 4.2   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   a single run   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   I use ROUGE from a python package , and it needs no parameter settings .   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Section 4.5   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   Section 4.5   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   students   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   Not applicable . Left blank .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   Not applicable . Left blank .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   Not applicable . Left blank.4616