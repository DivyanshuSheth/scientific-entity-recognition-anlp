  Garam LeeMinsoo KimJai Hyun Park   Seung - won HwangJung Hee CheonCryptoLabSeoul National University   Abstract   Embeddings , which compress information   in raw text into semantics - preserving low-   dimensional vectors , have been widely adopted   for their efficacy . However , recent research has   shown that embeddings can potentially leak pri-   vate information about sensitive attributes of   the text , and in some cases , can be inverted to   recover the original input text . To address these   growing privacy challenges , we propose a pri-   vatization mechanism for embeddings based   on homomorphic encryption , to prevent po-   tential leakage of any piece of information in   the process of text classification . In partic-   ular , our method performs text classification   on the encryption of embeddings from state-   of - the - art models like BERT , supported by an   efficient GPU implementation of CKKS en-   cryption scheme . We show that our method   offers encrypted protection of BERT embed-   dings , while largely preserving their utility on   downstream text classification tasks .   1 Introduction   In recent years , the increasingly wide adoption of   vector - based representations of text such as BERT ,   eLMo , and GPT ( Devlin et al . , 2019 ; Peters et al . ,   2018 ; Radford et al . , 2019 ) , has called attention   to the privacy ramifications of embedding mod-   els . For example , Coavoux et al . ( 2018 ) ; Li et al .   ( 2018 ) show that sensitive information such as the   authors ’ gender and age can be partially recovered   from an embedded representation of text . Song   and Raghunathan ( 2020 ) report that BERT - based   sentence embeddings can be inverted to recover up   to 50%–70 % of the input words .   Previously proposed solutions such as differen-   tial privacy based on perturbation / noise ( Qu et al . ,   2021 ) , require manually controlling the noise in-   jected into embeddings , to control the privacy-   utility trade - off to a level suitable for each down-   stream task . In this work , we propose a privacysolution based on Approximate Homomorphic En-   cryption , which is able to achieve little to no accu-   racy loss of BERT embeddings on text classifica-   tion , while ensuring a desired level of encrypted   protection , i.e. 128 - bit security .   Homomorphic Encryption ( HE ) is a crypto-   graphic primitive that serves computations over en-   crypted data without any decryption process . While   previous works have focused on homomorphic   computation where the inputs are numerical data ,   in applications such as privacy - preserving machine   learning algorithms ( Lauter , 2021 ) , logistic regres-   sion ( Kim et al . , 2018 ) , and neural network infer-   ence ( Gilad - Bachrach et al . , 2016 ) , they have rarely   been applied to unstructured data such as text . Re-   cent works in this direction include Podschwadt   and Takabi ( 2020 ) , who conduct sentiment clas-   sification over encrypted word embeddings using   RNN . However , they use a simple embedding layer   which maps words in a dictionary to real - valued   vectors , and model training is only supported on   plaintext . The most closely related work to ours is   PrivFT ( Badawi et al . , 2020 ) , a homomorphic en-   cryption based method for privacy preserving text   classification built on fastText ( Joulin et al . , 2017 ) .   We next describe our approach , focusing on our   distinctions from PrivFT :   •BERT Embedding - based Method : The princi-   ple behind PrivFT is to perform all neural network   computations in encrypted state . For this purpose ,   it adopts fastText ( Joulin et al . , 2017 ) , which takes   bag - of - words vectors as input , followed by a two-   layer network and an embedding layer . However ,   PrivFT does not utilize pre - training ; as a conse-   quence , the embedding matrix and classifer of   PrivFT must be updated from scratch , taking sev-   eral days to train on a single dataset .   We introduce a new method for text classifica-   tion on encrypted data . The crux is to operate   a simple downstream classifier on encryptions3169of semantically rich vector representations ( i.e.   BERT embeddings ) . By using rich input repre-   sentations , our method significantly outperforms   PrivFT , while the use of a simple downstream clas-   sifier on encrypted data makes our method much   more practical . Importantly , by leveraging pre-   trained embeddings from models such as BERT ,   a state - of - the - art in many NLP tasks , our method   enables the training of a strong classifier in en-   crypted state within hours . As such , our method   is well positioned to take full advantage of the   recent trends in NLP , that rely on the language   understanding capability of increasingly larger   pre - trained language models ( Brown et al . , 2020 ;   Kaplan et al . , 2020 ) .   •Better GPU Implementation : As BERT rep-   resentations are real - valued vectors , we adopt   CKKS scheme , which is well - suited for dealing   with real numbers compared to other HE schemes .   We develop an efficient GPU implementation of   CKKS which greatly improves computation speed .   While PrivFT also provides a GPU implemen-   tation of CKKS , their implementation lacks the   bootstrapping operation of CKKS . Inevitably , this   limits the multiplicative depth of PrivFT , and it   makes the method less scalable . It also results in   the use of less secure CKKS parameters which   have roughly 80 - bit security level . In contrast ,   our GPU implementation includes the bootstrap-   ping operation , which allows unlimited number   of multiplications . This enables us to use a higher   degree polynomial approximation ( which is key to   achieving a high downstream accuracy ) , and more   secure CKKS parameters ( 128 - bit security level ) .   Moreover , with practicality in mind , we improved   the implementation in terms of communication   cost . More precisely , we introduce a practical im-   plementation of CKKS to significantly reduce the   size of ciphertexts by more than 7.4×compared   to the rudimentary implementation .   We experimentally validate our approach on text   classification datasets , showing that it offers en-   crypted protection of embedding vectors , while   maintaining utility competitive to plaintext on   downstream classification tasks . Additionally , we   compare our method with PrivFT on homomorphic   training on encrypted data , showing it outperforms   PrivFT , with much improved training efficiency .   2 Method   We focus on the scenario in which the user directly   applies the privacy mechanism to the output embed-   dings from a neural text encoder , before passing it   on to a service provider for usage in a downstream   task . This is also referred to as a local privacy   setting ( Qu et al . , 2021 ) .   The privatization procedure Min the local   privacy setting can be defined as follows :   M(x ) = P(F(x ) ) ( 1 )   where xis the raw text input , Fis Sentence-   BERT ( Reimers and Gurevych , 2019 ) , a popular   pre - trained model for obtaining sentence embed-   dings , and Pdenotes a privacy mechanism . Next ,   we securely classify the text datum , x , by feeding   its privatized embedding , M(x ) , to the down-   stream classification model . In this work , we adopt   a logistic regression model ( in encrypted state ) as   the downstream classifier . Figure 1 demonstrates   the entire privatization inference procedure , start-   ing with user ’s embedding of raw text and encryp-   tion of embedding , to the operation of the classi-   fier in encrypted state and finally , the output of   encrypted classification results . We note that the   training process also can be performed in encrypted   state as we describe in Section 2.2 .   2.1 Baseline : Local Differential Privacy   As a baseline for the local privacy setting , we imple-   ment noise - based local differential privacy ( LDP ) .   Qu et al . ( 2021 ) introduced noise - based LDP for   single - token embeddings as privatization mecha-   nismP. In the case of single - token embeddings , lo-   cal differential privacy can be achieved with respect   to a chosen Euclidean distance by adding randomly3170   sampled noise Ndrawn from an n - dimensional dis-   tribution with density p(N)∝exp(−η||N|| ) . That   is , the privacy mechanism is P(y ) = y+N , where   ydenotes an embedding vector . In our work , we   adopt the same mechanism to sentence embeddings .   Following Qu et al . ( 2021 ) , the noise N∈Ris   sampled as a pair ( r , p ) , where ris the distance   from the origin and pis a point in B(the unit   hypersphere in R).ris sampled from Gamma dis-   tribution Γ(n,)andpis sampled uniformly over   B , andNis computed as N = rp .   2.2 HE Based Logistic Regression   We now describe our proposed privatization mech-   anism in detail . We adopt Eq.1 , with the privacy   mechanism P(y ) = H(y ) , where His the homo-   morphic encryption . For downstream tasks , we   feed the privatized embedding M(x)to an en-   crypted logistic regression classifier . By utilizing   HE , an encrypted model and labels will be obtained   after the training and inference process . Only the   user who knows the secret key of HE can decrypt   the results and get either the classifier or labels for   the classification .   For the homomorphic encryption H , we adopt   the CKKS scheme ( Cheon et al . , 2017 , 2018 , 2019 ) .   While the majority of HE schemes are being opti-   mized for computations over finite fields , CKKS   supports efficient computations over real numbers ,   so it is advantageous in application to real world   data . We refer the readers to the paper ( Cheon et al . ,   2017 ) for full details of CKKS .   CKKS is a levelled homomorphic encryption   scheme , where the level of each ciphertext indi-   cates the remaining number of times we can oper-   ate . When we multiply two ciphertexts of level   l , the output ciphertext has a level of l−1 . Once   the level of a ciphertext becomes too low , we can   refresh its level higher by using the bootstrappingtechnique so that the number of possible operation   times increases . For ciphertexts ctandctof com-   plex vector messages mandm , we summarize   the operations of CKKS as follows :   •Add(ct , ct ): output a ciphertext of m+m .   •Mult(ct , ct ): output a ciphertext of m⊙m ,   where ⊙is the entry - wise multiplication .   •Bootstrap ( ct ): output a ciphertext of mat   refreshed level .   While it is prevalent to encrypt data into the top   level , L , in this work , we encrypt the data into a   lower level , 3 , to decrease the initial size of cipher-   texts . Note that the ciphertexts are the privatized   embeddings , so their size determines the commu-   nication cost . As shown in Table 1 , by using the   lower level ciphertexts , we reduce the initial size   of ciphertext by more than 7.4×in both Twitter   training dataset ( 10.8 GB to 1.4 GB ) , and SNIPS   training dataset ( 85.3 GB to 11.4 GB ) .   Finally , we feed the output of our privatization   mechanism to the next step , the training and in-   ference of an encrypted logistic regression classi-   fier . However , since CKKS supports only addi-   tion and multiplication while the logistic function   ( 1/(1 + exp(−x))is a non - polynomial function ,   we evaluate the logistic function via its polynomial   approximation . We use the minimax approximate   polynomial ( Pachon and Trefethen , 2009 ) of de-   gree15on[−12,12]that approximates the logistic   function within the error of 0.00614 on[−12,12 ] .   2.3 Datasets   To validate our approach in real - world scenarios ,   we conduct experiments on tasks with realistic pri-   vacy concerns and utility needs . We select text   classification tasks on data in three settings :   •Tweets Hate Speech Detection ( Sharma ,   2018 ): Is a crowd - sourced dataset of Tweets   for binary classification , where labels de-   note a Tweet as containing hate speech , if   it has a racist or sexist sentiment associated   with it . We created random data splits for   train / validation / test , with 11,634/3,197/4,795   examples , respectively .   •SNIPS ( Coucke et al . , 2018 ): Is a dataset   of crowd - sourced queries collected from the3171   Snips V oice Platform , distributed among 7   user intents . It has been widely adopted   in evaluating spoken language understanding   ( SLU ) systems . We use the same data splits   as Goo et al . ( 2018 ) ; Qin et al . ( 2019 ) , with   13,084/700/700 examples , respectively .   •Youtube Spam Collection ( Badawi et al . ,   2020 ): Is a public data set collected for   spam research from UCI Machine Learning   Repository , where five datasets are composed   by 1,956 real messages extracted from five   videos . As train / validation / test splits are not   provided , we created our own random splits ,   with 1,564/196/196 examples , respectively .   3 Experiments   3.1 Encrypted Sentence Classification   Once sentence embeddings are extracted from   Sentence - BERT for each input text , the vectors con-   sist of 768 numerical values of 32 - bit floating point   from -1 to 1 . Then , a logistic regression model   is trained for binary classification on the Twitter   dataset , and multiclass classification on the SNIPS   dataset , respectively .   To perform a fair comparison of the results of   each approach , we keep the same implementation   of logistic regression for plaintext , as that of the   ciphertext model . Multiclass classification is per-   formed as multiple separate binary logistic regres-   sion models for each class , and we take the argmax   from the combined results ; One - vs - Rest ( OvR ) . Ex-   periments for noise - based local differential privacy   on plaintext are conducted in the same way , using   the privacy mechanism described in Section 2.1.Logistic regression parameters are optimized by   SGD with Nesterov momentum . For all models ,   the best performing model and optimal threshold   for F1 was identified by validation set performance .   For plaintext experiments , the following hyper-   parameters were used for training : Learning rate   3.0 , gamma 0.9 , batch size 256 for Twitter dataset ,   and learning rate 3.0 , gamma 0.1 , batch size 128   for SNIPS dataset . Both models were trained for 10   epochs . For the parameters of the CKKS scheme ,   we selected the dimension N= 2and set the   size of the maximum modulus qto be 1540 bits .   We note that our CKKS parameters satisfy 128-   bit security level ( Albrecht , 2017 ) . For ciphertext   experiments , the following hyperparameters were   used for training : Learning rate 3.0 , gamma 0.9 ,   batch size 512 for Twitter dataset , and learning rate   2.0 , gamma 0.1 , batch size 512 for SNIPS dataset .   Both models were trained for 10 epochs . Addition-   ally , we developed an efficient parallelized CKKS   implementation for bootstrapping with GPU accel-   eration for the encrypted logistic regression model .   For implementation , we use a dual - NVLink Nvidia   Quadro RTX6000 GPU with 24 GiBs of memory ,   on a server with a Intel Xeon Gold 6242R CPU ( 80   core ) and 125 GiBs of RAM .   3.2 Embedding Inversion   As a quantitative evaluation of inversion risk , we   adopt sentence embedding inversion . Introduced   in Song and Raghunathan ( 2020 ) , embedding in-   version is an adversarial attack whose goal is to   recover the original text ( its tokens ) from its em-   bedding . In this work , we focus on black - box in-   version , where the adversary can only interact with   the model by querying it to obtain embeddings , and   is therefore more pertinent to real - world privacy   considerations.3172   4 Results   We report the results of our logistic regression ex-   periments in Table 2 . We compare our approach ,   denoted as Ciphertext , with the Plaintext baseline ,   as well as the noise - based LDP from Qu et al .   ( 2021 ) , at different levels of the noise paramter   η(smaller indicates larger noise ) . Measured by   F1 / AUC metric , our HE classifier achieves roughly   98.79%/99.58 % and98.76%/99.89 % of the plain-   text baseline classifier ’s performance on Twitter   and SNIPS test sets , respectively , indicating that   our HE of embeddings is able to preserve their   downstream utility to a significant degree . We   find that our model performs better at all noise   levels considered in Qu et al . ( 2021 ) ( up to η=   175 ) , nearly matching the plaintext model . On the   other hand , for noise - based LDP , we observe a clear   trade - off between increasing ( via decreasing η ) pri-   vacy protection and classification performance . As   can be seen with η= 50,75on both datasets , the   decrease in performance becomes greater as ηbe-   comes smaller and privacy protection is prioritized .   Moreover , at any reasonable level of η , noise - based   LDP can not necessarily guarantee the complete   elimination of inversion risk .   We next perform sentence embedding inversion   experiments on SNIPS . In Table 3 , we report the   results at varying levels of η , using black - box in-   version with a multi - label classification model as   in Qu et al . ( 2021 ) . For plaintext , the degree of in-   version risk is consistent with black - box inversion   results from Song and Raghunathan ( 2020 ) , who re-   port F1 of 59.76 for inverting BERT - based sentence   embeddings , indicating a high degree of invertibil-   ity . Our results show that , in order to significantly   reduce inversion risk , noise - based LDP requires   lowηsettings , sacrificing downstream utility . In   contrast , our method eliminates conventional risk   of black - box inversion : Because all results of HE   inference remain encrypted , and can not be revealed   without decryption with the user ’s secret key , black-   box inversion can not be applied . Therefore , 128 - bit   security level of homomorphic encryption guaran-   tees practically complete protection from inversion ,   while offering significantly improved performance .   Finally , to directly compare our model with   PrivFT , we conduct an experiment on the YTSC   dataset , following the methodology in Section 3 .   We report the results in Table 4 , along with PrivFT   results on the same dataset from Badawi et al .   ( 2020 ) . We measure the test accuracy of the classi-   fier , as well as the wallclock time required to per-   form encrypted training . We find that our method   requires only 460.81seconds with a single GPU   to achieve 90.8%test accuracy , whereas PrivFT   needs 5.04days with 8GPUs to obtain 86.3%test   accuracy . This amounts to roughly ×9,450 faster   training per epoch , while achieving higher accu-   racy and utilizing 1/8the number of GPUs . These   results experimentally validate our expectation that   homomorphic encryption of pretrained embeddings   significantly improves performance and efficiency .   5 Conclusion   We propose a privatization mechanism based on   homomorphic encryption which , by leveraging   BERT pre - trained embeddings , enables efficient   training of an HE logistic regression classifier with   little to no loss of downstream utility . While our   method compares favorably to noise - based LDP   and PrivFT , we also note that there are some limita-   tions . Since HE based models require higher com-   putation costs compared to plaintext models , the   challenge remains to adopt more complex models ,   such as neural networks , as downstream classifiers .   Nevertheless , the privacy benefits and efficiency   of our method makes it a suitable candidate for   scenarios with real - world privacy concerns.3173Acknowledgements   We would like to show our gratitude to Younggi   Lee and Seewoo Lee from CryptoLab for assis-   tance with the experiments . We also greatly thank   Jeonghwan Kim and Sungwoo Oh from KB Kook-   min Bank who provided the initial research topic   and suggestions for feasiblity in the real - world ap-   plications .   Cheon ’s team was supported by Institute of Infor-   mation & communications Technology Planning   & Evaluation ( IITP ) grant funded by the Korea   government ( MSIT ) [ NO.2020 - 0 - 00840 , Develop-   ment and Library Implementation of Fully Homo-   morphic Machine Learning Algorithms supporting   Neural Network Learning over Encrypted Data ,   50 % ] . Hwang ’s team was supported by Microsoft   Research Asia and IITP [ ( 2022 - 00155958 , High   Potential Individuals Global Training Program ) and   ( NO.2021 - 0 - 01343 , Artificial Intelligence Gradu-   ate School Program ( Seoul National University ) ,   50 % ] .   References31743175