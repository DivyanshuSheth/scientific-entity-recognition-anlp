  Jianing Wang , Chengyu Wang , Minghui Qiu , Qiuhui Shi ,   Hongbin Wang , Jun Huang , Ming GaoSchool of Data Science and Engineering , East China Normal University , Shanghai , ChinaAlibaba Group , Hangzhou , ChinaAnt Group , Hangzhou , ChinaKLATASDS - MOE , School of Statistics , East China Normal University , Shanghai , China   lygwjn@gmail.com , chengyu.wcy@alibaba-inc.com   minghui.qmh@alibaba-inc.com , qiuhui.sqh@antgroup.com   hongbin.whb@@antgroup.com , huangjun.hj@alibaba-inc.com   mgao@dase.ecnu.edu.cn   Abstract   Extractive Question Answering ( EQA ) is one   of the most essential tasks in Machine Reading   Comprehension ( MRC ) , which can be solved   by fine - tuning the span selecting heads of   Pre - trained Language Models ( PLMs ) . How-   ever , most existing approaches for MRC may   perform poorly in the few - shot learning sce-   nario . To solve this issue , we propose a   novel framework named Knowledge Enhanced   Contrastive Prompt - tuning ( KECP ) . Instead of   adding pointer heads to PLMs , we introduce   a seminal paradigm for EQA that transforms   the task into a non - autoregressive Masked Lan-   guage Modeling ( MLM ) generation problem .   Simultaneously , rich semantics from the ex-   ternal knowledge base ( KB ) and the passage   context support enhancing the query ’s represen-   tations . In addition , to boost the performance   of PLMs , we jointly train the model by the   MLM and contrastive learning objectives . Ex-   periments on multiple benchmarks demonstrate   that our method consistently outperforms state-   of - the - art approaches in few - shot settings by a   large margin .   1 Introduction   Span - based Extractive Question Answering ( EQA )   is one of the most challenging tasks of Machine   Reading Comprehension ( MRC ) . A majority of re-   cent approaches ( Wang and Jiang , 2019 ; Yang et al . ,   2019 ; Dai et al . , 2021 ) add pointer heads ( Vinyals   et al . , 2015 ) to Pre - trained Language Models   ( PLMs ) to predict the start and the end positions   of the answer span ( shown in Figure 1(a ) ) . Yet ,   these conventional fine - tuning frameworks heavilyFigure 1 : The comparison of the standard fine - tuning   and prompt - tuning framework . The blocks in orange   and green denote the modules of PLMs and newly ini-   tialized modules , respectively . ( Best viewed in color . )   depend on the time - consuming and labor - intensive   process of data annotation . Additionally , there   is a large gap between the pre - training objective   of Masked Language Modeling ( MLM ) ( i.e. , pre-   dicting the distribution over the entire vocabular-   ies ) and the fine - tuning objective of span selection   ( i.e. , predicting the distribution of positions ) , which   hinders the transfer and adaptation of knowledge   in PLMs to downstream MRC tasks ( Brown et al . ,   2020 ) . A straightforward approach is to integrate   the span selection process into pre - training ( Ram   et al . , 2021 ) . However , it may cost a lot of compu-   tational resources during pre - training .   Recently , a branch of prompt - based fine - tuning   paradigm ( i.e. prompt - tuning ) arises to transform   the downstream tasks into the cloze - style prob-   lem ( Schick and Schütze , 2021 ; Han et al . , 2021 ;   Li and Liang , 2021a ; Gao et al . , 2021 ; Liu et al . ,   2021a ; Assem et al . , 2021 ; Chada and Natara-   jan , 2021 ) . To specify , task - specific prompt tem-   plates with [ MASK ] tokens are added to input texts   ( [ MASK ] denotes the masked language token in3152PLMs ) . The results of the masked positions gener-   ated by the MLM head are used for the prediction .   By prompt - tuning , we can use few training samples   to fast adapt the prior knowledge in PLMs to down-   stream tasks . A natural idea is that we can trans-   form EQA into the MLM task by adding a series   of masked language tokens . As shown in Figure   1(b ) , the query is transformed into a prompt tem-   plate containing multiple [ MASK ] tokens , which   can be directly used for the answer tokens predic-   tion . However , we observe that two new issues   for vanilla PLMs : 1 ) the MLM head , which is   based on single - token non - autoregressive predic-   tion , has a poor inference ability to understand the   task paradigm of EQA ; 2 ) there are many confus-   ing span texts in the passage have similar semantics   to the correct answer , which can unavoidably make   the model produce negative answers . Therefore ,   a natural question arises : how to employ prompt-   tuning over PLMs for EQA to achieve high perfor-   mance in the few - shot learning setting ?   In this work , we introduce KECP , a novel   Knowledge Enhanced Contrastive Prompting   framework for the EQA task . We view EQA as   an MLM generation task that transform the query   to a prompt with multiple masked language tokens .   In order to improve the inference ability , for each   given example , we inject related knowledge base   ( KB ) embeddings into context embeddings of the   PLM , and enrich the representations of selected   tokens in the query prompt . To make PLMs bet-   ter understand the span prediction task , we further   propose a novel span - level contrastive learning ob-   jective to boost the PLM to distinguish the correct   answer with the negatives with similar semantics .   During the inference time , we implement a highly-   efficient model - free prefix - tree decoder and gener-   ate answers by beam search . In the experiments ,   we evaluate our proposed framework over seven   EQA benchmarks in the few - shot scenario . The   results show that our method consistently outper-   forms state - of - the - art approaches by a large mar-   gin . Specifically , we achieve a 75.45 % F1 value on   SQuAD2.0 with only 16 training examples .   To sum up , we make the following contributions :   •We propose a novel KECP framework for few-   shot EQA task based on prompt - tuning.•InKECP , EQA is transformed into the MLM   generation problem , which alleviates model   over - fitting and bridges the gap between pre-   training and fine - tuning . We further employ   knowledge bases to enhance the token rep-   resentations and design a novel contrastive   learning task for better performance .   •Experiments show that KECP outperforms all   the baselines in few - shot scenarios for EQA .   2 Related Work   In this section , we summarize the related work on   EQA and prompt - tuning for PLMs .   2.1 Extractive Question Answering   EQA is one of the most challenging MRC tasks ,   which aims to find the correct answer span from   a passage based on a query . A variety of bench-   mark tasks on EQA have been released and at-   tracted great interest ( Rajpurkar et al . , 2016 ; Fisch   et al . , 2019 ; Rajpurkar et al . , 2018 ; Lai et al . , 2017 ;   Trischler et al . , 2017 ; Levy et al . , 2017 ; Joshi et al . ,   2017 ; Chada and Natarajan , 2021 ) . Early works   utilize attention mechanism to capture rich inter-   action information between the passage and the   query ( Wang et al . , 2017 ; Wang and Jiang , 2017 ) .   Recently , benefited from the powerful modeling   abilities of PLMs , such as GPT ( Brown et al . ,   2020 ) , BERT ( Devlin et al . , 2019 ) , RoBERTa ( Liu   et al . , 2019 ) and SpanBERT ( Joshi et al . , 2020 ) ,   etc . , we have witnessed the qualitative improve-   ment of MRC based on fine - tuning PLMs . How-   ever , this standard fine - tuning paradigm may cause   over - fitting in the few - shot settings . To solve the   problem , ( Ram et al . , 2021 ) propose Splinter for   few - shot EQA by pre - training over the span selec-   tion task , but it costs a lot of time and computa-   tional resources to pre - train these PLMs . On the   contrary , we leverage prompt - tuning for few - shot   EQA without any additional pre - training steps .   2.2 Prompt - tuning for PLMs   Prompt - tuning is one of the flourishing research   in the past two years . GPT-3 ( Brown et al . , 2020 )   enables few / zero - shot learning for various NLP   tasks without fine - tuning , which relies on handcraft   prompts and achieves outstanding performance .   To facilitate automatic prompt construction , Auto-   Prompt ( Shin et al . , 2020 ) and LM - BFF ( Gao et al . ,   2021 ) automatically generate discrete prompt to-   kens from texts . Recently , a series of methods learn3153   continuous prompt embeddings with differentiable   parameters for natural language understanding and   text generation task , such as Prefix - tuning ( Li and   Liang , 2021b ) , P - tuning V2 ( Liu et al . , 2021a ) ,   PTR ( Han et al . , 2021 ) , and many other related   works ( Li and Liang , 2021b ; Qin and Eisner , 2021 ) .   Different from previous work ( Ram et al . , 2021 ) ,   we focus on prompt - based learning for the chal-   lenging low - resource EQA .   3 The KECP Framework   In this section , we formally present our task and   the techniques of the KECP framework in detail .   The overview of KECP is shown in Figure 2 .   3.1 Task Overview   Given a passage P = p , · · · , pand the cor-   responding query Q = q , · · · , q , the goal is   to find a sub - string of the passage as the answer   Y = p , · · · , p , where n , m are the lengths of the   passage , the query , respectively . p(i= 1 , · · · , n )   andq(j= 1 , · · · , m ) refer to the tokens in P   andQ , respectively . k , ldenotes the start and end   position of the passage , 1≤k≤l≤n . Rather   than predict the start and the end positions of the   answer span , we view the EQA task as a non-   autoregressive MLM generation problem . In the   following , we will provide the detailed techniques   of the KECP framework.3.2 Query Prompt Construction   Since we transform the conventional span selec-   tion problem into the MLM generation problem ,   we need to construct prompt templates for each   passage - query pair . In contrast to previous ap-   proaches ( Brown et al . , 2020 ; Gao et al . , 2021 )   which generate templates by handcrafting or neu-   ral networks , we find that the query Qin EQA   tasks naturally provides hints for prompt construc-   tion . Specifically , we design a template mapping   Tbased on several heuristic rules ( please refer   to Appendix A for more details ) . For example ,   the query “ What was one of the Norman ’s ma-   jor exports ? ” can be transformed into a template :   “ [ MASK][MASK][MASK ] was one of the Nor-   man ’s major exports ” . If a sentence does not match   any of these rules , multiple [ MASK ] tokens will   be directly added to the end of the query . The num-   ber of [ MASK ] tokens in prompts is regarded as a   pre - defined hyper - parameter denotes as l .   LetQ = q , q , · · · , qdenote a query   prompt where qis a dispersed prompt token , m   is the length of query prompt . We concatenate the   query prompt Q and the passage text Pwith   some special tokens as input x :   x =[ CLS ] Q [ SEP ] P[SEP ] , ( 1 )   where [ CLS ] and[SEP ] are two special tokens   that represent the start and separate token in PLMs.31543.3 Knowledge - aware Prompt Encoder ( KPE )   As mentioned above , to remedy the dilemma that   vanilla MLM has poor abilities of model inference ,   empirical evidence suggests that we can introduce   the KB to assist boosting PLMs . For example ,   when we ask the question “ What was one of the   Norman ’s major exports ? ” , we expect the model to   capture more semantics information of the selected   tokens “ Norman ’s major exports ” , which is the   imperative component for model inference .   To achieve this goal , inspired by Liu et al .   ( 2021b ) where pseudo tokens are added to the in-   put with continuous prompt embeddings , we pro-   pose the Knowledge - aware Prompt Encoder ( KPE )   to aggregate the multiple - resource knowledge to   the input embeddings of the query prompt . It   consists of two main steps : Passage Knowledge   Injection ( PKI ) and Passage - to - Prompt Injection   ( PPI ) , where the first aims to generate knowledge-   enhanced representations from passage context and   KB , while the second is to flow these representa-   tions to the selected tokens of query prompts .   3.3.1 Passage Knowledge Injection ( PKI )   For knowledge injection , we first introduce two em-   bedding mappings E(·)andE ( · ) , where E ( · )   aims to map the input token to the word embed-   dings from the PLM embedding table , E(·)de-   notes to map the input token to the KB embed-   dings pre - trained by the ConVE ( Dettmers et al . ,   2018 ) algorithm based on WikiData5 M ( Wang   et al . , 2021 ) .   In the beginning , all the tokens in x are en-   coded into word embeddings x. Hence , we can   obtain the embeddings of query prompt and pas-   sage , denote as Q = E(Q ) ∈Rand   P = E(P)∈R. Additionally , for each to-   kenp∈P , we retrieve the entities from the KB   that have the same lemma with p , and the averaged   entity embeddings are stored as their KB embed-   dings . Formally , we generate the KB embeddings   pof the passage token p :   p = Mean ( e|lem(p ) = lem(e)),(2 )   where lem is the lemmatization operator ( Dai et al . ,   2021 ) , e = E(e ) . We then directly com-   bine word embeddings and KB embeddings by   g = p+p , where pis the word embeddingsofi - th token in the passage text . g∈Ris the em-   beddings with knowledge injected . Finally , we ob-   tain knowledge - enhanced representations denoted   asG = gg,···,g , where G∈R.   3.3.2 Passage - to - Prompt Injection ( PPI )   The goal of PPI is to enhance the representations   Qof selected prompt tokens by the interaction   between the query and the passage representations .   As discovered by ( Zhang et al . , 2021 ) , injecting   too much background knowledge may harm the   performance of downstream tasks , hence we only   inject knowledge to the representations of part of   the prompt tokens . To be more specific , given r ( <   m)selected prompt tokens q∈Q , we   create the corresponding embeddings q∈R   by looking up the embeddings from Q. For each   prompt token , we leverage self - attention to obtain   the soft embeddings v∈R :   v = SoftMax ( qWG/√   d)G,(3 )   where W∈Ris the trainable matrix . d   denotes the scale value . We add residual con-   nection to vandqby linear combination as   u = v+q , where udenotes the enhanced   representations of selected prompt tokens .   Finally , we only replace the original word em-   beddings xof selected prompt tokens qwithu   in the PLM ’s embeddings layer . To this end , we use   very few parameters to implement the rich knowl-   edge injection , which alleviate over - fitting during   few - shot learning .   3.4 Span - level Contrastive Learning ( SCL )   As mentioned above , many negative span texts in   the passage have similar and confusing semantics   with the correct answer . This may cause the PLM   to generate wrong results . For example , given the   passage “ Google News releases that Apple founder   Steve Jobs will speak about the new iPhone 4 prod-   uct at a press conference in 2014 . ” and the query   “ Which company makes iPhone 4 ? ” . The model is   inevitably confused by some similar entities . For   examples , “ Google ” is also a company name but is   insight of the entity “ Apple ” in the sentence , and   “ Steve Jobs ” is not a company name although it is   as expected from the answer .   Inspired by contrastive learning ( Chen et al . ,   2020 ) , we can distinguish between the positive   and negative predictions and alleviate this confu-   sion problem . Specifically , we firstly obtain a se-   ries of span texts by the slide window , suppose as3155Y = p···p , where kandldenote the start   and the end positions of the i - th span . Then , we   filter out some negative spans that have similar se-   mantics with the correct answer Y. In detail , we   follow SpanBERT ( Joshi et al . , 2020 ) to represent   each span by the span boundary . The embeddings   that we choose are the knowledge - enhanced rep-   resentations Gin Section 3.3 , which consists of   rich context and knowledge semantics . For each   positive - negative pair ( Y , Y ) , we compute the sim-   ilarity score and the candidate intervals with top- S   similarity scores are selected as the negative an-   swers , which can be viewed as the semantically   confusion w.r.t . the correct answer . For the i - th   negative answer Y , we have :   Z=/summationdisplayPr(Y|P , Q ; Θ),(4 )   where Prdenotes the prediction function of the   MLM head . Ydenotes the j - th token in the corre-   sponding span . We can also calculate the score Z   of the ground truth in the same manner . Hence , for   each training sample , the objective of the span - level   contrastive learning can be formulated as :   L=−1   S+ 1log[exp{Z }   exp{Z}+/summationtextexp{Z } ] ,   ( 5 )   Finally , the total loss function is written as follows :   L = L + λL+γ||Θ|| , ( 6 )   where L denotes the training objective of   token - level MLM . Θdenotes the model parameters .   λ , γ∈[0,1]are the balancing hyper - parameter and   the regularization hyper - parameter , respectively .   3.5 Model - free Prefix - tree Decoder   Different from conventional text generation , we   should guarantee that the generated answer must be   thesub - string in the passage text . In other words ,   the searching space of each position is constrained   by the prefix token . For example , in Figure 2 , if the   prediction of the first [ MASK ] token in Q   is “ fighting ” , the searching space of the second to-   ken shrinks down to “ { horsemen , [ END ] } ” , where   [ END ] is the special token as the answer termi-   nator . We implement a simple model - free prefix-   tree ( i.e. trie - tree ) decoder without any parameters ,   which is a highly - efficient data structure that pre-   serves the dependency of each passage token . At   each[MASK ] position , we use beam search algo-   rithm to select top- Sresults . The predicted text ofthe masked positions with highest score calculated   by Eq . ( 4 ) is selected as the final answer .   4 Experiments   In this section , we conduct extensive experiments   to evaluate the performance of our framework .   4.1 Baselines   To evaluate our proposed method , we consider   the following methods as strong baselines : 1 )   RoBERTa ( Liu et al . , 2019 ) is the optimized ver-   sion of BERT , which introduces dynamic mask-   ing strategy . 2 ) SpanBERT ( Joshi et al . , 2020 )   utilizes the span masking strategy and predicts   the masked tokens based on boundary represen-   tations . 3 ) WKLM ( Xiong et al . , 2020 ) belongs   to knowledge - enhanced PLM , which continue to   pre - trains on BERT with a novel entity replacement   task . 4 ) Splinter ( Ram et al . , 2021 ) is the first work   to regard span selection as a pre - training task for   EQA . 5 ) P - tuning - V2 ( Liu et al . , 2021a ) is the   prompt - based baseline for text generation tasks .   4.2 Benchmarks   Our framework is evaluated over two benchmarks ,   including SQuAD2.0 ( Rajpurkar et al . , 2018 ) and   MRQA 2019 shared task ( Fisch et al . , 2019 ) . The   statistics of each dataset are shown in Appendix .   SQuAD 2.0 ( Rajpurkar et al . , 2018 ): It is a widely-   used EQA benchmark , combining 43k unanswer-   able examples with original 87k answerable exam-   ples in SQuAD1.1 ( Rajpurkar et al . , 2016 ) . As   the testing set is not publicly available , we use the   public development set for the evaluation .   MRQA 2019 shared task ( Fisch et al . , 2019 ): It is   a shared task containing 6 EQA datasets formed in   a unified format , such as SQuAD1.1 ( Rajpurkar   et al . , 2016 ) , NewsQA ( Trischler et al . , 2017 ) ,   TriviaQA ( Joshi et al . , 2017 ) , SearchQA ( Dunn   et al . , 2017 ) , HotpotQA ( Yang et al . , 2018 ) and   NQ ( Kwiatkowski et al . , 2019 ) . Following ( Ram   et al . , 2021 ) , we use the subset of Split I , where the   training set is used for training and the development   set is for evaluation .   4.3 Implementation Details   Follow the same settings as in ( Ram et al . , 2021 ) ,   for each EQA dataset , we randomly choose Ksam-   ples from the original training set to construct the   few - shot training set and development set , respec-   tively . As the test set is not available , we evaluate   the model on the whole development set.3156   In our experiments , the underlying PLM is   RoBERTa - base ( Liu et al . , 2019 ) and the default   hyper - parameters are initialized from the Hugging-   Face . We train our model by the Adam algo-   rithm . The learning rate for MLM is fixed as 1e-5 ,   while the initial learning rate for other new mod-   ules ( self - attention in PPI ) in KECP is set in { 1e-5 ,   3e-5 , 5e-5 , 1e-4 } with a warm - up rate of 0.1 , the   L2 weight decay value is γ= 0.01 . The balance   hyper - parameter is set as λ= 0.5 . The number of   [ MASK ] tokens in query prompts is l = 10 .   The number of negative spans is S= 5 . In few-   shot settings , the definition scope of the sample   number is K∈ { 16,32,64,···,512 } . We set the   batch size and the epoch number as 8 and 64 , re-   spectively . During experiments , we choose five   different random seeds { 12,21,42,87,100}(Gao   et al . , 2021 ) and report the averaged performance .   Because the generated answer text can be easy con-   verted to a span with start and end position , we   follow ( Ram et al . , 2021 ) to use the same F1 met-   ric protocol , which measures the average overlap   between the predicted and the ground - truth answer   texts at the token level .   4.4 Main Results   As shown in Table 1 , the results indicate that KECP   outperforms all baselines with only 16 training   examples . Surprisingly , we achieve 75.45 % and   67.05 % F1 values over SQuAD2.0 ( Rajpurkar et al . ,   2018 ) and SQuAD1.1 ( Rajpurkar et al . , 2016 ) with   only 16 training examples , which outperforms the   state - of - the - art method Splinter ( Ram et al . , 2021 )   by 22.40 % and 12.45 % , respectively . We also ob-   serve that the result of RoBERTawith vanilla   MLM head is lower than any other of PT meth-   ods . It explains the necessity of the improvement   of reasoning ability and the constraints on answer   generation . To make fairly comparison , we also re-   port the results of KECP , which is the basic   model without injected KB . It makes a substantial   improvement in all tasks , showing that prompt-   tuning based on MLM generation is more suit-   able than span selection pre - training . In addition ,   we find that all results of traditional PLMs ( e.g.   RoBERTa ( Liu et al . , 2019 ) and SpanBERT ( Joshi   et al . , 2020 ) ) over seven tasks are lower than   WKLM ( Xiong et al . , 2020 ) , which injects domain-   related knowledge into the PLM . Simultaneously ,   our model outperforms P - tuning V2 ( Liu et al . ,   2021a ) and KECP by a large margin . These   phenomenon indicate that EQA tasks can be further   improved by injecting domain - related knowledge .   4.5 Detailed Analysis and Discussions   Ablation Study . To further understand why KECP   achieves high performance , we perform an ablation   analysis to better validate the contributions of each   component . For simplicity , we only present the3157   ablation experimental results on SQuAD2.0 with   16 , 1024 and all training samples .   We show all ablation experiments in Table 2 ,   where w/o . KPE equals to the model without any   domain - related knowledge ( denotes to remove both   PKI & PPI ) . w/o . PPI denotes to only inject knowl-   edge into selected prompt tokens without trainable   self - attention . w/o . SCL means training without   span - level contrastive learning ( i.e. λ= 0 ) . We   find that no matter which module is removed , the   effect is decreasing . Particularly , when we remove   both PKI and PPI , the performance is decreased   by 12.38 % , 11.73 % and 5.95 % , respectively . The   declines are larger than other cases , which indi-   cates the significant impact of the passage - aware   knowledge enhancement . We also find the SCL   employed in this work also plays an important role   in our framework , indicating that there are many   confusing texts in the passage that need to be effec-   tively distinguished by contrastive learning .   Sample Efficiency . We further explore the model   effects with different numbers Kof training sam-   ples . Figure 3 shows the performance with the dif-   ferent numbers of training samples over the MRQA   2019 shared task ( Fisch et al . , 2019 ) . Each point   refers the averaged score across 5 randomly sam-   pled datasets . We observe that our KECP consis-   tently achieves higher scores regardless of the num-   ber of training samples . In particular , our method   has more obvious advantages in low - resource sce-   narios than in full data settings . In addition , the   results also indicate that prompt - tuning can be an-   other novel paradigm for EQA .   Effects of Different Prompt Templates . In this   part , we design two other template mappings :   •T(None ) : directly adding a series of   [ MASK ] tokens without any template tokens .   •T(Manual ) : designing a fixed template with   multiple [ MASK ] tokens ( e.g. , “ The answer   is[MASK ] · · · ” ) .3158   To evaluate the efficiency of our proposed template   mapping method compared with these baselines ,   we randomly select three tasks ( i.e. , SQuAD2.0 ,   NewsQA and HotpotQA ) and train models with   full data . As shown in Table 3 , we find that two sim-   ple templates have the similar performance . Our   proposed method outperforms them by more than   1.0 % in terms of F1 score .   Hyper - parameter Analysis . In this part , we inves-   tigate on some hyper - parameters in our framework ,   including the number of masked tokens l , the   balance coefficient λand the negative spans sam-   pling number S. We also record the inference time   over a batch with 8 testing examples . As shown in   Table 4 , when we tune l , λandSare fixed as   0.5 and 5 , respectively . Results show that length of   masked tokens plays an important role in prompt-   tuning . We fix l = 10 , S= 5 and tune λ ,   and achieve the best performance when λ= 0.5 .   We fix λ= 0.5 , l = 10 and tune the parame-   terS. We find the overall performance increases   when increasing the sampled negatives . However ,   we recommend to set Saround 5 due to the faster   inference speed .   Effectiveness of Span - level Contrastive Learn-   ing . Furthermore , to evaluate how the model im-   proved by span - level contrastive learning ( SCL ) ,   we randomly select one example from the develop-   ment set of SQuAD2.0 ( Rajpurkar et al . , 2018 ) , and   visualize it by t - sne ( Van der Maaten and Hinton ,   2008 ) to gain more insight into the model perfor-   mance . As shown in Figure 4 , the correct answer   is “ Jerusalem ” ( in red ) . We also obtain 5 negative   spans ( in blue ) which may be confused with the cor-   rect answer . When the PLM is trained without SCL ,   in Figure 4(a ) , we observe that all negative answers   are agglomerated together with the correct answer   “ Jerusalem ” . It makes the PLM hard to search for   the suitable results . In contrast , Figure 4(b ) rep-   resents the model trained with SCL . The result   demonstrates that all negative spans can be better   divided with the correct answer “ Jerusalem ” . This   shows that SCL in our KECP framework is reliable   and can improve the performance for EQA .   The Accuracy of Answer Generation . A major   difference between previous works and ours is that   we model the EQA task as text generation . Intu-   itively , if the model correctly generates the first an-   swer token , it is easy to generate the remaining an-   swer tokens because of the very small search space .   Therefore , we analyze how difficult it is for the   model to generate the first token correctly . Specifi-   cally , we check whether the generated first token   and the first token of the ground truth are within   a fixed window size n. As shown in Table 5 ,   we find the accuracy of our method is lower than   RoBERTa - base ( Liu et al . , 2019 ) when n= 1 .   Yet , we achieve the best performance when increas-   ing the window size nto 5 . We think that our   KECP can generate some rehabilitation text for the   answer . For example in Figure 4 , the PLM may gen-   erate “ the conquest of Jerusalem ” rather than the   correct answer with single token “ Jerusalem ” . This   phenomenon reflects the reason why we achieve   lower accuracy when n= 1 . But , we think that   the generated results are still in the vicinity of the   correct answer .   5 Conclusion   To bridge the gap between the pre - training and fine-   tuning objectives , KECP views EQA as an answer   generation task . In KECP , the knowledge - aware3159prompt encoder injects external domain - related   knowledge into the passage , and then enhances   the representations of selected prompt tokens in   the query . The span - level contrastive learning ob-   jective is proposed to improve the performance   of EQA . Experiments on multiple benchmarks in   both instance - level and task - level few - shot scenar-   ios show that our framework consistently outper-   forms the state - of - the - art methods .   Limitations   Our work addresses the problem of few - shot span-   based EQA only ( a type of MRC tasks in NLP )   based on contrastive prompting . We believe that   prompt - tuning can be applied to other types of   MRC tasks , such as cloze - style MRC and multiple-   choice MRC . We leave it as future work . Another   limitation is that the correct generation of the first   answer token is still not satisfactory , as discussed   in the experiments . We will also improve the per-   formance of KECP by applying controllable text   generation techniques in the future .   Ethical Considerations   Our contribution in this work is fully methodolog-   ical , namely a knowledge - enhanced contrastive   prompting ( KECP ) to boost the performance of   few - shot extractive question answering . Hence ,   there are no direct negative social impacts of our   work .   Acknowledgments   This work has been supported by the National Nat-   ural Science Foundation of China under Grant No .   U1911203 , Alibaba Group through the Alibaba   Innovation Research Program , the National Natu-   ral Science Foundation of China under Grant No .   61877018 , the Research Project of Shanghai Sci-   ence and Technology Commission ( 20dz2260300 )   and the Fundamental Research Funds for the Cen-   tral Universities .   References3160   A The Mapping Rules of Query Prompt   Based on the analysis on the syntactic forms of   queries from SQuAD ( Rajpurkar et al . , 2016 , 2018 )   and the MRQA 2019 shared task ( Fisch et al . ,   2019 ) , we find that the queries in EQA can be di-   rectly transformed into the prompt templates with   multiple [ MASK ] tokens . Let T : s→sbe the   prompt mapping where sandsrepresent the origi-   nal sentence and the prompt template , respectively .   We list four rules for query prompt construction   with corresponding example :   •Rule 1 .T(<s > be / done · · · ? ) → · · ·   [ MASK ] · · · be / done · · · , where < s > can   be chosen among { " what " , " who " , " whose " ,   " whom " , " which " , " how"}.3161   •Rule 2 .T(where be / done · · · ? ) → · · ·   be / done at the place of [ MASK ]   · · · .   •Rule 3 .T(when be / done · · · ? ) → · · ·   be / done at the time of [ MASK ]   · · · .   •Rule 4 .T(why be / done · · · ? ) →the   reason why · · · be / done [ MASK ] · · · .   For the query that does not match these rules will   be directly appended with multiple masked lan-   guage tokens . Table 6 shows the examples of each   mapping rule .   B Data Sources   In this section , we give more details on data sources   used in the experiments .   B.1 The Benchmarks of EQA   We choose two widely used EQA benchmarks for   the evaluation , including SQuAD2.0 ( Rajpurkar   et al . , 2018 ) and the MRQA 2019 shared task ( Fisch   et al . , 2019 ) . Specifically , the MRQA 2019 sharedtask was proposed to evaluate the domain trans-   ferable of neural models , where the authors se-   lected 18 distinct question answering datasets , then   adapted and unified them into the same format .   They divided all datasets into 3 splits , where Split   I is used for model training and development ,   Split II is used for development only and Split   III is used for evaluation . Because our work fo-   cuses on few - shot learning settings , we simply   choose 6 dataset from Split I in our experiments ,   including SQuAD1.1 ( Rajpurkar et al . , 2016 ) ,   NewsQA ( Trischler et al . , 2017 ) , TriviaQA ( Joshi   et al . , 2017 ) , SearchQA ( Dunn et al . , 2017 ) , Hot-   potQA ( Yang et al . , 2018 ) and NQ ( Kwiatkowski   et al . , 2019 ) . We also choose SQuAD2.0 ( Ra-   jpurkar et al . , 2018 ) to conduct evaluations .   In few - shot learning settings , for each dataset ,   we randomly select Kexamples with five differ-   ent random seeds for training and development ,   respectively . For the full data settings , we follow   the same settings of Splinter ( Ram et al . , 2021 ) to   use all training data .   B.2 External Knowledge Base   For the domain - related knowledge base , we use   WikiData5 M ( Wang et al . , 2021 ) , which is a   large - scale knowledge graph aligned with text   descriptions from the corresponding Wikipedia   pages . It consists of 4,594,485 entities , 20,510,107   triples and 822 relation types . We use the   ConVE ( Dettmers et al . , 2018 ) algorithm to pre-   train the entity and relation embeddings . We set   its dimension as 512 , the negative sampling size as   64 , the batch size as 128 and the learning rate as   0.001 . Finally , we only store the embeddings of all3162   the entities . For the passage knowledge injection ,   we use entity linking tools ( e.g , TAGME tool in   python ) to align the entity mentions in passages .   The embeddings of tokens are calculated by the   lemmatization operator ( Dai et al . , 2021 ) .   C Details of Negative Span Sampling   To construct negative spans for span - level con-   trastive learning ( SCL ) , we follow a simple pipeline   to implement confusion span sampling . At first , we   use a sliding window to obtain a series of span texts .   Next , we filter out span texts which are incomplete   sequences or dissatisfy with the lexical and gram-   matical rules . Finally , we calculate the semantic   similarity between each candidate span text and the   true answer . Formally , suppose Y = y , y , · · · , y   is the ground truth . Given one candidate span   X = x , x , · · · , y , where l , lare the lengths   of the ground truth and the candidate span text ,   respectively , we have :   Sim(X , Y ) = dist ( X , Y )   · cos(1   l / summationdisplayy,1   l / summationdisplayy)(7 )   where y , ydenote the knowledge - injected repre-   sentations of i - th token , respectively . cos(X , Y )   aims to compute the cosine similarity between X   andY. We also introduce the dist ( X , Y)func-   tion to represent the normalized position distance   between XandYby the intuition that the text   closer to the correct answer is prone to confusion .   Specifically , for each candidate X , we obtain the   distance between the first token of XandY , and   calculate the normalized weight for each candidate .   For example in Figure 1 , the distance between the   candidate “ avid Crusad ” and the answer “ fighting   horsemen ” is 16 , and the normalized weight is 0.15.We provide a brief ablation study for this module .   Specifically , w/o . SCL means that we remove all   techniques of this module ( setting λ= 0 in Equa-   tion ( 6 ) ) . w/o . filter & sort denotes randomly sam-   pling Sspans without the pipeline . w/o . dist rep-   resents setting dist ( X , Y ) = 1 in Equation ( 7 ) .   As shown in Table 8 , the results demonstrate that   our model can be improved by the combination of   all techniques.3163