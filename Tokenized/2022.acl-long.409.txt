  Cunliang Kong , Yun Chen , Hengyuan Zhang , Liner Yang , Erhong YangSchool of Information Science , Beijing Language and Culture UniversitySchool of Information Management & Engineering ,   Shanghai University of Finance and EconomicsNational Language Resources Monitoring and Research Center Print Media Branch ,   Beijing Language and Culture UniversityBeijing Advanced Innovation Center for Language Resources ,   Beijing Language and Culture University   Abstract   The definition generation task can help lan-   guage learners by providing explanations for   unfamiliar words . This task has attracted much   attention in recent years . We propose a novel   task of Simple Definition Generation ( SDG ) to   help language learners and low literacy readers .   A significant challenge of this task is the lack   of learner ’s dictionaries in many languages ,   and therefore the lack of data for supervised   training . We explore this task and propose a   multitasking framework SimpDefiner that only   requires a standard dictionary with complex   definitions and a corpus containing arbitrary   simple texts . We disentangle the complexity   factors from the text by carefully designing   a parameter sharing scheme between two de-   coders . By jointly training these components ,   the framework can generate both complex and   simple definitions simultaneously . We demon-   strate that the framework can generate relevant ,   simple definitions for the target words through   automatic and manual evaluations on English   and Chinese datasets . Our method outperforms   the baseline model by a 1.77 SARI score on   the English dataset , and raises the proportion of   the low level ( HSK level 1 - 3 ) words in Chinese   definitions by 3.87 % .   1 Introduction   Helping language learners understand words in   doubt is an important topic in the field of Intelligent   Computer - Assisted Language Learning ( ICALL )   ( Segler et al . , 2002 ; Enayati and Gilakjani , 2020 ;   Lolita et al . , 2020 ) . In recent years , researchers   attempted to automatically generate definitions for   words rather than formulating predefined word-   definition inventories ( Ishiwatari et al . , 2019 ; Yang   et al . , 2020 ; Huang et al . , 2021 ) . There are two   reasons for this . Firstly , it can be difficult for users   to distinguish which sense is appropriate in theFigure 1 : Different definitions for advertisement in   the Oxford Dictionary ( OD ) and Oxford Advanced   Learner ’s Dictionary ( OALD ) .   current context because of the cognitively inaccu-   rate nature of discrete sense boundaries ( Rosch and   Mervis , 1975 ; Kilgarriff , 1997 ; Tyler and Evans ,   2001 ) . Secondly , the predefined inventories need   to be updated manually by lexicographers , which   is time - consuming and causes dictionaries to lag   behind the ever - changing language usage .   Different from previous work ( Noraset et al . ,   2017 ; Gadetsky et al . , 2018 ; Mickus et al . , 2019 ;   Kong et al . , 2020 ) that focused only on how to gen-   erate definitions , we further propose a novel task   ofSimple Definition Generation ( SDG ) . Making   the definitions easier to read and understand could   benefit the language learners , low literacy readers ,   as well as helping people with aphasia or dyslexia .   For example , compared with the Oxford Dictionary   ( OD ) , the Oxford Advanced Learner ’s Dictionary   ( OALD ) has simpler definitions , which are specif-   ically designed for language learners . As shown   in Figure 1 , the definition of the word advertise-   ment in OALD does not contain difficult words or   phrases such as announcement andpublic medium .   The goal of SDG task is to generate simple def-   initions for languages that lack learner ’s dictio-   nary . For example , Chinese as Second Language   ( CSL ) learners do not have suitable dictionaries .   As Zhang ( 2011 ) pointed out , since the difficulty of5934definitions is not considered , the existing dictionary   can not meet CSL learner ’s needs .   The SDG task is challenging because it requires   a model to learn from a standard dictionary con-   taining complex definitions and then generate sim-   ple ones , and hence fully unsupervised . A seem-   ingly feasible solution is to generate definitions   first and then simplify them , i.e. , the generation-   simplification pipeline . However , the simplification   task requires dataset with complex - simple sentence   pairs , and such data is also difficult to find in lan-   guages other than English ( Martin et al . , 2020 ) .   Besides , the pipeline methods do not perform well   due to accumulated errors ( Section 6.1 ) .   To solve this dilemma and bridge the gap be-   tween practical needs for simple definitions and   current trivial definition generation systems , we   present a novel method for the SDG task . As illus-   trated in Figure 2 , our method leverages a multi-   tasking framework SimpDefiner to generate sim-   ple definitions by performing three sub - tasks at the   same time , which are definition generation , text   reconstruction , and language modeling tasks . The   framework consists of a fully shared encoder and   two partially shared decoders . We disentangle the   complexity factors from the text by designing a   parameter sharing scheme . Particularly , we share   parameters in Complexity - Dependent Layer Nor-   malization and Complexity - Dependent Query Pro-   jection of the transformer architecture ( Vaswani   et al . , 2017 ) to control the complexity ( Section   3.3 ) . Through joint learning and sharing parame-   ters between the decoders , the SimpDefiner is able   to generate complex and simple definitions simul-   taneously .   Main contributions of our paper are listed below :   •For the first time , we propose the task of SDG   to generate simple definitions without super-   vised training data .   •We propose a multitasking framework Sim-   pDefiner to tackle this task . Through joint   training three sub - tasks , the framework can   generate complex and simple definitions si-   multaneously .   •Both automatic and manual evaluations   demonstrate the effectiveness of SimpDe-   finer . The framework outperforms the base-   line model by 1.77 SARI score on the English   test set . And the proportion of low level words   ( HSK level 1 - 3 ) in generated definitions raised   by 3.87 % on the Chinese test set .   2 Related Work   2.1 Definition Generation   The definition generation task is first introduced   by Noraset et al . ( 2017 ) . Although this task is   proposed as a potentially useful tool for explainable   AI , many subsequent works believe that it can assist   language learning by giving definitions for words   in the text ( Ishiwatari et al . , 2019 ; Mickus et al . ,   2019 ; Yang et al . , 2020 ) .   Various studies attempted to generate multiple   different definitions for polysemous words . Gadet-   sky et al . ( 2018 ) tackled this problem by comput-   ing the AdaGram vectors ( Bartunov et al . , 2016 )   of input words , which are capable of learning dif-   ferent representations at desired semantic resolu-   tions . However , generating different definitions   based on contexts , i.e. , example sentences , became   the mainstream method ( Chang et al . , 2018 ; Reid   et al . , 2020 ; Li et al . , 2020 ; Bevilacqua et al . , 2020 ) .   Among them , some studies used pre - trained lan-   guage models to obtain contextualized embeddings .   Reid et al . ( 2020 ) initialized encoders with BERT   ( Devlin et al . , 2019 ) and employed variational in-   ference for estimation and leveraged contextual-   ized word embeddings for improved performance .   Bevilacqua et al . ( 2020 ) employed a novel span-   based encoding scheme to fine - tune a pre - trained   English encoder - decoder system to generate defini-   tions . Huang et al . ( 2021 ) leveraged the T5 ( Raffel   et al . , 2019 ) model for this task and introduced a5935re - ranking mechanism to model specificity in defi-   nitions .   Our proposed SimpDefiner also takes the given   word and context as input . Differently , our main fo-   cus is to generate definitions with appropriate com-   plexity to better help language learners . Besides ,   our model is based on MASS ( Song et al . , 2019 ) ,   which is a pre - trained encoder - decoder model and   is suitable for generation tasks .   2.2 Sentence Simplification   Researchers usually regard the sentence simplifi-   cation task as a monolingual variant of machine   translation ( MT ) ( Wubben et al . , 2012 ) . Benefiting   from the advancement of neural machine transla-   tion , this task has also made great progress in recent   years .   Lately , many works built upon the Seq2Seq MT   model ( Sutskever et al . , 2014 ) performed well .   First attempted by Nisioi et al . ( 2017 ) , the Seq2Seq   models for this task are able to perform lexical sim-   plification and content reduction simultaneously by   training on complex - simple sentence pairs . This   method was inherited and improved by many sub-   sequent works , such as combining with the rein-   forcement learning method by setting a simplifica-   tion reward ( Zhang and Lapata , 2017 ) , augmenting   memory capacities ( Vu et al . , 2018 ) or training   with multitasking on entailment and paraphrase   generation ( Guo et al . , 2018 ) . Martin et al . ( 2019 )   proposed to prepend additional prompt tokens to   source sentences at train time , which enables the   end - users to condition the simplifications returned   by the model on attributes like length , lexical com-   plexity , and syntactic complexity . This control-   lable simplification system ( called ACCESS ) and   its improved version MUSS ( Martin et al . , 2020 )   achieved SOTA results on the Turk corpus in terms   of the SARI metric ( Xu et al . , 2016 ) .   The generation - simplification pipeline methods   are used as baselines of the SDG task , and we use   both ACCESS and MUSS models for the simplifi-   cation . Unlike the baseline , the SimpDefiner can   generate simple definitions directly , alleviating the   accumulated errors .   2.3 Unsupervised Style Transfer   Style transfer aims to change the style attributes   while preserving the content . Our work is re-   lated to unsupervised style transfer by regarding   the text complexity as one of the style attributes   ( Kawashima and Takagi , 2019).Dumoulin et al . ( 2017 ) demonstrated that the   neural networks can capture the artistic style of   a diversity of paintings . The authors discovered   that adjusting parameters in the layer normaliza-   tion mechanism leads to different artistic styles .   This method permits users to transform images to   arbitrary styles learned from individual paintings .   Jin et al . ( 2020 ) successfully applied this method to   the task of headline generation , allowing the model   to generate headlines of a specific style , such as hu-   morous , romantic or click - baity , in an unsupervised   manner .   By treating the task of simplification as a variant   of style transfer , we borrow the insight of learn-   ing complexity - dependent parameters in the Layer   Normalization mechanism . Additionally , we intro-   duce the language modeling task into SimpDefiner ,   which is to enhance the decoder and make it more   sensitive to text complexity .   3 Method   We integrate three sub - tasks of definition genera-   tion , text reconstruction , and language modeling   into the SimpDefiner . This section first gives a   formal definition of the SDG task , then introduces   each sub - task , and finally the parameter sharing   scheme .   3.1 Task Formulation   The SDG task is to generate a simple definition   dfor a given word and context ( w , c ) , where   c= [ w , . . . , w , . . . , w]is a sentence contain-   ingw . This task is challenging because there is   no corpus like { ( w , c , d)}and hence it is   fully unsupervised .   The only data available in this work in-   clude a standard dictionary dataset G =   { ( w , c , d)}and a simple text corpus Y=   { y } . Note that we use dfor complex defi-   nitions and dfor simple ones .   3.2 Multitasking Framework   We design the three sub - tasks in the SimpDefiner   to learn different abilities . Cooperating with each   other , the entire framework obtains the ability to   compute the conditional probability P(d|w , c )   of simple definitions in a zero - shot manner .   Specifically , the definition generation task aims   to model the probability of a complex definition   given the word and context P(d|w , c)(Sec-   tion 3.2.1 ) . And the text reconstruction task aims5936to model the probability of a simple sentence   given the corrupted version P(y|˜y)(Section 3.2.2 ) .   As we can see , neither task can directly get the   P(d|w , c ) . To solve the problem , we assume   that complexity and semantic information are con-   trolled by different parameters in the decoders , and   we attempt to disentangle the complexity factors   from the text through a carefully designed param-   eter sharing scheme . In the inference stage , we   obtain a simple definition by feeding the encoded   hidden state into the reconstruction decoder as in   Figure 2 . The detailed parameter sharing scheme   is in Section 3.3 .   Nevertheless , the complexity information may   still be kept in some shared parameters , resulting in   the reconstruction decoder fail to generate simple   definitions occasionally . Eliminating the complex-   ity information in all shared parameters is obvi-   ously technically impossible . Instead , we introduce   the language modeling task ( Section 3.2.3 ) to en-   hance the reconstruction decoder and make it more   focused on simple text generation . The experiment   results in Section 6 confirm our assumption .   3.2.1 Definition Generation Task   We follow the mainstream method ( Yang et al . ,   2020 ; Kong et al . , 2020 ; Reid et al . , 2020 ) to con-   catenate the word and context together with a spe-   cial token [ SEP ] as x= ( w;[SEP ] ; c ) . The entire   sequence is then fed into SimpDefiner , and the defi-   nition is obtained by the following language model :   P(d|x;θ ) = YP(d|d , x;θ),(1 )   where dis the t - th token of the definition , and   θis the set of parameters . The model is optimized   using the following loss function .   L(θ ) = −XlogP(d|x;θ)(2 )   3.2.2 Text Reconstruction Task   We corrupt each sentence in the corpus Yby ran-   domly deleting or blanking some words and shuf-   fling the word orders . And then we obtain a new   corpus ˜Y={(˜y , y ) } , and ˜yis a corrupted   version of y. We input ˜yinto SimpDefiner and   obtain yby solving a self - supervised task of   P(y|˜y;θ ) = YP(y|y,˜y;θ),(3)where yis the t - th token of the sentence , and θis   a set of parameters . The loss function of this task   is as follows :   L(θ ) = −XlogP(y|˜y;θ).(4 )   3.2.3 Language Modeling Task   This task facilitates zero - shot generation of   P(d|x)by jointly training the reconstruction   decoder as a language model . Once the model cap-   tures correct complexity that guides the model to   generate the desired simple texts , it ’s more likely   for the model to ignore the wrongly shared com-   plexity information . Similar to Eq . 3 , we have :   P(y|θ ) = YP(y|y;θ ) . ( 5 )   It is equivalent to masking the encoder out and ig-   noring the attention modules between the encoder   and reconstruction decoder . The model is opti-   mized by the following loss function :   L(θ ) = −XlogP(y|θ ) . ( 6 )   Finally , we train the entire SimpDefiner by   jointly minimizing the weighted sum of all above   mentioned loss functions . And the overall loss   function is calculated as :   L = λL+λL+λL , ( 7 )   where λ , λ , λare hyper - parameters .   3.3 Parameter - Sharing Scheme   For parameters in the decoders , we divided them   into two parts , which are complexity - independent   and complexity - dependent parameters . The former   ones are shared between decoders , and the latter   ones are not , as illustrated in Figure 3 .   We now introduce the complexity - dependent lay-   ers , namely Complexity - Dependent Layer Normal-   ization and Complexity - Dependent Query Projec-   tion .   Complexity - Dependent Layer Normalization   Previous works ( Dumoulin et al . , 2017 ; Jin et al . ,   2020 ) demonstrated that the layer normalization is   related to the style of the target texts . We further   argue that as an attribute of style , the complexity   can be retained by independent layer normalization .   Thus , we make the scaling and shifting parameters5937   for layer normalization not shared in both decoders .   This approach is to transform a layer activation x   into a complexity - specific normalized activation z   as :   z = γ(x−µ   σ)−β , ( 8)   where µ,σare the mean and standard deviation of   the batch of x , andγ , βare learnable parameters   specific to complexity c. Note that cis a binary vari-   able indicating different decoders . This mechanism   is used in all decoder layers .   Complexity - Dependent Query Projection The   decoder layers extract information from encoded   hidden states through cross - attention mechanism .   We believe that the required information may vary   for different complexity . Therefore , the parameters   of the linear mapping used for the query transfor-   mation in the cross - attention are not shared among   decoders . This calculation is as follows :   Q=ˆQ·W , ( 9 )   where Wis the query transformation matrix spe-   cific to complexity c. The obtained query vector   Qis then fed into the cross - attention mechanism .   By using this approach , the model can obtain dif-   ferent information from the encoded hidden states   for different complexities.4 Datasets   We evaluate the proposed multitasking framework   on both English and Chinese datasets . Each lan-   guage has a definition generation dataset and a   simple text corpus .   4.1 English Dataset   The English datasets are constructed from the   Oxford Dictionary ( OD ) and Oxford Advanced   Learner ’s Dictionary ( OALD ) . Since the OALD   is for language learners , it has much simpler defi-   nitions than OD . Therefore , we use the OD for the   definition generation training , and use the OALD   for validation of simple definition generation . Note   that the words used for testing are excluded from   the training and validation sets .   For the definition generation dataset , we directly   use the OD dataset published by Gadetsky et al .   ( 2018 ) . The training set has 33,128 words and   97,855 entries . Each entry consists of a triplet   of(w , c , d ) . For testing , we align the words   and context in OD with the definitions in OALD   through manual annotation . The annotated test set   includes 3,881 words and 5,111 entries , which is   used for automatic evaluation in experiments . Each   entry in the test set has both golden complex and   simple definitions from OD and OALD , respec-   tively . Detailed statistics are listed in Table 1 .   We extract the OALD definitions that are not in   the test set for constructing the simple text corpus .   This corpus has 32,395 sentences with an average   length of 12.12 . We list more statistics in Table 2 .   During training , the definition generation dataset   and the simple text corpus are randomly sampled   as mini - batches respectively . And there is no align-   ment between the two mini - batches at each step .   4.2 Chinese Dataset   For the definition generation dataset , we use the   Chinese WordNet ( CWN ) ( Huang et al . , 2010 ) ,   which is a semantic lexicon aiming to provide a   knowledge base of sense distinction . We use the   corresponding words , contexts , and definitions in   CWN for the definition generation task . We split   the entire dataset into training , validation , and test   sets roughly according to the ratio of 8:1:1 . The   training set contains 6,574 words and 67,861 en-   tries . Statistics are listed in Table 1.5938   For the simple text corpus , we extract 58,867   sentences from a number of primary level Chinese   as Second Language textbooks , with an average   sentence length of 14.62 .   Since no suitable dictionary can be used for eval-   uation , there are no golden simple definitions in   Chinese Dataset . In the experiments , we count   the difficulty level of words in definitions to esti-   mate if they are simple . We also organize a manual   evaluation to score the accuracy and simplicity of   definitions .   5 Experiments   This section presents the experimental settings and   evaluation methods .   5.1 Settings   Baselines We compare the SimpDefiner with   generation - simplification pipelines . We first em-   ploy LOG - CaD ( Ishiwatari et al . , 2019 ) and MASS   ( Song et al . , 2019 ) models to generate definitions ,   and then employ ACCESS ( Martin et al . , 2019 )   and MUSS ( Martin et al . , 2020 ) models to sim-   plify them . Thus , we have four different pipeline   baselines . Since these models are not available in   Chinese , we only apply these pipelines to English   datasets . For the Chinese SDG task , we specially   pretrained a MASS - ZH model from scratch using   theChinese Gigaword Fifth Editioncorpus . Note   that we set the learning rate to 3e-4 , warmup steps   to 500 when fine - tuning both MASS and MASS-   ZH.SimpDefiner We use the parameters in the   MASS model to initialize the encoder and two de-   coders in SimpDefiner . For the sentence corruption   in the text reconstruction task , we randomly delete   or blank words with a uniform probability of 0.2 ,   and randomly shuffle the order of words within 5   tokens . For the language modeling task , we set the   input representations to 0and use the simplified   text as the target output . We tune the λparameters   in Eq . 7 on the validation set and adopt the same   hyper - parameters as the baseline for comparison .   We set 5 different random seeds as and report the   average result of multiple runs . Each run takes 7.68   GPU hours on 4 GeFource RTX 2080 Ti GPUs .   5.2 Evaluation   Evaluation of the generated definitions mainly fo-   cuses on two aspects , i.e. , accuracy and simplicity .   We perform both automatic and manual evaluations   for each aspect .   We first introduce these automatic metrics , and   then the manual evaluation method .   BLEU Previous definition generation studies   ( Noraset et al . , 2017 ; Yang et al . , 2020 ; Kong et al . ,   2020 ) used the BLEU ( Papineni et al . , 2002 ) score   to measure the closeness of generated results to   the standard answers , and to evaluate the accuracy   of results . Since the English test set is manually   annotated , we calculate the BLEU score of both   complex and simple definitions , respectively .   Semantic Similarity In addition to the BLEU   score , we use the sentence - transformers toolkit   ( Reimers and Gurevych , 2020 ) to convert the gen-   erated definitions and references into sentence vec-   tors , and calculate cosine similarity between them .   SARI SARI ( Xu et al . , 2016 ) is a lexical simplic-   ity metric that measures how good are the words   added , deleted and kept by a simplification model .   This metric compares the model output to simplifi-   cation references and the original sentence . We use5939   the SARI implementation in the EASSE toolkit .   HSK Level HSK , namely Chinese Proficiency   Test , is set up to test the proficiency of non - native   speakers . It has nine levels , from easy to hard ,   and each level corresponds to a vocabulary . We   count the proportion of words at levels 1 - 3 and   7 + in the generated definitions . The higher the   proportion of words in levels 1 - 3 ( 7 + ) , the easier   ( more challenging ) the definitions are understood .   Manual Evaluation We randomly select 200   words and contexts from the Chinese test set and   let the MASS and SimpDefiner generate definitions   for them one by one . We mix the two generated   definitions and the golden complex definition and   then ask three native - speaker annotators to score   them . Specifically , each annotator evaluates the   definitions on two criteria of accuracy and simplic-   ity . Both criteria have a range of 1 - 3 . For accuracy ,   the annotators are asked to evaluate how semanti-   cally relevant the definitions are to the word . For   simplicity , the annotators are asked to evaluate how   simple the definitions are . After collecting evalua-   tion results , we average the scores as final score .   6 Results and Analysis   6.1 Main Results   Table 3 and Table 4 present the experiment re-   sults on the English and Chinese test sets respec-   tively . Results show that our proposed SimpDe-   finer significantly outperforms baseline methods of   generation - simplification pipelines on both English   and Chinese datasets .   For English results , the performance of simple   definition generation improves 2.1 and 8.46 on the   BLEU and SemSim metrics respectively , and im-   proves 1.77 on the SARI metric . This indicates   that both accuracy and simplicity are effectively   improved comparing with the baseline . We also   observe that complex definition generation also im-   proves by 0.17 on BLEU and 1.09 on SemSim .   This shows that SimpDefiner improves the ability   to generate both complex and simple definitions .   For Chinese results , we compute the HSK Level   metric on generated simple definitions . We can see   that the proportion of low - level ( HSK level 1 - 3 )   words increases by 3.87 % , and that of high - level   ( HSK level 7 + ) words decreases by 0.46 % . The   lexical complexity of the SimpDefiner generated   definitions are significantly reduced .   Besides , we also conduct a manual evaluation   on the Chinese test set , and the results are listed in   Table 5 . From the averaged scores , we observe that   SimpDefiner outperforms MASS by 0.2 in terms   of accuracy ( more accurate ) and 0.18 in terms of   simplicity ( more straightforward ) . On the accuracy   score , all three annotators agree that SimpDefiner   has higher accuracy than MASS , which shows the   superiority of our framework . As expected , the   golden definitions have the highest accuracy in the   table , far exceeding the definitions generated by   the two models . We believe this is caused by in-   sufficient knowledge in the model , and this can be   solved by using larger pretrained models , such as   BART ( Lewis et al . , 2019 ) . On the simplicity score ,   three annotators agree that SimpDefiner generates   simpler definitions than MASS , and two of three   annotators think SimpDefiner generates simpler   definitions than the golden ones .   6.2 Ablation Study   We conduct ablation experiment to demonstrate   the effectiveness of SimpDefiner components and5940   the parameter sharing scheme . For the language   modeling ( LM ) and text reconstruction ( TR ) tasks ,   we ablate them by setting their weights to 0 . For   the layer normalization ( LN ) and query projection   ( QP ) as parameter - shared layers , we ablate them   by sharing their parameters between models . We   illustrate the experiment results in Table 6 .   In general , ablating any of the components or   parameter - shared layers reduces the performance in   terms of simple definitions , which indicates that the   SimpDefiner benefits from both components and   parameter sharing scheme . We also observe that the   performance of ablation experiments have slight   disturbance on complex definitions . But since we   pay more attention to the performance on simple   definitions , we argue that the benefits of SimpDe-   finer far outweigh the losses .   6.3 Analysis on Hyper - Parameters   Furthermore , we conduct additional experiments   on the English dataset to study how hyper-   parameters affect the performance . By setting dif-   ferent λto each model , we observe the relationship   between the performance and these weights .   The experiment results are listed in Table 7 .   From the table , we observe the inconsistency be-   tween metrics . As the definition generation task   weight declines , the BLEU and SemSim metrics   are generally declining , but the SARI metric is in-   creasing . Since the BLEU and SemSim measure   the accuracy and the SARI measures simplicity ,   we consider this phenomenon as a seesaw between   the two attributes of accuracy and simplicity . The   balance between them can be achieved by condi-   tioning the hyper - parameters .   6.4 Case Study   Table 8 shows two generation cases from English   and Chinese test set respectively . In both cases , the   golden definition is a long sentence with quite com-   plicated syntax . The baseline generated definitions   contains difficult words and often wrongly defines   the given word . In the English case , the word com-   mander is defined by the baseline as an officer of   the highest rank in a country , which is incorrect in   most cases . In the Chinese case , the baseline gen-   erated definition contains difficult words like 凭借   ( reference ) and特定事件 ( specific events ) . On the   other hand , the SimpDefiner generates simple and   accurate definitions in both cases .   7 Conclusion   In this work , we propose the SDG task , a novel task   of generating simplified definitions in a zero - shot   manner . To this end , we leverage a multitasking   framework SimpDefiner to tackle this task . We   introduce a text reconstruction task to the frame-   work to control the text complexity , and a language   modeling task to enhance the decoder . For evalu-   ation , we construct a novel test set in English by   manually aligning the two dictionaries of OD and   OALD . The automatic and manual evaluations indi-   cate that the our proposed framework can generate   more accurate and more straightforward definitions   than other models and the generation - simplification   pipelines . In the future , we will try to combine5941the current method with prompt learning methods ,   aiming to let users condition the complexity of gen-   erated definitions .   Acknowledgements   This work was supported by the funds of Bei-   jing Advanced Innovation Center for Language Re-   sources ( No . TYZ19005 ) , Research Project of the   National Language Commission ( No . ZDI135 - 131 )   and National Natural Science Foundation of China   ( No . 62106138 , No . 61872402 ) . We would like   to thank Xiaowan Wang , Chenhui Xie , and Junhui   Zhu for their manual evaluation and all anonymous   reviewers for their valuable comments and sugges-   tions on this work .   References59425943