  Hanhao QuYu CaoJun GaoLiang DingRuifeng XuHarbin Institute of Technology , ShenzhenPeng Cheng Laboratory   { hhqu0917,jgao95}@stu.hit.edu.cn xuruifeng@hit.edu.cnThe University of Sydney , AustraliaJD Explore Academy   { ycao8647,ldin3097}@uni.sydney.edu.au   Abstract   We present IBR , an Iterative Backward Reason-   ing model to solve the proof generation tasks on   rule - based Question Answering ( QA ) , where   models are required to reason over a series of   textual rules and facts to find out the related   proof path and derive the final answer . We   handle the limitations of existed works in two   folds : 1 ) enhance the interpretability of rea-   soning procedures with detailed tracking , by   predicting nodes and edges in the proof path   iteratively backward from the question ; 2 ) pro-   mote the efficiency and accuracy via reason-   ing on the elaborate representations of nodes   and history paths , without any intermediate   texts that may introduce external noise dur-   ing proof generation . There are three main   modules in IBR , QA and proof strategy pre-   diction to obtain the answer and offer guid-   ance for the following procedure ; parent node   prediction to determine a node in the existing   proof that a new child node will link to ; child   node prediction to find out which new node   will be added to the proof . Experiments on   both synthetic and paraphrased datasets demon-   strate that IBR has better in - domain perfor-   mance as well as cross - domain transferability   than several strong baselines . Our code and   models are available at https://github .   com / find - knowledge / IBR .   1 Introduction   Endowing machines with reasoning capabilities is   a longstanding problem ( Newell and Simon , 1956 )   in the field of AI . Though existing tasks such as   multi - hop QA ( Yang et al . , 2018 ; Welbl et al . , 2018 )   or logical - reasoning QA ( Yu et al . , 2020 ; Dua et al . ,   2019 ) impose a higher requirement on the reason-   ing capabilities , they usually just request for an   answer without the reasoning procedure that would   make it interpretable . Recently , Clark et al . ( 2020 )   proposed new datasets and tasks for interpretableFigure 1 : Illustration of generating proof iteratively . Re-   garding the proof path as a graph , and using the question   as the initial node , other nodes and edges will be added   step by step . ( The gold proof is the obtained path in a re-   verse order exclude the question ) . The main challenges   are wrong ( can not derive the answer ) or redundant ( can   derive the answer , but the path is longer than the optimal   one ) branches may be involved .   reasoning . Given a question , coupling with a set of   facts ( plain statements ) and rules ( implication re-   lationships ) that are expressed in natural language ,   there are two tasks : 1 ) predicting the binary an-   swer ; 2 ) generating the proof path behind this an-   swer . Large - scale pretrained models have shown   strong performance on the first subtask in the early   work ( Liu et al . , 2019 ) , but there still remain chal-   lenges for the second one . These proof paths are   usually more complicated than those involved in   multi - hop QA tasks , as there are more nodes and   branches rather than a single - directed chain .   Several approaches have been proposed   to simultaneously address the two subtasks .   PROVER ( Saha et al . , 2020 ) and PROBR ( Sun   et al . , 2021 ) try to construct the reasoning path at   once , where two classifiers are used to determine   whether each node or edge is involved in the proof   path respectively based on corresponding encoded2968representations . But they lack interpretability on   tracking the detailed reason for selecting each   step . To make proof generation more interpretable ,   Proofwriter ( Tafjord et al . , 2021 ) and EVR ( Liang   et al . , 2021 ) decompose complex reasoning over   the question into multiple simple procedures ,   resulting in iterative and interpretable processes   with the help of intermediate texts . Nevertheless ,   both of them suffer from efficiency and external   errors issues . The reason is that they both require   a large searching space , as they perform on the   whole inferable texts and ignore the structure   information from the history path that has been   obtained . Moreover , the generation of intermediate   text is costly and may introduce extra noise   propagation .   Inspired by the top - down AMR parsing ( Cai   and Lam , 2019 ) , where a sentence is divided   into sub - meanings iteratively , we present Iterative   Backward Reasoning ( IBR ) for better proof gener-   ation . It generates a proof path iteratively starting   from the core component for QA , i.e. the question ,   making the process interpretable with trackable in-   termediate states . Regarding a higher efficiency   and accuracy , and two challenges mentioned in   Figure 1 , the proof generation module of IBR sim-   plifies the intermediate process of reasoning as well   as avoids the unnecessary search for a possible un-   suitable branch . To add a new node and edge to the   path , there are two steps in IBR for each iteration :   1 ) finding out the next parent node , i.e. one existing   rule or fact in the parsed history path that a new   node will become its child ; 2 ) determine which   rule or fact that will be the new child node and   added to the path . Equipped with question - aware   representations from a pre - trained encoder , along   with structure - aware node and path features , our   model can choose the optimal endpoint . It accom-   plishes reasoning with the highest possibility to   obtain a correct subsequent proof path based on   relevant features , getting rid of intermediate texts   while avoiding redundancy on all possible texts   than previous iterative works .   In addition , to make IBR applicable for samples   with incomplete proof paths , which are abandoned   in the former backward iterative model EVR ( Liang   et al . , 2021 ) , we employ a proof strategy predic-   tor to output a proof type . This prediction is then   integrated into the later proof generation actions ,   making the process more controllable under differ-   ent conditions . We validate our approach on several datasets   that are widely used in previous studies ( i.e. DU0-   DU5 , Birds - Electricity , and ParaRules ) spanning   different settings ( i.e. fully - supervised , fewer train-   ing data , and out - of - domain ) . Experimental results   show that , compared to existing strong baselines   including both non - iterative and iterative ones , IBR   can achieve the best overall performance of proof   generation and comparable answer prediction accu-   racy , along with noticeable generalization capabil-   ity . Extensive analyses show that 1 ) the improve-   ments come from our elaborately designed iterative   and simplified proof generation modules , and 2 )   both the reasoning ability and latency could be sig-   nificantly improved compared to former iterative   models , making a better trade - off considering its   reasonable interpretability .   2 Related Work   Question answering and reasoning . Endowing   machines to do reasoning over explicit knowledge   is a primitive task ( Newell and Simon , 1956 ) . Early   works tried to solve it by converting texts into logic   forms ( Newell and Simon , 1956 ; Musen and Lei ,   1988 ) . But such kinds of approaches can be af-   fected by the error propagation caused by semantic   parsing ( Zettlemoyer and Collins , 2012 ; Berant   et al . , 2013 ; Berant and Liang , 2014 ) .   Lately , question answering ( QA ) is employed   as an important task for machine reasoning . Nu-   merous datasets were proposed , including synthe-   sized data ( Weston et al . , 2016 ) , comprehension on   natural texts ( Rajpurkar et al . , 2016 ; Joshi et al . ,   2017 ; Fisch et al . , 2019 ) or more complex rela-   tionship reasoning ( Tafjord et al . , 2019 ; Lin et al . ,   2019 ) . There are also multi - hop QA tasks like Hot-   potQA ( Yang et al . , 2018 ) or QAngaroo ( Welbl   et al . , 2018 ) , and logical QA datasets such as Re-   Clor ( Yu et al . , 2020 ) and LogiQA ( Liu et al . , 2020 ) ,   in which textual rules need to be inferred implicitly   from a long supporting context . Plenty of studies   try to solve these problems via neural networks and   achieve remarkable performance ( Joshi et al . , 2020 ;   Yu et al . , 2018 ; Shao et al . , 2020 ) . Nevertheless ,   nearly all of them only focus on the prediction of   final answers and neglect the acquisition of inter-   pretable proofs . Although some datasets provide   proof paths for better interpretability , these paths   are only short chains with very few entities and   can not teach models to generate complex proofs.2969Proof generation . NLProlog ( Weber et al . , 2019 )   first employs logic programming to search for a   proof and then predicts the answer in multi - hop   QA . Recently , Clark et al . ( 2020 ) propose new rule-   based QA datasets for this line of research that in-   clude more complex proof paths , and present Rule-   Taker to answer questions . Saha et al . ( 2020 ) argue   that producing answer proofs makes models more   reliable and propose PROVER , a transformer - based   model that enumerates all possible nodes and edges   of a proof path and predicts whether each one exists   at once based on their embeddings . PROBR ( Sun   et al . , 2021 ) further improves this framework using   the probabilistic graph to model more variables .   There has been also an increasing interest in solv-   ing proof generation iteratively . EVR ( Liang et al . ,   2021 ) splits the question into sub - questions , using   generated intermediate texts to guide proof genera-   tion step by step . ProofWriter ( Tafjord et al . , 2021 )   shares a similar idea but uses intermediate textual   conclusions instead and a more powerful T5 - 11B   model ( Raffel et al . , 2020 ) for generation , which   makes it hard to reproduce . IBR is also an itera-   tive model , being more interpretable than at - once   models . Despite getting rid of intermediate texts   and directly using various representations to finish   each step , it improves efficiency and effectiveness .   3 Methodology   3.1 Task Definition   We first formulate the proof generation task as fol-   lows . Given a tuple ( C , Q , A , P ) , where C=   { RF}is the contexts containing several textual   rules and facts RF , Qis the question , A∈ { True ,   False}is the answer , and Pindicates the proof path   for the detailed reasoning procedure to derive A ,   our goal is twofold : 1 ) predicting the answer A ,   and 2 ) generating the proof path P. Taking DU0-   DU5 ( Clark et al . , 2020 ) dataset as example , Pis   a single - directed acyclic graph having the shortest   path to derive A.Pcan start from one or multiple   nodes but must end in one node that directly entails   or contradicts Q. A node in Pcan be a fact , a   rule , or a special NAF ( Negation As Failure ) node .   Edges between nodes indicate that the start nodes   can be used to prove the end nodes during reason-   ing . Proofs in the dataset can be roughly classified   into two types according to their strategies Sto   prove the question : ( 1 ) Proof : the question can be   directly proven to be True or False using the given   Cand NAF ; ( 2 ) Fail - Proof : the question can not   be explicitly deduced barely using Cand NAF as   some key information is missed , hence a positive   statement is judged as False while a negative state-   ment as True in such cases ( Figure 2 ) .   3.2 Overview   The proposed Iterative Backward Reasoning ( IBR )   model takes Qas the initial node and produce a   proof path Pbackward , from the end node to the   start node . Two actions are included at each itera-   tion : ( 1 ) Predicting the new parent node , i.e. a   node in the derived proof path where a child node   will be added ( except the first step that only Qex-   ists ) ; ( 2 ) Predicting the child node , i.e. the fact   or rule in Cthat will be the child for the selected   parent node . After each iteration , a new node and   an associated edge are added . After obtaining the   whole reasoning path , we remove Qand reverse all   edges to get the final proof P.   The Figure 3 illustrates our IBR model , which   can be divided into three modules , ( 1 ) QA and   Strategy Prediction , ( 2 ) Parent Node Prediction ,   and ( 3 ) Child Node Prediction . In order to make   the question Qcan fully interact with context C   ( facts and rules ) and obtain better representations ,   IBR uses pretrained RoBERTa ( Liu et al . , 2019 ) as   the backbone network . The input of RoBERTa is   the concatenation of the question Qand the context   C={RF } , separated by special [ SEP ] token ,   denoted as [ CLS ] Q[SEP ] [ SEP ] C[SEP ] .   IBR only uses the QA prediction and strategy   prediction modules once at first to predict the an-   swerAand the strategy of the proof ( refer to § 3.1 ,   where the latter one will result in different proof2970   generation procedures . In order to improve the   reasoning efficiency as well as accuracy , instead   of using generated intermediate texts ( Liang et al . ,   2021 ; Tafjord et al . , 2021 ) , all possible nodes ( rules   and facts ) are represented by node embeddings in   IBR . The initial state of the proof is only the rep-   resentation of the question h , then the rest of the   reasoning path will be constructed based on it .   Samples with Fail - Proof strategy differs from   ones with Proof , because their proofs are usually   short without sub - branches , and only consist of   rules due to lacking essential supporting facts . To   take the advantage of such a property distinction   and extend the applicability compared to former   models ( Liang et al . , 2021 ) that can not generate   proofs for Fail - Proof samples , we apply different   actions in modules ( 2 ) and ( 3 ) depending on the   output from strategy prediction .   3.3 QA and Strategy Prediction Module   This module aims to predict the answer Aof the   question Qand the corresponding strategy Sof   proof P. Since the representation of [ CLS ] token   from pretrained models is proven to have the ca-   pability of modeling the whole input , we use it as   the input feature for both predictions as they con-   dition the global information . The encoded [ CLS ]   by RoBERTa , his passed to a linear layer   and the softmax function σfor answer and strategy   classification respectively , P = σ(f(h ) ) ,   P = σ(f ( h ) ) .   Here , fandf indicate the linear layer   for QA classification and strategy classification ,   respectively . PandP are binary - class   probability values , the former one is for values   ofA∈ { True , False } while the later one is for   values of S∈ { Proof , Fail - proof } .   3.4 Parent Node Prediction Module   This module determines which node in the cur-   rent reasoning path is going to be the next parent   node that a new child node will link to . To bet-   ter represent the sequential information of each   possible node ( fact or rule ) , an LSTM ( Hochreiter   and Schmidhuber , 1997 ) is used to further encode   the token - level embedding from RoBERTa . The   hidden state in the last step is used as the textual   representation hof a possible parent node RF .   In addition , selecting a node from the existing   proof path also needs global and structural model-   ing on the history path . To make this procedure a   more convenient representation that involves the   order of reasoning , the path is regarded as a tree   structure and nodes are reordered by level traver-   sal from top to down . Since Qis always the root   node of the tree , e.g. , if Qhave two children RF   andRF , and RFhas a child RF , the reordered   representation sequence is [ h , h , h , h ] . We   then utilize another LSTM model to encode the2971reordered representation sequence of the current   reasoning path obtained before , extracting the over-   all state of the path , which is the hidden state hat   the last time step in this LSTM .   A parent node attention based on the Trans-   former attention ( Vaswani et al . , 2017 ) is used to   obtain the weights of all possible parents nodes .   It takes hand the representation sequence of the   current path H= [ h , h. . . h]as input , i.e.   Att(h , H ) = σ(f(h)(f(H))/√   d),(1 )   where fandfindicate linear layers , σis a soft-   max function , and dis the dimension of h. As   we discussed in § 3.2 , different operations are em-   ployed for corresponding strategy types of proofs .   1 ) If the predicted proof strategy is Proof , we se-   lect the node with the highest weight as the parent   node RF . 2 ) If the predicted proof strategy is   Fail - proof , we use the last node in the current path ,   i.e.hinH , as the parent node RF , because no   sub - branch is included in such proof paths .   3.5 Child Node Prediction Module   This module decides which node will be added   to the proof path and linked to the parent node   RFwe have obtained before . To derive the rep-   resentations of candidate child nodes , similar to   § 3.4 , we apply another LSTM model to the en-   coded RoBERTa embeddings and get hforRF .   Since we discussed a special NAF node in § 3.1   which may contain information from the whole   context , we utilize a linear layer f to trans-   form the [ CLS ] token embedding hinto its   representation h . Moreover , we initialize a   representation h for the special END node ,   indicating that the proof generation process will   finish here .   During selecting the new child node , we need   to consider not only the knowledge of the history   path , but also the state of the parent node . To bet-   ter model such relationships , we propose a Path   Focus Selection module to generate relevant fea-   tures before predicting the child node . A 2 - layer   Transformer model along with a LSTM model is   introduced . It first encodes the representations of   node sequence Hfrom Parent Node Prediction re-   spectively , then fuses their hidden state via a linear   layer f ,   h = f([Trans ( h , H , H ) ; LSTM ( H ) ] ) .   ( 2)Here , his the representation of the selected par-   ent node in § 3.4 , fis the linear layer for feature   fusing , while [ · ; · ] stands for concatenation . q , k , v   inTrans ( q , k , v ) indicate the inputs corresponding   to Query , Key , and Value in a transformer model ,   and only the hidden state in the last time step is   remained in both Trans andLSTM . It is worth   noting that the LSTM used here is a supplementary   knowledge source for a better representation ac-   cording to our empirical study . Such an operation   results in a feature hthat is aware of both the   history proof path and the parent node that a child   will link to .   This feature hwill then be used in the Child   Node Attention to calculate the attention weights   on all possible child nodes . Particularly , an atten-   tion model same as Eq . 1 is applied on hand a   series of child node representations obtained be-   foreH= [ h. . . h , h , h ] , and the   attention weights are defined as Att(h , H ) . It   contains all facts and rules in the context , and the   special NAF node as well as END node .   Similar to § 3.4 , we also apply different actions   according to our predicted proof strategies before .   ( 1 ) If the strategy is Proof , we select the child node   with the highest attention weight from all candi-   dates as the new node in the proof path .   ( 2 ) If the strategy is Fail - proof , since RFis the   last node during reasoning and this procedure is   a first - order logical under such a situation , there   is no need to make complex modeling on the de-   rived path . Therefore , we directly use its parent   node representation hrather than encoded state   from Transformer in Eq . 2 to get h. But LSTM   is remained to maintain some basic modeling capa-   bility on the path . In child node attention , we mask   all fact nodes and select the one with the highest   weight among the remaining nodes , because this   kind of proof usually only contains rules and such   masking can avoid extra errors .   3.6 Training and Inference   The whole model is trained via binary cross-   entropy losses from all three above modules jointly ,   L = L+L + L + α∗L .   LandL correspond to the loss of QA   prediction and strategy prediction , respectively . α   is a hyperparameter to reweigh the influence of   [ CLS ] token . L is the loss for parent node   prediction , where the cross - entropy is calculated   between the attention weight vector and a one - hot2972vector indicating the gold parent node . L is in   a similar way on child node prediction . Note that   samples labeled as Fail - proof strategy are not in-   volved in the training of parent node prediction . As   all their proof paths are chains and the new parent   node is always the last node added to the path , so   learning about these data may introduce model bias .   To determine the gold reasoning order used as the   target for training , we set a higher priority of fact   nodes than rule nodes , as the clearer subject infor-   mation is involved in facts . E.g. , for a parent node   with multiple children , the gold reasoning order of   child node prediction is NAF nodes first , then fact   nodes , and finally rule nodes . If there are more than   one fact or rule nodes , IBR randomly swaps their   order within each type at different training epochs .   During inference , IBR first makes predictions   on the answer Aand strategy S , then generate the   parent node and child node iteratively , until the   special END node is predicted as the new child   node . IBR uses beam search to keep the top - K best   proof paths at each proof generation step and select   the best one as the final prediction , where the beam   size is set as 8 .   4 Experiments   Following former studies ( Saha et al . , 2020 ; Sun   et al . , 2021 ) , we evaluate our IBRon three datasets   and four settings including fully - supervised train-   ing , training using fewer samples , testing on out - of-   domain samples , and generalization to more com-   plex proofs or language .   4.1 Setup   Datasets . Experiments are conducted on three   datasets raised by Clark et al . ( 2020 ) , where we   use the same test split as previous works for fair   comparison :   •DU0 - DU5 : Five synthesized datasets created by   translating hand - crafted rules and formal language   to natural language . It is divided by the highest   depth of proof , where DU stands for " Depth Upto "   ( DU=0,1,2,3,5 ) . Data in higher DU values also   contain samples with lower depth . Note that proofs   in DU0 only have one supporting or opposing fact .   All related results are reported on DU5 test split .   •Bird - Electricity : It is a test - only dataset that   contains samples about birds and electric circuits . It is generated in the same way as DU0 - DU5 , but   is in different domains from DU0 - DU5 .   •ParaRules : This dataset consists of 40k ques-   tions expressed in paraphrased natural language   based on synthetic data , which is created by crowd-   sourcing . Multiple facts get together in one state-   ment here rather than separated in DU0 - DU5 .   Baselines . We consider the following baselines .   •RuleTaker ( RT ) ( Clark et al . , 2020 ): a RoBERTa   based model that only predicts answers .   •PROVER ( PV ) ( Saha et al . , 2020 ): a method   that treats the proof as a graph and predicts all   its nodes and edges at once , also using RoBERTa   model as the backbone , same as IBR .   •PROBR ( PB ) ( Sun et al . , 2021 ): it improves   PROVER by introducing the probabilistic graph   that jointly considers the answer , nodes and edges .   •EVR ( Liang et al . , 2021 ): an iterative model that   predicts the next proof item by generating textual   sub - questions based on logical operator . Note that   this model is not applicable for samples whose   proof strategy is Fail - proof discussed in § 3.1 , so   we make comparison with it separately .   Metrics . We closely follow previous works to   evaluate the performance of models via answer pre-   diction ( QA ) accuracy and proof generation ( PA )   accuracy . Since some samples may have multiple   gold proofs , a generated proof will be considered   correct , as long as its nodes and edges match with   the nodes and the edges in any of the gold proofs .   Full Accuracy ( FA ) is also included , where a sam-   ple is regarded as correct only both the predicted   answer and proof are correct .   4.2 Results under Fully - Supervised Training   We train IBR on the training split of the DU5   dataset and evaluate on the test split of DU5 . We   compare the performance of IBR with baselines ex-   cept for EVR in Table 1 , while with EVR in Table 2   where only partial test split is included , excluding   samples whose proof strategy is Fail - proof . Be-   cause EVR always fails on these samples ( EVR on   these excluded samples is given in Appendix A.5 ) .   Obviously , IBR achieves the best proof gener-   ation accuracy ( PA ) as well as full accuracy ( FA )   among all baseline models , on samples with every   depth . Our model also shows a greater advantage   on samples with deeper proof path , e.g. , 81.7 vs.2973   72.2 on PA when depth is 5 , illustrating the supe-   riority of iterative models on complex proof paths .   Besides , despite not being the best in answer accu-   racy ( QA ) , there is a very narrow gap between our   model and the best one , which proves that IBR is   still a comprehensive model covering both subtasks .   When compared to EVR , also an iterative model ,   IBR shows significantly stronger performance on   all metrics , benefiting from our elaborate two - fold   reasoning process at each step .   4.3 Using Fewer Training Samples   We also explore the performance of IBR when train-   ing using fewer data , ranging from 10k to 30k to   all the examples ( 70k ) in DU5 . The comparison   between our model , PROVER ( PV ) , and PROBR   ( PB ) is shown in Table 3 , in all three metrics . Our   model significantly has the best proof generation   performance than the other two baselines in all   cases , due to the iterative architecture requiring less   global modeling capability and thus fewer training   samples . Although PB shows a promising answer   prediction accuracy under fewer - data settings , the   performance of IBR is close to it while better than   PV , e.g. , 94.3 vs. 87.1 under 10k . In addition , in   Table 4 , we also compare with EVR under the same   settings but using a different test set that excludes   Fail - proof samples . EVR outperforms IBR under   the 10k setting for proof generation , but IBR is   stronger if more training samples are available .   4.4 Evaluation of Out - of - Domain Data   We further test the out - of - domain performance of   IBR against baselines on Birds - Electricity dataset   to evaluate their robustness , where B1 and B2 are   two sets from the birds domain , and E1 - E4 are   four sets from the electricity domain . Results are   shown in Table 5 and Table 6 . Note that Fail - proof   samples are still not involved in the comparison for   EVR . Overall , our IBR achieves 2.5 % promotion   in PA while an equivalent result on QA , compared   to PROVER . Despite being the best one on QA ,   PROBR is also defeated by IBR on both PA and FA .   In addition , our model shows more improvement   on the hardest E3 and E4 subsets , which further   verifies its robustness . When it comes to EVR , we   can find its cross - domain capability is relatively   weak as it sees a significant drop in PA , and IBR   is superior to it without any doubt . Because the   cross - domain generation for intermediate texts is   much harder , our usage of high - level node features   to finished reasoning can alleviate this challenge .   4.5 Generalization Ability   Generalize to higher depths . Following the pre-   vious work ( Sun et al . , 2021 ) , we test the general-2974   ization ability of IBR by first training the model on   the training splits of DU0 , DU1 , DU2 , and DU3 ,   then test them on the test split of DU5 with deeper   proof paths respectively . Results are shown in Ta-   ble 7 . We notice that all models suffer performance   degeneration especially when the proof depth of   the training set is lower , because it is hard for the   model to learn complex reasoning based on sim-   ple proof paths . However , IBR still realizes the   best performance in terms of PA and FA , especially   onDU3 , where it gets 4.2 % PA / FA promotion to   PROBR and even outperforms PROVER trained   on the whole DU5 data . These observations again   prove that iterative approaches can better learn the   detailed reasoning step by step , obtaining a better   generalization capability than at - once models .   Generalize to complex language . We also eval-   uate whether IBR can be applied to samples where   questions and statements are expressed in more   human - like natural language . Following Clark et al .   ( 2020 ) , we train models on the combined training   partitions of DU3 and ParaRules then test them on   the ParaRules test set . To our best knowledge , it   is the dataset that is closest to real - world applica-   tions . Table 8 demonstrates that our model sees a   slight promotion in PA / FA while a similar accuracy   as PROVER in QA , indicating that IBR still has   good applicability when doing reasoning on more   complicated and natural texts .   5 Analysis   5.1 Ablation Study   To explore the effects between different compo-   nents in our model , we consider the following abla-   tions : 1 ) IBR + Gold - Parent : given the gold parent   nodes during inference to explore the accuracy of   child node prediction ; 2 ) IBR + Gold - Child : given   the gold child nodes to verify the accuracy of par-   ent node prediction ; 3 ) w / oQA : removing QA task   in loss to check its impact on proof generation ; 4 )   w / onode LSTM : using mean pooling rather than   LSTM encoding to get the representations of nodes ;   5)w / ofocus LSTM : Removing the supplementary   LSTM in path focus selection .   Results on the whole DU5 test split are given   in Table 9 . As the numeric performance shows,2975   giving either gold parent nodes or gold child nodes   can benefit the performance especially the later   one . This signifies that our parent node prediction   achieves promising accuracy while the prediction   of child nodes can be further improved . Moreover ,   IBR can still learn to generate proofs without super-   vision from answers . And LSTM encoders attribute   to a better representation of both the nodes and the   path that has been derived .   5.2 Latency Analysis   To demonstrate the computational efficiency of   IBR , we compare the per sample inference time   of IBR with EVR , also an iterative proof genera-   tion model , on the test split of DU5 . Additionally ,   we also compare the per sample inference time   of IBR with PROVER and PROBR , both at - once   models . All models are tested on one NVIDIA   Tesla - V100 GPU with the same batch size and   the beam size of IBR sets to 1 for a fair comparison .   As shown in Figure 4 , our IBR could achieve up to   ×119.5 speedup compared with EVR , benefiting   from our reasoning based on node and path features   rather than intermediate texts . It is also noticeable   that the runtime of EVR grows linearly with depth ,   while such an effect is slight on our model . Because   EVR needs to infer on all contexts at every step , but   IBR uses a simplified parent node prediction based   on the derived path . Figure 5 illustrates that IBR   is also faster than PROVER because PROVER has   some constraints during post - processing in infer-   ence , like ensuring proof connectivity , which takes   extra time .   6 Conclusion   This paper presents IBR , a proof generation model   via iterative backward reasoning for rule - based QA   tasks . We equip the reasoning procedure with de-   tailed hidden state tracking by predicting nodes   and edges in the proof path iteratively backward   from the question , and allow the model to reason   on the elaborate representations of nodes and his-   tory paths . Our model is more interpretable than   previous at - once models , and is also more effective   and efficient than former iterative models . Exper-   iments also demonstrate the superiority of IBR to   various baselines on proof generation under various   settings .   Acknowledgements   This work was partially supported by the National   Natural Science Foundation of China ( 61876053 ,   62006062 , 62176076 ) , the Shenzhen Foundational   Research Funding JCYJ20210324115614039 ,   Shenzhen Science and Technology Program   JSGG20210802154400001 , and the Joint Lab of   HITSZ and China Merchants Securities .   References297629772978A Appendix   A.1 Implementation Details   Parameter Value   Training Epochs 8   Optimizer AdamW   Batch Size 16   RoBERTa Learning rate 1e-5   QA and Strategy Pre Learning rate 1e-5   Parent Node Pre Learning rate 2e-4   Child Node Pre Learning rate 5e-4   All LSTM Learning rate 1e-3   Dropout Rate 0.1   LSTM hidden state for parent node1024and child node encoding   LSTM hidden state for path encoding1024 in parent node prediction   Transformer hidden state in path1024focus selection   LSTM hidden state in path focus256selection   Seed 42   We implement our model based on PyTorch   along with Huggingface - Transformers toolkit . We   use RoBERTa modelas our backbone en-   coder to generate token - level representations . Ta-   ble 10 shows the implementation details of IBR ,   including learning rates for different modules . All   linear layers used in our model have one layer . The   model trained after 8 epochs will be used in the   evaluation . We remove functional words without   lexical meaning like " a " and " the " from facts , rules ,   and questions to shorten the input length , so each   training epoch takes about 2 hours . We select these   hyper - parameters according to tuning them empiri-   cally based on the performance . All experiments   are run on NVIDIA Tesla - V100 GPUs . The main   experiment performance of IBR fluctuates by one   point .   A.2 Dataset Details   We next introduce the details of the three datasets   used in our experiment . All of them are firstly ap-   plied in rule - based QA and proof generation tasks   in Clark et al . , 2020 .   DU0 - DU5 : A series of synthesized datasets   where rules and facts are all generated via manually   designed logical programming , while questions are   generated by combining random logical operations   among them . Data are divided into 5 subsets ac-   cording to their maximum reasoning depth ( D ) in   the proof path , D = 0 , 1 , 2 , 3 , 5 . There are 100k   questions in each subset , where 70k / 10k / 20k   samples in the train / validation / test partition re-   spectively . D = 0 means that the question can be   proven directly using a fact in contexts . In our ex-   periment in § 4 , we only use the data from DU5 for   testing because it covers all possible depths , while   the train set is the train split in DU5 except § 4.5 ,   where we use train split from DU0 , DU1 , DU2 and   DU3 for training . We provide some statistics of   DU5 in Table 11 .   Birds - Electricity : It is a set of data that only   contains 5k test samples for the evaluation of ro-   bustness and out - of - domain performance of mod-   els . The Birds data only require reasoning up to   depth 1 and 2 ( B1 and B2 ) , while Electricity data   have reasoning depths ranging from 1 to 4 . Both of   them include new vocabulary that is not included   in DU0 - DU5 .   ParaRules : A more challenging dataset contains   paraphrased samples on the synthesized ones via   crowdsourcing . It has 40k questions against about   2k theories . The statements are expressed in a   more natural way , posing a discrepancy between   DU0 - DU5 . It has 28k / 4k / 8k samples in the   train / validation / test split respectively . In § 4.5 ,   we combine it with the extensive DU3 for training,2979resulting in a train set containing 119k samples .   A.3 Possible Limitations of Our Model   Since our strategy prediction module and opera-   tions corresponding to different strategies in node   prediction modules are specially designed for the   current datasets , we may need to redesign some   specific operations to reach the best performance ,   if some novel proof types are included in new   datasets . But we believe our architecture will still   take effect without modification . Besides , the inter-   pretability of IBR is not so strong as former works   like EVR that make use of intermediate texts .   A.4 Strategy Accuracy of IBR   D Cnt Strategy Accuracy   0 6299 99.9   1 4434 99.1   2 2915 99.3   3 2396 99.0   4 2134 99.2   5 2003 99.7   All 20192 99.4   We provide the strategy prediction accuracy on   DU5 in Table 12 . It proves that IBR is also well   able to make predictions on the proof strategies .   This is partly due to RoBERTa ’s powerful repre-   sentation capability . On the other hand , there is a   certain connection between the answer to the ques-   tion and the strategy , and there are some common   elements at the semantic representation level that   can be learned together .   A.5 Performance of EVR and IBR on   Fail - proof Samples   As we have discussed in § 4.2 , EVR ( Liang et al . ,   2021 ) is not applicable for samples containing Fail-   proof proofs , because it can not obtain proper in-   termediate questions to proceed correct following   reasoning . Here , we compare our model with EVR   on these samples in DU0 - DU5 , as illustrated in   Table 13 . Although EVR can achieve promising   performance on answer prediction ( QA ) for these   samples , it can not generate any correct proof path   in such cases , which have already been discussed   in its original paper .   A.6 Proof Generation samples   We provide some proof generation samples in Fig-   ure 6 for a better understanding of this task , where   questions , all contexts , and the proof path gener-   ated by our IBR are given ( all consistent with the   given labels).29802981