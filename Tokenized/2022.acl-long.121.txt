  Abelardo Carlos Martínez Lorenzo , Marco Maru , and Roberto NavigliSapienza NLP Group   Sapienza University of RomeBabelscape , Rome   first.lastname@uniroma1.it , surname@babelscape.com   Abstract   A language - independent representation of   meaning is one of the most coveted dreams   in Natural Language Understanding . With this   goal in mind , several formalisms have been   proposed as frameworks for meaning represen-   tation in Semantic Parsing . And yet , the de-   pendencies these formalisms share with respect   to language - specific repositories of knowledge   make the objective of closing the gap between   high- and low - resourced languages hard to ac-   complish . In this paper , we present the Ba-   belNet Meaning Representation ( BMR ) , an in-   terlingual formalism that abstracts away from   language - specific constraints by taking advan-   tage of the multilingual semantic resources of   BabelNet and VerbAtlas . We describe the ra-   tionale behind the creation of BMR and put   forward BMR 1.0 , a dataset labeled entirely   according to the new formalism . Moreover , we   show how BMR is able to outperform previous   formalisms thanks to its fully - semantic framing ,   which enables top - notch multilingual parsing   and generation . We release the code at https :   //github.com / SapienzaNLP / bmr .   1 Introduction   Natural Language Understanding ( NLU ) enables   machines to understand human language . A key   enabling task in NLU is that of Semantic Pars-   ing , whose longed - for dream is that of developing   a formalism that can be used as an interlingual   representation of meaning , i.e. , one that , indepen-   dently of the language , can explicitly embed sen-   tence meaning into a machine- and human - readable   form ( Navigli , 2018 ) . To this end , different for-   malisms such as Abstract Meaning Representation   ( Banarescu et al . , 2013 , AMR ) , Universal Concep-   tual Cognitive Annotation ( Abend and Rappoport ,   2013 , UCCA ) and Universal Meaning Represen-   tation ( Van Gysel et al . , 2021 , UMR ) , have been   proposed over the years .   As of now though , AMR is the most popularformalism for Semantic Parsing , being widely ap-   plied to a variety of areas of NLP , such as Machine   Translation ( Song et al . , 2019 ) , Question Answer-   ing ( Lim et al . , 2020 ; Bonial et al . , 2020b ; Kapani-   pathi et al . , 2021 ) , Human - Robot Interaction ( Bo-   nial et al . , 2020a ) , Text Summarization ( Hardy and   Vlachos , 2018 ; Liao et al . , 2018 ) and Information   Extraction ( Rao et al . , 2017 ) .   The primary precept of AMR is that different   sentences carrying the same meaning should have   the same graph representation . Nonetheless , a   few inherent properties of AMR make it inappro-   priate for the purpose of providing a language-   agnostic representation of meaning . In fact , nodes   within AMR graphs are represented by means of   either English lemmas or OntoNotes frames ( Hovy   et al . , 2006 ) which , in turn , are based on PropBank   ( Kingsbury and Palmer , 2002 ) . The issue with lem-   mas is that they are merely surface forms devoid of   semantics , whereas , with respect to frames , even   though analogous repositories exist in other lan-   guages such as AnCora for Spanish ( Aparicio et al . ,   2008 ) or the Chinese PropBank ( Xue and Palmer ,   2009 ) , they are not mutually interlinked , hence   making the cross - lingual application of AMR ardu-   ous to achieve ( Conia et al . , 2021 ) .   Against this background , we follow the ideas put   forward by Navigli et al . ( 2022 ) and develop the Ba-   belNet Meaning Representation ( BMR ) , a formal-   ism providing the building blocks for a language-   agnostic representation of meaning by exploiting   the wealth of multilingual knowledge contained   in BabelNet ( Navigli and Ponzetto , 2010 ; Nav-   igli et al . , 2021)and VerbAtlas ( Di Fabio et al . ,   2019 ) .   In outline , the main contributions of this paper   are as follows : ( i ) we introduce BMR , a new Se-   mantic Parsing formalism that can be used as an   interlingua , ( ii ) we produce BMR 1.0 , i.e. , the first1727lexical - semantic dataset annotated according to the   BMR formalism , ( iii ) we create and release models   that can generate BMR graphs from text and text   from BMR graphs in English , German , Spanish ,   and Italian , and ( iv ) we describe a sound experi-   mental setup to show how , thanks to its fully se-   mantic framing , BMR outdoes previous formalisms   in both preserving and encoding textual informa-   tion , as well as in being used as an interlingua in   downstream tasks such as Machine Translation .   2 Related Work   Even though the vast majority of formalisms for   Semantic Parsing have been designed with English   in mind , several approaches have attempted to nar-   row the gap between English and other languages .   For instance , Universal Conceptual Cognitive An-   notation ( Abend and Rappoport , 2013 , UCCA ) was   proposed as a cross - lingual annotation formalism in   which words in a sentence are connected using se-   mantic relations not tied to specific languages . And   yet , while UCCA reflects the semantic relations be-   tween nodes via a set of coarse - grained roles , it rep-   resents concepts by means of simple lemmas , hence   preventing an abstraction from language - specific   constraints . Parallel Meaning Bank ( Abzianidze   et al . , 2017 , PMB ) , an approach based on the Dis-   course Representation Theory ( Kamp and Reyle ,   1993 , DRT),also emerged . In PMB , English sen-   tences are parsed with labels that are automatically   projected to non - English translations . PMB too ,   however , can not be seen as a unified interlingual   representation , since it uses English - specific mean-   ing repositories .   As regards Abstract Meaning Representation   ( Banarescu et al . , 2013 , AMR ) , instead , several   approaches have tried to adapt it for cross - lingual   use . As a case in point , Xue et al . ( 2014 ) analyzed   the viability of tailoring the AMR formalism to fit   other languages by making use of language - specific   repositories similar to PropBank ( Aparicio et al . ,   2008 ; Xue and Palmer , 2009).On a different note ,   Damonte and Cohen ( 2018 ) and Blloshmi et al .   ( 2020 ) attempted to adopt AMR as an interlingual   formalism , despite its English - centric nature , by   assuming that the AMR graph of an English sen-   tence is also representative of translations of that   sentence in other languages . Once again , theseapproaches testify to the limits of AMR as an inter-   lingua , given the drawbacks of dealing with struc-   tural divergences among different languages . In   recent years , Zhu et al . ( 2019 ) have recommended   abstracting the AMR formalism away in order to   reduce its language - specific complexity by preserv-   ing just the predicate roles and relations that con-   stitute the core semantic information of sentences .   Conversely , rather than decreasing the complexity   of AMR , the Universal Meaning Representation   ( Van Gysel et al . , 2021 , UMR ) extends it by in-   cluding new features that render the formalism less   tied to a specific language . In particular , UMR en-   riches the verbal predicates with information about   grammatical aspect and scope , while introducing   temporal and modal dependencies at the document   level . Finally , it enhances AMR to use it as a cross-   lingual formalism by employing language - specific   repositories and relations . Yet , the focus of UMR   is that of providing languages with the necessary   resources to parse texts , rather than being an inter-   lingual representation .   In contrast to previous approaches , and thanks   to the multilingually - shared word meanings and se-   mantic roles taken from the interlinked repositories   of BabelNet ( Navigli et al . , 2021 ) and VerbAtlas   ( Di Fabio et al . , 2019 ) , we put forward BMR , a   formalism that fully detaches from syntax and thus   stands as a lexical - semantic representation that is   able to bring different languages together .   3 Preliminaries   To accomplish the goal of an interlingual meaning   representation , we disconnect our formalism from   language - specific constraints of any kind . To this   end , we draw on resources that inherently connect   word meanings and predicate - argument structures   across languages , i.e. , BabelNet and VerbAtlas .   BabelNet ( Navigli et al . , 2021 ) is a multilingual   encyclopedic dictionary and semantic knowledge   base in which concepts are represented as synsets   ( sets of synonyms that convey the same meaning ) ,   linked via semantic relation edges like hypernymy   or meronymy . BabelNet was built by the aggre-   gation of several knowledge resources including   WordNet ( Fellbaum , 1998 ) , Wikipedia and Wik-   tionary , resulting in a remarkable ontology of con-   cepts and named entities covering 500 languages .   Given its versatility , which makes it suitable for a   wide range of tasks across languages , we employ   its most recent version 5.0 as a tool to switch the1728   focus of Semantic Parsing formalisms from words   to multilingual concepts .   VerbAtlas ( Di Fabio et al . , 2019 ) is a manually-   curated lexical - semantic inventory that collapses   the BabelNet verbal synsets into around 450   semantically - coherent frames , each defining pro-   totypical argument structures via human - readable   relationships ( e.g. AGENT , THEME ) . Thanks to its   linkage to BabelNet , VerbAtlas represents the best   option for handling predicate - argument relations in   BMR in a language - independent manner .   4 BabelNet Meaning Representation   Like AMR , BMR embeds the semantics of a sen-   tence in a directed acyclic graph , with nodes and   edges connecting them . However , where AMR re-   lies on English lemmas and OntoNotes frames to   represent nodes and relations ( see Figure 1 ) , BMR   disposes of language - specific constraints , and em-   ploys multilingual concepts and self - explanatory   semantic roles ( see Figure 2).In what follows   ( Sections 4.1 to 4.4 ) , we will describe and detail   the features that make BMR stand out with respect   to a widely - employed Semantic Parsing formalism   such as AMR , as well as their integration into the   AMR 3.0 dataset ( Knight et al . , 2020 ) to produce   the BMR 1.0 dataset .   4.1 Self - explanatory Semantic Relations   As briefly mentioned in Section 1 , AMR derives   its coarse - grained frames and argument structuresfrom the English PropBank section of OntoNotes ,   a repository which is circumscribed to the English   language and that features semantic relations that   are both predicate - specific and largely unintelli-   gible without a gloss . For example , in Figure 1 ,   the subgraph representation of students ’ parents   is pivoted on the frame have - rel - role-91 ,   where the relations : ARG0 , : ARG1 , and : ARG2   identify the first entity , the second entity , and the   role of the first entity , respectively . As importantly ,   even though language - specific repositories simi-   lar to PropBank have been used to annotate non-   English sentences with structures comparable to   those of AMR ( Aparicio et al . , 2008 ; Xue and   Palmer , 2009 ) , there is not an exact one - to - one   mapping between the frames they define , meaning   that , e.g. , the frame have - rel - role-91 might   not be featured in the other inventories . Therefore ,   with the aim of overcoming language specificity ,   we replace PropBank with VerbAtlas as an alter-   native repository of predicate - argument structure   information , which , as explained above , inherently   accounts for multilingually - shared semantics .   To build the BMR 1.0 dataset , we exploit the   mapping provided by Di Fabio et al . ( 2019 ) , which   links VerbAtlas frames and arguments to PropBank ,   and use it to replace the original frames and se-   mantic roles in the AMR 3.0 dataset with those of   VerbAtlas ( e.g. , the frame take-01 corresponds   toMOVE_BY_MEANS_OF in VerbAtlas , and its   ARG0 toAGENT ) . However , this mapping is in-   complete and , as a result , several predicates found   within AMR 3.0 can not be transitioned directly .   Among these , two kinds of predicates can be identi-   fied , ( i ) predicates that OntoNotes labels as verbal ,   and ( ii ) non - verbal predicates and special predi-   cates which AMR uses to define special semantic   structures ( e.g. , have - rel - role-91 ) . To deal   with these predicates , we asked a linguistto create   a mapping between PropBank and VerbAtlas for   the missing verbal predicates , and , with respect to   the others instead , to map them to BMR adapting   previous semantic roles and creating new ones to   better accommodate their argument structures .   4.2 Node Merging   Multiword expressions and idioms are rendered   word by word in AMR , using node composition.1729   Nevertheless , such an approach is not feasible for   an interlingual representation , since the overall   meaning of an expression can not , as a general rule ,   be compositionally inferred from the meanings of   its individual words . Therefore , in BMR we make   use of the available BabelNet synsets to identify   the meaning of a multiword expression or idiom ,   and hence we represent it with a single node . As   a case in point , the idiom at the last minute which ,   according to Wiktionary , is defined as “ very close   to a deadline or potential crucial event ” , does not   entail that something will happen precisely inthe   last minute . This exact expression , that in AMR   3.0 is represented using two nodes ( mandl ) as :   ( m / minute : mode ( l / last ) )   appears in BMR as a single node m :   ( m / at _ the_last_minute / bn : 00114428 r )   As a result , we are both able to ( i ) abstract away   from language - specific lexicons making use of con-   cepts connected across languages and , concurrently ,   to ( ii ) reduce the graph density , hence easing the   computational burden for systems .   Another intrinsic limit of AMR as an interlingual   representation is that , since the meaning of nodes   can only be partially identified using OntoNotes   frames , AMR maximizes their usage so as to ex-   press as many concepts as possible , even non-   verbal ones . The main reason this constitutes an   issue is that the OntoNotes frame composition used   to define a concept and the concept itself are not   semantically equivalent . For example , the con-   cept of student , which AMR represents as “ a per-   son who studies ” by means of the connection be-   tween the node of person with the OntoNotes framestudy-01 , is arguably different from the defini-   tion of student as , quoting the BabelNet synset   gloss , “ a learner who is enrolled in an educational   institution ” . Additionally , these language - specific   rules are not transferable across languages , and   they are not consistent even within AMR itself , as ,   whenever a verbalization is not viable ( AMR does   not render professor as “ a person who professes ” ) ,   the word is included in the graph as it is .   In the remainder of this Section , we describe the   strategies by means of which we remodel AMR 3.0   to obtain BMR 1.0 employing node merging .   Multiword Expression Identification To merge   nodes , we must first identify the words or multi-   word expressions that are represented by several   nodes in the AMR graph . In this regard , we proceed   by lemmatizing the original sentences in AMR 3.0   using the 3.1 version of the SpaCy software library   ( Honnibal and Johnson , 2015 ) . At this stage , for   each sentence , we check for the longest concate-   nations of lemmas that match a BabelNet synset   lexicalization in BabelNet 5.0 . Once the expres-   sions have been identified , we use the automatic   AMR aligner of Flanigan et al . ( 2014 ) to get the   alignments between the tokens in the original sen-   tence ( and , consequently , the identified words and   multiwords ) and the graph nodes .   Manual Validation The automatic identification   of multiwords can be noisy and lead to poor node   merging choices which , in turn , can result in wrong   sense attributions . For instance , in the sentence   “ the rest of the world knows the same ” , the multi-   word rest of the world is identified , even though   its only meaning in BabelNet is that of “ a team   of players from many countries ” , which is clearly1730not appropriate in the reported context . To address   this issue , we asked our expert linguist to manually   inspect all of the automatically detected multiword   instances within the AMR 3.0 dataset in order to   maintain , modify or delete them .   Graph Conversion Finally , using the multi-   words and the alignments derived from the previous   steps , we navigate the AMR graphs bottom - to - top   and collapse together nodes referring to the same   word or multiword expression ( i.e. , first reducing   nodes closer to the graph leaves and then moving   towards the graph root ) .   As a result , we move from the original figure of   936,769nodes of AMR 3.0 to 828,483 in BMR   1.0 , reducing the graph density by a notable 11.6 % .   4.3 Number , Tense and Aspect   Even though AMR is able to encode textual infor-   mation in its semantic structure , its formalism does   not account for the inclusion of word components   that are crucial for understanding meaning , and   that languages express via the grammatical cate-   gories of number , tense and aspect . This , along   with the fact that the importance of incorporating   such details in Semantic Parsing formalisms has al-   ready been stressed in the literature ( Donatelli et al . ,   2018 ; Bonial et al . , 2019 ) , leads us to implement   these features to further enhance the representative   power of BMR . To this end , we employ SpaCy in   order to retrieve the Penn Treebank part - of - speech   tags ( Marcus et al . , 1993 ) , which inherently pro-   vide information with respect to number , tense , and   aspect , for all the words and multiword expressions   aligned with a node in the graphs . In practice , we   account for tense by enriching each verbal node   with the semantic role : timing showing a value   of+or−to indicate events that will take place in   the future or that happened in the past , respectively .   Similarly , we handle plurality of the nominal nodes   by adding the : quantity relation followed by   a+value ( see Figure 2 ) . Lastly , we account for   aspect by adding the relation : ongoing followed   by a + mark to verbal nodes expressing the imper-   fective aspect ( ongoing or usual actions ) .   4.4 Graph Disambiguation   An interlingual representation of meaning has the   basic requirement of being fully linked to an in-   ventory of meanings which can be expressed in   multiple languages . For this reason , in order to   make nodes in BMR graphs language - independent , we enhance them with BabelNet synsets informa-   tion . An example of why this is needed is provided   in Figure 1 , where the predicate take-01 em-   ployed in AMR is defined in OntoNotes with the   very coarse - grained gloss of “ take , acquire , come   to have , choose , bring with you from somewhere ,   receiving , internalizing , bringing along , enacting ” ,   and the ambiguous word plane is merely repre-   sented as a lexical node , which provides no cues   for understanding whether it refers to an airplane ,   a geometric plane , or a carpenter ’s plane , inter alia .   Moreover , the combination of the two does not clar-   ify whether “ take the plane ” means “ to take a flight ”   or “ to take the carpenter ’s plane somewhere ” .   Lacking a pointer to a more fine - grained and   multilingual word sense inventory also has the dis-   advantage of preventing the use of the formalism   as a means of moving across languages effectively .   For example , if the word parents is not assigned   the proper word sense , it would lead to ambiguous   translations in languages such as Spanish , where   the corresponding word padres can indicate both   the meaning of “ parents ” , but also the meaning   of “ fathers ” . Therefore , the advantages that come   from the disambiguation of nodes with BabelNet   are twofold : ( i ) resolving language ambiguity while   representing word meaning explicitly , and ( ii ) inter-   connecting the same meanings across languages .   Adding the disambiguation information to AMR   3.0 graphs is our last step in order to complete its   conversion to BMR 1.0 . To this end , we employ a   set of different strategies : ( a ) we exploit the map-   ping from VerbAtlas frames to BabelNet synsets   to assign word senses to nodes based on their lem-   mas , ( b ) , we use the Wikipedia page information   featured in AMR nodes representing named enti-   ties to retrieve the corresponding synset BabelNet   identifies that page with , and ( c ) , we make use   of ESCHER ( Barba et al . , 2021),a state - of - the-   art system for Word Sense Disambiguation , i.e. ,   the task of automatically assigning a meaning to   a word in context ( Bevilacqua et al . , 2021b ) , to   disambiguate the nodes without word senses .   As a result , we succeed in assigning a BabelNet   synset to an overall figure of 92 % AMR content   nodes ( i.e. , nodes aligned with content words ) , with   42,549fully disambiguated graphs out of 59,255.17315 Experimental Setup   To demonstrate the importance of BMR ’s semantic   framing , its aptness at preserving lexical informa-   tion , and its effectiveness in acting as an interlin-   gual representation , we devise three experiments to   assess its performance in comparison with AMR .   Before delving into their details ( Section 5.2 ) , as   well as describing our models and the evaluation   measures we employ ( Sections 5.3 and 5.4 , respec-   tively ) , we first provide thorough information re-   garding the datasets used in our experiments .   5.1 Datasets   Aside from the original AMR 3.0 and BMR 1.0   datasets described in Section 4,the following   datasets are employed in our experiments , namely :   ( i ) AMR + , which features the set of enhancements   applied to the English AMR 3.0 , as described from   Section 4.1 to 4.3 ( excluding node disambiguation ) ,   and ( ii ) BMR * , i.e. , a version of BMR 1.0 that does   not include lemma information .   For each dataset , we also create language-   specific versions in German ( DE ) , Italian ( IT ) and   Spanish ( ES ): starting from the English AMR 3.0 ,   we followed Blloshmi et al . ( 2020 ) and create train-   ing and development sets for these languages by us-   ing gold AMR graphs – and their converted AMR + ,   BMR and BMR * versions – and pairing them with   silver sentences translated with the machine trans-   lation models of Tiedemann and Thottingal ( 2020 ,   OPUS - MT ) . As test data , we use the 1,371parallel   sentences of Abstract Meaning Representation 2.0   - Four Translations , that translate into our set of   non - English languages their English ( EN ) counter-   parts ( a subset of AMR 3.0 ) found in the AMR 2.0   test split .   5.2 Tasks   Graph - to - Text ( GtoT ) Our first experiment con-   cerns the Graph - to - Text generation task , i.e. , the   task of transforming graph meaning representations   into their corresponding text , and has the goal of   appraising the effectiveness of BMR as a tool for   generating texts in different languages . In this con-   text , we also conduct an ablation study on AMR + to assess the individual impact brought about by   each feature described in Section 4 .   Text - to - Graph ( TtoG ) Our second experiment   deals instead with the Text - to - Graph generation   task ( Semantic Parsing ) , i.e. , the task of generating   a graph according to a given formalism , starting   from raw text . The aim of TtoG is to assess the   complexity of generating BMR graphs compared   to AMR ones .   Text - to - Graph - to - Text ( TGT ) Finally , in the   third experiment , we evaluate the suitability of   AMR and BMR to be used as interlingual repre-   sentations by means of the combination of Text-   to - Graph and Graph - to - Text parsing going from a   source to a target language . In the same context , we   also conduct an ablation study on BMR to assess   the impact of the disambiguation in the graphs .   5.3 Models   All models employed in our experiments are built   on top of SPRING ( Bevilacqua et al . , 2021a ) , an   auto - regressive model for AMR parsing and gen-   eration based on the BART ( Lewis et al . , 2020 )   pretrained language model . Since the original   SPRING works with pairs of sentences and lin-   earized versions of the graphs , we modify its tok-   enizer to account for BMR nodes , since they con-   tain BabelNet synset IDs too . Furthermore , we add   all synsets that appear more than oncewithin   BMR 1.0 to the model ’s vocabulary and adapt   SPRING to the mBART language model ( Liu et al . ,   2020 ) in order to account for multiple languages in   the GtoT and TGT experiments .   Given the datasets described in Section 5.1 ,   we confront models trained on AMR 3.0 , BMR   1.0 , AMR + and BMR * for each language   ( AMR / BMR / AMR + /BMR * ) . As re-   gards the ablation study of the GtoT experiment ,   we apply each modification introduced to AMR   3.0 one at a time , and obtain several versions of   the dataset , each of which is used to train ad-   ditional models , namely , AMR 3.0 ( i ) including   self - explanatory relations ( AMR ) , ( ii ) includ-   ing self - explanatory relations and node merging   ( AMR ) , ( iii ) featuring the number category   ( AMR ) , ( iv ) featuring the tense and aspect cat-   egories ( AMR ) , and ( v ) featuring the number ,   tense and aspect categories together ( AMR).1732   5.4 Evaluation Measures   To evaluate the text generation tasks ( i.e. , GtoT   and TGT ) , we use five standard Natural Language   Generation measures , namely , BLEU ( Papineni   et al . , 2002 ) , chrF++ ( Popovi ´ c , 2017 ) , METEOR   ( Banerjee and Lavie , 2005 ) , and ROUGE - L ( Lin ,   2004 ) , tokenizing system predictions with the   JAMR script ( Flanigan et al . , 2014 ) . For the TtoG   experiment , instead , as is customary , we employ   the Smatch measure ( Cai and Knight , 2013 ) .   6 Results   6.1 GtoT   Results for the GtoT experiment are reported in   Table 1 . As can be seen , BMR obtains the high-   est scores for all the measures across the board ,   testifying to its effectiveness at generating text in   multiple languages . Interestingly , when BMR is   confronted with AMR + , the benefits of featuring   disambiguation information immediately becomeevident , with highest scores on each measure .   Results for the ablation study are , instead , shown   in Table 2 . Even though the impact of self-   explanatory relations is not striking in this scenario   ( AMR model ) , the use of node merging al-   ready leads to an evident performance boost , par-   ticularly for BLEU and ROUGE - L ( AMR ) .   Not surprisingly , the addition of the grammatical   categories of number , tense , and aspect to AMR   3.0 corroborates the thesis of Donatelli et al . ( 2018 )   and Bonial et al . ( 2019 ) , with results for the dif-   ferent measures growing between 1.3to4.2points   for AMRcompared to the baseline AMR   model . Moreover , demostrating the beneficial in-   teraction of all features described in Section 4 ,   the AMR + model significantly outperforms the   baseline model by 1.7points on METEOR ( low-   est ) and 5.0points on BLEU ( highest ) , while also   outscoring each other model featuring only specific   modifications .   6.2 TtoG   Results for this experiment are shown in Table 3   and provide evidence for the high degree of com-   plexity that BMR graphs have in comparison to   their AMR counterparts . In particular , AMR +   ( which , except for the disambiguated nodes , has   the same graph structure as BMR ) outperforms   BMRby3.5Smatch points , demostrating that   the extra layer represented by the inclusion of   disambiguation information makes BMR graphs   harder to generate automatically starting from raw   text . As a matter of fact , a model attempting to gen-   erate BMR graphs needs to provide disambiguation   for each node ( and not just for the verbal predi-   cates ) , hence it faces a much more difficult task .   6.3 TGT   Finally , in Table 4 we report the scores for the TGT   experiment , by means of which we appraise the   capability of formalisms to act as bridges to trans-   late sentences , first , performing a Text - to - Graph   step , and then a Graph - to - Text one . Despite having   shown lower performances in comparison to AMR1733   in the TtoG experiment , the high scores obtained by   BMR in this experiment demonstrate that it is bet-   ter suited as an interlingua . Nevertheless , AMR +   outperforms BMR in a few settings , likely due to   the higher complexity entailed by BMR parsing , as   explained in Section 6.2 . Corroborating this the-   sis are the results shown in Table 5 , where BMR   scores are compared against a model ( AMR+ * ) in   which , to perform the Graph - to - Text step , AMR+   uses a BMR parser with the synset information re-   moved , rather than its own parser . The outcome of   this ablation study , with BMR now systematically   outscoring its competitor , sheds further light upon   the effectiveness of synset - driven disambiguation   for encoding valuable sentence information .   Returning to the results given in Table 4 , even   though performances for BMR * models are the   lowest ( yet competitive , and sometimes higher than   AMR ) on the board , it is worth remarking that this   setting does not feature the lemma information . In   fact , in order to be purely semantic , BMR graphs   should solely feature the BabelNet synset infor-   mation . However , given that state - of - the - art Se-   mantic Parsing and generation models make use   of pre - trained language models such as BART and   mBART , which are trained with data in human lan-   guage ( hence devoid of synset information ) , the   performance of fully - semantic models drops if lem-   mas are not taken into account . Additionally , cur-   rently available text generation metrics are sub-   optimal when employed to assess semantics , since   these measures evaluate similarities at the lemma   level . Therefore , though a fully - semantic modelcould infer the meaning of a BabelNet synset , its   performances will be penalized for not generating   specific lemmas while outputting perfectly suitable   synonyms . In view of this , BMR 1.0 incorporates   the lemma information along with the BabelNet   synset specifying its meaning ( see also Appendix   A ) , demostrating that lexical - semantic representa-   tions improve over purely lexical ones .   7 BMR * : A Case Study   Results for the experiments we conducted depict   BMR * as the model that , on the whole , achieves the   lowest scores . With the aim of showing how such   results might arise due to inadequate evaluation   measures ( see Section 6.3 ) , we propose a focused   case study in which we qualitatively inspect the dif-   ferences between graphs and sentences generated   by means of the AMR and BMR * models . Starting   from the sentence “ My friend did not tolerate his fa-   ther ’s behaviour ” ( Figure 3 ) , it can be seen how the   grammatical categories of number and tense for the   words friend andtolerate are correctly preserved by   BMR * only . Additionally , it can be noted how the   complex structure that defines child in AMR can   confuse the model when there is a reentrant node   ( in this case , the model does not know to whom   the father is related ) . As interestingly , the sentence   generated via BMR * replaces tolerate with the syn-   onym put up with , which worsens its performance   according to exact string matching metrics , but , at   the same time , provides an insight of a higher level   of abstraction when lemmas are omitted .   8 Error Analysis   Although the experiments reported in Section 5 tes-   tify to the quality of BMR , following an in - house   behavioral analysis inspired by the work of Ribeiro   et al . ( 2020 ) , we identify three main classes of er-   rors that undermine the application of BMR as an   interlingua , one concerning the formalism ( reposi-   tory contraints ) , one tied to the data contained in   the BMR 1.0 dataset ( disambiguation constraints ) , 1734and one concerning the language - specific lexicons   ( language - specific constraints ) .   Repository constraints BabelNet features a   wealth of synsets covering content words in a mul-   tilingual setting , but , at the same time , does not pro-   vide information regarding parts of speech other   than nouns , verbs , adjectives and adverbs . As a   result , BMR uses language - specific lemmas to rep-   resent conjunctions or ambiguous pronouns such as   anyone , which can mean either “ not a single person ”   or “ everyone ” , depending on the use of negative or   positive phrasing . On a different note , with roughly   6,500 languages spoken in the world and Babel-   Net 5.0 featuring a subset of them , the definition of   BMR as an interlingua is actually constrained to the   number , albeit large , of 500 BabelNet languages .   Disambiguation constraints The creation of   BMR 1.0 is based upon the Word Sense Disam-   biguation task carried out via a state - of - the - art sys-   tem ( Barba et al . , 2021 , ESCHER ) . And yet , this   neural architecture is trained to predict word senses   featured in the WordNet 3.0 sense inventory only .   By virtue of the fact that , following the node merg-   ing strategy ( Section 4.2 ) , we can obtain polyse-   mous multiwords found in BabelNet but not in   WordNet ( as is the case of run off at the mouth ) , we   can not provide disambiguation for such instances .   This justifies the fact that 8 % of content nodes in   BMR are not disambiguated ( see also Section 4.4 ) .   Language - specific constraints The number of   items in a lexicon and the degree of word polysemy   vary from language to language ( Talmy , 2000 ) . Us-   ing BabelNet synsets to represent abstract concepts   and connect them multilingually is certainly a de-   sirable feature . However , there are concepts and   expressions that exist in a given language only , e.g. ,   owing to their being culturally connoted . For ex-   ample , the Spanish word espeto , which refers to a   traditional way of cooking freshly - caught sea fish ,   has no equivalent in English . Though the concept   is featured in BabelNet , it has no lexicalizations in   other languages and , as such , it would need to be   paraphrased in order to be rendered .   9 Conclusion   Current Semantic Parsing formalisms share tight   dependencies with semantic repositories which   are both language - specific and isolated from word   senses in other languages . As a result , they are   not fit to be used as interlingual representations of   meaning . In this paper , we put forward BMR , a   new language - independent formalism that abstracts   away from language - specific constraints thanks to   two multilingual semantic resources , namely , Ba-   belNet and VerbAtlas . To put our formalism into   practice , we also created BMR 1.0 , the first dataset   labeled according to BMR .   Our experiments demostrate the impact that the   fully - semantic framing of our formalism has in   comparison to the widely - employed formalism of   AMR , as well as showing its ability to be a better   tool at encoding textual information , and a much   more effective interlingua in a text - to - graph - to - text   machine translation task .   As future work , we plan to ( i ) create a sin-   gle multilingual model to parse graphs and gen-   erate text in any language , ( ii ) apply BMR cross-   lingually to other downstream tasks such as text   summarization , ( iii ) evolve the formalism to pre-   vent the inclusion of lexical information of any   kind . We make our code and data available to   the research community at https://github .   com / SapienzaNLP / bmr .1735AcknowledgmentsThe authors gratefully acknowledge   the support of the ERC Consolida-   tor Grant MOUSSE No . 726487 ,   the Marie Skłodowska - Curie project   Knowledge Graphs at Scale ( Know-   Graphs ) No . 860801 , and the   ELEXIS project No . 731015 under   the European Union ’s Horizon 2020   research and innovation programme . References1736173717381739A Reading BMR Graphs   The BMR formalism renders graphs in a text-   friendly fashion following the AMR custom .   Specifically , edges are represented by means of   standardized semantic relations names preceded   by a colon ( e.g. : agent , or its inverse relation   : agent_of ) , and nodes are identified by triplets :   ( i d / lemma / Babel synset i d )   Left to right , the triplet shows : ( i ) the unique iden-   tifier ( i d ) of the node,(ii ) the lemma for the word   ( or multiword expression ) in the original sentence ,   and ( iii ) the BabelNet synset i d taken from Babel-   Net 5.0 that is assigned to disambiguate the node .   Lastly , node hierarchy in BMR is represented by   means of open and closed round brackets , and spe-   cial characters such as + indicate special features   of some nodes , such as , e.g. , grammatical tense   information . Figure 4 shows an example of a BMR   graph ( bottom ) in comparison to the AMR graph   ( top ) for the same sentence , in text - friendly format .   B Semantic Roles in BMR   Semantic roles in BMR ( Table 6 ) are largely based   on the VerbAtlas inventory and have been mod-   ified to account for non - verbal entities drawing   inspiration from property lists available in the liter-   ature ( Dixon , 2010 ; Leone et al . , 2020 ) . Similarly   to AMR , each relation has its inverse , expressed   by appending _ of to it ( e.g. , : purpose versus   : purpose_of ) . Roles in AMR which are not   listed in Table 6 are preserved in BMR ( e.g. , : age ,   : degree , : frequency or : manner ) .   CAMR 3.0 to BMR 1.0 Manual Mapping   Examples   Non - verbal predicates , as well as special predi-   cates found within AMR 3.0 have been mapped   to the BMR formalism according to the set of se-   mantic relations described in Appendix B ( see also   Section 4.1 ) by means of an in - house annotation   interface . The choice of BabelNet synsets to ex-   press the meaning of the original predicates fol-   lowed a simple set of annotation strategies , sorted   by desired priority : using the predicate name as   a query to look for available synsets , ( i ) pick a   nominal synset also featured in WordNet 3.0 ( e.g. ,   querying with the lemma liberality for the predi-   cateliberal.02 ) , ( ii ) pick an adjectival synset   featured in WordNet 3.0 , ( iii ) pick a nominal synset   not featured in WordNet 3.0 , ( iv ) pick an adjectival   synset not featured in WordNet 3.0 , ( v ) pick a syn-   onym to query for available synsets ( e.g. , querying   with the lemma correct for predicate be_it.07 ) .   See Table 7 for a random sample of AMR 3.0 to   BMR 1.0 mappings.17401741