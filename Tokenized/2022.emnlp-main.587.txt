  Yu Fei , Zhao Meng , Ping Nie , Roger Wattenhofer , Mrinmaya SachanETH Zurich , Peking University   feiyuwalter@gmail.com , { zhmeng , wattenhofer}@ethz.ch ,   ping.nie@pku.edu.cn , mrinmaya.sachan@inf.ethz.ch   Abstract   Recent work has demonstrated that pre - trained   language models ( PLMs ) are zero - shot learn-   ers . However , most existing zero - shot methods   involve heavy human engineering or compli-   cated self - training pipelines , hindering their ap-   plication to new situations . In this work , we   show that zero - shot text classification can be   improved simply by clustering texts in the em-   bedding spaces of PLMs . Specifically , we fit   the unlabeled texts with a Bayesian Gaussian   Mixture Model after initializing cluster posi-   tions and shapes using class names . Despite   its simplicity , this approach achieves superior   or comparable performance on both topic and   sentiment classification datasets and outper-   forms prior works significantly on unbalanced   datasets . We further explore the applicability of   our clustering approach by evaluating it on 14   datasets with more diverse topics , text lengths ,   and numbers of classes . Our approach achieves   an average of 20 % absolute improvement over   prompt - based zero - shot learning . Finally , we   compare different PLM embedding spaces and   find that texts are well - clustered by topics even   if the PLM is not explicitly pre - trained to gen-   erate meaningful sentence embeddings . This   work indicates that PLM embeddings can cat-   egorize texts without task - specific fine - tuning ,   thus providing a new way to analyze and utilize   their knowledge and zero - shot learning ability .   1 Introduction   Recent developments in large pre - trained language   models ( PLMs ) ( Devlin et al . , 2019 ; Liu et al . ,   2019 ; Raffel et al . , 2020a ) open up the possibil-   ity of classifying texts without massive in - task data   annotation . Such a zero - shot setting is receiving   increasing attention as it is a good way to eval-   uate the generalizability of knowledge in PLMs . Currently , most existing methods either utilize key-   words for self - training ( Chang et al . , 2008 ; Meng   et al . , 2018 ; Wang et al . , 2021 ) or reformulate the   classification task into a cloze task using prompts   ( Brown et al . , 2020 ; Schick and Schütze , 2021 ; Gao   et al . , 2021a ) . Keyword - based methods usually   train multiple modules sequentially ( Meng et al . ,   2020b ) , while prompting methods depend heavily   on human engineering ( Liu et al . , 2021 ) or external   knowledge ( Hu et al . , 2021 ) . Such task - specific   training or engineering is inefficient and usually   does not generalize well to new applications .   In this work , we show that we can better elicit the   zero - shot text classification abilities of PLMs sim-   ply by clustering texts in their embedding spaces .   We draw inspiration from recent findings ( Aha-   roni and Goldberg , 2020 ) that texts in the same   domain ( e.g. , legal or medical texts ) tend to be clus-   tered together in the PLM embedding spaces . This   indicates that PLMs already have the knowledge   to distinguish texts with different meanings . Fol-   lowing this idea , we propose SimPTC : ASimple   Probabilistic TextClassification framework build-   ing upon state - of - the - art sentence embeddings Sim-   CSE ( Gao et al . , 2021b ) . Given an unlabeled   dataset and the corresponding class names , SimPTC   models the texts in each class with a Gaussian   distribution and fits the text embeddings with a   Bayesian Gaussian Mixture Model ( BGMM ) . To   initialize the clusters , we first use the class names   to generate class - related anchor sentences . Then   the initial cluster assignment of a text is determined   according to its similarity to the class anchors in   the embedding space .   Despite the simplicity of SimPTC , it achieves   state - of - the - art performance while avoiding many   previously mentioned drawbacks of existing meth-   ods : 1 ) Without self - training of the PLM , SimPTC   achieves superior or comparable performance on   both topic and sentiment classification datasets ; 2 )   Unlike prompt - based methods , SimPTC works well8560without human engineering or access to external   knowledge ; 3 ) SimPTC outperforms previous meth-   ods when the dataset is unbalanced . Finally , once   we obtain the sentence embeddings , we no longer   use the PLM , and SimPTC clusters the embeddings   in a fixed dimensional space . Thus , one can easily   apply SimPTC to new and large datasets .   To explore the applications and limitations of   SimPTC , we compare it with prompt - based zero-   shot learning ( Schick and Schütze , 2021 ) on 14   datasets with more diverse topics , text lengths , and   numbers of classes . SimPTC gives consistently bet-   ter performance with a 20 % absolute improvement   in macro - F1 score on average . We find that SimPTC   handles domain - specific rare class names and large   class numbers better , while both the prompt - based   method and SimPTC suffer when the class names   are abstract concepts , e.g. , subjective v.s. objective .   Finally , we analyze the embedding spaces of dif-   ferent PLMs using SimPTC . Surprisingly , although   RoBERTa ( Liu et al . , 2019 ) is not explicitly   pre - trained to generate meaningful sentence em-   beddings , texts of the same topic are clustered with   state - of - the - art zero - shot accuracy . A Larger PLM   like T5 ( Raffel et al . , 2020b ) is able to achieve   better zero - shot results , even matching the fully   supervised performance of BERT ( Devlin et al . ,   2019 ) on some datasets . On the other hand , Sim-   CSE embeddings separate topics better , and texts of   sub - topics can form sub - clusters . On some datasets ,   we can even observe a linear semantic structure .   To conclude , the strong performance of such a   simple clustering - based algorithm suggests that the   zero - shot learning ability of PLMs is still under-   explored . With SimPTC , we provide a new starting   point to utilize and analyze the implicit knowledge   and zero - shot learning ability of PLMs .   2 Related Work   In this section , we review three types of zero - shot   text classification approaches . Zero - shot text clas-   sification aims at classifying texts without any an-   notated data . This is also referred to as weakly-   supervised text classification as it can use various   weak supervision signals , such as the names or   descriptions of the classes , to make predictions .   Keyword - driven methods The most common   supervision signal is keywords ( Chang et al . , 2008 ;   Mekala and Shang , 2020 ) . Meng et al . ( 2018 ,   2020b ) use iterative self - training on unlabeled in-   task data to refine the model or keyword sets . Wanget al . ( 2021 ) learn document representations that   align with the classes . Zhang et al . ( 2021b ) build   a keyword graph to take the connections between   keywords into account . Unlike these approaches ,   SimPTC contains no model training or keyword re-   finement process and depends solely on the sen-   tence embedding spaces of PLMs .   Clustering - based methods Early clustering-   based methods work with discrete text represen-   tations such as TF - IDF ( Zeng et al . , 2003 ) or bag-   of - words ( Kyriakopoulou and Kalamboukis , 2006 ) .   Recently , ULR ( Chu et al . , 2021 ) has explored   clustering - based text classification with contextual-   ized sentence embeddings . However , ULR requires   fine - tuning the PLM on extra task - related data and   uses a heuristic regularization . The K - Means - based   approach also places a strong spherical assumption   on the cluster shapes . In this work , we show that   neither the task - relevant pre - training nor the heuris-   tic designs are necessary . The original embedding   spaces of PLMs are sufficient to give strong results   with a more flexible clustering algorithm . Neverthe-   less , it is possible to utilize unsupervised learning   to further improve the clustering quality of text rep-   resentations like in Gupta et al . ( 2022 ) and Zhang   et al . ( 2021a ) . We leave this as a future direction .   Prompt - based methods Prompt - based methods   perform zero - shot learning in a natural way by   mimicking human behaviors when solving NLP   tasks ( Brown et al . , 2020 ) . Many existing works   on prompts focus on text classification , where a   template is used to transform the classification task   into a cloze task , and a verbalizer maps the pre-   dicted words into classification labels ( Schick and   Schütze , 2021 ) . With carefully designed templates   and verbalizers , prompt - based methods can per-   form comparably to supervised methods in text   classification . Various methods have been explored   for designing templates ( Gao et al . , 2021a ; Qin and   Eisner , 2021 ) and verbalizers ( Cui et al . , 2022 ) .   Other researchers leverage external knowledge . Hu   et al . ( 2021 ) expand label names with knowledge   bases , and Chen et al . ( 2022 ) re - train PLMs by   adaptively retrieving extra data .   SimPTC shares the idea of utilizing natural lan-   guage templates and class names . Nevertheless ,   instead of reformulating the classification task ,   SimPTC uses natural language templates and class   names to construct class - related texts , which are   used to compute initial cluster positions and shapes8561   for the subsequent probabilistic clustering step .   3 SimPTC   As illustrated in Figure 1 , SimPTC formalizes a zero-   shot text classification task into a clustering prob-   lem and solves it in three steps : Encode , Match ,   and Update . We start by modeling each class with   a Gaussian cluster in the embedding space . Next ,   the Encode step and Match step provide a coarse   initialization of the cluster means and covariances   using the class names . Finally , starting from the ini-   tialization , we fit the unlabeled data with a BGMM .   We elaborate on the three steps of SimPTC below .   3.1 Encode   The first step of SimPTC is to construct class anchor   sentences by filling the class names expanded based   on external knowledge bases into natural language   templates . Then we encode both the unlabeled   texts and the class anchor sentences into the PLM   embedding space ( Figure 1 top ) .   Expanding class names To make the anchor sen-   tences more class - indicative and less dependent   on the exact textual forms of the class names , we   expand the class names using external knowledge   bases . Specifically , we use ConceptNet Number-   batch ( Speer et al . , 2017 ) , a set of word embeddings   with semi - structured , common sense knowledgefrom ConceptNet ( Speer et al . , 2017 ) combining   word2vec ( Mikolov et al . , 2013 ) and GloVe ( Pen-   nington et al . , 2014 ) . To extract Mrelated words   given a class name s , we simply choose the words   whose embeddings have top- Mlargest inner prod-   ucts with the embedding of s :   S = top - M(xs ) ,   where Sis the expanded class name set of s;V   is the vocabulary ; bold font denotes word embed-   dings . Words that appeared in multiple S ’s are   deleted . If m > 1class names are given for one   class , for each name we extract M / m words . See   Appendix A for extracted word examples .   Constructing anchor sentences We take the   idea of using natural language templates from   prompt - based methods ( Schick and Schütze , 2021 )   to construct anchor sentences . A template is a piece   of text containing one or multiple special tokens   to be filled in , such as “ The text is about ⟨mask⟩. ” .   By replacing the ⟨mask⟩token with the expanded   class names s∈S , we get a set of class - related   sentences . Unlike prompt - based methods , we al-   low class names with multiple tokens . The anchor   embeddings of the same class are averaged to give   the final anchor vector ( Figure 1 top middle).8562   3.2 Match   Let{x , x , . . . , x}be the embeddings of a set   of unlabeled texts of size N , and{a , a , . . . , a }   be the averaged anchor vectors for Kclasses . The   pseudo - label ˆyofxare determined by :   ˆy= arg maxcos - sim ( x , a ) . ( 1 )   { ˆy}are then used to compute the initial cluster   means and covariances . We call this pseudo - label-   generating process Encode&Match ( E&M ) .   Figure 2 illustrates the encoded anchor vec-   torsa ’s and example vectors x ’s after perform-   ing PCA . The anchor vectors a ’s indeed reflect   the relative positions of the clusters . To pro-   vide more insights , we conduct a pilot experi-   ment on AG ’s News ( Zhang et al . , 2015 ) dataset .   We show the zero - shot performance of E&Mand   Vanilla Prompting , the vanilla prompt - based   zero - shot text classification method used in Schick   and Schütze ( 2021 ) , in Table 1 . For a fair com-   parison , we use the original class names directly to   construct anchor sentences for E&M.E&Mprovides a   competitive initialization and is more stable across   different choices of natural language templates .   3.3 Update   Model classes with Gaussian clusters To cap-   ture the position and shape characteristics of text   clusters , we model the texts of the same class with   a Gaussian in the embedding space and define a   Gaussian Mixture Model ( GMM ) . Then the likeli-   hood of the dataset is given by   p(X|θ ) = /productdisplay / summationdisplayπN(x|µ,Σ ) ,   where θ= ( π,µ,Σ)denotes the model parame-   ters;π={π , . . . , π},µ={µ , . . . , µ } , and   Σ={Σ , . . . , Σ}are the priors , means , and   covariances of each component respectively . We   can further require all components to share the   same covariance matrix to add extra regularization   when the data is sparse , or we have additional prior   knowledge that the clusters have similar shapes .   Variational update Clustering in a high dimen-   sional space can be challenging , for instance , when   the data is limited , or the initialization is poor . One   simple solution is to inject prior knowledge , such   as assuming a uniform prior on the classes as in   several prompt - based methods ( Zhao et al . , 2021 ;   Hu et al . , 2021 ) . However , debiasing model ex-   plicitly can be harmful when the prior is incorrect .   To balance injecting prior knowledge and fitting   the data , we turn to the Bayesian approaches and   introduce prior distributions on model parameters .   We choose a Dirichlet distribution as the prior for   mixture weights πto favor balanced weights :   p(π ) = Dir(π|α ) = C(α)/productdisplayπ   where C(α)is a normalizing constant , and α   can be interpreted as the prior number of observa-   tions associated with each class . We simply choose   α = N / K . For the means and covariances , we   choose a non - informative Gaussian - Wishart prior   ( see Appendix C for details ) . Then we update the   model with the standard variational optimization   ( Bishop and Nasrabadi , 2006 ) . As BGMM is guar-   anteed to converge ( Boyd et al . , 2004 ) , we stop up-   dating when the model predictions stop changing   or the maximum number of iterations is reached .   The overall SimPTC algorithm is summarized   in Algorithm 1 . Note that , in general , we can8563replace Encode&Match with any initialization   method and Bayesian GMM with any clustering   algorithm ( see discussion in § 4.2 ) .   Algorithm 1 : SimPTC   Input : unlabeled texts U ; test texts U ;   class names S ; sentence encoder E ;   max iteration T   Output : The prediction of U   X←E(U ) ;   X←E(U ) ;   { ˆy } ← Encode&Match ( § 3.1 and § 3.2 ) ;   M←BayesianGMM (   initial predictions ← { ˆy } ,   weight prior α← |U|/|S| ,   mean & cov prior ←Eq . ( 2 ) in App . C ,   max iter ←T ,   ) ;   FitMwithX ;   { y } ← prediction of MonX ;   Return { y }   4 Experiments   We conduct extensive experiments to understand   SimPTC . We compare SimPTC with state - of - the - art   zero - shot text classification methods in § 4.1 , study   the effect of its components in § 4.2 , and explore   its applications and limitations on a wide range   of tasks in § 4.3 . For all experiments , we use the   SimCSE supervised RoBERTa embeddings ,   which are in Rand trained using NLI datasets   via contrastive learning starting from the original   RoBERTa model . We discuss and analyze   other PLMs , such as T5 in § 4.4 .   4.1 Comparison with State - of - the - art   We evaluate the zero - shot text classification perfor-   mance of SimPTC on five benchmark datasets .   Datasets We use three topic datasets : AG ’s News   ( Zhang et al . , 2015 ) , DBpedia ( Lehmann et al . ,   2015 ) , and Yahoo ( Zhang et al . , 2015 ) , and two   sentiment datasets : IMDb ( Maas et al . , 2011 ) and   Amazon ( McAuley and Leskovec , 2013 ) . The full   dataset statistics can be found in Appendix D.   Implementations Following Hu et al . ( 2021 ) ,   we manually design four templates ( Appendix B )   for every dataset . The number of extracted class-   related words for each class is 1000 . We fit the   BGMM with both the unlabeled train and test data . For topic datasets , each Gaussian has its individual   covariance . For sentiment datasets , all Gaussians   share the same covariance to provide extra regular-   ization as the data is relatively sparse . The max-   imum iterations are set empirically based on the   size of unlabeled data . See Appendix D for details .   Baselines We compare SimPTC with the follow-   ing methods . Vanilla Prompting is the vanilla   prompt - based zero - shot text classification without   self - training used in Schick and Schütze ( 2021 ) .   We use the original class names and templates de-   signed by Hu et al . ( 2021 ) for predicting . ULR   ( Chu et al . , 2021 ) performs zero - shot text classi-   fication by clustering data using K - Means with   a heuristic regularization . Since ULR originally   uses an encoder pre - trained with extra in - domain   data , we evaluate ULRwith the same embeddings   used by SimPTC .LOTCLass ( Meng et al . , 2020b )   is a state - of - the - art keyword - based method that in-   volves training multiple models with multiple tasks   sequentially . KPT(Hu et al . , 2021 ) is the state - of-   the - art prompt - based method that utilizes external   knowledge bases and contextualized calibration to   produce stable zero - shot predictions .   Experimental Design We conduct experiments   to evaluate the following three claims :   C1 : SimPTC achieves superior or compara-   ble performance on both topic and sentiment   datasets . Table 2 reports the accuracy on the test   sets . We report the average scores with standard   deviations for methods using multiple natural lan-   guage templates . Without fine - tuning the PLM ,   SimPTC presents superior or comparable perfor-   mance on all datasets . On IMDb , KPTgets slightly   better results ( 91.6v.s.91.0 ) but has a much larger   standard deviation ( 2.7v.s.0 ) . Moreover , KPTim-   properly poses a balanced dataset assumption ( Ap-   pendix H ) , which hurts model performance when   the dataset is unbalanced ( see C3 ) .   C2 : SimPTC gives stable predictions across   different templates . Compared to Vanilla   Prompting , E&Mgives a better or comparable per-   formance on all datasets with much lower standard   deviations across different natural language tem-   plates ( Table 2 ) . The observation holds even when   we compare E&Mwith the prompt - based method en-   hanced with external knowledge ( KPT).SimPTC fur-   ther reduces the standard deviations and improves   performance.8564   C3 : SimPTC consistently outperforms prior work   when the classes in the dataset are unbalanced .   Currently , most benchmark datasets are balanced .   Overfitting to this balanced bias reduces the gener-   alizability of the method . To illustrate this problem ,   we conduct the following experiment on IMDb .   We keep the texts of one class with a ratio vary-   ing from 0.01to0.9to generate different unbal-   anced settings , and we compare SimPTC with KPT   andLOTCLass .KPTinjects a balanced dataset as-   sumption directly into its design ( Appendix H ) , and   LOTCLass is a self - training keyword - based method   without an explicit balanced assumption . As shown   in Figure 4 , the performance of KPTandLOTClass   drops significantly as the dataset becomes more   unbalanced , whereas SimPTC achieves consistently   better performance . As the class ratio approaches   zero , the micro - F1 score of KPTgoes to 50since   the balanced prior forces the model to make a bal-   ance prediction . Although LOTClass is purely data-   driven , the data imbalance still dramatically affects   its self - training process . On the other hand , E&M   provides a strong starting point for SimPTC , and   SimPTC further improves its performance . We discuss the convergence of SimPTC , the effect   of unlabeled dataset size , and sharing covariance   matrix in Appendix E , F and G respectively .   4.2 Ablations   We try to understand what contributes to the com-   petitive performance of SimPTC by studying the im-   portance of 1 ) the choice of natural language tem-   plate and class names , 2 ) the initialization method ,   and 3 ) the clustering algorithm .   4.2.1 Templates and Class Names   SimPTC gives state - of - the - art results even with-   out carefully designed templates or class names   extracted using external knowledge . We first   evaluate SimPTC using only the original class   names for constructing class anchor sentences ( -   class name expansion in Table 2 ) . SimPTC still   gives a comparable performance on all datasets .   Then we further test SimPTC with the naive tem-   plate “ ⟨mask⟩ ” ( -manual templates in Table 2 ) .   The performance is again only slightly affected .   Unlike prompt - based methods , which are sensi-   tive to the quality of class names and templates,8565   SimPTC gives strong performance even without ex-   ternal knowledge or human engineering .   4.2.2 Initialization Method   SimPTC is robust to the quality of initialization .   We use E&M to initialize the clusters mainly be-   cause E&Mworks directly with the text embeddings   computed for later clustering , adding only mini-   mal additional computations . In general , SimPTC   works with any initialization method ( see Algo-   rithm 1 ) . As a comparison , we test using Vanilla   Prompting(VP ) as the initialization . We report the   results averaged over four templates on five bench-   marks in Table 3 . Although VPgives a slightly   worse initialization performance , SimPTC achieves   a similar performance after clustering , showing the   robustness of SimPTC to the initialization method .   4.2.3 Clustering Algorithm   In this section , we aim to show what makes a good   choice of clustering algorithm for SimPTC by com-   paring BGMM with K - Means and GMM .   Modeling cluster shapes is beneficial . As   shown in Table 4 , BGMM outperforms K - Means   on all five balanced benchmark datasets . This   shows that putting a strong assumption on the clus-   ter shapes like K - Means limits the clustering step ’s   performance . Since the SimCSE embedding space   is rather well - structured , we further test SimPTC +   K - Means with the original RoBERTa embed-   dings . The performance on IMDb drops from 92.3   to 54.1 , indicating that BGMM is a more robust   choice for clustering PLM embeddings in general .   Adding prior on cluster weights helps on many-   class tasks . Following the previous observation ,   GMM outperforms K - Means on AG News , IMDb ,   and Amazon by allowing to model the cluster   shapes using data . However , GMM fails on many-   class tasks like DBpedia and Yahoo ( Table 4 ) ,   showing the benefits of adding prior on cluster   weights as extra regularization .   Learnable cluster weights handle class imbal-   ance . The learnable mixing weights of BGMM   ( and GMM ) model the proportion of classes and   therefore handle unbalanced clusters . To test this ,   we again compare three clustering algorithms on   IMDb dataset with different class ratios . Figure   4 shows that K - means fails completely when the   dataset is unbalanced . BGMM and GMM perform   better by allowing the cluster weights to adapt to   the data , but GMM is less stable in extreme cases .   4.3 TC14 Datasets   To further study the potential applications and limi-   tations of SimPTC , we collect 14 publicly available   text classification datasets with various topics , text   lengths , and numbers of classes ( Table 5 ) . For sim-   plicity , we refer to these datasets as TC14 . For   more dataset information , see Appendix I.1 .   Setup To simulate the most basic scenario , we   evaluate SimPTC with the naive template “ ⟨mask⟩ ”   and the original class names without expansion . We   choose Vanilla Prompting as the baseline since   it is the most widely used zero - shot prompt - based   method . For a fair comparison , we do not engineer   templates or verbalizers and use the original class   names with templates adopted from Hu et al . ( 2021 )   ( see Appendix I.2 for implementation details).8566   Results We report the macro - F1 scores on TC14   in Figure 5 and put micro - F1 scores in Appendix   I.3.E&Moutperforms Vanilla Prompting on 12   out of 14 datasets . SimPTC further boosts the per-   formance and gives a superior performance on all   14 datasets , showing the strong generalizability of   our approach . SimPTC achieves the most gain when   1 ) the class names contain multiple tokens ( e.g. ,   Banking77 ) ; 2 ) the number of classes is large ( e.g. ,   StackOverflow ) ; 3 ) the class names contain rare or   domain - specific words ( e.g. , Biomedical ) .   When does SimPTC not work very well ? Both   Vanilla Prompting andE&Msuffer when the class   names are abstract concepts , e.g. , subjective and   objective in the Subj dataset . This suggests that   prompting and current text embeddings are still   poor at linking texts to class names describing ab-   stract properties . But interestingly , the two classes   of Subj separate well in the SimCSE embedding   space ( Figure 6 ) , indicating the ability of PLM   embedding spaces to capture abstract semantic con-   cepts . Additionally , both methods underperform   self - training keyword - based methods in long docu-   ment tasks ( see Appendix I.4 for more details ) .   4.4 Different Encoders   In this section , we utilize SimPTC to analyze dif-   ferent PLM embedding spaces . Specifically , we   ask two questions : 1 ) Are the texts also clus-   tered by topics in the embedding spaces of PLMs   that are not explicitly trained to generate mean-   ingful embeddings ? 2)Are the embeddings   of larger PLMs more informative ? To answer   these questions , we compare RoBERTa ( RL )   ( Liu et al . , 2019 ) , Sentence RoBERTa ( SRL )   ( Reimers and Gurevych , 2019 ) , SimCSE super-   vised RoBERTa ( SimCSE ) , and T5 - 3B ( Raffel   et al . , 2020b ) embedding spaces . For sentence em-   beddings , we average the embeddings of all tokens   in a text for RL , and use the embeddings of the last   hidden states from the encoder for T5 - 3B .   4.4.1 Quantitative Results   PLM embeddings can categorize text with-   out task - specific fine - tuning . AsRLis not pre-   trained to generate meaningful sentence embed-8567   dings , E&Mdoes not work with RL . So we initialize   SimPTC using Vanilla Prompting . We do the   same for SRLas it provides a better initialization .   We share the covariance matrices to offer extra   regularization . Surprisingly , as shown in Table 6 ,   the original RLachieves comparable performance   toSimCSE and outperforms the more sophisticated   sentence encoder SRLon 4 out of 5 datasets .   Larger PLMs tend to have more informative   embedding spaces . With a larger model T5 - 3B ,   SimPTC gives even better results . Initialized using   VP , T5 - 3B achieves comparable or better perfor-   mance on 4 out of 5 datasets than the state - of - the-   art sentence encoder SimCSE , matching even the   supervised BERT performance on IMDb . This indi-   cates that embedding spaces of larger PLMs might   have even better clustering properties , which agrees   with their stronger zero-/few - shot learning ability .   4.4.2 Qualitative Analysis   To explain the first finding in § 4.4.1 , we analyze   the 3D PCA visualization of the Amazon dataset   in three embedding spaces ( Figure 7 ) . We observe   that : 1 ) RLpreserves the dataset sub - structures , but   the two sentiment clusters do not separate very well.2)SRLpushes semantically close texts together by   introducing an extra training objective , which leads   to more separable clusters , but the detailed struc-   tures of data are lost . 3 ) The SimCSE embeddings   separate the two classes distinctively , and the texts   are further clustered together by sub - topics , such   as books or products . Very interestingly , a clear   linear semantic sub - structure can be observed :   ¯v−¯v≈¯v−¯v≈¯v−¯v ,   where ¯vis the cluster center vector of all nega-   tive product reviews ; ¯vand¯vare the centers   of two sentiment classes . Therefore RLoutperforms   SRLpossibly because it is more descriptive of texts .   With a good separability of topics and the ability   to capture data sub - structures , SimCSE achieves the   best overall zero - shot classification performance .   5 Conclusion   In this work , we show that a simple clustering-   based approach , SimPTC , can achieve state - of - the-   art zero - shot text classification performance on   a wide range of tasks . With extensive experi-   ments , we identify the keys to cluster texts in the   PLM embedding spaces and also the limitations of   SimPTC . Further analysis of different PLMs shows   that PLMs can categorize texts in their embedding   spaces without being trained to derive semanti-   cally meaningful sentence embeddings , and Larger   PLMs tend to have more informative embeddings .   We hope our exploration into the embedding spaces   of PLMs can provide insights into understanding   and developing new methods to elicit the zero-/few-   shot learning ability of PLMs.8568Limitations   We identify three limitations of SimPTC as well as   this work : 1 ) Due to the nature of clustering and   sentence embeddings , SimPTC still suffers at many-   class tasks with long documents and tasks with   abstract class names ( e.g. , subjective v.s. objective ) ;   2 ) Currently how to apply SimPTC to other NLP   tasks like NLI is not straightforward . 3 ) Due to   computational resource constraints , our analysis is   limited to PLMs with parameters up to 3 Billion .   It would be interesting to see if our observations   generalize to the largest models like GPT-3 ( 175B )   ( Brown et al . , 2020 ) and PaLM ( 540B ) ( Chowdhery   et al . , 2022 ) , which show the strongest zero-/few-   shot ability .   Ethics Statement   This work aims to analyze how to use PLM   knowledge in their embedding spaces to catego-   rize texts on different topics . Unlike many other   deep - learning - based models , SimPTC involves no   large neural model pre - training , re - training , or fine-   tuning throughout the entire development of the   method . Once we get the embeddings of the un-   labeled texts , the PLMs are not used anymore .   Thus developing and applying our approach re-   quires only minimal computational resources and   cause fewer carbon emissions than methods that   require dataset - specific fine - tuning or engineering .   Besides , we do not anticipate any significant eth-   ical issues introduced by our approach . We use   only off - the - shelf PLMs , and the datasets involved   are all publicly available topic or sentiment classi-   fication datasets . Nevertheless , we urge anyone to   evaluate the robustness of the method before using   SimPTC in sensitive contexts such as healthcare or   legal scenarios .   References856985708571A Expanded Class Name Examples for   All Datasets   Some examples of the original and extracted class   names are shown in Table 11 - 14 .   B Templates Used for All Datasets   AG ’s News :   The news is about ⟨mask⟩.   The news is related to ⟨mask⟩.   ⟨mask⟩is the topic of the news .   This week ’s news is about ⟨mask⟩.   DBpedia :   The object is about ⟨mask⟩.   The object is related to ⟨mask⟩.   ⟨mask⟩is the topic of the object .   ⟨mask⟩is the subject of the object .   Yahoo :   The answer is about ⟨mask⟩.   The answer is related to ⟨mask⟩.   ⟨mask⟩is the topic of the answer .   ⟨mask⟩is involved in the answer .   Amazon :   A⟨mask⟩product review .   The product review is ⟨mask⟩.   The reviewer found the product ⟨mask⟩.   The product is ⟨mask⟩.   IMDb :   A⟨mask⟩movie review .   The movie review is ⟨mask⟩.   The reviewer found the movie ⟨mask⟩.   The movie is ⟨mask⟩.C Math foundation of the SimPTC Update   Step   Bayesian approaches inject prior knowledge by   introducing prior distribution on model parameters   while still allowing the model to fit the data . In this   section we first discuss the prior distributions we   choose . Then we show how these choices affect   the model prediction by analyzing the maximum   a posteriori probability ( MAP ) solution of model   parameters .   Prior distributions Following Bishop and   Nasrabadi ( 2006 ) , we choose a Dirichlet distri-   bution as the prior for mixture weights π , and a   Gaussian - Wishart prior for the mean and precisions ,   i.e. , the inverse of covariance Λ = Σ :   p(π ) = Dir(π|α ) = C(α)/productdisplayπ   p(µ,Λ ) = p(µ|Λ)p(Λ )   = /productdisplayN(µ|m,(βΛ ) ) ·   W(Λ|W , ν ) ,   where C(α)is a normalizing constant , and αcan   be interpreted as the prior number of observations   associated with each mixture . We simply choose   α = to favor balanced weights . For the means   and covariances , we offer the model maximum free-   dom to fit the data by choosing a non - informative   prior ( Murphy , 2007 ) . Specifically , we set :   m= 0 , β→0,W=1   dΣ , ν = d,(2 )   where Σis some initial guess of the covariance   matrix , which can be set as the empirical covari-   ance of the data . Then we update the model with   the standard variational optimization ( Bishop and   Nasrabadi , 2006 ) for Bayesian GMM .   MAP solution Here , we show the MAP solution   after one update step to give some intuition about   how our choice of prior model parameters ( 2)in-   fluences the update of model parameters . As the   standard EM update of maximum likelihood meth-   ods , the variational update also contains two steps .   In the variational E step , we evaluate the respon-   sibilities using the current variational distribution   parameters :   r:=E[z ] ,   where zis the binary latent variable indicating   whether data xbelongs to cluster k ; and in the8572Name Type # Class Training Size Test Size Max Iter Covariance Setting   AG ’s News Topic 4 120000 7600 50 Full   DBpedia Topic 14 560000 70000 40 Full   Yahoo Topic 10 1400000 60000 20 Full   Amazon Sentiment 2 200000 10000 50 Tied   IMDb Sentiment 2 25000 25000 150 Tied   variational M step , we update the variational distri-   bution parameters . For simplicity , we introduce the   following statistics :   N=/summationdisplayr   ¯x=1   N / summationdisplayrx   S=1   N / summationdisplayr(x−¯x)(x−¯x ) .   Then the MAP solution of π,µ,Σgiven the re-   sponsibilities r ’s after a variational M steps is   given by   π = α−1 + N   K(α−1 ) + N   µ=¯x   Σ = dΣ+NS   N−1,(3 )   where dis the number of feature dimensions and K   is the number of classes . We can see that by choos-   ing non - informative prior ( 2)of(µ,Σ ) , we allow   the model to fit the data with maximum freedom .   By choosing a large α , we can push the mixing   weights towards uniform but still allow the model   to fit the data .   D Datasets Statistics and Model Settings   The statistics of the five datasets used in § 4.1 and   max iteration numbers can be found in Table 7 . For   Amazon , we use the same test set sampled by Hu   et al . ( 2021 ) and randomly sample 200,000 texts   from the original training set for the unlabeled train-   ing data . Since SimCSE only handles texts with a   maximum length of 512 , we crop texts with lengths   exceeding 512 . We choose the maximum number   of iterations empirically according to the size of   the unlabeled data which is equal to the training set   size plus the test set size . For topic datasets , each   Gaussian has its individual covariance matrix . For   sentiment datasets , all Gaussians share the same   covariance matrix to provide extra regularization as   the data is relatively sparse . The effect of sharing   the covariance matrix is discussed in Appendix G.   E Convergence Analysis   Although SimPTC is guaranteed to converge , it is   unclear whether it will converge to a good solu-   tion when the algorithm stops . Therefore we study   how the model performance varies as the updating   process proceeds . We plot the test accuracy of in-   termediate update steps on all datasets in Figure   8 , where the standard deviations caused by using   different templates are illustrated with blurred ar-   eas . We observe that the performance gradually   improves and converge in all dataset except Yahoo ,   where SimPTC still converges to a result much bet-   ter than the initialization . Also , as shown in the   blurred areas in Figure 8 , the update step is sta-8573   ble when different templates are used . Moreover ,   SimPTC almost converges on all five datasets under   our setting of the maximum number of iterations .   F Effect of Unlabeled Dataset Size   In the standard setting , we use both the train and   test set for fitting the Bayesian GMM . To study   the effect of the unbalanced dataset size , we keep   the unlabeled test data and use the training data   with ratios varying from 0to1 . As illustrated in   Figure 9 , on almost all datasets , more unlabeled   data brings more improvement .   One possible explanation is : to model the shape   of all clusters with a certain error threshold , one   needs samples of a number at least linear to the   number of dimensions ( Vershynin , 2012 ) and lin-   ear to the number of classes . Therefore a large   unlabeled dataset helps the model to fit data with   many classes in a high - dimensional space better   ( for RoBERTa , the number is 1024 ) . By   sharing the covariance matrix ( Amazon and IMDb ) ,   we reduce the number of model parameters . Thus   SimPTC works better than fitting individual covari-   ance for each cluster ( Agnews , Dbpedia , and Ya-   hoo ) when the data is sparse . Since for many tasks   collecting unlabeled data is considered to be much   easier than collecting annotated data , we can im-   prove the performance of SimPTC in real - world ap-   plications at a low cost .   G Effect of Sharing Covariance Matrix   We explore two covariance settings in SimPTC .Full :   each Gaussian mixture has its own covariance Σ ,   andtied : all Gaussians share the same covariance   Σ. Note that the sharing the covariance matrices   ( thefullandtiedsetting ) is a standard hyperparam-   eter of GMM . The fullsetting is more flexible , and   as Table 8 shows it improves the initial E&Mpre-   dictions on all datasets . By sharing the covariance   matrices ( the tiedsetting ) we 1 ) reduce model pa-   rameters to provide extra regularization and 2 ) add   stronger assumptions on the cluster shapes . There-   fore it is useful when   •the data is relatively sparse ( e.g. , IMDb in   Table 8 and TC14 datasets in § 4.3 ) ,   •the embedding space of PLM is less structured   ( T5 and RoBERTa embeddings ( § 4.4 ) ) ,   •the texts of different classes describe similar   objects ( e.g. , sentiment tasks ) .   Otherwise , we recommend allowing clusters to   have different covariances .   H Implicit Balanced Assumption of KPT   Hu et al . ( 2021 ) proposed a data - dependent   Contextualized Calibration ( CC ) . They mo-   tivate CCby observing that some label words are   less likely to be predicted than others , regardless of   the label of input sentences . To solve the problem ,   CCworks in the following steps : First , to estimate   a contextualized prior distribution of label words   using some sampled unlabeled data :   P(v ) = EP([MASK ] = v|x )   ≈1   |C|/summationdisplayP([MASK ] = v|x),(4 )   where vstands for a particular label word , Dis the   data distribution , Pis the model prediction , Cis   a sampled subset of the dataset . Then they use the   contextualized prior of label words to calibrate the   predicted distribution :   ˜P([MASK ] = v|x)∝P([MASK ] = v|x )   P(v ) .   ( 5)8574Name Type Class name examples Template for prompting   20 News Topic comp.graphics ; sci.space [ Category : ⟨mask⟩]⟨text⟩   NYT - Topic Topic business ; politics ; sports [ Category : ⟨mask⟩]⟨text⟩   NYT - Location location united_states ; iraq ; japan [ Category : ⟨mask⟩]⟨text⟩   BBC News Topic sport ; business ; entertainment [ Category : ⟨mask⟩]⟨text⟩   Emotion Emotion sad ; joy ; anger [ Category : ⟨mask⟩]⟨text⟩   Banking77 Intent activate_my_card ; age_limit [ Category : ⟨mask⟩]⟨text⟩   TREC Question abbr . ; entity ; description [ Category : ⟨mask⟩]⟨text⟩   Biomedical Paper title aging ; chemistry ; erythrocytes [ Category : ⟨mask⟩]⟨text⟩   StackOverflow Question svn ; oracle ; bash [ Category : ⟨mask⟩]⟨text⟩   Yelp Sentiment positive ; negative It is ⟨mask⟩.⟨text⟩   SST-2 Sentiment positive ; negative It is ⟨mask⟩.⟨text⟩   SST-5 Sentiment very positive ; positive ; negative It is ⟨mask⟩.⟨text⟩   MPQA Opinion polarity positive ; negative It is ⟨mask⟩.⟨text⟩   Subj Subjectivity subjective ; objective It is ⟨mask⟩.⟨text⟩   The final probability is normalized to 1 .   The contextualized prior can be interpreted as   a marginal distribution . Consider we have one la-   bel word for each class . The contextualized prior   measures the portion of each class in the dataset   based on the model ’s predictions . Then CCpenal-   izes the probability of predicting one class if the   model thinks it assigns too many samples to this   class ( P(v)is large ) . Intuitively this is to force   the model to assign equal numbers of samples to   each class , which is to force a uniform marginal   distribution . The underlying implicit assumption is   that the dataset is balanced . Although CCimproves   the zero - shot performance of KPT , we argue that   this is because the evaluation datasets happen to be   balanced , and CCbecomes problematic when the   dataset is unbalanced ( see C2 in § 4.1 ) .   I TC14 Datasets   To study the applications and limitations of SimPTC ,   we collect the following 14 datasets with diverse   topics , text lengths , and class numbers . Specifi-   cally , we did a literature search in zero - shot text   classification and collected datasets that best fit   our text classification setting with label names that   have class - info . We first introduce the details of the   TC14 datasets ( § I.1 ) . Then we discuss the imple-   mentation details in § I.2 . We show the full results   in § I.3 and provide extra analysis in § I.4.I.1 Dataset Information   The datasets we used are :   •20 News ( Lang , 1995 ) is a news classification   dataset . It has a relatively long average text   length and many classes .   •NYT - Topic ( Meng et al . , 2020a ) is a long docu-   ment topic classification dataset that is very un-   balanced .   •NYT - Location ( Meng et al . , 2020a ) uses the   same corpus as NYT - Topic but categorizes the   texts according to locations . The dataset is very   unbalanced .   •BBC News ( Greene and Cunningham , 2006 ) is a   news dataset containing 2225 articles .   •Yelp ( Zhang et al . , 2015 ) is a review sentiment   dataset .   •Emotion ( Saravia et al . , 2018 ) is a dataset of En-   glish Twitter messages with six basic emotions ,   and the dataset is very unbalanced .   •Banking77 ( Casanueva et al . , 2020 ) is a dataset   composed of online banking queries annotated   with their corresponding intents . It has a very   fine - grained set of intents in the banking domain .   13,083 customer service queries are categorized   into 77 intents .   •SST-2 ( Socher et al . , 2013 ) is a sentence senti-   ment classification dataset .   •SST-5 ( Socher et al . , 2013 ) is a fine - grained sen-   timent classification dataset . Texts are classified   into five sentiment classes : very negative , nega-8575   tive , neutral , positive , and very positive .   •MPQA ( Wiebe et al . , 2005 ) is an opinion polarity   analysis dataset .   •Subj ( Pang and Lee , 2004 ) is a subjectivity anal-   ysis dataset .   •TREC ( V oorhees and Tice , 2000 ) is an unbal-   anced question classification dataset .   •Biomedical ( Xu et al . , 2017 ) is a paper title clas-   sification dataset , where 20,000 titles are catego-   rized into 20 groups .   •StackOverflow ( Xu et al . , 2017 ) is a dataset con-   taining 20,000 questions with 20 classes .   Since we are evaluating zero - shot methods , we   report scores on the full datasets ( dataset sizes are   shown in Table 5 ) .   I.2 Additional Implementation Details   We compare with Vanilla Prompting rather than   KPTbecause KPT has an improper balanced dataset   assumption ( § 4.1 C3 ) , and KPTcannot handle class   names containing multiple words .   For the 20 News dataset , we use class names   from Mekala and Shang ( 2020 ) as the original   class names are not complete English . We im-   plement Vanilla Prompting using OpenPrompt   ( Ding et al . , 2021 ) . When a class name contains   multiple words , we use the average probability   of predicting each word as implemented in Open-   Prompt . BBC News contains only 2225 texts and is   too small to fit a 1024 - by-1024 covariance matrix   even if we share the covariance matrices of clusters .   Banking77 has too many classes compared with   the dataset size , and as a result , Encode&Match ass - ing zero samples to some classes . To fix these two   problems , we perform a PCA to reduce the feature   dimension such that the reconstruction error is 3 %   before Encode&Match .   I.3 Full Results   We report the micro - macro F1 scores on TC14 in   Table 10 . For comparison , we also collect publicly   available state - of - the - art results on these datasets .   Some papers only report the accuracy of their mod-   els , and we report these numbers instead .   I.4 Additional Analysis   As discussed in § 4.3 , both prompting and E&Msuf-   fer on the Subj dataset where the class names are   abstract concepts ( subjective v.s. objective ) . As a   result , SimPTC also does not go very far from ran-   dom guessing ( 50 % ) . However , despite E&Mfailing   to link the texts correctly with the abstract class   names , the texts themselves are well - separated in   the embedding space ( Figure 6 ) . This suggests that   texts with abstract classes can also be clustered to-   gether in the PLM embedding spaces . A 10 - shot   setting ( averaged over 5 seeds ) improves SimPTC   from 52.0 to 89.2 on Subj , outperforming GPT-3   175B in - context learning ( 76.4 ) .   In terms of limitations , another important ob-   servation is that : on long document classification   tasks ( 20 News , NYT - Topic , NYT - Location ) , both   SimPTC andVanilla Prompting underperform   the state - of - the - art keyword - based method X - Class   ( Wang et al . , 2021 ) , showing an information loss   when PLMs encodes long documents into the em-8576bedding spaces . This indicates that in terms of   extracting information from long documents , self-   training keyword - based approaches still perform   better than zero - shot our clustering - based approach   and prompting methods.8577Class Name Expanded Class Names   politicsalt rightist , social fascism , psychopolitical , leader of opposition , junior minister ,   whipped vote , political , regressive leftism , policy making , dollar democracy , ...   sportsprofessional baseball , game set match , banana ball , empty bench , first touch ,   football , sportsman , visiting team , athletic , exhibition game , super cup , ...   businessaccount name , commerciality , making money , sprinkler strategy , web company ,   consumer good , business economics , maintained markup , commercial enterprise , ...   technologycryoengineering , aeronautical engineering , geotechnology , cwm silicon , nuclearism ,   digital technology , cryotechnology , xenotechnology , applied science , deepfake , ...   Class Name Expanded Class Names   companyhook stock , private corporation , large company , big company , business organization ,   furniture company , companies , sprinkler strategy , corp , livery company , ...   schoolelementary schooler , undergraduates , university student , dual school , antiuniversity ,   schoolless , overschooled , secondary modern , science room , state school , ...   artistarte povera , ernstian , art show , da vincian , polystylist , gallery opening , pricasso ,   artworks , artistdom , superrealist , artists , clean brushes , post impressionist ...   athleteolga korbut , athleticism , pull muscle , walking sports event , pancratical , nongymnast ,   sportswomen , athletic contest , weightlifter , winter olympics competition , ...   politicsalt rightist , social fascism , psychopolitical , leader of opposition , junior minister ,   whipped vote , political , regressive leftism , policy making , dollar democracy , ...   transportationantirail , air freight logistics , delivered ex ship , road rail , transmodal ,   water bailage , transportive , cargon , vecturist , multiride , transfer to hospital , ...   buildingtower block , nonbuilding , inbond , interior door , interiorscaper , split level ,   electrical wiring , seismic retrofit , house raising , sevenplex , office complex , ...   rivermountainlike , talav , mountainside , mount sharp , river , lake albert nyanza ,   subapennine , khabur , transmountain , longs peak , riverling , land form , monticulus , ...   villagekoprivnica , khutor , intown , b road , mini mall , oppidan , cybervillage , gaothan ,   lawley , shillingstone , shakespeare play , claygate , goosnargh , hamlets , northcott , ...   animalgambian pouched rat , cattle beast , wild game , cymothoa exigua , farm animal ,   bestiarian , stylophora , brazilian wandering spider , western black rhinoceros , ...   plantanthoxanthum odoratum , harpulla , calochortus amabilis , brazilian pepper tree ,   tree roots , cuphea , lespedeza bicolor , phoenix tree , akeake , rauli beech , nontree , ...   albumstudio album , lyrics , space cakes , guitar drums , song , chiodos , american life ,   dance pop , keys of kingdom , record deal , rock opera , songsheet , songcraft , ...   filmstar actor , filmically , company men , moving pictures , stfilm , getting acquainted ,   sound film , photographic film , collage film , cinematology , filmize , ...   bookmegabook , pilgrim ’s progress , neophiliac , forebook , young adult fiction , clipsheet ,   novels , novel , book , novelle , reading material , booklessness , e novel , ... 8578Class Name Expanded Class Names   society , culturecrowd elevator , cybersociety , macroculture , intersocietal , islandness ,   desocialize , cultureshed , overculture , preculture , ghost skin , antisociety , ...   science , mathematicsinequality sign , ur science , odd function , common antilog , hydroscience ,   known quantity , find out truth , science , commutative law , aetherometry , ...   healthbeing well , dietetist , hale and hearty , healthcare delivery , healthful , health ,   country doctor , geomedical , health centre , nutritionwise , patient contact , ...   education , referencepostsecondary school , uneducation , special educator , secondary education ,   cross index , tertiary education , forward reference , exophora , ...   computers , internetallows null sessions , dynamic ip address , friendly url , data processor ,   laptops , deadlink , web diving , dictionary attacker , nt account system , ...   sportsprofessional baseball , game set match , banana ball , empty bench ,   football , sportsman , visiting team , athletic , exhibition game , super cup , ...   business , financeadhocratic , net operating loss , business organization , capital structure ,   systematic risk , manufacturers rep , web company , garmento , ...   entertainment , musicbigophonic , good fun , entertaintment , natabhairavi , eating popcorn ,   allegro non troppo , semihemidemisemiquaver , musicaholic , ...   family , relationshipsmother father , enicocephalid , profamily , close friendship , salpidae ,   visual proximity , relations , lac scale , sexual relationship , ...   politics , governmentgovernmentalise , ruling party , westminster system , antiindependence ,   leader of opposition , cryptarchy , macropolitical , antipopulist , ...   Class Name Expanded Class Names   badoverawful , crappy , uglysome , not good , suck balls , do badder , blow chunks ,   shitly , godawful , sucktastic , worsts , horridsome , fucky , god awful , terrible , ...   goodcorrect answer , have good day , better job , clean apartment , double plus good , nice ,   talk with friends , goodish , supernice , like million bucks , healthy environment , ... 8579