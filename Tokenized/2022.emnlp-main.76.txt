  Fanghua YeXi WangJie HuangShenghui LiSamuel SternEmine YilmazUniversity College London , UKUniversity of Illinois at Urbana - Champaign , USAUppsala University , SwedenAffiniti AI , London , UK   { fanghua.ye.19 , xi - wang , emine.yilmaz}@ucl.ac.uk   jeffhj@illinois.edu , shenghui.li@it.uu.se , samuel.stern@affiniti.ai   Abstract   Existing dialogue datasets contain lots of noise   in their state annotations . Such noise can hurt   model training and ultimately lead to poor gen-   eralization performance . A general framework   named ASSIST has recently been proposed to   train robust dialogue state tracking ( DST ) mod-   els . It introduces an auxiliary model to generate   pseudo labels for the noisy training set . These   pseudo labels are combined with vanilla labels   by acommon fixed weighting parameter to train   the primary DST model . Notwithstanding the   improvements of ASSIST on DST , tuning the   weighting parameter is challenging . Moreover ,   a single parameter shared by all slots and all in-   stances may be suboptimal . To overcome these   limitations , we propose a meta learning - based   framework MetaASSIST to adaptively learn the   weighting parameter . Specifically , we propose   three schemes with varying degrees of flexibil-   ity , ranging from slot - wise to both slot - wise and   instance - wise , to convert the weighting param-   eter into learnable functions . These functions   are trained in a meta - learning manner by taking   the validation set as meta data . Experimental   results demonstrate that all three schemes can   achieve competitive performance . Most impres-   sively , we achieve a state - of - the - art joint goal   accuracy of 80.10 % on MultiWOZ 2.4 .   1 Introduction   Task - oriented dialogue systems have recently be-   come a hot research topic . They act as digital per-   sonal assistants , helping users with various tasks   such as hotel bookings , restaurant reservations , and   weather checks . Dialogue state tracking ( DST ) is   recognized as a core task of the dialogue manager .   Its goal is to keep track of users ’ intentions at each   turn of the dialogue ( Mrkši ´ c et al . , 2017 ; Rastogi   et al . , 2020 ) . Tracking the dialogue state accurately   is of significant importance , as the state informa-   tion will be fed into the dialogue policy learning   module to determine the next system action to per-   form ( Manotumruksa et al . , 2021 ) . In general , theFigure 1 : The structure of ASSIST and MetaASSIST .   Both frameworks utilize soft labels obtained by linearly   combining pseudo labels ( one - hot ) and vanilla labels   ( one - hot ) using a weighting parameter αto enhance the   training process compared to standard training that only   relies on vanilla noisy labels . ASSIST adopts a single α   that is shared by all slots and all training samples , while   MetaASSIST uses slot - wise ( and instance - wise ) αs .   dialogue state is represented as a set of ( slot , value )   pairs ( Henderson et al . , 2014 ; Budzianowski et al . ,   2018 ) . The slots for a particular task or domain are   predefined ( e.g. , “ hotel - name ” ) . Their values are   extracted from the dialogue context .   So far , a great variety of DST models have been   proposed ( Wu et al . , 2019 ; Campagna et al . , 2020 ;   Balaraman et al . , 2021 ; Lee et al . , 2021 ; Guo et al . ,   2022 ; Shin et al . , 2022 ; Wang et al . , 2022 ) . These   models assume that all state labels provided in the   dataset are correct , without considering the effect   of label noise . However , dialogue state annotations   are error - prone , especially considering that most   dialogue datasets ( e.g. , MultiWOZ Budzianowski   et al . , 2018 ) are collected through crowdsourcing .   The presence of label noise may impair model train-   ing and lead to poor generalization performance of   the trained model , as deep neural models can easily   overfit noisy training data ( Zhang et al . , 2021 ) .   In order to robustly train DST models from noisy   labels , Ye et al . ( 2022 ) proposed a general frame-   work dubbed ASSIST , which augments the stan-   dard model training procedure with a small clean   dataset . As shown in Figure 1 , ASSIST first trains1157an auxiliary model on the small clean dataset and   applies this model to generate pseudo labels for   each sample in the noisy training set . Then , it lin-   early combines the pseudo labels and vanilla labels   to train the primary model . Both theoretically and   empirically , ASSIST has been shown to be effec-   tive in reducing the impact of label noise .   However , ASSIST adopts a common weighting   parameter to combine the pseudo labels and vanilla   labels for all slots and all training samples , which   is suboptimal . In reality , different slots tend to have   different noise rates ( Eric et al . , 2020 ) , indicating   that the weighting parameter should be slot - wise .   On the other hand , different training samples may   also require different weighting parameters , since   whether pseudo labels or vanilla labels should be   preferred is highly dependent on specific training   instances . Furthermore , the weighting parameter is   considered a hyperparameter and thus needs to be   carefully tuned on each dataset .   To address the aforementioned limitations of AS-   SIST , we propose MetaASSIST , a meta learning-   based general framework that supports automati-   cally learning slot - wise ( and instance - wise ) weight-   ing parameters . Specifically , our contributions are :   •We propose three different schemes for trans-   forming the weighting parameters into learn-   able functions . These schemes have varying   degrees of flexibility , ranging from slot - wise   to both slot - wise and instance - wise .   •We propose to train these learnable functions   through a meta - learning paradigm that takes   the validation set as meta data and adaptively   adjusts the parameters of each learnable func-   tion ( as a result , the weighting parameters ) by   reducing the validation loss .   •We conduct extensive experiments to test the   effectiveness of the proposed three schemes .   All of them achieve superior performance . For   the first time , we achieve over 80 % joint goal   accuracy on MultiWOZ 2.4 ( Ye et al . , 2021a ) .   2 Preliminaries   In task - oriented dialogue systems , the DST module   transforms users ’ goals or intentions expressed in   unstructured natural languages into structured state   representations ( e.g. , a series of slot - value pairs ) .   The state representations are continually updated   in each round of the user - system interactions.2.1 Problem Statement   More formally , we symbolize a dialogue of Tturns   asX={(R , U ) , . . . , ( R , U ) } , where Rand   Udenote the system response and user utterance   at turn t(1≤t≤T ) , respectively . We adopt Xto   represent the dialogue context from the first turn to   thet - th turn , i.e. , X={(R , U ) , . . . , ( R , U ) } .   Further , let Sdenote the set of all the predefined   slots and B={(s , v)|s∈ S } the dialogue state   at turn t. Here , vis the corresponding value of slot   sat turn t. Then , the DST problem is defined as   learning a dialogue state tracker F : X→ B.   As discussed earlier , annotating dialogue states   via crowdsourcing is prone to incorrect and incon-   sistent labels . These noisy annotations are likely   to adversely affect model training . We denote the   noisy state annotations as ˜B={(s,˜v)|s∈ S } ,   where ˜vis the noisy label of slot sat turn t. In this   work , ˜Brefers to the labels provided in the dataset   andBrefers to the unknown true state annotations .   As pointed out by Ye et al . ( 2022 ) , existing DST   approaches are only able to learn a suboptimal di-   alogue state tracker ˜F : X→˜Brather than the   optimal dialogue state tracker F : X→ B. Aim-   ing at learning a strong dialogue state tracker Fto   better approximate F , Ye et al . ( 2022 ) proposed a   general framework ASSIST that supports training   DST models robustly from noisy labels .   2.2 Overview of ASSIST   ASSIST assumes that a small clean dataset is avail-   able . Based on this assumption , it firstly trains an   auxiliary model on the clean dataset . Then , it lever-   ages the trained model to generate pseudo labels   for each sample in the large noisy training set . The   generated pseudo labels are expected to be a good   complement to the vanilla noisy labels . Therefore ,   combining the two types of labels has the poten-   tial to reduce the influence of noisy labels when   training the primary model .   Denote the generated pseudo state annotations   as˘B={(s,˘v)|s∈ S } , where ˘vrepresents the   pseudo label of slot sat turn t. Within the frame-   work of ASSIST , the primary model is required   to predict ˘Band˜Bconcurrently during the train-   ing process . In other words , the target of model   training turns into learning a dialogue state tracker   F : X→C(˘B,˜B ) , where C(˘B,˜B)denotes a   combination of ˘Band˜B. There can be different   methods to combine the generated pseudo labels   and vanilla noisy labels . The most straightforward1158way is to combine them linearly , which is also the   strategy adopted in ASSIST . The linearly combined   label of slot sat turn tis formulated as :   v = α˘v+ ( 1−α)˜v , ( 1 )   where ˘vand˜vare the one - hot vector representa-   tion of the pseudo label ˘vand vanilla noisy label   ˜v , respectively . The parameter α(0≤α≤1)is   employed to control the weights of ˘vand˜v .   Letp(˘v|X , s)denote the likelihood of ˘vand   p(˜v|X , s)the likelihood of ˜v . Then , the likeli-   hood of the combined label vis calculated as :   p(v|X , s ) = p(˘v|X , s)p(˜v|X , s).(2 )   Based on this formula , the training objective of the   primary model can be derived as follows :   L=1   |D||S|/summationdisplay / summationdisplay−logp(v|X , s )   = α   |D||S|/summationdisplay / summationdisplay−logp(˘v|X , s)+   ( 1−α )   |D||S|/summationdisplay / summationdisplay−logp(˜v|X , s),(3 )   where Drepresents the noisy training set .   3 MetaASSIST : A Meta Learning - Based   Version of ASSIST   Equations ( 1)and(3)show that a single αis shared   by all slots when combining the pseudo labels and   vanilla labels . This is suboptimal , as the ratio of the   noise rate of pseudo labels to that of vanilla labels   tends to be different for different slots . When the   vanilla labels have higher quality than the gener-   ated pseudo labels , αshould be set to a small value ;   otherwise , a large αshould be used . This implies   that setting αto different values for different slots   can help train the primary model more robustly . In   the following , we first theoretically show that the   combined labels obtained via slot - wise weighting   parameters instead of a common one can better ap-   proximate the unknown true labels . Then , we elab-   orate on the proposed framework MetaASSIST .   3.1 Theoretical Justification   Following ( Ye et al . , 2022 ) , we employ the mean   squared loss to define the mean approximation error   of any corrupted labels ¨vto their corresponding   unknown true labels v , as formularized below :   Y=1   |D||S|/summationdisplay / summationdisplayE[∥¨v−v∥].(4)Here , Drefers to the small clean dataset . Both ¨v   andvare the vector representations of labels .   Letαbe the slot - wise weighting parameter for   slots . We utilize vto denote the combined label   obtained by replacing αwithαin Eq . ( 1 ) . Thus ,   v = α˘v+ ( 1−α)˜v . ( 5 )   Same as α , αis also bounded between 0 and 1 .   Substituting the corrupted labels ¨vin Eq . ( 4 )   withvandv , we have the following theorem :   Theorem 1 . The optimal mean approximation er-   ror with respect to the combined labels vderived   from slot - wise weighting parameters αis smaller   than or equal to that of the combined labels v   derived from a shared weighting parameter α , i.e. ,   minY≤minY.   Proof . The conclusion is obvious as we can replace   αwithαifY < Y , but not vice versa .   3.2 Slot - Wise Weighting Parameters as Meta   Learnable Functions   In the framework of ASSIST , αis treated as a hy-   perparameter . It needs to be meticulously tuned in   the training phase so as to help the primary model   achieve the best performance . Although it is feasi-   ble to tune a single parameter α , it would become   extremely painful to tune all the slot - wise parame-   ters . This is because multi - domain dialogues can   have dozens of or even hundreds of slots ( e.g. , there   are 37 slots in the MultiWOZ dataset Eric et al . ,   2020 ) . To circumvent the troublesome step of tun-   ing each slot - wise parameter αof slot s , we pro-   pose to learn all these parameters automatically via   meta learning ( Hospedales et al . , 2021 ) .   Specifically , we propose three different schemes   to cast the slot - wise weighting parameters as learn-   able functions , which are described in detail below :   Scheme One ( S1 ): The first scheme assumes that   the parameter αis fully independent of the dia-   logue context X. As a consequence of this assump-   tion , all the training samples will share the same α   for slot s. Given that the parameter αis restricted   to fall in the range of 0 to 1 , it is tricky to learn it by   gradient - based optimizers . In our implementation ,   we introduce an unconstrained learnable parameter   wand regard αas a Sigmoid function of w :   α = f(w ) = Sigmoid ( w ) . ( 6 )   As thus , the parameter wrather than αwill be   directly optimized during the training process.1159Scheme Two ( S2 ): Apart from being slot - wise ,   the second scheme assumes that the parameter α   should also be relevant to the dialogue context X   ( i.e. , instance - wise ) . This assumption is of practi-   cal significance , as whether the vanilla labels or the   pseudo labels should be preferred may vary across   the training samples . In order to make αinstance-   wise , we first construct a five - dimensional feature   vector based on the loss values of both vanilla la-   bels and pseudo labels , as shown below :   h= [ ˜l,˘l,˜l−˘l,˘l−˜l,˜l+˘l ] , ( 7 )   where ˜land˘lcorrespond to the loss value of the   vanilla label ˜vand pseudo label ˘vof slot sassoci-   ated with the dialogue context X , respectively . To   be more specific , ˜land˘lare calculated as follows :   ˜l=−logp(˜v|X , s ) , ( 8)   ˘l=−logp(˘v|X , s ) . ( 9 )   We then utilize an MLP network ( Rumelhart et al . ,   1986 ) with a single hidden layer followed by the   Sigmoid activation function to learn α :   α = f(h ) = Sigmoid ( MLP(h ) ) . ( 10 )   Scheme Three ( S3 ): The first and second schemes   require that the weights of the pseudo label ˘vand   vanilla label ˜vof each slot in each training sample   must add up to 1 . In reality , however , both ˘vand   ˜vcan be incorrect for some training samples , in   which case , it is beneficial to assign small weights   to both labels . In the third scheme , we remove the   constraint on the sum and adopt two weighting pa-   rameters to combine the pseudo labels and vanilla   labels . The combined label vis given by :   v= ˘α˘v+ ˜α˜v . ( 11 )   We learn ˘αand˜α(0≤˘α,˜α≤1 ) in the same   way as how αis learned in the second scheme :   ˘α = f(h ) = Sigmoid ( MLP(h ) ) , ( 12 )   ˜α = f(h ) = Sigmoid ( MLP(h ) ) . ( 13 )   It is noted that Eq . ( 11 ) can be rewritten as :   v= ( ˘α+ ˜α)/parenleftig   β˘v+ ( 1−β)˜v / parenrightig   , ( 14)where β= ˘α/(˘α+ ˜α ) . Comparing Eq . ( 14 )   to Eq . ( 5 ) , it can be seen that the main difference   is that the combined label is further weighted by   ˘α+ ˜α . This reweighting is expected to be able to   discard the training samples whose pseudo labels   and vanilla labels are both incorrect by adjusting   ˘α+ ˜αto be a small value .   In schemes S2 and S3 , the weighting parameters   are both slot - wise and instance - wise . Compared to   scheme S1 in which the weighting parameters are   only slot - wise , adding the instance - wise flexibility   can make the combined labels even more accurate   in the optimal case . For example , when the pseudo   label of slot sin a training sample is correct while   its vanilla label is wrong , the best αin scheme S2   will be 1.0 , which leads to 0 approximation error .   3.3 Learning Algorithm   When training the primary model , besides its own   parameters , the parameters of the learnable func-   tions that are used to predict the weights also need   to be optimized . Inspired by the common practice   that the best model checkpoint is chosen according   to the performance on the validation set , we decide   to employ the validation set as meta data and then   train the involved functions ( i.e. , f , f , fandf )   in a meta - learning manner .   For the sake of uniformly describing the learning   processes of the three proposed schemes , we unify   the combined label vas :   v = f(w)˘v+f(w)˜v , ( 15 )   where wandware the parameters of the learn-   able functions . Note that for schemes S1 ans S2 ,   f(w ) = 1−f(w ) . Then , the training objective   of the primary model is derived as :   L(Θ ) = 1   |D||S|/summationdisplay / summationdisplay−logp(v|X , s )   = 1   |D||S|/summationdisplay / summationdisplay / parenleftbig   f(w)˘l+f(w)˜l / parenrightbig   .   ( 16 )   Here , Θrepresents the parameters of the primary   model and is optimized by minimizing L(Θ ) , i.e. ,   Θ(w , w ) = arg minL(Θ ) . ( 17 )   The optimal parameters Θ(w , w)are expected   to achieve the best performance on the validation1160setD. Hence , we can optimize wandwin the   following way :   w , w= arg min / summationtext / summationtextl(Θ(w , w ) )   |D||S| ,   ( 18 )   where l(Θ(w , w ) ) = −logp(v|X , s)repre-   sents the loss of slot scorresponding to the valida-   tion sample X , calculated from the predictions of   the primary model with parameters Θ(w , w ) .   Batch - Based Online Approximation   As shown in Eqs . ( 17 ) and(18 ) , two nested loops   of optimization are required for calculating the op-   timal parameters Θ , wandw . Each single loop   on the whole dataset can be fairly expensive . Fol-   lowing ( Ren et al . , 2018 ) , we adopt an online strat-   egy to update Θ , wandwalternately through a   single optimization loop based on mini - batch data .   Algorithm 1 summarizes the overall training proce-   dure ( including auxiliary model training ) .   Algorithm 1 Learning algorithm of MetaASSIST   The procedure of training the primary model in   MetaASSIST is similar to that of standard model   training , except that three extra steps ( lines 11 - 13 )   are added . This is because the optimal combined la-   belvis unknown upon beginning . In Algorithm 1 ,   we choose to dynamically update vby adapting   wandw . At first , we use w andw to   derive vand train the primary model on batch Mfor one step , which results in an interim model with   parameters ˆΘ(w , w)(line 12 ) . Then ,   we apply this interim model to the validation batch   Mand compute the validation loss . By lowering   this loss ( e.g. , one - step optimization by SGD ) , we   obtain the updated wandw(line 13 ) . After   that , we use wandwto update vand apply   this new combined label to train the ( j−1)-th step   primary model on batch Magain , which eventu-   ally leads to the updated primary model ( line 14 ) .   4 Experimental Setup   4.1 Datasets   We conduct experiments mainly on MultiWOZ 2.4   ( Ye et al . , 2021a ) . It is the latest refined version of   MultiWOZ 2.0 ( Budzianowski et al . , 2018 ) , a large-   scale multi - domain task - oriented dialogue dataset   consisting of over 10,000 dialogues spanning seven   domains . The validation set and test set of Multi-   WOZ 2.4 have been carefully reannotated , while   its training set remains the same as that of Multi-   WOZ 2.1 ( Eric et al . , 2020 ) and is therefore noisy .   Following ( Ye et al . , 2022 ) , we adopt the validation   set as the small clean dataset . Thus , the validation   set is used to train both the auxiliary model and the   learnable functions . We also conduct experiments   on MultiWOZ 2.0 , whose validation set and test set   have been replaced with the counterparts of Multi-   WOZ 2.4 . Due to this change , we name the dataset   MultiWOZ 2.0 * in the following . The only differ-   ence between MultiWOZ 2.0 * and MultiWOZ 2.4   is that the training set of the former is much noisier .   4.2 Evaluation Metrics   We adopt Joint Goal Accuracy ( JGA ) , Joint Turn   Accuracy ( JTA ) and Slot Accuracy ( SA ) as evalu-   ation metrics . JGA is the primary metric for DST .   It refers to the ratio of dialogue turns of which the   entire state is correctly predicted . JTA is defined as   the ratio of dialogue turns in which the values of all   active slots are correctly predicted . A slot is said to   be active if its value needs to be updated . SA con-   siders only slot - level information and is calculated   as the average of all individual slot accuracies .   4.3 Auxiliary and Primary Models   We use the same auxiliary and primary models as   ASSIST to assess the effectiveness of MetaASSIST .   Since the clean dataset is small , a simple auxiliary   model AUX - DST was specially designed to avoid   overfitting ( Ye et al . , 2022 ) . AUX - DST leverages1161Primary   ModelFramework SchemeValidation Test   JGA(% ) JTA(% ) SA(% ) JGA(% ) JTA(% ) SA(% )   SOM - DSTASSISTα= 0.0 68.77 87.85 98.45 66.78 87.81 98.38   α= 1.0 77.35 91.05 98.98 68.69 88.41 98.55   α= 0.4 78.59 91.74 99.02 75.19 91.02 98.84   MetaASSISTS1 80.95 92.64 99.16 75.12 90.88 98.87   S2 78.87 92.01 99.07 76.74 91.65 98.95   S3 80.02 92.05 99.12 75.20 91.07 98.90   STARASSISTα= 0.0 74.33 90.26 98.86 74.84 90.77 98.92   α= 1.0 80.27 90.29 99.17 71.01 86.31 98.69   α= 0.4 82.68 92.93 99.26 79.41 91.86 99.14   MetaASSISTS1 83.40 93.03 99.32 77.80 90.85 99.05   S2 83.03 93.19 99.30 80.10 92.02 99.16   S3 83.13 93.45 99.30 79.37 91.84 99.12   AUX - DSTASSISTα= 0.0 72.47 89.57 98.78 70.37 89.31 98.67   α= 1.0 81.30 90.68 99.22 70.68 86.82 98.68   α= 0.4 83.97 93.49 99.33 78.14 91.03 99.07   MetaASSISTS1 83.89 93.41 99.33 77.25 91.16 99.04   S2 80.97 92.18 99.21 78.38 91.57 99.06   S3 81.99 92.88 99.24 78.57 92.09 99.08   slot - token attention to extract slot - specific infor-   mation and selects the value that best matches this   information as prediction . It is also adopted as one   primary model . The other primary models consid-   ered are : 1 ) SOM - DST ( Kim et al . , 2020 ) , an open   vocabulary method that regards the dialogue state   as a fixed - sized memory and selectively overwrites   this memory with new values ; and 2 ) STAR ( Ye   et al . , 2021b ) , an ontology - based method that uses   a stacked slot self - attention mechanism to learn the   correlations amongst slots automatically .   5 Results and Discussion   5.1 Main Results   Table 1 shows the performance of the three primary   models on MultiWOZ 2.4 trained using ASSIST   and our proposed framework MetaASSIST . We   observe that all three schemes in MetaASSIST sub-   stantially improve the performance of the primary   models on the test set compared to training with   only vanilla labels ( α= 0.0 ) or only pseudo la-   bels ( α= 1.0 ) . This observation indicates that the   proposed schemes are effective in learning appro - Frame Scheme JGA(% ) JTA(% ) SA(% )   ASSISTα= 0.045.14 77.86 96.71   α= 1.067.06 87.95 98.47   α= 0.670.83 89.14 98.61   Meta   ASSISTS1 70.18 88.69 98.60   S2 71.46 89.35 98.65   S3 70.48 88.84 98.60   priate weighting parameters for combining pseudo   labels and vanilla labels . Further , we observe that   scheme S2 consistently outperforms ASSIST with   the best common weighting parameter ( α= 0.4 ) ,   except the slot accuracy of AUX - DST . For example ,   STAR achieves 80.10 % joint goal accuracy when   using scheme S2 to learn the weighting parame-   ters . Table 2 presents the performance of SOM-   DST trained on MultiWOZ 2.0 * . It also shows that   scheme S2 achieves better results .   On both MultiWOZ 2.4 and MultiWOZ 2.0 * , we   find that the performance of scheme S1 slightly lags   behind ASSIST ( with the best value of α ) in terms   of joint goal accuracy , even though the weighting1162   DomainASSIST MetaASSIST   α= 0.0α= 0.4 S2   Attraction 83.22 86.56 88.62   Hotel 64.52 73.52 75.93   Restaurant 77.67 83.57 85.60   Taxi 54.76 63.65 67.71   Train 82.73 88.73 88.19   parameters learned in scheme S1 are slot - wise . The   reason we speculate is that the learning algorithm   fails to find the optimal slot - wise weighting param-   eters , but only the suboptimal ones . In § 5.4 , we   show that scheme S1 can actually outperform AS-   SIST when the weighting parameters are initialized   with the best value of αused in ASSIST .   As for scheme S3 , Table 1 shows that it achieves   the best performance when AUX - DST is adopted   as the primary model . For SOM - DST and STAR ,   its performance is comparable to the best results of   ASSIST . Table 1 also demonstrates that scheme S3   consistently outperforms scheme S1 . However , it is   inferior to scheme S2 when taking SOM - DST and   STAR as the primary model . Recall that scheme S3   has the highest degree of flexibility in weighting   parameters . These results suggest that while higher   flexibility can in principle yield better results , the   practical performance may not be particularly good   due to the difficulty of learning optimal values for   the weighting parameters .   From Table 1 , it can be further seen that scheme   S1 consistently achieves higher validation perfor-   mance than schemes S2 and S3 ( except the joint   turn accuracy of STAR ) . This might be confusing   because scheme S1 underperforms schemes S2 and   S3 on the test set . Moreover , the validation set is   utilized to train the learnable functions in the threeschemes . Hence , high validation performance is   expected . However , we found that the distributions   of the validation and test sets are not exactly the   same ( e.g. , some slot values only appear in the test   set ) . This implies that scheme S1 tends to overfit   the validation data . While scheme S2 and scheme   S3 suffer less from this issue , because the weight-   ing parameters in them are not only related to state   labels but also to the dialogue context .   5.2 Domain - Specific Accuracy   Apart from the overall performance comparison ,   we also investigate the performance improvements   in each domain . For this purpose , we report the   domain - specific joint goal accuracy of SOM - DST   on MultiWOZ 2.4 in Table 3 . As can be observed ,   MetaASSIST achieves the best performance in four   domains . In particular , MetaASSIST outperforms   ASSIST ( α= 0.4 ) by4.06absolute points in the   taxi domain . It can also be observed that MetaAS-   SIST consistently outperforms ASSIST across all   domains when ASSIST only considers vanilla la-   bels ( α= 0.0 ) .   5.3 Distribution of Learned Weights   Figure 2 illustrates the distribution of the learned   weights in each scheme . We conduct this study on   MultiWOZ 2.4 and use STAR as the primary model .   As shown in Figure 2 ( a ) , the learned weights in   scheme S1 indeed vary across slots . For most slots ,   the weights are less than 0.5 , indicating that their   vanilla labels are of higher quality than pseudo la-   bels . We also observe that the average weight of   each slot in scheme S2 is smaller than the corre-   sponding weight in scheme S1 . In fact , the learned   weights in scheme S2 are more consistent with the   optimal value used in ASSIST ( i.e. , 0.4).1163   Since schemes S2 and S3 are instance - wise , we   randomly select a slot and plot the distribution of   weights of this slot over all training samples . The   results are shown in Figures 2 ( b ) and ( c ) . As can be   seen , the learned weights vary across training sam-   ples . In scheme S2 , although the learned weights   for most training samples fall between 0.4 and 0.5 ,   there are also many samples whose weights can be   as small as 0 or as large as 1 . Note that scheme   S3 has two weighting parameters . We plot the dis-   tribution of their sums . It is interesting to observe   that the sums of most training samples are around   1 , even though we have removed the summation   constraint in scheme S3 . Nonetheless , we also ob-   serve that the sums of many training samples are   less than 1 , meaning that small weights have been   assigned to both pseudo labels and vanilla labels .   Figure 3 illustrates the distribution of weights in   scheme S2 relative to loss values of pseudo labels   and vanilla labels . We see that when both vanilla   loss and pseudo loss are very small , the weights are   around 0.5 . When the vanilla loss is much smaller   than the pseudo loss , the weights tend to be small .   And when the pseudo loss is much smaller than the   vanilla loss , the weights tend to be large .   The observations above confirm the strong capa-   bility of MetaASSIST in learning proper slot - wise   ( and instance - wise ) weights based on loss values .   5.4 Scheme S1 with Prior Knowledge   Given that the weighting parameters in scheme S1   are only slot - wise , we can readily initialize these   parameters with any specified value . This implies   that we can integrate prior knowledge into scheme   S1 . Specifically , we study using the optimal value   ofαfound in ASSIST to initialize its weighting pa-   rameters . The results on MultiWOZ 2.4 are shown   in Figure 4 . We observe that the prior knowledge   can effectively improve the performance of scheme   S1 for all three primary models . Furthermore , theresults demonstrate that scheme S1 can outperform   ASSIST when they use the same prior knowledge .   5.5 Performance over Training Epochs   Figure 5 depicts the changing curves of validation   accuracy and test accuracy over training epochs .   We utilize SOM - DST as the primary model and   conduct this experiment on MultiWOZ 2.4 . For   MetaASSIST , scheme S2 is applied . It is shown   that the validation and test accuracy using MetaAS-   SIST improves much faster than using ASSIST   during early training epochs . In subsequent epochs ,   the validation accuracy with MetaASSIST is also   higher and changes more smoothly .   6 Related Work   DST has been studied for more than one decade .   Traditional DST models rely on a separate language   understanding module to extract relevant informa-   tion ( Wang and Lemon , 2013 ; Williams , 2014 ) . In   recent years , designing DST models based on neu-   ral networks , especially pretrained language mod-   els , has become the mainstream and a large number   of neural DST models have been proposed ( Mrkši ´ c   et al . , 2017 ; Wu et al . , 2019 ; Hosseini - Asl et al . ,   2020 ; Zhu et al . , 2020 ; Lin et al . , 2021 ; Lee et al . ,   2021 ; Zhao et al . , 2021 ; Feng et al . , 2022 ; Hu et al . ,   2022 ; Guo et al . , 2022 ; Heck et al . , 2022 ; Man-   otumruksa et al . , 2022 ; Sun et al . , 2022 ) .   Although these neural DST models have demon-   strated good performance , they fail to consider the   effect of label noise . It has been shown that no mat-   ter how noisy the training data are , neural models   can easily overfit the training data ( Zhang et al . ,   2021 ) . As a result , the generalization performance   of models trained on noisy data is usually unsat-   isfactory . Recently , Ye et al . ( 2022 ) proposed a   general framework , ASSIST , to robustly train DST   models on noisy data . Their experimental results   show that several existing DST models can achieve1164much higher performance when trained under this   framework . However , as discussed earlier , ASSIST   contains a parameter that needs to be tuned on each   dataset . Besides , the parameter is shared among   all slots and all training samples , which we have   shown to be suboptimal . Our proposed framework   leverages meta learning to automatically learn slot-   wise ( and instance - wise ) parameters , overcoming   the limitations of ASSIST .   The essence of meta learning is learning to learn   ( Hospedales et al . , 2021 ; Zhu et al . , 2022 ) , which   makes it a natural fit for our task of automatically   learning parameters . We found that several exist-   ing works ( Huang et al . , 2020 ; Zeng et al . , 2021 ;   Dingliwal et al . , 2021 ) have already applied meta   learning to DST . These works directly adopt the   MAML ( Finn et al . , 2017 ) algorithm or its variants   and focus on improving the few - shot learning abil-   ity of DST models . While our focus is to improve   the robustness of DST models .   7 Conclusion   In this work , we proposed a meta learning - based   general framework MetaASSIST to robustly train   DST models on noisy data . MetaASSIST improves   ASSIST by automatically learning slot - wise ( and   instance - wise ) weighting parameters that are used   to combine pseudo labels and vanilla labels . Our   comprehensive experiments demonstrate the effec-   tiveness of MetaASSIST . For future work , we plan   to extend the current framework to utilize pseudo   labels generated by multiple auxiliary models .   Limitations   Our proposed framework MetaASSIST learns to   weight pseudo labels and vanilla labels by mini-   mizing the validation loss . Although it reduces the   impact of label noise on model training , it runs the   risk of biasing the trained model towards overfitting   the validation data . One may argue that selecting   the best model checkpoint based on validation per-   formance is a standard strategy in machine learning .   However , our empirical study shows that high per-   formance on the validation set does not necessarily   lead to high performance on the test set . This is   because the validation set and test set are usually   small , and their empirical data distributions can dif-   fer a lot . For a model trained with our framework   to have high generalization performance , the vali-   dation set should be unbiased , but this requirement   seems to be very demanding . In practice , we canaugment the validation set to alleviate this problem .   Another limitation is that our proposed learn-   ing algorithm is more time - consuming than regular   model training . As described in Algorithm 1 , for   each training batch , the model needs to perform   two forward and backward passes ( the first pass to   obtain the interim model , the second pass to ob-   tain the updated model ) . For each validation ( meta )   batch , the model also needs to perform one forward   and backwad pass . Therefore , the learning algo-   rithm needs 3×training time compared to regular   training . Nonetheless , compared to ASSIST , the   proposed framework MetaASSIST is more time-   efficient . For ASSIST , we need to try a large num-   ber of values for αto find the best one .   Ethics Statement   The DST module is an essential component in many   industrial and commercial dialogue systems . Per-   formance improvements on DST can help these sys-   tems better understand users ’ requirements , thereby   improving user satisfaction . Our proposed frame-   work could be applied to these systems and improve   their DST performance . The proposed framework   can also be applied to other NLP and machine learn-   ing applications .   Acknowledgements   This work was funded by the Alan Turing Institute   under the EPSRC grant EP / N510129/1 and the EP-   SRC Fellowship titled “ Task Based Information Re-   trieval ” and grant reference number EP / P024289/1 .   References116511661167Model Scheme Epochs Learning Rate   SOM - DSTS1 30 4e-5   S2 25 2e-5   S3 25 1e-5   STARS1 15 5e-5   S2 15 1e-5   S3 12 3e-5   AUX - DSTS1 12 1e-4   S2 15 2.5e-5   S3 12 2e-5   A Implementation Details   The MultiWOZ dataset contains seven domains : at-   traction , hotel , restaurant , taxi , train , hospital and   police . However , the hospital domain and police   domain only occur in the training set . Following   previous works ( Wu et al . , 2019 ; Kim et al . , 2020 ) ,   we remove the two domains . This results in five   domains with 30 slots in total .   For a fair comparison with ASSIST , we directly   employ the pseudo labels published by the authors   instead of training a new auxiliary model ourselves   to generate pseudo labels . For all primary models ,   we modify their released code to implement our   learning algorithm . All the primary models adopt   BERT ( Devlin et al . , 2019 ) as the dialogue con-   text encoder and are initialized using the pretrained   BERT - base - uncased model . As for the MLP net-   work in schemes S2 and S3 , we set the hidden layer   dimension to 768 . The output layer dimension is   fixed at 1 . The MLP network is randomly initial-   ized . For scheme S1 , we initialize the weighting   parameters to be 0.5 . For all primary models , we   adopt their default hyperparameter settings , except   the training epochs . For SOM - DST , we halve the   batch size due to its high GPU memory require-   ment . We fix the validation ( meta ) batch size at 8   for all three primary models . AdamW ( Loshchilov   and Hutter , 2017 ) is employed as the optimizer and   a linear scheduler with warmup is created to adjust   the learning rate dynamically . The warmup propor-   tion is fixed at 0.1 . Tables 4 and 5 summarize the   training epochs and peak validation ( meta ) learning   rate in each scheme for each model .   B Convergence Analysis   Considering that our proposed learning algorithm   optimizes the primary model and the learnable func - Model Scheme Epochs Learning Rate   SOM - DSTS1 25 3e-5   S2 25 1e-5   S3 25 8e-6   tion alternately , it is meaningful to study its conver-   gence . To this end , we plot the loss value curves   of training batch and validation ( meta ) batch over   training steps . We adopt AUX - DST as the primary   model and apply scheme S1 to learn the weighting   parameters . We conduct this experiment on Mul-   tiWOZ 2.4 . The results are illustrated in Figure 6 .   As can be observed , the training loss and validation   ( meta ) loss both converge to relatively small values   after sufficient training steps .   C Error Analysis   We further investigate the error rate with respect   to each slot . We adopt SOM - DST as the primary   model and compare scheme S2 to ASSIST with   the best value of α(α= 0.4 ) and ASSIST without   using the pseudo labels ( α= 0.0 ) . We conduct   the experiment on MultiWOZ 2.4 as well and the   results are illustrated in Figure 7 . It is shown that   MetaASSIST achieves lower error rates for 28 slots   when compared to ASSIST ( α= 0.0 ) . MetaAS-   SIST also outperforms ASSIST ( α= 0.4 ) on 18 of   the 30 slots . These results verify again the superi-   ority of our proposed framework MetaASSIST.11681169