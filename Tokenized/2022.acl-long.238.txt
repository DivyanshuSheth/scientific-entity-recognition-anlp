  Casey Meehan and Khalil Mrini and Kamalika Chaudhuri   UC San Diego   { cmeehan , kmrini , kamalika}@eng.ucsd.edu   Abstract   User language data can contain highly sensi-   tive personal content . As such , it is impera-   tive to offer users a strong and interpretable   privacy guarantee when learning from their   data . In this work , we propose SentDP : pure   local differential privacy at the sentence level   for a single user document . We propose a   novel technique , eepandidate , that com-   bines concepts from robust statistics and lan-   guage modeling to produce high - dimensional ,   general - purpose ϵ-SentDP document embed-   dings . This guarantees that any single sen-   tence in a document can be substituted with   any other sentence while keeping the embed-   dingϵ-indistinguishable . Our experiments in-   dicate that these private document embeddings   are useful for downstream tasks like sentiment   analysis and topic classification and even out-   perform baseline methods with weaker guaran-   tees like word - level Metric DP .   1 Introduction   Language models have now become ubiquitous   in NLP ( Devlin et al . , 2019 ; Liu et al . , 2019b ;   Alsentzer et al . , 2019 ) , pushing the state of the art   in a variety of tasks ( Strubell et al . , 2018 ; Liu et al . ,   2019a ; Mrini et al . , 2021 ) . While language models   capture meaning and various linguistic properties   of text ( Jawahar et al . , 2019 ; Yenicelik et al . , 2020 ) ,   an individual ’s written text can include highly sen-   sitive information . Even if such details are not   needed or used , sensitive information has been   found to be vulnerable and detectable to attacks   ( Pan et al . , 2020 ; Abdalla et al . , 2020 ; Carlini   et al . , 2020 ) . Reconstruction attacks ( Xie and Hong ,   2021 ) have even successfully broken through pri-   vate learning schemes that rely on encryption - type   methods ( Huang et al . , 2020 ) .   As of now , there is no broad agreement on   what constitutes good privacy for natural language   ( Kairouz et al . , 2019 ) . Huang et al . ( 2020 ) ar-   gue that different applications and models require   different privacy definitions . Several emerging   works propose to apply Metric Differential Privacy   ( Alvim et al . , 2018 ) at the word level ( Feyisetan   et al . , 2019 ; Feyisetan and Kasiviswanathan , 2021 ;   Carvalho et al . , 2021 ; Qu et al . , 2021 ; Yue et al . ,   2021 ; Xu et al . , 2021 ) . They propose to add noise   to word embeddings , such that they are indistin-   guishable from their nearest neighbours .   At the document level , however , the above defi-   nition has two areas for improvement . First , it may   not offer the level of privacy desired . Having each   word indistinguishable with similar words may not   hide higher level concepts in the document , and   may not be satisfactory for many users . Second ,   it may not be very interpretable or easy to com-   municate to end - users , since the privacy definition   relies fundamentally on the choice of embedding   model to determine which words are indistinguish-   able with a given word . This may not be a clear   and precise enough for end - users to grasp .   In this work , we propose a new privacy defini-   tion for documents : sentence privacy . This guaran-   tee is both strong and interpretable : any sentence   in a document must be indistinguishable with any   other sentence . A document embedding is sentence-   private if we can replace any single sentence in the   document and have a similar probability of produc-   ing the same embedding . As such , the embedding   only stores limited information unique to any given   sentence . This definition is easy to communicate   and strictly stronger than word - level definitions , as   modifying a sentence can be changing one word.3367   Although this definition is strong , we are able   to produce unsupervised , general embeddings of   documents that are useful for downstream tasks   like sentiment analysis and topic classification . To   achieve this we propose a novel privacy mecha-   nism , eepandidate , which privately samples a   high - dimensional embedding from a preselected   set of candidate embeddings derived from public ,   non - private data.eepandidate works by first pre-   tuning a sentence encoder on public data such that   semantically different document embeddings are   far apart from each other . Then , we approximate   each candidate ’s Tukey Depth within the private   documents ’ sentence embeddings . Deeper candi-   dates are the most likely to be sampled to represent   the private document . We evaluateeepandidate   on three illustrative datasets , and show that these   unsupervised private embeddings are useful for   both sentiment analysis and topic classification as   compared to baselines .   In summary , this work makes the following con-   tributions to the language privacy literature :   1.A new , strong , and interpretable privacy defi-   nition that offers complete indistinguishability   to each sentence in a document .   2.A novel , unsupervised embedding technique , eepandidate , to generate sentence - private   document embeddings .   3.An empirical assessment ofeepandidate ,   demonstrating its advantage over baselines ,   delivering strong privacy and utility .   2 Background and Related Work   Setting . We denote a ‘ document ’ as a sequence of   sentences . Let s∈ S be any finite - length sentence . Then , the space of all documents is X = Sand   document x∈ X is written as x= ( s , s , . . . , s )   for any non - negative integer kof sentences . In   this work , we focus on cohesive documents of sen-   tences written together like reviews or emails , but   our methods and guarantees apply to any sequence   of sentences , such as a collection of messages writ-   ten by an individual over some period of time .   Our task is to produce an embedding z∈Rof   any document x∈ X such that any single sentence   s∈xis indistinguishable with every other sen-   tence s∈ S\s . That is , if one were to replace any   single sentence in the document s∈xwith any   other sentence s∈ S\ s , the probability of pro-   ducing a given embedding zis similar . To achieve   this , we propose a randomized embedding function   ( the embedding mechanism ) M :X →R , that   generates a private embedding z = M(x)that is   useful for downstream tasks .   2.1 Differential Privacy   The above privacy notion is inspired by Differential   Privacy ( DP ) ( Dwork , 2006 ) . It guarantees that —   whether an individual participates ( dataset D ) or   not ( dataset D ) — the probability of any output   only chances by a constant factor .   Definition 2.1 ( Differential Privacy ) .Given any   pair of datasets D , D∈ D that differ only in the   information of a single individual , we say that the   mechanism A :D → O , satisfies ϵ-DP if   Pr[A(D)∈O]≤ePr[A(D)∈O ]   for any event O⊆ O .   Note that we take probability over the random-   ness of the mechanism Aonly , not the data distri-   bution . DP has several nice properties that make3368it easy to work with including closure under post-   processing , an additive privacy budget ( composi-   tion ) , and closure under group privacy guarantees   ( guarantees to a subset of multiple participants ) .   See Dwork et al . 2014 for more details .   When our output space is a discrete and fi-   nite set of alternatives to choose from O=   ( o , o , . . . , o ) , we may use the exponential mech-   anism to satisfy ϵ-DP ( McSherry and Talwar , 2007 ) .   To do so , we specify a utility function over in-   put / output pairs , u :D × O → R. The utility   of choosing alternative o∈ O when the input is   dataset D∈ D is then given by u(D , o ) . The   sensitivity ofu(·,·)is the worst - case change in   utility over pairs of neighboring datasets , ∆u=   max|u(D , o)−u(D , o)| .   Definition 2.2 . Theexponential mechanism A :   D → O is a randomized algorithm with output   distribution   Pr[A(D ) = o]∝exp ϵu(x , r )   2∆u   .   2.2 Related Work   Natural Language Privacy . Previous work has   demonstrated that NLP models and embeddings   are vulnerable to reconstruction attacks ( Carlini   et al . , 2020 ; Abdalla et al . , 2020 ; Pan et al . , 2020 ) .   In response there have been various efforts to de-   sign privacy - preserving techniques and definitions   across NLP tasks . A line of work focuses on how   to make NLP model training satisfy DP ( Kerrigan   et al . , 2020 ; Bagdasaryan et al . , 2019 ) . This is dis-   tinct from our work in that it satisfies central DP   – where data is first aggregated non - privately and   then privacy preserving algorithms ( i.e. training )   are run on that data . We model this work of the   local version of DP ( Dwork et al . , 2006 ) , wherein   each individual ’s data is made private before cen-   tralizing . Our definition guarantees privacy to a   single document as opposed to a single individual .   A line of work more comparable to our approach   makes documents locally private by generating a   randomized version of a document that satisfies   some formal privacy definition . As with the pri-   vate embedding of our work , this generates locally   private representation of a given document x. The   overwhelming majority of these methods satisfy an   instance of Metric - DP ( Alvim et al . , 2018 ) at the   word level ( Feyisetan et al . , 2019 ; Feyisetan and   Kasiviswanathan , 2021 ; Carvalho et al . , 2021 ; Qu   et al . , 2021 ; Yue et al . , 2021 ; Xu et al . , 2021 ) . As   discussed in the introduction , this guarantees thata document xis indistinguishable with any other   document xproduced by swapping a single word   inxwith a similar word . Two words are ‘ similar ’   if they are close in the word embeddings space ( e.g.   GloVe ) . This guarantee is strictly weaker than our   proposed definition , SentDP , which offers indistin-   guishability to any two documents that differ in an   entire sentence .   Privacy - preserving embeddings . There is a   large body of work on non - NLP privacy - preserving   embeddings , as these embeddings have been shown   to be vulnerable to attacks ( Song and Raghunathan ,   2020 ) . Li and Clifton ( 2021 ) attempt to generate   locally private embeddings by bounding the em-   bedding space , and we compare with this method   in our experiments . Kamath et al . ( 2019 ) propose   a method for privately publishing the average of   embeddings , but their algorithm is not suited to op-   erate on the small number of samples ( sentences ) a   given document offers . Finally , Beimel et al . ( 2019 )   propose a method for privately learning halfspaces   inR , which is relevant to private Tukey Medi-   ans , but their method would restrict input examples   ( sentence embeddings ) to a finite discrete set in R ,   a restriction we can not tolerate .   3 Sentence - level Privacy   We now introduce our simple , strong privacy defi-   nition , along with concepts we use to satisfy it .   3.1 Definition   In this work , we adopt the local notion of DP   ( Dwork et al . , 2006 ) , wherein each individual ’s data   is guaranteed privacy locally before being reported   and centralized . Our mechanism Mreceives a   single document from a single individual , x∈ X.   We require that Mprovides indistinguishability   between documents x , xdiffering in one sentence .   Definition 3.1 ( Sentence Privacy , SentDP ) .Given   any pair of documents x , x∈ X that differ only in   one sentence , we say that a mechanism   M :X → O satisfies ϵ-SentDP if   Pr[M(x)∈O]≤ePr[M(x)∈O ]   for any event O⊆ O .   We focus on producing an embedding of the   given document x , thus the output space is O = R.   For instance , consider the neighboring documents   x= ( s , s , . . . , s)andx= ( s , s , . . . , s)that   differ in the second sentence , i.e. s , scan be3369anypair of sentences in S. This is a strong no-   tion of privacy in comparison to existing definitions   across NLP tasks . However , we show that we can   guarantee SentDP while still providing embeddings   that are useful for downstream tasks like sentiment   analysis and classification . In theory , a SentDP   private embedding zshould be able to encode any   information from the document that is not unique   to a small subset of sentences . For instance , z   can reliably encode the sentiment of xas long as   multiple sentences reflect the sentiment . By the   group privacy property of DP , which SentDP main-   tains , two documents differing in asentences are   aϵindistinguishable . So , if more sentences reflect   the sentiment , the more Mcan encode this into z   without compromising on privacy .   3.2 Sentence Mean Embeddings   Our approach is to produce a private version of   the average of general - purpose sentence embed-   dings . By the post - processing property of DP , this   embedding can be used repeatedly in any fashion   desired without degrading the privacy guarantee .   Our method makes use of existing pre - trained sen-   tence encoding models . We denote this general   sentence encoder as G : S →R. We show in our   experiments that the mean of sentence embeddings ,   g(x ) = XG(s ) , ( 1 )   maintains significant information unique to the doc-   ument and is useful for downstream tasks like clas-   sification and sentiment analysis .   We call g(x)thedocument embedding since it   summarizes the information in document x. While   there exist other definitions of document embed-   dings ( Yang et al . , 2016 ; Thongtan and Phien-   thrakul , 2019 ; Bianchi et al . , 2020 ) , we decide to   use averaging as it is a simple and established em-   bedding technique ( Bojanowski et al . , 2017 ; Gupta   et al . , 2019 ; Li et al . , 2020 ) .   3.3 Tukey Depth   Depth is a concept in robust statistics used to de-   scribe how central a point is to a distribution . We   borrow the definition proposed by Tukey ( 1975 ):   Definition 3.2 . Given a distribution PoverR , the   Tukey Depth of a point y∈Ris   TD(y ) = infP{y : w·(y−y)≥0}.In other words , take the hyperplane orthogonal   to vector w , h , that passes through point y. Let   Pbe the probability under Pthat a point lands on   one side of hand let Pbe the probability that a   point lands on the other side , so P+P= 1.yis   considered deep if min(P , P)is close to a half   forallvectors w(and thus all hpassing through y ) .   TheTukey Median of distribution P , T(P ) , is   the set of all points with maximal Tukey Depth ,   T(P ) = arg maxTD(y ) . ( 2 )   We only access the distribution Pthrough a finite   sample i.i.d . points , Y={y , y , . . . , y } . The   Tukey Depth w.r.t . Yis given by   TD(y ) = inf|{y∈Y : w·(y−y)≥0}| ,   and the median , T(Y ) , maximizes the depth   and is at most half the size of our sample   .   Generally , finding a point in T(Y)is hard ;   SOTA algorithms have an exponential dependency   in dimension ( Chan , 2004 ) , which is a non - starter   when working with high - dimensional embeddings .   However , there are efficient approximations which   we will take advantage of .   4eepandidate   While useful and general , the document em-   bedding g(x)does not satisfy SentDP . We now   turn to describing our privacy - preserving tech-   nique , eepandidate , which generates general ,   ϵ-SentDP document embeddings that preserve rele-   vant information in g(x ) , and are useful for down-   stream tasks . To understand the nontrivial nature   of this problem , we first analyze why the simplest ,   straightfoward approaches are insufficient .   Motivation . Preserving privacy for high dimen-   sional objects is known to be challenging ( Kamath   et al . , 2019 ; Feyisetan and Kasiviswanathan , 2021 ;   Zhou et al . , 2009 ) . For instance , adding Laplace   noise directly to g(x ) , as done to satisfy some pri-   vacy definitions ( Feyisetan et al . , 2019 ; Alvim et al . ,   2018 ) , does not guarantee SentDP for any ϵ. Recall   that the embedding space is all of R. A change   in one sentence can lead to an unbounded change   ing(x ) , since we do not put any restrictions on   the general encoder G. Thus , no matter how much   noise we add to g(x)we can not satisfy SentDP .   A straightforward workaround might be to sim-   ply truncate embeddings such that they all lie in3370a limited set such as a sphere or hypercube as   done in prior work ( Li and Clifton , 2021 ; Abadi   et al . , 2016 ) . In doing so , we bound how far   apart embeddings can be for any two sentences ,   ∥G(s)−G(s)∥ , thus allowing us to satisfy   SentDP by adding finite variance noise . However ,   such schemes offer poor utility due to the high di-   mensional nature of useful document embeddings   ( we confirm this in our experiments ) . We must add   noise with standard deviation proportional to the   dimension of the embedding , thus requiring an un-   tenable degree of noise for complex encoders like   BERT which embed into R.   Our method has three pillars : ( 1)sampling from   a candidate set of public , non - private document   embeddings to represent the private document , ( 2 )   using the Tukey median to approximate the docu-   ment embedding , and ( 3)pre - training the sentence   encoder , G , to produce relevant candidates with   high Tukey depth for private document x.   4.1 Taking advantage of public data :   sampling from candidates   Instead of having our mechanism select a private   embedding zfrom the entire space of R , we focus   the mechanism to select from a set of mcandi-   date embeddings , F , generated by mpublic , non-   private documents . We assume the document xis   drawn from some distribution µover documents X.   For example , if we know xis a restaurant review , µ   may be the distribution over all restaurant reviews .   Fis then a collection of document embeddings   overmpublicly accessible documents x∼µ ,   F={f = g(x ) :x , . . . , x∼µ } ,   and denote the corresponding distribution over f   asg(µ ) . By selecting documents Fto be similar   in nature to the private document x , we inject an   advantageous inductive bias into our mechanism ,   which is critical to satisfy strong privacy while   preserving meaningful information relevant to x.   4.2 Approximating the document embedding :   The Tukey Median   We now propose a novel mechanism M , which   approximates g(x)by sampling a candidate embed-   ding from F.Mworks by concentrating prob-   ability on candidates with high Tukey Depth w.r.t .   the set of sentence embeddings S={G(s ) :   s∈x } . We model sentences sfrom document   xas i.i.d . draws from distribution ν . Then , Siskdraws from g(ν ) , the distribution of sentences   fromνpassing through G. Deep points are a good   approximation of the mean under light assumptions .   Ifg(ν)belongs to the set of halfspace - symmetric   distributions ( including all elliptic distributions e.g.   Gaussians ) , we know that its mean lies in the Tukey   Median ( Zhu et al . , 2020 ) .   Formally , Mis an instance of the exponential   mechanism ( Definition 2.2 ) , and is defined by its   utility function . We set the utility of a candidate   document embedding f∈Fto be an approxima-   tion of its depth w.r.t . sentence embeddings S ,   u(x , f ) = cTD(f ) . ( 3 )   The approximation cTD , which we detail in the   Appendix , is necessary for computational effi-   ciency . If the utility of fis high , we call it a   ‘ deep candidate ’ for sentence embeddings S.   The more candidates sampled ( higher m ) , the   higher the probability that at least one has high   depth . Without privacy , we could report the deep-   est candidate , z = arg maxcTD(f ) . However ,   when preserving privacy with M , increasing m   has diminishing returns . To see this , fix a set of sen-   tence embeddings Sfor document xand the i.i.d .   distribution over candidate embeddings f∼g(µ ) .   This induces a multinomial distribution over depth ,   u(x ) = Pr [ u(x , f ) = j],Xu(x ) = 1 ,   where randomness is taken over draws of f.   For candidate set Fand sentence embeddings   S , the probability of M ’s selected candidate , z ,   having ( approximated ) depth jis given by   Pr[u(x , z ) = j ] = a(x)e   Pa(x)e(4 )   where a(x)is the fraction of candidates in Fwith   depth jw.r.t . the sentence embeddings of document   x , S. Formsufficiently large , a(x)concentrates   around u(x ) , so further increasing mdoes not   increase the probability of Msampling a deep   candidate .   For numerical intuition , suppose m= 5000 ( as   in our experiments ) , ≥bcandidates have depth   ≥j , and all other candidates have depth 0 , M   will sample one of these deep candidates w.p . ≥   0.95under the settings in Table 1 .   For low ϵ < 10(high privacy ) , about 1 % of can-   didates need to have high depth ( ≥3)in order to be3371   ϵ bj   3 55 5   6 25 3   10 5 2   23 1 1   reliably sampled . Note that this is only possible for   documents with ≥6sentences . For higher ϵ≥10 ,   Mwill reliably sample low depth candidates   even if there are only a few .   From these remarks we draw two insights on   howeepandidate can achieve high utility .   ( 1)More sentences A higher kenables greater   depth , and thus a higher probability of sampling   deep candidates with privacy . We explore this ef-   fect in our experiments .   ( 2)Tuned encoder By tuning the sentence encoder   Gfor a given domain , we can modify the distribu-   tion over document embeddings g(µ)and sentence   embeddings g(ν)to encourage deep candidates   ( high probability ufor deep j ) that are relevant to   document x.   4.3 Taking advantage of structure :   cluster - preserving embeddings   So far , we have identified that deep candidates from   Fcan approximate g(x ) . To produce a good ap-   proximation , we need to ensure that 1 ) there re-   liably exist deep candidates for any given set of   sentence embeddings S , and 2 ) that these deep   candidates are good representatives of documentx . The general sentence encoder Gused may not   satisfy this ‘ out of the box ’ . If the distribution   on document embeddings g(µ)is very scattered   around the instance space R , it can be exceed-   ingly unlikely to have a deep candidate famong   sentence embeddings S. On the other hand , if   distribution g(µ)is tightly concentrated in one re-   gion ( e.g. ‘ before training ’ in Figure 3 ) , then we   may reliably have many deep candidates , but sev-   eral will be poor representatives of the document   embedding g(x ) .   To prevent this , we propose an unsupervised , effi-   cient , and intuitive modification to the ( pretrained )   sentence encoder G. We freeze the weights of G   and add additional perceptron layers mapping into   the same embeddings space H : R→R , pro-   ducing the extended encoder G = H ◦ G. Broadly ,   we train Hto place similar document embeddings   close together , and different embeddings far part .   To do so , we leverage the assumption that a given   domain ’s distribution over document embeddings   g(µ)can be parameterized by nclusters , visu-   alized as the black circles in Figure 3 . H ’s aim   is to recode sentence embeddings such that docu-   ment embedding clusters are preserved , but spaced   apart from each other . By preserving clusters , we   are more likely to have deep candidates ( increased   probability ufor high depth j ) . By spacing clus-   ters apart , these deep candidates are more likely   to come from the same or a nearby cluster as doc-   ument x , and thus be good representatives . Note   thatHis domain - specific : we train separate H   encoders for each dataset .   4.4 Sampling Algorithm   The final component ofeepandidate is comput-   ing the approximate depth of a candidate for use   as utility in the exponential mechanism as in Eq .   ( 3 ) . We use a version of the approximation al-   gorithm proposed in Gilad - Bachrach and Burges   2012 . Intuitively , our algorithm computes the one-   dimensional depth of each famong x ’s sentence   embeddings Son each of prandom projections .   The approximate depth of fis then its lowest depth   across the pprojections . We are guaranteed that   cTD(f)≥TD(f ) . Due to space constraints ,   we leave the detailed description of the algorithm   for the Appendix .   Theorem 4.1 . Msatisfies ϵ-Sentence Privacy   Proof follows from the fact that cTD(f)has   bounded sensitivity ( changing one sentence can3372   only change depth of fby one ) . We expand on   this , too , in the Appendix .   5 Experiments   5.1 Datasets   We produce private , general embeddings of docu-   ments from three English - language datasets :   Good Reads ( Wan and McAuley , 2018 ) 60k   book reviews from four categories : fantasy , his-   tory , romance , and childrens literature . Train-48k |   Val-8k | Test-4k   20 News Groups ( Lang , 1995 ) 11239 corre-   spondences from 20 different affinity groups .   Due to similarity between several groups   ( e.g. comp.os.ms-windows.misc and   comp.sys.ibm.pc.hardware ) , the dataset   is partitioned into nine categories . Train-6743k |   Val-2247k | Test-2249k   IMDB ( Maas et al . , 2011 ) 29k movie reviews   from the IMDB database , each labeled as a positive   or negative review . Train-23k | Val-2k | Test-4k   To evaluate utility of these unsupervised , private   embeddings , we check if they are predictive of   document properties . For the Good Reads and20   News Groups datasets , we evaluate how useful the   embeddings are for topic classification . For IMDB   we evaluate how useful the embeddings are for   sentiment analysis ( positive or negative review ) .   Our metric for performance is test - set macro Fscore .   5.2 Training Details & Setup   For the general encoder , G : S →R , we use   SBERT ( Reimers and Gurevych , 2019 ) , a version   of BERT fine - tuned for sentence encoding . Sen-   tence embeddings are generated by mean - pooling   output tokens . In all tasks , we freeze the weights of   SBERT . The cluster - preserving recoder , H , as well   as every classifier is implemented as an instance   of a 4 - layer MLP taking 768 - dimension inputs and   only differing on output dimension . We denote an   instance of this MLP with output dimension oas   MLP . We run 5 trials of each experiment with ran-   domness taken over the privacy mechanisms , and   plot the mean along with a ±1 standard deviation   envelope.eepandidate : The candidate set Fconsists   of 5k document embeddings from the training set ,   each containing at least 8 sentences . To train G ,   we find n= 50 clusters with k - means . We train a   classifier C = MLPon document embeddings   g(x)to predict class , where ris the number of   classes ( topics or sentiments ) .   5.3 Baselines   We compare the performance ofeepandidate   with 4 baselines : Non - private , Truncation , Word-   level Metric - DP , and Random Guesser .3373Non - private : This demonstrates the usefulness   of non - private sentence - mean document embed-   dings g(x ) . We generate g(x)for every document   using SBERT , and then train a classifier C =   MLPto predict x ’s label from g(x ) .   Truncation : We adopt the method from Li and   Clifton 2021 to truncate ( clip ) sentence embed-   dings within a box in R , thereby bounding sen-   sitivity as described at the beginning of Section   4 . Laplace noise is then added to each dimension .   Documents with more sentences have proportion-   ally less noise added due to the averaging operation   reducing sensitivity .   Word Metric - DP ( MDP ): The method from   Feyisetan et al . 2019 satisfies ϵ-word - level metric   DP by randomizing words . We implement MDP to   produce a randomized document x , compute g(x )   with SBERT , and predict class using C .   Random Guess : To set a bottom - line , we show   the theoretical performance of a random guesser   only knowing the distribution of labels .   5.4 Results & Discussion   How does performance change with privacy pa-   rameter ϵ ?   This is addressed in Figures 4a to 4c . Here , we   observe how the test set macro Fscore changes   with privacy parameter ϵ(a lower ϵoffers stronger   privacy ) . Generally speaking , for local differen-   tial privacy , ϵ < 10is taken to be a strong privacy   regime , 10≤ϵ < 20is moderate privacy , and   ϵ≥25is weak privacy . The truncation baseline   mechanism does increase accuracy with increasing   ϵ , but never performs much better than the random   guesser . This is to be expected with high dimension   embeddings , since the standard deviation of noise   added increases linearly with dimension .   The word - level MDP mechanism performs sig-   nificantly better than truncation , achieving rela-   tively good performance for ϵ≥30 . There are   two significant caveats , however . First , is the pri-   vacy definition : as discussed in the Introduction ,   for the same ϵ , word - level MDP is strictly weaker   than SentDP . The second caveat is the level of ϵ   at which privacy is achieved . Despite a weaker   privacy definition , the MDP mechanism does not   achieve competitive performance until the weak-   privacy regime of ϵ. We suspect this is due to two   reasons . First , is the fact that the MDP mechanism   does not take advantage of contextual information   in each sentence as our technique does ; randomiz - ing each word independently does not use higher   level linguistic information . Second , is the fact   that the MDP mechanism does not use domain-   specific knowledge as our mechanism does with   use of relevant candidates and domain specific sen-   tence encodings .   In comparison , eepandidate offers strong util-   ity across tasks and datasets for relatively low val-   ues of ϵ , even into the strong privacy regime . Be-   yond ϵ= 25 , the performance ofeepandidate   tends to max out , approximately 10 - 15 % below   the non - private approach . This is due to the fact   thateepandidate offers a noisy version of an   approximation of the document embedding g(x )   – it can not perform any better than deterministi-   cally selecting the deepest candidate , and even this   candidate may be a poor representative of x. We   consider this room for improvement , since there   are potentially many other ways to tune Gand se-   lect the candidate pool Fsuch that deep candidates   are nearly always good representatives of a given   document x.   How does performance change with the number   of sentences k ?   This is addressed in Figures 4d to 4f . We limit   the test set to those documents with kin the listed   range on the x - axis . We set ϵ= 10 , the limit of   the strong privacy regime . Neither baseline offers   performance above that of the random guesser at   this value of ϵ.eepandidate produces precisely   the performance we expect to see : documents with   more sentences result in sampling higher quality   candidates , confirming the insights of Section 4.2 .   Across datasets and tasks , documents with more   than 10 - 15 sentences tend to have high quality em-   beddings .   6 Conclusions and Future Work   We introduce a strong and interpretable local pri-   vacy guarantee for documents , SentDP , along witheepandidate , a technique that combines princi-   ples from NLP and robust statistics to generate   general ϵ-SentDP embeddings . Our experiments   confirm that such methods can outperform exist-   ing approaches even with with more relaxed pri-   vacy guarantees . Previous methods have argued   that it is “ virtually impossible ” to satisfy pure lo-   cal DP ( Feyisetan et al . , 2019 ; Feyisetan and Ka-   siviswanathan , 2021 ) at the word level while cap-   turing linguistic semantics . Our work appears to   refute this notion at least at the document level .   To follow up , we plan to explore other ap-3374proaches ( apart from k - means ) of capturing the   structure of the embedding distribution g(µ)to en-   courage better candidate selection . We also plan to   experiment with decoding private embeddings back   to documents by using novel candidates produced   by a generative model trained on F.   Acknowledgements   KC and CM would like to thank ONR under   N00014 - 20 - 1 - 2334 . KM gratefully acknowledges   funding from an Amazon Research Award and   Adobe Unrestricted Research Gifts . We would   would also like to thank our reviewers for their   insightful feedback .   References337533763377A Appendix   A.1 Privacy Mechanism   We now describe in detail our instance of the expo-   nential mechanism M. Recall from Definition   2.2 that the exponential mechanism samples candi-   datef∈Fwith probability   Pr[M(x ) = f]∝exp ϵu(x , f )   2∆u   .   Thus , Mis fully defined by its utility function ,   which , as listed in Equation ( 3 ) , is approximate   Tukey Depth ,   u(x , f ) = cTD(f ) .   We now describe our approximation algorithm of   Tukey Depth cTD(f ) , which is an adaptation of   the general median hypothesis algorithm proposed   by Gilad - Bachrach and Burges ( 2012 ) .   Note that we can precompute the projections on   line 10 . The runtime is O(mkp ): for each of m   candidates and on each of pprojections , we need   to compute the scalar difference with ksentence   embeddings . Sampling from the multinomial dis-   tribution defined by Pthen takes O(m)time .   Additionally note from lines 13 and 15 that util-   ity has a maximum of 0 and a minimum of − ,   which is a semantic change from the main paper   where maximum utility isand minimum is 0 .   A.2 Proof of Privacy   Theorem 4.1 Msatisfies ϵ-Sentence Privacy   Proof . It is sufficient to show that the sensitivity ,   ∆u= max|u(x , f)−u(x , f)| ≤1 .   Let us expand the above expression using the terms   in Algorithm 1 .   ∆u= max|maxu(x , f)−maxu(x , f)|   = max|min  h(x , f)−k   2   −min  h(x , f)−k   2  |   ≤max|min  h(x , f)−k   2   −    min  h(x , f)−k   2  −1   |   ≤1Algorithm 1 : Mcompute probabilities   Input : mcandidates F ,   sentence embs . S= ( s , . . . , s ) ,   number of projections p   Output : probability of sampling each   candidate P= [ P , . . . , P]v , . . . , v←random vecs . on unit spherefori∈[k]do forj∈[p]do s←sv end forend forfori∈[m]do forj∈[p]do f←fv h(x , f)←#{s : s≥f , l∈   [ k ] } u(x , f)← −  h(x , f)−   end for u(x , f)←maxu(x , f )   ˆP←exp(ϵu(x , f)/2)end forΨ←PˆPfori∈[m]do P←ˆPend forreturn P3378The last step follows from the fact that |h(x , f)−   h(x , f)| ≤1for all j∈[p ] . In other words , by   modifying a single sentence embedding , we can   only change the number of embeddings greater   thanfon projection jby 1 . So , the distance   ofh(x , f)fromcan only change by 1 on   each projection . In the ‘ worst case ’ , the distance  h(x , f)−  reduces by 1 on every projection v.   Even then , the minimum distance fromacross   projections ( the worst case depth ) can only change   by 1 , giving us a sensitivity of 1 .   A.3 Experimental Details   Here , we provide an extended , detailed version of   section 5 .   For the general encoder , G : S →R , we use   SBERT ( Reimers and Gurevych , 2019 ) , a version   of BERT fine - tuned for sentence encoding . Sen-   tence embeddings are generated by mean - pooling   output tokens . In all tasks , we freeze the weights of   SBERT . The cluster - preserving recoder , H , as well   as every classifier is implemented as an instance   of a 4 - layer MLP taking 768 - dimension inputs and   only differing on output dimension . We denote an   instance of this MLP with output dimension oas   MLP . We run 5 trials of each experiment with ran-   domness taken over the privacy mechanisms , and   plot the mean along with a ±1 standard deviation   envelope .   Non - private : For our non - private baseline , we   demonstrate the usefulness of sentence - mean docu-   ment embeddings . First , we generate the document   embeddings g(x)for each training , validation , and   test set document using SBERT , G. We then train   a classifier C = MLPto predict each docu-   ment ’s topic or sentiment , where ris the number   of classes . The number of training epochs is deter-   mined with the validation set.eepandidate : We first collect the candidate   setFby sampling 5k document embeddings from   the subset of the training set containing at least 8   sentences . We run k - means with n= 50 clus-   ter centers , and label each training set document   embedding t∈Twith its cluster . The sentence   recoder , H = MLPis trained on the training set   along with the linear model Lwith the Adam opti-   mizer and cross - entropy loss . For a given document   x , its sentence embeddings Sare passed through   H , averaged together , and then passed to Lto pre-   dictx ’s cluster . L ’s loss is then back - propagatedthrough H. A classifier C = MLPis trained   in parallel using a separate instance of the Adam   optimizer to predict class from the recoded em-   beddings , where ris the number of classes ( topics   or sentiments ) . The number of training epochs is   determined using the validation set . At test time ,   ( generating private embeddings using M ) , the   optimal number of projections pis empirically cho-   sen for each ϵusing the validation set .   Truncation : The truncation baseline ( Li and   Clifton , 2021 ) requires first constraining the em-   bedding instance space . We do so by computing   the 75 % median interval on each of the 768 di-   mensions of training document embeddings T.   Sentence embeddings are truncated at each dimen-   sion to lie in this box . In order to account for this   distribution shift , a new classifier C = MLP   is trained on truncated mean embeddings to predict   class . The number of epochs is determined with   the validation set . At test time , a document ’s sen-   tence embeddings Sare truncated and averaged .   We then add Laplace noise to each dimension with   scale factor , where wis the width of the box   on that dimension ( sensitivity in DP terms ) . Note   that the standard deviation of noise added is in-   versely proportional to the number of sentences   in the document , due to the averaging operation   reducing sensitivity .   Word Metric - DP : Our next baseline satisfies ϵ-   word - level metric DP and is adopted from ( Feyise-   tan et al . , 2019 ) . The corresponding mechanism   MDP :X → X takes as input a document xand   returns a private version , x , by randomizing each   word individually . For comparison , we generate   document embeddings by first randomizing the doc-   ument x = MDP ( x)as prescribed by ( Feyisetan   et al . , 2019 ) , and then computing its document em-   bedding g(x)using SBERT . At test time , we clas-   sify the word - private document embedding using   C .   Random Guess : To set a bottom - line , we show   the theoretical performance of a random guesser .   The guesser chooses class iwith probability q   equal to the fraction of ilabels in the training set .   The performance is then given byPq .   A.4 Reproducability Details   We plan to publish a repo of code used to gener-   ate the exact figures in this paper ( random seeds   have been set ) with the final version . Since we do3379not train the BERT base model G , our algorithms   and training require relatively little computational   resouces . Our system includes a single Nvidia   GeForce RTX 2080 GPU and a single Intel i9 core .   All of our models complete an epoch training on   all datasets in less than one minute . We never do   more than 20 epochs of training . All of our clas-   sifier models train ( including linear model ) have   less than 11 million parameters . The relatively   low amount of parameters is due to the fact that we   freeze the underlying language model . The primary   hyperparameter tuned is the number of projections   p. We take the argmax value on the validation set   between 10 and 100 projections . We repeat this for   each value of ϵ.   Dataset preprocessing : For all datasets , we limit   ourselves to documents with at least 2 sentences .   IMDB : This dataset has pre - defined train / test   splits . We use the entire training set and form the   test set by randomly sampling 4,000 from the test   set provided . We do this for efficiency in comput-   ing the Metric - DP baseline , which is the slowest   of all algorithms performed . Since the Metric - DP   baseline randomizes first , we can not precompute   the sentence embeddings G(s ) – we need to com-   pute the sentence embeddings every single time we   randomize . Since we randomize for each sentence   of each document at each ϵand each kover 5 trials   – this takes a considerable amount of time .   Good Reads : This dataset as provided is quite   large . We randomly sample 15000 documents from   each of 4 classes , and split them into 12 K training   examples , 2 K validation examples , and 1 K test   examples per class .   20 News Groups : We preprocess this dataset to   remove all header information , which may more   directly tell information about document class , and   only provide the model with the sentences from the   main body . We use the entire dataset , and form the   Train / Val / Test splits by random sampling.3380