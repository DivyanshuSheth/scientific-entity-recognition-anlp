  Nasim Nouri   Raouf Medical Group   Tehran , Iran   nasimnouri@raoufmed.com   Abstract   Recognizing offensive text is an important re-   quirement for every content management sys-   tem , especially for social networks . While   the majority of the prior work formulate this   problem as text classification , i.e. , if a text ex-   cerpt is offensive or not , in this work we pro-   pose a novel model for offensive span detection   ( OSD ) , whose goal is to identify the spans re-   sponsible for the offensive tone of the text . One   of the challenges to train a model for this novel   setting is the lack of enough training data . To   address this limitation , in this work we propose   a novel method in which the large - scale pre-   trained language model GPT-2 is employed to   generate synthetic training data for OSD . In par-   ticular , we propose to train the GPT-2 model in   a dual - training setting using the REINFORCE   algorithm to generate in - domain , natural and di-   verse training samples . Extensive experiments   on the benchmark dataset for OSD reveal the   effectiveness of the proposed method .   1 Introduction   It ’s no secret that social networks are growing in   popularity . However , growth in popularity also   brings some challenges , including the toxicity asso-   ciated with the content posted by users . It may take   different forms in social media , including insults ,   mockery , threats , discrimination , or swearing . The   presence of offensive text in social networks can   have a detrimental effect on their users , making   it desirable to identify and remove them from the   text .   Since this is an important requirement , the task   of offensive language detection has been exten-   sively studied in NLP community ( Schmidt and   Wiegand , 2017 ; Wulczyn et al . , 2017 ; Feng et al . ,   2018 ; Borkan et al . , 2019 ; Pavlopoulos et al . , 2019 ;   Sivanaiah et al . , 2020 ; Yasaswini et al . , 2021 ) Most   existing works , however , only classify a text snip-   pet as offensive or not , failing to provide further   information on which specific words and phrases inthe text contribute the most to its offensive tone . If   the text snippet is lengthy , the moderators will need   this information to decide how to proceed with the   offenses flagged . As such , in this work , we fill   this gap by proposing a novel model for the task   of offensive span detection ( OSD ) . As an example ,   in the given text “ This live streamer clearly has   no brain ; he is such a tool ! " , the phrase “ has no   brain " and the slang word “ tool " are two offensive   spans responsible for the toxicity of the text . One   of the barriers to this task is the lack of labeled   data . Inspired by the recent advances in the appli-   cation of pre - trained language models to augment   training data for low - resources tasks ( Zhang et al . ,   2020 ; Yang et al . , 2020 ; Peng et al . , 2020 ; Kumar   et al . , 2020 ; Anaby - Tavor et al . , 2020 ) , we propose   to employ the GPT-2 model to overcome the data   scarcity of OSD . To address this limitation , we pro-   pose a novel model in which the OSD training data   are augmented with the synthetic samples gener-   ated by a transformer - based language model . In   particular , the original labeled samples of OSD ,   with special markers before and after each offen-   sive span , are employed to fine - tune the parameters   of the GPT-2 model to generate sentences contain-   ing offensive spans . Moreover , in order to increase   the quality of the generated samples , we propose to   explicitly encourage the GPT-2 model to generate   diverse sentences while keeping them similar to   the original training samples . Also , the model is   encouraged to generate sentences that will result   in improvement of the performance of the OSD   task . To fulfill these objectives , in a dual train-   ing setting , the REINFORCE algorithm ( Williams ,   1992 ) is exploited to train the GPT-2 model . We   evaluate the proposed model on a recently released   dataset for offensive span detection . Our extensive   experiments show the effectiveness of the proposed   model by outperforming the strong baselines.25692 Model   Formal Task Description : The input to the model   is the document D= [ w , w , . . . , w]consisting   ofnwords . The label provided for the document   is also the sequence Y= [ y , y , . . . , y]in which   yis the label for the word win BIO format . This   problem is modeled as a sequence labeling task in   which the model predicts the label of every word   win the document D. In this work , we propose   a method to augment the original training samples   O , with synthetic labeled text Ggenerated by a   fine - tuned GPT-2 model . The rest of this section   describes the base model and the data augmentation   process .   2.1 Base Model   In our approach , we employ the pre - trained   BERT transformer as the base sequence   labeling model which is trained on D=   O / uniontextG. Specifically , the document D∈ D   is fed into the BERT model in the form of   [ CLS ] ww . . . w[SEP ] to obtain the word rep-   resentations X= [ x , x , . . . , x ] . Note that for   the words consisting of multiple word pieces we   take the average of their corresponding word - piece   representations . Next , the representations xare   sent to a feed - forward network to predict the label   distribution P(·|D , θ ) , where θis the parameters   of the BERT model . To train the model , we employ   the negative log - likelihood :   L=−/summationdisplay / summationdisplayP(y|D , θ ) ( 1 )   where yis the gold label for j - th word of the   document D.   2.2 Data Augmentation   One of the limitations for OSD is the lack of   enough labeled data . To address this limitation ,   inspired by the success of the generative language   models to augment data for other tasks , we propose   to employ GPT-2 to generate labeled synthetic data .   We first discuss the generation process , then we   provide details on how the generative model is en-   couraged to generate high - quality data .   Generation : Following prior works ( Zhang et al . ,   2020 ) , to generate synthetic data we employ GPT-   2 ( Radford et al . , 2019 ) model . GPT-2 is a   transformer - based language model pre - trained on40 GB of textual data . In order to fine - tune GPT-   2 for generating labeled data for OSD , we pro-   pose to employ the original labeled data G. Specif-   ically , the document D∈ G is first augmented   with special tokens at the beginning and the end of   the document and also around the offensive spans :   D= [ BOS ] w , w , . . .[OFFENSIV E]w ,   w , . . . , w[OFFENSIV E]w , . . . ,   w[EOS ] , where tis the length of the offensive   span in D. Note that there might be multiple offen-   sive span in a document . Next , the GPT-2 model is   trained in an auto - regressive manner on the labeled   augmented documents D. Specifically , the follow-   ing loss is employed for the fine - tuning process :   L=−/summationdisplay / summationdisplayP(w|D , α ) ( 2 )   where wis the j - th word in the label augmented   document D , Dis the left context of the word   win the document D , andαis the parameters of   the GPT-2 model .   Finally , the fine - tuned GPT-2 model is employed   to generate |O|synthetic data . Specifically , the   model is prompted with [ BOS ] token and the gen-   eration is stopped by generating the [ EOS ] to-   ken . In order to ensure that the generated data   are labeled , we keep only the generated samples   with at least one pair of [ OFFENSIV E]and   [ OFFENSIV E]tokens . The generated sam-   ples , i.e. , G , are combined with the original sam-   plesO , to obtain the final Ddataset to train the   base model .   Improving Quality of Generated Samples :   While the fine - tuning process of GPT-2 is supposed   to be effective to generate high - quality data , it has   been shown that the generated data might be noisy   or have repeated sentences ( Pouran Ben Veyseh   et al . , 2021 ) , providing harmful or less supervision   signals to the base model training . As such , we   propose to explicitly encourage GPT-2 model to   generate documents that results in better perfor-   mance on OSD task and satisfy the diversity re-   quirements of the generated data . In particular , we   propose to employ dual training with REINFORCE   to ensure the following requirements are observed :   ( 1)Usefulness : The generated documents should   be helpful to improve the performance on the fi-   nal task . As such , the F1 score of the base model ,   trained using D , on the original data Ois employed   as a measure of usefulness of the generated data :   R(G ) = F1(O ) ; ( 2)Diversity : If the generated2570samples are identical or similar to the original data ,   they will not provide enough new training signals   to the base model . As such , it is necessary to ensure   that the generated data can increase the diversity   of the data . To this end , using the representation   of the [ CLS ] token of each input document Dob-   tained from the base model , we cluster the docu-   ments in the combined dataset D. The number of   detected clusters are used as the diversity reward :   R(G ) = |C|   The overall reward for the generated documents   Gis computed as R = βR(G)+γR(G ) , where β   andγare trade - off parameters . The REINFORCE   algorithm is employed to update the parameters of   the GPT-2 model . Concretely , the parameters of the   generative model are updated by the estimated gra-   dient : ∇L=−(R(G))∇logP(G|α , O ) , where   P(G|α , O)is the probability of the generated data   Gcomputed as the product of the probabilities   P(D|α , O ) = /summationtextP(w|D , α ) .   Training Procedure : In order to simultaneously   update the parameters of the base model and also   the GPT-2 model , we propose a dual training proce-   dure . Specifically , at the first epoch , the parameters   of the GPT-2 model are updated using the loss L.   Next , GPT-2 model is employed to generate the la-   beled synthetic data to obtain the combined dataset   D. After one epoch of training the base model   using the loss L , the parameters of the GPT-2   model are updated using the REINFORCE algo-   rithm . The updated GPT-2 model is employed to   generate a new set of synthetic data to be replaced   with the previously generated data in D. The new   combined data will be next employed to update   the base model . This process is repeated until the   convergence of training .   3 Experiments   In order to evaluate the effectiveness of the pro-   posed model , called GAOSD ( Generation - based   Augmentation for Offensive Span Detection ) , in   our experiments , we use the dataset of SemEval   2021 Task 5 ( John Pavlopoulos and Laugier , 2021 ) .   This dataset contains annotations for 10,000 posts   ( comments ) obtained from the archive of Civil   Comment platform ( a platform for community to   share comments about various civility issues ) . We   use the official splits with 7939/690/2000 docu-   ments in train / development / test sets . For each doc-   ument , the word indices of offensive spans are pro-   vided . In our experiments , we create the BIO labels   using the provided word indices of the offensive   spans .   In our experiments , we use the BERTto en-   code data ; 2 layers for feed - forward neural net-   works with 250 hidden dimensions . The trade - off   parameters βandγare set to 0.1 and 0.05 , respec-   tively . The learning rate is set to 0.3 for the Adam   optimizer and the batch size of 64 is employed   during training . To evaluate the performance , we   use the official evaluation metrics for the SemEval   2021 Task 5 ( John Pavlopoulos and Laugier , 2021 ) .   We compare the performance of GAOSD with   the following baselines : ( 1 ) BiLSTM+CRF : The   GloVe embedded document is encoded by BiL-   STM and the labels are predicted by a CRF layer ;   ( 2)BERT+CRF : BERTparameters are fine-   tuned on OSD task and the task - specific head , i.e. ,   CRF , is employed for label prediction ; ( 3 ) HITSZ-   HLT ( Zhu et al . , 2021 ): This baseline is the exist-   ing SOTA model on SemEval 2021 Task 5 dataset ;   ( 4)SANER ( Nie et al . , 2020 ): This baseline is   the SOTA model for sequence labeling on user-   generated text ; ( 5 ) DUAL - MRC ( Mao et al . , 2021 ):   This is the SOTA model for opinion and aspect term   extraction . Note that since there are not target an-   notations in SemEval dataset , we skip the aspect   term extraction task to train this baseline . To evalu-   ate the performance we use the official metric , i.e.   char - level F1 - score , as the evaluation metric . Fol-   lowing prior work ( Zhu et al . , 2021 ) , we also report   the average of char - level precision and recall ( Note   that due to averaging , F1̸= 2(P∗R)/(P+R ) ) .   Results : Table 1 shows the performance of the   models on the test set . There are several obser-   vations from this table . First , the BiLSTM - CRF   model significantly underperforms the other base-   lines that employ BERT embedding . It clearly   shows that the background knowledge encoded   in the BERT model is necessary for the task of   offensive span detection . Second , both DUAL-2571   MRC and SANER baseline outperform the BERT-   CRF model . This higher performance could be   attributed to their capability to enhance the repre-   sentation of the words obtained from the BERT   model . Third , among all baselines , our proposed   model achieves the highest performance . Our hy-   pothesis for the achieved improvement is that in   the proposed method we employ more diverse sets   of patterns for expressing toxic . The increased   diversity is realized by generating more diverse   sentences . Also , this improvement proves that the   generated sentences are in - domain and task spe-   cific , as such resulting in an improvement . The   better performance of our model is impressive , es-   pecially considering that we use relatively simple   base model compared to other baselines ( in partic-   ular HITSZ - HLT which is an ensemble model ) .   Analysis : To study the contribution of the pro-   posed techniques , we conduct an ablation study on   the development set of the SemEval 2021 Task 5   dataset . Specifically , we ablate the quality improve-   ment component which ensures the usefulness and   diversity of the generated samples . In particular ,   we study the performance of the model when the   Usefulness Reward ( UR ) , the Diversity Reward   ( DR ) , or both of them ( UDR ) are ablated . Also ,   we study the performance of the model when no   dual training is employed ( DT ) . Specifically , we   first pre - train the base model on the available orig-   inal data . Next , we fix the parameters of the base   model and we use it to compute the usefulnessreward . The results are shown in Table 2 . This   table shows that all components are necessary , as   removing each will hurt the performance . Specifi-   cally , the dual training has the largest effect on the   final performance , indicating the importance of the   proposed method . Also , among the two proposed   rewards to improve the quality of the generated   data , we observe that usefulness reward is more   critical , indicating the importance of task - specific   generation for data augmentation .   Finally , in order to provide more insight into   the quality of the generated data , we provide some   randomly selected text generated by the fine - tuned   GPT-2 model . The results are shown in table 3 .   This table shows that the generated samples are   natural and also they contain the offensive spans .   The generative model is able to correctly locate   the offensive spans in the generated text , thereby   provided high - quality training samples for the base   model . It is worth noting that the offensive spans   generated by the fine - tuned GPT-2 model can be   either short spans , as in samples 1 and 3 in table 3 ,   or longer phrases , as in sample 2 .   4 Related Work   Prior works related to this task can be categorized   into two groups : ( i ) Toxicity Detection : These   works aim to classify a piece of text as toxic or non-   toxic ( Wulczyn et al . , 2017 ; Borkan et al . , 2019 ;   Schmidt and Wiegand , 2017 ; Pavlopoulos et al . ,   2017a , b , 2019 ; Zampieri et al . , 2019 ) . The main   limitation of these works is that they can not recog-   nize the spans in the text that are responsible for   the toxicity of the text . ( ii ) Opinion Word Extrac-   tion : In this group of prior works , models perform   a sequence labeling task to identify the spans in   the text that convey the sentiment ( Liu et al . , 2015 ;   Xu et al . , 2018 ; Yin et al . , 2016 ; Wang et al . , 2016 ,   2017 ; Li and Lam , 2017 ; Mao et al . , 2021 ) . The   major limitation of all these models is that they   require the existence of the target opinion ( i.e. , the   word or phrase that the text has a sentiment polarity   toward it ) .   5 Conclusion   In this work , we propose a novel method for aug-   menting data for offensive span detection tasks .   Specifically , we employ the pre - trained language   model GPT-2 to be fine - tuned on the available train-   ing samples for OSD . The fine - tuned model is able   to generate in - domain texts with special tokens in-2572dicating the offensive spans in them . Moreover , to   improve the quality of the generated documents ,   we propose a novel dual training setting in which   the feedback from the OSD model is employed   to guide the GPT-2 model to generate more im-   pact synthetic data . Together with a reward for   encouraging the diversity of the generated data , the   proposed method is effective to augment the train-   ing data for OSD , resulting in the state - of - the - art   performance on the recent benchmark datasets .   Ethical Consideration   In this work , we present a method for automatically   generating offensive spans using the pre - trained   generative language model GPT-2 . While the sole   purpose of the proposed method is to enhance the   performance of the offensive content detection sys-   tems in social networks , such a generative model   can also be misused by someone to automatically   make offensive posting continuously without much   effort . Prior to our discussion on our measures to   mitigate the potential harms of this research , we   first justify the risk of this harm . First , as shown   in the experiments , employing generation - based   models can improve the offensive span detection   performance by exposing the model to more di-   verse patterns of offensive content . Second and   more importantly , automatically generating train-   ing data for this task reduces the need to expose   annotators to a large amount of offensive content .   More specifically , since the GPT-2 generated data   is effective for training an OSD model , less offen-   sive content is needed to be annotated by human .   Thereby , the risk of harmful effects on the annota-   tors is decreased . However , as mentioned before ,   there is still room for misuse of the findings of this   research to automatically generate offensive con-   tent . As such , to mitigate the potential harms of   this method , we take extra measures into account .   In particular , first , we do n’t release the fine - tuned   GPT-2 model on the offensive data , therefore , no   one can directly use the artifacts of this research   for harmful purposes . Second , since this research   demonstrates the potential of the GPT-2 for generat-   ing natural - looking offensive content , in return , we   also study the effectiveness of a defensive method   in which a classifier is employed to identify con-   tents generated by GPT-2 from contents posted by a   human . More specifically , we train a BERT model   on a dataset consisting of 7,939 human - generated   and the same number , i.e. , 7,939 , automaticallygenerated offensive posts . The input content , i.e.   [ CLS ] ww . . . w[SEP ] where wis the i−th   word of the post , is encoded using the BERT   model . The representation of the [ CLS ] vector ob-   tained from the final layer of the BERTis sent   to a binary classifierto identify human - generated   and automatically generated texts . We evaluate the   performance of the trained binary classifier on a   test set of 4,000 offensive posts , with a ratio of   50 % human - generated content . The accuracy of   the classifier on the test set is 92.7 % ( note that a   random baseline would have an accuracy of 50 % ) .   Given the simplicity and the high performance of   the classifier to recognize the automatically gen-   erated posts , we expect that one can directly use   this defensive model to automatically and quickly   identify the model - generated offensive contents in   social networks , thereby mitigating the potential   harms of the findings of this research . Also , in   future work , with a more comprehensive classifier ,   better defensive performance is expected . One po-   tential improvement is to incorporate the context of   the postings . In particular , while this work shows   that GPT - generated content is helpful to improve   OSD performance , it does not show the degree to   which the generated offensive content is related to   the context of the posting . Finally , although this re-   search is conducted on a publicly available dataset   of offensive content , in order to prevent disclos-   ing the identity of people mentioned in the dataset ,   both in the training of the GAOSD and GPT-2 mod-   els , we hire 5 undergrad students to double - check   and anonymize the SemEval 2021 Task 5 dataset .   We expect by anonymizing the data , fewer human   subjects can be targeted by automatically generated   offensive text .   References257325742575