  Juhyuk Lee , Min - Joong Lee , June Yong Yang , Eunho Yang   Samsung Research , Samsung Electronics , South Korea ,   Samsung Advanced Institute of Technology , Samsung Electronics , South Korea ,   Korea Advanced Institute of Science and Technology ( KAIST ) , Daejeon , South Korea   { juhyuk.lee , minjoong.lee}@samsung.com   { laoconeth , eunhoy}@kaist.ac.kr   Abstract   The ability to extract entities and their relations   from unstructured text is essential for the auto-   mated maintenance of large - scale knowledge   graphs . To keep a knowledge graph up - to - date ,   an extractor needs not only the ability to recall   the triples it encountered during training , but   also the ability to extract the new triples from   the context that it has never seen before . In this   paper , we show that although existing extrac-   tion models are able to easily memorize and   recall already seen triples , they can not general-   ize effectively for unseen triples . This alarming   observation was previously unknown due to the   composition of the test sets of the go - to bench-   mark datasets , which turns out to contain only   2 % unseen data , rendering them incapable to   measure the generalization performance . To   separately measure the generalization perfor-   mance from the memorization performance , we   emphasize unseen data by rearranging datasets ,   sifting out training instances , or augmenting   test sets . In addition to that , we present a   simple yet effective augmentation technique   to promote generalization of existing extraction   models , and experimentally confirm that the   proposed method can significantly increase the   generalization performance of existing models .   1 Introduction   Relational Triple Extraction ( RTE ) , a more gener-   alized version of Relation Extraction , is the task of   extracting all relational triples in the form of ( sub-   ject , relation , object ) from a given sentence . The   ability to extract such triples is much required in the   construction and maintenance of knowledge graphs   such as Dbpedia ( Auer et al . , 2007 ) , Freebase ( Bol-   lacker et al . , 2008 ) , and Wikidata ( Vrande ˇci´c and   Krötzsch , 2014 ) from documents containing a large   number of new and emerging information . With language model pretraining ( Devlin et al . ,   2019 ; Radford et al . , 2019 ) , RTE methods achieved   a new state - of - the - art ( Wei et al . , 2020 ; Wang et al . ,   2020 ; Zheng et al . , 2021 ) . However , whether the   performance of these methods attributes to their   capabilities of recalling already seen data or their   ability to generalize and extract relations from un-   seen data is yet to be scrutinized .   To separately evaluate memorization and gen-   eralization , we categorize the triples in the test   set into three types : entirely seen ( completely   overlaps with triples in their respective training   sets ) , partially seen ( overlaps partially ) , and un-   seen ( completely new ) . We analyze common RTE   benchmark datasets NYT ( Riedel et al . , 2010 ) and   WebNLG ( Gardent et al . , 2017 ) using these cate-   gories , and find that 89.61 % and 91.10 % of triples   in NYT and WebNLG test sets are of the entirely   seen type . This suggests that benchmark results on   these datasets are heavily biased towards recalling   seen data . Thus , more reliable systematic evalu-   ation methods are in need to test generalization   performance .   In this paper , we propose three natural strategies   for evaluating generalization performance from a   limited number of given partially seen andunseen   triples . For the first two strategies , we directly in-   crease the proportion of partially seen andunseen   triples in test sets by 1 ) rearranging their respec-   tive datasets or 2 ) sifting out instances in their re-   spective training sets that overlap with the test set ,   rendering them unobserved . For the last strategy ,   we 3 ) augment test sets by replacing entities in   each test instance with similar ( and probably not   pre - observed ) words in order to increase diversity   as well as the proportion of partially seen andun-   seen triples . In addition to evaluating recent RTE   methods with the above evaluation strategies , we   propose a simple yet effective augmentation tech-   nique called Entity Noising to help RTE methods   to generalize beyond training data.3849   Our contributions are :   •We show for the first time that the current   benchmark datasets for relational triple ex-   traction exhibit significant entity pair overlap   between training and test data .   •We confirm that the current state - of - the - art   models trained on such datasets can not gener-   alize well to unseen triples .   •We propose three evaluation strategies to eval-   uate RTE methods systematically , and show   that the proposed simple augmentation tech-   nique called Entity Noising can assist RTE   methods in generalizing to unseen data .   2 Fine - grained Re - evaluation of the   Current State - of - the - arts   In this section , we mainly scrutinize the generaliza-   tion capabilities of current Relational Triple Extrac-   tion ( RTE ) methods and show for the first time that   they indeed struggle in extracting relational triples   from the context for unseen cases .   2.1 Datasets and Evaluation Metrics   We use two well - known benchmark datasets   NYT ( Riedel et al . , 2010 ) and WebNLG ( Gardent   et al . , 2017 ) for evaluation , following Wang et al .   ( 2020 ) and Zheng et al . ( 2021 ) . Also , predicted   triples are considered correct only if their whole   entity spans of both subject and object and theirrelation are exactly matched with ground truth . We   report the standard micro F1 for the overall perfor-   mance .   To assess the memorization and generalization   performances separately , we also compute type F1   with three triple types : entirely seen , partially seen ,   andunseen ( Section 2.2 ) . Type F1 is nothing but   F1 evaluated using instances which only consist of   a single triple type .   2.2 Triple Types   We describe three triple types - entirely seen , par-   tially seen , and unseen - in detail . For a set of   triples in the training set S={(s , r , o ) } , the   type of each triple ( s , r , o ) in the test set are de-   fined as follows . A triple ( s , r , o ) belongs to the   entirely seen type if ( s , r , o ) ∈S. For partially   seen type , triples ( s , r , o ) which satisfy conditions   [ ( s , r,·)∈Sor ( · , r , o)∈S]and(s , r , o ) ̸∈S   belong to it . Other triples belong to unseen type .   2.3 Detailed Evaluation with Triple Types   Using type F1 , we show that the current state - of-   the - arts CasRel ( Wei et al . , 2020 ) , TPLinker ( Wang   et al . , 2020 ) , and PRGC ( Zheng et al . , 2021 ) are   only able to memorize and recall already seen   triples , and are unable to generalize effectively for   unseen triples ( See Table 2 ) . This observation was   previously unknown due to the overlaps between   training and test data of benchmark datasets NYT   and WebNLG .   Indeed , as shown in Table 1 , 89.61 % and 91.10 %   of triples in NYT and WebNLG test sets com-   pletely overlap with triples in their respective train-   ing sets ( such triples are defined as entirely seen   type ) , while partially seen andunseen samples that   require generalization to predict are but a small   portion .   3Evaluating Generalization Performance   As shown in Table 1 , the proportion of partially   seen andunseen triples in the original benchmark   test sets are so small that they are not diverse3850   enough , rendering the evaluations of generaliza-   tion capabilities unreliable . Equipped with this   observation , we propose three strategies to increase   the proportion of partially seen andunseen triples   and add diversity to them for reliable evaluation of   Relational Triple Extraction ( RTE ) methods .   3.1 Rearranged Dataset   The basic approach to increasing the proportion   ofpartially seen andunseen triples is to rearrange   the given dataset splits . However , it is not possible   to emphasize unseen data just by randomly rear-   ranging the dataset , since it inadvertently incurs   overlaps between training and test data .   To emphasize the unseen data , we repeatedly   select a triple and distribute every instance which   contains that triple to the test set , rendering them   unobserved in the training set . In order to minimize   redundancy in the test set , we select a triple one by   one which occurs less . The detailed statistics are   shown in Table 1 and Appendix B.   3.2 Overlap Sifted Dataset   We propose another simple strategy to emphasize   unseen test samples . To render a triple in the test   set unobserved , we remove the instances contain-   ing that triple from the training set . Specifically ,   we randomly choose k%of the unique triples from   the test set , then remove all the instances contain-   ing the selected triples from the training set toconstruct an overlap sifted dataset . For demonstra-   tion , we construct three such datasets by choosing   k= 5,10,15 % , respectively . The detailed statis-   tics are presented in Table 1 and Appendix B.   3.3 Augmented Test Set   To add more diversity to partially seen andunseen   samples as well as increasing their proportion , we   create an augmented test set . The key idea is to   substitute every entity defined in every triple with   probable alternative words by utilizing the knowl-   edge of Masked Language Models ( Radford et al . ,   2019 ; Devlin et al . , 2019 ) and GloVe word embed-   dings ( Pennington et al . , 2014 ) , similar to the data   augmentation technique used in Jiao et al . ( 2020 ) .   With the augmented test set , it is able to assess   whether the ability of an RTE method is influenced   by the authenticity of the given text . The details   are in Appendix C and statistics are present in Ta-   ble 1 and Appendix B.   4 Entity noising   We further propose Entity Noising , a simple aug-   mentation technique to enhance the generalization   performance of existing Relational Triple Extrac-   tion methods . The key idea of Entity Noising is   to replace the entities in the given training input   sentence with completely random noisy words . To   apply Entity Noising , we sample a random noisy   word wfor each entity w , i.e. , w∼P(w|w ) .   The sampling strategy is defined as follows . First,3851   we sample token length l∈ { l−1 , l , l+ 1 }   ofwwith probability P(l = l ) = pand   P(l = l−1 ) = P(l = l+ 1 ) = /parenleftbig   1−p / parenrightbig   /2 ,   where lis a token length of w. This sampling   process introduces a small ( ±1 ) perturbation to the   token length lto prevent the model from mem-   orizing the number of tokens . After sampling   l , we sample wfrom the uniform distribution   w∼Uniform ( V ) , where Vis a subset of the   vocabulary Vwhich consists of all words of token   length l.   With sampling strategy w∼P(w|w ) , En-   tity Noising is applied to a given training sentence   x = ( w , w , · · · , w)to produce a noised   sentence x = ( w , w , · · · , w)according to   the following rule :   w=/braceleftigg   w∼P(w|w),ifwis an entity   w , otherwise   Finally , we determine which input xis fed to theextractor model with probability P(x = x ) =   pandP(x = x ) = 1−p . An overview   illustration of Entity Noising is shown in Figure 1 .   Entity Noising is different from a commonly   used data augmentation method such as Wei and   Zou ( 2019 ) which replaces entities with words sim-   ilar to them . Entity Noising replaces entities with   completely random noisy words . This feature al-   lows the model to utilize entity - agnostic informa-   tion , so that the model can learn to extract triples   from sentences by focusing on the context informa-   tion rather than the entities themselves . Therefore ,   with Entity Noising , the model is kept away from   memorizing the entity pair along with its relation .   5 Experiments   We conduct a series of experiments with recent Re-   lational Triple Extraction ( RTE ) methods on newly   constructed datasets ( Section 3).3852Rearranged Dataset ( Section 3.1 ) Table 3   shows the lack of generalization capabilities of re-   cent RTE methods in rearranged datasets as well   as original datasets . On rearranged datasets , Entity   Noising consistently improves the ability of gener-   alization on unseen triples , and for partially seen   triples , it at least does not hurt the generalization   capabilities . For original datasets , the evaluation   can be biased on some specific partially seen and   unseen samples since their proportion in test sets is   small , rendering inconsistent results .   Overlap Sifted Dataset ( Section 3.2 ) With over-   lap sifted datasets and original datasets , we eval-   uate recent RTE methods with and without Entity   Noising to get more insight into what extent they   generalize on unseen data . Table 4 shows that re-   cent RTE methods struggle in extracting triples   from unseen data , while Entity Noising promotes   their generalization capabilities in most cases .   Augmented Test Set ( Section 3.3 ) To assess   whether the ability of an RTE method is influenced   by the authenticity of the given text , we evaluate   recent RTE methods with and without Entity Nois-   ingonaugmented test set . We find that current   RTE methods are substantially influenced by the   authenticity of the given text , while Entity Nois-   ingrelieves that influence by a huge margin ( See   Table 5 ) .   6 Related Work   Open Information Extraction ( Open IE ) Open   IE is the task of extracting relations from the given   text without predefined relation type ( Stanovsky   et al . , 2018 ; Zhan and Zhao , 2020 ; Cui et al . , 2018 ;   Kolluru et al . , 2020 ) . Although Open IE is a more   general task than Relational Triple Extraction , it is   necessary to extract information using fixed rela-   tion type to get high quality relational triples from   specific domains such as science and business .   Data Leakage in NLP The overlapping problem   between training and test data makes the evaluation   biased towards assessing memorization capabilities   of models . Several works point out the overlapping   problem and quantify data leakage in basic NLP   tasks ( Elangovan et al . , 2021 ) and Open - Domain   Question Answering ( Lewis et al . , 2021 ) , but Rela-   tional Triple Extraction was not considered yet .   7 Conclusion   In this paper , we disclosed for the first time that   recent Relational Triple Extraction ( RTE ) methods   struggle to extract triples from unseen data , which   was previously unknown due to the test - train over-   lap problem in popular benchmark datasets . To   properly assess the generalization capabilities of   RTE methods , we developed three strategies to con-   struct rearranged dataset , overlap sifted dataset ,   andaugmented test set from original datasets . Fur-   thermore , we proposed a simple yet effective nois-   ing method to promote generalization and exper-   imentally confirm that it effectively improves the   generalization capabilities of existing RTE meth-   ods .   Acknowledgements   This work was supported by Institute of Infor-   mation & communications Technology Planning   & Evaluation ( IITP ) grant funded by the Korea   government(MSIT ) ( No.2019 - 0 - 00075 Artificial   Intelligence Graduate School Program(KAIST ) ,   No.2019 - 0 - 01371 Development of Brain - inspired   AI with Human - like Intelligence ) and National   Research Foundation of Korea ( NRF ) grant   ( 2018R1A5A1059921).3853References38543855A Training Details   In general , we train CasRel , TPLinker , and PRGC   for 300 , 500 epochs on NYT , WebNLG datasets . It   takes 5 GPU days for training models on NYT and   1 GPU day for training models on WebNLG . We se-   lect the best model by only using the F1 score of the   given validation set except overlap sifted dataset .   Foroverlap sifted dataset , the training instances are   sifted out according to the test instances , rendering   the triple type statistics of valid and test sets are   different . Therefore , we select the best model by   using the F1 score of overlap sifted test sets . For   Entity Noising , we set pto 0.1 and 0.05 for NYT   and WebNLG datasets and set pto 0.4 . Every   model is based on pre - trained BERT model BERT-   base - cased from Huggingface Transformers ( Wolf   et al . , 2020 ) , which contains 110 M parameters .   B Dataset Statistics   The statistics of dataset split are shown in Table 6 .   To compute type F1 defined in Section 2.1 , strat-   ification is necessary by extracting test instances   which only consist of single triple type among en-   tirely seen , partially seen andunseen . The stratifi-   cation statistics are shown in Table 7 .   C Augmented test sets   Discussions on augmented test set It is worthy   to note that the samples in the augmented test set   may not be “ true ” statements in the real world but   rather invented , as by construction their entities are   replaced with other similar words ( See examples   in Figure 2 ) . However , the true meaning of the   entity words is fundamentally irrelevant to the re-   lation between them given the context . Also , it is   unknown whether the relation in the sentence is a   fact . Thus , the ability of an RTE model to extract   relational triples should not be influenced by the   authenticity of the given text . Note that an ideal   RTE model should be able to extract the relational   triple ( The [ United States ] President [ Christopher ] )   if such fictitious content happens to exist in the   given text .   Although the ideal RTE model should not be   influenced by the authenticity of the given text ,   there exists potential risk . It is that the deployed   RTE model might extract the invalid triple from   wrong text . Therefore , the validation process which   checks the triple is needed before adding it to the   knowledge graph . Construction details of augmented test set We   now describe the construction details of the aug-   mented test set . First , we preemptively run the   language tokenizer to flag the wordpieces in the   entity words . we substitute all entity words in the   triples with masks ( one mask per word , not per   wordpiece ) . For single - word - single - wordpiece en-   tities , we use the language model to fill in their   masks independently . For single - word - multi - piece   entities , we do not use the language model but   search and substitute for the k - nearest words of the   original entity word in the GloVe embedding space .   For multi - word entities , each word constituting an   entity is sequentially substituted using the language   model .   Now we describe the detailed construction of   T . To measure the generalization perfor-   mance properly , it is required that the augmented   test set T consists of partially seen triples   as well as unseen triples since the ideal RTE model   is required to effectively extract both partially   seen andunseen triples . Therefore , we first con-   struct four augmented components of the test set   T , T , T , Tand take a union of them to   create the final augmented test set T =   T∪T∪T∪T. Among the four compo-   nents , Tconsists of triples with seen subject and   object ; Tconsists of triples with seen subject and   unseen object ; Tis symmetrical with T;T   consists of triples with unseen subject and object .   We now describe the construction details of four   components : T , T , TandT. First , for each   sample in the test set t ∈T , we get   a set of top- ksimilar entities Efor each entity   eint independently , so that there is no   correlation between each E. Then , we uniformly   sample efromEand replace ewitheto get   t ∈T .   Construction of TTmainly consists of   triples in which both subject and object entities   are already seen in the training set . Therefore , ev-   ery subject and object entity eis sampled from   E∩Euniformly , where Eis a set of en-   tities appeared in the training set . If we encounter   to sample from an empty set , we assign e = e.   Construction of T , TTmainly consists   of triples in which subject entities are seen and   object entities are unseen in the training set . There-   fore , subject and subject / object entities eare sam-   pled from E∩E , and object entities eare3856   sampled from E\E uniformly . Tis con-   structed symmetrically .   Construction of TTmainly consists of   triples in which both subject and object entities are   unseen in the training set . Therefore , every subject   and object entity eis sampled from E\E   uniformly.38573858