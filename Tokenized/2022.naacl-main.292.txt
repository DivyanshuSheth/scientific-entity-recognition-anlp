  Koel Dutta Chowdhury , Rricha Jalota ,   Cristina España - Bonet , and Josef van GenabithSaarland University , Saarland Informatics Campus , GermanyGerman Research Center for Artiﬁcial Intelligence ( DFKI )   koel.duttachowdhury@uni-saarland.de   rrja00001@stud.uni-saarland.de   { cristinae , Josef.Van_Genabith}@dfki.de   Abstract   Cross - lingual natural language processing re-   lies on translation , either by humans or ma-   chines , at different levels , from translating   training data to translating test sets . However ,   compared to original texts in the same lan-   guage , translations possess distinct qualities re-   ferred to as translationese . Previous research   has shown that these translation artifacts in-   ﬂuence the performance of a variety of cross-   lingual tasks . In this work , we propose a novel   approach to reducing translationese by extend-   ing an established bias - removal technique . We   use the Iterative Null - space Projection ( INLP )   algorithm , and show by measuring classiﬁca-   tion accuracy before and after debiasing , that   translationese is reduced at both sentence and   word level . We evaluate the utility of debias-   ing translationese on a natural language infer-   ence ( NLI ) task , and show that by reducing   this bias , NLI accuracy improves . To the best   of our knowledge , this is the ﬁrst study to de-   bias translationese as represented in latent em-   bedding space .   1 Introduction   “ Translationese ” refers to features in ( professional   human or machine ) translated text that distin-   guishes it from non - translated , original text in the   same language . Carriers of translationese include   lexical and word order choices that are inﬂuenced   by the source language ( Gellerstam , 1986 ) , as well   the use of more explicit and standardised construc-   tions ( Baker et al . , 1993 ) compared to original text .   Translationese has a signiﬁcant impact in machine   translation evaluation . Toral et al . ( 2018 ) found   that translating source sentences that are already   the result of translation are easier to translate than   original sentences . Similarly , Edunov et al . ( 2020 )   show that back - translation results in large BLEU   scores when translationese is on the source side and   original text is used as reference . To avoid such   artifacts , it is advised to use original source sen - tences for machine translation evaluation ( Zhang   and Toral , 2019 ; Graham et al . , 2020 ) . Riley et al .   ( 2020 ) train sentence - level classiﬁers to differen-   tiate translationese from original target text , and   then use this classiﬁer to tag the training data for   an NMT model to produce output that shows fewer   translationese effects . Translation - inherited arti-   facts have been shown to have signiﬁcant impact   on other tasks as well . For example , Singh et al .   ( 2019 ) show that substituting segments of origi-   nal training samples by their translations from an-   other language improves performance on natural   language inference ( NLI ) tasks . Clark et al . ( 2020 )   introduce a translation - free Question Answering   dataset to avoid having inﬂated gains from trans-   lation artifacts in transfer - learning tasks . Artetxe   et al . ( 2020 ) show that cross - lingual models suffer   from induced translation artifacts when evaluated   on translated test sets . These examples motivate   the need for reducing translation artifacts .   While a number of methods to remove or atten-   uate human - like biases ( e.g. , gender , race , etc . ) in   both static and contextualised word embeddings   have recently been proposed ( Bolukbasi et al . ,   2016 ; Gonen and Goldberg , 2019 ; Dev and Phillips ,   2019 ; Ravfogel et al . , 2020 ; Liang et al . , 2020 ;   Zhou et al . , 2021 ) , attenuating and eliminating a   more implicit signal like translationese in embed-   dings has yet to be studied . Translationese signals   are complex and multi - faceted and , unlike e.g. gen-   der and profanity , can in general not be captured   in terms of simple lists of contrastive word pairs   ( woman - man , she - he , etc . ) , but rather manifest as   a complex mix of morphological , lexical , syntac-   tic and semantic phenomena . Our study is a ﬁrst   attempt to directly debias translationese encoded   as latent representations , based on the recently pro-   posed Iterative Nullspace Projection ( INLP ) algo-   rithm ( Ravfogel et al . , 2020 ) .   The main contributions of our work are as fol-   lows . ( i)We propose to reduce the bias induced3983by translation by extending the INLP approach   to translationese debiasing at both the word and   sentence level , with ﬁndings demonstrating that   our debiasing approaches can effectively attenuate   translationese biases in both static word embedding   spaces as well as sentence representations based on   contextualised embeddings . ( ii)We use the INLP   method with a number of neural sentence - level   translationese classiﬁcation architectures ( fastText ,   mBERT , XLM ) , and propose two alternative meth-   ods for detecting explicit translationese bias in   word embeddings , and ﬁnd that after debiasing , the   models ’ performance on classifying translationese   degrades to that of a random classiﬁer . ( iii)Fi-   nally , by integrating the proposed debiasing method   within the NLI task , we show the effect of transla-   tion artifacts and their removal on the task .   2 Debiasing Strategies   Much previous research ( Bolukbasi et al . , 2016 ;   Zhao et al . , 2018 ; Dev and Phillips , 2019 ; Ravfogel   et al . , 2020 ) focuses on eliminating bias in word   embeddings . However , existing models use lists   of contrastive word pairs ( e.g. , woman - man , she-   he ) to detect , capture and mitigate speciﬁc biases   ( e.g. , gender , profanity , etc . ) . While translationese   can not , in general , be captured in simple lists of   contrastive word pairs , we do have labeled data at   sentence level : translated ( translationese ) and orig-   inal sentences . We use this data and the INLP algo-   rithm to directly mitigate translationese at sentence   level ( Section 3 ) . Additionally , we explore INLP   at word level to debias translationese in Section 4 .   Only a few earlier studies ( Dutta Chowdhury et al . ,   2020 , 2021 ) deal with translationese at the level of   word embedding spaces leveraging distances be-   tween graph - based representations of original and   translationese data . For debiasing word embedding   spaces , we adapt an idea from Gonen et al . ( 2020 )   to extract lists of pairs of identical words and ex-   amine how their use differs in translationese and   original data ( rather than contrasting word pairs ) .   If a word is used very differently in translated and   original data , this is reﬂected in differences in orig-   inal and translated word embedding spaces , and   is evidence of translationese in the embeddings .   Alternatively , we propose a simpler approach that   builds on a joint embedding space where words are   tagged according to their origin ( translationese or   original ) and without any need for a word list .   TheIterative Nullspace Projection algorithm(Ravfogel et al . , 2020 ) focuses on removing linearly   decipherable features from vector representations   originally for gender bias mitigation . Given a set   of labeled data with data points X = x, ... ,x   and task labels Y = y, ... ,y , we use a standard   classiﬁcation setup with a neural network and a   simple classiﬁer τon top . An encoder hencodes   xinto a representation vector h(x)andτpre-   dictsybased onh(x ) , i.e. ,y = τ(h(x ) ) . Let   Tbe the trait to be mitigated , also known as the   protected attribute . The goal of the INLP method   is to neutralise the ability of the classiﬁer τto lin-   early predict Tfromh.τis parameterised by a   matrixWand trained to predict Tfromh . Using   W , one can collapse the data onto its nullspace   N(W)with a projection matrix P. This guar-   anteesWPh(T ) = 0 , i.e. , the information   used to classify Tis linearly removed . By repeat-   ing this process itimes until no classiﬁer achieves   above - majority accuracy , INLP can neutralise all   features that Wuses for predicting Tfrom ˜h :   Details of the implementation are the same as in   Ravfogel et al . ( 2020 ) .   3 Translationese in Sentence   Embeddings   In our work , we are interested in adapting INLP   to study the impact of removing the translationese   attributesTfrom semantic representations , via a   binary classiﬁcation task . Speciﬁcally , the binary   classiﬁer learns to distinguish between original and   translationese sentences . Therefore , in our setup ,   labelsYcorrespond to original and translationese   and act as protected attributes .   Data . We use the Europarl corpus annotated   with translationese information from Amponsah-   Kaakyire et al . ( 2021 ) . We focus on three lan-   guages : English ( En ) , German ( De ) and Spanish   ( Es ) . The corpus provides originals in the three   languages ( L1 ) and translations into these three lan-   guages that come from original texts in the other   two ( L2 ) . We use the notation L1 – L2 to refer to the   different sets in Table 1 and Table 2 . For example ,   in En - De , L2 refers to English text translated from   German . For each corpus , there is an equal num-   ber of translated and original sentences : 42k for3984   De – En , De – Es , En – De , En – Es , Es – De and Es – En .   We use 70 % of the sentences for training , 15 % for   development and 15 % for testing .   Classiﬁer . We use a logistic classiﬁer on top   of sentence embeddings hobtained with 4 models   without any additional ﬁne - tuning to the transla-   tionese classiﬁcation task . ( i)fastText ( Joulin et al . ,   2016 ): we compute an average of all token vectors   in the sentence . ( ii)mBERT(Devlin et al . ,   2019 ): we use the [ CLS ] token in mBERT as   sentence representation . ( iii)mBERT(Devlin   et al . , 2019 ): we use mean pooling of mBERT ’s   contextualised word embeddings . ( iv)XLM   ( Conneau et al . , 2020 ): we use the [ CLS ] token   from XLM - RoBERTa .   Results . The ﬁrst four columns in Table 1 sum-   marise the translationese classiﬁcation accuracy   achieved by the four models . mBERTachieves   the best performance for all languages , while fast-   Text trails the pack . The ﬁnal column in Table 1   shows that INLP is close to perfection in remov-   ing translationse signals for the linear classiﬁers ,   reducing accuracy to a random 50 % .   4 Translationese in Word Embeddings   Unlike sentence - level debiasing , word - level debias-   ing needs a seed translationese direction to obtain   a debiased space . This is challenging for transla-   tionese as unlike , e.g. gender and profanity , trans-   lationese can not in general be captured in terms   of simple contrastive word pairs . In what follows ,   we introduce two approaches for debiasing transla-   tionese at the level of word embeddings .   Stepwise Aligned Space Projection . In order   to estimate the seed translationese direction , we   derive a list of words ( G ) used differently in trans-   lationeseTand original Odata using the usage   change concept from Gonen et al . ( 2020 ) . The   same word used in different data sets ( original andtranslated ) is likely to have different neighbours   in the two embedding spaces . We only use words   from the intersection of both vocabularies OandT.   We compute the score for context change across the   embeddingsOandTof the two data sets by consid-   ering the size of the intersection of two sets where   each word in a corpus is represented as its top- k   nearest neighbors ( NN ) in its embedding space :   where NN(w)is the set of k - NN of word win   embedding space i. The smaller the size of the   intersection , the more differently the word is used   in the two data sets ( and words with the smallest   intersection can be seen as indicators of transla-   tionese ) . GivenOandT , we collect a ranked list   of about 500 words with the smallest intersection   as our translationese word list G.Gallows us to   identify the seed translationese direction for INLP .   In our experiments we only consider words attested   at least 200 times in the data . Appendix A.3 shows   the top 50 elements for all the word lists . In our ex-   periments , we use the translated and original parts   of the data described in Section 3 to estimate the   word embeddingsOandTand usek=1000 nearest   neighbours in Equation 2 . Following Gonen et al .   ( 2020 ) , a large value of kresults in large neighbors   sets for each word in the two corpora , resulting in   a more stable translationese wordlist G.   Next , we create a joint word embedding space J   from the concatenation of the translated and origi-   nal data , TandO. Since this joint space Jincludes   both original and translationese signals , we then   align the previously unrelated OandTspaces to   this embedding space J , using VecMap ( Artetxe   et al . , 2018 ) , producing aligned spaces ˜Oand˜T ,   and resulting in an extended single embedding   space whereTandOare aligned toJ. Next ,   we compute the translationese direction vof the   same wordwin the two embeddings spaces , ˜Oand   ˜T , using ,   Finally , we compute the similarity of words in   Jalong the directions vand−v , to divide   them into two subspaces , translationese and non-   translationese , respectively . Using Equation 3 , we   initialise the INLP algorithm in two ways : ( i )   INLP.single : with a direction vector created from   the difference between two aligned spaces for the   highest ranked word in G , and ( ii)INLP.avg : by   averaging the differences of all words in G.3985   Direct Joint Space Projection . In this ap-   proach , we directly build the embeddings of a spe-   ciﬁc wordwfromOandTinto the same space   Jby annotating was eitherwandwon surface   in theOandTdata . In this way we can easily   track and distinguish the two embeddings of the   same wordwcoming from OandTdata in the   same embedding space Jresulting from the sim-   ple concatenation of two datasets . This eliminates   the need to compute the translationese direction   vectorvto group the subspaces and the complexity   of maintaining and aligning O , T , J,˜Oand˜T   spaces . Figure 1 in Appendix A.2.2 shows the t-   SNE projection ( Van der Maaten and Hinton , 2008 )   of the tagged tokens before and after debiasing .   Results . We compare the performance before   and after debiasing using our two word - level de-   biasing methods in Table 2 . As expected , debias-   ing reduces classiﬁcation accuracy for all language   pairs from∼100 % to∼50 % for both methods .   Translationese Word Lists . The content of our   extracted translationese word lists depends on the   language ( see Appendix A.3 ) . For Es , punctuation   is clearly used differently in originals and transla-   tions into Es . For De , pronominal adverbs play an   important role , especially when translations come   from Es . For En , there is no clear trend but , inter-   estingly , only one word in the top-50 list ( indeed )   overlaps with the words with a highest difference   in frequency of usage in the original and transla-   tionese corpus as analysed for Europarl in Koppel   and Ordan ( 2011 ) . The number of times and the   context where a word appears may reﬂect two dif-   ferent aspects of translationese .   5 Application to NLI   In order to investigate the impact of removing trans-   lationese artifacts from the translated data we anal-   yse its impact on the NLI task , where machine   translation is used . NLI predicts the relationshipbetween two sentences , premise and hypothesis ,   and classiﬁes it into one of the three categories   — entailment , contradiction , or neutral . Recently ,   Artetxe et al . ( 2020 ) showed that , in the existing   NLI datasets , there exists a signiﬁcant lexical over-   lap between the premise and the hypothesis , which   is utilised by neural NLI models to make predic-   tions with high accuracies . However , when the   premise and hypothesis are paraphrased indepen-   dently using translation and back - translation , lex-   ical overlap is reduced , negatively impacting the   performance of the models .   Below we test whether and if so , to which ex-   tent our INLP - based translationese debiasing ap-   proach can avoid the observed performance loss   in the back - translated NLI task . We generate   Back - Translated ( BT ) NLI dataset by indepen-   dently translating premise and hypothesis from   the Original SNLI data . Then , we train two NLI   models , one on Original and one on BT data . To   reduce the translationese artifacts resulting from   back - translation , we apply the sentence and word   embedding debiasing strategies as described in Sec-   tions 3 and 4 over the embeddings generated from   BT data , and use the resulting debiased - BT em-   beddings to train a third debiased NLI model in   Table 3 .   Finally , we consider two scenarios to evaluate   translationese debiasing - ( i)Symmetric [ Sym ] :   where Original is tested with original test set , and   BT and debiased NLI models are tested with BT   test data and ( ii)Asymmetric [ Asym ] : where all   these models are tested with original test data . We   use(i)to see whether debiasing the model trained   on translated train - test can bring its performance   closer to that of model trained on original train - test   data . In ( ii ) , we examine the asymmetry between   original test data and BT - NLI training data , and   whether our translationese debiasing of BT train-   ing data can offset this asymmetry and improve   NLI performance . Table 3 shows the classiﬁcation   accuracies with respect to ( i)and(ii ) .   Data . The large - scale SNLI dataset ( Stanford   Natural Language Inference ) ( Bowman et al . , 2015 )   contains 570k sentence pairs in the training set man-   ually classiﬁed as entailment , contradiction , or neu-   tral . We use a subset of 10 % of the training data for   our experiments . The development and test data are   used as in the original SNLI splits ( each containing   10k examples ) . We generate a back - translated vari-   ant of the training and test data using German ( De)3986   as the pivot language . For translation , we use the   pre - trained models of Facebook - FAIR ’s WMT-19   news translation task submission ( Ng et al . , 2019 ) .   Models . We train three different NLI models ,   each for original , back - translated and debiased ver-   sions of back - translated embeddings . For the word-   level setup , we use a single hidden BiLSTM layer   followed by a standard feedforward output layer on   top of frozen fastText word embeddings for the 3-   class NLI classiﬁcation . The computation of word   embeddings and debiasing follows the setup de-   scribed in Section 4 . For sentence - level debiasing ,   we use the BERTmethod explained in Section 3   with a linear SVC on top to predict the labels .   Results . Table 3 shows results consistent with   Artetxe et al . ( 2020 ) , in that models trained on Orig-   inal data outperform models trained on BT data in   bothSym andAsym scenarios . Table 3 also shows   that , after translationese debiasing , classiﬁcation   accuracy on SNLI - debiased improves modestly for   all models , with only a minor improvement at word-   level , and larger improvement at the sentence level .   Overall this may be due to the fact that transla-   tionese is a combination of lexical and syntactic   phenomena that is better captured at sentence - level .   Results in Table 3 suggest that debiasing translation   artifacts helps in reducing the asymmetry between   translated train and original test set . Therefore ,   rather than translating the entire test set to match   the training set in transfer - learning tasks , debiasing   the training set for translation artifacts is a promis-   ing direction for future work . Finally , for a com-   plex task such as translationese debiasing , linear   intervention alone may not be sufﬁcient . As a re-   sult , non - linear guarding approaches need to be   investigated further .   6 Conclusion   In this work , we remove translationese artifacts   by extending the debiasing INLP approach at both   word and sentence level . To the best of our knowl - edge , this is the ﬁrst paper that attempts at debi-   asing sentence and word embeddings for transla-   tionese . We introduce two techniques for debiasing   translationese at the word level : one ( Stepwise   Aligned Subspaces ) is akin to the subspace con-   struction approach of gender - debiasing proposed   by Bolukbasi et al . ( 2016 ) and Ravfogel et al .   ( 2020 ) , the second ( Direct Joint Subspace ) is a   simpliﬁed approach that operates directly on the   joint space without the use of a separate transla-   tionese word list and multiple independently com-   puted and subsequently aligned subspaces . Our   word - based debiasing study provides a systematic   view of translationese biases contained in static   embeddings . We also explore translationese debi-   asing at sentence level embeddings computed from   contextualised word embeddings . As expected , the   INLP - based linear translationese debiasing results   on static word embeddings are as “ perfect ” as our   sentence level results , reducing the performance   of a linear translationese classiﬁer on the debiased   data to chance , demonstrating that our debiasing   strategies effectively attenuate translationese sig-   nals in both these spaces .   Further , we evaluate the effects of debiasing   translation artifacts on a standard NLI task in two   settings . Even though we achieve " perfect " perfor-   mance for the translationese classiﬁcation - based   debiasing task with INLP , this translates into just   modest improvements resulting from INLP - based   debiasing translationese in neural machine transla-   tion in an NLI task , with slightly better results for   sentence than word debiasing . This demonstrates   that our debiasing approach is effective in reduc-   ing translation artifacts but that there is more to   translationese than is visibe to a linear classiﬁer .   Finally , we acknowledge that while this study is   the ﬁrst to debias translationese encoded as latent   representation in ( word and sentence ) embedding   space , the effect of this on the actual surface form   of the generated output is not investigated . We   hope to account for this in future work .   7 Acknowledgments   We would like to thank Saadullah Amin for   his helpful feedback . Funded by the Deutsche   Forschungsgemeinschaft ( DFG , German Research   Foundation ) – SFB 1102 Information Density and   Linguistic Encoding.3987References39883989A Appendix   A.1 Experimental Setup and   Hyperparameters   Each run in Table 1 took around 1.5 hours on a   GTX1080Ti GPU . Each classiﬁcation and debi-   asing step for SNLI sentence - level experiment in   Table 3 took approximately 2 hours on V100 - 32 GB   GPU . Other hyperparameter settings are shown in   the Table 4 .   A.2 Debiased Word Representations   A.2.1 Word Analogy Tests   To verify that debiasing does not hurt the quality   of the word representations , we estimate the per-   formance of the original and debiased embeddings   on the word analogy task using the MultiSIMLEX   benchmark ( Vuli ´ c et al . , 2020 ) . As MultiSIMLEX   does not cover German , we use German - Simlex   from Leviant and Reichart ( 2015 ) . After debiasing ,   Spearman’sρcorrelation coefﬁcients show negligi-   ble decreases of 0.02 on En - De and En - Es , 0.01 on   Es - En and Es - De , 0.3 on De - En and an increase of   0.01 for De - Es .   A.2.2 Visualisation   Figure 1 shows the t - SNE ( Van der Maaten and   Hinton , 2008 ) projection of the vectors in Direct   Joint Space Projection before and after debiasing   with INLP .   A.3 Translationese Word Lists   The size of the translationese word lists created via   the usage change algorithm of ( Gonen et al . , 2020 )   is shown in Table 5 and our top-50 elements per   language are shown in Table 6.39903991