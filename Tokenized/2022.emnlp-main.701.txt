  Sungdong KimGangwoo Kim   NA VER AI LabKAIST AIKorea University   sungdong.kim@navercorp.com gangwoo_kim@korea.ac.kr   Abstract   Conversational search ( CS ) needs a holistic un-   derstanding of conversational inputs to retrieve   relevant passages . In this paper , we demon-   strate the existence of a retrieval shortcut in   CS , which causes models to retrieve passages   solely relying on partial history while disre-   garding the latest question . With in - depth anal-   ysis , we first show that naively trained dense   retrievers heavily exploit the shortcut and hence   perform poorly when asked to answer history-   independent questions . To build more robust   models against shortcut dependency , we ex-   plore various hard negative mining strategies .   Experimental results show that training with   the model - based hard negatives ( Xiong et al . ,   2020 ) effectively mitigates the dependency on   the shortcut , significantly improving dense re-   trievers on recent CS benchmarks . In partic-   ular , our retriever outperforms the previous   state - of - the - art model by 11.0 in Recall@10   on QReCC ( Anantha et al . , 2021 ) .   1 Introduction   Conversational search ( CS ) is a task of retrieving   relevant passages from a large amount of web text   given the current question and its conversational   history , which consists of previously asked ques-   tions and their answers ( Dalton et al . , 2019 ) . Un-   like open - domain question answering ( ODQA ) tak-   ing a single question ( V oorhees and Tice , 2000 ;   Chen et al . , 2017 ) , CS assumes a sequence of ques-   tions interactively taken from information seekers .   Hence , the questions need to be understood with   the conversational history to find relevant evidence   at each turn .   To build a retriever that properly makes use of   the conversational history , we first analyze a simple   dense retriever baseline trained on one of the CS   datasets , QReCC ( Anantha et al . , 2021 ) . Our anal-   ysis shows us the existence of a retrieval shortcutFigure 1 : An example of a retrieval shortcut in con-   versational search . While we expect the retriever to   predict relevant passages by using all conversational   inputs up to q(Blue solid line ) , a dense retriever often   ignores current turn question qand only exploits previ-   ous history , a(Red dashed line ) . We show the shortcut   dependency is harmful to robust retrieval .   in recent CS datasets , indicating dense retrievers   heavily rely on the shortcut and retrieve irrelevant   passages . Specifically , these shortcuts represent the   spurious correlation between the conversational his-   tory and the relevant passages , pushing the dense   retrievers to ignore current questions . For example ,   as illustrated in Figure 1 , a dense retriever retrieves   wrong passages only paying attention to ‘ Russia ’   and ‘ World Cup ’ mentioned in the previous his-   tory ( a , a ) while ignoring the crucial cue ‘ win   the World Cup ’ in the current question q.   Motivated by our observation , we further test   how much the shortcut contributes to the perfor-   mance of current retrievers . First , we build a sim-   ple BM25 baseline , which only takes the previous   conversational history as input , but still performs10278surprisingly well on QReCC . Similarly , a dense   retriever trained by feeding the conversational his-   tory without the current question keeps 70 - 80 % of   the original performance . It implies a significant   effect of the shortcut dependency on dense retriev-   ers . From our analysis , we find the shortcut is more   likely to be learned when the topic of conversation   is constant . In other words , performance of the   models drops especially when they are asked to   answer history - independent questions .   To alleviate the overreliance on the shortcut ,   we explore using hard negative mining strategies ,   which have been recently proposed in ODQA and   CS ( Karpukhin et al . , 2020 ; Xiong et al . , 2020 ; Yu   et al . , 2020 ; Lin et al . , 2021b ) . Experimental results   show the model - based hard negatives make remark-   able improvements in various CS benchmarks and   are especially helpful to history - independent ques-   tions , mitigating the dependency on the shortcut   effectively . Our retrievers outperform baselines by   11.0 in Recall@10 on QReCC .   Our contributions are summarized in three folds :   •We reveal the presence of a retrieval short-   cutin the conversational search , and dense   retriever dependent on the shortcut is poor at   generalizing toward a real scenario .   •We show training the dense retriever with hard   negatives effectively mitigates the heavy short-   cut dependency by in - depth analysis .   •We achieve a new state - of - the - art of recent CS   benchmarks , QReCC and OR - QuAC .   2 Background and Related Work   LetX={q , a , ... , a , q}is a conversation up   to turn twhere the qandaare the question and   answer at turn t. We assume pre - chunked passages   collection C={p , p , ... , p}for the retrieval .   Then , the formal objective of conversational search   is learning function f : ( X , C)→P , where the   P={p , p , ... , p } ⊂ C andk≪ |C| .   On the other hand , conversational query rewrit-   ing ( CQR ) is a generative task that rewrites the   conversational input Xinto a standalone question   q(Yu et al . , 2020 ; V oskarides et al . , 2020 ; Lin et al . ,   2021c ; Kumar and Callan , 2020 ; Anantha et al . ,   2021 ; Wu et al . , 2021 ) . Then , existing retrieval sys-   tems such as BM25 take the standalone question   qto find Pat inference time , i.e. f(q , C)→P.   As a result , the CQR approaches do not require tore - train additional retriever in a conversational man-   ner . However , the approach is limited in triggering   information loss and long latency while rewriting   the conversation into the standalone question .   To overcome the limitations , Yu et al . ( 2021 ) ;   Lin et al . ( 2021b ) attempt to train dense retrievers   to directly represent the multi - round questions into   a single dense vector . They usually focused on   few - shot adaptation or weak supervision utilizing   other accessible resources including the standalone   questions for hard negative mining .   3 Retrieval Shortcut   First , we demonstrate the presence of the shortcut   in CS datasets . Formally , we define the shortcut as   where gold passage pcan be predicted in top - k   predictions even without the current question q.   Then , we show how heavily dense retriever relies   on the shortcut and how its overall performance is   overestimated .   3.1 Lexical Analysis   We investigate whether there are spurious lexical   cues to predict relevant gold passages in CS . Specif-   ically , we input X\{q}={q , a , ... , a}to   the BM25 to measure the shortcut . Figure 2 ( a )   shows the result . Surprisingly , we observe the   BM25 taking X\{q}achieves 58.4 for R@10   on QReCC ( Anantha et al . , 2021 ) even without   the current question q. It retains about 90 % of its   original performance from BM25 ( Xas an input ) ,   indicating X\{q}contains enough lexical cues to   predict p. However , a model taking only current   question qdoes not predict the gold passage well   since it does not contain enough lexical cues . In-   stead , the previous answer ais more responsible   for the performance , achieving 46.4 of R@10 .   3.2 Lower and Upper bounds Analysis   To examine how dense retriever trained on the   dataset behave , we contrast a dense retriever with   its lower and upper bound models in terms of de-   pendency on the retrieval shortcut . For this , we   train two Dense Passage Retriever ( DPR ) models   with in - batch negatives ( Karpukhin et al . , 2020 )   by feeding XandX\{q}as input query to each   model . We denote the latter one as DPR , and   it represents the lower bound model that does not   consider the current question qat all . Surprisingly ,   we find the DPRperforms 78 % of R@10 and 85%10279   of R@100 compared to DPR as shown in Figure 2   ( b ) . Thus , we presume the original DPR model   is also likely to depend on the shortcut . Next , we   introduce the upper bound model , GPT2QR ( Anan-   tha et al . , 2021 ) . It is less likely to be exposed   to the shortcut since it first generates standalone   question q , and then its BM25 retriever only takes   the decontextualized qas input . We also find that   the DPRis comparable with GPT2QR in R@10   despite the heavy shortcut dependency . It reminds   us the overall score is not enough to identify robust   retrieval methods .   3.3 Breakdown by Question types   To probe when and how models take the shortcut ,   we break down the evaluation results by question   types as in Wu et al . ( 2021 ) . Specifically , we define   three question types , first , no - switch , and switch .   Thefirstquestion is literally first question of con-   versation without any history . The no - switch and   switch questions can be distinguished by whether   pcontains similar or same topics as p , where   thepis a gold passage at turn tandt > 1 .   Figure 2 ( c ) shows the breakdown result of   R@10 . The DPRachieves competitive perfor-   mance with the DPR in no - switch questions , which   can benefit from previous conversational history .   However , the performances in other two types , first   andswitch , drop significantly . Similarly , when we   compare DPR with the GPT2QR , we find the per-   formance at no - switch turn largely contributes tothe gain while degraded in firstandswitch types .   As a result , its overreliance on the shortcut prevents   the model from generalizing toward real scenarios   where a large proportion of topic - switching ques-   tions could appear ( Adlakha et al . , 2022 ) . Thus ,   we claim that the proper ways to take the shortcut   could improve the overall score with performance   gains at the first andswitch turns while keeping   them at the no - switch .   4 Experiments   We hypothesize random in - batch negatives pro-   mote the shortcut dependency of the vanilla DPR   model because of their easy - to - distinguish nature .   Thus , we examine hard negative mining as one of   the solutions to push the retriever to exploit the   shortcut properly . We mainly evaluate it on two   CS benchmarks , QReCC and OR - QuAC ( Anantha   et al . , 2021 ; Qu et al . , 2020 ) .   4.1 Training Dense Retriever   DPR consists of two encoders , EandE , for   encoding conversational input and passages , re-   spectively . Each encoders takes the Xandp , a   passage in the C , to represent ddimensional vector .   Then , we can compute the similarity between the   representations via dot product .   sim(X , p ) = E(X)E(p )   Given the input X , the encoders are trained in   a contrastive manner with the negative passages10280P={p , p , ... , p}and its corresponding   positive passage p.   L=−loge   e+/summationtexte   Basically , we adopt in - batch negatives to obtain   theP(Karpukhin et al . , 2020 ) . For each query   representation , it computes the similarity score   with other ( B−1 ) number of passage represen-   tations except for its gold relevant passage in the   same batch , where the Bis batch size .   4.2 Hard Negative Mining   The in - batch negative is one of the intuitive options   to construct the negative examples while reduc-   ing memory consumption . However , it is often   easy to distinguish from the pand consequently   encourages shortcut dependency . To reduce the   dependency , we include a hard negative passage   pin the P. We first construct knumber of nega-   tive passages Nfor each training instance . Then ,   we randomly sample a passage from the Nto   include it in Pas the p. We denote off - the-   shelf retriever to obtain top- kpassages in Cfrom   given input query xasF(x , C , k ) . Specifically , we   compare three strategies for hard negative mining :   BM25 Negs De - facto strategy is BM25 - based   negative mining following Karpukhin et al . ( 2020 ) .   We mine the Nusing whole conversational input   X , i.e. ,N←BM25 ( X , C , k ) .   CQR Negs If gold standalone question qis avail-   able for each X , we can leverage it to find the   negative passages with off - the - shelf retriever as in   Yu et al . ( 2020 ) ; Lin et al . ( 2021b ) , i.e. , N←   F(q , C , k ) . For this , we employ another DPR pre-   trained on Natural Questions ( NQ ) ( Kwiatkowski   et al . , 2019 ) as the F.   Model Negs Lastly , we explore model - based   hard negative mining proposed by Xiong et al .   ( 2020 ) . First , we train vanilla DPR model on the   target dataset using only in - batch negative as in § 3 .   Then , we employ the model as Fto select negative   passages , i.e. , N← F ( X , C , k ) .   4.3 Implementation Details   DPR pre - trained on NQ dataset ( Kwiatkowski et al . ,   2019 ) of Karpukhin et al . ( 2020 ) is used for the ini-   tial checkpoint of our dense retrievers . It consistsof two BERT encoders and 220 M of learnable pa-   rameters ( Devlin et al . , 2019 ) . We set maximum   sequence length to 128 and 384 for Xandp , re-   spectively . All history is concatenated with a [ SEP ]   token in between . We retrain the first question and   truncate tokens from the left side up to the maxi-   mum length of 128 for X.   We train the models for 10 epochs with 3e-5   of learning rate ( lr ) . For optimization , AdamW is   used with 0.1 warming up ratio for linear lr decay   scheduling ( Kingma and Ba , 2017 ) . We build top   100 passages for the hard negatives N , i.e. ,k=   100 . Batch size is set to 128 for OR - QuAC and   256 for QReCC . We choose the best performing   model based on dev set . We use Pyserini ( Lin et al . ,   2021a ) to implement BM25 and IndexFlatIP index   of FAISS ( Johnson et al . , 2019 ) to perform dense   retrieval .   4.4 Baselines   In QReCC , we include BM25 and BM25take   XandX\{q}as input query , respectively . For   CQR baselines less dependent on the shortcut , we   include GPT2QR and CONQRR ( Anantha et al . ,   2021 ; Wu et al . , 2021 ) . They use standalone ques-   tion instead of directly encoding a conversation for   the input of off - the - shelf retriever such as BM25   or T5 - DE ( Ni et al . , 2022 ) finetuned on ODQA   dataset . Anantha et al . ( 2021 ) propose GPT2QR   as baseline model which is GPT-2 ( Radford et al . ,   2019 ) based CQR model . We only perform BM25   inference based on released model predictions by   authors instead of re - training it . CONQRR is based   on T5 ( Raffel et al . , 2020 ) for the CQR ( Wu et al . ,   2021 ) . Especially , Wu et al . ( 2021 ) train the CON-   QRR using reinforcement learning against retrieval   metrics ( MRR , Recall ) as reward signals . We also   include DPR and DPRwithout hard negative min-   ing to represent shortcut - dependent model .   In OR - QuAC , we compare our models with pre-   viously proposed dense retrieval approaches in con-   versational search , CQE ( Lin et al . , 2021b ) and   ConvDR ( Yu et al . , 2020 ) . Both of them utilize the   standalone question qto mine hard negatives and   knowledge distillation from off - the - shelf retrievers   trained on ODQA , regarding it as a teacher model .   Although they were not tested on QReCC , we can   indirectly compare them with others using DPR   with CQR Negs instead.10281   4.5 Results   We report scores among Mean Reciprocal Rank   ( MRR ) and Recall ( R@K , K ∈ { 5,10,100}).Ta-   ble 1 shows the retrieval performances of base-   line models and hard negative mining methods on   QReCC , and our findings are summarized :   Overall performances are not enough to dis-   tinguish robust methods in CS . We find lexical   baselines , BM25 and BM25 , outperform CQR-   based models , GPT2QR and CONQRR ( Anantha   et al . , 2021 ; Wu et al . , 2021 ) and vanilla DPR in   MRR of overall retrieval performances ( All ) . How-   ever , as we discussed in § 3 , the most performances   are from no - switch questions which can benefit   from the shortcut .   Hard negatives could mitigate shortcut de-   pendency of dense retrievers . We observe the   vanilla DPR underperforms the GPT2QR in first   andswitch questions . Also , there is a relatively   smaller gap between DPRand DPR in no - switch   type of questions . Compared to the vanilla DPR ,   all three negatives effectively improve the overall   performance . Especially , the history - independent   types , firstandswitch , are improved at most 12.7-   15.2 in R@10 indicating relaxed shortcut depen-   dency of the model . Figure 3 shows T - SNE visu-   alizations ( Van der Maaten and Hinton , 2008 ) to   compare DPR models with and without negatives   in embedding space . Different from the vanilla   DPR that fails to identify a gold passage from other   irrelevant passages , DPR trained with negatives   more clearly discriminates it from the distractors .   Among the negative mining methods , the   model - based hard negative consistently outper-   forms others . We observe consistent results in   other CS dataset , OR - QuAC ( Qu et al . , 2020 ) com-   pared to previous works ( Please see Appendix C ) .   Moreover , our model achieves a new state - of - the-   art with improvements of 11.0 % point R@10 .   5 Conclusion   In this work , we show the presence of the shortcut   in conversational search , which causes dense re-   triever often heavily relies on it when trained on in-   batch negatives . We find that shortcut dependency   hurts the generalization ability of dense retrievers .   To save the model from relying on the shortcut ,   we study various hard negative mining strategies .   The retriever trained with hard negatives appropri-   ately takes beneficial information of the shortcut   only when needed and achieves the state - of - the - art   performance on multiple CS benchmarks .   Limitations   Even if we explain the existence of shortcut in con-   versational search , we could not suggest specific so-   lutions to the shortcut dependency of dense retriev-   ers . In the preliminary study , we tried other meth-10282ods , e.g. , history masking to promote the model at-   tending more to the current question , but we found   those methods are not effective as the hard negative   mining in terms of shortcut dependency . However ,   we believe our work is an important step toward   more robust conversational search .   Another limitation is the implementation cost to   perform the model - based hard negative mining , i.e. ,   indexing and inference of dense retriever over huge   passages collection . Please see Appendix D for the   details . Especially , the cost is increased notoriously   according to the number of passage collections . We   expect a more efficient method to balance shortcut   dependency in future works .   Acknowledgements   The authors would like to thank to Kyunghyun   Cho , Jinhyuk Lee , Minjoon Seo , Sang - Woo Lee ,   Hwaran Lee and other members of NA VER AI for   their constructive comments .   References1028310284A Details of Question Types   We classify the no - switch andswitch questions us-   ing dot product score between BM25 vectors of   pandpas threshold in QReCC dataset . This   is similar with division of topic - concentrated and   topic - shifted questions in Wu et al . ( 2021 ) while   we take them only when t > 1to distinguish them   from firstquestions . The number of subsets is 267 ,   279 , and 573 for the first , no - switch , and switch re-   spectively . Please note that the sum of each subset   is not equal to the number of all(8209 ) since we   take the question types from only NQ and TREC   subdomains in the QReCC dataset as in Wu et al .   ( 2021 ) .   B Details of Dataset   We mainly conduct experiments on recent CS   benchmarks , OR - QuAC and QReCC ( Qu et al . ,   2020 ; Anantha et al . , 2021 ) . We briefly describe   the procedures of data construction and features of   each dataset . Table 2 shows dataset statistics we   used .   OR - QuAC Qu et al . ( 2020 ) extend one of the   popular CQA datasets , QuAC ( Choi et al . , 2018 ) to   the open - domain setting by aligning relevant pas-   sages with the questions in QuAC.Moreover , they   facilitate CQR as a subtask by reusing examples   in CANARD ( Elgohary et al . , 2019 ) . For retrieval ,   they construct passage collections from Wikipedia .   However , the dataset has limitations in that all ques-   tions in the same conversation share the same gold   passage . In other words , most of the questions in   OR - QuAC are no - switch type . Thus , it is vulner-   able to the shortcut . Even though it is far from   the real world scenario , we include OR - QuAC to   compare previous dense retrieval approaches ( Lin   et al . , 2021b ; Yu et al . , 2021 ) . We use smaller col-   lections C(6.9k ) provided by the authors for the   development . Model MRR R@5   BM25 ( q , C ) 0.216 30.6   BM25 ( q , C ) 0.043 5.6   BM25 ( Q , C ) 0.170 21.3   BM25 ( Q , C ) 0.198 24.9   ALBERT ( Qu et al . , 2020 ) 0.225 31.4   CQE(Lin et al . , 2021b ) 0.266 36.5   ConvDR ( Yu et al . , 2021 ) 0.616 75.0   DPR 0.525 63.9   w. Model Negs 0.633 75.9   QReCC Anantha et al . ( 2021 ) construct QReCC   dataset based on three existing datasets , QuAC ,   Natural Questions ( NQ ) , and TREC ( Choi et al . ,   2018 ; Kwiatkowski et al . , 2019 ; Dalton et al . ,   2019).To annotate gold passage , they reuse con-   versational questions in QuAC and CAsT as in Qu   et al . ( 2020 ) , while collecting new questions for the   NQ dataset . Given a question randomly selected   from NQ , each crowdworker alone generates not   only the following questions but also their corre-   sponding answers . Even though it contains more   diverse and realistic questions than the OR - QuAC ,   most of the questions ( 78 % ) still belong to the   QuAC , causing models to exploit the shortcut . We   newly select the development set by sampling 2k   conversations from the train set , since Anantha et al .   ( 2021 ) combined them into the train set when the   dataset is released . We also choose 7.3k number of   corresponding dev passages for the development   collections C. We only regard the examples that   contain ground truth relevant passages . Thus , the   actual number of training examples is 24,283 .   C Experimental Results on OR - QuAC   Table 3 shows results on OR - QuAC where most   of the questions are no - switch type . First , we ob-   serve another retrieval shortcut on the first question ,   which is not observed in QReCC . Even if we in-   put only first question to BM25 , BM25 ( q , C ) , it   achieves competitive results with ALBERT base-   line by Qu et al . ( 2020 ) . We presume the lexi-10285Data Training Indexing Inference   OR - QuAC 2h 8h 40 m   QReCC 2h 28h 11h   cal cues from the first question are caused by pre-   proccesing for the questions , rewriting to the stan-   dalone questions ( Qu et al . , 2020 ) .   Our DPR with model - based hard negatives con-   sistently outperforms the previous dense retriev-   ers ( Yu et al . , 2020 ; Lin et al . , 2021b ) . Even though   it is not fair comparison since their different back-   bones and setups , we can compare the models in   terms of hard negative mining strategies . Both CQE   and ConvDR utilize CQR - based negatives requir-   ing gold human rewrite q(CQR Negs ) . Similar to   result in Table 1 , our model with model - based neg-   atives ( Model Negs ) achieves better performances   without any usage of query rewriting .   D Computational Cost   Overall computational cost is summarized in Ta-   ble 4 . Please note that the number of passages col-   lection and test set of QReCC is much larger than   the other . Thus , we allocate 8 GPUs for QReCC   and 4 GPUs for OR - QuAC to perform training and   indexing . We conduct training and inference once   for all experiments because of the expensive com-   putational cost.10286E Qualitative Examples10287