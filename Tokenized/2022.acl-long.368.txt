  Seo Yeon Park and Cornelia Caragea   Computer Science   University of Illinois Chicago   spark313@uic.edu cornelia@uic.edu   Abstract   A well - calibrated neural model produces con-   ﬁdence ( probability outputs ) closely approx-   imated by the expected accuracy . While   prior studies have shown that mixup train-   ing as a data augmentation technique can im-   prove model calibration on image classiﬁca-   tion tasks , little is known about using mixup   for model calibration on natural language un-   derstanding ( NLU ) tasks . In this paper , we   explore mixup for model calibration on sev-   eral NLU tasks and propose a novel mixup   strategy for pre - trained language models that   improves model calibration further . Our pro-   posed mixup is guided by both the Area Un-   der the Margin ( AUM ) statistic ( Pleiss et al . ,   2020 ) and the saliency map of each sample ( Si-   monyan et al . , 2013 ) . Moreover , we combine   our mixup strategy with model miscalibra-   tion correction techniques ( i.e. , label smooth-   ing and temperature scaling ) and provide de-   tailed analyses of their impact on our proposed   mixup . We focus on systematically design-   ing experiments on three NLU tasks : natu-   ral language inference , paraphrase detection ,   and commonsense reasoning . Our method   achieves the lowest expected calibration er-   ror compared to strong baselines on both in-   domain and out - of - domain test samples while   maintaining competitive accuracy .   1 Introduction   Training a well - calibrated classiﬁer that produces a   match between conﬁdence ( the probability output   that a model assigns to a prediction ) and correct-   ness ( accuracy ) , is important in modern neural net-   works . As an example , if an AI - based application   knows what it does not know , or in other words ,   the chance that the current prediction is wrong , a   human is more helpful to correct the error . How-   ever , many works reveal that current deep neural   networks are prone to over - conﬁdence , which im-   plies that the models ’ conﬁdence is not reliable   ( Guo et al . , 2017 ) . This is a critical issue on thedeployment of AI - based user applications such as   the healthcare domain ( Zhu et al . , 2018 ; Li et al . ,   2019 ) or safety - critical domain ( Sarabadani , 2019 )   due to the problem of prediction trustworthiness .   Recently , the study of calibration on neural net-   work models especially on natural language pro-   cessing tasks has started to receive attention . To   overcome the problem of miscalibration , numerous   suggestions on how to address it have been pro-   posed . For example , Guo et al . ( 2017 ) revealed   that using temperature scaling before the ﬁnal soft-   max layer reduces calibration errors . Müller et al .   ( 2019 ) , Kumar and Sarawagi ( 2019 ) , and Wang   et al . ( 2020a ) found that label smoothing and its   variants yield better calibration for neural machine   translation . Desai and Durrett ( 2020 ) also reported   that the aforementioned miscalibration correction   methods can be applied to calibrate pre - trained   language models which are often miscalibrated po-   tentially due to over - parameterization .   Mixup ( Zhang et al . , 2018 ) is a data augmen-   tation method for deep neural networks in which   additional samples are generated during training   by combining random pairs of training inputs and   their associated labels . While simple to implement ,   mixup has been shown to improve both predictive   performance and model calibration , particularly on   image classiﬁcation tasks due to its regularization   effect through data augmentation ( Thulasidasan   et al . , 2019 ) . The recent success of mixup on image   classiﬁcation has led to the development of vari-   ous mixup strategies for NLU especially those that   use hidden state representations ( Guo et al . , 2019a ;   Chen et al . , 2020 ; Zhang et al . , 2020 ; Sun et al . ,   2020 ; Kong et al . , 2020 ; Yin et al . , 2021 ) . However ,   most prior works on NLU focus on performance   improvement using mixup rather than model cali-   bration . Despite its beneﬁts for calibration , a mixup   for correcting miscalibrated predictions is still an   under - explored topic in NLU . While Kong et al .   ( 2020 ) explored BERT ( Devlin et al . , 2019 ) cali-5364bration using mixup for both in - domain and out-   of - domain , they only focused on generating mixup   samples by utilizing the distance between instances   in the feature space . In contrast , we propose a novel   mixup method , in which we ﬁrst leverage the behav-   ior of a model on individual samples during training   ( training dynamics ) , which can reveal samples with   distinct pronounced characteristics — whether they   are easy - to - learn or hard - to - learn / ambiguous for   the model , and then we generate mixup samples by   mixing easy - to - learn with hard - to - learn / ambiguous   samples according to their similarity / dissimilarity   provided by saliency maps . Saliency maps cap-   ture how much each data portion contributes to   the ﬁnal classiﬁcation decision of a sample ( Si-   monyan et al . , 2013 ) . Intuitively , easy - to - learn   samples help with model optimization , whereas   hard - to - learn or potentially ambiguous samples are   essential for learning since they are the most chal-   lenging for the model ( Swayamdipta et al . , 2020 ) ,   and mixing them using saliency maps can yield   better calibrated models ( more realistic model con-   ﬁdence ) , e.g. , mixing easy - to - learn with hard - to-   learn / ambiguous samples by similarity in saliency   maps can beneﬁt in - domain calibration and by dis-   similarity can beneﬁt out - of - domain calibration . To   monitor training dynamics , we use the Area Un-   der the Margin ( AUM ) statistic ( Pleiss et al . , 2020 )   which measures how different a true label for a sam-   ple is compared to a model ’s beliefs at each epoch   and is calculated as the average difference between   the logit values for a sample ’s assigned class and its   highest non - assigned class across training epochs .   Moreover , we combine our mixup with well-   known miscalibration correction methods such as   label smoothing and temperature scaling ( Guo   et al . , 2017 ) to investigate their impact on our pro-   posed mixup . We conduct a comprehensive set of   experiments using BERT ( Devlin et al . , 2019 ) and   RoBERTa ( Liu et al . , 2019 ) to show the efﬁcacy   of our mixup approach by testing on three NLU   tasks : natural language inference , paraphrase detec-   tion , and commonsense reasoning . We achieve the   lowest Expected Calibration Error ( ECE ) without   accuracy drops in comparison with strong baseline   methods . Our contributions are as follows :   •We propose a novel mixup method which   is guided by AUM and saliency signals and   is targeted at improving model calibration .   Speciﬁcally , we compare logits to categorize   samples into two sets ( i.e. , a set of easy - to - learn samples and another set of hard-   to - learn / ambiguous samples ) , and interpo-   late samples across these two sets by ﬁnd-   ing the most similar and most dissimilar   samples from the other set while leveraging   saliency ( to compute sample similarities ) for   pre - trained language models ’ calibration on   in - domain and out - of - domain data .   •We combine our method with miscalibration   correction techniques ( i.e. , label smoothing ,   temperature scaling ) to investigate their im-   pact on our proposed mixup .   •We conduct comprehensive experiments   showing that our method achieves the low-   est expected calibration errors ( ECEs ) on both   in - domain and out - of - domain samples com-   pared with strong baselines without accuracy   drops on multiple NLU tasks , namely , natu-   ral language inferences , paraphrase detection ,   and commonsense reasoning .   2 Related Work   Model Calibration Calibration on NLU tasks   has been widely studied in related literature .   Nguyen and O’Connor ( 2015 ) provided the method   of how to analyze the calibration of non - neural   NLP models . Guo et al . ( 2017 ) examined the cal-   ibration of modern deep neural networks and re-   vealed that techniques such as temperature scaling   and dropout affect the calibration on binary / multi-   class classiﬁcation tasks . Wang et al . ( 2020b ) inves-   tigated the calibration of neural machine translation   models and found that inference suffers from se-   rious miscalibration . Jagannatha and Yu ( 2020 )   demonstrated that neural networks show high cali-   bration error on structured predictions such as NER ,   POS , and QA , and proposed to use a binary class   forecaster to calibrate the predictor conﬁdence for   a deﬁned output entity of interest . Desai and Dur-   rett ( 2020 ) explored pre - trained language models ’   calibration in combination with temperature scal-   ing and label smoothing both on in - domain and   out - of - domain datasets . Jung et al . ( 2020 ) jointly   optimized two objectives ( a cross - entropy loss and   a calibration loss ) and directly penalized the differ-   ence between the predicted and the true posterior   probabilities dynamically over the training steps .   He et al . ( 2021 ) obtained better calibration on nat-   ural language understanding tasks by augmenting   and training the classiﬁer jointly with an energy-   based model using noise - contrastive estimation.5365Mixup Mixup ( Zhang et al . , 2018 ) is a method   for data augmentation in which additional samples   are generated during training by convexly combin-   ing random pairs and their associated labels , and   aims to alleviate overﬁtting . Verma et al . ( 2019 )   showed that manipulating hidden representations   rather than manipulating input - level features on   mixup results in better regularization effects due   to the fact that it encourages the neural network to   focus more on representations of the real training   examples in a low dimensional subspace . Many   works have empirically noticed regularization ef-   fects that improve model performance on deep   neural networks . For example , Guo et al . ( 2019a )   explored the NLU speciﬁc mixup strategy by us-   ing sentence and word embeddings on CNNs and   LSTMs to add performance gains in supervised   text classiﬁcation . Chen et al . ( 2020 ) proposed   mixup for semi - supervised learning in which la-   beled and unlabeled samples are interpolated with   their hidden representations to improve the perfor-   mance of text classiﬁcation . Zhang et al . ( 2020 )   explored mixup for sequence labeling tasks with   active learning to improve the performance of su-   pervised sequence labeling tasks . Yin et al . ( 2021 )   proposed mixup that interpolates every instance   in a mini - batch to boost the performance of NLU   tasks on the pre - trained language model RoBERTa   ( Liu et al . , 2019 ) . Similar to us , Yoon et al . ( 2021 )   explored mixup by incorporating saliency signals   to generate augmented samples . Precisely , they use   saliency signals to select a span of text from one   sample to be replaced with another text span from   another sample . However , in contrast , our method   ﬁrst divides data samples into two categories ( easy-   to - learn and hard - to - learn / ambiguous categories )   according to their AUM ( Pleiss et al . , 2020 ) dis-   tribution monitored over training epochs and then   uses saliency to ﬁnd the most similar / dissimilar   samples across these two data categories .   Recently , several works started to explore mixup   for NLU model calibration . For example , Thulasi-   dasan et al . ( 2019 ) investigated the impact of mixup   for model calibration of NLU but only explored   in - domain settings with simple deep learning archi-   tecture such as CNNs . Kong et al . ( 2020 ) explored   BERT calibration using mixup as a regularization   component on in - domain and out - of - domain . How-   ever , their mixup method only relied on the feature   space distance between samples . In contrast , we   explore a novel mixup method in which we cat-   egorize the training samples into two sets usingAUM ( Pleiss et al . , 2020 ) and combine samples   across these two sets based on saliency signals , for   in - domain and out - of - domain model calibration .   3 Approach   3.1 Mixup   Background LetD = f(x;y)gbe   a training set and fa language model . Mixup train-   ing generates vicinity training samples according   to the rule introduced in Zhang et al . ( 2018 ):   ~x=x+ ( 1 )x   ~y=y+ ( 1 )y(1 )   wherexandxare two randomly sampled input   points , yandyare their associated one - hot en-   coded labels , and is a mixing ratio sampled from   a Beta (  ,  ) distribution with a hyper - parameter   . In mixup , training data is augmented by linearly   interpolating training samples in the input space .   3.2 Proposed Approach   We propose a mixup method targeted at improving   model calibration that synthesizes samples guided   by the Area Under the Margin ( AUM ) ( Pleiss et al . ,   2020 ) and saliency ( Simonyan et al . , 2013 ) .   Data Categorization In our method , we ﬁrst cat-   egorizeD into two sets ( a set of easy - to - learn   samples and a set of hard - to - learn / ambiguous sam-   ples ) according to the AUM of each sample . Given   a sample ( x;y ) , we compute AUM ( x;y)as the   area under the margin averaged across all training   epochsT. Speciﬁcally , at some epoch t2 T , the   margin is deﬁned as :   M(x;y ) = z max(z ) ( 2 )   whereM(x;y)is the margin of example xwith   gold labely , zis the logit corresponding to the   gold labely , andmax(z)is the largest other   logit corresponding to label knot equal to y. Pre-   cisely , the margin measures how different a gold   label is compared to a model ’s beliefs at each epoch   t. The AUM of ( x;y)across all epochs is :   AUM ( x;y ) = 1   TXM(x;y ) ( 3 )   Intuitively , the samples with high AUM are easy-   to - learn ( the model ’s belief matches the gold label ) ,   but they are essential for model optimization , while5366Algorithm 1 : Identify high / low AUM samples   Require :D = f(x;y)g ; modelffunction D - C ( D)D ; ;D ; TrainfforTepochs and compute   AUM ( x;y)for eachias in Eq . ( 3 ) foreach ( x;y)2D do ifAUM ( x;y)<median thenD D[(x;y ) else ifAUM ( x;y)median thenD D[(x;y ) end if end for returnD;Dend function   the samples with low AUM are hard - to - learn or   ambiguous ( and hence they are the most challeng-   ing for the model ) , but they are essential for learn-   ing . Our proposed mixup method ﬁrst splits D   into two data categories depending on whether the   AUM value is high or low , namely , DandD.   In experiments , we compute the median AUM over   the entire training samples and use it as a threshold   to split the dataset . If a sample has a lower AUM   than the threshold , we add the sample to D , oth-   erwise we add it toD. Accordingly , we balance   DandD , but other splits are possible . We   then conduct a mixup operation by referring to each   other set . Mixing easy - to - learn and hard - to - learn   adjusts the difﬁculty of samples and hence adjusts   models ’ conﬁdence according to samples ’ difﬁcul-   ties and yields better calibrated models . The data   categorization step is summarized in Algorithm 1 .   Mixup using Saliency Signals We conduct a   mixup operation on the two data categories gen-   erated by Algorithm 1 using saliency signals ( as   detailed below ) . For the mixup , rather than select-   ing random samples from DandDto mix ,   we utilize saliency signals to select samples . To   measure saliency , gradient - based methods are usu-   ally used for saliency computation ( Li et al . , 2016 ;   Rei and Søgaard , 2018 ; Yoon et al . , 2021 ) . Follow-   ing this idea , we simply compute the gradient of   the classiﬁcation loss Lwith respect to each logit   valuez2zand take the absolute value of the gra-   dient components as the saliency map or signature   Sfor a sample ( x;y)2D. For a sample   ( x;y ) , we then leverage its saliency map Sto ﬁnd   the most similar and most dissimilar samples fromAlgorithm 2 : Proposed Mixup   Require :D = f(x;y)g ; modelfD;D    - ( D)fork:= 0 to T doTotal _ Loss 0 fori:= 0 tojDjdoLoss CrossEntropy ( f(x);y ) Construct a saliency map Sby comput-   ing the gradient of Loss with respect   toz if(x;y)2Dthen : Find the most similar / dissimilar   samples fromDusing Eq . ( 4 ) else if ( x;y)2Dthen : Find the most similar / dissimilar   samples fromDusing Eq . ( 5 ) end if Generate two mixup samples , one for   ( x;y)and its most similar sample and   another for ( x;y)and its most dissim-   ilar sample , using Eq . 1 . ComputeCrossEntropy loss for each   mixup sampleLoss  Loss +   Loss+Loss end forTotal _ Loss Total _ Loss + Loss Update the model weightsend for   the other data category that ( x;y)does not be-   long to according to its AUM , in order to calibrate   in - domain and out - of - domain data . For example ,   if(x;y)2D , we ﬁnd its most similar sam-   ple(x;y)and its most dissimilar sample ( x;y )   fromD , that return the largest and smallest co-   sine similarity , respectively , with the saliency map   Sof(x;y ) . That is , the most similar and most dis-   similar samples to ( x;y)2Dare calculated   as follows :   ( x;y ) = argmaxCosSim ( S;S )   ( x;y ) = argminCosSim ( S;S )   ( 4 )   Similarly , if ( x;y)belongs toD , we ﬁnd the   most similar / dissimilar samples from D that   return the largest / smallest cosine similarity with S5367as follows :   ( x;y ) = argmaxCosSim ( S;S )   ( x;y ) = argminCosSim ( S;S )   ( 5 )   We then generate two mixup samples for a given   sample ( x;y)by interpolating the selected sam-   ples , which are the most similar sample ( x;y ) ,   and the most dissimilar sample ( x;y ) . For the   mixup operation , we follow the original mixing   ratio sampling strategy which is shown in Eq . ( 1 ) .   The ratiois sampled from a Beta (  ;  ) distribu-   tion with a hyper - parameter  .   Intuitively , by synthesizing the original sample   and the most similar sample from the other data   category , we calibrate in - domain data . The aug-   mented sample mimics in - domain sample since   it aligns the most with the original sample . Fur-   thermore , by selecting the sample from the other   category , we allow the generated mixup sample to   combine easy - to - learn and hard - to - learn samples   properly . By synthesizing the original and the most   dissimilar sample from the other data category , we   calibrate out - of - domain data . The augmented sam-   ple mimics out - of - domain instances since we pick   a sample that is the most dissimilar to the original   sample . As above , by selecting the sample from   the other category , we allow the augmented sample   to contain both information of easy - to - learn and   hard - to - learn samples , useful for both optimization   and learning . Note that our mixup method mixes   samples on the level of [ CLS ] hidden state repre-   sentations generated by task - speciﬁc layer on top of   the pre - trained language model . We summarize the   process in Algorithm 2 . We combine each loss by   weighted sum ( see Alg . 2 ) where  ;   ;  are hyper-   parameters that sum up to 1 . In our experiments ,   we conduct our mixup operation using mini - batch   SGD to update the model weights . Note that other   saliency measures are possible to compute similar-   ity / dissimilarity between samples and will be an   interesting future direction .   3.3 Calibration Metrics   A model is perfectly calibrated when the conﬁ-   dence estimate ^pof the model is equal to true prob-   ability ( accuracy ) P(^y = yj^p ) = ^p . ( Naeini et al . ,   2015 ; Guo et al . , 2017 ; Desai and Durrett , 2020 ) .   This can be empirically approximated by discretiz-   ing the probability interval into a ﬁxed number ofbinsM= 10 where each bin bcontains pre-   dicted probabilities that encompass the interval .   The expected calibration error ( ECE ) is calculated   by weighting the average of the difference between   each bin ’s accuracy and conﬁdence as follows :   acc(b ) = 1   jbjX1(^y = y )   conf(b ) = 1   jbjX^p   ECE = Xjbj   Njacc(b) conf(b)j   whereNis the total number of predictions .   3.4 Miscalibration Correction Methods   We explore the combination of miscalibration cor-   rection methods ( described below ) with mixup to   investigate their impact on our proposed mixup for   model calibration .   Label Smoothing ( LS ) In supervised learning ,   one - hot encoded labels fail to provide uncertainty   of inputs due to the fact that all the probability mass   is given to one class . This results in over - conﬁdent   models since the largest logit becomes larger than   the others which removes the uncertainty of label   space . Label smoothing ( LS ) is a solution to penal-   ize this by preventing the models from becoming   over - conﬁdent . In this work , we incorporate label   smoothing with our proposed mixup . We gener-   ate smoothed one - hot target signal while creating   mixup instances by distributingmass over   non ground - truth classes , where 2(0;1)is a   hyper - parameter and jyjis the number of classes .   Temperature Scaling ( TS ) Temperature scaling   ( TS ) is a post - processing step which re - scales the   logit vector zusing a single scale parameter tem-   perature , T > 0for all classes . TS has the effect   of softening the outputs to be uniform with T > 1 ,   whileT!0has the effect of collapsing probabil-   ity mass to one class . We explore the effect of TS   when incorporated with our proposed mixup .   4 Experiments   4.1 Tasks and Datasets   We evaluate our calibration - targeted mixup on three   natural language understanding tasks : natural lan-5368guage inference , paraphrase detection , and com-   monsense reasoning . We evaluate the models in-   domain ( training and testing on data from the same   distribution ) and out - of - domain ( training and test-   ing on data from different distributions ) . Mixup re-   duces the number of undesirable oscillations when   predicting especially on out - of - distribution sam-   ples ( Zhang et al . , 2018 ) . Hence , effective mixup   should be less prone to over-ﬁtting when handling   out - of - distribution data . To test the beneﬁts of our   proposed method for pre - trained language model   calibration , we use in - domain trained models to pre-   dict out - of - distribution test samples . We describe   our in - domain and out - of - domain sets as follows .   Natural Language Inference Stanford Natural   Language Inference ( SNLI ) is a natural language in-   ference task to predict if the relation between a hy-   pothesis and a premise is entailment , contradiction ,   orneutral ( Bowman et al . , 2015 ) . Multi - Genre   Natural Language Inference ( MNLI ) captures natu-   ral language inference with more diverse domains   ( Williams et al . , 2018 ) than SNLI .   Paraphrase Detection Quora Question Pairs   ( QQP ) is a paraphrase detection task to test if two   questions are semantically equivalent ( Iyer et al . ,   2017 ) . TwitterPPDB ( TPPDB ) is to determine   whether sentence pairs from Twitter convey similar   semantics when they share URLs ( Lan et al . , 2017 )   Commonsense Reasoning Situations With Ad-   versarial Generations ( SWAG ) is a commonsense   reasoning task to choose the most plausible contin-   uation of a sentence among four candidates ( Zellers   et al . , 2018 ) . HellaSWAG is a dataset built using   adversarial ﬁltering to generate challenging out - of-   domain samples . It is distributionally different in   that its examples exploit statistical biases in pre-   trained models .   4.2 Comparison Methods   In this work , we explore the mixup effects on NLU   with the goal of producing better calibrated models ,   in particular pre - trained language models , which   are BERT ( Devlin et al . , 2019 ) and RoBERTa ( Liu   et al . , 2019 ) . We consider the following baselines :   •Pre - trained Language Models : Pre - trained   language models ﬁne - tuning on each down-   stream task using BERT ( Devlin et al . , 2019 )   and RoBERTa ( Liu et al . , 2019).•Mixup ( Zhang et al . , 2018 ; Thulasidasan   et al . , 2019 ): Mixup augments training data   by linearly interpolating randomly selected   training samples in the input space . The inter-   polation of Mixup is performed on the input   embeddings obtained from the ﬁrst layer of   the language model .   •Manifold - mixup ( M - mixup ) ( Verma et al . ,   2019 ) : An extension of Mixup , which inter-   polates training samples in the hidden feature   space . The interpolation of Manifold - mixup   is performed on the features obtained from the   last layer of the language model .   Each method is compared with two variants where   miscalibration correction methods ( label smooth-   ing , LS and temperature scaling , TS ) are applied .   4.3 Implementation Details   We use the same set of hyper - parameters across all   tasks as Desai and Durrett ( 2020 ) for a fair compar-   ison . We train models with a maximum of 3 epochs .   For BERT , we set batch size of 16 , a learning rate of   1e-5 , gradient clip of 1.0 , and no weight decay . For   RoBERTa , we set batch size of 32 , a learning rate of   2e-5 , gradient clip of 1.0 , and weight decay of 0.1 .   We follow the published train / validation / test split   by Desai and Durrett ( 2020).For mixup , we use   a mixing ratio sampling strategy hyper - parameter   = 0:4 . We use loss weight hyper - parameters ,   ;   ;  ; values as 0:8=0:1=0:1respectively . We did   hyper - parameter search for label smoothing 2   [ 0:001;0:003;0:01;0:03;0:1;0:3 ] . We use=   0:01=0:03=0:3for BERT,= 0:003=0:03=0:3for   RoBERTa on SNLI / QQP / SWAG , respectively . We   use threshold values for splitting data into two   groupsD andD(the median AUM over   full training samples ) as 3:5=4:4=2:5for BERT ,   3:4=4:0=2:7for RoBERTa on SNLI / QQP / SWAG ,   respectively . For all results , we report the mean   across ﬁve training runs with random restarts . Fi-   nally , all experiments are conducted on a single   NVIDIA RTX A5000 24 G GPU with a total time   for ﬁne - tuning all models being under 24 hours .   Temperature scaling ( TS ) searches are performed   in the range of [ 0.01,5.0 ] with a granularity of 0.01   using development datasets . TS is completed very   fast since it uses separate cached logits.5369   4.4 Results   We show the comparison of experimental results   ( ECE ) on BERT and RoBERTa in Table 1 . For each   task , we train the model on in - domain training set ,   and evaluate its expected calibration errors ( ECEs )   on in - domain and out - of - domain test sets . We make   the following observations :   First , for in - domain data , label smoothing   ( LS ) does not exhibit its effectiveness on pre-   trained language models ’ calibration . Speciﬁ-   cally , for in - domain data , pre - trained language   models with LS ( i.e. , BERT+LS / RoBERTa+LS )   achieve higher expected calibration errors ( ECEs )   compared with vanilla pre - trained language mod-   els ( i.e. , BERT / RoBERTa ) on all tasks . In con-   trast , out - of - domain gains beneﬁt from LS ( ex-   cept RoBERTa on MNLI ) . From these results , we   conclude that simply incorporating label uncer-   tainty ( through label smoothing ) is not an effective   regularization method since LS does not consis-   tently improve the model calibration ( especially   for the in - domain setting ) . While temperature   scaling ( TS ) corrects the miscalibration of vanilla   pre - trained language models ( see BERT / RoBERTa   No TS vs. TS in the table ) , it fails to cor-   rect miscalibrated pre - trained language models   with LS ( see BERT+LS / RoBERTa+LS No TS vs. TS ) in - domain . Interestingly , for some cases of   out - of - domain data , pre - trained language models   with LS show comparatively low ECEs while TS   further reduces ECEs ( e.g. , BERT(LS ) on Twit-   terPPDB / HellaSWAG , RoBERTa(LS ) on TwitterP-   PDB ) . However , its impact is not enough as it still   results in high ECE . This implies that TS is not   a notable strategy either to pre - trained language   models ’ calibration . Accordingly , we conclude   that stronger regularization techniques are required   to calibrate the pre - trained language models .   Second , we ﬁnd that mixup on the hidden fea-   ture space ( i.e. , M - Mixup ) generally yields lower   ECE than mixup on the input embedding space   ( i.e. , Mixup ) on most tasks . We infer that Mixup   generates augmented samples that are not “ good ”   for model calibration ( i.e. , semantically or syntacti-   cally ) and fails to encourage regularization effects   that arise from mixup . We observe that mixup   training with LS is beneﬁcial to reduce ECEs on   some tasks . We ﬁnd that TS leads to much lower   ECEs on Mixup and M - Mixup ( with and without   LS ) on most tasks . However , this implies that base-   line mixup methods fail to produce well - calibrated   models independently ( without LS or TS ) . This   supports our intuition and motivation for the design   of a more robust approach of mixup.5370   Third , we observe that our proposed mixup   yields the best calibrated models ( lowest ECEs )   both on in - domain and out - of - domain data ( ex-   cept on SWAG with RoBERTa ) . We observe that   often LS effectively operates along with our pro-   posed mixup and achieves the lowest ECEs on most   tasks on in - domain and out - of - domain settings . In   contrast to baseline mixup methods , our proposed   mixup performs well on in - domain and out - of-   domain even without applying post - calibration cor-   rection TS ( see ECE values of baselines compared   with our ECE values ) . We also observe that TS im-   proves the model calibration further on our mixup   training in most cases . Accordingly , we conﬁrm   the robustness of our AUM and saliency guided   mixup for pre - trained language models calibration .   Accuracy We explore the accuracy of mixup   training and show comparisons in Table 2 .   We make the following observations : 1 ) Both   BERT+LS / RoBERTa+LS generally lead to substan-   tial accuracy drops especially on in - domain com-   pared with BERT / RoBERTa ( i.e. , 4.49 % accuracy   drops on SWAG ) . This implies that label smooth-   ing ( LS ) fails to improve model generalization by   simply manipulating labels ( changing from hard   to soft labels ) . This potentially leads to a loss of   information that is correlated to model generaliza-   tion ( Müller et al . , 2019 ) . 2 ) Mixup and M - Mixupfail to achieve an accuracy that is as good as that   of vanilla pre - trained language models , potentially   due to an increased chance of manifold intrusion   resulting from conﬂicts between the synthetic sam-   ples of the mixup and original training data ( Guo   et al . , 2019b ) . 3 ) In contrast , our proposed mixup   method generally achieves competitive accuracy   regardless of applying LS or not . This evidence   supports the robustness of our proposed mixup .   Note that TS does not affect the model ’s accuracy   because it does not change the maximum of the   softmax function .   4.5 Ablation Study   Effect of AUM and Saliency We investigate the   effectiveness of each component ( i.e. , AUM and   saliency ) in our proposed mixup . As shown in   Table 3 , our proposed mixup without the AUM   ( i.e. , -AUM ) and without saliency ( i.e. , -Saliency )   generally increase the expected calibration errors .   In our method without using AUM , we randomly   divide training data into two categories and con-   duct mixup operation based on saliency map . In   our method without using saliency , we randomly   pick two samples from the opposite low and high   AUM set and conduct mixup operation . The results   demonstrate that both metrics ( AUM and saliency )   are required to improve model calibration.5371   Effect of selecting the most similar and dissimi-   lar samples We explore the effectiveness of se-   lecting the most similar and dissimilar samples ,   which are used for mixing purposes for in - domain   and out - of - domain calibration , respectively . Specif-   ically , in our proposed mixup , we synthesize addi-   tional samples that mimic in - domain data by select-   ing the most similar sample from the other category   ( e.g. , an easy - to - learn sample is mixed with a hard-   to - learn / ambiguous sample that is most similar to   the easy - to - learn sample , by saliency maps ) . This   is because the selected sample aligns the most with   the given sample . This intuitively results in better   model generalization due to the effect arising from   data augmentation ( i.e. , augmenting samples that   are particularly similar to in - domain data ) and al-   lows better in - domain calibration . Similarly , we   calibrate out - of - domain by augmenting a sample   that mimics out - of - domain distribution . This is be-   cause we select the sample that is the most different   from a given sample by selecting the most dissimi-   lar sample from the other category . To verify this   intuition , we conduct our proposed mixup when   excluding the most similar instance ( i.e. , -similar )   and the most dissimilar instance ( i.e. , -dissimilar ) ,   respectively .   Table 3 shows the results of this ablation . We   observe that our proposed mixup without using the   most dissimilar sample ( i.e. , -dissimilar ) results in   higher ECEs compared with our mixup that uses   dissimilar samples on all tasks in the out - of - domain   setting for both BERT and RoBERTa . Interest-   ingly , we observe that our proposed mixup withoutusing the most similar sample ( i.e. , -similar ) re-   sults in higher ECEs compared with our mixup that   uses the most similar samples on in - domain and   out - of - domain data for both BERT and RoBERTa .   These results support that selecting the most sim-   ilar / dissimilar samples effectively calibrates pre-   trained models for in - domain / out - of - domain data .   5 Conclusion   We proposed a novel mixup guided by the Area   Under the Margins ( AUM ) and saliency maps to   mitigate the miscalibration of pre - trained language   models BERT and RoBERTa . We showed that   our proposed mixup method achieves the lowest   Expected Calibration Errors ( ECEs ) for both pre-   trained language models on various types of natural   language understanding tasks , for both in - domain   and out - of - domain data . For future work , we will   enhance our proposed mixup further , focusing not   only on model calibration but also on performance   gains . Exploring different saliency maps for com-   puting sample similarity / disimilarity ( and its de-   gree ) is another interesting future direction .   Acknowledgements   This research is supported in part by NSF CAREER   award # 1802358 and NSF CRI award # 1823292 .   Any opinions , ﬁndings , and conclusions expressed   here are those of the authors and do not necessar-   ily reﬂect the views of NSF . We thank AWS for   computing resources . We also thank our anony-   mous reviewers for their constructive feedback and   comments , which helped improve our paper.5372References53735374