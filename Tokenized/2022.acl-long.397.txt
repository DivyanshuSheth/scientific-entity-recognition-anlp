  Fangchao Liu , Hongyu Lin , Xianpei Han , Boxi Cao , Le SunChinese Information Processing LaboratoryState Key Laboratory of Computer Science   Institute of Software , Chinese Academy of Sciences , Beijing , ChinaUniversity of Chinese Academy of Sciences , Beijing , ChinaBeijing Academy of Artificial Intelligence , Beijing , China   { fangchao2017,hongyu,xianpei,boxi2020,sunle}@iscas.ac.cn   Abstract   Low - shot relation extraction ( RE ) aims to rec-   ognize novel relations with very few or even no   samples , which is critical in real scenario ap-   plication . Few - shot and zero - shot RE are two   representative low - shot RE tasks , which seem   to be with similar target but require totally dif-   ferent underlying abilities . In this paper , we   propose Multi - Choice Matching Networks to   unify low - shot relation extraction . To fill in the   gap between zero - shot and few - shot RE , we   propose the triplet - paraphrase meta - training ,   which leverages triplet paraphrase to pre - train   zero - shot label matching ability and uses meta-   learning paradigm to learn few - shot instance   summarizing ability . Experimental results on   three different low - shot RE tasks show that the   proposed method outperforms strong baselines   by a large margin , and achieve the best perfor-   mance on few - shot RE leaderboard .   1 Introduction   Relation extraction ( RE ) aims to extract the re-   lation between two given entities in the context .   The most popular approaches to build RE mod-   els are based on supervised learning ( Zeng et al . ,   2014 ; Baldini Soares et al . , 2019 ) . Despite the su-   perior performance , supervised relation extraction   approaches severely suffer from the data bottleneck ,   which restricts their application to more relation   types in real scenarios .   Consequently , low - shot relation extraction has   become a recent research hotspot in RE area . There   are two mainstream learning paradigms widely ex-   plored in low - shot relation extraction , namely zero-   shot RE ( Levy et al . , 2017 ) and few - shot RE ( Han   et al . , 2018 ) . Few - shot relation extraction aims   to identify instances of novel relation type with   only a few illustrative instances , while zero - shot   RE is more progressive , which only uses externalFigure 1 : Difference between zero - shot RE and few-   shot RE . ( a ) Zero - shot requires for the ability of label   semantic matching , while ( b ) Few - shot requires for the   ability of support instance ( Sup . Ins . ) summarizing .   knowledge and the name or definition of the novel   relations to recognize them . Because low - shot RE   only requires very limited manually annotated data ,   it can effectively alleviate data bottlenecks in con-   ventional RE and therefore attached great attention .   However , even with similar goals , zero - shot RE   and few - shot RE actually require different funda-   mental abilities . Specifically , zero - shot RE is built   onlabel semantic matching ability , which requires   models to sufficiently exploit the label semantic of   given novel relations , and matches relations and   queries based on their underlying semantics . While   few - shot RE is built on instance semantic summa-   rizing ability , which requires a model to quickly   generalize to novel relations by summarizing crit-   ical information from few - shot instances . Due to   this fundamental difference , current state - of - the - art   architectures are separately learned to deal with   these two low - shot RE tasks . For zero - shot RE ,   the most popular solution is to transform it into a   textual entailment ( Obamuyide and Vlachos , 2018 ;   Sainz et al . , 2021 ) , word prediction ( Brown et al . ,   2020 ) or MRC problem ( Levy et al . , 2017 ; Bragg   et al . , 2021 ) and use external resources from these   tasks to pre - training the label semantic matching   ability . However , the divergence between relation   extraction and these tasks will inevitably under-   mine the performance . Besides , MRC and tex-5785tual entailment architecture can only deal with one   novel relation each time , which significantly in-   creases the computational and storage cost of de-   ploying such models in real - world scenarios . For   few - shot RE , current methods mainly focus on sum-   marizing better prototypes from a few illustrative   instances ( Snell et al . , 2017 ) , or learning a model   that can generalize to novel types within a few   steps ( Finn et al . , 2017 ) . These approaches require   few - shot examples to fine - tune or summarize pro-   totypes , and therefore can not be directly applied   to zero - shot RE . As a result , current relation extrac-   tion models can not be effectively and efficiently   to apply to all low - shot RE settings .   In this paper , we propose to unify low - shot rela-   tion extraction by returning to the essence of rela-   tion extraction . Fundamentally , relation extraction   can be viewed as a multiple choice task . Given two   entities in context , a RE system needs to match the   most appropriate relation – or others for none - of-   the - above – from a set of pre - defined relation types .   The information required to accomplish the multi-   choice matching can be summarized from either   the surface form of relation name or from few - shot   instances . Motivated by this , we propose Multi-   Choice Matching Network ( MCMN ) for unified   low - shot RE , which is shown in Figure 2 . Specif-   ically , MCMN converts all candidate relation de-   scriptions into a multi - choice prompt . Then the in-   put instance is concatenated with the multi - choice   prompt and passes through a pre - trained encoder   to obtain the semantic representations of the input   instance and candidate relations . Finally , MCMN   conduct relation extraction by directly matching   the relation representations and the instance repre-   sentation .   To equip MCMN with both label semantic   matching ability and instance semantic summariz-   ing ability , we propose to pre - train MCMN via   triplet - paraphrase meta pre - training , which con-   tains the following two critical components : 1 ) a   text - triple - text paraphrase module , which can gen-   erate large - scale pseudo relation extraction data   to pre - train the label semantic matching ability   of MCMN ; 2 ) a meta - learning style training al-   gorithm , which enriches MCMN with instance se-   mantic summarizing ability to quickly generalize   across different relation extraction tasks . Specifi-   cally , given large - scale raw texts , triplet - paraphrase   first extracts ( subject , predicate , object ) triplets via   OpenIE ( Cui et al . , 2018 ) toolkit . Then based onthe extracted triplets , paraphrases of the original   texts is generated using an RDF - to - Text genera-   tion model . In this way , we can obtain large - scale   pseudo annotations by collecting the generated sen-   tences and the predicate in the triples . Such cor-   pus can be used to effectively pre - train the label   semantic matching ability of MCMN by match-   ing the paraphrases to the corresponding predicate .   Furthermore , to enrich MCMN with the instance   semantic summarizing ability , such pre - training   is conducted in a meta - learning paradigm . That   is , MCMN is asked to learn different relation ex-   traction tasks at each iteration , so that the MCMN   can not over - fit the pre - training corpus by directly   memorizing specific target relations .   To evaluate our methods , we conduct experi-   ments on three fairly different RE tasks : zero - shot   RE , few - shot RE , and few - shot RE with none - of-   the - above relation . Experiments show that the pro-   posed method outperform previous methods on all   these three tasks . Our source code is available   athttps://github.com/fc-liu/MCMN .   The main contributions of this work are :   •We propose MCMN , a unified architecture   for low - shot relation extraction by fundamen-   tally formulating relation extract using a multi-   choice matching paradigm .   •We propose to pre - train MCMN with triplet-   paraphrase meta training , which enriches   MCMN with label semantic matching abil-   ity and instance semantic summarizing ability   for both zero - shot RE and few - shot RE .   •We comprehensively study the performance   of MCNN on three different relation extrac-   tion tasks , including zero - shot , few - shot , and   few - shot with none - of - the - above relation ex-   traction , where MCMN outperforms strong   baseline models .   2 Background   In this section , we formulate relation extraction   task and the low - shot RE settings including zero-   shot RE and few - shot learning RE .   Relation Extraction . Suppose the input text T=   [ t , t , ... , tn ] contains ntokens , e= [ i , j]and   e= [ k , l]indicate the entity pair spans , where 1≤   i≤j , j < k ≤landl≤n . A relation instance   is defined as x= ( T , e , e ) . For example , the5786   tuple ( “ Tim Cook is the CEO of Apple Inc. ” , “ Tim   Cook ” , “ Apple Inc. ” ) is a relation instance . The   aim of relation extraction is to learn a mapping   function : f : x→y , where yis the relation class .   For example , we want mapping ( “ Tim Cook is the   CEO of Apple Inc. ” , “ Tim Cook ” , “ Apple Inc. ” ) to   its relation class “ CEO_of ” . Traditional RE tasks   typically pre - define the class space Yand annotate   a large set of instances to train the model . However ,   in real scenarios , the targeting relation types vary in   different tasks , and most of the novel relations lack   annotations , rendering the supervised paradigms   inapplicable . In that regard , how to transfer models   to novel tasks becomes critical .   Low - shot Relation Extraction . Low - shot rela-   tion extraction requires models to recognize novel   relations with very few samples . There are two   mainstream low - shot RE tasks , including :   Zero - shot RE . This task aims to conduct relation   extraction without any annotated instance other   than some external knowledge z(or side informa-   tion ) , such as relation descriptions . Models are   supposed to transfer the knowledge and extract the   targeting relation yfor input instance xthrough   only the external knowledge .   Few - shot RE . This task aims to conduct relation   extraction with only a few annotated instances per   novel relations . Each few - shot RE task contains a   support set S = S , ... , SforNnovel relations .   And for relation i , S = S , ... , Scontains K   annotated instances . Models are supposed to learn   to transfer the knowledge and extract the targeting   relation yfor instance xthrough the N - way K-   shot support set .   3 Multi - Choice Matching Networks   In this section , we introduce our multi - choice   matching networks ( MCMN ) . Different from previ-   ous unifying models , MCMN adopts a much more   efficient and lightweight decoding module . Follow-   ing are the detailed descriptions.3.1 Multi - choice Prompt   Fundamentally , relation extraction can be viewed   as a multiple choice task . Inspired by recent ad-   vances of prompt learning ( Brown et al . , 2020 ;   Schick and Schütze , 2021 ) , we construct a multi-   choice prompt for each relation extraction task by   directly concatenate all relation names or descrip-   tions . Formally , the multi - choice prompts are in   the following form :   [ C ] rel 1 [ C ] rel 2 ... [ C ] rel N   where [ C ] is the placeholder separator for the fol-   lowing relation . For example in Figure 2 , the tar-   get RE task contains three novel relations : em-   ployee_of , ceo_of , and others , of which the relation   descriptions are then concatenated altogether to   form the multi - choice prompt “ [ C ] employee of   [ C ] ceo of [ C ] others ” . After obtaining the multi-   choice prompt , we then feed it accompanied with   the input sentence into the instance encoder , and   the representations at separator [ C ] is regarded as   the representation of its following relation .   3.2 Instance Encoder   Before instance encoding , we concatenate the   multi - choice prompt with each input instance into   a single sentence , and separate them with a [ SEP ]   token . Besides , we follow ( Baldini Soares et al . ,   2019 ) and wrap the given entity pair with [ e1 ] ,   [ /e1 ] , [ e2 ] and [ /e2 ] respectively . For the example   in Figure 2 , the entire input to encoder is : “ [ CLS ]   [ C ] employee of [ C ] ceo of [ C ] others [ SEP ] [ e1 ]   Tim Cook [ /e1 ] is the CEO of [ e2 ] Apple [ /e2 ]   . [ SEP ] ” . Then we encode the entire sentence x   through a Transformer ( Vaswani et al . , 2017 ) en-   coder :   h , h , ... , h = H(x ) , ( 1 )   where his the output embedding for each token   inx , d is the dimension of hidden states . These   token embeddings are then used for multi - choice   matching and model prediction.5787   3.3 Multi - choice Matching and Prediction   The multi - choice matching module matches the   input instance to the corresponding relation . For   each relation type , we use hidden states of [ C ]   marker to represent each following relation :   h = h , ( 2 )   where his the representation for relation iand   his the hidden state for the i[C ] token . For   the input text , we simply average hidden states of   [ e1 ] and[e2 ] to obtain the instance representation   X :   X = avg(h , h ) . ( 3 )   Then we perform matching operation between the   instance and each relation :   D(x , y ) = ∥X−h∥. ( 4 )   In this equation , we adopt the Euclidean distance   to measure the similarity , and the corresponding   probability for each relation is :   P(y|x;θ ) = exp(−D(x , y))Pexp(−D(x , y)).(5 )   Finally , we choose the relation ˆywith the maximal   probability as the prediction :   ˆy= arg maxP(y|x;θ ) . ( 6 )   3.4 Training Loss   We adopt an end - to - end training manner by mini-   mizing the following loss function :   L(θ ) = −XI(y ) logP(y|x;θ),(7)where I(.)equals 1 if yis the golden class , other-   wise I ( . ) = 0 . The three - period training process   will be detailed described in the following section .   4 Training Strategies for Multi - Choice   Matching Networks   As mentioned above , the required abilities for zero-   shot and few - shot are different . In this paper , we   propose triplet - paraphrase meta pre - training , which   jointly learn the label semantic matching ability re-   quired by zero - shot RE and instance summarizing   ability required by few - shot RE . Following is the   detailed description of the pre - training framework .   4.1 Triplet - Paraphrase Construction   To endow the label semantic matching ability to   MCMN , it is required to incorporate large - scale   data of both relational sentences and relation types   to pre - train the model . Unfortunately , the highly   limited relation types in existing RE datasets may   lead to overfitting on specific relations and impair   the generalization of MCMN . In this paper , we pro-   pose the triplet - paraphrase to generate large - scale   pre - training data for MCMN from raw texts . The   overall procedure of triplet - paraphrase module is   demonstrated in Figure 3(a ) , which extracts pred-   icates from large - scaled raw texts as the relation   descriptions . Then we utilize the extracted rela-   tional triplets to generate paraphrase sentences for   further multi - choice matching pre - training . The   elaboration is presented below .   Relational Triplet Extraction . Most complete   sentences contain at least one relational triplet,5788which includes the subject , predicate , and object .   The predicate in a sentence corresponds to prop-   erty or relation between the subject and object ,   which can be regarded as a concrete expression   of one relationship . Therefore , To extract large-   scaled triplets from open domain texts , we use   OpenIE modelto extract on article collections of   Wikipedia . Considering the example sentence : The   service traces its history to an online service known   as PlayNET . OpenIE model extracts all the possible   triplets : ( an online service , known as , PlayNET )   and ( The service , traces , its history ) . We collect   all extracted predicates from raw texts to represent   the corresponding relations , preventing the mod-   els from overfitting specific relation types . These   triplets are further used for paraphrase generation   and pre - training .   Paraphrase Generation . One drawback of   matching predicate as the relation is that the predi-   cate extracted by OpenIE is commonly a span from   current sentence , which may lead models to take   the shortcut by directly matching through words   co - occurrence . To eliminate this shortcut , we fol-   low several recent works ( Agarwal et al . , 2021 ; Liu   et al . , 2021 ) to generate paraphrase texts to match   the predicate . Specifically , for extracted triplets , we   first wrap them with special markers “ [ H ] , [ R ] , [ T ] ”   correspond to subject , predicate and object . Then   we input the wrapped triplet texts to generate the   paraphrase texts . In our implementation , we adopt   T5(Raffel et al . , 2020 ) as the generator , and pre-   train it on WebNLG dataset ( Gardent et al . , 2017 ) .   For example , we wrap ( an online service , known   as , PlayNET ) to “ [ H ] an online service [ R ] known   as [ T ] PlayNET ” then generate the paraphrase text   playnet is an online service . After generating the   paraphrase , we then match it to the corresponding   predicate for pre - training .   4.2 Triplet - Paraphrase Meta Pre - training   Each instance in the pre - training batch contains the   paraphrase text and the corresponding predicate   span . In addition , as shown in Figure 3(a ) , we   concatenate all predicates in the current mini - batch   as the multi - choice prompt and follow the training   loss in Equation 7 to pre - train MCMN , where I(y )   equals to 1 when yis the corresponding predicate ,   otherwise , I(y ) = 0 . · Algorithm 1 MCMN for Few - shot Prediction   Require : n : fine - tuning epochs in online period   Require : θ : meta - learned model parameters   Require : S : support set , x : query instance   Require : α : learning rateθ = θ # save original modelforepoch in range ( n)do # compute loss of the support set : L = EL(θ ) # update model parameters : θ←θ−α∇Lend fory = f(x ) # predict the query instanceθ = θ # restore the original modelreturn y   4.3 Online Task Adaptation   In online learning or testing period , we adopt dif-   ferent adaptation strategies for different low - shot   tasks . For zero - shot RE , we directly use the trained   MCMN to conduct the task . For few - shot RE , we   perform an online task meta - training on the support   set , as shown in Algorithm 1 . For each few - shot   task with support set Sand query instance x , we   first update the model with all support instances :   θ←θ−α∇EL(θ),(8 )   where αis the learning rate , L((θ))is the loss   defined in Equation 7 . To avoid overfitting , we use   an early - stop criterion controlled by an adaptation   epoch threshold that once the adaptation epoch is   over the threshold , we exit the online fine - tuning   and give the prediction for current query instance   x :   y = f(x ) . ( 9 )   Finally , we restore the model parameter θ = θ   and repeat the procedure to the next task .   5 Experiments   5.1 Datasets and Task Settings   We conduct experiments on three low - shot rela-   tion extraction tasks : zero - shot RE ( Bragg et al . ,   2021 ) , few - shot RE ( Bragg et al . , 2021 ) and the   more challenging few - shot RE with none - of - the-   above ( NOTA ) ( Gao et al . , 2019b ) . These tasks are   all conducted based on FewRel dataset ( Han et al . ,   2018 ) , which is constructed through distantly align-   ing WikiData triplets to Wikipedia articles . In total ,   FewRel dataset consists of 100 relation types and5789   700 instances per type . Standard FewRel settings   adopt a split of 64/16/20 fraction corresponding to   train / validation / test set , where the train and valida-   tion sets are publicly accessible while the test set   is not . Following are the detailed settings for each   evaluation task .   Zero- and Few - shot Relation Extraction Set-   tings . We follow the standard Flex benchmark   settings , which separate the train and validation   sets from FewRel into a train set of 65 relations ,   a validation set of 5 relations and a test set of 10   relations . The test tasks are sampled and processed   through the FLEX official toolkit .   Few - shot RE with NOTA Relation Settings . A   drawback of conventional few - shot RE tasks is that   they neglect the existence of other relations , that   is all query instances are assumed to express one   of the given relations in the support set . Gao et al .   ( 2019b ) point out this problem and add the “ none-   of - the - above ” ( NOTA ) relation to consider the sit-   uation where query instance does not express any   of the given relations . In our experiment , we fol-   low the default settings of FewRel benchmark and   evaluate our methods on 5 - way 1/5 - shot tasks with   a 15 % or 50 % NOTA rate .   5.2 Baseline and Evaluation Metrics   Baseline Methods . For zero - shot and few-   shot RE tasks , we compare our model with   UniFew ( Bragg et al . , 2021 ) , a unified few - shot   learning model based on T5 ( Raffel et al . , 2020 ) .   This model converts each few - shot classificationtask into a machine reading comprehension format   and predicts the results through generation . With a   pre - training period on large - scaled MRC data , this   model reaches strong performance on both zero-   and few - shot tasks . For few - shot RE with NOTA   relation task , we compare our model with Bert-   Pair ( Gao et al . , 2019b ) , an instance - pair matching   framework for few - shot RE tasks . This model com-   putes a similarity and a dissimilarity score simulta-   neously between query instance and each support   instance , then aggregates the similarity score for   each relation and dissimilarity score for NOTA re-   lation . And the results of CNN andBERT based   prototypical networks from Gao et al . ( 2019b ) are   also reported .   Evaluation Metrics . For zero - shot and few - shot   RE tasks , we follow FLEX benchmark and report   the accuracy , confidence interval and standard de-   viation correspondingly . All these results reported   are from the official Flex toolkits . For few - shot RE   with NOTA relation task , we follow FewRel 2.0   benchmark and report the corresponding accuracy   for four different settings .   5.3 Hyperparameters and Implementation   Details   In the triplet - paraphrase construction period , we ex-   tract relation triplets from articles in Wikipedia and   generate the counterpart paraphrase texts . Over-   all , we generate about one million triplet and   paraphrase text pairs . In triplet - paraphrase meta-   training periods , we use a learning rate of 5e-6 ,   weight decay of 1e-6 , dropout rate of 0.5 , and a   linear learning schedule with a 0.95 weight decay.5790In the online task meta - training period , we use   learning rate of 5e-6 , and the adaptation epoch of   1 or 2 for FewRel NOTA tasks , epochs of 45 for   FLEX tasks , while keep other hyperparameters the   same . We use RoBERTa - large ( Liu et al . , 2019 )   to initialize our model . Furthermore , to better en-   dow the low - shot capability to our model , we adopt   annotated FewRel data ( Han et al . , 2018 ) as an   additionally supervised meta - training procedure .   5.4 Overall Results   Table 1 shows the overall results on three different   RE tasks . From this table , we can see that :   •MCMN with triplet - paraphrase pre - training   outperforms previous methods in all three   RE tasks and achieve state - of - the - art perfor-   mance . Compared with the strong baseline meth-   ods , MCMN achieves remarkable performance   improvements . In zero - shot and few - shot RE   tasks , MCNN with triplet paraphrase pre - training   outperforms the baseline methods by at least   1.8 % in average . In few - shot RE with NOTA task ,   our method outperforms previous best method   by at least 4.99 % in average and achieve the best   performance in the leaderboard .   •Our triplet - paraphrase pre - training achieves   promising results on low - shot RE tasks . Com-   paring with other pre - training strategies such as   UniFew model pre - trained with large annotated   MRC datasets , triplet - paraphrase pre - training   achieves much better performance on zero - shot   RE tasks . Besides , triplet - paraphrase can further   enhance MCMN to achieves the new state - of - the-   art results on all three low - shot RE tasks with   supervised meta - training procedure , which are   detailed analyzed in the next section .   •MCMN performs more robust than previous   methods . In zero - shot and few - shot tasks , our   methods perform a lower standard deviation and   more shallow confidence interval than baseline   methods , which means the prediction of our   methods is more stable across different tasks .   5.5 Detailed Analysis   In this section , we conduct several experiments for   in - depth analysis of our methods .   Ablation Studies on Zero- and Few - shot RE   Tasks . To evaluate the effect of each part of our   methods on zero- and few - shot RE tasks , we con-   duct separate experiments on triplet - paraphrase   pre - training , MCMN and MCMN without triplet-   paraphrase pre - training on Flex test set . As   shown in Table 2 , we can see that the pure   triplet - paraphrase pre - training model outperforms   RoBERTa - large model with a remarkable mar-   gin as well as leverages the MCMN model with   an improvement of at least 1.9 % compared with   MCMN without triplet - paraphrase pre - training on   both zero - shot and few - shot settings . These results   demonstrate that triplet - paraphrase pre - training   method can significantly improve the generaliza-   tion and performance of our model , and the frame-   work of multi - choice matching network is quite   applicable in low - shot RE tasks . Besides , we no-   tice the performance of pure triplet - paraphrase pre-   training model is lower than MCMN without triplet-   paraphrase pre - training . To study this issue , we   analyze the triplet - paraphrase data , and find that   many of the generated texts still consist of words in   predicates , though the expression is quite different   from the original sentences . This may still lead   to the shortcut learning problem . On top of that ,   the expression of predicates is much different from   the relation name , and the negative predicates are   much easier to distinguish than the real test cases .   These issues altogether result in poor performance .   Fortunately , the triplet - paraphrase pre - training pe-   riod can properly initialize MCMN and leverage   the final performance .   Ablation Studies on Few - shot NOTA RE tasks .   We also conduct detailed analyses of our meth-   ods in few - shot NOTA RE tasks . As shown in Ta-   ble 3 , the pure triplet - paraphrase pre - trained model   can also boost the performance of roberta - large   initialized model and leverage the supervised meta-   trained MCMN by at least 0.9 % in average . Al-   though we do not consider the NOTA relation in the   triplet - paraphrase pre - training period , this period   can also contribute to the further supervised meta-   training period , which indicates that the matching-   pattern learned in triplet - paraphrase pre - training5791   period is generalized and robust to down - stream   tasks . Besides , we notice that in NA rate of 0.5   tasks , the pure triplet - paraphrase pre - trained model   suffers from serious performance drops . This may   be caused by the large proportion of negative in-   stances in test tasks . Fortunately , this issue can be   alleviated by the online adaptation period .   Zero - shot NOTA RE tasks . This experiment   studies the zero - shot performance of our methods   on FewRel NOTA tasks . From Table 3 , we sur-   prisingly found that our methods also outperform   previous state - of - the - art few - shot NOTA models   even in zero - shot conditions . This also indicates   that our methods are effective in low - shot RE tasks   and are robust enough across different settings .   Computing Efficiency of Multi - Choice Match-   ing Networks . This experiment compares the   computing efficiency of our method with MRC-   based method . Each model is tested on the Flex   test set , including both zero - shot and few - shot RE   tasks . Models in zero - shot setting only need infer-   ence while both models in few - shot setting require   fine - tuning on the support set which involves time-   consuming back - propagation operations . For fair   comparison , we use a single TITAN RTX GPU   for each model and keep other computing environ-   ments the same . As a result , UniFew takes 647   minutes ( more than 10 hours ) to finish the test pre-   diction , while our method takes about 80minutes   to obtain the results in Table 1 , which improves the   speed of roughly an order of magnitude . The main   reason for such an efficiency discrepancy is that   UniFew , as a generative model , involves an auto-   regressive decoder to generate the results , whereas   our method directly matches the relation and in-   stance representations to give the results .   6 Related Works   Relation Extraction . Recent success of super-   vised relation extraction methods ( Zeng et al . , 2014;Zhou et al . , 2016 ) heavily depends on large amount   of annotated data . However , the bottleneck on data   annotation severely limits the adaptation of these   supervised methods to real scenarios . Recent works   reply to this dilemma from the perspective of low-   shot learning , which mainly focuses on zero- and   few - shot RE tasks . In this work , we shed light   on three representative sub - fields tasks , including   zero - shot RE , few - shot RE and few - shot RE with   NOTA relation to evaluate our methods   Zero - shot Relation Extraction . Levy et al .   ( 2017 ) firstly introduce the zero - shot relation ex-   traction task and adjust the machine reading com-   prehension ( MRC)-based paradigm for it . Fol-   lowing this line , other MRC - based methods have   been proposed ( Cetoli , 2020 ; Bragg et al . , 2021 ) .   Another paradigm for zero - shot RE is matching-   based ( Socher et al . , 2013 ) , which falls into the   text - entailment - based methods ( Obamuyide and   Vlachos , 2018 ; Sainz et al . , 2021 ) , and the represen-   tation matching - based methods ( Chen and Li , 2021 ;   Dong et al . , 2021 ) . Text - entailment - based methods   concatenate the relation description with the input   sentence to assess whether they entail the same   semantic relationship ; Representation matching-   based methods separately encode the relation and   instance into the same semantic space but are not   capable of handling the NOTA relation .   Few - shot Relation Extraction . Han et al . ( 2018 )   firstly propose the few - shot relation extrac-   tion task and adopt several meta - learning meth-   ods ( Munkhdalai and Yu , 2017 ; Snell et al . , 2017 ;   Satorras and Estrach , 2018 ; Mishra et al . , 2018 )   for it . Recent works on few - shot RE mostly cen-   ters around the metric - based methods ( Vinyals   et al . , 2016 ) , such as prototype - based methods ( Bal-   dini Soares et al . , 2019 ; Ye and Ling , 2019 ;   Gao et al . , 2019a ) and meta learning - based meth-   ods ( Finn et al . , 2017 ) . Besides , Gao et al . ( 2019b )   extend the FewRel challenge with few - shot domain5792adaptation ( DA ) and none - of - the - above ( NOTA )   tasks , which are more challenging and closer to   real - world application .   Few - shot RE with NOTA . Although NOTA re-   lation is common in conventional supervised RE   tasks ( Zhang et al . , 2017 ) , it is quite different in   few - shot scenarios due to the label inconsistency   problem . As an example , consider an instance that   expresses relation r. In task A , relation r is not   included in the support set , and thus model learns   the semantic mapping between this instance and   the NOTA relation . But in another task B where   relation r is included in the support set , the model   learned from task A may continue to match this   instance to NOTA relation . Because of the diffi-   culty , attempts to resolve this problem are scarce .   To the best of our knowledge , Bert - Pair ( Gao et al . ,   2019b ) is the only public method for this task , and   our work is the first method to unify the zero - shot ,   few - shot and few - shot with NOTA tasks .   7 Conclusions   In this paper , we propose Multi - Choice Match-   ing Networks to unify low - shot relation extrac-   tion . MCMN introduces a multi - choice prompt   to formulate relation extraction as in a multi-   choice paradigm . To equip MCMN with different   zero - shot and few - shot abilities , we propose the   triplet - paraphrase meta pre - training , which lever-   ages triplet paraphrase to pre - train zero - shot label   matching ability and uses meta - learning paradigm   to learn few - shot instance summarizing ability . Ex-   perimental results on three different RE tasks show   MCMN outperforms strong baseline models by   large margins .   Acknowledgements   We thank all reviewers for their insightful sug-   gestions . Moreover , this research work is sup-   ported by the Strategic Priority Research Program   of Chinese Academy of Sciences under Grant No .   XDA27020200 , and the National Natural Science   Foundation of China under Grants no . 62106251   and 62076233 .   Ethics Consideration   This paper has no particular ethic consideration . References579357945795