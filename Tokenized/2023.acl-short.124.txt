  Afra AminiTianyu LiuRyan Cotterell   { afra.amini , tianyu.liu , ryan.cotterell } @inf.ethz.chAbstract   We introduce a novel dependency parser ,   the hexatagger , that constructs dependency   trees by tagging the words in a sentence with   elements from a finite set of possible tags . In   contrast to many approaches to dependency   parsing , our approach is fully parallelizable   at training time , i.e. , the structure - building   actions needed to build a dependency parse   can be predicted in parallel to each other .   Additionally , exact decoding is linear in time   and space complexity . Furthermore , we derive   a probabilistic dependency parser that predicts   hexatags using no more than a linear model   with features from a pretrained language   model , i.e. , we forsake a bespoke architecture   explicitly designed for the task . Despite the   generality and simplicity of our approach , we   achieve state - of - the - art performance of 96.4   LAS and 97.4 UAS on the Penn Treebank   test set . Additionally , our parser ’s linear   time complexity and parallelism significantly   improve computational efficiency , with a   roughly 10 - times speed - up over previous   state - of - the - art models during decoding.https://github.com/rycolab/   parsing - as - tagging   1 Introduction   The combination of parallel computing hardware   and highly parallelizable neural network archi-   tectures ( Vaswani et al . , 2017 ) has enabled the   pretraining of language models on increasingly   large amounts of data . In order to apply pretrained   language models to downstream NLP tasks , many   practitioners fine - tune the pretrained model while   the task - specific architecture is jointly trained from   scratch . Typically , the task - specific architecture   is built upon the hidden representations generated   by the final layer of a pretrained model . Exploiting   pretrained language models in this manner has   boosted the performance considerably on many   NLP tasks ( Devlin et al . , 2019 ; Clark et al . , 2020;Figure 1 : From bottom to top , the figure shows the   dependency tree , the hexatags , and the binary head tree   for the sentence “ She reads fascinating papers . ”   Aghajanyan et al . , 2021 ) . However , for the end - to-   end fine - tuning process to be fully parallelizable ,   it is also necessary to parallelize the training of the   task - specific architecture . Unfortunately , due to   the complexity of the output in many structured   prediction tasks in natural language , e.g. , in de-   pendency parsing , state - of - the - art models still use   architectures with limited parallelization during   training ( Mrini et al . , 2020 ; Yang and Tu , 2022 ) .   In an attempt to develop parsers parallelizable   during training , a recent line of work recasts   parsing as tagging ( Li et al . , 2018 ; Strzyz et al . ,   2019 ; Kitaev and Klein , 2020 ; Amini and Cotterell ,   2022 ) . Under this approach , a parse tree is   linearized into a sequence of tags . The benefit   of such a paradigm is that tagging can be done by   only adding a linear classifier on top of a pretrained   language model and the tags can , thus , be predicted   independently . This leads to a parser that is highly   parallelizable and whose training can be easily   harmonized with the ( parallelizable ) fine - tuning of   pretrained language models . During decoding , an   exact algorithm is used to recover a valid sequence1453of tags which is then converted back to a parse tree .   Kitaev and Klein ( 2020 ) were the first to pro-   pose a parsing - as - tagging scheme with a constant   tag space for constituency parsing and , additionally ,   the first to achieve results competitive with the state-   of - the - art non - parallelizable constituency parsers   using such a tagger . However , for dependency pars-   ing , all dependency parsing - as - tagging schemes in   the literature ( Li et al . , 2018 ; Strzyz et al . , 2019 ;   Vacareanu et al . , 2020 ) have infinite tag sets whose   cardinality grows with the length of the input se-   quence , which limits such parsers ’ efficiency and   generality ( Strzyz et al . , 2019 ) . Moreover , in some   cases , this growth hinders generalization to sen-   tences longer than the longest training sentence .   Furthermore , tagging - based dependency parsers   still do not perform competitively with the best-   performing parsers in the literature ( Li et al . , 2018 ) .   In this paper , we propose a novel way of framing   projective dependency parsing as a tagging task .   Our approach makes use of 6 distinct tags , motivat-   ing us to naming the scheme hexatagger . In our ex-   periments , hexatagger achieves state - of - the - art per-   formance on the English Penn Treebank ( PTB ; Mar-   cus et al . , 1993 ) test set . Notably , it outperforms   parsers with more computationally expensive train-   ing procedures and extra constituency annotations ,   e.g. , the parser developed by Mrini et al . ( 2020 ) .   Furthermore , hexatagger achieves results competi-   tive to Yang and Tu ’s ( 2022 ) parser on the Chinese   Penn Treebank ( CTB ; Xue et al . , 2005 ) test set   and 12 languages on the pseudo - projectivized data   from the Universal Dependencies ( UD2.2 ; Nivre   et al . , 2018 ) benchmark . In terms of efficiency , our   experiments suggest that hexatagger is 10 times   faster than previous top - performing parsers , and   consumes significantly less memory , despite using   an exact dynamic program for decoding .   2 Hexatagging   In this section , we introduce hexatagging , a tag-   ging scheme that consists of 6 unique tag types .   We further prove by construction that there exists   an injective mapping between valid sequences of   hexatags and dependency trees .   2.1 Binary Head Trees   Before going into the details on how to represent   dependency trees with a sequence of tags , we intro-   duce binary head trees ( BHTs ) , a simple formal-   ism that serves as a useful intermediary betweendependency trees and sequence of hexatags . Intu-   itively , a BHT is a special form of a constituency   tree where each internal node is either labeled   when the head of the derived constituent is in the   left subtree orwhen the head is in the right sub-   tree . See Fig . 1 for a visual depiction of a BHT . In   the next theorem , we formally state the relationship   between the set of dependency trees and BHTs .   Theorem 1 . There exists a bijectivefunction that   maps every projective dependency tree to a BHT .   In the following two paragraphs , we sketch a   construction that such a function exists , i.e. , we   describe how to map any dependency tree to a   BHT and then how to map back any BHT to a   dependency tree and back again .   Projective Dependency Trees to BHTs . To con-   vert a dependency tree to a BHT , we start from   the root and do a depth - first traversal of the depen-   dency tree . To avoid spurious ambiguity ( Eisner   and Satta , 1999 ) , we canonically order arcs of the   tree by processing the arcs left to right and inside   out . Algorithmically , converting a dependency   tree to a BHT proceeds as follows . When we first   visit a word , we push it onto a stack and proceed   with visiting its dependents . When there is no de-   pendent word left to visit , we create a new node   ( or ) and attach the top two elements in the   stack as the left and right child of this node . A step-   by - step demonstration of this algorithm is shown   in Fig . 2 and pseudocode is provided in Alg . 1 .   BHTs to Projective Dependency Trees . To con-   vert a BHT back to the dependency tree we fol-   low Alg . 2 . Algorithmically , we process BHT in a   depth - first fashion . Upon visitingornodes ,   we combine the top two elements in the stack by   creating a dependency arc between them . The di-   rection of the arc is determined by the label of the   node ( or ) . See Fig . 3 for an example .   Once the dependency tree is converted to a BHT ,   we can linearize it to a sequence of hexatags in   a straightforward manner . Theorem 2 states the   relationship between BHTs and hexatags formally .   Theorem 2 . There exists a total and injective   function that maps every BHT to a valid hexatag   sequence , i.e. , in other words , every BHT can be1454   mapped to a unique hexatag sequence . However ,   some hexatag sequences do notcorrespond to   BHTs , i.e. , the function is not surjective .   In the following subsections , we prove by con-   struction that such a function exists . Throughout   the rest of the paper , we refer to those haxatagging   sequences that docorrespond to BHTs as valid .   2.2 From BHT to Hexatags   To transform a given BHT to a sequence of hex-   atags , we enumerate the action sequence that a   left - corner shift – reduce parser would take when   parsing this BHT ( Johnson , 1998 ) . Left - corner   parsers have actions that align more closely with   the input sequence than top - down or bottom - up   shift – reduce actions and , thus , offer a better lin-   earization for tagging tasks ( Amini and Cotterell ,   2022 ) . A simple explanation of this linearization   process is given by Kitaev and Klein ( 2020 , § 3.1 ) .   Their algorithm involves an in - order traversal of   the tree . Upon visiting each node , we generate a tag   that includes the direction of the arc that attachesthe node to its parent , i.e. , whether that node is a   left or a right child of its parent , and the label of   the node . When traversing a BHT , this paradigm   results in 6 distinct tag types :   • : this terminal node is the right child of its   parent ;   • : this terminal node is the left child of its par-   ent ;   • ( ): this non - terminal node is the right child   of its parent and the head of the corresponding   constituent is on the right ( respectively , left ) sub-   tree ;   • ( ): this non - terminal node is the left child   of its parent and the head of the corresponding   constituent is on the right ( respectively , left ) sub-   tree .   For an input sequence w = w···w , this process   gives us a hexatag sequence of length 2N−1 .   Fig . 1 depicts tree - to - tags transformation through   an example .   Labeled Dependency Trees . When converting   alabeled dependency tree to a sequence of hex-   atags , the arc labels must be encoded in the tags .   Therefore , while reading a terminal node , we con-   catenate the label of the arc that connects the node   to its parent with the hexatag . In this case , the num-   ber of distinct tags would be O(|A| ) , where |A|is   the number of unique arc labels . For example , in   Fig . 1 the hexatag generated while processing she   is:⟨,nsubj⟩.   2.3 From Hexatags to Dependency Trees   To transform a sequence of hexatags back to a   dependency tree , we again go through a two - step   process . First , we again interpret hexatags as   actions in a left - corner shift – reduce transition   system to construct a BHT . The actions in such a   transition system are as follows :   • : shift the leaf node into the stack ;   • ( ): create a new node labeled(respec-   tively , ) , attach the top element in the stack   as its left child , and attach a dummy node as its   right child ( ∅in step 2 in Fig . 3 ) ;   • : pop the subtree on the top of the stack . Re-   place the dummy node in the subtree with the   terminal node . Push the subtree back to the stack ;   • ( ): create a new node labeled(respec-   tively , ) . Pop the top element of the stack ,   attach it as the new node ’s left child , and set a   dummy node as the node ’s right child . Pop an-   other subtree of the stack , identify the dummy1455node in the subtree and replace it with the newly   created subtree . Push the subtree back to the   stack ( step 6 in Fig . 2 ) ;   3 Probability Model   In this section , we explain how to predict hexatags   in parallel . Our tagging model predicts two   hexatags for each word in the input sequence   with the exception of that last word , for which   we only predict one tag . As discussed in § 2.1 ,   a hexatagger produces a sequence of 2N−1   tagst= [ t , t , . . . , t]for an input sequence   of length N , w = ww···w . Therefore , an   intuitive way to match the tag sequence with the   input sequence is to assign two tags to each word .   We denote a training corpus SofMtuples of input   sequences and tag sequences { ( w , t ) } .   To learn the scoring function over tags , we   follow the same independence assumption as in   ( Kitaev and Klein , 2020 ) , i.e. , the probability   of predicting each tag is independent of other   tags given the input sequence . This assumption   barely harms model performance ( see Amini andCotterell , 2022 , Table 3 ) , but significantly speeds   up the training process by enabling each tag to   be predicted in parallel , and complexity reduces   by a factor of O(N ) . The training objective is   to minimize the negative log - likelihood of the   gold - standard tag sequences , i.e.   L(θ ) = −/summationdisplaylogp(t|w ) ( 1a )   = −/summationdisplaylog / productdisplayp(t|w ) ( 1b )   = −/summationdisplay / parenleftbigg / summationdisplaylogp(t|w)(1c )   + /summationdisplaylogp(t|w)/parenrightbigg   where θrefers collectively to the parameters of   the two linear projections and the parameters of   the pretrained model . To obtain p(t|w)and   p(t|w ) , we apply two independent linear   projections on the contextualized representation   ofwgiven by a pretrained model and convert   that to a probability distribution using softmax .   4 Decoding   Our goal in this section is to develop an efficient   algorithm to find the highest - scoring hexatag se-   quence under the model developed in § 3 . As stated   in Theorem 2 , the transformation function between   BHTs and hexatag sequences is not surjective , i.e. ,   not all the tag sequences can be transformed back   into a BHT . Therefore , we need to find a valid   hexatag sequence with the maximum probability   under the model that canbe transformed back to   a BHT . Once such hexatag sequence is found , we   can follow the two - step algorithm described in § 2.3   to obtain the corresponding dependency tree .   To find the highest - scoring valid hexatag se-   quence , we follow the linear - time algorithm de-   veloped by Kitaev and Klein ( 2020 ) . For a hexatag   sequence to be valid , we should be able to interpret   it as actions in a left - corner shift – reduce transitions   system , described in § 2.3 . Concretely :   •The first action can only bebecause other   actions need at least one item in the stack ;   • The actions , can only be performed if   there is at least two items in the stack;1456   •After performing all the actions , the stack   should contain a single element .   The above shows that the validity of a hexatag   sequence only depends on the number of elements   in the stack at each point of the derivation .   5 Experiments   We conduct experiments on the English Penn   Treebank ( PTB ; Marcus et al . , 1993 ) , the Chinese   Penn Treebank ( CTB ; Xue et al . , 2005 ) , and the   Universal Dependencies 2.2 ( UD2.2 ; Nivre et al . ,   2018 ) . For UD2.2 , we adopt the pseudo - projective   transformation ( Nivre and Nilsson , 2005 ) to   convert non - projective trees into projective trees   following previous work ( Wang and Tu , 2020 ;   Yang and Tu , 2022 ) . We report dataset statistics   in App . E and hyperparameter settings in App . F.   Accuracy . We train the hexatagger model based   on XLNet ( Yang et al . , 2019 ) and report the results   on PTB and CTB in Table 2 . Furthermore , we eval-   uate hexatagger in a set of 12 topologically diverse   languages on UD corpus , where we use Multilin-   gual BERT ( Devlin et al . , 2019 ) as the underlying   model ( see Table 1 ) . In PTB , we observe that hex-   atagger achieves state - of - the - art results , compared   to models with custom architectures and even in   some cases with extra annotation . In CTB and UD ,   hexatagger follows the best performance closely .   Efficiency . We compare the efficiency of hexatag-   ger with biaffine modules , which are the backbone   of many neural graph - based parsers ( Kiperwasser   and Goldberg , 2016 ; Dozat and Manning , 2017 ;   Mrini et al . , 2020 ; Yang and Tu , 2022 ) . As de-   picted in Table 3 , we observe that our hexatagger   is an order of magnitude faster and consumes less   memory . Further analysis is included in App . C.   6 Conclusion   In summary , hexatagging , our novel scheme , offers   a parallelizable and efficiently decodable backbone   for dependency parsing . Without relying on custom   architecture for dependency parsing , the hexatag-   ger achieves state - of - the - art accuracy on several   datasets using no more than a pretrained language   model and linear classifiers.1457Limitations   Non - projectivity . The primary theoretical lim-   itation of hexatagger is that it can only produce   projective dependency trees . We would like to ex-   plore the possibility of extending hexatagger to   non - projective parsing for future work .   Interpretibility . As a trade - off for efficiency ,   hexatagger does not model dependency arcs   directly . Compared to graph - based models that   explicitly score arc scores between pairs of words ,   it is more difficult to interpret the output of   hexatagger .   Ethics Statement   We do not believe the work presented here further   amplifies biases already present in the datasets .   Therefore , we foresee no ethical concerns in this   work .   Acknowledgments   We would like to thank Tim Vieira for his invalu-   able feedback throughout the process of this paper .   Afra Amini is supported by ETH AI Center doc-   toral fellowship .   References145814591460A Algorithms   Algorithm 1 Create a BHT from a dependency   tree .   Algorithm 2 Create a dependency tree from a BHT .   B Related Work   Traditionally , approaches to dependency parsing   have been taxonomized into graph - based and   transition - based parsers . The authors of this pa-   per take the stance that this distinction is mislead-   ing because the difference lies not in the models   themselves , but rather in whether exact or approx-   imate inference algorithms are employed . For   instance , Kuhlmann et al . ( 2011 ) gives exact al-   gorithms for transition - based dependency parsers ,   which exposes the inability to formally distinguish   graph - based and transition - based parsers . Thus , we   classify our related work into sections : exact and   approximate decoding . Further , we review works   on tagging - based parsing which is the most relevant   line of work to this paper .   Exact Decoding . Most exact algorithms for pro-   jective dependency parsing models apply a modi-   fied form of the CKY algorithm on nested depen-   dency trees . The best runtime among the com-   monly deployed algorithms O / parenleftbig   N / parenrightbig   ( Eisner , 1996 ) ,   but algorithms based on fast matrix multiplication   exist and can achieve a lower runtime bound ( Co-   hen and Gildea , 2016 ) . However , exact decodingofnon - projective parsers is intractable unless un-   der independence assumptions , e.g. , edge factored   assumption ( McDonald and Satta , 2007 ) . Edge-   factored parsers ( McDonald et al . , 2005 ; Dozat   et al . , 2017 ) construct graphs by scoring all possi-   ble arcs between each pair of words . They then use   the maximum spanning tree ( MST ) finding algo-   rithms for decoding to build the valid dependency   trees with maximum score in O / parenleftbig   N / parenrightbig   ( Zmigrod   et al . , 2020 ) . The discussed algorithms are exact in   inferring the dependency structure , however , they   are neither fast nor parallelizable .   Approximate Decoding . Despite not being ex-   act , transition - based parsers offer faster and typ-   ically linear - time parsing algorithms ( Kudo and   Matsumoto , 2002 ; Yamada and Matsumoto , 2003 ;   Nivre , 2003 ) . The dependency tree is inferred with   a greedy search through transition system actions .   Following this approach , actions are not predicted   in parallel and the configuration of the transition   system ( stack and buffer ) needs to be modeled with   a neural network ( Chen and Manning , 2014 ) , which   prevents using pretrained models out of the box .   Tagging - based parsing . Inspired by Bangalore   and Joshi ’s ( 1999 ) seminal work supertagging , a   recent line of work aims to utilize pretrained mod-   els and parse dependency trees by inferring tags for   each word in the input sequence . Li et al . ( 2018 ) ;   Kiperwasser and Ballesteros ( 2018 ) predict the rel-   ative position of the dependent with respect to its   parent as the tag . They then use beam tree con-   straints ( Lee et al . , 2016 ) to infer valid dependency   trees . Strzyz et al . ( 2019 ) provides a framework   for analyzing similar tagging schemes . Although   these works have demonstrated potential in this   area , none achieved state - of - the - art results com-   pared to custom architectures and algorithms de-   veloped for dependency parsing . Additionally , the   output space , or size of the tag set , is unrestricted ,   which limits the efficiency of this approach .   C Analysis   L- vs. R - .We examine the   effect of the two orders of binarization of Alg . 1 in   Table 4 . In our experiments , the choice of left - first   or right - first order has little to no effect on parsing   performance.1461   D Efficiency Evaluation   For efficiency comparison , we use BERT - large as   the base feature encoder for both Hexatagger and   Biaffine . We use the English PTB test set and   truncate or pad the input sentences to the control   length . The results are averaged over 3 random runs   on the same server with one Nvidia A100 - 80 GB   GPU . The other experimental settings are kept the   same ( i.e. , the version of PyTorch and Transformer ,   FP32 precision , batching ) .   E Datasets   Preprocessing . Following previous work ( Kiper-   wasser and Goldberg , 2016 ; Dozat and Manning ,   2017 ) , the dependency annotations are derived   by the Stanford Dependency converter v3.3.0   ( de Marneffe and Manning , 2008 ) from the tree-   bank annotations . Punctuation is omitted for evalu-   ation . Gold part - of - speech tags are provided to the   model both during training and evaluation follow-   ing the code released by Mrini et al . ( 2020 ) .   Some other authors use system - predicted part-   of - speech tags ( Zhou and Zhao , 2019 ) or use mixed   configurations . E.g. , Yang and Tu ( 2022 ) uses   gold part - of - speech tags on CTB and UD , while   not using any on PTB , Dozat and Manning ( 2017 )   uses gold part - of - speech tags on CTB but system-   predicted ones on PTB . Our preliminary experi-   ments show that removing the usage of part - of-   speech information barely affects the UAS metric ,   and gives us a performance of 97.4 UAS and 95.8   LAS on PTB .   Splits . All the datasets splits are consistent with   previous work . For PTB , we follow the standard   split of Marcus et al . ( 1993 ) , resulting in 39,832   sentences for training , 1,700 for development , and   2,416 for testing . For CTB , we follow the split of   Zhang and Clark ( 2008 ) , resulting in 16,091 sen-   tences for training , 803 for development , and 1,910   for testing . For UD2.2 , we follow Yang and Tu   ( 2022 ) and use the standard splits of the followingcorpora for experiments : BG - btb , CA - ancora , CS-   pdt , DE - gsd , EN - ewt , ES - ancora , FR - gsd , IT - isdt ,   NL - alpino , NO - rrt , RO - rrt , RU - syntagrus .   Licenses . The PTB and CTB datasets are li-   censed under LDC User Agreement . The UD2.2   dataset is licensed under the Universal Dependen-   cies License Agreement .   F Hyperparameter Settings   We use the Python NLTK package to process the   datasets , i.e. , converting CoNLL - U formatted data   to dependency trees , extracting dependency arcs   from dependency trees for evaluation , implement-   ing Alg . 1 and 2 . For UD , we apply MaltParser   v1.9.2to pseudo - projectivize the non - projective   trees ( Nivre and Nilsson , 2005 ) .   We use xlnet - large - casedfor English PTB ,   chinese - xlnet - midfor CTB , and bert - multilingual-   casedfor UD .   The dimension of POS tag embedding is set to   256 for all experiments . On top of concatenated   pretrained representations and POS embedding , we   use a 3 - layer BiLSTM with a hidden size of 768 for   base - sized models ( bert - multilingual - cased on UD )   and 1024 for large - sized models ( xlnet - large - cased   on PTB and chinese - xlnet - mid on CTB ) .   Dropout layers with a rate of 0.33 are applied   after the concatenated embedding layer , between   LSTM layers , and before the MLP projection layer   to hexatags .   For training , we used AdamW with a learning   rate of 2e−5for pretrained LMs and 1e−4for POS   embedding , BiLSTM , and MLP . The gradient clip-   ping threshold is set to 1.0 . The batch size is set to   32.1462ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Limitations   /squareA2 . Did you discuss any potential risks of your work ?   Ethics Statement   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract and Sec . 1   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   5 , App . D   /squareB1 . Did you cite the creators of artifacts you used ?   5   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   App D   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   App D   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Not applicable . Left blank .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   App D   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   App D   C / squareDid you run computational experiments ?   5   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   App . E1463 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   App . E   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   5   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   App . F   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   No response .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   No response .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   No response .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   No response .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   No response.1464