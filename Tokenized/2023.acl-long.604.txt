  Meiqi Chen , Yixin Cao , Yan Zhang , Zhiwei Liu , Peking UniversitySingapore Management UniversityMeituan   meiqichen@stu.pku.edu.cn   Abstract   Document - level Event Causality Identification   ( DECI ) aims to recognize causal relations be-   tween events within a document . Recent stud-   ies focus on building a document - level graph   for cross - sentence reasoning , but ignore im-   portant causal structures — there are one or   two “ central " events that prevail throughout the   document , with most other events serving as   either their cause or consequence . In this pa-   per , we manually annotate central events for a   systematical investigation and propose a novel   DECI model , CHEER , which performs high-   order reasoning while considering event cen-   trality . First , we summarize a general GNN-   based DECI model and provide a unified view   for better understanding . Second , we design an   Event Interaction Graph ( EIG ) involving the in-   teractions among events ( e.g. , coreference ) and   event pairs , e.g. , causal transitivity , cause(A , B )   ∧cause(B , C ) ⇒cause(A , C ) . Finally , we incor-   porate event centrality information into the EIG   reasoning network via well - designed features   and multi - task learning . We have conducted ex-   tensive experiments on two benchmark datasets .   The results present great improvements ( 5.9 %   F1 gains on average ) and demonstrate the ef-   fectiveness of each main component .   1 Introduction   Event Causality Identification ( ECI ) aims at identi-   fying causal relations between events within texts .   It is a fundamental NLP task and beneficial to vari-   ous applications , such as question answering ( Shi   et al . , 2021 ; Sui et al . , 2022 ) and future event fore-   casting ( Hashimoto , 2019 ; Bai et al . , 2021 ) . In   terms of the text length , events may occur within   the same sentence ( SECI ) or span across the en-   tire document ( DECI ) . DECI is more practical than   SECI but suffers from the lack of clear causal indi-   cators , e.g. , causal words because .   Recent DECI works often build a document-   level graph for cross - sentence reasoning , but ignore   important causal structures . Tran Phu and NguyenFigure 1 : An example of DECI . Solid green lines denote   target causal relations and dashed yellow lines denote   coreference . FIRE is the central event in this document .   ( 2021 ) take events as nodes and extract linguis-   tic / discourse relations as edges . Then , they apply   Graph Neural Network ( GNN ) to enhance even-   t / node embeddings with their neighbors for final   causality prediction . To avoid noisy and exhaustive   relation extraction , ERGO ( Chen et al . , 2022 ) in-   stead takes each event pair as nodes and leverages   GNN on the relational graph for high - order causal   transitivity , e.g. , cause(A , B ) ∧cause(B , C ) ⇒   cause(A , C ) . However , some useful prior event rela-   tions such as coreference are discarded . Moreover ,   we observe a causal information loss from docu-   ment to graph . Not all events are equally important .   There are one or two “ central " events that prevail   throughout the document , and other events are ei-   ther to explain their cause or the consequence ( Gao   et al . , 2019 ) . As shown in Figure 1 , event FIRE is   the central event . It is mentioned several times ( i.e. ,   coreferences blaze andfire ) , causing almost all the   other events ( e.g. , collapsed andrepairs ) .   In this paper , we propose to consider the above   causal structures while leveraging the reasoning   power of GNN . To do so , we highlight the follow-   ing questions :   •How to identify central events ? Are they rec-   ognizable?10804•How to effectively consider such causal struc-   tures for cross - sentence reasoning ?   To address the issues , we manually annotate   central events in the public dataset EventStory-   Line ( Caselli and V ossen , 2017 ) and propose a   novel DECI model , Centrality - aware High - order   EvEntReasoning network ( CHEER ) . We first   summarize a general GNN - based DECI model for   better understanding . Then , we design an Event   Interaction Graph ( EIG ) that involves interactions   between events and among event pairs ( i.e. , high-   order relations ) . Finally , we incorporate event cen-   trality information into the EIG reasoning network   via well - designed features and multi - task learning .   In specific , for the first challenge , we preserve   centrality information into event embeddings using   two measures : ( i ) position centrality to maintaining   the order of sentences where events are located , and   ( ii ) degree centrality that counts the number of prior   relations of each event . The motivation is that a cen-   tral event usually summarizes the main content at   the beginning and almost all the other events are rel-   evant to it . Then , we use the centrality - aware event   embeddings for central event prediction . Evalu-   ated on our central event annotations , we found   that this centrality modeling method is feasible and   effective , with potential for further improvement .   For the second challenge , based on the general   GNN - based DECI model , our proposed EIG uni-   fies both event and event - pair graphs , so that we   can reason over not only available causal structures   but also high - order event relations . Particularly ,   there are three types of edges . First , two event pair   nodes shall be connected if they share a common   event , so that their relational information can be   fused for transitivity . Second , we connect event   nodes to their corresponding event pair nodes to en-   hance event embeddings with high - order reasoning .   Moreover , the edge types will be further distin-   guished according to whether the event node is a   central event or not . Third , EIG is also scalable to   prior event relations ( e.g. , coreference ) that connect   event nodes if available .   Our contributions can be summarized as follows :   •We propose to consider causal structures ( i.e. ,   event centrality and coreference ) and manu-   ally annotate central events for investigation .   •We design an EIG and propose a novel DECI   framework CHEER for effective reasoning at   the document level.•Extensive experiments on two benchmark   datasets validate the effectiveness of CHEER   ( 5.9 % F1 gains on average ) .   2 Related Work   2.1 Sentence - level ECI   Early feature - based methods explore different re-   sources for causal expressions , such as lexical and   syntactic patterns ( Riaz and Girju , 2013 , 2014b , a ) ,   causality cues or markers ( Do et al . , 2011 ; Hidey   and McKeown , 2016 ) , temporal patterns ( Ning   et al . , 2018 ) , statistical information ( Hashimoto   et al . , 2014 ; Hu et al . , 2017 ) , and weakly super-   vised data ( Hashimoto , 2019 ; Zuo et al . , 2021b ) .   Recently , some methods have leveraged Pre - trained   Language Models ( PLMs ) for the ECI task and   have achieved promising performance ( Kadowaki   et al . , 2019 ; Liu et al . , 2020 ; Zuo et al . , 2020 ) .   To deal with implicit causal relations , Cao et al .   ( 2021 ) incorporate external knowledge from Con-   ceptNet ( Speer et al . , 2017 ) , and Zuo et al . ( 2021a )   learn context - specific causal patterns from external   causal statements .   2.2 Document - level ECI   Following the success of sentence - level natural lan-   guage understanding , many tasks are extended to   the entire document , such as relation extraction   ( Yao et al . , 2019 ) , natural language inference ( Yin   et al . , 2021 ) , and event argument extraction ( Ma   et al . , 2022 ) . DECI poses new challenges to cross-   sentence reasoning and the lack of clear causal   indicators . Gao et al . ( 2019 ) propose a feature-   based method that uses Integer Linear Program-   ming ( ILP ) to model the global causal structures .   DSGCN ( Zhao et al . , 2021 ) uses a graph inference   mechanism to capture interaction among events .   RichGCN ( Tran Phu and Nguyen , 2021 ) constructs   an even graph and uses GCN ( Kipf and Welling ,   2017 ) to capture relevant connections . However ,   noise may be introduced in the construction of   edges and the interdependency among event pairs   is neglected . ERGO ( Chen et al . , 2022 ) builds a re-   lational graph and model interaction between event   pairs . Although intuitive , some meaningful event   relations such as coreference are ignored . Com-   pared with them , CHEER could capture high - order   interactions among event pairs automatically while   being compatible with prior event relations . More-   over , we consider the centrality of events to conduct   global reasoning.10805   3 Methodology   Given document Dand all its events , DECI is to   predict whether there is a causal relation between   any two event mentions eandeinD. As shown in   Figure 2 , our proposed CHEER includes four main   components : ( 1 ) Document Encoder to encode   the document and output contextualized represen-   tations of events ; ( 2 ) Event Interaction Graph   that builds a graph including event nodes and event   pair nodes for document - level reasoning . ( 3 ) Event   Centrality Incorporation that incorporates event   centrality information through two aspects . ( 4 )   EIG Reasoning Network that improves the qual-   ity of event and event pair representations by con-   ducting inference over EIG , and then combines two   types of node embeddings for final classification .   3.1 Document Encoder   Given document D= [ x]where Dcan be of   any length L , the document encoder aims to out-   put the contextualized document and event repre-   sentations . Almost arbitrary PLMs can serve as   the encoder . In this paper , we leverage pre - trained   BERT ( Devlin et al . , 2019 ) as a base encoder to   obtain the contextualized embeddings . Following   conventions ( Chen et al . , 2022 ) , we add special   tokens at the start and end of D(i.e . , “ [ CLS ] ”   and “ [ SEP ] ” ) , and insert additional special tokens   “ < t > ” and “ < /t > ” ’ at the start and end of all the   events to mark the event positions . Then , we have :   where h∈Ris the output embedding of token x.   Then , we use the embedding of the token “ [ CLS ] ”   for document representation and the embedding of   the token “ < t > ” for event representation . Considering BERT ’s original limits that it can not   handle documents longer than 512 , we leverage a   dynamic window mechanism to deal with it . Specif-   ically , we divide Dinto several overlapping spans   according to a specific step size and input them into   BERT separately . For the same event occurring in   different spans , we calculate the average of all the   embeddings of the corresponding token “ < t > ” to   obtain the final event representation hfor event i.   3.2 Event Interaction Graph   Our EIG could not only performs high - order in-   ference among event pairs but also be compatible   with prior event relations . Specifically , given all   the events of document D , we formulate EIG as :   G={V , E } , where Vis the set of nodes , Eis the   set of edges . There are two types of nodes in V :   the nodes for a single event Vand the nodes to   represent a pair of events V. Each node in Vis   constructed by combining any two events of D.   For global inference , we introduce three main   types of edges in E : ( 1 ) ( Event pair ) - ( event pair )   edgesEfor two event pairs that share at least one   event , e.g. , the green line of ( FIRE , collapsed ) -   ( collapsed , repairs ) in Figure 2 , which is motivated   by the causal transitivity described in Introduction ;   and ( 2 ) Event - ( event pair ) edges Efor an event   pair and its corresponding two events , e.g. , the pink   line of FIRE -(FIRE , collapsed ) in Figure 2 . ( 3 )   Event - event edges Efor prior event relations ob-   tained by external knowledge or tools ( this type   of edge is optional ) . Take coreference edges as an   example ( the yellow line of FIRE -firein Figure 2 ) ,   they are helpful for causal reasoning , since there is   no causal relation between coreference events them-   selves . Moreover , coreference events shall have the10806same causal relations between other events , which   is so - called coreference consistency . Therefore ,   both coreference consistency and causal transitivity   can be regarded as a kind of high - order reasoning .   3.3 Event Centrality Incorporation   Considering the centrality of events is based on   the motivation that the central event should play   a more important role in global inference . In this   section , we introduce two aspects for incorporat-   ing event centrality information into our model .   First , we propose centrality - aware event embed-   dings , which could be used to predict whether an   event is a central event . Obtained the contextual-   ized event embeddings houtput by the document   encoder , we perform the following two different   centrality encoding modules :   Position Centrality Encoding which assigns   each event an embedding vector c∈Rac-   cording to which sentence the event locates in the   document . We initialize the vector randomly for   each position . The motivation is central events of-   ten appear in the front of the document to summa-   rize the core gist . For example , in Figure 2 , the first   sentence of the document outlines the main context   of story and contains the central event FIRE .   Degree Centrality Encoding which assigns each   event an embedding vector c∈Raccording   to the degree of its corresponding event node in   EIG . We initialize the vector randomly for each   degree . Intuitively , central events are throughout   the document with many repeated mentions . Thus ,   central events will have a greater degree . For exam-   ple in Figure 2 , the degree of central event FIRE is   greater than that of event collapsed , due to it has   two coreference events blaze andfire .   As the centrality encoding is applied to each   event , we directly add it to the event contextualized   embeddings . Formally , for an event eand its corre-   sponding embedding h , the final centrality - aware   event embeddings is obtained by :   c = h+c+c , ( 2 )   where c , care obtained by the position and   degree centrality encoding of e , respectively .   Central Events Prediction and EIG Enhance-   ment Once obtained the centrality - aware event   embeddings , we use them to predict whether an   event is a central event : p = f(cW ) , where   fdenotes the sigmoid function , W∈Risthe parameter weight matrix . if pis greater than   0.5 , we will regard eas a central event . Then , we   increase the type of edges in E : we further divide   the event - ( event pair ) edges into central event -   ( event pair ) edges Eandnormal event - ( event   pair ) edges E , and so does the event - event edges .   In this way , the interaction of central events on EIG   could have more of a special influence .   Central Events Annotation We manually anno-   tate central events on the public dataset EventSto-   ryLine to investigate the effect of centrality . In   specific , we annotate central events considering the   following rules : ( 1 ) the central events should be the   focus of the story ; ( 2 ) almost all other events de-   scribed in the document should be related to it ; ( 3 )   the coreference of central events will be regarded   as central events , too ; ( 4 ) on the premise of express-   ing the main content of the document correctly and   completely , the number of central events should be   as small as possible . According to the rules , we   have three annotators to complete the task . Each   document was annotated by two junior annotators   independently . If the answers of the two annota-   tors were inconsistent , a senior annotator checked   the answers and made the final decision . The aver-   age inter - annotator agreement is 86.4 % ( Cohen ’s   kappa ) . For 258 documents of EventstoryLine , we   get 352 central events , of which 166 documents   have one central event , 90 documents have two   central events , and only 2 documents have three   central events ( these documents have more than   30 sentences and introduce several independent   events ) . Then , we use the labels to train the model   to predict central events :   L=−/summationdisplaylog(p ) . ( 3 )   More analysis can be seen in Section 4.5 .   3.4 EIG Reasoning Network   In this section , we first describe a general GNN-   based DECI model , then instantiate our implemen-   tation by considering causal structures . Finally , we   provide a unified view for better understanding and   discussing existing models .   A General GNN - based DECI Model To predict   whether there is a causal relation between events   eande , we concatenate “ [ CLS ] ” embeddings   of the document , the event features z , z , event   pair features z , and define the probability of being10807causal relation as follows :   p = f([h||z||z||z]W ) , ( 4 )   where fdenotes the softmax function , ∥denotes   concatenation , Wis the parameter weight ma-   trix . Event - related features are typically initial-   ized with contextualized embeddings via PLM in   Section 3.1 and enhanced through L - layer GNN   reasoning . The l - th layer takes a set of node em-   beddings Z∈Ras input , and outputs a   new set of node embeddings Z∈R ,   where N=|V|+|V|is the number of nodes , d   anddare the dimensions of input and output   embeddings , respectively . Formally , the output of   thel - th layer for node vcan be written as :   z = σ   /summationdisplayg / parenleftig   z , z / parenrightig    , ( 5 )   where σdenotes non - linearity , Ndenotes the set   that contains all the first - order neighbors of v , gde-   notes how to aggregate neighborhood information .   By stacking multiple layers L , multi - hop reasoning   could be reached .   EIG Reasoning Network Instantiation   Event & Event - pair Features For an event node   e , we directly take the centrality - aware event em-   beddings for its initialization :   z = cW , v∈ V , ( 6 )   where 0denotes the initial state for the following   neural layers , W∈Ris a parameter weight   matrix to make event nodes be the same size as the   following event pair nodes for efficient computing .   As for an event pair node ( e , e)→v , we   concatenate their corresponding two contextualized   event embeddings as the event pair node features :   z= [ h∥h ] , v∈ V , ( 7 )   EIG Reasoning It is intuitive that different types   of edges represent various semantics contributing   differently to the causality prediction . To handle   this heterogeneity issue , EIG Reasoning Network   incorporates the edge features with a self - attention   mechanism during aggregation . Specifically , let   Tdenote the number of edge types in EIG . We   incorporate the edge features and learn a scalar   γ(1≤t≤T)for each different type of edge to   measure their importance :   γ = rW , ( 8)where r∈Ris the edge feature specified by   the edge type t , W∈Ris parameter vector   according to t. In this way , we could adaptively ad-   just the interaction strength between two adjacent   nodes by weighing different types of connections   withγ.γwill be automatically learned .   Figure 2 illustrates an example of the entire pro-   cess of CHEER ( here we take a sub - graph of EIG   for brevity ) . Different colors of edges indicate dif-   ferent connection types in EIG . Edges with the   same color ( i.e. , the same edge type ) will use the   same γ . Each layer has its own set of γ . Then   we could instantiate the aggregation function gas :   g / parenleftig   z , z / parenrightig   = f(γ+α)(zW),(9 )   where fdenotes the softmax function , W∈   Ris the parametwer weight matrix . α   is computed by a shared self - attention mecha-   nism ( Vaswani et al . , 2017 ) to measure the im-   portance of neighbor jtoi , where W , W∈   Rare parameter weight matrices :   α=(zW)(zW )   √d . ( 10 )   As shown in Figure 2 , the above process can be   organized as a matrix multiplication to compute   representations for all the nodes simultaneously   through a weighted adjacency matrix . Denote A   as the ( i , j)-element of the binary adjacency matrix   A , Ais 1 if there is an edge between nodes vand   vor 0 otherwise . We could compute each entry of   the edge - aware adjacency matrix as follows , where   δ = f(γ+α)is the normalized weight :   A = δA , ( 11 )   Figure 2 shows that the corresponding neighbor   node features are aggregated with different weights   according to δto obtain the representation of the   target node . Finally , the node representations of   layer lcan be obtained by :   Z = σ / parenleftig   AZW / parenrightig   . ( 12 )   3.5 Training   Following ERGO ( Chen et al . , 2022 ) , we adopt the   focal loss ( Lin et al . , 2017 ) to alleviate the false-   negative issue ( i.e. , the number of negative samples   during training far exceeds that of positives ) . We   adopt the β - balanced variant of focal loss , which10808introduces a weighting factor βin[0,1]for the   class “ positive ” and 1−βfor the class “ negative ” .   The loss function Lcan be written as :   L=−/summationdisplayβ(1−p)log(p),(13 )   where τis the focusing hyper - parameter , βis a   weighting hyper - parameter and its value is related   to the ratio of positive and negative samples .   Besides , we find that predicting causal and coref-   erence relations jointly brings benefits . A support   point for this is that these two types of relations are   mutually exclusive . Thus , we leverage the coref-   erence information and perform a ternary classi-   fication training , i.e. , to predict the label of each   sample as a causal relation class , a coreference re-   lation class , or no relation class ( negative samples ) .   The final loss function combines event central-   ity and causality learning , where λis a hyper-   parameter :   L = λL+L , ( 14 )   3.6 A Unified View of GNN - based DECI   Methods   CHEER is a general framework that first constructs   a document - level graph , then incorporates event   centrality , and finally conducts reasoning on the   graph . In this section , we discuss the difference   between CHEER and previous GNN - based DECI   methods . Note that only CHEER considers joint   training , and we do not discuss loss function here .   ( 1 ) RichGCN ( Tran Phu and Nguyen , 2021 ) has   only event nodes and uses vanilla GCN ’s aggre-   gation function : g / parenleftig   z , z / parenrightig   = zW. By re-   moving : i ) event centrality incorporation , ii ) event   pair nodes and their relevant edges , iii ) edge fea-   tures and self - attention mechanism , CHEER could   degenerate into RichGCN ’s framework .   ( 2 ) DSGCN ( Zhao et al . , 2021 ) has only   event nodes and uses a combination of GCNs :   g / parenleftig   z , z / parenrightig   = /summationtextαzW , where αde-   notes a feature filter . By removing : i ) event cen-   trality incorporation , ii ) event pair nodes and their   relevant edges , iii ) edge features and modifying g   accordingly , CHEER is scalable to DSGCN .   ( 3 ) ERGO ( Chen et al . , 2022 ) has only event-   pair nodes and performs self - attention aggregation :   g / parenleftig   z , z / parenrightig   = f(α)(zW ) . By removing i )   event centrality incorporation , ii ) event nodes and   their relevant edges , and iii ) edge features , CHEER   could degenerate into ERGO ’s framework . Therefore , by modifying the event centrality in-   corporation , the construction of EIG , and the aggre-   gation function , CHEER can degenerate into differ-   ent GNN - based DECI methods , and thus provide a   unified view for better document - level reasoning .   4 Experiments   4.1 Experimental Setup   Datasets Details We evaluate CHEER on two   widely used datasets . EventStoryLine ( version   0.9 ) ( Caselli and V ossen , 2017 ) contains 22 topics ,   258 documents , and 5,334 events . Among them ,   1,770 intra - sentence and 3,885 inter - sentence event   pairs are annotated with causal relations . Follow-   ing Gao et al . ( 2019 ) , we group documents ac-   cording to their topics . Documents in the last two   topics are used as the development data , and docu-   ments in the remaining 20 topics are employed   for 5 - fold cross - validation . Causal - TimeBank   ( Mirza , 2014 ) contains 184 documents and 6,813   events . Among them , 318 event pairs are anno-   tated with causal relations . Following Tran Phu   and Nguyen ( 2021 ) , we employ 10 - fold cross-   validation and only evaluate ECI performance for   intra - sentence event pairs because the number of   inter - sentence event pairs in Causal - TimeBank is   quite small ( i.e. , only 18 pairs ) . EventStoryLine   provides ground - truth event coreference chains , but   Causal - TimeBank does not . To solve this , we have   preprocessing steps on Causal - TimeBank . We first   perform pre - training on EventStoryLine , and then   use the pre - trained model to extract coreference   data for Causal - TimeBank . We also use the Stan-   ford CoreNLP toolkit ( Manning et al . , 2014 ) for   a supplement . After the preprocessing steps , we   add event - event coreference edges Eto EventSto-   ryLine and Causal - TimeBank . We perform a joint   training in Section 3.5 on EventStoryLine . In eval-   uation , we only report and compare the prediction   results of causal relations with baselines .   Implementation Details We set the dynamic   window size in Section 3.1 to 256 , and divide docu-   ments into several overlapping windows with a step   size of 32 . We implement our method based on the   Pytorch version of Huggingface Transformer ( Wolf   et al . , 2020 ) . We use uncased BERT - base ( Devlin   et al . , 2019 ) as the document encoder . We optimize   our model with AdamW ( Loshchilov and Hutter ,   2019 ) using a learning rate of 2e-5 with a linear   warm - up for the first 8 % steps . We apply layer nor-10809malization ( Ba et al . , 2016 ) and dropout ( Srivastava   et al . , 2014 ) between the EIG reasoning network   layers . We clip the gradients of model parameters   to a max norm of 1.0 . We perform early stopping   and tune the hyper - parameters by grid search based   on the development set performance : dropout rate   ∈{0.1 , 0.2 , 0.3 } , focusing parameter τ∈{0 , 1 ,   2 , 3 } , weighting factor β∈{0.25 , 0.5 , 0.75 } , loss   weight λ∈{0.1 , 0.2 } . Our model is trained on an   NVIDIA RTX 2080 GPU with 24 GB memory .   Evaluation Metrics We adopt Precision ( P ) , Re-   call ( R ) , and F1 - score ( F1 ) as evaluation metrics ,   same as previous methods ( Tran Phu and Nguyen ,   2021 ) to ensure comparability .   4.2 Baselines   We compare our proposed CHEER with various   state - of - the - art SECI and DECI methods .   SECI Baselines ( 1)KMMG ( Liu et al . , 2020 ) , a   mention masking generalization method using ex-   tenal knowledge . ( 2 ) KnowDis ( Zuo et al . , 2020 ) ,   a knowledge - enhanced distant data augmentation   method to alleviate the data lacking problem . ( 3 )   CauSeRL ( Zuo et al . , 2021a ) , which learns context-   specific causal patterns from external causal state-   ments . ( 4 ) LearnDA ( Zuo et al . , 2021b ) , which   uses knowledge bases to augment training data .   ( 5)LSIN ( Cao et al . , 2021 ) , which constructs a   descriptive graph to leverage external knowledge .   DECI Baselines ( 1)OP(Caselli and V ossen ,   2017 ) , a dummy model that assigns causal re-   lations to event pairs . ( 2 ) LR+ andLIP ( Gao   et al . , 2019 ) , feature - based methods that construct   document - level structures and use various types of   resources . ( 3 ) BERT ( our implementation ) a base-   line method that leverages dynamic window and   event marker techniques . ( 4 ) RichGCN ( Tran Phu   and Nguyen , 2021 ) , which constructs a document-   level interaction graph and uses GCN to capture rel-   evant connections . ( 5 ) ERGO ( Chen et al . , 2022 ) ,   which builds a relational graph and model inter-   action between event pairs . We compare with its   BERT - base implementation for fairness . Due to   DSGCN ( Zhao et al . , 2021 ) does not provide re-   sults on benchmark datasets and does not release   codes , we do not compare with it here .   4.3 Overall Results   Since some baselines can not handle the inter-   sentence scenarios in EventStoryLine , and the   number of inter - sentence event pairs in Causal-   TimeBank is quite small ( i.e. , only 18 pairs ) . Thus   we report the results of intra- and inter - sentence   settings separately .   Intra - sentence Evaluation From Table 1 , we   can observe that : ( 1 ) CHEER outperforms all the   baselines by a large margin on both datasets , which   demonstrates its effectiveness . ( 2 ) Compared with   feature - based methods OP , LR+ , and LIP , models   using PLMs far boost the performance , which ver-   ifies that BERT could extract useful text features   for the ECI task . We notice that OP achieves the   highest Recall on EventStoryLine , which may be   due to simply assigning causal relations by mim-   icking the textual order . This leads to many false   positives and thus a low Precision .   Inter - sentence Evaluation From Table 2 , we can   observe that : ( 1 ) CHEER greatly outperforms all10810   the baselines under both inter- and ( intra+inter)-   sentence settings . This demonstrates that CHEER   can make better document - level inferences via our   effective modeling over EIG . ( 2 ) the overall F1-   score of the inter - sentence setting is much lower   than that of the intra - sentence , which shows the   challenge of DECI where events scatter in the doc-   ument without clear causal indicators . Specifically ,   the BERT baseline could achieve competitive per-   formance under the intra - sentence setting . How-   ever , it performs much worse than LIP , RichGCN ,   ERGO , and CHEER under inter - sentence settings ,   which indicates that a document - level structure   or graph helps capture the global interactions for   causal relation prediction .   4.4 Ablation Study   To analyze the effect of each main component   proposed in CHEER , we consider evaluating the   following ablated models on the EventStoryLine   dataset . As shown in Table 3 : ( 1 ) Effect of Event   Centrality ( w/o event centrality ) , which removes   event centrality incorporation introduced in Sec-   tion 3.3 . Removing event centrality leads to in-   formation loss from the document to the graph .   The performance degradation proves our contribu-   tion to preserving the event centrality information .   ( 2)Effect of Edge Features ( w/o edge features ) ,   which does not incorporate the edge features in   Section 3.4 and thus the learnable scalar γis re-   moved in aggregation function . We can see that re-   moving the edge - aware scalar clearly decreases the   performance , which validates the necessity of cap-   turing the semantic information of different edge   features in EIG . ( 3 ) Effect of Coreference ( w/o   coref ) , which removes the Eedges in EIG and   does not use the ground - truth coreference chains   as auxiliary training labels . The results indicate   that the prior coreference information is helpful for   the DECI task and supports us to unify event and   event - pair graphs .   4.5 Event Centrality Investigation   We further analyze the role of central events in the   DECI task and the effect of our incorporation ways .   4.5.1 Role of Central Events   In Figure 3 , the histograms represent the F1 results   of CHEER under intra / inter / intra+inter settings on   EventStoryLine . Three different groups represent   three different ways of event causality incorpora-   tion , and the lines represent F1 results of central   events prediction under three ways : ( 1 ) w/o event   centrality , which removes the event centrality in-   corporation introduced in Section 3.3 ; ( 2 ) CHEER ,   the original incorporation way ; ( 3 ) w/ g - t central   events , which preserves centrality - aware event em-   beddings as event node features initialization but   uses ground - truth central event labels to distinguish   edge types . It can be seen that the F1 result of   our central event classification reaches nearly 80 % ,   which is feasible and still has space for improve-   ment . We also observe that compared with using   ground - truth labels , the inaccuracy of event cen-   trality prediction limits the performance of DECI .   Nevertheless , the performance of event centrality   prediction could be higher by using more advanced   encoding methods .   4.5.2 Case Study   In this section , we conduct a case study to further   illustrate an intuitive impression of CHEER and   choose the SOTA baseline ERGO for comparison .   In Figure 3 , we show a piece of text with five events ,   where quake is the central event ( with a corefer-   ence earthquake ) We notice that : ( 1 ) ERGO cannot10811   achieve the coreference consistency ( No.1 and 4   event pairs ) , but CHEER could solve this explicitly   by introducing prior relations and joint training . ( 2 )   ERGO could suffer from the false negative issue   ( No.3 event pair ) . For example when ( quake , de-   stroying ) receives positive prediction from ( quake ,   die ) but negative prediction from ( die , destroying ) ,   it tends to think the transitivity does not hold and   outputs a wrong prediction . In contrast , CHEER   blocks the propagation over these misleading paths   by making central events take effect . 3 ) In the bot-   tom graph , we visualize the normalized weights δ   of Equation ( 11 ) with ( left part ) and without event   centrality information ( right part ) . For clarity , we   only show some main nodes and edges here . We   could see that when there is no event centrality   incorporation , the δvalues of neighboring nodes   to ( quake , destroying ) are relatively even , which   makes its prediction disturbed by negative paths ,   i.e. , information from ( die , destroying ) node . When   the event centrality is incorporated , ( quake , destroy-   ing ) pays more attention to the paths where central   events are involved , i.e. , quake node and ( quake ,   die ) node . Therefore , CHEER can learn more from   such informative neighbors for the DECI task .   5 Conclusion   In this paper , we propose a novel centrality - aware   high - order event reasoning network ( CHEER ) to   conduct global reasoning for DECI . We first sum-   marize a general GNN - based DECI model and pro-   vide a unified view for better understanding . Then   we design an Event Interaction Graph ( EIG ) that   involves prior event relations and high - order inter-   actions among event pairs . Finally , we incorpo - rate event centrality via well - designed features and   multi - task learning . Extensive experiments show a   great improvement of CHEER for both intra- and   inter - sentence ECI on two benchmark datasets . Fur-   ther analysis demonstrates the effectiveness of each   main component .   Limitations   Although our modeling of event centrality is feasi-   ble and effective , there is still space for improve-   ment . The performance of event centrality pre-   diction could be higher by using more advanced   encoding methods .   Besides , it is meaningful to further explore the   interactions among various types of event relations .   Existing datasets only cover limited relation types   at once , and many works focus on the identification   of causal relations alone . In this paper , although   we further consider the effect of coreference rela-   tions and perform joint classification , there are still   some other relations that can be explored , such as   temporal relations , subevent relations , etc .   Acknowledgments   This work was supported by the Singapore Ministry   of Education ( MOE ) Academic Research Fund   ( AcRF ) Tier 1 grant , as well as cash and in - kind   contribution from the industry partner(s ) .   References108121081310814ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Limitations   /squareA2 . Did you discuss any potential risks of your work ?   Not applicable . Left blank .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract & 1 Introduction   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   4 Experiments   /squareB1 . Did you cite the creators of artifacts you used ?   4.1 Experimental Setup   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   Not applicable . Left blank .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   4.1 Experimental Setup   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Not applicable . Left blank .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Not applicable . Left blank .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   4.1 Experimental Setup   C / squareDid you run computational experiments ?   4 Experiments   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   No response.10815 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   4.1 Experimental Setup   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   4.3 Overall Results   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   4.1 Experimental Setup   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   3.3 Event Centrality Incorporation   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   3.3 Event Centrality Incorporation   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   Not applicable . Left blank .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   Not applicable . Left blank .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   Not applicable . Left blank .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   Not applicable . Left blank.10816