  Jiarui Yao , Nianwen Xue , and Bonan MinBrandeis UniversityRaytheon BBN Technologies   { jryao , xuen}@brandeis.edu , bonan.min@raytheon.com   Abstract   The task of modal dependency parsing aims to   parse a text into its modal dependency struc-   ture , which is a representation for the factual-   ity of events in the text . We design a modal   dependency parser that is based on priming   pre - trained language models , and evaluate the   parser on two data sets . Compared to baselines ,   we show an improvement of 2.6 % in F - score   for English and 4.6 % for Chinese . To the best   of our knowledge , this is also the first work on   Chinese modal dependency parsing .   1 Introduction   Modal dependency parsing ( MDP ) is the task of   parsing a text into a modal dependency structure   ( MDS ) ( Vigus et al . , 2019 ) in which each event   in the text is linked to a conceiver , the informa-   tion source of the event . An MDS is a graph in   which the nodes are events and conceivers , and   the edges represent the level of certainty that a   conceiver holds with respect to the event . An ex-   ample MDS is presented in Figure 1 , where Jeroen   Weimar is the conceiver of the event travelled , and   is certain that the traveling event has happened , as   indicated by the edge label Pos . Vigus et al . ( 2019 )   define 6 categories of modal strength , or levels of   certainty , and they are full positive ( Pos ) , partial   positive ( Prt ) , positive neutral ( Neut ) , negative neu-   tral ( Neutneg ) , partial negative ( Prtneg ) andfull   negative ( Neg ) . The root node of an MDS is always   the author ( AUTHOR ) of a document , the ultimate   source of all information sources mentioned in the   text .   Modal dependency parsing is thus the task of   taking a text as input and parsing it into a modal   dependency structure . MDP departs from previous   approaches to event factuality prediction that cast   it as an event classification ( e.g. Saurí and Puste-   jovsky ( 2012 ) ) or regression ( e.g. Lee et al . ( 2015 ) )   problem aimed at just predicting the level of cer-   tainty of an event . The level of certainty alone isinsufficient in judging the factuality of an event ,   and knowing the information source ( conceiver ) is   also crucially important . For example , in Figure   1 , our judgment of whether the event travelled has   happened also crucially depends on the credibility   of the information source , Jeroen Weimar , in addi-   tion to the level of certainty the information source   holds towards the event .   Figure 1 : A modal dependency tree for “ A person in   Traralgon had tested positive to COVID-19 on Sunday .   The Victorian government ’s COVID-19 response com-   mander Jeroen Weimar confirmed ‘ this individual has   travelled to Melbourne . ’ ”   Yao et al . ( 2021 ) develop the first modal depen-   dency parser by first separately extracting events   and conceivers , then building up the MDS bottom-   up with a ranking model . One shortcoming of this   approach is that it fails to capture the fact that the   status of an entity as a conceiver is conditioned on   its being the information source of an event . For   instance , in Figure 1 , a person is an entity but is   not a conceiver as it is not the source of any event .   As a result , Yao et al . ( 2021 ) report relatively low   conceiver extraction F - score compared to event ex-   traction ( 70.4 % for conceiver extraction vs. 90.8 %   for event extraction ) . Errors in conceiver extrac-   tion will propagate to the structure building stage ,   leading to lower overall MDS parsing accuracy .   In this paper , we describe an approach to MDP   based on language model priming in which we con-   struct a prompt with an event and use it to predict2913its chain of conceivers as well as the level of cer-   tainty the conceivers hold . This approach avoids   the error propagation problem in Yao et al . ( 2021 )   and also takes better advantage of powerful pre-   trained language models . Our experiments show   that this approach outperforms previous models for   both English and Chinese .   2 Approach   We approach MDS parsing by first performing   event extraction , then use the extracted events to   construct the prompt for the purpose of identifying   their conceivers . Given a document , a language   model such as BERT ( Devlin et al . , 2019 ) is used   to obtain the contextualized representation for each   token . A standard BIO tagging model is then ap-   plied to identify events , where B , I , O refer to the   beginning , inside , and outside of an event respec-   tively .   The next step in MDS parsing is to identify con-   ceivers for each extracted event . More formally ,   given an event eas a child node , the task is to   extract ( e , c , cc ) , where cis the conceiver of e ,   andccis the conceiver of c. In theory , a child   event can have a chain of conceivers longer than   two , but in over 96 % of the cases , an event has a   chain of two conceivers or less . We thus made the   simplifying assumption that an event can have a   chain of two conceivers at most .   Our model receives an event - specific text se-   quence as input , then predicts a tag from a target   set { B - C , I - C , B - CoC , I - CoC , O } for each token   in the sequence . B - C and I - C labels are for tokens   inc , and B - CoC , I - CoC are for tokens in cc . We   construct the event - specific sequence , seq , by con-   catenating a prompt and a context sequence in the   form of [ CLS ] a prompt [ SEP ] a context sequence   [ SEP ] . Letsdenote the sentence containing e , we   add token markers < EVENT > , < /EVENT > before   and after the event span in sto get the prompt for   e. For a child event e , its parent conceiver can   usually be found within a window surrounding s.   Thus , the context sequence for eis constructed by   taking the surrounding sentences of sin a window ,   followed by two special tokens < AUTHOR > and   < NULL > representing the AUTHOR and NULL-   CONCEIVER node . Figure 2 shows an example   of the input sequence seqwith gold tags . The input sequence seqis then encoded with   a pre - trained language model . Let H = ( h , ... ,   h ) denote a sequence of contextualized represen-   tations for the input tokens in seq , the score for   the tag of the j - th token is :   ˆy = FFN(h ) ,   where FFNis a feed - forward neural network .   To learn the edge label between a child node   and its parent node , we use a separate feed - forward   neural network to map hto the edge label set .   The edge label set includes the modal relations in   the data set plus the N / A label , which is chosen   when there is no relation between the child node   eand token j , i.e. when token jis neither part of   the conceiver of enor part of the conceiver of the   conceiver of e. The score for the edge label of the   j - th token is :   ˆy = FFN(h ) ,   where FFNis a feed - forward neural network .   In the training phase , we minimize the following   cross - entropy loss :   L = L+L ,   where LandLrefer to the parent tagging loss   and edge labeling loss respectively .   Inference In an MDS , each child node only has   one parent node . To enforce a well - formed MDS ,   we apply two rules in the inference stage : ( i ) if   more than one conceiver is predicted for e , the   first prediction is taken ; ( ii ) if a conceiver does n’t   have a conceiver , by default it is attached to the   AUTHOR with the majority label in the data set .   3 Experiments   3.1 Data   We evaluate our approach on an English modal de-   pendency data set ( Yao et al . , 2021 ) and a Chinese   modal dependency data set ( Liu and Xue , 2022 )   that consists of about 300 news articles . For En-   glish , we use the same data split as in Yao et al .   ( 2021 ) . For Chinese , we randomly split the data set   to training ( train in Table 1 ) , developing ( dev ) and   test ( test ) sets . The statistics of the two data sets   are in Table 1.2914   # Doc # Event # Conc   Englishtrain 289 19,541 2,344   dev 32 2,307 298   test 32 2,168 296   Chinesetrain 237 11,679 879   dev 30 1,464 136   test 30 1,318 116   3.2 Baselines   When evaluating English modal dependency pars-   ing , we compare our prompt - based model with two   variants of the ranking based models described in   Yao et al . ( 2021 ): a pipeline model and a joint   model . The joint model uses a shared BERT en-   coder for both event / conceiver extraction and struc-   ture building .   As there is no existing model for Chinese modal   dependency parsing , we re - implemented the joint   learning variant of the ranking based model in Yao   et al . ( 2021 ) to serve as our baseline , with minor   modifications . We use a shared BERT encoder for   the event / conceiver extraction and structure build-   ing , following Yao et al . ( 2021 ) , but encode all the   sentences in a document as a long sequence instead   of encoding it sentence by sentence . Full details   about the differences between the two models can   be found in Appendix C.   3.3 Experiment Setup   We use the Hugging Face ( Wolf et al . , 2020 ) imple-   mentation of XLM - RoBERTa - base ( Conneau et al . ,   2020 ) for Chinese . For English , we use BERT-   large - cased ( Devlin et al . , 2019 ) , same as Yao et al .   ( 2021 ) . When generating input sequences for the   proposed prompt - based model , we use a window   of 5 sentences before and 5 sentences after for En-   glish , and all the sentences before and 3 sentences   after for Chinese . For the ranking baseline , we se - lect candidate parents from the same window size   as the prompt - based model , and keep at most 16   candidate parents for English , 40 for Chinese . Our   window size and number of candidate parents are   consistent with Yao et al . ( 2021 ) ( for English ) , for   Chinese , they cover over 99 % of the cases in the   Chinese development set . Full details of the hyper-   parameter settings can be found in the Appendix .   3.4 Main Results   Tables 2 and 3 present the experimental results .   Same as Yao et al . ( 2021 ) , we report the exact   match scores for event identification , and micro-   average F scores for all experiments . For modal   dependency parsing , F scores are computed on   < child , parent , relation > triples , with results based   on system - identified events and conceivers .   Event identification In Table 2 , we compare our   event identification ( ID ) model with previous mod-   els . All models extract events using a BIO tagger .   On English data , our model is slightly better than   both models in Yao et al . ( 2021 ) . Cross - lingually ,   our English event ID results are higher than Chi-   nese results . Possible reasons are discussed in Sec-   tion 3.5 .   ModelsEnglish Chinese   Dev Test Dev Test   Yao et al . ( 2021)-P 92.7 90.9 - -   Yao et al . ( 2021)-J 92.8 90.8 - -   Ours 93.2 91.9 87.4 88.6   Overall parsing Table 3 presents a compari-   son of our prompt - based model with previous re-   sults and our own baseline . For both English and   Chinese modal dependency parsing , our prompt-   based model consistently outperforms all baselines .   Our prompt - based model outperforms the pipeline2915model of Yao et al . ( 2021)-P by 3.0 % on the devel-   opment set and 4.4 % on the test set . In addition ,   our own baseline is slightly better than Yao et al .   ( 2021)-J , a ranking - based joint model , possibly be-   cause of the different encoding mechanisms the   two models use ( see 3.2 ) . Lastly , compared with   our own baseline , the prompt - based model achieves   an improvement of 0.9 % in absolute F - score on the   English development set and 2.6 % on the English   test set . For Chinese , the improvements are even   larger : 3.8 % on the development set and 4.6 % on   the test set .   ModelsEnglish Chinese   Dev Test Dev Test   Yao et al . ( 2021)-P 69.7 67.5 - -   Yao et al . ( 2021)-J 70.3 69.0 - -   baseline ( ours ) 71.8 69.3 61.7 59.0   prompt - based ( ours ) 72.7 71.9 65.5 63.6   3.5 Cross - lingual Comparison   Our experimental results show that English MDP   results are in general better than Chinese . There   are a few possible explanations . As discussed in   Section 3.1 , the English data set is larger than the   Chinese data set on every count . More training data   typically means higher model accuracy . A closer   look at the data reveals other differences between   the two data sets as well . Table 4 breaks down the   types of parent a child has for the two languages .   We can see that in the English data , 69 % of child   nodes have the AUTHOR as parent , while in the   Chinese data , that percentage is 52.6 % . The two   data sets have similar proportion of cases when the   child is in the same sentence as the parent : 23.7 %   vs. 27.5 % . However , the Chinese data set has a   much higher percentage of cases where the parent   is in a different sentence from the child : 19.9 % vs.   5.7 % . Parents that are further away are harder to   predict . There is a linguistic explanation for why   in Chinese parent conceivers are further apart from   the event child : Chinese allows dropped pronouns ,   and as a result , the conceiver is often found in a   previous sentence of the event . In Table 5 , 王军   ( Wang Jun ) in Sentence 8 is the conceiver of events   in Sentence 9 because of a dropped pronoun in   Sentence 9 .   ... [ S8]王军指出，今年是“十三五”规划收   官之年，下半年各项税收工作任务异常艰   巨 。   ... [ S8 ] Wang Jun pointed out that this year is the   end of the 13th Five - Year Plan , and the taxation   tasks in the second half of the year are extremely   challenging .   [ S9 ] ( 王军指出)各级税务机关既要抓好重点   工作落实，努力把疫情造成的损失补回来 。   [ S9 ] ( Wang Jun pointed out ) Tax authorities at all   levels should not only do a good job in   implementing key tasks , and strive to make up   for the losses caused by the pandemic .   4 Related Work   Early works cast event factuality prediction ( EFP )   as a classification or regression problem and have   employed rule - based ( Nairn et al . , 2006 ; Lotan   et al . , 2013 ) or machine learning approaches ( Diab   et al . , 2009 ; Lee et al . , 2015 ; Saurí and Pustejovsky ,   2012 ; Stanovsky et al . , 2017 ) . More recently ,   different types of neural models have been ap-   plied to this problem , such as LSTM - based RNNs   ( Rudinger et al . , 2018 ) , Generative Adversarial   Networks ( Qian et al . , 2018 ) , or graph neural net-   works ( Pouran Ben Veyseh et al . , 2019 ) . Qian et al .   ( 2019 ) and Cao et al . ( 2021 ) extended the sentence   level task to document - level EFP . Our work is most   closely related to that of Yao et al . ( 2021 ) , which   casts EFP as modal dependency parsing . However ,   they first extract events and conceivers and then   build the MDS by ranking the candidate parents   for each event . In contrast , we perform modal de-   pendency parsing by constructing a prompt with   the event to predict its conceiver parent , simplify-   ing the pipeline . Our prompt - based approach also   bears resemblance to works applying prompt - based   learning to other NLP tasks , such as event extrac-   tion ( Liu et al . , 2020 ; Fincke et al . , 2021 ) , relation   extraction ( Li et al . , 2019 ) , named entity recogni-   tion ( Li et al . , 2020 ) and coreference resolution2916(Wu et al . , 2020 ) .   5 Conclusion   In this paper , we propose a model for modal de-   pendency parsing based on priming pre - trained lan-   guage models . We evaluate the model on an En-   glish modal dependency data set , and for the first   time , evaluate the model on a Chinese modal de-   pendency data set . Experimental results show that   our model consistently outperforms baselines on   both data sets .   Acknowledgements   We thank the anonymous reviewers for their helpful   comments .   This work is supported in part by a grant from   the IIS Division of National Science Foundation   ( Award No . 1763926 ) entitled “ Building a Uniform   Meaning Representation for Natural Language Pro-   cessing ” . All views expressed in this paper are   those of the authors and do not necessarily repre-   sent the view of the National Science Foundation .   This research is based upon work supported in   part by the Office of the Director of National Intel-   ligence ( ODNI ) , Intelligence Advanced Research   Projects Activity ( IARPA ) , via Contract No . 2019-   19051600006 under the IARPA BETTER program .   The views and conclusions contained herein are   those of the authors and should not be interpreted   as necessarily representing the official policies , ei-   ther expressed or implied , of ODNI , IARPA , or   the U.S. Government . The U.S. Government is   authorized to reproduce and distribute reprints for   governmental purposes notwithstanding any copy-   right annotation therein .   References2917   A Data sets   We use a publicly available English modal depen-   dency data set constructed by Yao et al . ( 2021 ) ,   which consists of news articles from the following   news media sources : Business Standard , Business   Insider , NBC News , The New York Times , Reuters ,   The Guardian , The Washington Post , CNN , Fox   News , Yahoo News and Wikinews . We also use a   Chinese modal dependency data set constructed by   Liu and Xue ( 2022 ) that consists of news articles   from Xinhua newswire .   B Implementation details   We optimize our models with the BertAdam opti-   mizer of a linear scheduler with a warmup ratio of   0.1 . The learning rate is 2e-5 . We apply a dropout   rate of 0.1 over the last layer of the pretrained lan-   guage model output to get the contextualized rep-   resentations . We use a 2 - layer FFN with ReLU   activations for all models . The hidden unit size of   the FFNs is the hidden size of the pretrained lan-   guage model , i.e. 1024 for bert - large - cased , 768   for xlm - roberta - base . For the proposed prompt-   based model , we use a batch size of 12 , maximum   sequence length of 512 for Chinese , a batch size of   6 , maximum sequence length of 384 for English .   Sequences that are longer than the maximum se-   quence length are cut to segments with a stride of   64 for both languages .   We train all the models for 30 epochs on a   NVIDIA Tesla V100 ( 16 GB ) GPU . We run all2918the models for 3 runs with different seeds , and re-   port the average F - scores across runs . Each epoch   takes about 45 minutes for English , 19 minutes for   Chinese .   C Baselines   We give more details about the two ranking base-   lines : baseline ( ours ) and Yao et al . ( 2021)-J in   Table 3 . Given a child node , the two models first   generate a candidate parent set for the child , then   compute the pair score for each child - parent pair .   The candidate parent with the highest pair score   is selected as the parent . There are a few differ-   ences between the two models . First , Yao et al .   ( 2021 ) encode a document sentence by sentence ,   i.e. they add a [ CLS ] and [ SEP ] token before and   after each sentence and encode them with the lan-   guage model . We encode all the sentences in a   document together , i.e. we add a [ CLS ] and [ SEP ]   token before and after each document , and encode   it with the language model . If a document is longer   than the maximum sequence length ( T ) , we split it   into segments and encode each segment indepen-   dently . Each segment has T/2 overlapping tokens   with the previous segment . The values of T are   the same as the maximum sequence length values   in section B. The final token representations are   derived by taking the average of the token repre-   sentations in each segment . Next , we obtain the   node representations by simply taking the average   token representations in a node , while they take the   concatenation of the start token , end token and the   span token vector in the node as the node represen-   tations . Lastly , even if Yao et al . ( 2021 ) propose a   multi - task learning model by jointly learning node   identification and structure building , they train the   structure building stage with gold nodes . Our base-   line is trained in an end2end fashion : the model   first identifies nodes , then uses the system identi-   fied nodes as the input for the structure building   stage.2919