  Mali Jin , Daniel Preo¸ tiuc - Pietro , A. Seza Do ˘gruöz , Nikolaos AletrasUniversity of Sheffield , Bloomberg , Ghent University   { mjin6 , n.aletras}@sheffield.ac.uk   dpreotiucpie@bloomberg.net   as.dogruoz@ugent.be   Abstract   Bragging is a speech act employed with the   goal of constructing a favorable self - image   through positive statements about oneself . It   is widespread in daily communication and es-   pecially popular in social media , where users   aim to build a positive image of their persona di-   rectly or indirectly . In this paper , we present the   first large scale study of bragging in computa-   tional linguistics , building on previous research   in linguistics and pragmatics . To facilitate this ,   we introduce a new publicly available data set   of tweets annotated for bragging and their types .   We empirically evaluate different transformer-   based models injected with linguistic informa-   tion in ( a ) binary bragging classification , i.e. ,   if tweets contain bragging statements or not ;   and ( b ) multi - class bragging type prediction   including not bragging . Our results show that   our models can predict bragging with macro   F1 up to 72.42 and 35.95 in the binary and   multi - class classification tasks respectively . Fi-   nally , we present an extensive linguistic and   error analysis of bragging prediction to guide   future research on this topic .   1 Introduction   The desire to be viewed positively is a key driver   of human behavior ( Baumeister , 1982 ; Leary and   Kowalski , 1990 ; Sedikides , 1993 ; Tetlock , 2002 )   and creating a positive image often leads to per-   sonal rewards ( Gilmore and Ferris , 1989 ; Hogan ,   1982 ; Schlenker , 1980 ) . Self - presentation strategies   are means for individuals to build and establish this   positive social image to meet their goals ( Goffman   et al . , 1978 ; Jones et al . , 1982 ; Jones , 1990 ; Bak   et al . , 2014a ) . Bragging ( or self - praise ) is one of   the most common strategies and involves disclos-   ing a positively valued attribute about the speaker   or their in - group ( Dayter , 2014 , 2018).Social media platforms tend to promote self-   presentation tendencies ( Chen et al . , 2016 ) and   allow users to craft an idealized self - image of them-   selves ( Chou and Edge , 2012 ; Michikyan et al . ,   2015 ; Halpern et al . , 2017 ) . Self - presentation on-   line is predominantly positive ( Chou and Edge ,   2012 ; Lee - Won et al . , 2014 ; Matley , 2018 ) . Fur-   thermore , self - promotion is acceptable and even de-   sired in certain online contexts ( Dayter , 2018 ) . This   is also amplified by social media platforms through   the presence of likes or positive reactions to users ’   posts ( Reinecke and Trepte , 2014 ) which often are   used to quantify impact on the platform ( Lampos   et al . , 2014 ) . Bragging in particular was found to   be more frequent on social media than face - to - face   interactions ( Ren and Guo , 2020 ) .   However , bragging is considered a high risk   act ( Brown and Levinson , 1987 ; Holtgraves , 1990 ;   Van Damme et al . , 2017 ) and can lead to the op-   posite effect than intended , such as dislike or de-   creased perceived competence ( Jones et al . , 1982 ;   Sezer et al . , 2018 ; Matley , 2018 ) . It is , thus ,   paramount to understand the types of bragging   and strategies to mitigate the face - threat intro-   duced by bragging as well as how effective the   self - presentation attempt is ( Herbert , 1990 ) . Table   1 shows examples of a non - bragging and bragging   statements grouped in six types under a taxonomy   that we propose in this paper based on previous   linguistic research ( Dayter , 2018 ; Matley , 2018 ) .   Despite its pervasiveness and importance in on-   line communication , bragging has yet to be studied   at scale in computational ( socio ) linguistics . The   ability to identify bragging automatically is im-   portant for : ( a ) linguists to better understand the   context and types of bragging through empirical   studies ( Dayter , 2014 ; Ren and Guo , 2020 ) ; ( b ) so-   cial scientists to analyze the relationship between   bragging and personality traits , online behavior   and communication strategies ( Miller et al . , 1992 ;   Van Damme et al . , 2017 ; Sezer et al . , 2018 ) ; ( c ) on-3945   line users to enhance their self - presentation strate-   gies ( Miller et al . , 1992 ; Dayter , 2018 ) ; ( d ) enhanc-   ing NLP applications such as intent identification   ( Wen et al . , 2017 ) and conversation modeling .   In this paper , we aim to bridge the gap between   previous work in pragmatics and the computational   study of speech acts . Our contributions are :   •A new publicly available data set containing a   total of 6,696 English tweets annotated with   bragging and their types ;   •Experiments with transformer - based models   combined with linguistic features for bragging   identification ( binary classification ) and brag-   ging type classification ( seven classes ) ;   •A qualitative linguistic analysis of markers of   bragging in tweets and the model behavior in   predicting bragging .   2 Related Work   Bragging as a Speech Act Bragging as a speech   act is considered a face - threatening act to posi-   tive face ( i.e. the desire to be liked ) under polite-   ness theory ( Brown and Levinson , 1987 ) . It is di-   rectly oriented to the speaker and may threaten their   likeability if the bragging is perceived negatively ,   while also may affect hearer ’s face by implying   that their feelings are not valued by the speaker   ( Matley , 2018 ) . Bragging online plays an important   role in self - presentation and its pervasiveness chal-   lenges classic politeness theories , such as the mod-   esty maxim ( Leech , 2016 ) and the self - denigrationmaxim ( Gu , 1990 ) . Thus , research in social psy-   chology and linguistics has mostly focused on iden-   tifying the pragmatic strategies for bragging that   mitigate face threat and their impact of likeability   and perceived competence , which the speakers aim   to increase with this self - presentation strategy .   Bragging Strategies Modest and sincere self-   presentation styles are more likely to be perceived   positively ( Sedikides et al . , 2007 ) . Bragging framed   as mere information - sharing , but with positive con-   notation to the speaker , can make the speaker be   perceived as more likeable ( Miller et al . , 1992 ) .   It can also be perceived negatively and causes   greater aggression when it involves boasting , el-   ements of competitiveness , use of superlatives and   explicit comparisons to others ( Miller et al . , 1992 ;   Hoorens et al . , 2012 ; Scopelliti et al . , 2015 ; Matley ,   2018 ) . In addition , competence related statements   are more likely to be negatively perceived than   those based on warmth ( e.g. the ability to form con-   nections with others ) ( Van Damme et al . , 2017 ) .   Common mitigation strategies include speaker ’s at-   tempts to deny compliments , shifting focus to per-   sons closely related to them , reframing bragging as   praise from a third party , admitting the bragging act   through disclaimers ( e.g. using # brag ) or express-   ing it as a complaint ( Wittels , 2011 ; Sezer et al . ,   2018 ) , question , narration or sharing ( Dayter , 2018 ;   Matley , 2018 ; Ren and Guo , 2020 ) . The success of   self - presentation strategies are also impacted by the   social context ( Tice et al . , 1995 ) or speaker identity   ( Paramita and Septianto , 2021).3946Analysis of Bragging Bragging has been studied   in the context of a small ballet community ( Dayter ,   2014 ) , a pick - up artist forum ( Rüdiger and Dayter ,   2020 ) and a small set of WhatsApp conversations   ( Dayter , 2018 ) . On social media , Matley ( 2018 )   studied the functional use of hashtags ( e.g. # brag ,   # humblebrag ) in Instagram posts , Tobback ( 2019 )   examined bragging strategies on LinkedIn , Ren   and Guo ( 2020 ) investigated bragging and its prag-   matic functions in Chinese social media and Mat-   ley ( 2020 ) studied impact of mitigating bragging   through irony showing that bragging was negatively   perceived . However , all these studies rely on man-   ual analyses of small data sets ( e.g. < 300 posts ) .   Speech Acts in NLP Speech acts have been   studied in NLP with examples including polite-   ness ( Danescu - Niculescu - Mizil et al . , 2013 ) , com-   plaints ( Preo¸ tiuc - Pietro et al . , 2019 ; Jin and Ale-   tras , 2020 , 2021 ) , humor ( Yang et al . , 2021 ) , par-   ody ( Maronikolakis et al . , 2020 ) , irony ( Bamman   and Smith , 2015 ) , deception ( Chen et al . , 2020 )   and self - disclosure ( Bak et al . , 2012 ; Levontin and   Yom - Tov , 2017 ; Ravichander and Black , 2018 ) .   Self - disclosure is closer to bragging as it is related   to revealing personal information about oneself . It   is usually employed to improve or maintain rela-   tionships ( Bak et al . , 2012 ) as measured through   conversation frequency ( Bak et al . , 2014b ) . On the   other hand , bragging is about aspects that are posi-   tively valued by the audience with the goal of im-   proving the speaker ’s self - image . Bak et al . ( 2014a )   aim to predict different levels of self - disclosure   statements , from general to sensitive ; while Wang   et al . ( 2021 ) examine gender differences in self-   promotion by Congress members on Twitter . Brag-   ging also involves in some cases possessions ( Chin-   nappa and Blanco , 2018 ) .   3 Bragging Data   3.1 Bragging Definition & Types   Definition Bragging is a speech act which explic-   itly or implicitly attributes credit to the speaker for   some good ( e.g.possession , skill ) that is positively   valued by the speaker and their audience ( Dayter ,   2014 ) . A bragging statement should clearly express   what the author is bragging about .   Types We generalize and extend the bragging   types based on the definitions by Dayter ( 2018 ) and   Matley ( 2018 ) . The former summarizes them as ac-   complishments and some aspects of self ; while thelatter includes everyday achievements ( e.g. cook-   ing ) and personal qualities . We divide the ‘ some as-   pects of self ’ category into two categories , namely   ‘ Possession ’ and ‘ Trait ’ respectively . We also add   an ‘ Affiliation ’ category for bragging involving a   group to which the speaker belongs . In total , we   consider six bragging types and a non - bragging cat-   egory . Table 1 shows the definitions of each type .   Classification Tasks Given the taxonomy above ,   we define two classification tasks : ( i ) binary brag-   ging prediction ( i.e. if a tweet contains a bragging   statement or not ) ; and ( ii ) seven - way multiclass   classification for predicting if a tweet contains one   of the six bragging types or no bragging at all .   3.2 Data Collection   To the best of our knowledge , there is no other   data set available for our study . We use Twitter   for data collection as tweets are openly available   for research and widely used in other related tasks ,   e.g. predicting sentiment ( Rosenthal et al . , 2017 ) ,   affect ( Mohammad et al . , 2018 ) , sarcasm ( Bamman   and Smith , 2015 ) , stance ( Mohammad et al . , 2016 ) .   Random Sampling We select tweets for anno-   tation by randomly sampling from the 1 % Twitter   feed one day per month from January 2019 to De-   cember 2020 ( approximately 10k tweets per day ) to   ensure diversity using the Premium Twitter Search   API for academic research .   Keyword - based Sampling To give a model ac-   cess to more positive examples of bragging state-   ments for training , we use a keyword - based sam-   pling method that increases the hit rate of bragging ,   following previous work on labeling infrequent lin-   guistic phenomena , e.g. irony ( Mohammad et al . ,   2018 ) or hate speech ( Waseem and Hovy , 2016 ) .   We build queries based on indicators of posi-   tive self - disclosure ( e.g. I , just ) ( Dayter , 2018 ) and   stylistic indicators , e.g. positive emotion words ,   present tense verbs ( Bazarova et al . , 2013 ) . As the   frequency of these keywords is high , we construct   multi - word queries consisting of a personal pro-   noun and an indicator . In addition , we use a short   list of curated bragging - related hashtags . After an-   notating 1,000 tweets , we compute the percentage3947   of bragging tweets for each keyword and remove   from sampling tweets with less than 5 % ( i.e. [ I ,   amazed ] , [ I ’m , amazing ] , [ I ’m , best ] , [ my , best ] , [ I ,   excellent ] , # humble ) .   We initially collected around 6 K and 368 K   tweets using hashtags and multi - word queries re-   spectively . We obtain over 9k tweets by keeping   all tweets collected using hashtags and sample 1 %   from those collected using multi - word queries to   balance the two types .   Data Filtering After collecting tweets , we ex-   clude those with duplicate or no meaningful textual   content ( e.g. only @-mentions or images ) . We only   focus on English posts and filter out non - English   ones using the language code provided by Twitter .   We also exclude retweets and quoted tweets , as   these do not typically express the thoughts of the   user who retweeted them . Moreover , we exclude   131 tweets containing a URL in the text because   these were related to advertisements based on ini-   tial results from our annotation calibration rounds .   This resulted in a total of 6,696 tweets which is   of similar size with data sets recently released for   social NLP ( Oprea and Magdy , 2020 ; Chung et al . ,   2019 ; Beck et al . , 2021 ; Mendelsohn et al . , 2021 ) .   3.3 Annotation and Quality Control Process   We manually annotate tweets for providing a solid   benchmark and foster future research . All authors   of the paper have significant experience in linguis-   tic annotation . We run three calibration rounds of   100 tweets each , where all annotated all tweets and   discussed disagreements , until a Krippendorf ’s Al-   pha above 0.80 in the seven - class task was reached .   To monitor quality , a subset of 1,564 tweets were   annotated by two annotators or more in case of   disagreements . If a tweet fits into multiple bragging   types , we assign the more prominent one . The   annotation is based only on the actual text of the   tweet without considering additional modalities   ( e.g. images ) , context or replies . This is similar   to the information available to predictive models   during training . We selected the final label as the   majority vote and a final label was assigned after   consensus in cases of three different votes . The   full task guidelines , examples and interface are   presented in Appendix B.   The inter - annotator agreement between two an-   notations of all tweets is : ( a ) percentage agree-   ment : 89.03 ; ( b ) Krippendorf ’s Alpha ( Krippen-   dorff , 2011 ) ( 7 - class ): 0.840 ; ( c ) Krippendorf ’s   Alpha ( binary ): 0.786 . Agreement values are be-   tween the upper part of the substantial agreement   band and the perfect agreement band ( Artstein and   Poesio , 2008 ) . The final data set consists of 6,696   tweets with one of the seven classes . Before anno-   tation , the keyword - based and randomly sampled   tweets were shuffled to not induce frequency bias .   Data set statistics are shown in Table 2 , including   statistics across the two sampling strategies . The   model performance curve by varying the training   set size indicates that annotating more data is not   likely to lead in substantial improvements in brag-   ging prediction ( see Figure 3 in Appendix ) .   3.4 Self - disclosure in Bragging   We conduct an analysis of the relationship between   self - disclosure and bragging as they are closely re-   lated . We use self - disclosure lexicon by Bak et al .   ( 2014a ) to assign each tweet in our data set a la-   bel ( i.e. self - disclosure or non - self - disclosure ) . The   percentages of self - disclosure across each brag-   ging type are shown in Table 3 . We also used self-   disclosure models as a predictor for bragging in3948early experimentation but the results are omitted   due to the low performance .   3.5 Data Splits   We use the keyword sampled data for training and   the random data for development and testing ( in   the ratio of 2:8 ) because the latter is representative   of the real distribution of tweets ( see Table 2 ) .   4 Predictive Models   We evaluate vanilla transformer - based mod-   els ( Vaswani et al . , 2017 ) and further leverage ex-   ternal linguistic information to improve them .   BERT , RoBERTa and BERTweet We exper-   iment with Bidirectional Encoder Representa-   tions from Transformers ( BERT ; Devlin et al .   ( 2019 ) ) , RoBERTa ( Liu et al . , 2019 ) and BERTweet   ( Nguyen et al . , 2020 ) . RoBERTa is a more ro-   bust variant of BERT that obtains better results   on a wide range of tasks . BERTweet is pre-   trained on English tweets using RoBERTa as ba-   sis and achieves better performance on Twitter   tasks ( Nguyen et al . , 2020 ) . We fine - tune BERT ,   RoBERTa and BERTweet for binary and multiclass   bragging prediction by adding a classification layer   that takes the [ CLS ] token as input .   BERTweet with Linguistic Features We inject   linguistic knowledge that could be related to brag-   ging to the BERTweet model with a similar method   proposed by Jin and Aletras ( 2021),that was   found to be effective on complaint severity clas-   sification , a related pragmatics task . The method   is adapted from Rahman et al . ( 2020 ) , which in-   tegrates multimodal information ( e.g. audio , vi-   sual ) in transformers using a fusion mechanism   called Multimodal Adaption Gate ( MAG ) . MAG   integrates multimodal information to text represen-   tations in transformer layers using an attention gat-   ing mechanism for modality influence controlling .   We first expand vectors of linguistic information   to a comparable size to the embeddings fed to the   pre - trained transformer . We , then , use MAG to con-   catenate contextual and linguistic representations   after the embedding layer of the transformer sim-   ilar to Rahman et al . ( 2020 ) . The output is sent   to a pre - trained BERTweet encoder for fine - tuning   followed by an output layer .   We experiment with these linguistic features:•NRC : The NRC word - emotion lexicon con-   tains a list of English words mapped to ten   categories related to emotions and sentiment   ( Mohammad and Turney , 2013 ) . We represent   each tweet as a 10 - dimensional vector where   each element is the proportion of tokens be-   longing to each category .   •LIWC : Linguistic Inquiry and Word Count   ( Pennebaker et al . , 2001 ) is a dictionary - based   approach to count words in linguistic , psy-   chological and topical categories . We use   LIWC 2015 to represent each tweet as a 93-   dimensional vector .   •Clusters : We use Word2Vec clusters pro-   posed by Preo¸ tiuc - Pietro et al . ( 2015 ) to rep-   resent each tweet as a 200 - dimensional vector   over thematic subjects .   5 Experimental Setup   Text Processing We pre - process text by lower-   casing , replacing all username mentions with place-   holder tokens @USER and emojis with words using   demojize . We also remove hashtags that are used   as keywords ( e.g. # brag ) in data collection . Finally ,   we tokenize the text using TweetTokenizer .   Baselines   Majority Class : As a first baseline , we label all   tweets with the label of the majority class .   LR - BOW : We train a Logistic Regression with   bag - of - words using L2 regularization .   BiGRU - Att : We also train a bidirectional Gated   Recurrent Unit ( GRU ) network ( Cho et al . , 2014 )   with self - attention ( Tian et al . , 2018 ) . Tokens are   first mapped to GloVe embeddings ( Pennington   et al . , 2014 ) and then passed to a bidirectional GRU .   Subsequently , its output is passed to a self - attention   layer and an output layer for classification .   Hyperparameters ForBiGRU - Att , we use 200-   dimensional GloVe embeddings ( Pennington et al . ,   2014 ) pre - trained on Twitter data . The hidden size   ish= 128 where h∈{64 , 128 , 256 , 512 } with   dropout d= .2 , d∈{.2 , .5 } . We use Adam op-   timizer ( Kingma and Adam , 2015 ) with learning   ratel= 1e-2 , l∈{1e-3 , 1e-2 , 1e-1 } . For BERT , 3949   RoBERTa andBERTweet , we use the base cased   model ( 12 layers and 109 M parameters , 12 lay-   ers and 125 M parameters and 12 layers and 135 M   parameters accordingly ) and fine - tune them with   learning rate l= 3e-6 , l∈{1e-4 , 1e-5 , 5e-6 , 3e-6 ,   1e-6 } . For BERTweet with linguistic features , we   project these to vectors of size l = 200 , l   = 400 , l = 768 , l∈{10 , 93 , 200 , 400 , 600 ,   768 } . For MAG , we use the default parameters   from Rahman et al . ( 2020 ) . For multi - class classi-   fication , we apply class weighting due to the im-   balanced data and set the training epoch to n= 40 ,   n∈{15 , 20 , 25 , 30 , 35 , 40 , 45 , 50 , 55 , 60 , } . The   maximum sequence length is set to 50 covering   95 % of tweets in the training set . We use a batch   size of 32 .   Training and Evaluation We train each model   three times using different random seeds and report   the mean Precision , Recall and F1 ( macro ) . We   apply early stopping during training based on the   dev loss . The experiments with linguistic features   are performed with the best pre - trained transformer   in each of the two classification tasks .   6 Results   Binary Bragging Classification Table 4 ( left )   shows the predictive performance of all models   on predicting bragging ( i.e. binary classification ) .   Overall , BERTweet models with linguistic infor-   mation achieve better overall performance . Trans-   former models perform substantially above the ma-   jority class baseline ( +23.29 F1 ) and above Logis-   tic Regression ( +18.76 ) . BERTweet ( 71.44 F1 ) per-   forms better than BERT ( 64.58 F1 ) and RoBERTa   ( 67.34 F1 ) , which illustrates the advantage of pre-   training on English tweets for this task .   Performance is further improved ( +0.98 F1 ) by   using LIWC features alongside BERTweet , which   indicates that injecting extra linguistic informationbenefits bragging identification . We speculate that   this is because a bragging statement usually con-   tains particular terms ( e.g. personal pronouns , pos-   itive terms ) or involves at least one certain aspect   or theme ( e.g. reward or property ) , which can be   captured by linguistic features ( e.g. feature Iand   ACHIEVE in LIWC ) . Combining lexicons lead to   worse results than using a single one , so we refrain   from reporting these results for clarity .   Multi - class Bragging Classification Table 4   ( right ) shows the predictive performance of all mod-   els on multiclass bragging type prediction includ-   ing not bragging . We again find that pre - trained   transformers substantially outperform the majority   class baseline ( +21.1 F1 ) and logistic regression   ( +16.27 F1 ) . In line with the binary results , we   find that BERTweet ( 34.86 F1 ) performs best out of   all transformers . BERTweet - Clusters outperforms   all models ( 35.95 F1 ) , which indicates that topi-   cal information helps to identify different types of   bragging . Each bragging type might be particularly   specialized to certain topics ( e.g. weight loss in   ‘ Achievement ’ category ) .   7 Analysis   Linguistic Feature Analysis We analyze the lin-   guistic features i.e. unigrams , LIWC and part - of   speech ( POS ) tags associated with bragging and   its types in all tweets of our data set . For this pur-   pose , we first tag all tweets using the Twitter POS   Tagger ( Derczynski et al . , 2013 ) . Each tweet is rep-   resented as a bag - of - words distribution over POS   unigrams and bigrams to reveal distinctive syntac-   tic patterns of bragging and their types . For each   unigram , LIWC and POS feature , we compute cor-   relations between its distribution across posts and   the label of the post . Then , we use the method   introduced by Schwartz et al . ( 2013 ) to rank the   features using univariate Pearson correlation with3950   words normalized to sum up to unit for each tweet .   Table 5 ( left ) presents the top 15 features from   unigrams ( lowercase ) and LIWC ( uppercase ) and   top 10 features from POS unigrams and bigrams   correlated with bragging and non - bragging tweets .   We notice that the top words in the bragging cate-   gory can be classified into ( a ) personal pronouns   ( e.g. my , I ) that usually indicate the author of the   bragging statement ; ( b ) words related to time ( e.g.   FOCUSPAST , TIME , during ) ; and ( c ) words re-   lated to a specific bragging target ( e.g. RELATIV ,   ACHIEVE , REWARD , managed ) . These findings   are in line with the indicators of positive self-   disclosure by Dayter ( 2018 ) and Bazarova et al .   ( 2013 ) . Furthermore , personal pronouns followed   by a verb in past tense ( PRP_VBD ) is common in   bragging ( e.g. I forgot what it ’s like to be good at   school . Today I finished a thing we were doing so   fast that everyone around me started asking ME   for help instead of the prof :’) )   Table 5 ( right ) presents the top 15 features from   unigrams ( lowercase ) and LIWC ( uppercase ) corre-   lated with bragging tweets grouped in six types . We   observe that Achievement statements usually in-   volve verbs that are in past tense or indicate a result   ( e.g. FOCUSPAST , finished , beat ) . A POS pattern   common in Achievement statements is a cardinal   number followed by nouns in plural ( CD_NNS ) ,   similar to its unigram and LIWC features ( NUM-   BER,3,5 ) ( e.g. I made a total of 5 dollars fromonline surveys wooo ) . It is worth noting that one of   the prevalent LIWC features for Action isFOCUS-   FUTURE . This is because the user may brag about   a planned action ( e.g. @USER You know what ? I ’m   going to make some PizzaRolls Brag ) . Most of the   top words in Feeling express emotion or sensitivity   ( e.g. happy , blessed ) , which is consistent with the   top POS feature , RB_JJ ( e.g. absolutely chuffed , so   happy ) . In Trait category , words are mostly pro-   nouns ( e.g. I , PRP , PRP_VBP ) and verbs ( e.g. VBP ,   VBP_JJ ) . Words appear frequently in Possession   category are actions related to purchase ( e.g. own ,   buy ) and nouns related to a tangible object ( e.g.   car , bedroom ) . In addition , users usually show off   the value of their possessions using statements that   involve currency signs ( $ ) or currency signs fol-   lowed by a number ( $ _ CD ) ( e.g. I just signed a   new three - year contract and I ’ll be getting 235 any-   time minutes per month . Plus , the company is going   to throw in a phone for just $ 49 per month . I ’ll   bet you ca n’t beat that deal ! ) . Finally , top words   inAffiliation category involve positive feeling to-   wards belonging to a group ( e.g. proud , amazing )   and nouns related to it ( e.g. FAMILY , team ) .   Bragging and Post Popularity We also analyze   the association between bragging posts and the   number of favorites / retweets they receive by other   users . Similar to the previous linguistic feature   analysis , we use univariate Pearson correlation to   compute the correlations between the log - scaled fa-3951   vorites / retweets number of each tweet and its label   ( i.e. bragging or non - bragging ) by controlling the   numbers of followers and friends of the user who   post the tweet . Our results show that the number of   favorites is positively correlated with bragging ( see   Appendix Figure 5 ) while there is no correlation   between bragging and the number of retweets .   We further explore the popularity of different   bragging types . We randomly analyze a set of 443   tweets containing 56 bragging statements , where   the follower and friend number of users are within a   similar range : from 100 to 500 followers and from   500 to 1000 friends ( r= 0.19 , p < .01 ) . We com-   pute the mean and median Twitter favorites across   the six bragging classes ( see Table 6 ) . We observe   that bragging statements about Affiliation such as   family members or sports teams are more likely   to receive considerable amount of favorites with   the mean of 5.5 . For example , 14 users favorite the   tweet This maybe is a little , but I ’m SO proud of my   research group . We represent so many different per-   sonality types , cultures , ways of thinking , etc , and   every single member of my lab ( all 21 of them ) . We   speculate this is because praising the group that one   belongs to instead of oneself as a bragging strategy   enables users be perceived as more likeable . Fur-   thermore , bragging about Achievement is generally   marked as favorite by other users with the median   of 3 , where bigger achievements in the content such   as job offers may receive more favorites ( e.g. tweet   Scored 80 % on my thesis . Rather proud of that   given the circumstances : new baby ; pandemic ; late   topic change due to lockdown ; minimal uni support   because of furloughs ; and an international move .   was marked as favorite 15 times ) .   Class Confusion Analysis Figure 1 presents the   confusion matrix of human agreement on seven   classes normalized over the actual values ( rows ) .   We observe that Non - bragging ( 97 % ) , Achievement   ( 81 % ) and Action ( 78 % ) have high agreement , con-   sistent with the class frequency . Affiliation ( 77 % ) ,   Possession ( 76 % ) and Trait ( 72 % ) have compara - ble percentages as these are easily associated with   a bragging target or group . The Feeling category   has the lowest percentage mostly caused by mis-   classification to the Action category . This is due   to the fact that both types are not associated to a   concrete outcome by definition , with the feeling   class linked to a feeling linked to an action . Thus ,   it makes the boundary between bragging about the   action or the feeling associated to the action more   challenging to interpret . The next most frequent   confusion is between possession andachievement ,   which usually arises when a tangible possession is   involved and the annotators disagree if the author   was bragging about the actual possession or the   action that lead to the author obtaining that posses-   sion ( e.g. @USER I just got some stealth 300 easily   the best headset I ’ve ever had going from astro to   turtle beach was a night and day difference ) .   Figure 2 presents the confusion matrix between   bragging type predictions from the best perform-   ing model , BERTweet - Clusters , on the multi - class   classification task . First , we observe that the model   is more likely to misclassify other classes as the   dominant class , Non - bragging . Secondly , the most   unambiguous classes are Non - bragging ( 87 % ) and   Achievement ( 52 % ) , which are in line with human   agreement . Also , the model is good at identifying   Trait ( 50 % ) and Possession ( 46 % ) due to the par-   ticular bragging targets ( e.g. personalities , skills   or tangible objects ) . Furthermore , we notice that   the percentages of Action ( 31 % ) and Feeling ( 37 % )   are low . We speculate this is because they share   more similarities with other classes ( e.g. involving   actions ) . This might also explain the high percent-   age of misclassified data points between Action and   Achievement , Feeling andAction . Lastly , the model   often confuses Affiliation with Feeling likely be-   cause the terms that express positive feelings ( e.g.   ‘ proud ’ , ) also appear frequently in Affiliation   ( see Table 5 ) .   Error Analysis Finally , we perform an error anal-   ysis to examine the behavior and limitations of our   best performing model ( i.e. BERTweet - LIWC for   binary classification and BERTweet - Clusters for   multi - class classification ) and identify pathways to   improve the task modeling .   We first start with the binary bragging classifica-   tion . We observe that non - bragging tweets contain-   ing positive sentiment are easy to be misclassified   as bragging and even if such tweets involve some-   thing valued positively by authors , the purpose is3952   usually to express recommendation , compliment or   appreciation to others : Another frequent error happens when non - bragging   tweets contain popular bragging targets such as   achievement - oriented ( e.g. weight loss , marathon )   or possession - oriented ( e.g. car , electronics ):   Bragging often involves contextual understanding   that goes beyond word use and require deep un-   derstanding of the context to determine the label .   For example , common terms such as first , finally ,   justoften appear in both non - bragging ( T3 ) and   bragging ( T4 ) tweets :   Models also fail to detect bragging mainly be-   cause it is indirect or there are no typical trigger   terms , so they lean on pre - training to contextualize :   Some bragging statements use additional mitiga-   tion strategies , e.g. re - framing the bragging state-   ment as irony , as a complaint or invoking praise   from a third party :   Finally , we highlight some representative exam-   ples of model confusion between bragging types .   One example is when users ’ actions lead or not to a   concrete result . In this example the model predicted   Action , but the actual label is Achievement :   Another example is an Action misclassified as   Possession . This usually happens when a common   phrase indicative of a certain type of bragging ( a   new dish ) ) is invoked as part of an action :   Other errors occur when multiple types of brag-   ging are present ( e.g. feeling and action ) but the   label expresses the more salient type , such as the   feeling highlighted in this example :   8 Conclusion   We presented the first computational approach to   analyzing and modeling bragging as a speech act   along with its types in social media . We introduced   a publicly available annotated data set in English   collected from Twitter . We experimented using   transformer models combined with linguistic infor-   mation on binary bragging and multiclass bragging   type prediction . Finally , we presented an extensive   analysis of features related to bragging statements   and an error analysis of the model predictive be-   havior . In future work , we plan to study the ex-   tent to which bragging is used across various loca-   tions ( Sánchez Villegas et al . , 2020 ; Sánchez Ville-   gas and Aletras , 2021 ) and languages and how it is   employed by users across contexts .   Acknowledgements   We would like to thank Ari Silburt , Danae Sánchez   Villegas , Yida Mu , and all the anonymous review-   ers for their valuable feedback.3953Ethics Statement   Our work has received approval from the Ethics   Committee of the Department of Computer Science   at the University of Sheffield ( No 037572 ) and   complies with Twitter ’s data policy for research .   References3954395539563957A Impact of Multiple Annotations   Table 7 shows the performance of binary brag-   ging classification of the best performing model   ( BERTweet - LIWC ) on two different subsets of the   test data : one annotated by a single annotator ( 2,130   tweets ) and the other annotated by two or more an-   notators until consensus is reached ( 522 tweets ) .   The results show that the same model tested on the   two different subsets of test data lead to similar re-   sults . This shows there is no quantitative difference   between the data sets annotated by two or more   annotators when compared to a single annotator .   B Guidelines and Annotation Interface   Thank you for your participation in our study . Dur-   ing our experiment , we will ask you to read and   evaluate a tweet which may include a bragging or   a praisal statement .   Instructions You need to identify whether or not   a tweet includes a bragging statement .   Bragging Bragging is a speech act which explic-   itly or implicitly attributes credit to the speaker for   some ‘ good ’ ( possession , accomplishment , skill ,   etc . ) which is positively valued by the speaker and   the potential audience . As such , bragging includes   announcements of accomplishments , explicit pos-   itive evaluations of some aspect of self and other   types defined below . A bragging statement should   clearly express what the author is bragging about   ( i.e. the target of bragging ) .   If the tweet is about bragging , decide on the cate-   gory where the tweet belongs to from the following   categories :   Achievement The act of bragging is about a   concrete outcome obtained as a result of the tweet   author ’s actions . These results may include achieve-   ments , awards , products , and/or positive change in   a situation or status ( individually or as part of a   group ) .   Examples :   •Finally got that offer ! Whoop ! !   •Our team won the championship   Action The act of bragging is about a past , cur-   rent or upcoming action of the user that does not   have a concrete outcome   Examples :   •Hanging at Buffalo Wild Wings with @user for   the # ILLvsASU game . # BraggingRights   •Guess what ! I met Matt Damon today !   Feeling The act of bragging is about a feeling   that is expressed by the user for a particular situa-   tion .   Example :   •Im so excited that I am back on my consistent   schedule . I am so excited for a routine so I can   achieve my goals ! !   Trait The act of bragging is about a personal   trait , skill or ability of the user .   Examples:3958•To be honest , I have a better memory than my   siblings   •I look great after losing weight   Possession The act of bragging is about a tangi-   ble object belonging to the user .   Example :   •Look at our Christmas tree ! I kinda just wanna   keep it up all year !   Affiliation The act of bragging is about being   part of a group ( e.g. family , team , org etc . ) and/or   a certain location including living in a city , neigh-   borhood or country , enrolled into a university , sup-   porting a team , working in a company etc .   Example :   •My daughter got first place in the final exam , so   proud of her !   Not bragging If the tweet is not about bragging ,   then select " No . This is not a bragging statement . "   Examples :   •One of the best books I ’ve ever read   •hahahahahaha   •You got ta admit , that ’s some mighty awesome   aim !   •Vote in the poll below for your book of choice !   •I think this is great   •dear everyone announcing they are at " Friends-   giving " , we get it , you have friends   •In case you did n’t know , Adam Silver is in charge   •I feel terrible   •I do n’t know why you are celebrating   •This is exactly what is going on !   •I love you   Select " No . This is not a bragging statement " ,   also in cases when :   •there is not enough information to determine that   the tweet is about bragging   •the bragging statements belong to someone other   than the author of the tweet   •the relationship between author and peo-   ple / things mentioned in the tweet are unknown :   – This kid is smart   – That was an amazing stream   – Kudos to mike Dunleavy ! It ’s hard to get a   franchise record ANYTHING in Chicago   • the post is about the act of bragging :   – We want to hear you brag !   – Trump is n’t Bragging anymore as his trade-   war hits the stockmarket hard   – Dudes are getting too cocky these days . Them   lil labels and that dar do n’t impress everyone .   brag differently   Not available Finally , if the tweet is not avail-   able or displayed , or is in a language other than   English , please select the " Not available " option .   Other considerations Please verify the content   of hashtags as these may give clues towards the cat-   egory of the tweet . The judgment should be made   only based on the given content of the tweet - please   do not search the tweet on Twitter or online in order   to identify additional context.3959