  Emmy Liu and Graham Neubig   Language Technologies Institute   Carnegie Mellon University   { mengyan3 , gneubig}@cs.cmu.edu   Abstract   Compositionality , the phenomenon where the   meaning of a phrase can be derived from its   constituent parts , is a hallmark of human lan-   guage . At the same time , many phrases are   non - compositional , carrying a meaning beyond   that of each part in isolation . Representing   both of these types of phrases is critical for lan-   guage understanding , but it is an open question   whether modern language models ( LMs ) learn   to do so ; in this work we examine this question .   We first formulate a problem of predicting the   LM - internal representations of longer phrases   given those of their constituents . We find that   the representation of a parent phrase can be   predicted with some accuracy given an affine   transformation of its children . While we would   expect the predictive accuracy to correlate with   human judgments of semantic compositionality ,   we find this is largely notthe case , indicating   that LMs may not accurately distinguish be-   tween compositional and non - compositional   phrases . We perform a variety of analyses ,   shedding light on when different varieties of   LMs do and do not generate compositional rep-   resentations , and discuss implications for future   modeling work .   1 Introduction   Compositionality is argued to be a hallmark of lin-   guistic generalization ( Szabó , 2020 ) . However ,   some phrases are non - compositional , and can-   not be reconstructed from individual constituents   ( Dankers et al . , 2022a ) . Intuitively , a phrase like   " I own cats and dogs " is locally compositional ,   whereas " It ’s raining cats and dogs " is not . There-   fore , any representation of language must be easily   composable , but it must also correctly handle cases   that deviate from compositional rules .   Both lack ( Hupkes et al . , 2020 ; Lake and Baroni ,   2017 ) and excess ( Dankers et al . , 2022b ) of compo-   sitionality have been cited as common sources ofFigure 1 : An illustration of the local composition pre-   diction problem with [ CLS ] representations .   errors in NLP models , indicating that models may   handle phrase composition in an unexpected way .   In general form , the compositionality principle   is simply “ the meaning of an expression is a func-   tion of the meanings of its parts and of the way   they are syntactically combined ” ( Pelletier , 1994 ) .   However , this definition is underspecified ( Partee ,   1984 ) . Recent efforts to evaluate the compositional   abilities of neural networks have resulted in several   testable definitions of compositionality ( Hupkes   et al . , 2020 ) .   Previous work on compositionality in natural   language focuses largely on the definition of substi-   tutivity , by focusing on changes to the constituents   of a complex phrase and how they change its repre-   sentation ( Dankers et al . , 2022a ; Garcia et al . , 2021 ;   Yu and Ettinger , 2020 ) . The definition we examine   islocalism : whether or not the representation of   a complex phrase is derivable only from its local   structure and the representations of its immediate   “ children ” ( Hupkes et al . , 2020 ) . A similar con-   cept has been proposed separately to measure the   compositionality of learned representations , which   we use in this work ( Andreas , 2019 ) . We focus   on localism because it is a more direct definition   and does not rely on the collection of contrastive   pairs of phrases . This allows us to examine a wider   range of phrases of different types and lengths .   In this paper , we ask whether reasonable compo-9053sitional probes can predict an LM ’s representation   of a phrase from its children in a syntax tree , and if   so , which kinds of phrase are more or less compo-   sitional . We also ask whether this corresponds to   human judgements of compositionality .   We first establish a method to examine local   compositionality on phrases through probes that   try to predict the representation of a parent given   its children ( section 2 ) . We create two English-   language datasets upon which to experiment : a   large - scale dataset of 823 K phrases mined from   the Penn Treebank , and a new dataset of idioms   and paired non - idiomatic phrases for which we   elicit human compositionality judgements , which   we call the Compositionality of Human - annotated   Idiomatic Phrases dataset ( CHIP ) ( section 3 ) .   For multiple models and phrase types , we find   that phrase embeddings across models and repre-   sentation types have a fairly predictable affine com-   positional structure based on embeddings of their   constituents ( section 4 ) . We find that there are   significant differences in compositionality across   phrase types , and analyze these trends in detail ,   contributing to understanding how LMs represent   phrases ( section 5 ) . Interestingly , we find that hu-   man judgments do not generally align well with   the compositionality level of model representations   ( section 6 ) . This implies there is still work to be   done at the language modelling level to capture a   proper level of compositionality in representations .   2 Methods and Experimental Details   2.1 Tree Reconstruction Error   We follow Andreas ( 2019 ) in defining deviance   from compositionality as tree reconstruction error .   Consider a phrase x= [ a][b ] , where aandbcan be   any length > 0 . Assume we always have some way   of knowing how xshould be divided into aand   b. Assume we also have some way of producing   representations for x , a , andb , which we represent   as a function r. Given representations r(x),r(a )   andr(b ) , we wish to find the function which most   closely approximates how r(x)is constructed from   r(a)andr(b ) .   ˆf= arg min1   |X|/summationdisplayδ ( 1 )   δ = d(r(x ) , f(r(a ) , r(b ) ) ( 2 )   Where Xis the set of possible phrases in the   language that can be decomposed into two parts , Fis the set of functions under consideration , and   dis a distance function . An example scenario is   depicted in Figure 1 .   Ford , we use cosine distance as this is the most   common function used to compare semantic vec-   tors . The division of xintoaandbis specified by   syntactic structure ( Chomsky , 1959 ) . Namely , we   use a phrase ’s annotated constituency structure and   convert its constituency tree to a binary tree with   the right - factored Chomsky Normal Form conver-   sion included in NLTK ( Bird and Loper , 2004 ) .   2.2 Language Models   We study representations produced by a variety   of widely used language models , specifically the   base-(uncased ) variants of Transformer - based   models : BERT , RoBERTa , DeBERTa , and GPT-   2(He et al . , 2021 ; Liu et al . , 2019 ; Devlin et al . ,   2019 ; Radford et al . , 2019 ) .   2.2.1 Representation extraction   Let[x , ... , x]be a sequence of N+ 1input to-   kens , where xis the [ CLS ] token if applicable , and   xis the end token if applicable . Let [ h , ... , h ]   be the embeddings of the input tokens after the i - th   layer .   For models with the [ CLS ] beginning of se-   quence token ( BERT , RoBERTa , and DeBERTa ) ,   we extracted the embedding of the [ CLS ] token   from the last layer , which we refer to as the CLS   representation . For GPT-2 , we extracted the last   token , which serves a similar purpose . This corre-   sponds to handhrespectively .   Alternately , we also averaged all embeddings   from the last layer , including special tokens . We   refer to this as the A VG representation .   1   N+ 1 / summationdisplayh ( 3 )   2.3 Approximating a Composition Function   To use this definition , we need a composition func-   tionˆf . We examine choices detailed in this section .   For parameterized probes , we follow the prob-   ing literature in training several probes to predict a   property of the phrase given a representation of the   phrase . However , in this case , we are not predict-   ing a categorical attribute such as part of speech .   Instead , the probes that we use aim to predict the9054parent representation r(x)based on the child rep-   resentations r(a)andr(b ) . We call this an approxi-   mative probe to distinguish it from the usual use of   the word probe .   2.3.1 Arithmetic Probes   In the simplest probes , the phrase representation   r(x)is computed by a single arithmetic operation   onr(a)andr(b ) . We consider three arithmetic   probes :   ADD ( r(a ) , r(b ) ) = r(a ) + r(b ) ( 4 )   W1(r(a ) , r(b ) ) = r(a ) ( 5 )   W2(r(a ) , r(b ) = r(b ) ( 6 )   2.3.2 Learned Probes   We consider three types of learned probes . The   linear probe expresses r(x)as a linear combination   ofr(a)andr(b ) . The affine probe adds a bias term .   The MLP probe is a simple feedforward neural   network with 3 layers , using the ReLU activation .   LIN(r(a ) , r(b ) ) = αr(a ) + αr(b)(7 )   AFF ( r(a),r(b))=αr(a ) + αr(b ) + β(8 )   MLP ( r(a ) , r(b ) ) = Wh(9 )   Where   h = σ(W[r(a);r(b ) ] )   h = σ(Wh ) ,   Wis(300×2),Wis(768×300 ) , and Wis   ( 1×768 ) . We do not claim that this is the best   MLP possible , but use it as a simple architecture to   contrast with the linear models .   3 Data and Compositionality Judgments   3.1 Treebank   To collect a large set of phrases with syntactic   structure annotations , we collected all unique sub-   phrases ( ≥2words ) from WSJ and Brown sections   of the Penn Treebank ( v3 ) ( Marcus et al . , 1993 ) .   The final dataset consists of 823 K phrases after   excluding null values and duplicates . We collectedthe length of the left child in words , the length of   the right child in words , and the tree ’s production   rule , which we refer to as tree type . There were   50260 tree types in total , but many of these are   unique . Examples and phrase length distribution   can be found in Appendix A , and Appendix B.   3.2 English Idioms and Matched Phrase Set   Previous datasets center around notable bigrams ,   some of which are compositional and some of   which are non - compositional ( Ramisch et al . ,   2016b ; Reddy et al . , 2011 ) . However , there is a   positive correlation between bigram frequency and   human compositionality scores in these datasets ,   which means that it is unclear whether models are   capturing compositionality or merely frequency ef-   fects if they correlate well with the human scores .   Because models are likely more sensitive to sur-   face features of language than humans , we gathered   a more controlled set of phrases to compare with   human judgments .   Since non - compositional phrases are somewhat   rare , we began with a set of seed idioms and bi-   grams from previous studies ( Jhamtani et al . , 2021 ;   Ramisch et al . , 2016b ; Reddy et al . , 2011 ) . We used   idioms because they are a common source of non-   compositional phrases . Duplicates after lemmatiza-   tion were removed .   For each idiom , we used Google Syntactic   NGrams to find three phrases with an identical part   of speech and dependency structure to that idiom ,   and frequency that was as close as possible relative   to others in Syntactic Ngrams ( Goldberg and Or-   want , 2013).For example , the idiom " sail under   false colors " was matched with " distribute among   poor parishioners " . More examples can be found   in Table 1 . An author of this paper inspected the   idioms and removed those that were syntactically   analyzed incorrectly or offensive .   4Approximating a Composition Function   4.1 Methods   To approximate the composition functions of mod-   els , we extract the CLS andA VG representations   from each model on the Treebank dataset . We used   10 - fold cross - validation and trained the learned   probes on the 90 % training set in each fold . The9055   remaining 10 % were divided into a test set ( 5 % )   and dev set ( 5 % ) .   To fairly compare probes , we used mini-   mum description length probing ( V oita and Titov ,   2020).This approximates the length of the online   code needed to transmit both the model and data ,   which is related to the area under the learning curve .   Specifically , we recorded average cosine similarity   of the predicted vector and actual vector on the test   set while varying the size of the training set from   0.005 % to 100 % of the original . We compare the   AUC of each probe under these conditions to se-   lect the most parsimonious approximation for each   model .   4.2 Results   We find that affine probes are best able to cap-   ture the composition of phrase embeddings from   their left and right subphrases . A depiction of   probe performance at approximating representa-   tions across models and representation types is in   Figure 2 . However , we note that scores for most   models are very high , due to the anisotropy phe-   nomenon . This describes the tendency for most   embeddings from pretrained language models to be   clustered in a narrow cone , rather than distributed   evenly in all directions ( Li et al . , 2020 ; Ethayarajh ,   2019 ) . We note that it is true for both word and   phrase embeddings .   Since we are comparing the probes to each other   relative to the same anisotropic vectors , this is not   necessarily a problem . However , in order to com - pare each probe ’s performance compared to chance ,   we correct for anisotropy using a control task . This   task is using the trained probe to predict a ran-   dom phrase embedding from the set of treebank   phrase embeddings for that model , and recording   the distance between the compositional probe ’s pre-   diction and the random embedding . This allows us   to calculate an error ratio , where dist   represents the original average distance from the   true representation , and dist is the average   distance on the control task . This quantifies how   much the probe improves over a random baseline   that takes anisotropy into account , where a smaller   value is better . These results can be found in Ap-   pendix E. The results without anisotropy correction   can be found in Appendix G. In most cases , the   affine probe still performs the best , so we continue   to use it for consistency on all the model and repre-   sentation types .   We also compare the AUC of training curves   for each probe and find that the affine probe re-   mains the best in most cases , except RoBERTa   andDeBERTa . Training curves are depicted in   Appendix C. AUC values are listed in Appendix H.   Interestingly , there was a trend of the right child   being weighted more heavily than the left child ,   and each model / representation type combination   had its own characteristic ratio of the left child to   the right child . For instance , in BERT , the weight   on the left child was 12 , whereas it was 20 for the   right child .   For example , the approximation for the phrase   " green eggs and ham " with BERT [ CLS ] embed-   dings would be : r("green eggs and ham " ) =   12r("green eggs " ) + 20 r("and ham " ) + β.9056   5 Examining Compositionality across   Phrase Types   5.1 Methods   Intuitively , we expect the phrases whose represen-   tations are close to their predicted representation   to be more compositional . We call similarity to the   expected representation , sim(r(x),ˆf(r(a ) , r(b ) ) ) ,   thecompositionality score of a phrase .   We record the mean reconstruction error for each   tree type and report the results . In addition to com-   paring tree types to each other , we also examine the   treatment of named entities in subsubsection 5.2.1 .   We examine the relationship between length of a   phrase in words and its compositionality score in   subsubsection 5.2.2 .   5.2 Results   There is a significant difference between the mean   compositionality score of phrase types . Particu-   larly , the A VG representation assigns a lower com-   positionality score to NP →NNP NNP phrases ,   which is expected since this phrase type often corre-   sponds to named entities . By contrast , the CLS rep-   resentation assigns a low compositionality score to   NP→DT NN , which is unexpected given that such   phrases are generally seen as compositional . The   reconstruction error for the most common phrase   types is shown in Figure 5 .   Because different phrase types may be treated   differently by the model , we examine the relative   compositionality of phrases within each phrase   type . Examples of the most and least compositional   phrases from several phrase types are shown in Ta-   ble 2 for RoBERTa . Patterns vary for model and   representation types , but long phrases are generallyrepresented more compositionally .   5.2.1 Named Entities   We used SpaCy to tag and examine named entities   ( Honnibal and Montani , 2017 ) , as they are expected   to be less compositional . We find that named enti-   ties indeed have a lower compositionality score in   all cases except RoBERTa , indicating that they   are correctly represented as less compositional . A   representative example is shown in Figure 3 . Full   results can be found in Appendix J. We break down   the compositionality scores of named entities by   type and find surprising variation within categories   of named entities . For numerical examples , this   often depends on the unit used . For example , in   RoBERTarepresentations , numbers with " mil-   lion " and " billion " are grouped together as composi-   tional , whereas numbers with quantifiers ( " about " ,   " more than " , " some " ) are grouped together as not   compositional . The compositionality score distri-   butions for types of named entities are presented in   Figure 4 .   5.2.2 Examining Compositionality and Phrase   Length   There is no consistent relationship between phrase   length and compositionality score across models   and representation types . However , CLS andA VG   representations show divergent trends . There is a   strong positive correlation between phrase length   and compositionality score in the A VG representa-   tions , while no consistent trend exists for the CLS   representations . This indicates that longer phrases   are better approximated as an affine transformation   of their subphrase representations . This trend is   summarized in Appendix D. All correlations are   highly significant.9057   6 Comparing Compositionality   Judgments of Humans and Models   6.1 Methods   6.1.1 Human Annotation   Human annotators assigned labels to each phrase   in the matched dataset from subsection 3.2 : 1 for   not compositional , 2 for somewhat compositional ,   and 3 for fully compositional . They could also de-   cline to answer if they felt that the phrase did n’t   make sense on its own . Furthermore , they were   asked how much each subphrase ( left and right )   contributed to the final meaning , from 1 for not at   all , to 3 for a great deal . The Likert scale of 1 - 3 was   chosen based on analysis of previous composition-   ality annotation tasks , which found that extreme   values of compositionality were the most reliable   ( Ramisch et al . , 2016a ) .   Initially , six English - speaking graduate students   were recruited . The six initial annotators all an-   notated the first 101 examples and the subset of   three annotators with the highest agreement who   agreed to continue ( Krippendorff α= 0.5750 ) were   recruited for the full study , annotating 1001 exam-   ples . For the full study , the agreement was higher   ( α= 0.6633 ) . We took the mean of composition-   ality judgments to be the final score for phrases .   The instructions shown to annotators are in Ap-   pendix F. Examples judgments from an annotator   can be found in Table 3.9058   6.1.2 Model Comparison   To compare human judgments to model composi-   tionality scores , we use the best trained approxi - mative probe for each model and representation   type to predict a vector for the full phrase based   on its left and right subphrases ( taking the probe9059trained on the first fold ) . We use cosine similar-   ity to the expected representation as the measure   of how compositional a phrase is for a model and   representation type .   We take the Spearman correlation between   model compositionality scores and human com-   positionality judgments and observe differences   between human judgments and compositionality   scores from model representations .   6.2 Results   6.2.1 Correlation with human judgments   There is a weak correlation between model and   human compositionality scores . The most promis-   ing trend is found in RoBERTa , where both CLS   andA VG representations have a significant positive   correlation with human judgments . Results are in   Table 4 , with corrected p - values ( Holm , 1979 ) .   6.2.2 Subphrase Contribution Test   Annotators indicated to what extent they believed   each part of the phrase contributed to the final   meaning . We examined examples in which an-   notators rated one part of the phrase , for exam-   plea , as contributing more to the final mean-   ing , and checked how often d(r(x ) , r(a ) ) >   d(r(x ) , r(b ) ) . Models do surprisingly poorly at   this test , with most performing below chance . Re-   sults are presented in Table 5 . An error analysis   onRoBERTaindicated that in many cases , er-   rors were due to idiomaticity failures . For example ,   " noble gas " is a type of gas that was rated as being   more similar to " gas " by humans , but " noble " by   RoBERTa .   6.2.3 Idiomaticity Test   Because idioms were matched with non - idiomatic   expressions , we tested for correctly identifying the   idioms . We limited the analysis to pairs where the   idiomatic expression was rated as less composi-   tional than the matched expression . Results are   shown in Table 5 . Results are better than the sub-   phrase contribution test , but models do not achieve   good results , the best performing representation   being RoBERTa .   6.2.4 Correlations with Other Factors   We examine correlations of model and human com-   positionality scores with the frequency and length   of the phrase in words . As noted before , there is a   strong correlation between length and composition-   ality score in models but not in human results . Re-   sults are in Appendix K. A comparison of phrases   rated as most and least compositional by humans ,   as well as RoBERTa , is presented in Table 6 .   7 Related work   7.1 Background on Compositionality   Compositionality has been debated in the philoso-   phy of language , with opposing views ( Herbelot ,   2020 ): the bottom - up view that the meaning of a   larger phrase is a function of the meaning of its   parts ( Cresswell , 1973 ) , and the top - down view9060   that smaller parts only have meaning as a func-   tion of the larger phrase ( Fodor and LePore , 1992 ) .   It is likely that there is a blend of bottom - up and   top - down processing corresponding to composi-   tional and non - compositional phrases respectively   ( Dankers et al . , 2022a ) .   Hupkes et al . have proposed several composi-   tionality tests based on previous interpretations :   ( Hupkes et al . , 2020 ) . We focus on localism , corre-   sponding to the bottom - up view .   7.2 Other Definitions of Compositionality   Other works do other tests for compositionality , no-   tably substitutivity ( Hupkes et al . , 2020 ) . Evidence   suggests that models may be unable to modulate   the bottom - up and top - down processing of phrases   ( Dankers et al . , 2022b , a ) . Substitutivity effects ap-   pear to not be represented well ( Garcia et al . , 2021 ;   Yu and Ettinger , 2020 ) . This indicates that phrases   are not being composed as expected and motivates   our study of how local composition is carried out   in these models , and which types of phrase are   processed top - down and bottom - up .   7.3 Studies of Localism   Previous studies of local composition focus on bi-   grams , particularly adjective - noun and noun - noun   bigrams ( Nandakumar et al . , 2019 ; Cordeiro et al . ,   2019 ; Salehi et al . , 2015 ; Reddy et al . , 2011 ;   Mitchell and Lapata , 2010 ) . However , many of   these studies assume an additive composition func-   tion or only fit a composition function on the bi - grams in their datasets .   A study finds some evidence for successful local   composition in the case of mathematical expres-   sions , but used a constrained test set on a domain   that is expected to be perfectly locally composi-   tional ( Russin et al . , 2021 ) .   7.4 Approximating LM Representations   There has been recent interest in understanding the   compositionality of continuous representations gen-   erated by neural models ( Smolensky et al . , 2022 ) .   LM representations have been approximated as the   output of explicitly compositional networks based   on tensor products ( McCoy et al . , 2020 , 2019 ;   Soulos et al . , 2020 ) . These are typically evalu-   ated based on compositional domains , such as the   SCAN dataset ( Lake and Baroni , 2017 ) .   Previous work on the geometry of word embed-   dings within a sentence shows that language mod-   els can encode hierarchical structure ( Coenen et al . ,   2019 ; Manning et al . , 2020 ; Jawahar et al . , 2019 ) .   However , it is an open question as to why LMs do   not tend to generalize well compositionally ( Lake   and Baroni , 2017 ; Keysers et al . , 2020 ) .   8 Conclusion   We analyze the compositionality of representations   from several language models and find that there   is an effective affine approximation in terms of a   phrase ’s syntactic children for many phrases . Al-   though LM representations may be surprisingly   predictable , we find that human compositionality   judgments do not align well with how LM repre-   sentations are structured .   In this work , we study the representations pro-   duced after extensive training . However , the consis-   tency of several trends we observed suggests that   there may be theoretical reasons why LM represen-   tations are structured in certain ways . Future work   could investigate the evolution of compositionality   through training , or motivate methods that would al-   low LMs to achieve improved compositional gener-   alization while representing non - compositionality .   Acknowledgments   Thank you to Amanda Bertsch , Ting - Rui Chiang ,   Varun Gangal , Perez Ogayo , and Zora Wang for   participating in compositionality annotations . This   work was supported in part by a CMU Presidential   Fellowship to the first author , and the Tang Family   AI Innovation Fund.9061Limitations   One limitation of this work is that it was conducted   on a relatively small set of language models trained   on English , and the diversity of patterns within   even this set of language models and representation   types is great . However , we note that the experi-   ments can be easily repeated for any language that   has a treebank or good - quality syntactic parsers . A   related limitation is that these analyses are depen-   dent on what we take to be the " child " constituents   of a parent phrase . It may be harder to examine   compositionality for languages that differ substan-   tially from English , or that can not be easily parsed   using existing tools .   Although we try to carefully catalog behaviour   observed on natural language phrases , it is likely   that smaller - scale experiments providing a more   mechanistic understanding of model behaviour   would be easier to parse for readers . Although this   would be ideal , we leave this for future work , as our   main goal was to examine how language models   represent phrases considered to be compositional   and non - compositional in natural language .   Another limitation is that although we diagnose   a problem in language models , we do not provide a   clear avenue to fix it . Further work could be done to   understand what data distributions or training meth-   ods encourage model representations to be more   aligned with human judgments . Additionally , al-   though compositionality is linguistically important ,   more effort could be put towards understanding   the downstream tasks for which it is more impor-   tant . For instance , there could be clear issues in   machine translation if non - compositional phrases   are not represented properly , but these phrases may   not be important in other areas such as instruction   following or code generation .   Ethics Statement   Potential Risks and Impacts   Although we aim to document compositionality   effects in English , we acknowledge that this perpet-   uates the problem of English being the dominant   language in NLP research . It is possible that con-   clusions here do not hold for other languages , and   further work is needed to understand whether these   conclusions transfer .   Additionally , although we tried to filter out of-   fensive idioms from CHIP , this was based on one   person ’s best judgment , and it is possible that someof the terms in the dataset may be offensive to some   people . Overall , phrases in the dataset tend to be   benign , but some idioms are meant to have a perjo-   rative meaning .   Computational Infrastructure and Computing   Budget   To run our computational experiments , we made   use of a shared compute cluster . We used approxi-   mately 100 GPU hours to run experiments , mainly   due to running results for different language mod-   els and representation types . We did not have any   computational budget besides that already used to   maintain the cluster .   References906290639064A Treebank dataset tree types   Due to space constraints , we only show the top 20   tree types . This can be found in Table 7 .   B Treebank dataset phrase lengths   C Probe learning curves   Learning curves of the approximative probes   ( across 10 folds ) are shown in Figure 7 .   D Length Correlation   The correlations of the phrase length ( in words )   and compositionality scores in Treebank are shown   in Table 8.E Error ratio of probes90659066F Annotation setup and instructions   Annotators were recruited from a population of   graduate students . Initially , 6 annotators completed   the pilot experiment , which consisted of 101 exam-   ples . The subset of three annotators with highest   agreement was asked if they would like to com-   plete the full study . One annotator in the highest-   agreement group could not continue to the full   study , so this annotator was excluded , and the next   group with highest agreement was chosen . The   agreement values in subsubsection 6.1.1 are for the   final group of annotators chosen .   The experiment was implemented on the   Qualtrics platform , and participants were first pre-   sented with a consent form , linking to more back-   ground information on the study , and informing   them that their participation was entirely volun-   tary . After agreeing to the terms , participants were   shown some examples and went through 3 prac-   tice questions . The example given are shown in   Figure 8 , and the annotation interface is shown in   Figure 9 and Figure 10 . After completing the prac-   tice section , annotators began annotating the real   examples , which followed the same interface as the   practice examples .   Annotators were all located in the United States ,   paid approximately $ 15 per hour for their work.9067 G Compositionality scores without   anisotropy correction   The raw compositionality scores can be found in   Table 10 .   H AUC of approximative probesI Mean deviation of phrase types by tree   type   The mean deviation of the most common tree types   can be found in Figure 11 .   J Further named entity results   Named entity results can be found in Figure 12 and   Figure 13.90689069907090719072 K Frequency and length correlations9073