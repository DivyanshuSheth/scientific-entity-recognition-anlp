  Yanzeng Li , Bingcong Xue , Ruoyu Zhang , Lei ZouWangxuan Institute of Computer Technology , Peking University . Beijing , ChinaNational Key Laboratory of General Artificial Intelligence , BIGAI , Beijing , ChinaTopGraph . AI   liyanzeng@stu.pku.edu.cn   { xuebingcong , ry_zhang , zoulei}@pku.edu.cn   Abstract   Attribute extraction aims to identify attribute   names and the corresponding values from de-   scriptive texts , which is the foundation for ex-   tensive downstream applications such as knowl-   edge graph construction , search engines , and   e - Commerce . In previous studies , attribute   extraction is generally treated as a classifi-   cation problem for predicting attribute types   or a sequence tagging problem for labeling   attribute values , where two paradigms , i.e. ,   closed - world and open - world assumption , are   involved . However , both of these paradigms   have limitations in terms of real - world applica-   tions . And prior studies attempting to integrate   these paradigms through ensemble , pipeline ,   and co - training models , still face challenges   like cascading errors , high computational over-   head , and difficulty in training . To address   these existing problems , this paper presents   Attribute Tree , a unified formulation for real-   world attribute extraction application , where   closed - world , open - world , and semi - open at-   tribute extraction tasks are modeled uniformly .   Then a text - to - tree generation model , AtTGen ,   is proposed to learn annotations from different   scenarios efficiently and consistently . Experi-   ments demonstrate that our proposed paradigm   well covers various scenarios for real - world   applications , and the model achieves state - of-   the - art , outperforming existing methods by a   large margin on three datasets . Our code , pre-   trained model , and datasets are available at   https://github.com/lsvih/AtTGen .   1 Introduction   Attribute Extraction ( AE ) is a practical applica-   tion of the Information Extraction ( IE ) task , aim-   ing to identify the attribute name and the corre-   sponding attribute value from unstructured or semi-   structured text fragments ( Ghani et al . , 2006 ; Ravi   and Pasca , 2008 ; More , 2016 ) . Figure 1 shows a   typical product profile with extracted attribute tags . Figure 1 : An example of attribute extraction , high-   lighted with annotations in different tagging forms .   As the foundation for various downstream applica-   tions such as knowledge graph construction , search   engines , e - Commerce and recommender systems ,   AE has attracted extensive research interest in re-   cent years ( Zheng et al . , 2018 ; Xu et al . , 2019 ; Zhu   et al . , 2020 ; Jain et al . , 2021 ; Zhang et al . , 2022 ; Li   and Zou , 2022 ) .   There are two basic subtasks in the research of   AE , namely , attribute name extraction and attribute   value extraction . And we use the RDF - style triple   < e , n , v > to denote the entity , attribute name , and   attribute value respectively . According to whether   the attribute name set is pre - defined , AE can be   divided into two paradigms , i.e. , the Closed - World   Assumption ( CWA ) and the Open - World Assump-   tion ( OWA ) . For CWA AE , the attribute name nis   limited to a finite set of the pre - defined schema ,   where attribute name extraction is typically mod-   eled as a classification task ( Zeng et al . , 2014 ; Zhou   et al . , 2016 ) , and attribute value extraction models   are trained for each target attribute ( Zheng et al . ,   2018 ; Zhu et al . , 2020 ; Yan et al . , 2021 ) . While for   OWA AE , which is also known as “ New Attribute   Discover ” ( Wong and Lam , 2010 ; Zhang et al . ,   2022 ) and “ Open Information Extraction ” ( Cui   et al . , 2018 ) , the attribute name is schema - free and   can be extracted from the text . Sequence tagging   methods are broadly employed to extract those at-   tributes ( Xu et al . , 2019 ) . Recently , researchers2139also explore novel paradigms such as Question An-   swering ( QA ) models ( Wang et al . , 2020 ; Shinzato   et al . , 2022 ; Yang et al . , 2022 ) and generative mod-   els ( Roy et al . , 2022 ) to generalize the ability of   attribute extraction .   However , AE in the real world is far more com-   plicated . On the one hand , in closely related fields   like e - commerce , new types of products with new   sets of attributes are so constantly arising that the   pre - defined schema is never enough . For exam-   ple , an analysis in Zhang et al . ( 2022 ) has shown   that only 30 / 51 attributes are found in existing   structured product profiles of Amazon ’s 10 product   types . On the other hand , however , attribute extrac-   tion methods should n’t overlook the huge value and   commonalities behind known attributes , and it is   inherent that not all attributes can be fully identified   by open extraction methods due to the lack of literal   name mentions , e.g. name and size in Figure 1 . It is   possible to carry out both CWA andOWA methods   when needed , just as Zhang et al . ( 2021 ) attempts   preliminarily . But apart from the fragmentation   of the problem form and the unnecessary comput-   ing overhead , a more prominent issue is that such   simple integration neglects the natural connections   between the CWA vocabulary and the OWA ability   in attribute extraction , and thus can not achieve sat-   isfactory results . In this paper , we , for the first time ,   explicitly unify the different AE paradigms in the   form of Attribute Tree , and present a text - to - tree   based generative model called AtTGen to solve the   real - world attribute joint extraction task .   Specifically , our proposed AtTGen successfully   implements the unification of attribute tagging   and classification tasks by generating the Attribute   Tree , and congenitally circumvents the problem of   “ null”-value that troubles pioneers ( Xu et al . , 2019 ;   Wang et al . , 2020 ) . Further , the head entity is op-   tional as the root node on Attribute Tree to meet the   actual situation , as well as to enhance the extraction   performance with the help of the subject guidance   ( Yu et al . , 2021 ; Zhang et al . , 2021 ) . AtTGen re-   duces the length of the generated sequence and   thus shrinks the search space by conducting the   tree generation model . And it can accurately mark   out the span of attribute values and extract unseen   attributes with the pointer - copy mechanism ( Zhou   et al . , 2018 ) . Moreover , the teacher forcing man-   ner(Williams and Zipser , 1989 ) and the converted   path - generation training objective further reduce   the exposure bias ( Zhang et al . , 2020 ) to improvethe generalization and effectiveness .   In short , the major contributions of this paper   can be summarized as follows :   •We are the first to define different attribute extrac-   tion paradigms like CWA , OWA and semi - open   as the attribute tree generation problem , formally   unifying multiple tasks and fully capturing the   internal connections .   •We design a novel text - to - attribute tree genera-   tion model with a pointer - based copy mechanism   for extracting both literal mentions and category   labels .   •We evaluate our model on several benchmark   datasets . Experimental results show that our   method achieves state - of - the - art ( SOTA ) and out-   performs existing works by a large margin in all   scenarios including open , semi - open and closed-   world attribute extraction .   2 Preliminary   We first formalize the definition of two mainstream   paradigms widely used in Attribute Extraction .   Definition 1 ( Closed - World Assumption ) .CWA AE   receives a descriptive text T= [ t , t , ... ] , e.g. a   product title , and a pre - defined schema Awhich   contains a set of attributes ( i.e. , attribute vocabu-   lary ) to extract all attribute pairs < n , v > for a pos-   sibly given head entity e , where n∈ A is the at-   tribute name ( also called attribute type ) , and v∈ T   is the attribute value extracted from the text .   Definition 2 ( Open - World Assumption ) .OWA AE   takes a descriptive text T= [ t , t , ... ] as input , and   the target is to discover all attribute pairs < n , v >   for a possibly given head entity e , where both the   attribute name nand the attribute value vare from   the given text , i.e. n∈ T andv∈ T.   As stated in Section 1 , individual one of the   above paradigms does not always work well in   real - world applications , and the pipeline approach   adopted by Zhang et al . ( 2021 ) to merge the results   of the two paradigms would introduce problems   such as cascading errors . Therefore , we propose a   formal definition of real - world AE and its solution   in the following sections .   3 Problem Formalization   Section 1 has expounded that attribute extraction in   real - world applications sometimes needs both the2140   guidance of the schema and the ability to extract   free attributes from texts . It is actually an extensive   aggregation covering both CWA and OWA AE , as   well as a semi - open scenario where attribute names   can be obtained from both . Therefore we formally   define the real - world attribute extraction as :   Definition 3 ( Real - world Attribute Extraction ) .   Given a text T , and an optional A , “ real - world   AE ” is to fill the explicit slots for the optional cate-   gory in A , or to dig more free attributes from T , or   to capture attributes from both AandT. i.e. , the fi-   nal result of real - world AE is a set of attribute pairs   < n , v > where v∈ T , n∈ H = { A,∅ } ∪ { T , ∅ }   andH ̸=∅.   To implement such an extraction paradigm uni-   formly , we devise a principled structure , Attribute   Tree , to formally model the target of all real - world   AE circumstances :   Definition 4 ( Attribute Tree ) .An attribute tree T   for a descriptive sentence sent is an unweighted   tree with a fixed height h= 2 . All the branches   of the tree Thave a determined order ( r , v , n ) , and   the root ris the only entry node that can be either   empty ∅or the head entity ( also called the subject )   subj of the attributes .   Figure 2 visualizes the attribute tree and its in-   stances . The path from the root to the leaves is also   the reasoning path of the proposed model . Borrow-   ing the notation from epistemology ( Martin - Löf ,   1996 ) , there are :   { sent , r } ⊢v   { sent , r , v } ⊢nr∈ { ∅ , subj } ( 1 )   which means the attribute value vis derived from   the original sentence sent and the root node r ; and   the attribute name n , whether coming from the   input text or the given schema , can be predicted   by the integrated information from the sentence ,   the attribute value , and the root node . This kind   of path order can naturally evade the insignificant“NULL ” value problem pointed out by Shinzato   et al . ( 2022 ) .   Definition 5 ( Subject Guidance ) .Setting the sub-   jectsubj of a descriptive sentence sent as the root   node rof the corresponding attribute tree Twhen   available , i.e. let r = subj in Equation 1 , is called   enabling the subject guidance .   As attributes typically characterize entities and   are strongly bound to the subject , we naturally in-   troduce the subject guidance for AE in such a way   and the effectiveness has been preliminarily demon-   strated in Yu et al . ( 2021 ) ; Zhang et al . ( 2021 ) .   4 Methodology   We design a unified tree generative model AtTGen ,   committing to jointly extracting attribute names   and values under various scenarios in the real world .   It is partially inspired by the success of Seq2Tree   models ( Dong and Lapata , 2016 ; Liu et al . , 2019 ;   Zhang et al . , 2020 ) and pointer - copy based span-   selector ( Zhou et al . , 2018 ; Ma et al . , 2022 ) in other   tasks . The overall architecture is shown in Figure   3 , and we demonstrate the model details in the   following subsections .   4.1 Encoder   We employ the classical BiLSTM - CNN ( Chiu and   Nichols , 2016 ) neural network to encode the in-   put text into a continuous latent space . Given a   sequence input [ t , t , ... , t ] , the encoded text rep-   resentation h∈Ris obtained by :   h = Encoder ( sent )   = Conv(BiLSTM(Emb ( sent))(2 )   in which Emb is to gain the embedded vector of   tokens from the lookup table and mis the dimen-   sion of the embedding , BiLSTMis Bidirectional   Long Short - Term Memory network ( Hochreiter   and Schmidhuber , 1997 ) for modeling the depen-   dencies of the input sequence , and Convis Con-   volutional Network ( Collobert et al . , 2011 ) for ex-   tracting features from the encoded text representa-   tion . Meanwhile , the category labels of attribute   names from the given schema also contain useful   semantic information for generating the attribute   tree , thus we use the same encoder to obtain the   label representation of the attribute names as :   h = Encoder ( labels ) ( 3)2141   Then we can concatenate the two parts and get   the initial root node representation as h=   Encoder ( [ sent||labels ] ) , which allows the succes-   sor decoders to uniformly generate nodes from both   the input sentence and the category label set .   In addition , the subject of the attribute would   be concatenated with the input sentence as   [ ⟨subject ⟩,[sep ] , t , ... , t]for the subject guid-   ance , in which [ sep]is a separator token .   4.2 Tree Decoder   The decoding target of our method is to generate a   structured attribute tree . As a tree can be divided   into several paths from the root node to the leaf   node , the generation of a tree can also be decom-   posed into the problem of generating multiple paths .   Therefore , the decoder of AtTGen is denoted as :   rs , h , s = Decoder ( T , h , s ) ( 4 )   where rsis the generated result , his the repre-   sentation of the decoded tokens , sandsare   the current and the previous state of the decoder   respectively . Each decoding step relies on several   inputs : ( 1 ) the target space of decoding T , which is   to limit the selection range of the final result of the   decoder and thus shrinks the search space ; ( 2 ) the   representation of the antecedent path h ; ( 3 ) the   state of the decoder s , used to determine the cur-   rently decoded node is at what level of the attribute   tree .   Specifically , given the input hand the previous   decoding state s , a unary LSTM is employed   for decoding the state sas :   s = LSTM(h , s ) ( 5)The decoding feature hfor generating results is   obtained by a convolutional network Convwith   an attention - based weighted sum like ( Bahdanau   et al . , 2015 ) as :   h = Conv(Att(h , s ) ) ( 6 )   Then the final result as follows is decoded from   the pointer - based span copier ( Ptr ) explained in   Section 4.3 :   i , i = Ptr(h),Ptr(h )   rs = T[i : i](7 )   The whole decoding process for AtTGen is de-   scribed in Algorithm 1 .   Algorithm 1 : Attribute Tree Decoder   where ∅is a randomly initialized vector to repre-   sent the initial decoding state . r , handsare the2142decoder ’s output for the root node ( the optional sub-   ject ) , representing the generated result , the hidden   representation and the current state respectively .   Similarly , ( v , h , s ) and ( n , h , s ) are the other   two sets of outputs from the decoder , for the decod-   ing process of attribute values and attribute names   respectively . Note that if subject guidance is en-   abled , the decoder will update hby decoding sub-   ject firstly , and construct the root node of the tree   ( Line 2 - 4 ) , otherwise the root node is replaced by a   placeholder ( Line 5 - 7 ) . The attribute values and at-   tribute names are sequentially decoded in the order   of Equation 1 to construct Attribute Tree as shown   in Line 8 - 15 in Algorithm 1 .   4.3 Span Copier   We propose to use a unified span copier to ensure   the spans are correctly copied from the original sen-   tence or the label set during the decoding process .   Ptr(h ) = σ(Wh+b )   Ptr(h ) = σ(Wh+b)(8 )   in which WandWare trainable weights , b   andbare trainable bias , hdenotes the hidden   state of the current decoding step , and σis the   sigmoid active function . The Ptrproduces a   constant vector that denotes the start / end index of   the copied span . For those nodes in the closed-   world setting whose mention does not exist in the   original text ( e.g. , name , size , and price in Figure   1 ) , we further add an equality constraint Ptr=   Ptr , restricting the pointers to select only one   category label when decoding from the label set ,   which reduces generative errors and improves the   training efficiency .   4.4 Training Objective   In the decoding process , we apply teacher forcing   manner ( Williams and Zipser , 1989 ) for efficient   training and encourage the model to reduce the   distance of all paths between the generated tree and   the ground truth :   L = δ / summationdisplayBCE(Ptr(h ) , y )   + /summationdisplay / summationdisplayBCE(Ptr(h ) , y )   where δ∈ { 0,1}indicates whether to enable the   subject guidance ; y / ydenotes the golden   standard start / end index of either a literal mentionor a category label of the target span ; hrepre-   sents the hidden state of the decoder to distinguish   the level it is decoding . BCE is the Binary Cross   Entropy loss to optimize the prediction of the index   vectors individually for each step:(y , y ) = −1   N / summationdisplayy·lny+(1−y)·ln(1−y )   where Nis the length of the input sentence , yis   the predicted probability of the i - th element and y   is the corresponding ground truth .   5 Experiments   5.1 Experimental Setup   Datasets . We conduct our experiments on three   publicly available datasets to examine the capacity   and the generality of our model over various real-   world AE settings :   MEPA VE ( Close - World Benchmark)(Zhu et al . ,   2020 ) is a multimodal e - Commerce product at-   tribute extraction dataset , which contains 87k prod-   uct description texts ( in Chinese ) and images , in-   volving 26 types of attributes . We follow the same   dataset settings as Zhu et al . ( 2020 ) , except that we   leave the visual information and use the description   texts only .   AE-110 K ( Open - World Benchmark)(Xu et al . ,   2019 ) is a collection of 110k product triples ( in En-   glish ) from AliExpress with 2,761 unique attributes .   It can well measure the open extraction ability and   generation performance of different models . We   split this dataset via the cleaning script of Shin-   zato et al . ( 2022 ) , and remove invalid and “ NULL ”   value attributes following Roy et al . ( 2022 ) .   Re - CNShipNet ( Semi - Open Benchmark ) is a re-   vised version of the functional attribute extraction   dataset CNShipNet(Zhang et al . , 2021 ) , where nu-   merical attributes account for the majority to bring   new challenges . We manually fix the incorrect an-   notations in the old version and rebalance the ratio   of closed- to open - setting labels ( Li et al . , 2021 ) .   Now it contains about 5k entity - attribute instances   ( mostly in Chinese ) , among which 40 % obtain at-   tributes from the literal texts and others are within   9 pre - defined attribute types .   Baselines . We compare the proposed model with   several strong and typical baselines including:21431 ) Sequence Tagging - based methods , a kind com-   monly adopted in IE which typically uses seman-   tic tags such as BIO to identify the extracted   items : RNN - LSTM ( Hakkani - Tür et al . , 2016 ) ,   Attn - BiRNN ( Liu and Lane , 2016 ) , and BiLSTM-   CRF ( Huang et al . , 2015 ) are all specially designed   RNN - based models for modeling the intent of clas-   sification and extraction tasks . ScalingUp ( Xu   et al . , 2019 ) is a BERT - based model to extract at-   tribute values with BiLSTM to perform interaction   attention between attribute names and values .   2 ) PLM - based methods : BERT ( Devlin et al . ,   2019 ) is a well - known pre - trained language model   ( PLM ) and we follow the vanilla setting of   classification and sequence tagging tasks , Joint-   BERT ( Chen et al . , 2019 ) is a variant of BERT to   solve slot filling and classification jointly .   3 ) Joint IE - based ( JE ) methods , which originate   from the entity - relation extraction task and typi-   cally extract entities and classify relations in a cas-   cading fashion : ETL - Span ( Yu et al . , 2020 ) and   CasRel ( Wei et al . , 2020 ) are two classic JE mod-   els for relation extraction and we adapt them to the   AE task here . SOAE ( Zhang et al . , 2021 ) achieved   SOTA on CNShipNet by merging the results of a   JE model and a classification model . JA VE ( Zhu   et al . , 2020 ) is an attention - based attribute joint   extraction model and M - JA VE further takes advan-   tage of multimodal information , and they were the   best models for MEPA VE .   4 ) Sequence Generative Model : We also implement   the latest word sequence generation method ( Roy   et al . , 2022 ) based on the large - scale pre - trained   BART ( Lewis et al . , 2020 ) model .   We conduct the baselines and adapt them to the   target datasets accordingly . See Appendix A for   implementation details .   Metrics . Following previous works ( Zheng et al . ,   2018 ; Xu et al . , 2019 ; Zhu et al . , 2020 ; Zhang et al . ,   2021 ) , we use F1 score as the metric and adopt   Exact Match criteria ( Wei et al . , 2020 ) , in which   only the full match to the ground truth is considered   correct . We report the results of attribute name and   value extraction respectively as Zhu et al . ( 2020 ) .   5.2 Main Results   This section presents the overall results of the mod-   els over various AE scenarios in Table 1 , 2 , and   3 . In general , we can observe that our model out-   performs the baselines over all three scenarios in   real - world AE .   As shown in Table 1 , our model achieves a big   improvement in the closed - world AE task . Even   though the previous SOTA model ( M - JA VE BERT   version ) introduces PLM and takes advantage of   extra multimodal information ( product images ) , we   still gain a 9.09 % improvement in attribute value   extraction and 5.79 % in attribute name prediction .   In the open setting shown in Table 2 , AtTGen   consistently performs well in attribute value ex-   traction , with a 6.45 % improvement than BART ,   an elaborate and dedicated PLM - based model . It   has a slightly lower result compared with BART   when extracting attribute names ( 0.86 % ) , due to   the absence of the semantic knowledge contained   in the large - scale PLMs for efficiency issues . We   will consider introducing such knowledge in fu-   ture work , which we believe will further improve   the performance . But the current results are still   strong enough to demonstrate the open extraction   capability of our model .   As for the semi - open scenario displayed in Table   3 , our model again outperforms CasRel , a strong   joint model in the information extraction field . We2144   also attain better results than SOAE , which was   the SOTA on this dataset by conducting both OWA   and CWA models . This can be credited to our   unified attribute tree model to naturally capture the   intrinsic connections in the partial - closed world .   It can be concluded that , as the first to design   a tree generative model in AE , our method can   be silkily adapted to different real - world scenarios   at a small cost , and achieves remarkable results   whether the dataset is in the e - Commerce domain   ( MEPA VE , AE-110 K ) or news ( Re - CNShipNet ) ,   and whether the language of the datasets is En-   glish ( AE-110 K ) or Chinese ( MEPA VE and Re-   CNShipNet ) . Moreover , unlike quite many base-   lines relying on external knowledge in the large-   scale language models , we achieve outstanding re-   sults by training from scratch , and thus has a dom-   inant advantage in the parameter - efficiency ( e.g. ,   BERT has ~110 M parameters , BART has ~139 M ,   AtTGen has only ~2 M ) . We hypothesize that the   superiority comes from the unified problem formal-   ization as well as the novel tree generation model   design . On the one hand , our model keeps the   simplicity as a generation model , providing a uni-   fied way to capture the semantic associations be-   tween open and closed vocabulary , and between   attribute names and values . On the other hand , dif-   ferent from traditional Seq2Seq models that decode   all triples autoregressively into a linear sequence ,   our tree structure decomposes the decoding target   into several paths of length three , removing the   unnecessary order among different triplets and ef-   fectively alleviating the exposure bias problem in   long - distance generation tasks ( Zhang et al . , 2020 ) .   Furthermore , we notice that the performance of   the models varies across different datasets , which   can be attributed to the varying levels of complexity   and quality of the datasets . For example , MEPA VE   is a well - annotated benchmark with only a small   number of attribute types , hopefully for better re-   sults . While AE-110 K suffers an inevitable long-   tail distribution problem , and Re - CNShipNet is   limited by the data scale and the uncertain ratio of   CWA /OWA labels , posing greater challenges and   leading to the results that all models still have a   large room for improvement .   5.3 Ablation Study   In this section , we carry out several ablation ex-   periments to study the effectiveness of each sub-   component in AtTGen . The whole results are listed   in Table 4 and we can find these phenomenons :   1 ) The performance reduces by 3.15 % on Re-   CNShipNet dataset without the subject guidance ,   indicating the usefulness to exploit the constraint   semantics of the subject in attribute extraction .   Along with the findings in Yu et al . ( 2021 ) ; Zhang   et al . ( 2021 ) , we may conclude that subject guid-   ance is a powerful enhancement in various infor-   mation extraction situations .   2 ) We remove the span copier by replacing it with   an ordinary token generator to extract values from   the whole vocabulary . It can be seen that the perfor-   mance drops by 8.75 % on average , and the degra-   dation is more evident in the open and semi - open   settings , where the performances are down to the   same level as other sequence tagging - based models .   This proves that the advantage of the model largely   comes from the copy mechanism to detect bound-   ary information of the spans rather than directly   modeling the attributes . We therefore say that span   copier can play a prominent role in AE .   3 ) We also explore the influence of the generation   order in Attribute Tree and the results show that   changing the path order from ( r , v , n ) to(r , n , v )   slightly reduces the effect ( 4.7 % averagely ) . Some-   what different from a prior experiment conducted2145 in ( Zhang et al . , 2020 ) , which shows that in entity-   relation joint extraction task , relations should come   first to get the best performance , our conclusion   here is that attribute values should be extracted   before attribute names , especially in open sce-   narios . One possible explanation for this difference   between relation and attribute extraction is that at-   tribute values typically have more evident patterns   to trigger the following attribute name prediction .   Besides , the path order of ( r , v , n ) is able to reduce   the confusion of multifarious attribute names and   well evades the “ NULL ” value problem .   4 ) Removing schema information directly deprives   the model ’s capacity to learn from the existing on-   tology , and significantly degrades its performance   on the Re - CNShipNet dataset , showing that pre-   defined schema can strengthen models ’ applica-   bility in real - world AE applications .   By these ablation studies , we have not only   demonstrated that each delicate design in our model   plays an important role , but proposed several inter-   esting findings which we believe will shed some   light for future research .   5.4 Case Study   We present two case studies from Re - CNShipNet   dataset to further illustrate our proposed Attribute   Tree and the effectiveness of AtTGen model , as   shown in Figure 4 . In the first case , the sentence   contains an out - of - schema attribute , “ sea trialed ” ,   which is ignored by the BERT - based extraction   model . While our AtTGen model , starting from a   given subject , identifies all attribute pairs including   the purely literal one by first listing all possible   attribute values and then smoothly corresponding   to names based on the value and the context . In   the other case , the number “ 158,700 ” is misex-   tracted as “ 700 ” by the Bert - based extractor due to   the interference of the thousands - separator . This   roots in the model ’s failure to really understand   numerical values , which is a unique challenge to   deep learning - based techniques ( Xue et al . , 2022 ) .   Nonetheless , AtTGen directly captures the bound-   ary pattern of numbers and successfully retains the   complete value with the span copier , showing a   possible solution for this challenge .   6 Related Works   Attribute Extraction is a classical IE task with   extensive research . In earlier years , heuristic   rules and dictionaries were usually used to iden - tify attributes and extract attribute values from the   texts ( Tan et al . , 1999 ; Sasaki and Matsuo , 2000 ;   Vandic et al . , 2012 ; More , 2016 ; Zheng et al . , 2018 ;   Yan et al . , 2021 ) . With the development of deep   learning for NLP , researchers attempt to leverage   neural network technology - based model for tag-   ging attributes ( Huang et al . , 2015 ; Hakkani - Tür   et al . , 2016 ; Mai et al . , 2018 ) or classifying attribute   types ( Riedel et al . , 2010 ; Zeng et al . , 2014 ; Am-   playo , 2019 ; Iter et al . , 2020 ; Zhao et al . , 2021 ) .   Beyond CWA AE , researchers also explore AE in   OWA scenario , e.g. , some prior works try to ex-   pand free attributes from plain texts ( Wong and   Lam , 2010 ; Zhang et al . , 2022 ; Cui et al . , 2018 )   and extract the values of schema - free attributes ( Xu   et al . , 2019 ) . Recently , more novel frameworks are   proposed to generalize the capacity of AE models .   A VEQA ( Wang et al . , 2020 ; Shinzato et al . , 2022 )   and MA VEQA ( Yang et al . , 2022 ) introduce Ques-   tion Answering framework for AE task , and Roy   et al . ( 2022 ) tries to employ large - scale PLM to   introduce external knowledge . Further , some aca-   demics propose multimodal AE tasks and datasets   to enrich the research ( IV et al . , 2017 ; Zhu et al . ,   2020 ) . Generative Information Extraction , a ris-   ing technique in these two years ( Ye et al . , 2022 ) ,   is also an inspiration for proposing this research . A   contemporaneous work ( Roy et al . , 2022 ) adopts se-   quence generation models and preliminarily shows   the potential of generative models in open - world at-   tribute extraction . Alongside sequence - based gen-   eration models , structure generation models are   also widely studied and have shown power in other   IE tasks . For example , REBEL ( Huguet Cabot   and Navigli , 2021 ) introduces a structure - linearized   model for relation extraction ; Seq2UMTree ( Zhang   et al . , 2020 ) conducts a sequence - to - unordered-   multi - tree generation model for extracting entities   and relations jointly ; UIE ( Lu et al . , 2022 ) proposes   a text - to - structure generation framework that can   universally model different IE tasks based on the   guidance of the pre - defined schema .   Though both attribute extraction and generative   models have been widely explored , we are the first   to design a novel tree generation model for AE   and demonstrate the effectiveness on our unified   real - world paradigm .   7 Conclusion and Future Work   In this paper , we formulate the real - world AE task   into a unified Attribute Tree , and propose a simple2146   but effective tree - generation model to extract both   in - schema and schema - free attributes from texts .   Experiments on three public datasets demonstrate   our prominent performance over various scenarios ,   and detailed analyses also reveal several interesting   findings for attribute extraction .   Several potential directions are left for the fu-   ture . The first one is that our current approach does   not utilize the commonly - provided multimodal in-   formation in e - Commerce , which can be naturally   introduced into our tree structure as nodes for bet-   ter results later . Besides , PLM has powerful effects   on understanding the semantics of texts and scaling   to open - domain AE applications , so incorporating   knowledge of different granularity from PLMs is   also an attractive extension to be explored .   8 Limitations   Adapting PLMs to our proposed model does not go   as smoothly as expected , because there are three   different forms of tokenization : the PLM tokenizer ,   the multilingual tokenizer implemented in our pro-   posed model , and the special annotations of numer-   ical values / entity mentions / long - winded attribute   values in the attribute extraction datasets , which   are difficult to reconcile simultaneously . Although   our model without PLM has outperformed PLM-   based ones , this does impose a limitation for future   explorations .   Although Re - CNShipNet , one of the datasets   used in our experiments , is more accurate with our   careful re - annotating , the size of which is still so   small that would produce randomness bias during   the model training and may affect the final experi-   mental results .   Besides , due to the limitation of computational   resources , we did not conduct experiments on largelanguage models such as T5 ( Raffel et al . , 2020 ) ,   LLaMA ( Touvron et al . , 2023 ) , etc . , which may   lead to insufficiency of the experiment .   Ethics Statement   This work uses three publicly available datasets ,   and we respect and adhere to their user agree-   ments and licenses . The content of pre - existing   datasets does not reflect our perspectives . We , the   in - house authors , re - annotate one of these datasets ,   i.e. , Re - CHShipNet ; the purpose of re - annotation   is mainly to correct errors and re - balance the ratio   ofCWA /OWA labels . The annotation may intro-   duce personal judgment and bias , which may bring   potential risks . Further , the potential downstream   applications of this work include knowledge graph   construction , search engine , e - Commerce , recom-   mendation system , etc . ; we caution that our pro-   posed method may cause misextraction or false   information , and may fail in the case of out - of-   distribution and domain shift , which may harm   those applications .   Acknowledgements   This work was supported by NSFC under grant   61932001 and U20A20174 . Lei Zou is the corre-   sponding author of this paper . We would gratefully   appreciate the reviewers for their precious com-   ments that help us to improve this manuscript .   References214721482149   A Implementation Details   We implement our model on PyTorch , and manu-   ally tune the hyper - parameters based on the dev   set . It is trained using Adam with the batch   size / learning rate / maximum training epoch set to   512/0.0002/40 . The model of the best epoch evalu-   ated on the dev set is saved as the final model . For   the encoder , we use 200 - dimensional embeddings ;   the 2 - layer BiLSTMis configured with 200 hid-   den state size , and the kernel size of Convis   set to 3 . For the decoder , we use a 1 - layer uni-   directional LSTMfor decoding the state , and   Convwith the same configuration of Conv   to extract the generative features . All the experi-   ments are performed on a cluster with Nvidia A40   GPUs , and we run each experiment 5 times with   different seeds , reporting the average scores to en-   sure reliability . For more implementation details ,   please refer to our publicly available repository at   https://github.com/lsvih/AtTGen .2150ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Section 8 ( Limitations ) .   /squareA2 . Did you discuss any potential risks of your work ?   Section 8 ( Limitations ) and Ethics Statement .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract and Section 1 .   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   Section 4 & Section 5 .   /squareB1 . Did you cite the creators of artifacts you used ?   Section 5 .   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   Ethics Statement Section .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   Section 5.1 .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   Ethics Statement Section .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   Section 3 .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   Section 5 .   C / squareDid you run computational experiments ?   Section 5 & Appendix A.   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   Appendix A & Section 5.22151 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   Appendix A & Section 5.1   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   Appendix A & Section 5.1   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   Appendix A.   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   No response .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   No response .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   No response .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   No response .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   No response.2152