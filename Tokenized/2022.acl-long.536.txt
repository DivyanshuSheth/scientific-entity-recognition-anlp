  Subhabrata Dutta   Jadavpur University   subha0009@gmail.comJeevesh Juneja   Delhi Technological University   creativityinczenyoga@gmail.com   Dipankar Das   Jadavpur University   dipankar.dipnil@gmail.comTanmoy Chakraborty   IIIT - Delhi   tanmoy@iiitd.ac.in   Abstract   Identifying argument components from un-   structured texts and predicting the relation-   ships expressed among them are two primary   steps of argument mining . The intrinsic com-   plexity of these tasks demands powerful learn-   ing models . While pretrained Transformer-   based Language Models ( LM ) have been   shown to provide state - of - the - art results over   different NLP tasks , the scarcity of manu-   ally annotated data and the highly domain-   dependent nature of argumentation restrict the   capabilities of such models . In this work ,   we propose a novel transfer learning strategy   to overcome these challenges . We utilize   argumentation - rich social discussions from   theChangeMyView subreddit as a source of   unsupervised , argumentative discourse - aware   knowledge by ﬁnetuning pretrained LMs on   a selectively masked language modeling task .   Furthermore , we introduce a novel prompt-   based strategy for inter - component relation   prediction that compliments our proposed ﬁne-   tuning method while leveraging on the dis-   course context . Exhaustive experiments show   the generalization capability of our method on   these two tasks over within - domain as well as   out - of - domain datasets , outperforming several   existing and employed strong baselines .   1 Introduction   Computational argument mining from texts is the   ﬁne - grained process of understanding opinion dy-   namics . In the most fundamental sense , argument   understanding requires the identiﬁcation of the   opinions posed and justiﬁcations provided to sup-   port or falsify them . Generally , automated argu-   ment mining is a multi - stage pipeline identiﬁed   with three general steps ( Lippi and Torroni , 2015 ;   Stab and Gurevych , 2017 ) – separating argumen-   tative spans from non - argumentative ones , classi - Figure 1 :   fying argument components , and inducing a struc-   ture among them ( support , attack , etc . ) . While   different argumentation models deﬁne different   taxonomies for argument components , popular ap-   proaches broadly categorize them as ‘ claims ’ and   ‘ premises ’ ( Stab and Gurevych , 2017 ; Egawa et al . ,   2019 ; Mayer et al . , 2020 ) . As these components are   not necessarily aligned to sentence - level segments   and can be reﬂected within clausal levels , the task   of argument component identiﬁcation requires a   token - level boundary detection of components and   component type classiﬁcation .   Context of argumentation in online discus-   sions . Online discussions originating from back-   and - forth posts from users reﬂect a rich interaction   of opinion dynamics on large scale . In Figure 1 , we   show a sample argument component annotation of   consecutive posts from two users . The token - level   granularity of components ensures that a single   sentence may contain multiple components of the   same ( in 1st post ) or different kinds ( in 2nd and 4th   posts ) . Moreover , two adjacent spans of texts , even   with the same argumentative role , can be deﬁned   as two separate components ( see the 4th post for   example ) . It is trivial to say that the meaning of   any post ( as well as its argumentative role ) is de-7774pendent on the context . To be speciﬁc , the third   post can be identiﬁed as argumentative ( a premise   in this case ) only when its predecessor post and its   components are taken as the context . Similarly , a   certain span of the ﬁrst post is quoted in the second   one signaling a concrete manifestation of dialogic   continuity . One may even observe the user - speciﬁc   argumentation styles : 1st user ( author of the ﬁrst   and third posts ) usually keeps claims and premises   in separate sentences , while the 2nd user prefers   to use multi - component , complex sentences . Exist-   ing studies on argumentation formalism recognize   such continuity and deﬁne inter - post component   relations ( Ghosh et al . , 2014 ; Hidey et al . , 2017 ) .   However , the previous approaches for automated   extraction , classiﬁcation and relating argumenta-   tive components work on individual posts only and   deﬁne the inter - post discourse in the later stages of   relation prediction .   This is trivially counter - intuitive for two major   reasons : ( i ) if we consider two text spans from sepa-   rate comments to be linked by some argumentative   relation , then there exists a continuity of discourse   between these spans and a model is likely to ben-   eﬁt if it decides the boundaries and types of these   two components conditioned on that continuous   information ; ( ii ) users carry their style of argumen-   tation ( simple consecutive sentences vs. long com-   plex ones , usage of particular markers like ‘ I think   that ’ etc . ) , and if the model is informed about these   while observing the complete conversation with   back - and - forth posts , it is more likely to extract   correct components easily .   Scarcity of labeled data . Irrespective of the do-   main , argument annotation is a resource - intensive   process . A few previous studies ( Habernal and   Gurevych , 2015 ; Al - Khatib et al . , 2016 ) attempted   to exploit a large amount of unlabeled data in a   semi - supervised fashion . However , such methods   require the components to be deﬁned at sentence-   level ( and thereby adding redundant spans into the   predictions ) as they perform some sentence similar-   ity matching to generate pseudo - labels . Pretrained   language models like BERT ( Devlin et al . , 2019 )   provide a workaround to handle the scarcity of   task - speciﬁc annotated data . A parameter - intensive   model is initially trained in a self - supervised man-   ner on a large bulk of text ; this pretraining enables   the model to learn general language representation ,   which is then ﬁnetuned on task - speciﬁc labeled   data . However , the amount of the latter still deter - mines the expressive power of such models ( Wang   et al . , 2020 ) .   Present work . Considering these challenges ,   we formulate a novel transfer learning method us-   ing Transformer - based language models . We use   large amount of unlabelled discussion threads from   Reddit ’s r / ChangeMyView ( CMV ) community as   the source of argumentative knowledge . Pretrained ,   Transformer - based language models are ﬁnetuned   on this dataset using a Masked Language Mod-   elling task . Instead of randomly masking tokens   to predict , we select several markers in the text   that are shown to signal argumentative discourse   in previous works ( Chakrabarty et al . , 2019 ; Eckle-   Kohler et al . , 2015 ) . The language models are   then made to predict these markers in the MLM   task , thereby learning to relate different compo-   nents of text according to their role in the argu-   mentation presented . We call this novel ﬁnetun-   ing method Selective Masked Language Modeling   ( sMLM ) . Furthermore , to explore the role of con-   text in argument mining , we use sMLM to ﬁnetune   a post - level language model based on BERT ( De-   vlin et al . , 2019 ) and RoBERTa ( Liu et al . , 2019 )   and a thread - level language model based on Long-   former ( Beltagy et al . , 2020 ) . We present efﬁcient   incorporation of several Reddit - speciﬁc structural   cues into the Longformer architecture . These ﬁne-   tuned language models are then used for two fun-   damental components of argument mining : token-   level argument component identiﬁcation ( ACI ) and   inter - component relation type prediction ( RTP ) . To   further utilize the sMLM -based training of the lan-   guage models , we propose a novel prompt - based   approach to predict relations among argument com-   ponents . We perform exhaustive experiments to   explore the efﬁcacy of our proposed methods for   argument mining in both in - domain andout - of-   domain benchmark datasets : manually annotated   Reddit discussions and scientiﬁc papers . Our exper-   iments show clear improvements achieved by our   methods ( 0:59and0:69F1 for ACI and RTP , re-   spectively ) over several state - of - the - art baselines .   2 Related Work   A general overview of argument mining can be   found in the survey articles by Lytos et al . ( 2019 )   and Lawrence and Reed ( 2019 ) . In the current   scope , we look into three major areas of research7775 in argument mining .   Argument component detection and classiﬁ-   cation . Previous studies have sought to address   argument boundary detection and component type   prediction either as separate , successive tasks in the   pipeline ( Stab and Gurevych , 2017 ) or jointly in a   single computational pass ( Eger et al . , 2017 ) . Stud-   ies also explored classical machine learning frame-   works like SVM - HMM ( Habernal and Gurevych ,   2017 ) , CRF ( Stab and Gurevych , 2017 ) , etc . with   rich manual feature engineering . With the de-   velopment of neural network - based algorithms ,   BiLSTM - CNN - CRF models emerged as a popular   choice ( Schulz et al . , 2018 ; Eger et al . , 2017 ; Chern-   odub et al . , 2019 ) . Very recently , large pretrained   language models like BERT have also been utilized   ( Mayer et al . , 2020 ; Chakrabarty et al . , 2019 ) .   Discourse markers for learning language rep-   resentation . Similar to our sMLM ﬁnetuning strat-   egy , Nie et al . ( 2019 ) proposed an unsupervised   sentence representation learning strategy where a   neural model is trained to predict the appropriate   discourse marker connecting two input sentences .   Using a set of 15 markers , they showed that such   a ﬁnetuning can help models in downstream NLI   tasks . Chakrabarty et al . ( 2019 ) used a distant su-   pervision approach using a single marker In my   honest opinion to ﬁnetune BERT on a large collec-   tion of ChangeMyView threads and then performed   argument component classiﬁcation . However , they   did not deal with the component identiﬁcation task   and performed classiﬁcation of already identiﬁed   components at sentence - level . Opitz and Frank   ( 2019 ) suggested that while identifying the rela-   tion between two components , these models often   rely more on the context and not the content of   the components ; discourse markers present within   the context provide strong signals for the relation   prediction task .   Argument mining over Reddit . A few recent   studies explored argumentation over Reddit . Hidey   et al . ( 2017 ) proposed a two - tier annotation scheme   of claim - premise components and their relations ,   deﬁning ﬁve different semantic roles of premises ,   using ChangeMyView discussion data . Egawa et al .   ( 2019 ) also analyzed semantic roles of argument   components over ChangeMyView threads ; however ,   their primary focus remained on the dynamics of   persuasion , similar to Dutta et al . ( 2020).3 Selective MLM ﬁnetuning of   Pretrained Language Models   Though pretrained language models are devel-   oped to overcome the problem of small annotated   data on different language processing tasks , they   still require task - speciﬁc ﬁnetuning for better re-   sults ( Wang et al . , 2020 ) . In the speciﬁc domain   of argument mining , annotated data is scarce , and   attempting to ﬁnetune a massive language model   with very small training data comes with the risk of   overﬁtting . Moreover , different datasets follow dif-   ferent strategies for annotation . We seek to devise   a novel transfer learning strategy where a given   Transformer - based pretrained language model is   directed to focus on argumentative discourse us-   ing large - scale , unlabelled data . We choose the   ChangeMyView ( CMV ) community as the source   of this transfer for two speciﬁc reasons : ( i ) it pro-   vides us with a large , readily available resource of   interactions strictly focused on debates around ver-   satile topics , and ( ii ) discussions in CMV contain a   mixture of dialogic continuity over successive turns   along with elaborate argumentation presented in a   single turn . We hypothesize that such a versatile   combination of discourse can make the language   model more generalizable over dialogic as well as   monologic argument mining tasks .   3.1 Discourse structure of CMV   Discussion forums like Reddit facilitate users to   begin a discussion with an initial post ( submis-   sions , in the case of Reddit ) and then comments   under that post to instantiate a discussion . Users   may post a comment in reply to the submission as   well as the already posted comments . A typical   discussion over Reddit forms a tree - like structure   rooted at the submission . Any path from the root   to a leaf comment can be perceived as an inde-   pendent dialogic discourse among two or multi-   ple users ; henceforth , we will call such paths as   threads . Formally , a thread Tis an ordered se-   quencef(u;P)ji;j2N;u2Ug , wherePis   a text object ( a submission when j= 1and a com-   ment , otherwise ) , uis the author of P , andUis   the set of all unique users engaged in the thread T.   For brevity , we indicate Pas a post in general .   The dialogic nature of discussions naturally as-   sumes this context to be the whole thread T. How-   ever , if we consider any two successive posts P   andPinT , they manifest the interests and   styles of two separate participants along with the7776discourse continuity of the overall thread , which   must be distinguished within the deﬁnition of the   context . To take into account the complete dialogic   context of the thread , we represent a thread as a sin-   gle contiguous sequence of tokens with each post   Pfrom userubeing preceded by a special token   [ USER -i]withi2f0;;jUj 1 g , to encode   which post is written by which user .   Reddit also offers users a quoting facility : users   can quote a segment from the previous post ( one to   which they are replying ) within their posts and em-   phasize that their opinions are speciﬁcally focused   on that segment . We delimit such quoted segments   with special tokens [ STARTQ ] and[ENDQ ] in the   quoting post to demarcate the dialogic discourse .   Chakrabarty et al . ( 2019 ) also used quoting as sig-   nals for following premises . Additionally , we re-   place URLs with the special token [ URL ] to inform   the presence of external references that often act as   justiﬁcations of subjective opinions .   3.2 Selective MLM ﬁnetuning   Masked Language Modeling is a common strategy   of training large language models ; a certain frac-   tion of the input tokens are masked and the model   is trained to predict them , consequently learning a   generalized language representation . Instead of ran-   domly selecting tokens to mask , we select speciﬁc   markers that might signal argumentative discourse .   While the model is trained to predict these mark-   ers , it learns the roles and relationships of the text   spans preceding and following them . Following   the work by Eckle - Kohler et al . ( 2015 ) , we select   multiple markers signaling Opinion , Causation , Re-   buttal , Fact presentation , Assumption , Summary ,   and some additional words , which serve multiple   purposes depending on the context .   As shown in Figure 2 , to predict the marker I   think in the ﬁrst post , the model needs to learn that   the following text span “ that most Jewish people    ” expresses the user ’s opinion on the topic . Sim-   ilarly , in the second post , for the input segment   “ hspaniSohspaniifhspani ” , to correctly pre-   dict the masked markers as Soandif , a language   model needs to learn the fact that the truth value of   the statement expressed in hspaniis conditioned   uponhspani , and this dependence is inferred from   hspani .   Effect of context sizes . CMV threads provide a   natural segmentation of the discourse context into   comment / post - level vs. thread - level . We seek to ex-   plore the effect of the context size at different mod-   ules of argument mining ( i.e. , argument component   detection and relation type prediction ) . For this ,   we use our proposed selective MLM approach to   ﬁnetune a pretrained RoBERTa / BERT - base model   in the comment / post - level regime , and train Long-   former models in the thread - level regime . Long-   former uses sparse , global attention ( i.e. , some to-   kens attend to all the tokens in the input sequence )   to capture the long - range dependencies . We use the   special tokens indicating the users ( c.f . Section 3.1 )   as the globally attending tokens for Longformer .   3.3 Argument component identiﬁcation   After ﬁnetuning the language model on the se-   lective MLM task , we proceed to our ﬁrst   task of identifying argument components in   threads . Since the detection is done in token-   level , we use the standard BIO tagging scheme :   for a component class htypei , the beginning   and the continuation of that component are   marked as B - htypeiandI - htypei , respectively ,   while any non - component token is labeled as O.   Therefore , if one uses the usual claim - premise   model of argumentation , the label set becomes   fB - claim;I - claim;B - premise;I - premise;Og .   3.4 Inter - component relation prediction   While identifying the relation between two given   related argument components , it is important to   understand the role of those text segments within   the context of the discourse . Furthermore , we seek7777   to utilize the knowledge acquired by a language   model in the sMLM ﬁnetuning step as well . Keep-   ing these two factors in mind , we propose a novel ,   prompt - based identiﬁcation of argument compo-   nents . This approach is inspired by recent popu-   larity of prompt - based ﬁne - tuning methods in the   community ( Liu et al . , 2021 ) . At its core , these   methods involve directly prompting the model for   the required knowledge , rather than ﬁne - tuning   [ CLS ] or mean - pooled embeddings . For exam-   ple , to directly use a model to summarise a text , we   can append " TL;DR : " to the text ( Radford et al . ,   2019 ) , and let the model generate tokens following   it ; we expect the next few tokens to constitute a   summary of all the previous text .   Since the underlying Transformer LMs have   been trained using some Cloze task ( i.e. , ﬁlling   the blanks from the context ) previously , it is more   natural for it to predict a token given a context .   However , there are two challenges : ( i ) one needs to   design a suitable prompt , and ( ii ) in case of classiﬁ-   cation tasks like RTP , it is challenging to perform   Answer Mapping , i.e. , to map all the possible to-   kens to some particular relation class . To tackle   these challenges , we design our proposed relation   prediction method in the following manner ( see   Figure 3 )   For each pair of related components , say ,   component-1 and component-2 , said by user - i and   user - j , respectively , where component-2 refers to   component-1 , we append to the thread , a promptwith the template : " [ USER - i ] said < component1 >   [ MASK ] [ MASK ] [ MASK ] [ USER - j ] said < com-   ponent2 > " ( we used three mask tokens since that   is the upper bound of the marker size used for   sMLM ) . We expect that the words predicted at   the masked position such as “ because ” , “ in spite   of what ” etc . would be indicative of the rela-   tion of the two components . For the example   thread shown in Figure 3 , in a zero - shot predic-   tion , sMLM -ﬁnetuned Longformer predicts " I " ,   " disagree " , " I " at the three masked positions . This   “ disagree " clearly corresponds to the undercutter   relation between the two components . In fact , the   base Longformer without sMLM ﬁnetuning pre-   dicts a space , a full stop and another space at the   three masked positions . This additionally proves   the efﬁcacy of the sMLM ﬁnetuning .   Instead of engineering a token - to - relation type   mapping , the predicted token embeddings at the   masked positions are concatenated and fed into a   linear layer to predict probabilities over the set of   relation types . This way , we allow the model to   learn and map from the token space to the relation   type space .   4 Experiment Setup   4.1 Dataset   For the sMLM ﬁnetuning , we use the subset of   Winning Args ( ChangeMyView ) ( CMV ) dataset   ( Tan et al . , 2016 ) provided in ConvoKit ( Chang   et al . , 2020 ) . We use 99 % of this data for train-   ing , and reserve 1 % for checking accuracy on the   sMLM task . The entire data consists of 3;051   submissions and 293;297comments posted in the   ChangeMyView subreddit by 34;911unique users .   We extract the threads from these posts following   the reply structure and end up with 120;031threads   in total .   To train and evaluate all the models for ACI and   RTP , we use the manually annotated Reddit dis-   cussion threads provided by Hidey et al . ( 2017 ) and   further extended by Chakrabarty et al . ( 2019 ) for   training and evaluation . The extended version of   this dataset contains 113CMV discussion threads   manually annotated with argument components fol-   lowing the standard claim - premise model .   Additionally , we use the argument annotated Dr.   Inventor Corpus ( Lauscher et al . , 2018 ) which   consists of 40 scientiﬁc publications from the ﬁeld   of computer graphics . There are three types of argu-   mentative components here : Background Claims7778(BC ) , consisting of claims from previous works   in the paper , Own Claim ( OC ) consisting of the   new claims made by the authors of the paper , and   Data . The Data class mainly consists of citations ,   references to ﬁgures , etc . This dataset has three   relation types , viz . , support , contradicts andse-   mantically same . Additional dataset details are   provided in Appendix A.   4.2 Baseline methods   ForACI , we consider two state - of - the - art token-   level argument identiﬁcation models : LSTM-   MTL . Eger et al . ( 2017 ) proposed an end - to - end ar-   gument mining architecture which uses a BiLSTM-   CNN - CRF sequence tagger to jointly learn compo-   nent detection , classiﬁcation , and relation parsing   tasks.LSTM - MData . Schulz et al . ( 2018 ) pro-   posed a BiLSTM - CNN - CRF based model which   aims to generalize argument mining using multi-   domain training data in an MTL setting . We aug-   ment our data with their original set of 6datasets .   ForRTP , as no prior work exists to the best   of our knowledge , we consider our own baselines .   First , we consider Context - less RoBERTa , a   pretrained RoBERTa model , which takes the two   components with a [ SEP ] token between them and   predicts the relation using [ CLS ] token ’s embed-   ding . It is context - less as only two components   without the surrounding context are used to predict   the label . Second , we consider Contextless QR-   Bert . This uses the same ﬁne - tuning methodology   asContextless RoBERTa and is initialized from   the pre - trained Quote - Response relation prediction   model of Chakrabarty et al . ( 2019 ) .   ForRTP , we try another traditional strategy , in-   stead of prompting , for our models : Mean Pool-   ing . The mean pooling approach ﬁrst ﬁnds an em-   bedding of each of the two related components by   averaging the Transformer embeddings at all token   positions within a component . These embeddings   are concatenated and passed into a linear layer for   predicting the type of relation between the two re-   lated components .   To further evaluate the efﬁcacy of our sMLM   training strategy , we ﬁnetune a pretrained Long-   former on the Winning Args Corpus , with the usual   MLM , i.e. , masking 15 % of tokens at random , in-   stead of selective masking . We call this the domain-   adapted Longformer , DA - LF .   4.3 Implementation details   We use the pretrained base version of Longformer   ( 12layers , 768model size ) . The size of the local   attention window was set to the default 512 . The   maximum sequence length was ﬁxed at 4096 .   Following the suggestions in Reimers and   Gurevych ( 2017 ) , we repeat our experiments on   the 5 different data splits . The scores reported in   the tables for various models correspond to the av-   erage value of the mean of 5 runs , over the last   5 epochs for that particular metric . We provide   additional implementation details in Appendix B.   5 Evaluation   We evaluate the models based on precision , recall ,   and F1 scores for predicting claims and premises .   For a more rigorous setting , we use exact match   of the whole span between gold and predicted la-   bels , i.e. , if the gold label is [ O , B - claim , I - claim ,   I - claim , I - claim , O ] then only the predictions [ O ,   B - claim , I - claim , I - claim , I - claim , O ] , or [ O , I-   claim , I - claim , I - claim , I - claim , O ] can be consid-   ered as true positives . We use the popular SeqE-   val ( Nakayama , 2018 ) framework .   5.1 Argument component identiﬁcation   Table 1 shows the results for argument component   identiﬁcation on the CMV Modes dataset . We com-   pare models based on their micro - averaged F1 over   the two component types ( claims , premises ) , and   token level accuracy . Firstly , we observe huge   difference in token - level accuracy scores as we   move from the existing best performing LSTM   based methods with accuracy of 0.54 to BERT,7779   having an accuracy of 0.62 . Such a difference   is expected since pretrained language models like   BERT provide a head - start in case of small datasets   like CMV Modes . Though the token - level accu-   racy increases , the micro - averaged F1 for exact   component match does not increase much till we   start using RoBERTa . Since pretrained Longformer   was trained originally from the RoBERTa check-   point ( Beltagy et al . , 2020 ) , we can conclude that   RoBERTa provides signiﬁcant performance gain   compared to BERT , owing to its larger training   data and protocol . Longformer trained with our   proposed sMLM ﬁnetuning clearly outperforms   the rest of the models in terms of overall F1 score   for component identiﬁcation . However , the effects   of selective MLM is more prominant in case of   thread - level context ( i.e , Longformer ) compared to   comment - level context ( i.e , RoBERTa ) .   We can observe that context plays different   roles for different component types : while sMLM -   ﬁnetuned Longformer and RoBERTa perform com-   parably for claim detection , in case of premises ,   the access to the complete context helps the Long-   former to perform better . We can observe a similar   trend in ACI - task on Dr. Inventor dataset ( see Ta-   ble 2 ) . While Base Longformer performs compara-   ble to its sMLM counterpart to detect Background   and Own Claims , sMLM provides a 4 point im-   provement in F1 score for the Data class which   plays a similar role of premises towards the claims .   Intuitively , textual segments expressing claims con-   tain independent signals of opinion that is less de-   pendent on the context ; pretrained language mod-   els might be able to decipher their roles without   additional information either from the thread - level   context ( in case of CMV Modes , speciﬁcally ) or en-   hanced relation - awareness induced by the sMLM   ﬁnetuning . However , identifying segments that   serve the role of premises to a claim intrinsically   depends on the claims as well as the discourse ex-   pressed in a larger context .   5.2 Relation type prediction   In Table 3 , we present the results for relation   type identiﬁcation on the CMV Modes dataset .   We again compare models based on their micro-   averaged F1 over all relation types . Firstly , we   consider the traditional mean pooling approach .   Within this approach , we observe a 3 point im-   provement for the sMLM pre - trained Longformer   on the 80 - 20 split , while maintaining same perfor-   mance on the 50 - 50 split . Furthermore , the prompt   based methods consistently outperform the mean   pooling one , irrespective of whether we use base   Longformer or sMLM pretrained one.7780   Within the prompting approach , we also observe   increased and consistent improvement in perfor-   mance due to sMLM pretraining on both 80 - 20   and 50 - 50 splits . The gap in micro - F1 scores be-   tween sMLM and base Longformer for 80 - 20 split   increases from 3 points in mean pooling to 5 points   in prompting ( 0 to 7 points improvements for 50-   50 split ) . As we can observe in Figure 4 , sMLM -   ﬁnetuned Longformer admits a very narrow margin   of variation on random splits , compared to the base   Longformer . Furthermore , sMLM ﬁnetuning con-   sistently outperforms domain - adapted ﬁnetuning   ( DA - LF ) , indicating the unique knowledge transfer   achieved by the former .   We hypothesise that this approach works bet-   ter as this regime models our ﬁnal RTP task , as a   task that is more natural ( in a sense similar to the   (  ; B) natural tasks of Saunshi et al . ( 2021 ) ) for a   Longformer model pre - trained with sMLM . Intu-   itively , the model learns to predict discourse mark-   ers at masked positions during sMLM pre - training   and during ﬁne - tuning on downstream tasks too ,   the model will naturally try to predict discourse   markers at the masked positions . The discourse   markers occurring at the masked positions are di-   rectly related to the relation between the two com-   ponents . For instance , when there is a “ but ” be-   tween two components , we know that the two com-   ponents present opposing views more or less . Here   again , we observe that sMLM does not hurt the   base performance under domain shift ( Table 4 ) .   We observe that the RoBERTa model performs   worse than Base - LF - prompt , which incorporates   the entire context of the thread . Also the ef-   fect worsens with reduced training set size , and   RoBERTa model performs worse by 7 points in   terms of micro - F1 for the 50 - 50 split . Furthermore ,   we observe that the mean pooling strategy , even   though it uses context , performs worse ( by 4 points   on 80 - 20 split ) than the context - less RoBERTa .   Though , our sMLM pretrained model , manages   to perform at par with the context - less RoBERTa   with the mean pooling strategy . This means , that   the using the right ﬁne - tuning method is essential .   Extra context can be utilised fully in longformer ,   only when pre - training and ﬁne - tuning tasks are   nicely aligned .   5.3 Dependence on the presence of markers   Following the analyses presented by Opitz and   Frank ( 2019 ) , we investigate whether the pres-   ence / absence of the markers used in the sMLM   step within the vicinity of the components play any   role in the ACI orRTP performances . Since the   relation type among component - pairs that reside   distant from each other are less likely to be inferred   by the presence of markers in the context , we anal-   yse the percentage of wrong predictions as we vary   the distance between two related components , in   Figure 5 . While error rate does vary proportion-   ally to the distance , we observe that sMLM - LF   consistently yields lower percentage of wrong pre-   dictions as we vary the distance between the related   components compared to base Longformer . This   clearly indicates the superior capability induced by   thesMLM ﬁnetuning to decipher the relationship   among components not linked by direct context   ( i.e. , not within a sentence or a single comment ) .   For the ACI task , however , we observe that the   absence of markers in the vicinity of the compo-   nents actually enables better identiﬁcation , both   in case of sMLM ﬁnetuned and pretrained Long-   former ( see Table 5 ) .   6 Conclusion   We presented the results for two important tasks   in the argument mining pipeline , viz . , ACI and   RTP . The experiments clearly elucidated the im-   portance of alignment between the downstream and   pre - trainig tasks , and the effect of various ways   of modelling the tasks . The importance of en-   tire thread ’s context in discussion forums , as well7781as how to incorporate that into transformer - based   models fruitfully has also been made clear .   Acknowledgements   The authors would like to thank Chris Hidey and   Smaranda Muresan , for clariﬁcations providing re-   garding their work . T. Chakraborty would like to   acknowledge the support of Ramanujan Fellowship ,   CAI , IIIT - Delhi and ihub - Anubhuti - iiitd Founda-   tion set up under the NM - ICPS scheme of the De-   partment of Science and Technology , India .   References77827783A Dataset Details   Stats for the CMV Modes dataset are provided in   Table 6 . These stats are obtained after truncation   of threads to 4096 token sequence length . Dur-   ing data analysis , we observed that several threads   share the same initial post ( submission ) . Hence , we   make sure that all threads with the same initial post   entirely lie in either the train split , or the test .   For both CMV Modes , and Dr. Inventor Cor-   pus , we only consider contiguous spans of texts as   single components , as opposed to the labelling in   the dataset . Discontiguous spans are re - labelled as   separate components and the model is trained and   tested with these new labels , instead .   For CMV Modes dataset , we add an extra   " continue " class of relations to denote relation   between two dis - contiguous spans of same ar-   gumentative component annotated in the data .   We group together various relation types anno-   tated in the CMV modes data into the 5 broad   classes as follows : support ( " continue " class and   " support " class ) , agreement ( " agreement " , " under-   stand " classes ) , direct attack ( " attack " , " rebuttal   attack " , " rebuttal " , " disagreement " classes ) , under-   cutter attack ( " undercutter " , " undercutter attack "   classes ) , partial ( " partial agreement " , " partial at-   tack " , " partial disagreement " classes ) . These group-   ings are based on the broad annotation guidelines   provided for the annotations of CMV Modes data .   For Dr. Inventor Corpus , due to the low number   ofsemantically same relations(44 ) compared to   support ( 4535 ) and contradicts ( 564 ) in the orig-   inal dataset , we add the label ( " parts - of - same " )   which indicates that two dis - contiguous spans be-   long to the same argumentative component to the   semantically same category . We also , merge to-   gether sections of papers to efﬁciently utilise 4096   token length of Longformer model . The detailed   statistics after truncation to 4096 sequence length   are presented in Table 7 .   B Implementation Details   We use the pretrained base version of Longformer   ( 12layers , 768model size ) . The size of the local   attention window was set to the default 512 . The   maximum sequence length was ﬁxed at 4096 . We   added the special tokens that we used , to the pre-   trained Longformer tokenizer . For ACI our models   use a CRF layer.sMLM training for Longformer   based models was done on thread level and for   BERT and RoBERTa based models on comment-   level . We used mini - batch learning ; approximately   similar length input threads were batched together   keeping the total number of tokens per batch ﬁxed   to8;194for Longformer and 1024 for BERT and   RoBERTa models , and accumulated gradients over   3 batches .   We trained our models for a total of 10epochs   on sMLM task , while saving checkpoints after each   epoch . We used Adam optimizer with a learning   rate of 10 . For all downstream tasks , we train   our models for 30epochs , again , with Adam opti-   mizer with learning rate of 2e 5as suggested by   Mosbach et al . ( 2021 ) . We use same batch sizes   assMLM training and accumulate gradients over   4 batches . We observe that for prompting RTP on   CMV - Modes , not making [ USER - i ] tokens global ,   leads to better performance , hence we report results   for same .   We ﬁnd that sMLM training for 4 epochs is   most beneﬁcial , for performance on downstream   task . Hence , we report results for the same check-   point . Following the suggestions in Reimers and   Gurevych ( 2017 ) , we repeat our experiments on 5   different data splits and present the distributions   in the Appendix . For the results at any epoch ,   the score plotted corresponds to mean over the 57784   runs , and error regions correspond to the Bessel   corrected standard deviation . The scores reported   in the tables for various models correspond to the   average value of the mean of 5 runs , over the last   5 epochs for that particular metric . Table 8 pro-   vides examples of markers of various kinds , that   are masked during the sMLM training .   C Additional results77857786