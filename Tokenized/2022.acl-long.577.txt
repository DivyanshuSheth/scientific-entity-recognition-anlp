  Katherine Lee† Daphne Ippolito†‡ Andrew Nystrom† Chiyuan Zhang†   Douglas Eck† Chris Callison - Burch‡ Nicholas Carlini†   Abstract   We ﬁnd that existing language modeling   datasets contain many near - duplicate exam-   ples and long repetitive substrings . As   a result , over 1 % of the unprompted out-   put of language models trained on these   datasets is copied verbatim from the train-   ing data . We develop two tools that allow   us to deduplicate training datasets — for exam-   ple removing from C4 a single 61 word En-   glish sentence that is repeated over 60;000   times . Deduplication allows us to train mod-   els that emit memorized text ten times less   frequently and require fewer training steps   to achieve the same or better accuracy . We   can also reduce train - test overlap , which af-   fects over 4%of the validation set of stan-   dard datasets , thus allowing for more accurate   evaluation . Code for deduplication is released   athttps://github.com/goog/l.Vare-research/   dedup / l. Varicate - text - datasets .   1 Introduction   A key factor behind the recent progress in natural   language processing is the development of large-   scale text corpora used to train increasingly large   language models . These datasets have grown from   single gigabytes to as much as a terabyte over the   past few years ( Chelba et al . , 2013 ; Xue et al . , 2020 ;   Graff et al . , 2003 ; Brown et al . , 2020 ) . Because   it is so expensive to perform manual review and   curation on massive datasets , they tend to suffer   in quality compared to their smaller predecessors .   This has implications far beyond metrics like per-   plexity and validation loss , as learned models re-   ﬂect the biases present in their training data ( Ben-   der et al . , 2021 ; Wallace et al . , 2019 ; Sheng et al . ,   2020 ) . Quantitatively and qualitatively understand-   ing these datasets is therefore a research challenge   in its own right ( Dodge et al . , 2021a).We show that one particular source of bias , du-   plicated training examples , is pervasive : all four   common NLP datasets we studied contained dupli-   cates . Additionally , all four corresponding valida-   tion sets contained text duplicated in the training   set . While naive deduplication is straightforward   ( and the datasets we consider already perform some   naive form of deduplication ) , performing thorough   deduplication at scale is both computationally chal-   lenging and requires sophisticated techniques .   We propose two scalable techniques to detect   and remove duplicated training data . Exact sub-   string matching identiﬁes verbatim strings that are   repeated . This allows us to identify cases where   only part of a training example is duplicated ( § 4.1 ) .   Approximate full document matching uses hash-   based techniques ( Broder , 1997 ) to identify pairs   of documents with high n - gram overlap ( § 4.2 ) .   We identify four distinct advantages to training   on datasets that have been thoroughly deduplicated .   1.Over 1%of tokens emitted unprompted from   a model trained on standard datasets ( e.g. , C4 )   are part of a memorized sequence ( See § 6.2 ) —   even though the 1.5 billion parameter model   is much smaller than the 350 GB dataset it   was trained on . By deduplicating the training   dataset we reduce the rate of emitting memo-   rized training data by a factor of 10.   2.Train - test overlap is common in non-   deduplicated datasets . For example , we ﬁnd a   61 - word sequencein C4 ( Raffel et al . , 2020 )   that is repeated 61;036times verbatim in the   training dataset and 61times in the validation   set ( 0:02 % of the samples in each dataset ) .   18424This train - test set overlap not only causes re-   searchers to over - estimate model accuracy , but   also biases model selection towards models   and hyperparameters that intentionally overﬁt   their training datasets .   3.Training models on deduplicated datasets is   more efﬁcient . Processing a dataset with our   framework requires a CPU - only linear - time   algorithm . And so because these datasets are   up to 19 % smaller , even including the dedu-   plication runtime itself , training on dedupli-   cated datasets directly reduces the training   cost in terms of time , dollar , and the environ-   ment ( Bender et al . , 2021 ; Strubell et al . , 2019 ;   Patterson et al . , 2021 ) .   4.Deduplicating training data does not hurt   perplexity : models trained on deduplicated   datasets have no worse perplexity compared   to baseline models trained on the original   datasets . In some cases deduplication reduces   perplexity by up to 10 % . Further , because re-   cent LMs are typically limited to training for   just a few epochs ( Radford et al . , 2019 ; Raffel   et al . , 2020 ) , by training on higher quality data   the models can reach higher accuracy faster .   To summarize , data duplication offers signiﬁcant   advantages and no observed disadvantages . In the   remainder of this paper we present our text dedu-   plication framework in § 4 , and study the extent of   duplicate content in common NLP datasets ( e.g. ,   C4 , Wiki-40B , and LM1B ) in § 5 . We then exam-   ine the impact of deduplication on test perplexity   ( § 6.1 ) and on the frequency of emitting memorized   content ( § 6.2 ) . Finally , we analyze to what ex-   tent perplexity on existing , released models are   skewed as a result of overlap between the train and   test / validation splits ( § 6.3 ) .   2 Related Work   Large language model datasets . While we be-   lieve our results are independent of model archi-   tecture , we perform our analysis on Transformer-   based decoder - only language models ( Vaswani   et al . , 2017 ) trained for open - ended text generation .   These current state - of - the - art models are trained   on internet text . For example , the GPT-2 family   of models Radford et al . ( 2019 ) is trained on Web-   Text , a dataset of web documents highly ranked on   Reddit — however this dataset was not made avail-   able publicly . A common dataset starting pointis CommonCrawl , an index of public webpages .   Among the models trained on CommonCrawl in-   clude GPT-3 ( Brown et al . , 2020 ) with the addition   of book datasets , GROVER ( Zellers et al . , 2019 ) on   a restricted subset ﬁltered to news domains called   RealNews , and T5 ( Raffel et al . , 2020 ) on a cleaned   version of common crawl called C4 . Other models   are trained on more curated Internet sources — for   example Guo et al . ( 2020 ) used high quality pro-   cessed Wikipedia text from 40 different languages   to train monolingual 141.4 M parameter language   models . Non - English models necessarily use dif-   ferent datasets ; Zeng et al . ( 2021 ) for instance in-   troduced PANGU-  , a family of models with up to   200B parameters that were trained on a non - public   corpus of cleaned and ﬁltered Chinese - language   documents from CommonCrawl and other sources .   Since many of these datasets are not public , we   deduplicate three that are : Wiki-40B , C4 , and   RealNews – as well as the One Billion Word Lan-   guage Model Benchmark ( Chelba et al . , 2013 ) , a   smaller dataset commonly used for evaluation .   Contamination of downstream tasks . When   models are trained on datasets constructed by crawl-   ing the Internet , it is possible the model will train   on the test set of downstream target tasks . For ex-   ample , Radford et al . ( 2019 , § 4 ) performed a post-   hoc analysis to identify 8 - gram overlaps between   GPT-2 ’s training set and datasets used for evalu-   ation , and Dodge et al . ( 2021b ) analyzed C4 and   found that up to 14.4 % of test examples for various   standard tasks were found verbatim ( normalizing   for capitalization and punctuation ) in the dataset .   A more proactive approach removes contaminated   data . Trinh and Le ( 2018 , Appendix B ) removed   documents from their CommonCrawl - based train   set that overlapped substantially with the common-   sense reasoning used for evaluation . And GPT-3   ( Brown et al . , 2020 , § 5 ) did the reverse and re-   moved downstream evaluation examples from their   training data by conservatively ﬁltering out any   train set examples with a 13 - gram overlap with   any evaluation example . Up to 90 % of tasks were   ﬂagged as potentially contaminated .   In our research , we do not focus on the impact of   duplicate text in pretrained models on downstream   benchmark tasks ; instead we address how duplicate   text in the LM training and validation sets impacts   model perplexity and the extent to which generated   text included memorized content .   28425Memorizing training data . The privacy risks of   data memorization , for example the ability to ex-   tract sensitive data such as valid phone numbers   and IRC usernames , are highlighted by Carlini et al .   ( 2020 ) . While their paper ﬁnds 604 samples that   GPT-2 emitted from its training set , we show that   over1%of the data most models emit is memorized   training data . In computer vision , memorization of   training data has been studied from various angles   for both discriminative and generative models ( e.g.   Arpit et al . , 2017 ; Webster et al . , 2019 ; Feldman   and Zhang , 2020 ; Stephenson et al . , 2021 ; Teter-   wak et al . , 2021 ) .   Duplicate text in training data . The Book Cor-   pus ( Zhu et al . , 2015 ) , which was used to train pop-   ular models such as BERT , has a substantial amount   of exact - duplicate documents according to Bandy   and Vincent ( 2021 ) . Allamanis ( 2019 ) shows that   duplicate examples in code datasets cause wors-   ened performance on code understanding tasks .   3 Language Modeling Datasets   We analyze the presence of duplicate text in four   datasets of varying sizes that have been used for   training natural language generation systems , pro-   ducing general - purpose pre - trained models , and for   language model benchmarking . While this paper   restricts itself to English datasets , we expect that   non - English datasets suffer from similar issues and   could likewise beneﬁt from de - duplication .   Wikipedia ( Wiki-40B ) consists of multi - lingual   cleaned Wikipedia text ( Guo et al . , 2020 ) . We   take the English portion , which contains 2.9 M   Wikipedia pages with an average length of 768 BPE   tokens . The dataset creators do not indicate any   deduplication was performed aside from removing   redirect - pages ( e.g. , “ sunﬂower ” to “ Helianthus ” ) .   One - Billion Word benchmark ( LM1B ) con-   tains 30 M sentences of news commentary ( Chelba   et al . , 2013 ) . Unlike the other datasets we analyze ,   LM1B ’s examples are one sentence long rather   than multi - sentence documents . The average ex-   ample length is 32 BPE tokens . While this dataset   is extremely standard for benchmarking language   models , Radford et al . ( 2019 , Sec 4 ) note it has   13.2 % overlap of the test set with the train set .   Colossal Cleaned Common Crawl ( C4 ) is   made up of 360 M web documents , with an average   length of 486 BPE tokens ( Raffel et al . , 2020 ) . C4was introduced as a pre - training dataset for T5 , a set   of encoder - decoder models which have been widely   used in ﬁne - tuned downstream tasks . The dataset   was previously deduplicated in a more sophisti-   cated process than the prior two datasets . Each   paragraph was hashed and paragraphs resulting in   hash collisions were removed . This was followed   by a pass that removed placeholder text , code , and   prohibited words . See Dodge et al . ( 2021a ) for a   detailed breakdown of the source text in C4 .   RealNews is a subset of the Common Crawl con-   sisting of articles from news domains ( Zellers et al . ,   2019 ) . It contains 31 M documents with average   length 793 BPE tokens . RealNews was dedupli-   cated by inserting a hash of the ﬁrst 100 characters   of each document into a bloom ﬁlter ( Bloom , 1970 )   and then excluding any document which resulted in   a hash collision . Like C4 , examples with duplicate   URLs were excluded .   4 Methods for Identifying Duplicates   The simplest technique to ﬁnd duplicate examples   would be to perform exact string matching between   all example pairs , but as we will show , this is insuf-   ﬁcient . We introduce two complementary methods   for performing deduplication . First , using a suf-   ﬁx array ( Manber and Myers , 1993 ) , we remove   duplicate substrings from the dataset if they oc-   cur verbatim in more than one example . Second ,   we use MinHash ( Broder , 1997 ) , an efﬁcient algo-   rithm for estimating the n - gram similarity between   all pairs of examples in a corpus , to remove entire   examples from the dataset if they have high n - gram   overlap with any other example .   We consider a dataset D = fxgas a collec-   tion of examplesx . Each of these examples is itself   a sequence of tokens : x=   x;x;;x   .   4.1 Exact Substring Duplication   Due to the diversity of possibilities in human lan-   guage , it is rare for the same idea to be expressed   identically in multiple documents unless one ex-   pression is derived from the other , or both are quot-   ing from a shared source . This observation moti-   vates deduplicating exact substrings . We call our   approach E S . When two examples   xandxshare a sufﬁciently long substring ( that   is , a substring for which x = x ) , that   substring is removed from one of them . Based   on statistical analyses ( § B ) , we select k= 50 to-   kens as the minimum matching substring length .   38426A breakdown of the computation needed for this   approach can be found in Appendix B.   4.1.1 Sufﬁx Arrays   This exact - substring - matching criterion , while con-   ceptually simple , is computationally prohibitive   with naive ( quadratic ) all - pair matching . To im-   prove the efﬁciency , we concatenate all the exam-   ples of the entire dataset Dinto a giant sequence S ,   and construct a Sufﬁx Array AofS. A sufﬁx array   ( Manber and Myers , 1993 ) is a representation of a   sufﬁx tree ( Weiner , 1973 ) that can be constructed   in linear time inkSk ( Kärkkäinen and Sanders ,   2003 ) and enables efﬁcient computation of many   substring queries ; in particular , they allow us to   identify duplicated training examples in linear time .   Sufﬁx arrays have the advantage over sufﬁx trees   in that they are 10–100 more memory efﬁcient   ( Manber and Myers , 1993 ) , requiring just 8 bytes   per input token , though they are asymptotically   less efﬁcient for some query types . They have been   used widely in NLP , such as for efﬁcient TF - IDF   computation ( Yamamoto and Church , 2001 ) and   document clustering ( Chim and Deng , 2007 ) .   The sufﬁx array Afor a sequenceSis a   lexicographically - ordered list of all sufﬁxes con-   tained in the sequence . Formally ,   A(S ) = arg sort all_sufﬁxes ( S )   For example , the sufﬁxes of the sequence “ banana ”   are ( “ banana ” , “ anana ” , “ nana ” “ ana ” , “ na ” , “ a ” )   and so the sufﬁx array is the sequence ( 6 4 2 1 5 3 ) .   In practice , we construct Sfrom the bytes of the   BPE tokenization of the text ( § 6 ) .   4.1.2 Substring matching   After constructing A , it is straightforward to iden-   tify duplicated training examples . Suppose that   the sequence swas repeated exactly twice in the   training datasetSat positions iandj , that is ,   S = S. Then the indices i;jwill occur   adjacent to each other in the sufﬁx array A.   Finding all repeated sequences is thus a matter of   linearly scanning the sufﬁx array from beginning to   end and looking for sequences A;Athat share   a common preﬁx of at least some threshold length .   Any satisfying sequences are recorded . This al-   gorithm is embarrassingly parallel , and so we can   efﬁciently process the dataset . Based on experi-   mentation ( Appendix B ) , we choose a threshold   length of 50 BPE tokens for all experiments.4.2 Approximate Matching with MinHash   We also perform approximate deduplication based   on matching entire examples . This method , which   we call ND , is a good complement to the   exact substring matching , especially for web crawl   text , as it handles the very common case of docu-   ments being identical except for interspersed tem-   plated ﬁelds ( such as the last row of Table 1 ) .   MinHash ( Broder , 1997 ) is an approximate   matching algorithm widely used in large - scale   deduplication tasks ( Versley and Panchenko , 2012 ;   Gabriel et al . , 2018 ; Gyawali et al . , 2020 ) , in-   cluding to deduplicate the training set for a large   Chinese - language LM ( Zeng et al . , 2021 ) . Given   two documents xandx , the main idea is to repre-   sent each document by its respective set of n - grams   dandd . We can then use hash functions to ap-   proximate the Jaccard Index ( Jaccard , 1912 ):   Jaccard(d;d ) = =   If the Jaccard Index between danddis sufﬁ-   ciently high , it is likely that documents are approx-   imate matches of each other . To efﬁciently approx-   imate the Jaccard index , MinHash constructs doc-   ument signatures by sorting each of the n - grams   via a hash function , and then keeping only the k   smallest hashed n - grams . There are multiple ways   to construct estimators of the Jaccard index from   these kinds of signatures ( Cohen , 2016 ) .   In our implementation , we use 5 - grams and a   signature of size 9,000 . The probability that two   documents are considered a potential match is   Pr(d;djJaccard(d;d ) = s ) = 1 (1 s )   whereb= 20 andr= 450 are user - settable pa-   rameters to control the strength of the ﬁlter . See   Appendix A for more details .   For each pair of documents identiﬁed as a poten-   tial match , more computationally expensive similar-   ity metrics can be employed as a subsequent ﬁlter-   ing step . In particular , we identify two documents   as duplicates if they are matched by the MinHash   algorithm and their edit similarity is greater than   0.8 . The edit similarity between token sequences   xandxis deﬁned as :   EditSim(x;x ) = 1 EditDistance ( x;x )   max(jxj;jxj )   To build clusters of similar documents , we con-   struct a graph that has an edge between two doc-   uments if they are considered a match . Then , we   48427   use the method introduced in Ł ˛ acki et al . ( 2018 ) to   identify connected components . A breakdown of   the computation needed is given in Appendix A.   5 Deduplication Results   We deduplicate each of the four datasets with both   of our two techniques . When text was duplicated   across multiple data splits , we prioritized keeping   a copy in the test or validation set and removing it   from the train set .   5.1 Amount of Text Removed   With ND , we found that the web - scrape   datasets contain between 3.04 % ( on C4 ) to 13.63 %   ( on RealNews ) near duplicates ( Table 2 ) . Near-   duplicate text is much less common in Wiki-40B ,   forming only 0.39 % of the train set . In C4 , the ma-   jority ( 1.8 M ) of near - duplicate clusters consisted of   just a single pair of examples that matched against   each other , but there were 280 clusters with over   5,000 examples in them ( Figure 1 ) , including one   cluster of size 250,933 .   On average with E S , we remove   more total content than with ND(de-   spite E S not removing any examples   outright)—for example removing 7:18 % of the to-   kens in C4 . The exception is LM1B , where E - S removes 8less data than ND .   On investigation , we ﬁnd this is due to the fact that   LM1B documents are signiﬁcantly shorter : 90 %   of all documents are under 50 tokens , and so are   not even candidates for potential matches even if   the entire sequence matched verbatim . We ﬁnd   that both NDandE S remove   similar content — 77 % of the training examples that   NDremoves from C4 have at least one ver-   batim length- 50match found by E S .   584285.2 Properties of Duplicated Text   While the authors of both RealNews and C4 ex-   plicitly attempted deduplication during dataset con-   struction , the methods were insufﬁcient to capture   the more subtle types of duplicate text commonly   found on the internet . In C4 and Wiki-40B , we   qualitatively observe that much of the text identi-   ﬁed as near - duplicated is computer - generated . The   text is identical except for the names of places , busi-   nesses , products , dates , and so on . Because these   examples frequently differ by just a few words at   a time , deduplication strategies relying on exact   string matching would fail to identify a match . Ex-   ample duplicate pairs from each dataset can be   found in Table 1 ( more examples in the Appendix ) .   For RealNews and LM1B , derived from news   sites , we observe that many near - duplicates occur   because the same news article appears on multiple   news sites with slightly different formatting . For   example , in LM1B , there is one example that starts   “ MINEOLA , N.Y. - New York ofﬁcials say [ ... ] ” and   another that starts “ ( AP ) - New York ofﬁcials say   [ ... ] ” . The two examples are otherwise identical .   5.3 Train / Test Set Leakage   Both deduplication methods identify overlap be-   tween the train set and the validation set ( Table 2 ) .   For example , 4.6 % of the C4 validation set and   14.4 % of the RealNews validation set examples   had an approximate duplicate in their respective   training sets . Such duplication is problematic since   it could cause evaluation metrics to be unfairly in-   ﬂated for models that are better at memorizing their   train sets . We evaluate the effect of this leakage on   publicly released models in Section 6.3 .   6 Impact on Trained Models   . We trained 1.5B parameter “ XL " , decoder-   only , Transformer - based language models similar   to GPT-2 , on C4- O , C4- ND , and   C4 - E S , respectively . We use the T5   codebase and model architecture from Raffel et al .   ( 2020 ) , and each model was trained for about two   epochs on its respective dataset . To better under-   stand the amount of variance in the perplexities   of trained models , we also trained three different   random seeds of the 110 M parameter “ base " model   for each of the above three datasets — for a total of   nine base - sized models .   For all experiments , we used a Byte Pair Encod-   ing ( BPE ) vocabulary trained on C4- ND   with a budget of 50 K tokens , which resulted in a   vocabulary the same size as GPT-2 ’s . We trained   with a maximum sequence length of 512 tokens   ( for longer documents , we randomly extracted sub-   sequences of this length . ) Further training details   can be found in Appendix C.   6.1 Model Perplexity   We computed the perplexity of our trained mod-   els on the validation sets of LM1B and Wiki-40B ,   and on subsets of the C4 validation set ( Figure 2 ) .   For the base size , we observe that all models have   similar perplexity on the original C4 validation set   and on validation set examples that were identi-   ﬁed as unique ( no near - duplicate in either train   or validation ) . However , both models trained on   deduplicated data have signiﬁcantly higher perplex-   ity on validation set examples that have duplicates   in the training set than the model trained on the   original C4 . E S -deduplicated results   in higher perplexity than ND - deduplicated .   These trends holds true for the XL sized model as   well . While this may suggest E S du-   plication results in models least overﬁt on the train   set , note that both of these techniques have used   separate duplicate thresholds and a different choice   of thresholds could change the results .   When evaluating on the validation sets of LM1B   and Wiki-40B , we found that models trained on   ND - deduplicated C4 consistently achieved   lowest perplexity ( for LM1B eval with base models ,   see Appendix Figure 7 ) . E S dedupli-   cation decreases perplexity of the XL model by   almost 3 points perplexity on Wiki-40B which is   68429   much larger than the variation of about 1 point per-   plexity we observed in the base models . This is   despite seeing fewer tokens of training data overall .   Lastly , we note all our XL models achieved < 35   perplexity on LM1B , which is less than the 42.16   perplexity reported for the 1.5B GPT-2 using a   vocabulary the same size as ours .   6.2 Generated Text   Data duplication has the effect of biasing the   trained LM towards particular types of examples .   This can contribute to a lower diversity of genera-   tions , and increased likelihood that the generated   content is copied from the training data ( Carlini   et al . , 2020 ) . For our generation experiments , we   use top - krandom sampling with k= 50 and exper-   iment with prompted and unprompted generation .   No prompt . We ﬁrst evaluate memorization ten-   dencies in the case where the model is asked   to generate text without any prompt sequence .   We generate 100,000 samples , each up to 512   tokens in length ( examples provided in the Ap-   pendix ) . For each generated token , we say the   token is memorized if it is part of a 50 - token sub-   string that is exactly contained in the training data .   On XL- O , over 1 % of the generated to-   kens belong to memorized sub - sequences ( see Ta-   ble 4 ) . This is10more memorization than XL-   E S or XL- ND . Some example   subsequences that were copied verbatim from the   train set can be found in Table 9 in the Appendix .   With prompting . In most real use cases , lan-   guage model generation is controlled by providing   a prompt for the model to continue . We experi-   ment with four possible prompt sources : training   examples identiﬁed by E S as having   near - duplicates in the train set ( train dup ) , train-   ing examples identiﬁed as unique ( train unique ) ,   validation set examples with a near - duplicate in   the train set ( valid in train ) , and validation set ex-   amples identiﬁed as unique across all splits ( valid   unique ) . We select the ﬁrst 32 tokens of each exam-   ple as the prompt , which means we can evaluate the   fraction of generations which are near - duplicates   with the ground - truth continuation for the prompt   ( Figure 3 ) . When the prompt comes from dupli-   cate examples in the train set , XL- O repro-   duces the groundtruth continuation over 40 % of the   time . XL- E S and XL- NDstill   copy the groundtruth more often when the prompt   comes from a duplicate example than when the   prompt comes from a unique example , suggesting   that more stringent deduplication may be necessary   to remove memorization tendencies entirely .   6.3 Impact on Existing Models   Train - test leakage does not just impact models   trained on C4 . Table 5 shows that the presence   of near - duplicates of the evaluation set in the train   set has a signiﬁcant impact on model perplexity   for two standard models : Transformer - XL ( Dai   et al . , 2019 ) , which was trained on LM1B , and   GROVER ( Zellers et al . , 2019 ) , which was trained   on RealNews . For Transformer XL , the perplexity   78430halves on examples identiﬁed as near - duplicates .   For GROVER , the difference , though not quite as   stark , is present in both model sizes considered .   Existing models also suffer from the problem   of generating text from their train sets . We ﬁnd   that1:38 % of the tokens in the ofﬁcial release of   25k GROVER - Mega outputsare part of verbatim   matches in RealNews of at least length 50 . Like-   wise , more than 5 % of the tokens in ~200k se-   quences outputted by GPT - Neo 1.3B ( Black et al . ,   2021 ) are part of a 50token matches of its training   data , the Pile ( Gao et al . , 2020 ) .   7 Discussion   The focus of this paper is on the datasets used to   train language models . While recent work focused   on documenting the potential harms that could arise   from problematic datasets ( Bender and Friedman ,   2018 ; Gebru et al . , 2020 ) , less work has been done   to quantitatively analyze properties of real language   modelling datasets , like Dodge et al . ( 2021a ) has   done for C4 . Our paper provides analysis on one   particular axis , that of data duplication .   Our experiments measured what could be quan-   tiﬁed : the amount of duplicate content in com-   mon datasets , the effect of deduplication on trained   model perplexity , and the reduction of memorized   content in trained models through deduplication .   We do not focus on the nature of the data being   removed by deduplication or memorized by LMs .   Privacy is an important subject for future work ,   as memorized training data has signiﬁcant privacy   consequences . By this , we mean the standard pri-   vacy deﬁnition that a model should not reveal any-   thing particular to the speciﬁc dataset it was trained   on , as opposed to another training dataset from a   similar distribution ( Shokri et al . , 2017).Train-   ing on standard datasets that have not yet been   deduplicated results in models that are particularly   sensitive to examples that happened to be repeated   multiple times , and this has negative privacy im-   plications . For instance , it could violate a person ’s   expectations of privacy if their publicly available   personal data appeared in a different , surprising   context . Downstream applications of LMs , suchas the game AI Dungeon , should also not output   memorized content like adverts for real products .   We stress that in our experiments , we do not dis-   tinguish between undesired memorized text ( such   as phone numbers ) , innocuous memorized text   ( common phrases ) , and text we may want to be   memorized ( such as a quote by a public ﬁgure ) ,   and instead treat all instances of the LM generat-   ing text that closely matches the training set as   problematic . While we qualitatively observed that   much of the identiﬁed memorized content was rel-   atively innocuous , a more systematic study of the   risks associated with the detected memorization   was beyond the scope of this work .   We also do not investigate the negative conse-   quences of deduplication . Some language tasks   explicitly require memorization , like document re-   trieval or closed - book question answering . Also ,   text that gives attribution is often duplicated across   documents , so removing duplicate substrings could   correspond to removing justthe attribution , which   could result in models that learn the content with-   out its attached attribution . Deduplication is also   not sufﬁcient to remove privacy - sensitive data like   bank passwords and medical records which should   never be used in training data ( Brown et al . , 2022 ) .   Ultimately , whether memorization is a desired   property of a language model , or else risky and   unwanted , depends both on the nature of the text   that has been memorized and on the downstream   applications of the trained model . However , since   the trend has been towards creating datasets and   models that are application - agnostic , we encourage   researchers to think carefully about the limitations   of the data they have collected and the how the   model ’s intended usage constrains what should be   part of the training set . Developing techniques to   memorize or forget speciﬁc sequences depending   on the end application is a promising research di-   rection .   8 Conclusion   We encourage future language model research to   perform dataset deduplication , either by training   on the deduplicated datasets we release , using the   deduplication tools we release , or following our   approach to deduplicate datasets with new tools .   The exact technique used to perform dedupli-   cation is less important than performing stringent   deduplication in the ﬁrst place . On the whole , dedu-   88431plication does not harm , and sometimes improves ,   model perplexity , despite the fact that the dedupli-   cated datasets are smaller and faster to train on .   It is especially important that there are no dupli-   cates between the training and testing sets , because   overlap here explicitly encourages selecting models   that memorize the training data . Lastly , deduplica-   tion helps to reduce some of the privacy concerns   around LMs memorizing their training data .   Ethics   The developers of large language models typi-   cally attempt to create training data that reﬂects   natural human communication , but current meth-   ods to collect and curate such datasets are falli-   ble . There are multiple reasons some text ends   up over - represented . For example , bot replies ,   auto - generated templates , and licenses are repeated   for structural ( e.g. , legal , economical ) reasons ( as   was also observed by Dodge et al . ( 2021a ) ) . Ad-   ditionally , common techniques for acquiring and   “ cleaning ” data can result in an over - representation   of particular subsets of world users , often those   who are English - speaking and publishing in es-   tablished forums . This effectively under - represents   non - English speakers as well as groups whose com-   munication mostly occurs outside of the public   web . In this paper , we focus on the problem of   over - representation of some types of text ( struc-   tural duplicates ) but do not address the problem of   under - representation of others .   Additionally , while we discuss when memorized   content might be desired and when it might not   be desired , our analysis does not disambiguate   these two cases . Work to disambiguate helpful   from harmful memorization is tremendously com-   plex and would require a different set of research   methodologies than are presented in this work .   Acknowledgements   We are grateful to the many researchers whose   technical help , feedback , and discussions shaped   this project : Jacob Austin , Samy Bengio , Olivier   Bousquet , James Bradbury , Fernando Diaz , Mark   Diaz , Noah Fiedel , Jonathan Frankle , David   Grangier , Stefanie Karp , David Mimno , Gaurav   Mishra , Michael Mozer , Sharan Narang , Alex Pas-   sos , Adam Roberts , Hanie Sedghi , Jascha Sohl-   dickstein , David So , Florian Tramer , and Yun   William Yu . We are also grateful to the GoogleBrain women who have given us continuous sup-   port .   Chris Callison - Burch and Daphne Ippolito ’s   research is supported in part by the DARPA   KAIROS Program ( contract FA8750 - 19 - 2 - 1004 ) ,   the DARPA LwLL Program ( contract FA8750 - 19-   2 - 0201 ) , and the IARPA BETTER Program ( con-   tract 2019 - 19051600004 ) . The views and conclu-   sions contained herein are those of the authors and   should not be interpreted as necessarily represent-   ing the ofﬁcial policies , either expressed or implied ,   of DARPA , IARPA , or the U.S. Government .   Contributions   Each of the authors on this paper signiﬁcantly con-   tributed to the ﬁnal results .   •Katherine trained the models used in the pa-   per , built and ran the eval and text generation   pipelines , contributed signiﬁcantly to writing ,   analysis , and project organization and manage-   ment .   •Daphne ran the approximate matching data dedu-   plication pipelines , extracted prompts and evalu-   ation datasets , ran eval pipelines , and contributed   signiﬁcantly to planning , writing , and analysis .   •Andrew wrote the code to perform deduplica-   tion with approximate matching , helped evaluate   energy expenditure , and helped with analysis .   •Chiyuan helped generate plots and contributed to   project scoping , writing , and data analysis .   •Chris offered mentorship and guidance through-   out the project and contributed to writing .   •Doug offered mentorship and guidance through-   out the project and contributed to writing .   •Nicholas wrote the sufﬁx array implementation ,   ran all E S deduplication experi-   ments , contributed signiﬁcantly to planning , writ-   ing , and analysis , as well as scoping the project .   References   98432   108433   118434   128435A Further Details on ND   For our MinHash based deduplication method , doc-   uments are ﬁrst space tokenized , then each consec-   utive 5 - gram is hashed using tabulation hashing .   The set of these hashes is the signature for the doc-   ument . For each element in a document ’s signature ,   the element is hashed using kother hash functions .   The minimum hashed element for each of the k   hash functions is stored . These minimum hashes   are then partitioned into rbuckets , with bhashes   per bucket . These bhashes are augmented into a   single value , then if two documents have the same   value in at least one bucket , they ’ll be marked as   a potential match . The probability that two doc-   uments are considered a potential match is equal   to   Pr(d;djJaccard(d;d ) = s ) = 1 (1 s )   wheresis the Jaccard index between the two   documentsiandj . For document pairs that were   identiﬁed as potential matches , we computed their   actual Jaccard index , and if that was above 0.8 ,   we computed their edit similarity . Document pairs   with edit similarity higher than 0.8 were identi-   ﬁed as duplicates . After some experimentation , we   chose to use b= 20 , andr= 450 , sok= 9;000 ,   so as to make sure a collision at the desired Jaccard   index threshold of 0.8 had a high probability of   occurring .   We also tested an alternative conﬁguration —   ﬁltering to document pairs with Jaccard index of at   least 0.9 and edit similarity of at least 0.9 . In this   case , we used b= 20 , r= 40 , andk= 800 . Fig-   ure 4 shows the histogram of Jaccard similarities   and edit similarities for all document pairs which   collided in min - hash space , for our chosen conﬁgu-   ration ( blue ) and for the alternative conﬁguration   ( orange ) . This allows us verify if the threshold   chosen has few comparisons around the chosen   threshold , then we ’ve likely captured the majority   of actual near duplicates above that threshold . To   verify that yourself , look at the left hand tails of   the distributions . Since both 0.8 and 0.9 begin to   vanish at the same point ( in spite of the fact that the   two thresholds are optimized for accuracy around   different thresholds ) , we feel comfortable saying   that we ’re capturing the majority of actual near   duplicates .   Computational Analysis LetNbe the number   of documents and Tbe the maximal number of to - kens in a document . Edit similarity has a worst case   complexity of T , so the worst case complexity is   O(N+bkTN ) = O(N )   sinceb , k , andTare all  N. The left term is the   complexity of grouping by the signatures , and the   right represents the pathological worst case of all   documents falling into the same Bbuckets .   The highly distributed NDimplementa-   tion we employed is one used for large - scale pro-   duction tasks at Google . On the English C4 dataset ,   the algorithm consumed approximately 41.5 kWh   of energy . Note that our choices of kandbwere   designed to produce very high recall , and with dif-   ferent parameters , the algorithm could be made   much more energy efﬁcient while producing simi-   lar results .   B Further Details on E S   Parallel linear time construction . We build a   parallelized linear time sufﬁx array algorithm . As   a building block , we make black - box use of the   SA - IS algorithm for constructing a sufﬁx array   in linear time Nong et al . ( 2009 ) ; Ko and Aluru   ( 2003 ) . Unfortunately , this algorithm is not eas-   ily parallelized directly , so we introduce a simple   divide and conquer approach to parallelizing the   array construction .   We build our implementation in Rust and ex-   tend an existing sufﬁx array librarywith three   modiﬁcation . The ﬁrst two are straightforward im-   plementation differences : we modify the code to   allow datasets larger than 4 GB , and we remove the   requirement that strings parse as valid UTF-8 se-   quences in favor of raw byte sequences . Our third   change is more signiﬁcant : we re - implement the   algorithm so that we can stream the sufﬁx array   itself off disk .   Parallel partial sufﬁx array construction . Our   divide and conquer sufﬁx array construction algo-   rithm starts by partitioning the dataset into Kdiffer-   ent “ splits ” with SA - IS run over independently on   each split in parallel . This algorithm still requires   O(N)work but runs in O(N = K ) wall - clock time .   This gives us Nseparate sufﬁx arrays A.   Given two sufﬁx arrays AandAfor two se-   quencesSandSit ’s not completely trivial to   construct a single sufﬁx array AforS = SjjS   because of the boundary conditions . Instead , we   138436   do n’t build the data S = SjjSbut rather let   S = SjjS[uptoK ] for someKgreater than   the longest substring match . Then we build the   arrays onSandS. To merge the arrays together   we can remove the items from the ﬁrst array af-   ter indexjSjand merge - sort insert them into the   second .   Parallel merge of partial sufﬁx arrays . We   now merge these separate arrays together into a   single sufﬁx arrayA , Consider the simpler case of   two partial sufﬁx arrays BandCthat we would   like to merge together . We can achieve this by   lettingi= 0 indexBandj= 0 indexC. Each   iteration of the algorithm then pushes BintoA   ifS < SandCotherwise , repeating until   i = jBj 1andj = jCj 1 . To generalize to K   splits , we need only replace the single comparison   above with a min - heap requiring O(logK )  10   work on each iteration .   Observe that in the general case this algorithm   isO(Nmlog(K))whereNis the length of the   dataset , mis the average length of a preﬁx match ,   andKis the number of splits . It is therefore incor-   rect to call this algorithm linear time in the general   case , for ours it is . Because the length of the longest   match is bounded above by the length of the longest   sequence , as long as the size of the dataset is inde-   pendent of the length of the longest sequence in the   dataset , this algorithm remains efﬁcient .   Again , we can parallelize this operation among   Lsimultaneous jobs ( in practice we set K = Las   the number of threads on our machine ) . In the K=   2case , joblprocessesi2[jN = L ; ( j+ 1)N = L ] ,   choosing the bounds of jby binary searching intoCso thatS < S < S. The case where   K > 2is identical except that we repeat this over   allKpartial sufﬁx arrays .   Computational Analysis . We run our algorithm   on a single VM on the cloud with 96cores and   768 GB of memory . Our algorithm is efﬁcient , for   example processing the Wiki-40B training set ( 3   million examples containing 4 GB of text ) in 2:3   minutes wall - clock time ( 2:1CPU - hours of work ) .   The350 GB C4 dataset takes under 12 hours ( wall-   clock ) to build a sufﬁx array ; although we are still   memory constrained and so this corresponds to   1000 CPU - hours . Once the sufﬁx array has been   constructed , it takes under an hour to deduplicate   the C4 dataset .   Note that this algorithm still requires that the   dataset itself ﬁts in memory ( so that we can efﬁ-   ciently index in arbitrary positions ) , but we do not   need to ﬁt the entire sufﬁx array into memory . This   is fortunate since our sufﬁx array requires an 8   space overhead . For example , the sufﬁx array for   the350 GB C4 is 1:5 TB .   Compared to the cost of training a language   model on this dataset , the additional work required   to deduplicate the training dataset is negligible .   Setting a threshold of duplicates . An important   question is how long must a substring match be   before it is counted as a duplicate . In Figure 5 , we   plot the frequency of substring matches within the   four datasets we will consider . For each substring   of lengthk , we compute the probability that there   exists another sequence of length kidentical to this   148437   one ; formally :   m(k ) = Pr   9j6 = i : S = S   :   We choose 50tokens as the threshold to be conser-   vative : the “ bend in the knee ” occurs at 10tokens ,   and manual inspection of length- 25matches found   no false positives . We then doubled this value to   have an exceptionally large margin for error .   C Further Details on Model Training   Each model was trained for two epochs . Since both   C4 - O and C4- E S contain ap-   proximately 365 M examples , we performed 152 K   steps with a batch size of 4800 ( or approximately   2 epochs ) . C4- NDcontains approximately   350 M examples , we performed 146 K steps ( or ap-   proximately 2 epochs ) . On a 128 - core TPU v3 pod   slice , XL models trained on C4- O and C4-   E S took approximately 131 hours ( 5.5   days ) to train , while the XL model trained on C4-   NDtook approximately 126 hours to train .   Like T5 , models were trained with the Adafactor   optimizer ( Shazeer and Stern , 2018 ) . A constant   learning rate of 0.01 was used for the base models   and 0.001 for the XL models .   The 1.5B parameter XL models had 24 layers ,   each with 32 attention heads . The model embed-   ding size was 2,048 , the feed forward layers had   a hidden size of 5,120 , and the key / value dimen-   sion size for the attention heads 64 . The 110Mparameter base models had 12 layers , each with 12   attention heads . The model embedding size was   768 , the feed forward layers had a hidden size of   2,048 , and the key / value dimension size for the   attention heads 64 .   D Energy Consumption   We trained for approximately 131 hours or 5.5   days on a 128 - core TPU v3 . The approximate   deduplicated dataset is 3.9 % smaller than the orig-   inal dataset and trains in 63 hours / epoch , saving   us around 5 hours of compute time for the two   epochs . The XL- O model was trained in   North America where the XL- E S and   XL - NDwere trained in Taiwan . We used   data from Patterson et al . ( 2021 ) to estimate amount   of energy used in training these models by comput-   ing the amount of MWh /hour / core and multiply-   ing by our usage ( see Table 6 for how we computed   these values ) . For simplicity , we use estimates   from Taiwainese datacenters as an estimate . We es-   timate training 2 epochs of XL- O and XL-   E S uses5:86MWh . XL- ND   is trained for fewer steps and we estimate uses   5:63MWh . Training each base model was approxi-   mately 3 days on a 64 - core TPU v3 pod slice which   uses an estimated 1:61MWh .   In addition to model training , evaluation and in-   ference were performed on 64 - core TPU v3 pod   slices . Generating 100,000 sequences from the XL   models takes approximately 0.64 hours . We gen-   erated 100,000 sequences for each of ﬁve types of   prompts for two checkpoints of the model for a   total of 1 M sequences per model . This took ap-   proximately 19.2 hours . We estimate generating   3 M sequences uses 0:43MWh .   E More Results   Qualitative Examples . Table 8 shows several ex-   amples of pairs of documents in C4 whose edit dis-   tance is close to our chosen edit similarity thresh-   old of 0.8 . Table 9 shows substrings which were   identiﬁed by E S as being in C4 more   than once . Table 10 shows several examples of   unprompted generations which were identiﬁed as   memorized are shown .   Distribution of memorization . Figure 6 shows   the distribution in memorization amount over all   generated sequences when using four types of   prompting : train example with duplicates in train ,   158438train examples without any duplicates , validation   examples with duplicates in train , and validation   examples without any duplicates .   URLs with many duplicates . Table 11 shows   the URLs had the largest proportion of examples   identiﬁed by NDas near - duplicates . For   C4 , these tend to be websites that sell many similar   products and thus have a large amount of templated   text . For RealNews , content aggregators seem es-   pecially common .   NDcluster sizes . Figure 8 shows the dis-   tribution of cluster sizes from running ND   on RealNews , LM1B , and Wiki-40B ( results for   C4 are in Figure 1 the main paper ) .   Dataset Sizes Table 13 gives the size in BPE to-   kens and in examples of each dataset before and   after deduplication . Because most datasets were   168439   178440   already deduplicated of exact matches during their   creation , E S deduplication does not   actually remove any examples .   Perplexity on LM1B. Figure 7 is the same as   Figure 2 of the main paper , except with perplexity   on LM1B included . LM1B was omitted from the   main paper ’s ﬁgure in order to improve readability .   188441   198442   208443   218444   228445