  Wongyu Kim , Youbin Ahn , Donghyun Kim , and Kyong - Ho LeeDepartment of Artificial Intelligence , Department of Computer Science   Yonsei University , Seoul , Republic of Korea   { rladnjsrb9999 , ybahn , dhkim92 , khlee98}@yonsei.ac.kr   Abstract   Each utterance in multi - turn empathetic dia-   logues has features such as emotion , keywords ,   and utterance - level meaning . Feature transi-   tions between utterances occur naturally . How-   ever , existing approaches fail to perceive the   transitions because they extract features for the   context at the coarse - grained level . To solve   the above issue , we propose a novel approach   of recognizing feature transitions between ut-   terances , which helps understand the dialogue   flow and better grasp the features of utterance   that needs attention . Also , we introduce a re-   sponse generation strategy to help focus on   emotion and keywords related to appropriate   features when generating responses . Experi-   mental results show that our approach outper-   forms baselines and especially , achieves signif-   icant improvements on multi - turn dialogues .   1 Introduction   Humans have empathy which is the ability to under-   stand situations others have experienced and emo-   tions they have felt from the situations ( Eisenberg   and Strayer , 1987 ) . That ability also enables to in-   terest and console others while sharing a conversa-   tion . Thus , empathetic response generation task has   been considered noteworthy . Figure 1 shows an ex-   ample of a multi - turn empathetic dialogue dataset ,   EmpatheticDialogues ( Rashkin et al . , 2019 ) con-   structed to solve the task . A speaker talks about   one of 32 emotion labels and a situation related   to the emotion label , and a listener empathizes ,   responding to the speaker . Existing approaches   ( Rashkin et al . , 2019 ; Lin et al . , 2019 ; Majumder   et al . , 2020 ; Li et al . , 2020 ; Kim et al . , 2021 ) for the   task achieve promising results but show limitations   when dialogues become long because they extract   features from the concatenation of all tokens in the   context at the coarse - grained level .   However , at the fine - grained level , each utter-   ance in multi - turn empathetic dialogues has fea-   tures such as emotion , keywords that each denoteFigure 1 : An example of EmpatheticDialogues with   response A and B. Response B is from one of state - of-   the - art models . Highlighted words are keywords .   what an interlocutor feels and primarily says , and   utterance - level meaning that can be known when   looking at the entire utterance . In addition , it is a   natural phenomenon that features of each utterance   differ from the previous , as the dialogue is pro-   longed . Hence , we humans instinctively recognize   these feature transitions , which helps us understand   how the dialogue flows and grasp the features of ut-   terance that needs attention . Also , humans respond   to others , focusing on emotion and keywords re-   lated to appropriate features . Take the example in   Figure 1 . In the first turn , the speaker is excited to   see the speaker ’s sister in a long time by mention-   ing keywords ( e.g. , ‘ sister ’ , ‘ visit ’ , ‘ decade ’ ) , and   the listener reacts to the excitement and asks about   her by mentioning keywords ( e.g. , ‘ exciting ’ , ‘ see ’ ,   ‘ live ’ ) . However , in the second speaker utterance ,   the speaker becomes embarrassed because of the   speaker ’s boyfriend ’s bad table manners by men-   tioning keywords ( e.g. , ‘ boyfriend ’ , ‘ loud ’ , ‘ eater ’ ) .   We humans recognize that the features of second   speaker utterance have changed compared to those   of previous utterances , and usually decide to be   attentive to the features of the second utterance .   Then , by focusing on information such as keywords   of that utterance and emotion and keywords ( e.g. ,   ‘ bad ’ , ‘ impression ’ ) related to the features of that   utterance , humans generate empathetic , coherent,4118and non - generic responses like response A. How-   ever , the model which produces non - empathetic   and incoherent response like response B , consid-   ers that the features of the first speaker utterance   represent the context from the coarse - grained view .   In this paper , we first propose to annotate fea-   tures on each utterance at the fine - grained level   ( § 4 ) . Then , we introduce a novel Emp athetic re-   sponse generator based on Recognizing Feature   Transitions ( Emp - RFT ) , which has two essential   parts : Feature Transition Recognizer and Response   Generation Strategy . The first part recognizes   feature transitions between utterances , utilizing   comparison functions of Wang and Jiang ( 2017 ) ,   which makes Emp - RFT understand the dialogue   flow and grasp appropriate features of utterance   that needs attention . The second part helps Emp-   RFT focus on emotion and keywords related to   appropriate features . Specifically , by fusing con-   text with keywords , such keywords are emphasized   within each utterance and get more attention when   generating responses . Then , Emp - RFT detects   next emotion and keywords that denote emotion   and keywords of the response , which helps figure   out proper emotion and keywords for generation .   Lastly , inspired by Dathathri et al . ( 2020 ) ; Chen   et al . ( 2020 ) , a new mechanism of Plug and Play   Language Model(PPLM ) , contrastive PPLM using   contrastive loss , is introduced , which controls Emp-   RFT to actively use the keywords detected to be   next keywords when generating responses .   We conduct experiments on EmpatheticDia-   logues . Emp - RFT outperforms strong baselines ,   particularly , when dialogues are multi - turn .   Our main contributions are as follows . ( 1 ) We   introduce a novel approach that recognizes feature   transitions between utterances , which results in   understanding how the dialogue flows and grasp-   ing the features of utterance that the model should   be attentive to . ( 2 ) We propose a response gener-   ation strategy including fusing context with key-   words , next emotion and keywords detection , and   contrastive PPLM . The strategy makes our model   focus on emotion and keywords related to appro-   priate features when generating responses . ( 3 ) In   the experiments , Emp - RFT outperforms baselines ,   especially , when dialogues are prolonged .   2 Related Work   Since Rashkin et al . ( 2019 ) release EmpatheticDi-   alogues , many approaches have been proposed togenerate empathetic responses . Lin et al . ( 2019 )   propose mixture of emotional experts . Majumder   et al . ( 2020 ) propose emotion grouping , emotion   mimicry , and stochastic sampling . Li et al . ( 2020 )   extract emotional words through lexicon and pro-   pose an adversarial generative model . Shen et al .   ( 2021 ) apply dual - learning with unpaired data for   the bidirectional empathy . Gao et al . ( 2021 ) in-   tegrate emotion cause into response generation   process through gated mechanism . Sabour et al .   ( 2021 ) ; Li et al . ( 2022 ) use implicit commonsense   for context modelling . Kim et al . ( 2021 ) train a   model to extract words that cause the speaker ’s   emotion and attach RSA Framework ( Frank and   Goodman , 2012 ) to any generative models to gen-   erate responses , focusing on emotion cause words .   Recently , many studies have shown remarkable   improvements through recognizing transitions of   features between utterances in open - domain multi-   turn dialogues . Qiu et al . ( 2020 ) perceive transi-   tions of emotion states for context modelling . Zou   et al . ( 2021 ) propose a module to manage key-   word transitions . Zhan et al . ( 2021 ) model external   knowledge transitions to select a knowledge used   for generation . In multi - turn empathetic dialogues ,   we consider emotions , keywords , and utterance-   level meaning ( Gu et al . , 2021 ) as important fea-   tures of each utterance and propose a novel ap-   proach of recognizing feature transitions between   utterances .   3 Task Formulation   Given context con= [ u , . . . , u ] , where an   utterance u= [ u , . . . , u]consists of |u|   words , we can obtain e= [ e , . . . , e]and   k= [ k , ... , k ] , where eandk= [ k , ... , k ]   each denote emotion and |k|keywords of u   through data preparation ( § 4 ) . To conduct next key-   words detection , we construct keyword pairs kps   ( § 4.2 ) whose each pair has two keywords each from   keywords of the speaker utterance and keywords   of the listener utterance in the same turn . Finally ,   given con , e , k , and kps , we detect next emotion   eand next keywords k= [ k , . . . , k ] , and   generate an empathetic response y= [ y , . . . , y ] .   4 Data Preparataion   In this section , we introduce feature annotation in   the speaker and listener utterances.4119   4.1 Feature Annotation in Speaker Utterances   Emotion and Keywords of Speaker Utterance   ( EofSU / KofSU ) . Speakers try to say an emotional   experience that causes a certain emotion in the ut-   terance . Thus , we leverage a model ( Kim et al . ,   2021 ) which is trained to jointly detect an emotion   and emotion cause words of the speaker utterance ,   using EmpatheticDialogues . We regard top-6 emo-   tion cause words as keywords and remove stop-   words and punctuations in keywords .   4.2 Feature Annotation in Listener Utterances   Emotion of Listener Utterance ( EofLU ) . We fine-   tune RoBERTa ( Liu et al . , 2019 ) to detect an emo-   tion given a situation description in EmpatheticDi-   alogues . Then , the model predicts an emotion of   the listener utterance .   Keywords of Listener Utterance ( KofLU ) . Lis-   teners express empathy in the utterance through   three Communication Mechanisms ( CMs ) ( Sharma   et al . , 2020 ) including emotional reaction , inter-   pretation , and exploration . Thus , three models are   leveraged , where each model is trained to detect   words that cause one of three CMs , using another   dialogue dataset for mental health support . Then ,   three models predict such words in the listener ut-   terance . Since predicted words take up slightly a   lot in the listener utterance , these words are filtered   out in the keyword pairs construction .   Keyword Pairs Construction . Inspired by Zou   et al . ( 2021 ) , keyword pairs kpsare constructed not   only to filter out above predicted words , but also to   conduct next keyword detection . Given a dialogue   corpus , all pairs are extracted , where each pair has   a head word and a tail word each from keywords in   the speaker utterance and predicted words in the lis-   tener utterance in the same turn . Then , all pairs are   filtered out to obtain high - frequency pairs through   pointwise mutual information ( PMI)(Church and   Hanks , 1990 ) which can measure the association   between two words in a corpus . Filtered pairs be-   come kps . A tail word of a kpis regarded as a   keyword of the listener utterances joined to extract   that keyword pair .   Performances of feature annotations are summa-   rized in Table 1 and show reliable results . How-   ever , test sets for KofLU based on Empathetic-   Dialogues , do n’t exist . Thus , we randomly sam-   ple 100 test dialogues in EmpatheticDialogues and   ask 3 human workers to annotate whether each   word plays important role for empathizing in the   listener utterances . By majority voting , the final   verdict on each annotation is decided . We com-   pute the inter - annotator agreement on annotation   of test sets for KofLU through Fleiss ’ kappa ( κ )   ( Fleiss and Cohen , 1973 ) , and result in 0.55 , where   0.4 < κ<0.6indicates moderate agreement .   5 The Emp - RFT Model   In this section , we detail Emp - RFT whose overall   architecture is shown in Figure 2 .   5.1 Context Encoding   Word - Level Encoder . Emp - RFT contains an en-   coder f(·)which has the six - layer encoder of   BART ( Lewis et al . , 2020 ) as the backbone and ex-   tracts feature vectors of each u. Inspired by BERT   ( Devlin et al . , 2019 ) , we prefix each utterance with   a[SEN ] token , so u= [ SEN ] . Then , each token4120is represented as emb , the sum of the following   four embeddings : word embedding , position em-   bedding , role embedding and emotion embedding   M∈R. Then , the encoder transforms   each utterance into a list of output hidden states :   [ ˆh , ... , ˆh ] = f([emb , ... , emb]),(1 )   where ˆh∈R. For each utterance , we can obtain   utterance - level meaning vector ˆhderived from   the token [ SEN ] , concatenated keyword vectors   ˆk∈Rderived from the tokens correspond-   ing to k(pis the index for keywords . ) , and emo-   tion vector ˆe = Mˆh .   Feature Transition Recognizer . Emp - RFT has   a component that operates as the process illustrated   in Figure 3 . The component computes feature tran-   sition information between feature vectors , utiliz-   ing two comparison functions , subtraction and mul-   tiplication of Wang and Jiang ( 2017 ) . Each feature   vector is compared to previous two feature vec-   tors . First , emotion transition information etiis   computed :   eti= ReLU ( W(f(ˆe,ˆe,ˆe))),(2 )   f(ˆe,ˆe,ˆe )   =    (ˆe−ˆe)⊙(ˆe−ˆe )   ˆe⊙ˆe   ( ˆe−ˆe)⊙(ˆe−ˆe )   ˆe⊙ˆe   ,(3 )   where fand⊙each denote our transition infor-   mation computing function and Hadamar product ,   andW∈R. Next , utterance - level mean-   ing transition information utiis computed :   uti= ReLU ( W(f(ˆh,ˆh,ˆh))),(4 )   where W∈R. We then obtain enhanced   utterance vector of each utterance by integrating   utterance - level meaning vector , and emotion and   utterance - level meaning transition information :   ¯h= FC([ˆh;eti;uti ] ) , ( 5 )   where FCis a fully - connected layer with size   ofd . In addition , keyword transition information   ktiis computed between concatenated keyword   vectors and cross - encoded vectors c , where t∈   { i−1 , i−2 } :   kti= ReLU ( W(f(ˆk , c , c))),(6 )   c= softmax ( Q(K))ˆk , ( 7 )   Q=ˆkW , K=ˆkW , ( 8)   where W∈R , WandW∈R. We   can obtain enhanced keyword vector of each key-   word by integrating keyword vector , and keyword   transition information :   ¯k= FC([ˆk;kti ] ) , ( 9 )   where FCis a fully - connected layer with size   ofd . Consequently , the enhanced feature vectors   guide Emp - RFT to accurately grasp the features   of utterance that the model should be attentive to   when given feature transition information .   Utterance - Level Encoder . Emp - RFT contains   another encoder g(·)which has the six - layer en-   coder of BART , and transforms enhanced utterance   vectors with global position embeddings ( GPE )   into a context representation to capture relation-   ships between utterances ( Gu et al . , 2021 ):   [ ¨h , ... , ¨h ] = g([¯h , ... , ¯h ] ) . ( 10 )   Emp - RFT consists of hierarchical structures of en-   coders through word - level and utterance - level en-   coders . This structure makes Emp - RFT compre-   hend each utterance at the fine - grained level , and4121understand the context by integrating information   based on comprehension of each utterance .   Fusing Context with Keywords . Emp - RFT   fuses context with keywords as the process illus-   trated in Figure 4 . We first dynamically build key-   word graph for each context . Keywords in each   context become nodes and are initialized by cor-   responding enhanced keyword vectors with GPE .   Edges are built across the below cases : ( 1 ) be-   tween two keywords from the same utterance and   ( 2 ) between a keyword from a certain utterance   and another keyword from the previous two utter-   ances . Also , a tail word in a kpwhose head word   iskis appended as a node and connected with   k node . Appended nodes ( ANs ) are initial-   ized through BART decoder whose parameters are   frozen with GPE , and used for next keywords de-   tection . To obtain keyword representation ˆvfrom   the keyword graph ( ois the index for nodes . ) , nodes   are updated based on multi - head graph - attention   mechanism ( Veli ˇckovi ´ c et al . , 2018 ; Li et al . , 2022 ) .   This mechanism makes Emp - RFT not only capture   relationships between nodes but also manage in-   fluences of each appended node through attention   architecture :   ˆv = v+/hugeparallel / summationdisplayα(Wv ) , ( 11 )   α = exp ( ( Wv)Wv )   /summationtextexp ( ( Wv)Wv),(12 )   where v,∥,A , and α each denote a node   representation , the concatenation of MH atten-   tion heads , the neighbours of vin the adjacency   matrix A , and self - attention weight and W ,   W , W∈R(d = d / MH ) . Lastly ,   we can obtain the fused context representation   H= [ h , ... , h]by fusing the context repre-   sentation with the sum of keyword representations :   h= FC([¨h ; sum([ˆ v , ... , ˆv])]),(13 )   where FC is a fully - connected layer with size   ofd . Consequently , keywords are emphasized   within each utterance and get greater attention   when generating responses .   Next Emotion and Keywords Detection . Emp-   RFT detects next emotion eand keywords k ,   which helps figure out proper emotion and key-   words for generation . First , based on the max-   pooled fused context representation , next emotion   distribution is predicted :   P= softmax ( MMP(H ) ) , ( 14 )   where MPdenotes maxpooling . We use the emo-   tion with the highest probability ( ˆe ) for generation .   Also , Emp - RFT predicts whether the word of each   AN belongs to the next keywords through the bi-   nary classification , where the true label denotes the   word belongs to :   P=/productdisplaysoftmax ( W[ˆv ; MP ( H)]),(15 )   where W∈R. We consider the words of   ANs whose probabilities for the true label ≥0.8   as the keywords ( ˆk ) for generation .   5.2 Response Generation   Response Generator . Emp - RFT includes a re-   sponse generator ( RG ) which has the six - layer de-   coder of BART as the backbone . Through the four   embeddings with ˆe , explained previously , we can   obtain the input sequence embedding for RG . We   prefix it with the sum of node representations cor-   responding to ˆk . Then , RG is fed to predict proba-   bility distribution on each next token ybased on   the fused context representation :   P(y|con , e , k , kps ) = /productdisplayP(y|y , H).(16 )   Training . We apply cross - entropy loss to three   objectives ( eq . 14 , 15 , 16 ) , and train parameters of4122Emp - RFT in end - to - end manner through the sum   of all losses .   Contrastive PPLM . Analysis on the generated   responses of the trained Emp - RFT shows that an ac-   tive reflection of ˆkis demanded . Thus , inspired by   Dathathri et al . ( 2020 ) ; Chen et al . ( 2020 ) , we pro-   pose Contrastive PPLM with a discriminator using   contrastive loss . Existing discriminators ( Dathathri   et al . , 2020 ; Majumder et al . , 2021 ) are trained   to predict whether a sentence contains a certain   attribute , using cross - entropy loss . Then , the gra-   dient of the loss is passed to the generative model   to generate a sentence containing such attribute   during inference . However , since keywords are   not attributes but objects , we train a discriminator   to predict whether a response in EmpatheticDia-   logues is more similar to the keyword set of the   response(positive sample ) than the keyword sets of   another responses(negative samples ) in the same   batch , using contrastive loss based on the similarity   between objects :   L=−logexp(rks / τ)/summationtextexp(rks / τ ) , ( 17 )   where r , ks , τandBeach denote response and key-   word set representations , a temperature parameter   and batchsize . During inference , we repeatedly   sample three random ANs except for nodes of ˆk ,   and consider the sum of such AN representations   as one of negative samples and the sum of node   representations corresponding to ˆkas a positive   sample . Then , the gradient of the contrastive loss   is passed to Emp - RFT .   6 Experiments   6.1 Dataset and Baselines   Dataset . Experiments were conducted on Empa-   theticDialogues ( Rashkin et al . , 2019 ) which con-   tains 24,850 multi - turn dialogues . For each dia-   logue , we can extract a certain number of instances   corresponding to the number of turns within the   dialogue . This totals to 47,611 instances , where   22,761 are multi - turn . In one turn of a dialogue ,   a speaker talks about one of 32 evenly distributed   emotion labels and a situation related to the emo-   tion label and a listener empathizes by responding   to the speaker . Following the instructions of the   dataset , we use 8:1:1 train / valid / test split .   Baselines . We compared Emp - RFT to the fol-   lowing five baseline models : ( 1 ) MoEL ( Lin et al . ,   2019 ) is a transformer - based generative model , which has decoders for each emotion and integrates   outputs of the decoders according to predicted emo-   tion distribution . ( 2 ) EmpDG ( Li et al . , 2020 )   uses emotional words and consists of an adversarial   framework including a generator and discrimina-   tors which reflect the user feedback . ( 3 ) MIME   ( Majumder et al . , 2020 ) is also a transformer - based   generative model which mimics user emotion based   on emotion grouping and uses stochastic sampling   for varied responses . ( 4 ) MIME+Focused S1 and   ( 5)Blender+Focused S1 ( Kim et al . , 2021 ) attach   RSA Framework to MIME and Blender ( Roller   et al . , 2021 ) . Blender is a pretrained model with   90 M parameters size , using an immense number of   dialogues . It is finetuned on EmpatheticDialogues .   Using distractors and Bayes ’ Rules , RSA Frame-   work makes the models focus on certain parts of the   post , such as emotion cause words when generating   responses in the single - turn dialogues . Implemen-   tation details about Emp - RFT and baselines are   covered in Appendix A.1 .   6.2 Evaluation Metrics   Automatic Evaluation . We evaluated the models ,   using the following three metrics : ( 1 ) Perplexity   ( PPL ) ( Vinyals and Le , 2015 ) measures how highly   likely tokens are generated , which evaluates the   overall quality of the model . ( 2 ) Distinct - n ( Dist - n )   ( Li et al . , 2016 ) measures how diverse the gener-   ated response is via the unique words within its   n - gram . ( 3 ) . We use BERTscore ( F ) ( Zhang   et al . , 2019 ) which measures token - level semantic   similarities between the generated response and the   gold response based on embeddings from BERT   ( Devlin et al . , 2019 ) .   Human Ratings . Human evaluations for the dia-   logues models are essential because of insufficient   reliability on automatic metrics . We randomly sam-   pled 100 test dialogues and asked 3 human workers   to score models ’ generated responses on 1 to 5   point scale , following the four metrics ( Rashkin   et al . , 2019 ): ( 1 ) Empathy measures whether the   generated response understands the speaker ’s emo-   tion and situation . ( 2 ) Relevance measures whether   the generated response is coherent to the context .   ( 3)Fluency measures whether the generated re-   sponse is grammatically correct and readable . ( 4 )   Since we conclude that models generating generic   responses are not empathizing to the speaker , we4123   useDiversity to measure whether the generated   response is non - generic .   Human A / B Test . We further conducted a hu-   man A / B test which provides stronger intuitions   and higher agreements than human ratings , be-   cause this is carried with 3 human workers select-   ing the better response when given two generated   responses ( Sabour et al . , 2021 ) .   6.3 Analysis of Response Generation   We abbreviate feature transition recognizer , con-   trastive PPLM , next emotion and keywords detec-   tion , and fusing context with keywords as FTR , CP ,   NEKD , and FCK , respectively .   Automatic Evaluation Results . The overall   automatic evaluation results are shown in the left   part of Table 2 . Emp - RFT performed exceed-   ingly on all metrics except for PPL , which wasnearly the same as Blender+Focused S1 . The im-   provements on other metrics indicated that our   approach was effective for generating generally   high quality and non - generic responses which   were also semantically similar with the gold re-   sponse . While the utilization of pretrained mod-   els yielded significant improvements compared to   models only trained on EmpatheticDialogues , Emp-   RFT showed even greater performance when com-   pared to Blender+Focused S1 endowed with more   significant number of dialogues . In addition , due   to utilization of FTR , Emp - RFT obtained remark-   able results even on multi - turn instances , whereas ,   other models suffered due to their means of utiliz-   ing features for the context at the coarse - grained   level .   Human Evaluation Results . In the right part   of Table 2 , Emp - RFT acquired the highest scores   on all metrics , which demonstrated that all com-   ponents of Emp - RFT helped generate responses   that are empathetic , coherent to the context , and   non - generic . Also , utilizing pretrained models   showed significant improvements , especially on   Fluency and Diversity scores . In Table 3 , the gen-   erated responses from Emp - RFT were more pre-   ferred , which indicated Emp - RFT consistently out-   performed other methods in various experiments .   When observing at the models ’ performance differ-   ence between multi - turn instances and all instances ,   only Emp - RFT continued to perform consistently ,   whereas other models showed significant perfor-4124   mance drops under multi - turn instances . From this ,   we concluded that Emp - RFT continuously under-   stood the dialogue flow .   Ablation Study . To better understand effects of   each component in Emp - RFT , we conducted the   ablation study . We gradually ablated each compo-   nent within the response generation strategy in a   hierarchical manner . ( 1 ) w/o FTR : Feature tran-   sition recognizer was disabled , which resulted in   considerable drops on all metrics , especially on   PPL , F , Empathy , and Relevance scores on   multi - turn instances , because Emp - RFT could not   grasp the attention - needed features of utterance   within multi - turn instances through FTR . ( 2 ) w/o   CP : Contrastive PPLM was removed , which caused   lower Dist - n and Diversity scores , because Emp-   RFT could not actively use various ˆkwhen gener-   ating responses through CP . ( 3 ) w/o ( CP+NEKD ) :   Next emotion and keywords detection were dis-   abled , which interfered with Emp - RFT ’s utilization   of the next emotion and keyword . It droped not   only Dist - n and Diversity scores but also other met-   rics . ( 4 ) w/o ( CP+NEKD+FCK ) : Fusing the con-   text representation with keyword representations   was disregarded . Since keywords were no longer   emphasized for context modelling , such informa-   tion could not get more attention when generating   responses . It caused drops on all metrics , particu-   larly on F , Dist - n , and Diversity .   6.4 Analysis of Next Emotion and Keywords   We report the results in terms of NEKD in Table   4 . Since all baselines have not conducted NEKD ,   we trained models showing promising results such   asCoMAE ( Zheng et al . , 2021 ) , ConceptFlow   ( Zhang et al . , 2020 ) and CG - nAR ( Zou et al . , 2021 )   with EmpatheticDialogues . ( More details are cov-   ered in Appendix A.2 ) . Then , we compared Emp-   RFT to those models . Emp - RFT outperformed   other models on all metrics , which proved Emp - RFT figured out which emotion and keywords were   proper for generation .   6.5 Case Study   The cases from the models are shown in Table 5 . In   the first case , MoEL and MIME expressed regret ,   which was emotionally inappropriate to the con-   text . All baselines except for MoEL failed to grasp   the proper features within the context , and there-   fore generated incoherent responses . Especially ,   Blender+Focused S1 ignored the features of u.   Since Emp - RFT understood the dialogue flow , it   became attentive to not only the features of ubut   also those of u , u , mentioning ( ‘ procrastinate ’ ,   ‘ foods ’ , ‘ safety ’ ) , which led to empathy and co-   herence . In the second case , all baselines could n’t   understand the longer context , which resulted in im-4125proper empathy . Also , Blender+Focused S1 disre-   garded the features of u , and therefore overlooked   the speaker ’s sadness . Emp - RFT fully compre-   hended why the speaker ’s happiness changed to the   sadness . In both cases , without FTR , the responses   of Emp - RFT were non - empathetic and incoherent   because of dismissing appropriate features . In the   third case , we report the case in terms of the re-   sponse generation strategy . Without CP , NEKD ,   and FCK , Emp - RFT produced a generic response .   With the utilization of FCK , Emp - RFT perceived   the word ‘ cancer ’ in ubut expressed excessive   emotion by mentioning ‘ scary ’ . When Emp - RFT   additionally conducted NEKD , Emp - RFT gener-   ated emotionally appropriate responses by men-   tioning ‘ sorry ’ and ‘ hard ’ , and utilized the keyword   ‘ lost ’ . Lastly , with CP , Emp - RFT generated a di-   verse response , actively using ˆk .   7 Conclusion   We proposed a novel approach that recognizes fea-   ture transitions between utterances , which led to   understanding the dialogue flow and grasping the   features of utterance that needs attention . Also , to   make our model focus on emotion and keywords   related to appropriate features , we introduced a re-   sponse generation strategy including fusing context   with keywords , next emotion and keywords detec-   tion , and contrastive PPLM . Experimental results   showed that our model outperformed baselines , and   especially , achieved significant improvements on   multi - turn instances , which proved our approach   was effective for empathetic , coherent , and non-   generic response generation .   8 Ethical Considerations   We expect that our proposed approach does not suf-   fer from ethical problems . The dataset we use in   our work is EmpatheticDialogues which is English-   based . The dataset is constructed by crowdsourcing   with Amazon Mechanical Turk , which protects pri-   vate user information ( Rashkin et al . , 2019 ) . In   addition , the dialogue dataset is anticipated not   to have responses which include discrimination ,   abuse , bias , etc , because the robust collection pro-   cedure of EmpatheticDialogues ensures the qual-   ity of the dataset . Thus , we expect that models   trained using the dataset , do not generate inappro-   priate responses which harm the users . However ,   we inform that our model utilizes a pretrained lan-   guage model , which may produce inappropriateresponses . Lastly , we anticipate our model make   potential users be interested and consoled by gen-   erating empathetic responses .   Acknowledgements   We thank all anonymous reviewers for their mean-   ingful comments , and Hyeongjun Yang , Chan-   hee Lee and Sunwoo Kang of Yonsei Univer-   sity for their discussion and feedback about our   work . This work was supported by the Na-   tional Research Foundation of Korea(NRF ) grant   funded by the Korea government(MSIP ; Ministry   of Science , ICT & Future Planning ) ( No . NRF-   2022R1A2B5B01001835 ) . Also , this work was   partly supported by the Institute of Information and   Communications Technology Planning and Eval-   uation(IITP ) grant funded by the Korean govern-   ment(MSIT ) ( No . 2020 - 0 - 01361 - 003 , Artificial   Intelligence Graduate School Program ( Yonsei Uni-   versity ) ) . Kyong - Ho Lee is the corresponding au-   thor .   References41264127   A Implementation Details   A.1 Empathetic Response Generation Models   We use the official codes of all baselines , and follow   the implementations ( MoEL , EmpDG , MIME , MIME+Focused S1 and Blender Focused S1).Our model is implemented by Pytorch , and based   on two encoders of BART - base and a decoder of   BART - base . Hidden size dis 768 and the number   of emotion classes nis 32 . MH and the num-   ber of layers of graph attention network are each 4 .   Using Adam optimization ( Kingma and Ba , 2015 ) ,   our model is trained on single RTX 3090 GPU with   a batch size of 4 . We apply early - stopping and se-   lect a model showing the best performance through   perplexity on the valid set . For contrastive PPLM ,   we utilize the official code of PPLM . We set a   temperature parameter τand batch size to 0.5 and   64 , respectively . Through represenations derived   from the last token of BART decoder whose pa-   rameters are frozen , we can obtain each response   representation rand each keyword set represen-   tation ks , where the keyword set corresponds to   the response . Thus , ksbecomes a positive sample   forr , and keyword set representations for other   responses in the same batch become negative sam-   ples .   A.2 Next Emotion and Keywords Detection   We utilize the repositories and follow implemeta-   tion details of CoMAE , ConceptFlow , and   CG - nAR . We train three models , using Empa-   theticDialogues instead of originally used datasets.4128