  Daimeng Wei , Zhanglin Wu , Hengchao Shang , Zongyao Li ,   Minghan Wang , Jiaxin Guo , Xiaoyu Chen , Zhengzhe Yu , Hao Yang   Huawei Translation Service Center , Beijing , China   { weidaimeng , wuzhanglin2,shanghengchao , lizongyao , wangminghan ,   guojiaxin1,chenxiaoyu35,yuzhengzhe,yanghao30}@huawei.com   Abstract   Back Translation ( BT ) is widely used in   the ﬁeld of machine translation , as it has   been proved effective for enhancing transla-   tion quality . However , BT mainly improves   the translation of inputs that share a similar   style ( to be more speciﬁc , translation - like in-   puts ) , since the source side of BT data is   machine - translated . For natural inputs , BT   brings only slight improvements and some-   times even adverse effects . To address this   issue , we propose Text Style Transfer Back   Translation ( TST BT ) , which uses a style trans-   fer model to modify the source side of BT data .   By making the style of source - side text more   natural , we aim to improve the translation of   natural inputs . Our experiments on various lan-   guage pairs , including both high - resource and   low - resource ones , demonstrate that TST BT   signiﬁcantly improves translation performance   against popular BT benchmarks . In addition ,   TST BT is proved to be effective in domain   adaptation so this strategy can be regarded as a   general data augmentation method . Our train-   ing code and text style transfer model are open-   sourced .   1 Introduction   Works in neural machine translation ( NMT )   ( Sutskever et al . , 2014 ; Bahdanau et al . , 2016 ; Wu   and et.al , 2016 ; Vaswani et al . , 2017 ) greatly im-   prove translation quality . However , current meth-   ods generally require large amount of bilingual   training data , which is a challenging and some-   times impossible task . As obtaining monolingual   data is much easier , researchers have long ex-   ploited methods to enhance model performances   using monolingual data , for example , language   model fusion for phrase - based ( Brants et al . , 2007 ;   Koehn , 2009 ) and neural machine translation ( Gul-   cehre et al . , 2015 , 2017 ) , back translation ( Sen-   nrich et al . , 2016 ) , and dual learning ( Cheng et al . , Figure 1 : Bilingual and BT data used for English →   German training . Nature indicates data generated by   native speakers ; HT indicates data generated by hu-   man translators from another language , and MT indi-   cates machine translation results . MT andHT styles   are close , but far from Nature .   2016 ; He et al . , 2016 ; Xia et al . , 2017 ) . The com-   bination of such monolingual methods can further   improve model performances .   Back Translation ( BT ) , a data augmentation   method to generate synthetic parallel data by trans-   lating content from target language back to source   language , is widely used in the ﬁeld of machine   translation . BT has many variants ( Sennrich et al . ,   2016 ; Edunov et al . , 2018 ; Caswell et al . , 2019 )   and each has own merits .   In terms of text style , models that use BT are   usually trained on three types of data . Real par-   allel data constitutes the ﬁrst two types : natural   source with human - translated target ( Nature →   HT ) or human - translated source with natural tar-   get ( HT→Nature ) . Back translation data con-   stitutes the third type : machine - translated source   with natural target ( MT→Nature ) , as shown in   Figure 1 .   Inspired by van der Werff et al . ( 2022 ) , who   ﬁnd that a classiﬁer can distinguish MT data from   HT data , we train a similar classiﬁer to classify   Nature andMT data and ﬁnd that a high per-   centage of original text is marked as Nature by   the classiﬁer . However , the percentage of Nature   content is low in human - translated data and even   lower in machine - translated data . In general , hu-7944Metrics Method Original Reverse All   BLEUBitext 46.3 34.9 42.2   BT 41.8 42.6 42.7   COMETBitext 58.7 64.9 61.8   BT 53.5 69.8 61.6   man and machine translated data are similar , but   far different from original text .   We ﬁnd that when the input style is close to   Nature , the output is biased towards HT ; and   when the input style is closed to HT , the output   is biased towards Nature ( for details , see Sec-   tion 6.1 ) . Since the input used to generate BT   data is Nature , the output is close to HT . So   BT mainly improves the translation of translation-   like inputs . For natural inputs , BT brings only   slight improvements and sometimes even adverse   effects . However , in practical use , most inputs sent   to NMT models are natural language written by na-   tive speakers , rather than translation - like content .   We use one original test set ( Nature →HT )   and one reverse test set ( HT→Nature ) to mea-   sure BT performance respectively . As shown in   Table 1 , BLEU ( Post,2018 ) and COMET ( Rei   et al . , 2020a ) scores increase on the reserve test   set but decrease on the original test set after BT .   Based on the ﬁnding , this paper aims to explore   a method to enhance translation of Nature input   on basis of BT , while maintaining its effectiveness   in translating translation - like content . Since BT   connects translation - like input with Nature tar-   get , we assume that if we could connect Nature   input with Nature target , translation of Nature   input could be further enhanced .   Therefore , we propose Text Style Transfer Back   Translation ( TST BT ) , aiming to turn MT →   Nature data into Nature →Nature data to   enhance the translation of Nature input . How-   ever , transferring translation - like text to a natural   style is a zero - shot issue , because we can hardly   obtain parallel data with the same meaning but dif-   ferent styles ( MT andNature ) . We propose two   unsupervised methods . Our experiments on high-   resource and low - resource language pairs demon-   strate that TST BT can signiﬁcantly enhance trans-   lation of Nature input on basis of BT variantswhile brings no adverse effect on HTinputs . We   also ﬁnd that TST BT is effective in domain   adaptation , demonstrating generalizability of our   method .   Our contributions are as follows :   •We analyze the style of BT text and rational-   ize its ineffectiveness on Nature input . We   herein propose TST BT to solve this issue .   •TST BT combines Text Style Transfer with   BT data to further improve translation of   Nature inputs in high and low resource , as   well as in - domain and out - of - domain scenar-   ios against various BT baselines .   •Our experiment results show that TST BT is   effective in domain adaptation as well , which   further improves model performance on basis   of BT augmentation .   2 Related Work   2.1 Back Translation   Back Translation is ﬁrst proposed by Bertoldi and   Federico ( 2009 ) ; Bojar and Tamchyna ( 2011 ) for   phrase - based systems , and then applied to neural   systems by Sennrich et al . ( 2016 ) .   In general , the standard BT adopts beam search   for output generation , so in this paper , we denote it   as Beam BT . The following are some BT variants :   •Sampling BT ( Edunov et al . , 2018 ): ran-   domly samples translation results based on   the probability of each word during decoding ,   thus largely increases BT data diversity .   •Noised BT ( Edunov et al . , 2018 ): adds three   types of noise to the one - best hypothesis pro-   duced by beam search .   •Tagged BT ( Caswell et al . , 2019 ): adds an ex-   tra token to synthetic data to distinguish it   from genuine bitext .   In our experiment , we use the above four vari-   ants as baselines . Other BT variants include Meta   BT ( Pham et al . , 2021 ) , a cascaded method to   supervise synthetic data generation by using bi-   text information , aiming at generating more usable   training data.7945   2.2 Unsupervised Text Style Transfer   Text Style Transfer ( TST ) ( Fu et al . , 2018 ; Jin   et al . , 2022 ) , aiming to control attributes ( e.g. po-   liteness ) of text , is an important task in the area   of natural language generation . Three criteria are   used to measure TST : transferred style strength , se-   mantic preservation , and ﬂuency .   As TST training data is difﬁcult to obtain , unsu-   pervised approaches ( Dai and Liang , 2019 ; Yang   et al . , 2018 ; Krishna et al . , 2020 ; Luo et al . , 2019 )   are widely used . Among those , two particular   approaches are closely related to machine trans-   lation and style transfer . Riley et al . ( 2020 ) pro-   pose using a classiﬁer + tagging approach to make   natural input be translated more naturally . This   method is similar to the task of our paper , but   it has high requirements on bilingual data size   and can not ensure a stable improvement . Freitag   et al . ( 2019 ) propose training an Automatic Post-   Editing ( APE ) model with large - scale target - side   monolingual data . The APE model can also be   considered as a natural style transfer .   We design our TST model by referring to the   APE approach . The biggest difference between   TST and APE is that APE lacks the ability to   improve translation overall quality in some cases ,   while TST , which combines the advantages of   style transfer and back translation , can achieve sta-   ble improvements on basis of standard BT .   3 Method   We propose cascaded and direct approaches ( see   Figure 2 ) to transfer the style of source - side BT   data .   3.1 A Cascaded Approach   The cascaded approach generates standard BT   data ﬁrst and then modiﬁes the style of the source - side BT data . However , modifying translation - like   text to natural text is a zero - shot issue . To ad-   dress this , we ﬁrst train a Source to Target ( S2 T )   model and a Target to Source ( T2S ) model . We   use the reverse model ( T2S ) to generate BT data   { Source , Target } . To generate TST   training data , we employ Round Trip Translation   ( RTT ) as shown in formula 1and Figure 3(a ) .   Source = T2S(S2T(Source ) ) ( 1 )   We use { Source , Source } to train the TST   model , which uses an encoder - decoder architec-   ture , and apply the model to the source - side BT   dataSourceto get Nature →Nature data , as   shown in formula 2 .   Source = TST ( Source ) ( 2 )   The ﬁnal training data is denoted as :   { ( Source , Target ) ,   ( Source , Target ) }   3.2 A Direct Approach   Directly translating Nature data into Nature out-   puts is also a zero - shot issue ( Riley et al . , 2020 ) .   In order to make Nature input be translated more   naturally , and avoid the data size limitations men-   tioned by Riley et al . ( 2020 ) , we adopt a two - step   training strategy , which is inspired by Zhang et al .   ( 2021 ) , as shown in Figure 3(b ) .   We ﬁrst use source and target side monolin-   gual data to generate Source toTarget   andSourcetoTarget data respectively .   We use only Source toTargetdata to   train the translation model and perform incremen-   tal training with SourcetoTarget data .   During incremental training , we freeze all param-   eters in the encoder so the model only learns de-   coder parameters .   By using the two - step strategy , we aim to   let the translation model learn how to produce   Nature →Nature data . We consider this   approach as a Conditional Text Style Transfer   ( CTST ) method .   4 Experimental Setup   4.1 Data   Our main experiments are conducted on WMT18   EnDe , WMT17 ZhEn , and WMT16 EnRo news7946   translation data . For EnDe , we use 5.2 M bilin-   gual data except ParaCraw corpus to train the base-   line model , and 226.2 M German monolingual data   from NewsCrawl 2007 - 2017 for back translation .   For ZhEn , we use 19.1 M bilingual data to train the   baseline model , and 20.4 M English monolingual   data from News Crawl 2016 for back translation .   For EnRo , we use 0.6 M bilingual data to train the   baseline model and 2.2 M Romanian monolingual   data from News Crawl 2015 for back translation .   Training the TST model requires source - side   monolingual data . we use 24 M English monolin-   gual data from NewsCrawl 2007 - 2017 for EnDe   and EnRo , and 24 M Chinese monolingual data for   ZhEn .   4.2 Evaluation   We use metrics including BLEU ( Papineni et al . ,   2002 ) , ChrF ( Popovi ´ c,2015 ) , COMET ( Rei   et al . , 2020b ) and BLEURT ( Sellam et al . , 2020 )   to evaluate models performances on test sets .   Among them , BLEU and ChrF are calculated   using SacreBLEU(Post,2018 ) , COMET using   wmt20 - comet - da , and BLEURT using BLEURT-   20 . Based on the xlm - roberta - basepre - training   model , we use simpletransformersto train a bi-   nary classiﬁer to classify Nature andMT text   for subsequent experiments . The training data in-   cludes 10 M natural monolingual data and 10 M   machine - translated monolingual data . BT type Example sentence   Beam Raise the child , love the child .   Sampling Lift the child , love the child .   Noised Raise child love child , the .   Tagged < T > Raise the child , love the child .   4.3 Architecture   We train our NMT models and TST models with   Transformer ( Vaswani et al . , 2017 ) and fairseq   ( Ott et al . , 2019 ) , and employ FP16 to accelerate   training under a joint source and target language   vocabulary setting . Speciﬁcally , EnDE , ZhEn , and   the TST models use the Transformer - big structure   with a vocabulary size of 32 K , while EnRo models   use the Transformer - base structure with a vocab-   ulary size 16K. The dropout rate for EnDe base-   line model and TST model is 0.3 , and 0.1 for other   models . Other settings are as follows : batch size   as 4096 , learning rate as 7e-4 , warmup steps as   4000 , label - smoothing as 0.1 ( Szegedy et al . , 2016 ;   Pereyra et al . , 2017 ) , Adam β1as 0.9 , and β2as   0.98 ( Kingma and Ba , 2017 ) . For each training   task , we select the best model according to the per-   plexities measured on the dev set .   5 Result   TST can be combined with popular BT strategies .   Our strategy can be seen as a universal data argu-   mentation method on basis of BT . To better verify   the effectiveness of our method , Beam BT , Sam-   pling BT , Noised BT , and Tagged BT are selected   for comparative experiments ( see Section 2.1 ) .   Table 2is an example of synthetic source sen-   tences generated by four BT strategies . For Noised   BT , noise is added after TST is performed . While7947BLEU ChrF COMET BLEURT   All O R All O R All O R All O R   Bitext 32.9 35.2 28.9 60.8 62.1 59.1 54.8 50.1 59.7 73.6 71.8 75.6   + Beam BT 32.1 28.5 36.4 59.2 55.0 65.0 45.9 28.0 65.4 71.7 66.2 77.8   + TST 33.3 31.4 34.8 60.8 58.4 64.1 53.3 42.2 65.4 73.9 70.3 77.8   + TST 35.3 33.0 37.7 62.8 60.6 65.8 59.3 51.6 67.6 75.8 73.1 78.7   + Sampling BT 36.0 32.7 40.2 63.0 60.2 66.9 61.7 54.5 69.5 76.9 74.2 79.7   + TST 35.8 32.6 39.9 63.0 60.3 66.8 62.5 55.9 69.6 77.2 74.7 79.8   + Noised BT 36.6 36.2 36.4 63.6 62.6 65.0 59.8 53.4 66.9 75.7 73.0 78.5   + TST 37.0 36.5 37.1 64.1 63.1 65.5 62.3 57.1 67.9 76.5 74.4 78.9   + Tagged BT 37.0 36.6 36.7 63.9 63.1 64.9 61.6 56.0 67.6 76.2 73.9 78.6   + TST 37.4 37.4 36.5 64.3 63.8 64.9 62.2 57.2 67.6 76.6 74.4 78.9   + FT 33.6 36.4 28.9 61.5 63.1 59.3 56.3 52.4 60.4 74.1 72.5 75.8   + Beam BT 37.3 37.6 36.1 64.3 63.8 64.9 60.4 54.7 66.4 75.6 73.3 78.0   + TST 37.8 37.7 37.2 64.6 64.0 65.5 61.3 55.4 67.6 76.1 73.8 78.6   for other BT methods , we directly modify the   source side of BT data using our TST model .   To prove the effectiveness of TST BT , We per-   form experiments on high - resource ( EnDe and   ZhEn ) and low - resource ( EnRo ) languages , as   well as domain adaptation .   5.1 TST BT for EnDe   We believe that when we add Nature toNature   BT data , the translation of Nature input can be   improved . However , the target side of original test   set is human - translated , which could inﬂuences   the scores measured by over - lapping metrics , such   as BLEU and ChrF. For the purpose of fair evalua-   tion , we report multiple metric scores , including   BLEU , ChrF , COMET , and BLEURT . The ﬁnal   scores are averaged based on WMT14 - 18 test sets ,   as shown in Table 3 . The detail results are shown   in Appendix A.   All BT methods enhance model performance   over baselines . It has greater effect on reverse test   sets than original ones . Particularly , all metrics   on original test set decline after Beam BT is ap-   plied . This result is consistent with our ﬁndings   that merely adding BT data MT→Nature deteri-   orates translation of Nature input .   We try the two style transfer approaches men-   tioned above on basis of Beam BT . The result   shows that both cascaded and direct approaches   bring signiﬁcant improvements but the cascaded   approach is better . So we use the cascaded ap-   proach by default in following experiments . In general , TST BT mainly brings improvement   on original test sets while maintains standard BT ’s   effectiveness on reverse test sets . Although BLEU   and ChrF scores are ﬂuctuated , we observe steady   increase of COMET and BLEURT scores after   TST BT is applied . We observe similar improve-   ments against other BT baselines , with an average   improvement of 1.0 + COMET score .   According to the experiment results , TST is a   supplement to BT that further enhances the effec-   tiveness of BT .   5.1.1 Ablation Experiment   Although TST BT does not directly use additional   source text but the transfer model is trained with   source data . So we perform forward translation   ( FT ) or self - training ( Zhang and Zong , 2016 ) with   the same data and compare the FT , FT+BT ( Wu   et al . , 2019 ) , and FT + TST BT strategies , as   shown in Table 3 .   FT enhancement is considerable on the original   test set but slight on the reverse test set . FT +   BT brings signiﬁcant improvement on the reverse   and original test sets . When we perform TST BT   on such a strong baseline , we observe further 0.7   and 1.2 COMET score increases on original and   reverse sets respectively .   Although FT and TST use the same data , their   mechanisms are different and the two methods can   be used together . He et al . ( 2020 ) believe dropout   is the key for FT while TST BT focuses on style   transfer to create Nature toNature data , which7948BLEU ChrF COMET BLEURT   All O R All O R All O R All O R   Bitext 24.7 23.8 26.1 53.4 53.0 54.2 43.5 34.2 55.0 68.0 65.9 70.6   + Beam BT 26.4 23.7 30.9 55.1 53.5 58.1 46.4 36.2 59.2 69.1 66.6 72.2   + TST 26.6 23.5 31.8 54.9 53.1 58.4 47.8 37.4 60.5 69.5 67.0 72.7   BLEU ChrF COMET BLEURT   All O R All O R All O R All O R   Bitext 28.7 28.8 28.6 56.0 54.1 57.9 52.5 28.8 76.3 71.6 64.7 78.5   + Beam BT 32.3 29.0 35.8 59.0 54.8 63.5 63.5 38.9 88.1 74.0 66.9 81.0   + TST 31.7 27.8 35.6 58.6 54.1 63.3 66.9 43.1 90.7 75.2 68.2 82.1   + TST 31.9 27.8 36.1 58.6 54.0 63.5 65.0 39.9 90.2 74.5 66.9 82.1   further improves the translation of Nature input .   5.2 TST BT for ZhEn   The size of ZhEn bilingual data is 20 M , four times   that of EnDe . We perform TST on this language   pair to see whether TST BT is effective when ap-   plied to a even larger data size and to a language   from a different family . We use 20 M English   monolingual data to ensure the ratio of bilingual   and monolingual data is 1:1 . See overall results in   Table 4and detailed results in Appendix B.   The overall result is similar to that of EnDE .   We observe signiﬁcant increase of COMET and   BLEURT scores after applying TST BT , although   the BLEU and ChrF scores ﬂuctuate . TST BT   achieves 1.4 COMET score increase on average on   basis of Beam BT . We observe signiﬁcant increase   on both original and reverse test sets .   Our experiments also show that TST BT   achieves similar improvements against other BT   baselines in addition to Beam BT on ZhEn . The re-   sult is different from the EnDe experiment , where   the improvement brought by TST against Beam   BT is much greater than other BT baselines . We   assume that a larger bilingual data size and a dif-   ferent data ratio may be the reason .   It should be noted that the ZhEn baseline is al-   ready very strong considering the data size , and   even stronger after adding the standard BT data .   However , TST BT achieves further enhancement   against such strong baselines.5.2.1 Human Evaluation   We also perform human evaluation on ZhEn to   verify the enhancement brought by TST BT . We   randomly sample 300 sentences from WMT17 - 19   original and reverse test sets respectively . We fol-   low the evaluation scheme mentioned by Callison-   Burch et al . ( 2007 ) , and 8 professional annotators   are recruited to rate adequacy and ﬂuency of three   MT results on a 5 - point scale , given source text   and reference .   The result is listed in Table 6 . TST improves ad-   equacy and ﬂuency on both original and reverse   test sets . The result is consistent with COMET   and BLEURT scores in Table 4 . The human eval-   uation result again proves the effectiveness of our   method . Both automatic metrics and human evalu-   ations demonstrate that TST BT mainly brings en-   hancement on the original test set , indicating that   TST BT improves the translation of Nature input .   5.3 TST BT for EnRo   We further perform experiments in low - resource   scenario to test the generalizability of TST BT . We   use WMT16 EnRo bilingual data ( 0.6 M bilingual )   for the experiment . Table 5presents the results .   In this experiment , we compare the effective-   ness of two TST models : one is trained with   EnRo models , and the other , used for our EnDe   experiment , is trained with EnDe models . The   style transfer model trained with EnRo data im-   proves performance against BT baselines ( by 1.5   COMET score and 0.5 BLEURT score ) .   Another interesting ﬁnding is that the TST   model for the EnDe task also enhances the EnRo7949   model performance ( by 3.4 COMET score and 1.2   BLUERT score ) , which is even greater than that   of the TST model . The result indicates that it   is possible to build a universal pre - trained model   for sytle transfer . This result demonstrates that the   style transfer model is universal and can be applied   to other language pairs .   5.4 Domain Augmentation   We observe that the translation of in - domain nat-   ural inputs improve signiﬁcantly after applying   TST BT . We also found that TST BT still improve   translation of out - of - domain natural inputs ( like   IWSLT14 and Flores ( Goyal and Gao , 2022 ) ) test   set ( for details , see Appendix Table 19 ) .   Domain adaptation is a critical application of   BT . BT can improve in - domain performance given   in - domain monolingual data and an out - of - domain   translation model ( Edunov et al . , 2018 ) . If we train   a TST model to modify the source - side text gener-   ated by BT to an in - domain style , we assume in-   domain translation can be further improved .   To test our hypothesis , we train an out - of-   domain DeEn model using WMT18 news bilin-   gual data , and perform BT on 12 M biomedical En-   glish monolingual data . 2.5 M biomedical German   monolingual data is used to train the in - domain   TST model . The result is shown in Table 7 .   We observe signiﬁcant improvement brought by   BT and more surprisingly , further signiﬁcant im-   provement after we apply TST , with an increase of   1.4 COMET score and 0.7 BLEURT score . We be-   lieve the reason for such enhancement is the same   as that on Flores and IWSLT test sets mentioned   above : making the input style biased towards in-   domain or Nature text to augment the effective-   ness of BT . The experiment again demonstrates   the generalizability of TST BT .   6 Analysis   6.1 Style Tide   As shown in Figure 1 , bilingual data can be di-   vided into Nature toHT orHT toNature .   By learning such data , the model inclines to gen-   erate translation - like output when the input is   Nature , and vice versa . To illustrate the phe-   nomenon , we perform several rounds of trans-   lation on EN andDE data from   WMT18 EnDe test set . We calculate the propor-   tion of Nature text marked by the classiﬁer after   each round of translation .   As shown in Figure 4 , the percentage of   Nature sentences ﬂuctuates regularly after each   round of translation , no matter the translation   starts from De or En . For English original data ,   the percentage of Nature data is 85.7 % before   translation . The percentage drops to 7.3 % after   the ﬁrst round of translation into German , and then   bounces back to 51.9 after the second round of   translation back into English . As we analyzed   above , the style of input determines the style of   output .   In general , the composition of bilingual data , as   well as the difference between Nature andHT   style , makes the source - side BT text signiﬁcantly   different from Nature text . As a result , the trans-   lation of Nature input can hardly be improved by7950Equal TST better MT better   Annotator 1 220 27 53   Annotator 2 212 23 65   Annotator 3 218 24 58   standard BT .   6.2 Style and Quality of TST   To understand what changes a TST model makes   to the source - side text , we analyze the style and   quality difference before and after applying TST   to the source - side text .   Taking EnDe data as an example , we analyze   the style of English text before and after TST , and   compare the quality through human evaluation .   As shown in Figure 4 , after TST , the percentage   ofNature text increases from 5.5 to 20.1 . The im-   provement is signiﬁcant , reaching the same level   ofNature as human - translated data , but there is   still a certain gap with the real natural text .   In addition , to analyze the impact of TST on text   quality , we randomly select 300 sentences from   WMT14 test set and assess the quality of standard   BT data and TST data against references . We in-   vite three professional annotators to complete the   assessment . We use relative ranking and classify   the results into three categories : equal , TST bet-   ter or MT better . The result is shown in Table 8 ,   which is different from Freitag et al . ( 2019 ) . APE   can further improve translation quality but TST   can not .   Based on above analysis , we ﬁnd that TST does   not improve the overall quality of source - side BT   data . Instead , it modiﬁes the text towards a more   natural style , thus overcomes the weakness of stan-   dard BT . In addition , TST BT still maintains BT ’s   tolerance ( Bogoychev and Sennrich , 2019 ) of data   quality to make up the performance deterioration   caused by TST .   6.3 Style Transfer and BT Effects   In order to analyze the relationship between style   transfer results and ﬁnal improvement on trans-   lation quality , we compare the improvements   brought by TST BT data that is generated via two   different approaches ( cascaded / direct as we mo-   tioned above ) on EnDe and EnRo .   We use Strength of Style Transfer ( ACC ) and   Semantic Preservation ( Seman ) to measure styleTST TST BT   ACC Seman COMET   EnDe Beam BT 5.5 71.1 35.3   + TST 25.2 70.8 51.1   + TST 20.1 69.9 59.3   EnRo Beam BT 25.4 65.6 38.9   + TST 55.4 65.1 43.1   + TST 52.2 65.7 39.9   transfer results . Taking EnDe as an example ,   we perform BT on the DE data from the   reverse test set { EN , DE } , and calcu-   late Seman ( measured by BLEURT ) against ref-   erence EN . We then use the original test   set{EN , DE}to measure the improve-   ment of TST BT on the translation of Nature in-   put . The result shows that although the direct ap-   proach leads to higher ACC and Seman scores , the   cascaded approach brings greater enhancement to   the ﬁnal translation performance . The results are   shown in Table 9 .   For EnRo , we compare style transfer models   trained on EnRo and EnDe data as we stated be-   fore . Data modiﬁed by the TST achieves   higher ACC and Seman scores , and lead to greater   enhancement to the overall translation quality . The   result is different from our EnDe experiment .   Therefore , the relationship between style trans-   fer and the effect of BT enhancement can not be   drawn and more researches are required .   7 Conclusion   This paper proposes Text Style Transfer Back   Translation ( TST BT ) to further enhance BT effec-   tiveness . We make a detailed analysis of training   data styles and ﬁnd that BT hardly improves trans-   lation of Natural inputs , which are the main in-   puts in practical use . Our method simply modiﬁes   the style of source - side BT data , which brings sig-   niﬁcant improvements on translation quality , both   in high - resource and low - resource language sce-   narios . Further experiment ﬁnds that TST BT is   also effective in domain adaptation , which can fur-   ther expand the application of our method . The   generalizability of TST BT is thus proved.79518 Limitations   TST BT is simple and straightforward , which   brings great improvements against BT baselines .   However , comparing with standard BT , TST BT   requires an additional style transfer model and ad-   ditional time to process generated BT data .   References79527953A Experiment Details for EnDe79547955B Experiment Details for ZhEn7956   C Experiment Details for EnRo   D TST BT on OOD7957ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   8   /squareA2 . Did you discuss any potential risks of your work ?   6   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   1   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   4   /squareB1 . Did you cite the creators of artifacts you used ?   4   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   4   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   4   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   4   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   4   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   4   C / squareDid you run computational experiments ?   4   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   No response.7958 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   No response .   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   No response .   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   No response .   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   6.2   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   Not applicable . Left blank .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   Not applicable . Left blank .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   Not applicable . Left blank .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   Not applicable . Left blank .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   Not applicable . Left blank.7959