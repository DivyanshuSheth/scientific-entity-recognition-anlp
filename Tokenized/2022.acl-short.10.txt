  Ganesh JawaharMuhammad Abdul - MageedLaks V . S. LakshmananDeep Learning & Natural Language Processing Group , Data Management & Mining Group   The University of British Columbia   Abstract   In this work , we focus on the problem   of distinguishing a human written news   article from a news article that is created   by manipulating entities in a human written   news article ( e.g. , replacing entities with   factually incorrect entities ) . Such manipulated   articles can mislead the reader by posing as   a human written news article . We propose   a neural network based detector that detects   manipulated news articles by reasoning   about the facts mentioned in the article . Our   proposed detector exploits factual knowledge   via graph convolutional neural network along   with the textual information in the news article .   We also create challenging datasets for this task   by considering various strategies to generate   the new replacement entity ( e.g. , entity   generation from GPT-2 ) . In all the settings , our   proposed model either matches or outperforms   the state - of - the - art detector in terms of   accuracy . Our code and data are available   at https://github.com/UBC-NLP/   manipulated_entity_detection .   1 Introduction   A type of fake news that has received little atten-   tion in the research community is manipulated text .   Manipulated text is typically created by manip-   ulating a human written news article minimally   ( e.g. , replacing every occurrence of a particular en-   tity , ‘ Obama ’ in a news article with another Amer-   ican politician entity ) . Current fake news detec-   tors that exploit stylometric signals from the text   ( e.g. , choice of specific words to express false state-   ments ) are clearly insufficient for distinguishing   manipulated text from human written text ( Zhou   et al . , 2019 ; Schuster et al . , 2020 ) as the style un-   derlying the manipulated text is virtually identical   to human writing style . In this work , we focus on   this problem of distinguishing manipulated news   articles from human written news articles .   Table 1 : Example human written and manipulated text .   Named entities of organization type are shown in green .   Manipulated entities are shown in orange .   We consider a particular type of text manipu-   lation — entity perturbation ( Zhou et al . , 2019 ) ,   where a manipulated news article is created by mod-   ifying a fixed number of entities in a human writ-   ten news article ( e.g. , replacing them with entities   generated from a text generative model ) . E.g. , in   Table 1 , to mislead humans , the entity ‘ Relay Ven-   tures ’ can be replaced by ‘ Samsung ’ ( a candidate   replacement entity generated by the generative pre-   training-2 model ( GPT-2 ) ( Radford et al . , 2019 ) ) ,   which is locally consistent as some of the other   companies in the original text are also into device   manufacturing .   To distinguish a manipulated news article from   the original human written news article , we propose   a neural network based detector that jointly utilizes   the textual information along with the the factual   knowledge explicitly by building entity - relation   graphs which capture the relationship between dif-   ferent entities present in the news article . The fac-   tual knowledge is encoded by a graph convolutional   neural network ( Kipf and Welling , 2017 ) that cap-   tures the interactions between different entities and   relations , which we hypothesize , carries discrimina-   tory signals for the manipulated text detection task.86Our major contributions include : ( i ) a detector that   exploits factual knowledge to overcome the limi-   tations of relying only on stylometric signals , ( ii )   an approach to generate challenging manipulated   news article dataset using GPT-2 , and ( iii ) a collec-   tion of challenging datasets by considering various   strategies to generate the replacement entity .   2 Background and Related Work   The manipulated text detection task is related to   diverse research areas such as fake news detection ,   natural language understanding , and knowledge   bases .   Fake news detection . Research on Fake news de-   tection typically deals with challenges such as un-   derstanding the news content ( Schuster et al . , 2020 ) ,   claim verification ( Thorne and Vlachos , 2018 ) , ver-   ifying the credibility of the source ( Castillo et al . ,   2011 ) , and exploiting fake news propagation pat-   terns ( V osoughi et al . , 2018 ) . Our work is primarily   focused on detecting fake news in the form of ma-   nipulated text , by understanding the news content .   In the traditional problem setting , both fake and real   news is assumed to be written by a human ( Shu   et al . , 2017 ; Oshikawa et al . , 2020 ) . Since humans   tend to make stylistic choices ( e.g. , choosing some   specific language for writing false statements ) , the   fake news detector can perform reasonably on the   task by picking up on these stylometric signals .   One can also create fake news by manipulating a   human written news article minimally . Such ma-   nipulations include : entity perturbation ( e.g. , ‘ 12   people were injured in the shooting ’ to ‘ 24 people   were killed in the shooting ’ ) ( Zhou et al . , 2019 ) ,   subject - object exchange ( e.g. , ‘ A gangster was shot   by the police ’ to ‘ A policeman was shot by the   gangster ’ ) ( Zhou et al . , 2019 ) , and adding / deleting   negations ( e.g. , ‘ Trump does n’t like Obamacare ’ to   ‘ Trump likes Obamacare ’ ) ( Schuster et al . , 2020 ) .   These manipulations do not typically affect the   style and hence stylometric signals alone can not   help in building accurate manipulated text detection   models ( Zhou et al . , 2019 ; Schuster et al . , 2020 ) .   Natural language understanding . Pre - trained lan-   guage models such as BERT ( Devlin et al . , 2019 )   and RoBERTa ( Liu et al . , 2019 ) achieve strong   performance in diverse NLP tasks . Specifically ,   RoBERTa is the state - of - the - art detector when fine-   tuned for detection of synthetic text ( Solaiman   et al . , 2019 ; Jawahar et al . , 2020 ) . These mod-   els can also capture implicit world knowledge ( e.g. ,Paris is the capital of France ) that occurs frequently   in the text ( Petroni et al . , 2019 ) . However , it is   insufficient for solving our task ( Schuster et al . ,   2020 ) , as it is limited to frequent patterns .   Knowledge bases ( KBs ) . Knowledge bases ( e.g. ,   YAGO ( Tanon et al . , 2020 ) ) containing typically   a collection of facts ( e.g. , subject - relation - object   triples ) , provide specialized knowledge for down-   stream NLP tasks ( e.g. , question answering ( Baner-   jee and Baral , 2020 ) ) . One can integrate such sym-   bolic knowledge into pre - trained language models   during pre - training ( Zhang et al . , 2019 ) and finetun-   ing ( Liu et al . ( 2020 ) ; Zhong et al . ( 2020 ) , which   we follow in this work ) .   3 Manipulated Text Creation   In this work , we focus on a particular type of manip-   ulation — entity perturbation ( Zhou et al . , 2019 ) ,   where all occurrences of a fixed number of ran-   domly picked entities from a human written news   article are replaced with different replacement en-   tities . We replace named entities of three types :   person , organization and location ( recognized us-   ing spaCy ’s named entity recognizer ( NER ) ( Hon-   nibal et al . , 2020 ) ) . We ensure the replacement   ( new ) entity belongs to the same type as the origi-   nal ( old ) entity . We create challenging manipulated   text datasets by considering various strategies to   identify the new replacement entity : random most   frequent entity ( pick randomly from among the top   5000 entities ) , random least frequent entity ( pick   randomly from the bottom 5000 entities ) , and entity   generated by GPT-2 . Sample manipulated entities   obtained from different replacement strategies are   shown in Table 2 .   GPT-2 generated entity replacement . Strategies   that randomly identify the replacement entity ig-   nore the context provided by the news article . For   example , in news portion ( 1 ) , a random replace-   ment entity for ‘ Relay Ventures ’ can be ‘ Sales-   force ’ . However , it is likely locally inconsistent as   ‘ Salesforce ’ is not into device manufacturing unlike87many other co - occurring companies in the origi-   nal text . We propose a novel approach that makes   use of the state - of - the - art text generative model   GPT-2 to pick replacement entities that are locally   consistent . Revisiting the news portion ( 1 ) , let the   randomly selected entity to be replaced be ‘ Re-   lay Ventures ’ . We treat the fragment of text from   the beginning of the article up to the tokens be-   fore the first occurrence of the target entity ( ‘ Relay   Ventures ’ ) as the prompt . We provide this prompt   to GPT-2 , which can then generate the next few   tokens . We call the generated token sequence a   candidate replacement entity if the sequence starts   with an entity ( e.g. , ‘ Samsung ’ ) of same type as the   target entity ( ‘ Relay Ventures ’ ) and has no string   overlap with the target entity . If the constraints are   not met , we ask GPT-2 to create the generated se-   quence again up to a maximum of 10 attempts . The   candidate replacement entity thus obtained will be   used to replace all occurrences of the target entity .   For the news portion ( 1 ) , the candidate replacement   entity generated by GPT-2 is ‘ Samsung ’ , which is   locally consistent : similar to other companies in   the original text , Samsung manufactures devices .   4 Manipulated Text Detection   The goal of this work is to build a detector that dis-   tinguishes manipulated news article from human   written news article with high accuracy . In prior   work , Zhou et al . ( 2019 ) conclude that the manipu-   lated article can possibly be detected by checking   the facts underlying the article with knowledge   bases and Schuster et al . ( 2020 ) show that humans   can identify the manipulated text well when they   are allowed to consult external sources ( e.g. , inter-   net ) . Building on these findings , we hypothesize   thatfactual knowledge underlying the news arti-   cle can provide discriminatory signals for manip-   ulated text detection . To this end , we embody the   RoBERTa detector with explicit factual knowledge   so that the detector can reason about facts present   in the news article , whose details we discuss next .   Factual knowledge . For factual knowledge , we   leverage a variant of YAGO 4 KB ( Tanon et al . ,   2020 ) that contains only instances that have an En-   glish Wikipedia article . We then extract the facts in   a given document by first identifying all the entities   present in the document using spaCy ’s NER . For   each target entity , we grab all the triples in the KB   where the subject matches with the target entity   at surface level . These triples can be seen as thefirst hop neighbors of the target entity in the KB .   For a given document , the set of triples collected   over all identified entities is used to build the cor-   responding factual graph . A node can be an entity   or a relation . A directed edge is added between   subject and relation , as well as relation and object .   This factual graph contains rich factual information   about entities present in the document , which can   be exploited to reason about facts mentioned in the   article for correctness .   Integrating factual knowledge with RoBERTa .   Our proposed detector is an integration of the   RoBERTa model with factual knowledge . This   allows the detector to reason about facts men-   tioned in the article . To embed the factual knowl-   edge , we employ graph convolutional networks   ( GCNs ) ( Kipf and Welling , 2017 ) , where we stack   lGCN layers and the definition of the hidden rep-   resentation of each node vof the factual graph as   layerk+ 1 , in a graph G= ( V , E ):   whereW , b , h , N(v)correspond to layer spe-   cific model weights , biases , node representation ,   and neighbors of v in Grespectively . Note that   hdenotes the initial node features , which can be   initialized randomly or using a pre - trained entity   embedding such as Wikipedia2vec ( Yamada and   Shindo , 2019 ) .   Detector prediction . The factual knowledge about   entities present in the article is captured in the node   embeddings ( h ) corresponding to the last layer l   of the GCN model . The textual knowledge corre-   sponding to the document can be obtained from the   last layer representation ( r ) of the RoBERTa   model corresponding to the first token ( ‘ [ CLS ] ’ ,   special classification token ) of the RoBERTa input .   We combine the factual and the textual knowledge   by simply averaging all the GCN ’s entity embed-   dings and concatenating the entity average with   the RoBERTa ’s document embedding . Thus , the   unnormalized prediction probabilities ( mf(d ) ) of   our detector for the document dcan be given by :   where [ ; ] corresponds to the concatenation opera-   tion and W , bcorrespond to the affine trans-   formation specific model parameters for manipu-88   lated text detection . The output from mf(d)passes   through dropout followed by ReLU layer .   Identifying manipulated entities . To enable hu-   mans to understand our detector ’s decision and per-   form further investigation , we introduce a subtask   for the detector , namely identify the manipulated   entities among different entities present in the doc-   ument . For this subtask , we build on the entity   representations output by the last layer of the GCN   model . The unnormalized class prediction proba-   bilities ( ef(v ) ) for a given entity vfrom the article   can be given by :   where hdenotes the hidden representation at last   layerlfor the entity v , andW , bcorrespond to   the affine transformation specific model parame-   ters for entity classification . The overall objective   function of the proposed detector can be given by :   whereL , mf , andsresp . correspond to the func-   tion that computes the negative log - probability of   the correct label , detection prediction function , and   softmax function . ydenotes the entity manipu-   lation class label , which is 1if the entity eis ma-   nipulated , and 0otherwise . ydenotes the article   manipulation class label , which is 1if at least one   entity in article iis manipulated , and 0otherwise .   5 Experiments and Results   Dataset and Detector Settings . The human writ-   ten news articles used in our study are taken fromthe RealNews dataset ( Zellers et al . , 2019 ) , which   contains 5000 , 2000 , and8000 news articles in the   training , validation , and test set respectively . We   randomly pick half of the news articles in each   set for human written news article category and   the rest in each set for manipulation based on the   chosen replacement strategy . We also create three   different datasets for each replacement strategy by   varying the maximum number of entities to be ma-   nipulated from 1 to 3 . Detailed statistics of the   proposed datasets is in A.1 . The hyperparameter   search space for all detectors is offered in A.2 .   Hardest detection task . Table 3 presents the de-   tection accuracy results . We observe that the most   challenging dataset for the state - of - the - art detector   is surprisingly from random most frequent entity   replacement strategy with exactly one entity re-   placement . The random strategies fail to create a   challenging dataset with high ( e.g. , 3 ) number of   entity replacements , which indicates that the de-   tection task becomes easier with increase in the   number of locally inconsistent entities . Neverthe-   less , our proposed GPT-2 based entity replacement   strategy keeps the detection task harder even for   large number of replacements , thanks to the ability   of the strategy to generate locally consistent enti-   ties mostly . Regardless of the replacement strate-   gies , the detection performance of all the detectors   increases with the increase in the number of en-   tities that are manipulated in a document , that is ,   more the manipulations in a document , the easier   the detection task . This result is similar to pre-   vious research which performs manipulation by   adding / deleting negations in news articles ( Schus-   ter et al . , 2020 ) . A fake news propagator can thus89   manipulate exactly one entity in the news article to   make the detection task harder .   Detector performance . Nevertheless , our pro-   posed detector performs similarly to or outper-   forms the state - of - the - art detector on all replace-   ment strategies across different numbers of entity   replacements . This result validates our hypothesis   that leveraging both factual and textual knowledge   can improve detection performance , overcoming   the limitations of relying only on textual knowl-   edge . Improvements of our proposed detector on   the GPT-2 generated entity manipulation task are   not significantly high due to sizeable increase in   manipulated entities absent in the knowledge base   ( e.g. ,∼50 % , see last three rows in Table 6 ) .   Entity identification performance . Our proposed   detector is equipped to identify entities that are ma-   nipulated in a news article . This task is harder due   to the imbalanced nature of the task as most of the   entities present in the news article are not manipu-   lated . As shown in Table 3 , our proposed detector   achieves high precision ( ≥70 % ) in identifying   manipulated entities , which makes our detector ap-   pealing for applications that favor precision . The   recall is very low ( < 15 % ) , which indicates the   difficulty of the task . We also experiment with a   baseline RoBERTa model trained at the token level   to identify spans of manipulated entities . How-   ever , the model seems overwhelmed by the major-   ity class ( token not part of the manipulated entity   span ) and predicts all the tokens to belong to the   majority class . We believe there is a lot of room   for improvement in this subtask .   Detecting articles with unknown manipulated   entities . Table 4 shows performance of the detector   on manipulated articles when all the manipulated   entities are not present in the knowledge base . We   observe that our proposed detector can rely on the   relations corresponding to the non - manipulated en-   tities and pretrained textual representations to out - perform , or at least be on par with , the RoBERTa   model .   Quality gap between human and manipulated   text . Table 5 shows how the quality of the ma-   nipulated text changes with respect to human writ-   ten text across different replacement strategies , for   different numbers of replacements . We utilize   MAUVE ( Pillutla et al . , 2021 ) , a metric to measure   the closeness of machine generated text to human   language based on divergence frontiers . Since the   proposed manipulations touch only limited spans   ( i.e. , entities ) in the entire document , the overall   quality of the manipulated text does not change   much with more replacements .   6 Conclusion   We presented the first principled approach for de-   veloping a model that can detect entity - manipulated   text articles . In addition to textual information , our   proposed detector exploits explicit factual knowl-   edge from a knowledge base to overcome the limi-   tations of relying only on stylometric signals . We   constructed challenging manipulated datasets by   considering various entity replacement strategies ,   including with random selection and GPT-2 gen-   eration . On all the experimental settings , our pro-   posed model outperforms ( or is at least on par with )   the baseline detector in overall detection accuracy .   Our results show that manipulated text detection re-   mains challenging . We hope that our work will trig-   ger further research on this important but relatively   understudied subfield of fake news detection.90Acknowledgements   We gratefully acknowledge support from the Nat-   ural Sciences and Engineering Research Council   of Canada ( NSERC ; RGPIN-2018 - 04267 ) , the So-   cial Sciences and Humanities Research Council   of Canada ( SSHRC ; 435 - 2018 - 0576 ) , Canadian   Foundation for Innovation ( CFI ; 37771 ) , Com-   pute Canada ( CC),UBC ARC - Sockeye , and Ad-   vanced Micro Devices , Inc. ( AMD ) . Any opinions ,   conclusions or recommendations expressed in this   material are those of the author(s ) and do not nec-   essarily reflect the views of NSERC , SSHRC , CFI ,   CC , ARC - Sockeye , or AMD . We also thank Ayushi   Dalmia for proofreading and helpful discussions .   References91A Appendices   A.1 Summary Statistics of Proposed Datasets .   Table 6 displays the statistics of proposed datasets .   A.2 Hyperparameter Search Space for All   Detectors   Table 7 displays the search space for hyperparame-   ters used to tune all the detectors.9293