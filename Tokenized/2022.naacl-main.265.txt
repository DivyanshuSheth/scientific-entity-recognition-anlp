  Stephanie Brandl , Ruixiang Cui , Anders Søgaard   University of Copenhagen , Denmark   { brandl , rc , soegaard}@di.ku.dk   Abstract   Gender - neutral pronouns have recently been   introduced in many languages to a ) include   non - binary people and b ) as a generic singu-   lar . Recent results from psycholinguistics sug-   gest that gender - neutral pronouns ( in Swedish )   arenotassociated with human processing diffi-   culties . This , we show , is in sharp contrast   with automated processing . We show that   gender - neutral pronouns in Danish , English ,   and Swedish are associated with higher per-   plexity , more dispersed attention patterns , and   worse downstream performance . We argue that   such conservativity in language models may   limit widespread adoption of gender - neutral   pronouns and must therefore be resolved .   1 Introduction   Many linguistic scholars have observed how tech-   nology in general has altered the course of language   evolution ( Kristiansen et al . , 2011 ; Abbasi , 2020 ) ,   e.g. , through the influence of social media conven-   tions . Language technologies , in particular , have   also been argued to have such effects , e.g. , by re-   ducing the pressure to acquire multiple languages .   Gender - neutral pronouns is not an entirely mod-   ern concept . In 1912 , Ella Flag Young , then su-   perintendent of the Chicago public - school system ,   said the following to a room full of school princi-   pals : " The English language is in need of a personal   pronoun of the third person , singular number , that   will indicate both sexes and will thus eliminate   our present awkwardness of speech . " The use of   gender - neutral pronouns has become much more   popular in recent years ( Gustafsson Sendén et al . ,   2021 ) . In 2013 , a gender - neutral pronoun was po-   litically introduced in Swedish ( Gustafsson Sendén   et al . , 2015 ) which can be used for both , people   identifying outside the gender dichotomy and as a   generic pronoun where information about gender   is either unavailable or irrelevant . In a recently recorded eye - tracking study , Ver-   goossen et al . ( 2020a ) found no evidence that na-   tive speakers of Swedish find it harder to pro-   cess gender - neutral pronouns than gendered pro-   nouns , an argument often brought up by oppo-   nents of gender - inclusive language ( Speyer and   Schleef , 2019 ; Vergoossen et al . , 2020b ) . In com-   bination with their increasing popularity , this sug-   gests gender - neutral pronouns have been or will   be widely and fully adapted over time ( Gustafs-   son Sendén et al . , 2015 , 2021 ) . However , since   language technology has the potential to alter the   course of language evolution , we want to make sure   that our NLP models do not become a bottleneck   for this positive development .   Contribution We extract stimuli from a Swedish   eye - tracking study that has shown no increase in   processing cost in humans for the gender - neutral   pronoun hencompared to gendered pronouns . We   translate those stimuli into English and Danish and   compare model perplexity across gendered and   gender - neutral pronouns for all three languages .   Furthermore , we systematically investigate perfor-   mance differences across pronouns in downstream   tasks , namely natural language inference ( NLI ) and   coreference resolution . Across the board , we find   that NLP models , unlike humans , are challenged   by gender - neutral pronouns , incurring significantly   higher losses when gendered pronouns are replaced   with their gender - neutral alternatives . We argue   this is a problem the NLP community must take   seriously .   2 Model perplexity and attention   In this section we introduce a Swedish eye - tracking   study and explain how we adapt this study to inves-   tigate gender - neutral pronouns in language models.3624en da sv   she / he they xe hun / han de høn hon / han hen   perplexity 1 1.49 2.37 1 1.21 3.35 1 1.8   correlation0.12 0.26 0.32 -0.14 0.03 -0.1 0.19 0.09   0.28 0.33 0.49 0.13 0.17 0.21 0.65 0.72   0.28 0.33 0.49 0.13 0.17 0.22 0.65 0.72   Humans and hen Vergoossen et al . ( 2020a ) re-   cently recorded a Swedish eye - tracking study to   test the hypothesis whether the gender neutral pro-   noun henhas a higher processing cost during pro-   noun resolution than gendered pronouns . Partici-   pants were reading sentence pairs where the first   sentence contained a noun referring to a person and   the second sentence contained a pronoun referring   to that person either with a gendered pronoun or   hen , for example :   70 - åringen dammsög golvet i vardagsrummet .   Han / Hen skulle få besök på kvällen .   The 70 - year - old vacuumed the living room floor .   He / They would have visitors in the evening .   It has recently been shown that attention flow , in   contrast to attention itself , correlates with human   fixation patterns in task - specific reading ( Eberle   et al . , 2022 ) . We applied a similar analysis pipeline   here and extracted all 384 sentence pairs and fed   them into the uncased Swedish BERT model . We   calculate perplexity values for each sentence pair   over word probabilities as given by BERT with   the formula proposed by Wang et al . ( 2019 ) . Fur-   thermore , we calculate attention flow ( Abnar and   Zuidema , 2020 ) propagated from layers 1 , 6 and   12 and extract attention flow values assigned to   the pronoun with respect to the entity . Attention   flow considers the attention matrices as a graph ,   where tokens are represented as nodes and atten-   tion scores as edges between consecutive layers .   The edge values , i.e. , attention scores , define the   maximal flow possible between a pair of nodes .   We consider different parameters of human fix-   ation which we assume might be influenced by a   change in pronouns , in particular during pronoun   resolution , i.e. , first and total fixation time on the   pronoun and fixation time after the first fixation on   the noun . For both attention flow and perplexity ,   however we could not find any meaningful correla - tion to those parameters . One reason for that might   be that the dataset only contains fixations for the   two entities , i.e. , pronoun and noun , which makes   data comparably sparse and impossible to extract   complete reading patterns .   Language models and gender - neutral pronouns   We therefore focus on the model - based data alone   in order to understand how well language models   can deal with gender - neutral pronouns . For this ,   we consider perplexity values on sentence - level   and calculate rank - based Spearman correlation be-   tween perplexity and attention flow for the afore-   mentioned layers . Perplexity has been treated as an   indicator for model surprisal and language model   quality ( Goodkind and Bicknell , 2018 ) thus we   argue that it serves as a reasonable indicator for   processing difficulty .   With this analysis , we can see if a ) gender-   neutral pronouns cause a higher sentence perplex-   ity , i.e. , a higher surprisal and if b ) a possible   higher surprisal is connected to higher attention   flow values on the pronoun with respect to the en-   tity .   We furthermore translate the sentence pairs into   English and Danish where we use two sets of   gender - neutral pronouns : 3rd person plural ( hence :   they / de ) which are used in both languages as   gender - neutral pronouns ( Miltersen , 2020 ) and neo-   pronouns ( xe for English ( Hekanaho , 2020 ) and   høn for Danish).For the translation , we use the   Google Translate API for Python and manually cor-   rect sentences such that semantics agree with the   original sentences in Swedish . We apply the same   experiments to those translated datasets with un-   cased Danish BERTand uncased English BERT .   Results We show results on perplexity and corre-   lations in Table 1 for Danish , English and Swedish.3625Perplexity values for the datasets with gendered   pronouns are set to 1and we show relative increase   for gender - neutral pronouns within a language   since perplexity values have been shown to not be   comparable across languages ( Mielke et al . , 2019 ;   Roh et al . , 2020 ) . There we can see that perplexity   scores for sentences with gender - neutral pronouns   are significantly higher ( Wilcoxon signed - rank test   resulted in p - values < 0.01for all pair - wise com-   parisons ) .   For the correlation between perplexity and at-   tention flow on the Swedish sentence pairs , we   can see a clear development between the first layer   where there is no correlation ( p > 0.05 ) for gender-   neutral henand very low correlation for gendered   pronouns which changes for the other layers where   correlations for henare even higher ( ρ= 0.72 )   than for gendered pronouns ( ρ= 0.65 ) . This sug-   gests that there is some development across layers   that is stronger for henthan for gendered pronouns .   Furthermore , we see a similar evolvement for corre-   lations across layers in English but a much weaker   correlation for Danish .   To investigate those effects across layers further ,   we look at word embeddings for all Swedish pro-   nouns from all 12 layers in BERT and compute   pair - wise cosine similarity including the Swedish   word for book ( bok ) as a baseline where we expect   no specific relation to pronouns . In Figure 1 , we see   less similarity between henand the other pronouns   in the first layer . This changes for layer 6 and 12   where word representations seem to be more sim-   ilar and the three 3rd person pronouns hen , han ,   honget closer to each other . This is in line with   the literature where it has been found that single   attention heads perform better on pronoun resolu-   tion than others . In particular middle and deeper   layers have shown stronger attention weights be-   tween coreferential elements ( Vaswani et al . , 2017 ;   Webster et al . , 2018 ; Clark et al . , 2019 ) . Given that   we do not consider individual heads or layers but   the entire attention graph it is not surprising that we   also see those effects in the top layer as has been   shown in the original paper ( Abnar and Zuidema ,   2020 ) .   3 Downstream Tasks   We also perform downstream task experiments on   natural language inference and coreference reso-   lution for both gendered and gender - neutral pro-   nouns to investigate to what extent gender - neutral   pronouns influence the performance .   Natural Language Inference Natural Language   Inference ( NLI ) is commonly framed as a classi-   fication task , which tests a model ’s ability to un-   derstand entailment and contradiction ( Bowman   et al . , 2015 ) . Despite high accuracies achieved by   SOTA models , we are yet to know whether they suc-   ceed in combating gender bias , especially in cross-   lingual settings . We apply two multilingual models   mBERT(Devlin et al . , 2019 ) and XLM - R(Con-   neau et al . , 2020 ) with cross - lingual fine - tuning ,   i.e. , we fine - tune on English and apply both models   also on Danish and Swedish . Therefore , mBERT   was fine - tuned on the English MNLI train split and   evaluated on XNLI . For XLM - R , we apply a model   that has been fine - tuned on both MNLI and ANLI   ( Nie et al . , 2020 ) . For English we test both mod-   els on the MNLI test split , for Danish and Swedish   we test on the extended XNLI corpus ( Singh et al . ,   2019 ) , the manual translation of the first 15000 sen-   tences of the MNLI corpus ( Williams et al . , 2018 )   from English into 15 languages .   Coreference Resolution We also run pronoun   resolution experiments on the Winogender dataset   ( Rudinger et al . , 2018 ) where all 720 English sen-   tences include an occupation , aparticipant and a   pronoun . For each occupation , two similar sen-   tences are composed , one where the pronoun refers   to the occupation and one where it refers to the   participant . Those sentences are then presented   in versions with different pronouns ( female , male ,   singular they ) . For our experiments , we compare   performance for those pronouns and add a version3626en da sv   orig . they xe orig . de høn orig . de hen   mBERT 83.33 83.23 81.82 71.15 71.24 69.72 71.91 71.14 71.06   XLM - R 95.13 94.81 94.05 80.19 79.18 75.48 78.79 78.5 78.58   for the gender - neutral pronoun xe . We run experi-   ments with NeuralCoref 4.0 in SpaCy .. Lauscher   et al . ( 2022 ) conduct similar experiments in English   where all pronouns are exchanged for their POS tag ,   in contrast to our experiments where we only ex-   change gendered pronouns and replace them with   gender - neutral pronouns .   For Danish , we apply the recently published   coreference model ( Barrett et al . , 2021 ) to both the   corresponding test set from the Dacoref dataset and   agender - neutralized version where we exchange   gendered pronouns hun / han for either hønor sin-   gular de .   4 Results   Natural Language Inference Accuracies for all   languages and both models are displayed in Table   2 . We overall see a very small drop in performance   for the datasets with gender neutral pronouns com-   pared to the original sentences . For mBERT we see   differences of 0.09−1.51 % , for XLM - R the drop   is slightly higher with 0.21−4.71 % . We see the   biggest difference for the Danish pronoun hønin   comparison to the original dataset .   she he they xe   acc in % 42.92 43.75 27.92 0   Coreference Resolution Table 3 shows accura-   cies on the English Winogender corpus for all four   pronouns . We see a clear drop in performance from   gendered pronouns ( she , he ) to both gender - neutral   pronouns ( they , xe ) . For xe , the model was not able   to perform coreference resolution at all . In mostorig . de høn   F1 - score 0.64 0.63 0.62   Prec . 0.70 0.69 0.69   Recall 0.59 0.57 0.56   cases it was not even recognized as part of a cluster   and in the rare cases where it was , it was clustered   with the wrong tokens . Please note that since this   dataset is not labelled we are only classifying if the   pronoun has been clustered with the correct entity .   Results on the Danish Coref corpus , where we   are able to perform a more extensive coreference   resolution task are displayed in Table 4 . We were   able to replicate results from Barrett et al . ( 2021 )   ( the first column orig . ) and see small drops in   performance for singular deandhøn .   5 Related Work   More eye - tracking studies have been conducted in-   vestigating the influence in processing cost for both   gender - neutral pronouns and the generic male pro-   noun . Irmen ( 2007 ) and Redl et al . ( 2021 ) find male   biases when using generic male pronouns in Dutch   and generic role nouns in German . The authors   of Sanford and Filik ( 2007 ) found a clear process-   ing cost when using singular they in English , how-   ever their stimuli did not include any investigation   of how ( anti-)stereotypes influence this process-   ing cost and is thus only in parts comparable to   other studies . English datasets have been proposed   to investigate gender bias in pronoun resolution   but have not reported on performance differences   between gendered and gender - neutral pronouns   ( Rudinger et al . , 2018 ; Zhao et al . , 2018 ; Webster   et al . , 2018 ) . Sun et al . ( 2021 ) propose a rewrit-   ing task where data is transferred from gendered3627to gender - neutral pronouns to train more inclusive   language models . Cao and Daumé III ( 2020 ) and   Dev et al . ( 2021 ) discuss the necessity of including   non - binary pronouns into NLP research ( see also   Stanczak and Augenstein ( 2021 ) ) .   6 Discussion   With this paper we provide a first study on how   well language can handle gender - neutral pronouns   in Danish , English and Swedish for various tasks .   We observe an increase in perplexity for gender-   neutral pronouns and correlations between perplex-   ity on sentence level and attention flow on the   pronoun , in particular for English and Swedish   that gets stronger across layers . This indicates that   language models indeed struggle with the use of   gender - neutral pronouns , even with singular they ,   which has been used for many years as gender-   neutral ( Saguy and Williams , 2022 ) . The reason   for this most likely lies in the sparse representa-   tion of gender - neutral pronouns in the training data   and the fact that language models , once they are   trained and published usually are not updated ( Ben-   der et al . , 2021 ) . However , Transformer models   pre - trained on subword units have been shown to   be robust with respect to word frequency ( Sennrich   et al . , 2016 ) and thus should be able to process   unfamiliar gender - neutral pronouns . At the same   time , we observe that word representations of all   Swedish 3rd person pronouns grow closer in mid-   dle and top layers ( see Figure 1 ) which suggests   that relevant information is also learned for gender-   neutral hen .   For NLI , we only see a small drop in perfor-   mance when exchanging gendered pronouns for   gender - neutral pronouns which is in the same range   as a baseline analysis where we exchange punctua-   tion ( " ! " for " . " ) , except for Danish høn . We argue   that classification in NLI probably does not heavily   rely on individual pronouns in most cases . In stark   contrast to pronoun resolution where we see a very   clear drop in performance for English when ap-   plying singular they in comparison to both female   and male pronouns , again this is surprising since in   theory language models should have seen training   samples where singular they has been used . The   small drop in performance for Danish coreference   resolution might be because this dataset does not   solely focus on pronoun resolution , though further   investigation is needed here . We strongly argue that   more needs to be done to adapt language models toa more gender inclusive language , initiatives like   the rewriting task as proposed by Sun et al . ( 2021 )   need to be implemented and extended .   Acknowledgements   This work was partially funded by the Platform   Intelligence in News project , which is supported   by Innovation Fund Denmark via the Grand Solu-   tions program . We thank Vinit Ravishankar and   Jonas Lotz for fruitful discussions and Daniel Her-   shcovich and Yova Kementchedjhieva for proof-   reading and valuable inputs on the manuscript . We   also thank Kellie Webster for her valuable input on   gender - neutral pronouns .   References362836293630