  Daphna KeidarAndreas OpedalZhijing JinMrinmaya SachanETH Zürich , Max Planck Institute for Intelligent Systems , Tübingen , Germany   dkeidar@ethz.ch , andreas.opedal@inf.ethz.ch ,   zjin@tue.mpg.de , mrinmaya.sachan@inf.ethz.ch   Abstract   Languages are continuously undergoing   changes , and the mechanisms that underlie   these changes are still a matter of debate . In   this work , we approach language evolution   through the lens of causality in order to   model not only how various distributional   factors associate with language change , but   how they causally affect it . In particular , we   study slang , which is an informal language   that is typically restricted to a speciﬁc group   or social setting . We analyze the semantic   change and frequency shift of slang words and   compare them to those of standard , nonslang   words . With causal discovery and causal   inference techniques , we measure the effect   that word type ( slang / nonslang ) has on both   semantic change and frequency shift , as well   as its relationship to frequency , polysemy and   part of speech . Our analysis provides some   new insights in the study of language change ,   e.g. , we show that slang words undergo   less semantic change but tend to have larger   frequency shifts over time .   1 Introduction   Language is a continuously evolving system , con-   stantly resculptured by its speakers . The forces that   drive this evolution are many , ranging from pho-   netic convenience to sociocultural changes ( Blank ,   1999 ) . In particular , the meanings of words and   the frequencies in which they are used are not   static , but rather evolve over time . Several pre-   vious works , in both historical and computational   linguistics , have described diachronic mechanisms ,   often suggesting causal relationships . For example ,   semantic change , i.e. change in the meaning of a   word , has both been suggested to cause ( Wilkins ,   1993 ; Hopper and Traugott , 2003 ) and be caused by   ( Hamilton et al . , 2016 ) polysemy , while also partFigure 1 : We observe very different change dynamics   for the slang word “ duckface ” and the nonslang word   “ inclusive . ” “ Inclusive ” has acquired a new meaning ,   reﬂected in a high semantic change score of 0:77as   measured by our model . “ Duckface ” undergoes little   semantic change , scored 0:39by our model , while its   usage frequency varies greatly .   of speech ( POS ) has been implied to be a causal   factor behind semantic change ( Dubossarsky et al . ,   2016 ) . However , none of these studies perform a   causal analysis to verify these claims . Causality   ( Pearl , 2009 ) allows us to not only infer causal ef-   fects between pairs of variables , but also model   their interactions with other related factors .   In this work , we focus on the linguistic evolution   of slang , deﬁned as colloquial and informal lan-   guage commonly associated with particular groups   ( González , 1998 ; Bembe and Beukes , 2007 ) , and   use a causal framework to compare the change   dynamics of slang words to those of standard lan-   guage . More speciﬁcally , we compare the semantic   change as well as the changes in frequency , i.e. ,1422frequency shift , over time between slang words   and standard , nonslang words . We learn a causal   graphical model ( Spirtes et al . , 2000 ) to assess how   these variables interact with other factors they have   been previously found to correlate with , such as fre-   quency , polysemy andpart of speech ( Dubossarsky   et al . , 2016 ; Hamilton et al . , 2016 ) . Having discov-   ered a graph , we proceed to use do - calculus ( Pearl ,   1995 ) to evaluate the causal effects of a word ’s type   ( slang / nonslang ) on semantic change and frequency   shift .   Semantic change is measured using the average   pairwise distance ( APD ) ( Sagi et al . , 2009 ; Giu-   lianelli et al . , 2020 ) between time - separated con-   textualized representations , which were obtained   from a Twitter corpus via a bi - directional language   model ( Liu et al . , 2019 ) . Our method builds on re-   cent semantic change literature ( Schlechtweg et al . ,   2020 ) , with novel additions of dimensionality re-   duction and a combined distance function .   By deploying a causal analysis , we establish that   there is not just an association , but a direct effect of   a word ’s type on its semantic change and frequency   shift . We ﬁnd that a word being slang causes it to   undergo slower semantic change and more rapid   decreases in frequency . To illustrate , consider the   slang word “ duckface ” and the nonslang word “ in-   clusive ” as shown in Figure 1 . Duckface is a face   pose commonly made for photos ( Miller , 2011 )   in the early 2010s , and while it has largely de-   creased in frequency since , its meaning has not   changed . In contrast , the nonslang word “ inclu-   sive ” has developed a new usage in recent years   ( Merriam - Webster , 2019 ) and was given a high se-   mantic change score by our model .   Our analysis also sheds light on a couple of pre-   vious ﬁndings in the diachronic linguistics litera-   ture . We ﬁnd support for the S - curve theory ( Kroch ,   1989 ) , showing a causal effect from a word ’s pol-   ysemy to its frequency . This relationship is ev-   ident in the increase in frequency that the word   “ inclusive ” displays in Figure 1 after it develops   a new meaning ( Merriam - Webster , 2019 ) . How-   ever , similar to Dubossarsky et al . ( 2017 ) , we do   not ﬁnd causal links to semantic change from fre-   quency , polysemy , or POS , which have been sug-   gested in previous works ( Hamilton et al . , 2016 ;   Dubossarsky et al . , 2016 ) .   In summary , our main contributions are three-   fold : ( i ) we formalize the analysis of change dy-   namics in language with a causal framework ; ( ii)we propose a semantic change metric that builds   upon contextualized word representations ; and   ( iii ) we discover interesting insights about slang   words and semantic change – e.g. , showing that   the change dynamics of slang words are different   from those of nonslang words , with slang words   exhibiting both more rapid frequency ﬂuctuations   and less semantic change .   2 Related Work   2.1 Semantic Change   A typical method for measuring semantic change   is by comparing word representations across time   periods ( Gulordava and Baroni , 2011 ; Kim et al . ,   2014 ; Jatowt and Duh , 2014 ; Kulkarni et al . , 2015 ;   Eger and Mehler , 2016 ; Schlechtweg et al . , 2019 ) .   With this approach , previous research has proposed   laws relating semantic change to other linguistic   properties ( Dubossarsky et al . , 2015 ; Xu and Kemp ,   2015 ; Dubossarsky et al . , 2016 ; Hamilton et al . ,   2016 ) . For instance , Dubossarsky et al . ( 2016 )   ﬁnd that verbs change faster than nouns , whereas   Hamilton et al . ( 2016 ) discover that polysemous   words change at a faster rate , while frequent words   change slower . However , the validity of some of   these results has been questioned via case - control   matching ( Dubossarsky et al . , 2017 ) , highlighting   the inﬂuence of word frequency on the represen-   tations and thus on the semantic change metric   ( Hellrich and Hahn , 2016 ) . Such analyses can in-   deed give stronger evidence for causal effects . In   this work we take a methodologically different ap-   proach , considering observational data alone for   our causal analysis .   The aforementioned works rely on ﬁxed word   representations , whereas more recent approaches   ( Hu et al . , 2019 ; Giulianelli et al . , 2020 ) have pro-   posed semantic change measures based on con-   textualized word embeddings ( Peters et al . , 2018 ;   Devlin et al . , 2019 ) , which can ﬂexibly capture con-   textual nuances in word meaning . This has lead   to a further stream of work on semantic change   detection with contextualized embeddings ( Mar-   tinc et al . , 2020 ; Kutuzov and Giulianelli , 2020 ;   Schlechtweg et al . , 2020 ; Montariol et al . , 2021 ;   Kutuzov et al . , 2021 ; Laicher et al . , 2021 ) . We   build upon this line of work and extend them using   principal component analysis ( PCA ) and a combi-   nation of distance metrics.14232.2 Characterization and Properties of Slang   Slang is an informal , unconventional part of the   language , often used in connection to a certain   setting or societal trend ( Dumas and Lighter , 1978 ) .   It can reﬂect and establish a sense of belonging to a   group ( González , 1998 ; Bembe and Beukes , 2007 ;   Carter , 2011 ) or to a generation ( Citera et al . , 2020 ;   Earl , 1972 ; Barbieri , 2008 ) .   Mattiello ( 2005 ) highlights the role slang plays   in enriching the language with neologisms , and   claims that it follows unique word formation pro-   cesses . Inspired by this , Kulkarni and Wang ( 2018 )   propose a data - driven model for emulating the gen-   eration process of slang words that Mattiello ( 2005 )   describes . Others have described the ephemeral-   ity of slang words ( González , 1998 ; Carter , 2011 ) ,   although this property has not been previously ver-   iﬁed by computational approaches .   3 Causal Methodology for Change   Dynamics   Examining change dynamics through a causal lens   helps determine the existence of direct causal ef-   fects , by modeling the interactions between vari-   ables . For example , it allows us to conclude   whether word type directly inﬂuences semantic   change , or rather inﬂuences polysemy , which in   turn causes semantic change . In this section , we   ﬁrst give a short overview of relevant work on   causality , before presenting how we apply these   concepts to word change dynamics .   3.1 Overview of Causal Discovery and   Causal Inference   A common framework for causal reasoning is   through causal directed acyclic graphs ( DAGs )   ( Pearl , 2009 ) . A causal DAG consists of a pair   ( G;P)whereG= ( V;E)is a DAG and Pis   a probability distribution over a set of variables .   Each variable is represented by a node v2V , and   the graph ’s edges e2Ereﬂect causal relationships .   There are two main tasks in causality . Causal dis-   covery is the task of uncovering the causal DAG   that explains observed data . Assuming a causal   DAG , the task of causal inference then concerns   determining the effect that intervening on a vari-   able , often referred to as treatment , will have on   another variable , often referred to as outcome .   The causal DAG is often inferred from domain   knowledge or intuition . However , in cases where   we can not safely assume a known causal struc - ture , causal discovery methods come in useful .   Constraint - based methods ( Spirtes et al . , 2000 )   form one of the main categories of causal discov-   ery techniques . These methods use conditional   independence tests between variables in order to   uncover the causal structure . To do so , they rely   on two main assumptions : that the graph fulﬁlls   the global Markov property and the faithfulness   assumption . Together they state that we observe   conditional independence relations between two   variables in the distribution if and only if these two   variables are d - separated ( Geiger et al . , 1990 ) in   the graphical model . For more details , we refer to   Appendix D.1 .   Causal inference is commonly approached with   do - calculus ( Pearl , 1995 ) . We denote the interven-   tion distribution P(Yjdo(X = x))to be the distri-   bution of the outcome Yconditioned on an inter-   ventiondo(X = x)which forces the treatment   variableXto take on the value x. Note that this is   in general not necessarily equal to P(YjX = x ) .   When they are not equal , we say that there is con-   founding . Confounding occurs when there is a third   variableZ , which causes both the treatment Xand   the outcome Y.   We say that there is a causal effect of XonYif   there existxandxsuch that   P(Yjdo(X = x))6 = P(Yjdo(X = x)):(1 )   One way to quantify the causal effect is with the   average causal effect ( ACE ) :   E[Yjdo(X = x)] E[Yjdo(X = x ) ] : ( 2 )   To estimate the causal effect using observational   data , we need to rewrite the intervention distribu-   tion using only conditional distributions . Assuming   a causal DAG , this can be done with the truncated   factorization formula ( Pearl , 2009 ) ,   P(Xjdo(X = x ) ) =   = YP(XjX ) 1;(3 )   forWV , withXbeing the variables in P   corresponding to the nodes in W.14243.2 Causality for Change Dynamics   In this work , we estimate the direct causal effect of   a word ’s type on its semantic change and frequency   shift dynamics . In order to establish that such an   effect exists , and to know which variables to control   for , we turn to causal discovery algorithms . The   variables in our causal graph additionally include   frequency , polysemy and POS .   For learning the causal graph , we choose the   constraint - based PC - stable algorithm ( Colombo   and Maathuis , 2014 ) , an order - independent vari-   ant of the well - known PC algorithm ( Spirtes et al . ,   2000 ) , discussed in Appendix D.1 . We are learn-   ing a mixed graphical model ( Lauritzen , 1996 ; Lee   and Hastie , 2015 ) , consisting of both continuous   ( e.g. , frequency ) and categorical ( e.g. , type ) vari-   ables . For this reason we opt for constraint - based   algorithms , allowing us to tailor the conditional   independence tests according to the various data   types .   Having learned the causal graph ( Section 6.2 ) ,   we proceed to estimate the ACE of word type on   both semantic change and frequency shift using   do - calculus ( Section 6.3 ) .   4 Slang and Nonslang Word Selection   We select 100 slang words and 100 nonslang words   for our study , presented in Appendix E. In the trade-   off between statistical signiﬁcance and time spent   on computation and data collection , we found that   a set of 200 words was enough to get highly sig-   niﬁcant results . The slang words are randomly   sampled from the Online Slang Dictionary , which   provides well - maintained and curated slang word   deﬁnitions as well as a list of 4,828 featured slang   words as of June 2021 . We limit the scope of our   study to only encompass single - word expressions ,   and in so doing we ﬁlter out 2,169 multi - word   expressions . To further clean the data , we also   delete words with only one character and acronyms .   Lastly , we limit the causal analysis to words that   are exclusively either slang or nonslang , excluding   “ hybrid ” words with both slang and nonslang mean-   ings , such as “ kosher ” or “ tool . ” Including words   of this type would have interfered with the causal   analysis by creating a hardcoded dependency be-   tween word type and polysemy , as these words by   deﬁnition are polysemous . We do however per-   form a separate analysis of the hybrid words in   Appendix C.For the reference set of standard , nonslang ,   words we sample 100 words uniformly at random   from a list of all English words , supplied by the   wordfreq library in Python ( Speer et al . , 2018 ) .   5 Data Collection   We curate a Twitter dataset from the years 2010 and   2020 , which we select as our periods of reference ,   and collect the following variables :   •Word type : Whether a word is slang or not   •Word frequency : The average number of tweets   containing the word per day in 2010 and 2020   ( Section 5.2 )   •Frequency Shift : The relative difference in fre-   quency the word has undergone between 2010   and 2020 ( Section 5.3 )   •Polysemy : The number of senses a word has   ( Section 5.4 )   •Part of speech : A binary variable for each POS   tag ( Section 5.5 )   •Semantic change : The semantic change score   of the word from 2010 to 2020 ( Section 5.6 )   5.1 Twitter Dataset   As a social media platform , Twitter data is rich   in both slang and nonslang words . The Twitter   dataset we curated comprises 170,135 tweets from   2010 and 2020 that contain our selected words .   Sampling tweets from two separate time periods   allows us to examine the semantic change over a   10 - year gap . For every slang and nonslang word ,   and each of the two time periods , we obtain 200-   500 random tweets that contain the word and were   posted during the corresponding year . We keep   each tweet ’s text , tweet ID , and date it was posted .   As a post - processing step , we remove all URLs and   hashtags from the tweets . To protect user privacy ,   we further replace all user name handles with the   word “ user . ” On average , we have 346 tweets per   slang word and 293 tweets per nonslang word .   5.2 Word Frequency   We approximate a word ’s frequency by the average   number of times it is tweeted within 24 hours . This   average is calculated in practice over 40 randomly   sampled 24 hour time frames in a given year , in   each of which we retrieve the number of tweets con-   taining the word . The frequencies are calculated   separately for 2010 and 2020 . Due to the growing1425   popularity of social media , the number of tweets   has signiﬁcantly increased over the decade . There-   fore , we divide the counts from 2020 by a factor of   6:4 , which is the ratio between the average word   counts in both years in our dataset . The frequencies   from both years are then averaged to provide the   frequency variable for the causal analysis .   5.3 Frequency Shift   We are now interested in analyzing the dynamics   of frequency shifts . To evaluate the relative change   in frequency for a given word wwe take   FreqShift ( w ) = logx(w )   x(w)(4 )   where , x(w)is the frequency of word win yeark .   This has been shown to be the only metric for rela-   tive change that is symmetric , additive , and normed   ( Tornqvist et al . , 1985 ) . Importantly , this measure   symmetrically reﬂects both increases and decreases   in relative frequency . The mean relative changes in   frequency were 0:486(1:644 ) for slang words   and0:533(1:070 ) for nonslang words , where a   positive score corresponds to an increase in fre-   quency . As evident in Figure 2 , not only did more   slang words exhibit a decrease in frequency than   nonslang ones , the words that showed the highest   frequency increase are also slang .   We also examine the absolute value of Eq . ( 4 )   to evaluate the degree of change , may it be a de-   crease or an increase . We ﬁnd that , as expected , slang words have signiﬁcantly higher changes in   frequency than nonslang words ( p < 0:05 ) . See   Appendix C for more details .   5.4 Polysemy   We deﬁne a word ’s polysemy score as the number   of distinct senses it has . For nonslang words , we   take the number of senses the word has in Merriam   Webster and for slang words we take the number   of deﬁnitions on the Online Slang Dictionary . We   use two separate resources as we ﬁnd that no dictio-   nary encapsulates both slang and nonslang words .   The mean polysemy scores are ( 2:0742:595 )   for slang words and ( 3:0792:780 ) for nonslang   words with a signiﬁcant difference in distribution   ( p < 0:05)according to a permutation test , im-   plying that the latter are used with a larger variety   of meanings . In addition , the slang senses of the   hybrid words exhibit a distribution similar to those   of the slang words ( Appendix C ) . More polyse-   mous words tend to have a higher word frequency   in our dataset – the log transform of frequency and   polysemy display a highly signiﬁcant ( p<0:001 )   linear correlation coefﬁcient of 0:350 .   5.5 Part of Speech   For each word , we retrieve four binary variables , in-   dicating whether a word can be used as noun , verb ,   adverb or adjective , which were the four major   POS tags observed in our data . To calculate these   variables we run the NLTK POS tagger ( Loper and   Bird , 2002 ) on the tweets , and collect the distribu-   tion of POS tags for each word . Note that a word   may have more than one POS tag , depending on   the context in which it is used . Each of the binary   variables is then set to be 1 if the word had the   corresponding POS tag in at least 5 % of its tweets   and 0 otherwise .   5.6 Semantic Change Score   In this section we explain the details of how we   obtain the semantic change scores . We start by   ﬁne - tuning a bi - directional language model on a   slang - dense corpus ( Section 5.6.1 ) , after which   we survey the literature and propose metrics ( Sec-   tion 5.6.2 ) that we use to perform an extensive   experimentation study to ﬁnd the most suitable one   ( Section 5.6.3 ) . Finally , we apply this metric to our1426sets of slang and nonslang words on the Twitter   data ( Section 5.6.4 ) .   5.6.1 Obtaining Contextualized   Representations   We familiarize the bi - directional language model   with slang words and the contexts in which they are   used by ﬁne - tuning it on the masked language mod-   eling task . For this purpose we use a web - scraped   dataset from the Urban Dictionary , previously col-   lected by Wilson et al . ( 2020 ) . After preprocessing   and subsampling , the details of which can be found   in Appendix A.1 , we are left with a training set of   200;000slang - dense text sequences .   As our bi - directional language model we select   RoBERTa ( Liu et al . , 2019 ) . Beyond performance   gains compared to the original BERT ( Devlin et al . ,   2019 ) , we select this model since it allows for more   subword units . We reason , that this could be use-   ful in the context of slang words since potentially   some of the sub - units used in these words would   not have been recognized by BERT . We choose the   smaller 125 M parameter base version for computa-   tional reasons . We train the model using the Adam   optimizer ( Kingma and Ba , 2015 ) with different   learning rates   . The lowest loss on the test set   was found with   = 10 , which we proceed with   for scoring semantic change . For more details on   training conﬁgurations , we refer to Appendix A.2 .   5.6.2 Quantifying Semantic Change   In order to select a change detection metric , we   evaluate our model on the SemEval-2020 Task 1   on Unsupervised Lexical Semantic Change Detec-   tion ( Schlechtweg et al . , 2020 ) . This task provides   the ﬁrst standard evaluation framework for seman-   tic change detection , using a large - scale labeled   dataset for four different languages . We restrict   ourselves to English and focus on subtask 2 , which   concerns ranking a set of 37target words according   to their semantic change between two time peri-   ods . The ranking is evaluated using Spearman ’s   rank - order correlation coefﬁcient .Our space of   conﬁgurations includes layer representations , di-   mensionality reduction techniques and semantic   change metrics .   Layer Representations : Previous work ( Etha-   yarajh , 2019 ) has shown that embeddings re-   trieved from bi - directional language models are notisotropic , but are rather concentrated around a high-   dimensional cone . Moreover , the level of isotropy   may vary according to the layer from which the rep-   resentations are retrieved ( Ethayarajh , 2019 ; Cai   et al . , 2021 ) . This leads us to experiment with   representations from different layers in our ﬁne-   tuned RoBERTa model , namely , taking only the   ﬁrst layer , only the last layer or summing all layers .   Dimensionality Reduction : To the best of our   knowledge , only one previous semantic change   detection approach ( Rother et al . , 2020 ) has incor-   porated dimensionality reduction , more speciﬁcally   UMAP ( McInnes et al . , 2018 ) . As the Euclidean   distances in the UMAP - reduced space are very sen-   sitive to hyperparameters and it does not retain an   interpretable notion of absolute distances , it might   be unsuitable for pure distance - based metrics like   APD , and we therefore also experiment with PCA .   Metrics for Semantic Change : Given represen-   tationsX = fx;:::;xgfor a particular word   in time period t , we deﬁne the average pairwise   distance ( APD ) between two periods as   APD(X;X ) = 1   nnXd(x;x ) ;   ( 5 )   for some distance metric d(; ) , wheren;nare   the number of words in each time period . We   experiment with Euclidean distance d(x;x ) ,   cosine distance d(x;x)and Manhattan dis-   tanced(x;x ) . Furthermore , we propose a novel   combined metric . Note that d(;)2[0;1]and   d(;)2[0;2 ] . Further note that   jjx xjjjjxjj+jjxjj ( 6 )   Normalizing both metrics for a support in [ 0;1 ] , we   get a combined metric with the same unit support   to be the following average :   d(x;x ) = 0:5d(x;x)p   jjxjj+jjxjj(7 )   + d(x;x )   4(8 )   We argue that this provides a more complete met-   ric , capturing both absolute distance and the angle   between vectors .   In addition to the APD metrics , we experiment   with distribution - based metrics ( see Appendix B.1).1427Reduction h APD Score   PCA 100dandd0:489   PCA 100d 0:464   PCA 100d 0:298   None 768dandd 0:345   5.6.3 Evaluating the Semantic Change Scores   We ﬁrst compare the results for the three types   of layer representations for different APD metrics ,   and note that summing all layer representations   yields the best results . Consequentially , we pro-   ceed with the rest of the experiments using only   these representations . For both PCA and UMAP ,   we experiment with projecting the representations   down toh2 f2;5;10;20;50;100gdimensions .   These combinations are tested together with the   APD metrics as presented in Section 5.6.2 as well   as the distribution - based metrics described in Ap-   pendix B. The latter do not however in general   display signiﬁcant correlations .   We present a small subset of the scores result-   ing from the APD conﬁgurations in Table 1 , high-   lighting our ﬁnding that both PCA dimensionality   reduction and using a combined metric improve   the performance . More results and comparisons   to baselines are presented in Appendix B.3 . We   observe that the proposed combined metric consis-   tently outperforms both danddacross values   ofhfor PCA . We also note that UMAP projec-   tions perform poorly with the APD metrics and   that projecting down to 50 - 100 dimensions seems   to be optimal , which maintains 70 - 85 % of the vari-   ance as we illustrate in Appendix B.2 . In addition ,   both norm - based metrics danddperform worse   with dimensionality reduction . As our ﬁnal metric ,   we choose the best performing conﬁguration on   SemEval , with PCA h= 100 and the combined   metric , as seen in Table 1 .   5.6.4 Semantic Change Scores for Slang and   Nonslang Words on the Twitter Dataset   We obtain semantic change scores using the Twitter   dataset described in Section 5.1 . For the seman-   tic change analysis , we exclude words that have   less than 150 tweets in each time period within the   dataset , which leaves us with 80 slang and 81 non-   slang words . We also normalize the scores accord-   ing to the sample . The resulting semantic change   scores are shown in Figure 3 . The mean semantic   change scores are 0:564(0:114 ) for slang words   and0:648(0:084 ) for nonslang words . The dif-   ference in semantic change score distributions is   signiﬁcant ( p<0:001 ) via a permutation test . The   word with the highest semantic change score of 1   is “ anticlockwise , ” and the word with the lowest   score of 0is “ whadja . ”   6 Causal Analysis   6.1 Preparation for Causal Discovery   PC - stable is constraint - based and thus makes use   of conditional independence tests . In the case of   continuous Gaussian variables , we can perform   partial correlation tests to assess conditional inde-   pendence , since zero partial correlation in this case   is equivalent to conditional independence ( Baba   et al . , 2004 ) . As word frequency has been sug-   gested to follow a lognormal distribution ( Baayen ,   1992 ) , we take the log transform of it . The continu-   ous variables semantic change , frequency change   andlog - frequency are then all assumed to be ap-   proximated well by a Gaussian distribution , which   is conﬁrmed by diagnostic density and Q - Q plots   ( displayed in Appendix D.2 ) .   We categorize the discrete polysemy variable ,   experimenting with nine different plausible cate-   gorizations for the sake of robustness of the re-   sults . Word type and POS are categorical in na-   ture . For the categorical variables and for mixes   of categorical and continuous variables , we per-   form chi - squared mutual information based tests1428   ( Edwards , 2000 ) , since the approximate null distri-   bution of the mutual information is chi - squared   ( Brillinger , 2004 ) . For all conditional indepen-   dence tests we experiment with signiﬁcance levels   2f0:01;0:03;0:05 g.   6.2 Resulting Causal Structure   In Figure 4 we see the result from the above ap-   proach , with dashed lines representing edges that   were apparent in most but not all of the conﬁgura-   tions . See Appendix D.3 for a sensitivity analysis .   We ﬁrst observe that word type has a direct   causal effect on both the semantic change score   and the frequency shift , without any confounding   from the other variables . We also note a direct in-   ﬂuence of word polysemy on frequency .   Moreover , none of the four POS categories ,   which are all gathered in one node in Figure 4 ,   have a causal link to any of the other variables . We   additionally observe a dependency between word   type and polysemy . This edge could not be oriented   by the PC - stable algorithm , however we manually   orient it as outgoing from type and ingoing to pol-   ysemy , since an intervention on type should have   a causal effect on the number of word senses and   not vice versa . It is also interesting to note that   polysemy does not seem to have a causal effect   on semantic change . Its association with semantic   change ( p < 0:05 , rejecting the null hypothesis   of independence between polysemy and semantic   change ) is instead confounded by word type .   6.3 Causal Effects   In our case of no confounders , evaluating the   ACE of word type on semantic change is straight-   forward , as it reduces to the difference between theconditional expectations :   E[Sjdo(T = nonslang ) ]  E[Sjdo(T = slang ) ] =   = E[SjT = nonslang ]  E[SjT = slang ]   ( 9 )   See Appendix D.4 for a derivation . The case of   frequency shift is analogous .   We estimate the expectations by the sample   means on the normalized values and get an average   causal effect of 0:084 , which is a highly signiﬁ-   ca nt value ( p < 0:001 ) based on a t - test . For the   observed changes in relative frequency , calculated   according to Eq . ( 4 ) , we get an average causal ef-   fect of 1:017(p<0:001via a t - test ) .   7 Discussion   We analyze the dynamics of frequency shift and se-   mantic change in slang words , and compare them to   those of nonslang words . Our analysis shows that   slang words change slower in semantic mean-   ing , but adhere to more rapid frequency ﬂuctu-   ations , and are more likely to greatly decrease   in frequency . Our study is the ﬁrst computational   approach to conﬁrm this property in slang words   ( González , 1998 ; Carter , 2011 ) .   To ensure that this is the result of a causal ef-   fect , and not mediated through another variable or   subject to confounders , we model the data with a   causal DAG , by also considering the potential inter-   acting variables polysemy , frequency and POS . We   discover that there is no inﬂuence of confounders ,   nor are there mediators between a word ’s type and   its semantic change or its frequency shift , which   conﬁrms a direct causal effect . This means that if   we could intervene on a word ’s type , i.e. , by setting   it to be slang instead of nonslang or vice versa , we   would expect its change dynamics to differ .   Our results are consistent with those of Du-   bossarsky et al . ( 2017 ) , which found that neither1429the law relating semantic change to frequency , pol-   ysemy ( Hamilton et al . , 2016 ) nor prototypicality   ( Dubossarsky et al . , 2015 ) were found to be as   strong as previously thought after a case - control   study using a scenario without semantic change .   Indeed , there is no directed path from polysemy or   frequency to semantic change in our causal graph ,   but they are both inﬂuenced by word type . We leave   for future research to explore whether other word   categorizations , e.g. , related to speciﬁc domains ,   languages or phonetic aspects , sustain this result .   In addition , our analysis does not support the   claim that POS could underlie semantic change   ( Dubossarsky et al . , 2016 ) . We note however that   as our vocabulary contains 50 % slang words , the   results need not be consistent with results obtained   with a word sample drawn from standard language .   Moreover , in the causal structure we discover   thatword polysemy has a direct effect on word   frequency , which is in line with previous linguis-   tic studies showing that a word ’s frequency grows   in an S - shaped curve when it acquires new mean-   ings ( Kroch , 1989 ; Feltgen et al . , 2017 ) , as well   as a known positive correlation between polysemy   and frequency ( Lee , 1990 ; Casas et al . , 2019 ) . We   emphasize that this relationship is not merely an ar-   tifact of contextualized word representations being   affected by frequency ( Zhou et al . , 2021 ) , since our   polysemy score does not rely on word representa-   tions as in Hamilton et al . ( 2016 ) . Our approach   is however not without drawbacks – the polysemy   variable is collected from dictionaries , which may   be subjective in their assignments of word senses .   Our study , along with previous work on the dy-   namics of semantic change , is limited by mainly   considering distributional factors . Linguists have   suggested that sociocultural , psychological and po-   litical factors may drive word change dynamics   ( Blank , 1999 ; Bochkarev et al . , 2014 ) , and slang   words are not an exception . Although challenging   to measure , the inﬂuence of such factors on slang   compared to nonslang words would be interesting   to examine in future work .   In conclusion , we believe that a causal analysis   as we have presented here provides a useful tool to   understand the underlying mechanisms of language .   Complementing the recent emergence of research   combining causal inference and NLP ( Feder et al . ,   2021 ) , we have shown that tools from causality   can also be beneﬁcial for gaining new insights in   diachronic linguistics.8 Conclusion   In this work , we have analyzed the diachronic   mechanisms of slang language with a causal   methodology . This allowed us to establish that   a word ’s type has a direct effect on its semantic   change and frequency shift , without mediating ef-   fects from other distributional factors .   Acknowledgments   We would like to thank Steven R. Wilson for provid-   ing us with the Urban Dictionary data and Walter   Rader for providing us with a curated set of slang   words from the Online Slang Dictionary . For the   Twitter data , we are thankful to have been able to   get access to Twitter ’s Academic Research Track .   Finally , we gratefully acknowledge feedback and   helpful comments from Mario Giulianelli , Yifan   Hou , Bernhard Schölkopf and three anonymous   reviewers .   This material is based in part upon works sup-   ported by the John Templeton Foundation ( grant   # 61156 ) ; by a Responsible AI grant by the Hasler-   stiftung ; by an ETH Grant ( ETH-19 21 - 1 ) ; by   the German Federal Ministry of Education and   Research ( BMBF ): Tübingen AI Center , FKZ :   01IS18039B ; and by the Machine Learning Clus-   ter of Excellence , EXC number 2064/1 – Project   number 390727645 .   Ethical Considerations   Our dataset is composed solely of English text .   This means that our analysis applies uniquely to   the English language , and results may differ in   other languages . Moreover , for the purpose of this   study , we curated a dataset of 170;135tweets . We   emphasize that in order to protect the anonymity   of users , we remove all author IDs from the data ,   and replace all usernames with the general token   “ user . ” In the Urban Dictionary dataset we received   from Wilson et al . ( 2020 ) , we similarly remove the   author IDs and only consider the entry text .   References1430143114321433   A Appendix – Fine - tuning with Urban   Dictionary data   A.1 Preprocessing   The full Urban Dictionary data contains 3;534;966   word deﬁnitions . In the dataset provided by Wil-   son et al . ( 2020 ) , each entry contains a deﬁnition ,   examples in which the word occurs , number of up-   votes & downvotes from website visitors , username   of the submitter and a timestamp . As the data is   crowd - sourced , many of these entries are noisy and   of low quality . We therefore ﬁlter the lower quality   deﬁnitions out before ﬁne - tuning RoBERTa . Af-   ter performing data exploration , we came up with   two criteria that we found the most indicative of a   deﬁnition ’s quality : the number of upvotes it got ,   and its upvote / downvote ratio . The distribution of   upvotes , downvotes and the upvote / downvote ratios   in the dataset can be seen in Figure 6 below . We   also note that the number of submissions to Urban   Dictionary is relatively well - spread , see Figure 5 .   This implies that we do not have a strong bias to-   wards more recently popularized slang terms in the   dataset , and that we do have representation of the   entire time span of interest ; 2010 2020 .   We keep the entries having more than 20up-   votes and an upvote / downvote ratio of at least 2 .   This leaves us with 488;010Urban Dictionary en-   tries , out of which we randomly sample 100;000   to reduce the computation time in the ﬁne - tuning   process . We use both the deﬁnitions and the word   usage examples for ﬁne - tuning , producing a ﬁnal   dataset of 200;000sequences .   A.2 Training   We randomly split the data into 80 % train and 20 %   test , before training for 10epochs with an early   stopping with patience 3 . The batch size was set to   1 in the interest of memory constraints . Following1434   the setup from the pre - training stage as explained   in Liu et al . ( 2019 ) , we use the Adam optimizer   ( Kingma and Ba , 2015 ) with = 10 ;  = 0:9   &  = 0:98and a linear learning rate decay . For   the learning rate , we argue that since the initial-   ized parameters should provide a solution which   is already close to the optimum when evaluating   on our dataset ( our ﬁne - tuning being the very same   masked language modeling task as RoBERTa has   already been trained on ) , the learning rate should be   smaller . Thus , instead of picking the learning rate    = 610as was done by Liu et al . ( 2019 ) , we   experiment with   2 f10;10;10;10 g.   Training was done using an NVIDIA GeForce GTX   1080 8 GB GPU and took around 1 to 1.5 days per   model . B Appendix – Experiments on   SemEval-2020   B.1 Distribution - based Metrics   Method : In addition to the distance - based APD   metrics , we experiment with two distribution - based   ones , namely entropy difference ( ED ) & Jensen-   Shannon Divergence ( JSD ) ( Giulianelli et al . ,   2020 ) .   We assume a categorical distribution over a set   ofKword senses for word wand time period t.   The word sense sof an occurrence iis then given   by :   sCat (  ; : : : ;  ) = :P   Given two time periods of word sense distributions ,   we deﬁne the ED metric as   jH(s) H(s)j   with entropy H( ) . The JSD is given as :   1   2KL(PjjM ) +1   2KL(PjjM )   withM = andKL(jj)being the KL-   divergence .   We obtain the word sense distributions via a clus-   tering of the representations from both time periods .   We experiment with K - Means and Gaussian Mix-   ture Models ( GMMs ) , the latter proposed due to   its ability to ﬁnd more general cluster shapes . We   also experiment brieﬂy with Afﬁnity Propagation ,   which has been used in previous semantic change   detection work ( Martinc et al . , 2020 ; Kutuzov and   Giulianelli , 2020 ; Montariol et al . , 2021 ) . How-   ever , we ﬁnd it to be ill - suited for our purposes   since it results in an excessive amount of clusters in   comparison to how a human would classify word   senses .   For both K - means and GMM , we experiment   with selecting the optimal K2[1;10]through   two different procedures . The ﬁrst one is a slight ex-   tension of the method from Giulianelli et al . ( 2020 )   – we select the Kwhich optimizes the silhouette   score ( Rousseeuw , 1987 ) for a set of different ini-   tializations . Their approach does not consider the   single cluster case however , so we extend it by   settingK= 1 when the best silhouette score is   below a threshold of 0:1 . ForK - Means , we further   experiment with an automatic elbow methodfor1435   the sum of squared distances to the cluster cen-   troids , which decreases monotonically with the   number of clusters . We again select the cluster   assignments with the largest silhouette score for   multiple random initalizations . For GMM , we fur-   ther experiment with taking the model which corre-   sponds to the best Bayesian Information Criterion   ( Schwarz , 1978 ) .   Clustering examples : In Figure 7 we see three   clusters found for “ gag . ” They do not seem to   correspond to word senses however : An example   from the ﬁrst cluster is “ user i need a pic of you   begging if i ’ m boiling these because boiled eggs   make me gag . : d , ” an example from the second   cluster is “ lmao rt user user user so i tried that tuna   with cheese and my gag reﬂexes were in full affect   ! ” and an example from the third cluster is “ gag   me with a spoon ” – all seemingly referring to the   sensation of being about to vomit .   We show another example in Figure 8 of the   word “ gnarly , ” this time reduced to 2dimensions   using UMAP . Gnarly has three meanings according   to the Online Slang Dictionary : It can either mean   very good / excellent / cool , gross / disgusting or   painful / dangerous . These three word senses are   not separated by UMAP and GMM , for instance   both “ its a good thing one of my roomies is a dude   , who else would kill gnarly spiders in my room   when i start to hyperventilate ” and “ rt user bro my   wreck on the scooter was so gnarly like it was fun   i love shit like that . i wish i could ’ve been on   jackass ” are put in the ﬁrst cluster .   B.2 Variance Explained by PCA components   Consider Figure 9 for example plots of how much   variance is preserved with PCA on the contextual-   ized representations .   Baseline Score   Combined APD PCA100 0:489   Kutuzov and Giulianelli ( 2020 ) 0:605   Kaiser et al . ( 2020 ) 0:461   Rother et al . ( 2020 ) 0:440   B.3 Results   We further present more results of the experimen-   tation on the SemEval-2020 Task 1 Subtask 2 . All   tables show the Spearman ’s rank - order correlation   between the change metrics and the ground truths .   In Table 2 we compare our best performing setup   to the three best performing previous approaches on   SemEval-2020 Task 1 Subtask 2 . We see that only   Kutuzov and Giulianelli ( 2020 ) display a higher   score , which might be partially explained by the   fact that they ﬁne - tune their model on the SemEval   test corpora . We do not do this since our main goal   is not to beat state - of - the - art on the shared task ,   but rather to ﬁnd a good enough model to detect   semantic change in slang .   The results comparing the layer representations   can be observed in Table 3 . As a side observation   we also note that the less isotropic ﬁrst layer rep-   resentations seem to perform better than the more   isotropic last layer representations .   In Table 4 we present a comparison across differ-   ent layer representations for both APD - based and   distribution - based metrics . We observe that none   of the distribution - based metrics give signiﬁcant   results , even when used with dimensionality reduc-   tion techniques . While a few of them do have a1436   slight positive correlation , we omit this approach   altogether . The APD results on the other hand show   a high correlation for many of the conﬁgurations ,   providing an indication of the APD ’s robustness in   detecting semantic change . We show a selection of   these in Table 6.dAPDdAPD   First layer 0:22 0:234   Last layer 0:07 0:2   Sum of all layers 0:3360:332   Reps Cluster Metric Score p   First - APD d 0:22 0:19   First - APD d 0:23 0:16   First K - Means ED  0:08 0:64   First K - Means JSD 0:06 0:73   First GMM ED 0:05 0:76   First GMM JSD 0:07 0:67   Last - APD d 0:01 0:97   Last - APD d 0:20 0:24   Last K - Means ED 0:00 0:96   Last K - Means JSD 0:20 0:23   Last GMM ED  0:07 0:70   Last GMM JSD  0:10 0:57   All - APD d 0:34 0:04   All - APD d 0:33 0:05   All K - Means ED 0:03 0:85   All K - Means JSD 0:09 0:60   All GMM ED  0:13 0:43   All GMM JSD 0:00 0:99   C Appendix – Hybrid Words   We deﬁne hybrid words as words that have both   a slang and nonslang meaning , i.e. , occurring in   both Online Slang Dictionary ( OSD ) and Merriam   Webster ( MW ) . In this section , we compare the   polysemy , semantic change , frequency shift as well   as the absolute frequency change patterns of hybrid   words to slang and nonslangs .   Polysemy is collected for hybrid words from   OSD and MW separately . Since the MW dictio-   nary may also contain slang meanings , we ﬁlter   out deﬁnitions labeled as slang , informal orvul-   garfrom these scores . The mean polysemy scores   of the slang words are ( 2:0742:568 ) and the   mean OSD polysemy scores of the hybrid words   are(2:5802:178 ) , with a non - signiﬁcant differ-   ence ( p>0:05 ) in distribution according to a per-   mutation test . This tells us that we are not skewing1437APD Score p   d 0:336 0:042   d 0:332 0:045   d 0:409 0:012   dandd 0:345 0:037   d;dandd0:398 0:015   Dim APD Score p   PCA2 d 0:153 0:367   UMAP2 d 0:136 0:424   PCA5 d 0:209 0:215   PCA5 dandd 0:268 0:109   UMAP5 d;dandd 0:146 0:39   PCA20 dandd 0:42 0:010   PCA50 d 0:26 0:121   PCA50 d 0:394 0:016   PCA50 dandd 0:478 0:003   PCA50d;dandd0:344 0:037   UMAP50 d 0:158 0:35   PCA100 d 0:297 0:074   PCA100 dandd 0:489 0:002   UMAP100 d 0:133 0:433   the polysemy score distribution of the slang words   by excluding hybrid words .   As for the nonslang meanings of the hybrid   words , we get a mean polysemy score of ( 6:880   6:080 ) which is signiﬁcantly different ( p<0:001 )   from those of the nonslang words ( 3:0792:780 ) .   This is an interesting observation , implying that   had we included nonslang words with hybrid mean-   ing in our nonslang words sample , the difference   in polysemy between slang and nonslang words   would have been larger . Some example words from   this category with high MW polysemy scores in-   clude “ split , ” “ down ” and “ walk . ”   For the relative frequency changes , we present   the results as histograms in Figure 10 . The fre-   quency changes in hybrid words seem to fall be-   tween those of the slang words and the nonslang   words . We observe a mean and standard deviation   of 0:154and0:608respectively .   In addition , we compare the absolute relative fre-   quency changes as described in Section 5.3 across   slang , nonslang and hybrid words . The histograms   are presented in Figure 11 . We observe , respec-   tively , a mean and standard deviation of 1:246 &   1:180for the slang words , 0:950&0:724for the   nonslang words and 0:482&0:402for the hybrid   words . The difference in mean is signiﬁcant be-   tween the slang and nonslang words ( p < 0:05 ) ,   indicating that slang words have undergone a larger   absolute change in frequency . Furthermore , we   note a highly signiﬁcant difference ( p<0:001 ) in   the mean of the hybrid words compared to both the   slang and nonslang word means .   We compare the normalized semantic change   scores between the slang , nonslang and hybrid   words . Histograms over the semantic change scores   are shown in Figure 12 . We observe that the dis-1438   tribution over hybrid change scores seem again to   be centered between the slang and nonslang dis-   tributions , with mean 0:6210:073 . According   to a permutation text , there is a signiﬁcant differ-   ence in semantic change both between hybrid and   slang words ( p<0:001 ) and between hybrid and   nonslang words ( p<0:05).D Appendix – Causal Analysis   D.1 Preliminary on Constraint - based Causal   Discovery   Assumptions The constraint - based causal dis-   covery algorithms make use of two main as-   sumptions , namely the global Markov assump-   tion and the faithfulness assumption . The global   Markov property ( Peters et al . , 2017 ) holds if all d-   separations ( deﬁned below ) encoded in the causal   graph imply conditional independencies in the dis-   tribution over the variables contained in the graph .   More formally , for a graph G= ( V;E)and distri-   bution Pover the variables Xit holds that for any   disjoint subsets A;B andCofV   X?XjX;inG   ) X ? ? XjX;inP   The faithfulness assumption states the converse   of the global Markov assumption : All conditional   independencies in the distribution are encoded by   d - separations in the graph .   d - separation Two nodesA;B2Vare said to   bed - separated ( Geiger et al . , 1990 ) , by a set of   nodesZVif for all paths between AandB , at   least one of the following holds :   •The path contains a directed   chain A!C!B or   A C Bsuch thatC2Z   •The path contains a fork A C!B   such thatC2Z   •The path contains a collider   A!C B such that C = 2Z   orC=2Z8C2desc(C)(i.e . , neither C   nor any of its descendants is in Z )   We would then denote X?XjX.   Markov Equivalence Constraint - based algo-   rithms use conditional independence tests in order   to identify a Markov equivalence class of DAGs .   Two DAGs are deﬁned to be Markov equivalent   if they have the same skeleton ( edges omitting di-   rection ) and v - structures . The three vertices A;B   andCform a v - structure if A!B CandA   andCare not directly connected by an edge . Alter-   natively , two DAGs are Markov equivalent if they   describe the same set of d - separation relationships .   A Markov equivalence class is the set of all Markov   equivalent DAGs.1439   PC Algorithm One common constraint - based al-   gorithm is the PC algorithm ( Spirtes et al . , 2000 ) .   Starting with a full DAG , it eliminates an edge be-   tween adjacent vertices iandjifXandXare   conditionally independent given some subset of   the remaining variables . This process , including   the conditional independence tests , is conducted   iteratively starting from a conditioning set of size   k= 0 tok = jVj 2 . In addition to the global   Markov and faithfulness assumptions , the PC algo-   rithm also assumes causal sufﬁciency , namely the   absence of unobserved confounders . With these   assumptions satisﬁed and access to correct condi-   tional independence relations , the PC algorithm is   guaranteed to be sound , complete and uniformly   consistent ( Kalisch and Bühlmann , 2007 ) .   PC - stable PC - stable is an order - independent ex-   tension with the same guarantees as the original   ( Colombo and Maathuis , 2014 ) .   D.2 Diagnostic Plots   In Figure 13 we present the density and Q - Q plots   for semantic change score , log of word frequency   and log of frequency change .   D.3 Sensitivity Analysis on Polysemy   Polysemy is a discrete variable which we treat as   an ordered factor in the analysis by splitting it into   categories . Since polysmey can be plausibly cat-   egorized in different ways , we experiment with 9   different categorizations of it and examine the sta-   bility of the resulting graphs . For each categoriza-   tion , we run PC - stable with the three signiﬁcance   levels  2 f0:05;0:03;0:01 g. In Figure 14 we   present the results of this sensitivity analysis . We   see that the edges between word type and polysemy ,   from word type to frequency change , as well as the   edge from polysemy to frequency , are apparent in   all of the conﬁgurations . The edge from word type   to semantic change is apparent in 21/27 ( 77.8 % ) of   the conﬁgurations . We also observe a few edges   very rarely , and therefore label them as noise and   do not take them into account for the causal analy-   sis . These consist of an edge from the POS Noun   to semantic change in 3/27 ( 11.1 % ) of the conﬁg-   urations , and edges from polysemy to frequency   shift and from polysemy to semantic change each   apparent in 1/27 ( 3.7 % ) of the conﬁgurations .   By inferring the causal graph from a set of cate-   gorizations , we make up for the possible noise in   the polysemy variable and ensure that the graph   is not sensitive to small variations in the words ’   polysemy scores .   D.4 Causal Inference   Given the causal DAG in Figure 4 , we derive the ex-   pression for the average causal effect of word type   on semantic change . Deﬁne the following random   variables : T = word type , X = polysemy , Y=   frequency , Z = frequency shift and S = semantic   change , with respective probability mass functions   P&Pand probability density functions f , f   & f.   Note that the possible values for Tlie in1440fslang;nonslangg . By the truncated factorization   for the connected component of the causal DAG   ( i.e. , excluding POS ) , we have that   P(s;t;x;y;zjdo(T = t ) ) =   f(yjx)f(zjt)f(sjt)P(xjt ) 1   Marginalizing over T , we get   P(s;x;y;zjdo(T = t ) ) =   = f(yjx)f(zjt)f(sjt)P(xjt )   Next , marginalize over the continuous random vari-   ablesYandZto get   P(s;xjdo(T = t ) ) =   ZZf(yjx)f(zjt)f(sjt)P(xjt)dzdy =   Zf(yjx)f(sjt)P(xjt)Zf(zjt)dz   |{z}dy=   f(sjt)P(xjt)Zf(yjx)dy   |{z}=   f(sjt)P(xjt )   Finally   P(sjdo(T = t ) ) =   Xf(sjt)P(xjt ) = f(sjt )   Taking the expectation , we get   E[Sjdo(T = t ) ] = E[Sjt ]   E Appendix – Selected Words   In Appendix E we list all the slang and nonslang   words used in this study . Slang Nonslang Hybrid   a - list admitting annihilated   badass adulterous balling   blankie agenda bastard   bling allotted beef   blowjob anticlockwise bloody   blumpkin avoiders bomb   bonehead awesome book   bro banzai bookmark   bromance bright booty   bumfuck butane bounce   bupkis calorie bowl   chillax chug brains   chones committeeman candle   colitas competencies chicken   compo contenders classic   conniption conventionally crock   crappy copyediting decompress   dang deathblow dim   dis decomposition dirt   dogg despoil dose   duckface didot down   dudette doubleheader egg   fanboy echo eye   fap enhancements fat   gangsta epilator fence   glitterati estimated ﬁre   gorp ﬁddled ﬂuffer   gotsta galavant foxy   gunt glutton freckle   hasbian greeting fruitcake   horribad grisly gag   jabroni groans ghost   jalopy haircut gig   jerkwad heaviest gnarly   lame - o humblest god   lemme ignites gridlock   lowkey inclusive grip   mcdreamy intimidator grub   meme jugglers gumby   mosey jute hanger   motherfucking lawlessness head   mozzie legalist hell   netizen milepost hitter   nuker mistreatment item   pedo moldovan jammed   peeps morphology jill   plastered mushroom jock   poopy nonskid kick   preemie outlawing kosher   pregos pantsuit locks   prettyful peppy mad   rapey performative mine1441Slang Nonslang Hybrid   rehab postural money   relly protocol move   rooﬁe repentant mule   roshambo rump pecker   sesh sabertooth peckish   shart sailor peeper   shiesty scallywag pig   shtick scheme pinch   sicc sculptured plums   sinse scummiest postal   skeevy shield rad   skyrocket shylock ratchet   slore snug roadkill   snitch squall sausage   soused steeple scissor   spam strap scoot   spec superabundance scream   spec - ops sympathizer screaming   sucky telogen smoked   tenner terriﬁes sneak   thingamabob they split   trisexual trampolining squawk   tweeker underpainting stat   twit underrated stew   whadja unicorn streak   workaround unlike styling   wut unmatched swap   zooted upgrade thick   vanadium thirsty   threads   tool   toots   tweaker   walk   walkie   whippet   windy   wrecked   zombie   zounds1442