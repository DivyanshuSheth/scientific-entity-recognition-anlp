  Jiandian Zeng , Jiantao Zhouand Tianyi LiuState Key Laboratory of Internet of Things for Smart CityDepartment of Computer and Information Science , University of MacauDepartment of Computer Science and Engineering , Shanghai Jiao Tong University   { yb87470 , jtzhou}@um.edu.mo , liutianyi@sjtu.edu.cn   Abstract   For the missing modality problem in Multi-   modal Sentiment Analysis ( MSA ) , the incon-   sistency phenomenon occurs when the senti-   ment changes due to the absence of a modal-   ity . The absent modality that determines the   overall semantic can be considered as a key   missing modality . However , previous works all   ignored the inconsistency phenomenon , simply   discarding missing modalities or solely gener-   ating associated features from available modal-   ities . The neglect of the key missing modality   case may lead to incorrect semantic results . To   tackle the issue , we propose an Ensemble - based   Missing Modality Reconstruction ( EMMR ) net-   work to detect and recover semantic features   of the key missing modality . Specifically , we   first learn joint representations with remaining   modalities via a backbone encoder - decoder net-   work . Then , based on the recovered features ,   we check the semantic consistency to determine   whether the absent modality is crucial to the   overall sentiment polarity . Once the inconsis-   tency problem due to the key missing modality   exists , we integrate several encoder - decoder   approaches for better decision making . Exten-   sive experiments and analyses are conducted   on CMU - MOSI and IEMOCAP datasets , vali-   dating the superiority of the proposed method .   1 Introduction   Sentiment analysis has witnessed significant   progress in the past years ( Zhang et al . , 2016 ) ,   where the traditional textual sentiment classifica-   tion has developed into more complex Multimodal   Sentiment Analysis ( MSA ) models . Taking the   phase “ Yeah , I think so . ” for instance , it is hard   to read the emotion without enough lexical infor-   mation , and the acoustic modality may help in the   emotion recognition if available . Thus , it is cru-   cial to combine different modalities together for   accurate sentiment analysis . Figure 1 : Case of missing the key modality , where the   missing modality is marked with dotted red lines , and   the semantic words are marked in blue .   So far , MSA has been well studied under the   assumption that all modalities are always available .   However , in reality , such a strong assumption does   not always hold , and we often encounter scenarios   that partial modalities could be missing . To address   the missing data problem , a consequent effort has   been made on recovering absent modalities . Tran   et al . ( 2017 ) first identified the missing modality   problem in multimodal data . More recently , several   works ( Suo et al . , 2019 ; Ma et al . , 2021 ; Zhao et al . ,   2021 ; Yuan et al . , 2021 ; Zeng et al . , 2022 ) focused   on the missing modalities problem in an uncertain   manner .   However , all of the above works ignored a vi-   tal insight that the sentiment may change when a   modality is absent , resulting in the inaccurate pre-   diction results . For instance , as shown in Fig . 1 , the   acoustic modality is described with the emotional   tone for intuitive expression ; the visual modal-   ity consists of several facial images ; and the tex-   tual modality refers to the corresponding transcript .   Due to the slight tone in the acoustic modality and   the minor ripples in the facial features , the origi-   nal emotion is neutral with full modalities . Nev-   ertheless , once the acoustic modality is missing ,   the remaining sentiment is guided by the textual   modality and tends to be negative . The semantics   are inconsistent with or without the acoustic modal-   ity , and the absent modality can be considered as2924a key missing modality . Thus , the neglect of key   missing modality may lead to incorrect predictions .   It is nontrivial to mark and recover the key missing   modality for accurate emotion recognition in MSA .   Furthermore , with the recovered features , it is still   very challenging to trade off different modalities   when they express different emotions .   In this paper , we tackle the above challenges   by providing an ensemble solution that can accu-   rately detect and recover features of the key miss-   ing modality . More specifically , we propose an   Ensemble - based Missing Modality Reconstruction   ( EMMR ) network to handle the inconsistency prob-   lem and to further boost the performance . The   proposed EMMR consists of a backbone network   that utilizes an encoder - decoder structure to recover   the absent modality features . Besides , to discrimi-   nate the key missing modality , we compare seman-   tic of the recovered full modalities with the origi-   nal available modalities to check their consistency .   Then for mitigating the inconsistency , we aggregate   Auto - Encoder ( AE)-based and Transformer - based   encoder - decoder approaches in an ensemble man-   ner . Such a strategy naturally extends the feature   search space , and is thus better suited to make co-   herent decisions . As expected and will be verified   by experiments , the proposed EMMR significantly   outperforms several state - of - the - art baselines on   two benchmark datasets . Our major contributions   are summarized as follows :   •We propose EMMR to address the inconsis-   tency problem of missing key modality , so as   to boost the performance in MSA . The code   is publicly available .   •We integrate the AE - based and Transformer-   based encoder - decoder methods for decision   making to mitigate the inconsistency with bet-   ter predictive performance .   •Our EMMR achieves much better perfor-   mance in comparison with several state - of-   the - art methods over a variety of challeng-   ing MSA datasets including CMU - MOSI and   IEMOCAP .   2 Related Works   2.1 Missing Modality Problem in MSA   Regarding feature imputation strategies in MSA ,   previous works can be generally grouped into twocategories : 1 ) generative methods ( Tran et al . ,   2017 ; Vincent et al . , 2008 ; Shang et al . , 2017 ;   Zhang et al . , 2020 ) , and 2 ) joint learning meth-   ods(Pham et al . , 2019 ; Yuan et al . , 2021 ) .   Generative methods aim to generate new data   that match the observed distributions . Variational   Auto - Encoder ( V AE ) was proposed in ( Kingma and   Welling , 2014 ) to map the input variable to a multi-   variate latent distribution . Relying on GAN ( Good-   fellow et al . , 2014 ) , Cai et al . ( 2018 ) transformed   the missing modality problem into a conditional im-   age generation task , aiming at generating missing   modality images conditioned on the existing modal-   ity . Joint learning methods try to learn latent rep-   resentations from the observed ones . To improve   the robustness of the joint representation learning ,   the cycle consistency strategy was applied in ( Zhao   et al . , 2021 ) . Also , Zeng et al . ( 2022 ) reconstructed   the features of uncertain missing modalities with   attached tags .   We would like to point out that the above works   may make incorrect prediction without considering   the inconsistency when handing the case of missing   key modality . As will be clear soon , we give a   comprehensive analysis in terms of inconsistency   phenomenon in MSA .   2.2 Ensemble Learning   Ensemble learning ( Lee et al . , 2021 ) aims to obtain   better predictive performance than a single one by   combining several base models . In recent years , the   ensemble technique has been applied in many NLP   tasks ( Li et al . , 2021 ; Duan et al . , 2021 ) . The main   idea is that it would be better to weigh and aggre-   gate several opinions than to choose the opinion of   one single individual ( Sagi and Rokach , 2018 ) . To   be specific , Li et al . ( 2021 ) generated multiple can-   didate results with random seeds , and then trained   a fusion classifier to improve the emotion recogni-   tion performance . In addition , Duan et al . ( 2021 )   developed an ensemble language model for data   diversity with the technique of weight modulation .   Along this line , in this paper , we aggregate several   reconstruction approaches for ensemble learning   to trade off different modalities when they express   different emotions , and to further mitigate the in-   consistency with better predictive performance .   3 Methodology   In this section , we first present the problem defi-   nition with associated notations , and then give the2925details of all core components .   3.1 Preliminaries   Given a set of multimodal data with three modal-   ities : S= [ X , X , X ] , where X , XandX   denote visual , acoustic and textual modalities re-   spectively . Assuming only one modality is absent ,   without loss of generality , we use Xto repre-   sent the missing modality , where m∈ { v , a , t } .   Formally , our problem is defined as follows : for   the given triple ( X , X , X ) , one modality is ran-   domly missing . The primary task is to classify the   overall sentiment ( positive , neutral , ornegative )   based on the available modalities .   3.2 Backbone Network   Fig . 2 shows the backbone network based on the   encoder - decoder structure . Taking the triple ( X ,   X , X ) with the absent acoustic modality as an   input , it is first encoded by the Multi - Head Atten-   tion ( MHA ) module ( Vaswani et al . , 2017 ) , and   then goes through two branches : 1 ) one is encoded   by a pre - trained network which is trained with all   full modalities , and 2 ) another goes through an   encoder - decoder network to obtain the correspond-   ing outputs , where the encoder outputs are utilized   for the sentiment classification . At last , the forward   similarity loss and the backward reconstruction loss   are calculated to supervise the learning process of   joint features .   3.3 Feature Extraction   Before being processed by the MHA module , we   extract features for each modality as follows :   Visual Representations : Following ( Yu et al . ,   2010 ; Zeng et al . , 2022 ) , we also adopt Open-   Face2.0 toolkit ( Baltrusaitis et al . , 2018 ) to obtain   709 - dimensional visual representations except data   that are irrelevant attributes about the frame num-   ber , the face_id , and the timestamp , etc .   Textual Representations : For each textual utter-   ance , the pre - trained Bert ( Devlin et al . , 2019 ) ( 12-   layer , 768 - hidden , 12 - heads ) is utilized to acquire   768 - dimensional word vectors .   Acoustic Representations : Librosa ( McFee et al . ,   2015 ) is adopted to extract 33 - dimensional acous-   tic features , including attributes of the zero cross-   ing rate , the Mel - Frequency Cepstral Coefficients   ( MFCC ) and the Constant - Q Transform ( CQT ) .   Then , all extracted modality features are en-   coded by the MHA module :   E = MHA ( K , K , K ) ,   K∈ { X , X , X}.(1 )   Afterwards , all modalities are concatenated as a   whole input sequence X :   X= [ E||E||E ] , ( 2 )   where ||is the vertically concatenating operation .   3.4 Pre - trained Network   The pre - trained network with full modalities is uti-   lized to guide the learning process for missing   modalities . To be specific , we first concatenate   three full modalities , then feed them into a softmax   classifier for training :   E= [ E||E||E ] ,   P = softmax ( FC(E)).(3 )   Noting that once the model with full modalities is   well trained , we fix the pre - trained network during   the whole training stage .   3.5 Encoder - Decoder Network   The encoder - decoder network contains an encoder   ( ϕ ) mapping the input ( X ) , and a decoder ( ψ ) map-   ping the reconstructed input ( X ) , which can be   defined as follows :   X−→ F ,   F−→ X,(4 )   where Fis the output of the encoder .   Since ensemble learning incorporates the in-   formative knowledge from multiple models and   achieves better predictive performance in an adap-   tive manner , it can effectively mitigate the incon-   sistency phenomenon . In our scheme , the AutoEn-   coder ( AE ) ( Baldi , 2012 ) , the Missing Modality2926Imagination Network ( MMIN ) ( Zhao et al . , 2021 ) ,   and the Transformer - based encoder - decoder model   ( TF ) are chosen for decision making . We now in-   troduce them one by one .   3.5.1 AE   AE is the network trained to copy its input to its   output . In details , we adopt Fully Connected ( FC )   layers with the size of [ 300 , 256 , 128 , 64 , 128 , 256 ,   300 ] ( Please refer to the Appendix for details ) .   h=/braceleftbiggX , i = 0   ReLU ( FC(h)),0 < i≤7,(5 )   where the encoder output E = h , and the   decoder output D = h.   3.5.2 MMIN   MMIN adopts the Cascade Residual Autoencoder   ( CRA ) ( Tran et al . , 2017 ) structure with a set   of Residual Autoencoders ( RA ) . Specifically , we   adopt 5 RA with the same layer settings in AE .   Then the encoder output and the decoder output of   the CRA can be obtained as follows :   D = X+/summationdisplayX ,   E = FC([F||F|| ... ||F]),(6 )   whereFandXare the i - th RA ’s encoder outputs   and decoder outputs respectively .   3.5.3 TF   The Transformer architecture follows an encoder-   decoder structure , which can process sequential in-   put data effectively . With the Multi - Head Attention   ( MHA ) mechanism and Feed - Forward Networks   ( FFN ) , the encoder output ( E ) and the decoder   output ( D ) can be accessed :   E = FFN(MHA ( X , X , X ) ) ,   D = FFN(MHA ( F , F , F ) ) ,   FFN(x ) = ReLU ( Wx+b)W+b),(7 )   where WandWare two weight matrices , band   bare two learnable biases .   3.6 Ensemble   For the reconstruction of the input , we replace the   missing modality with the corresponding represen-   tations in the decoder output . For instance , given   the input ( X , X , X ) and the reconstructed out-   put ( D , D , D ) , we can obtain the recov-   ered input ( X , D , X ) . To simplify the sub-   sequent mathematical expression , we denote the   recovered input as ( I , I , I ) . The sentiment of   the recovered input can be acquired :   L = FC(MHA ( [ I||I||I ] ) ) . ( 8)   As aforementioned , the inconsistency phe-   nomenon occurs when the sentiment changes due   to the absence of a modality in MSA . Based on   this phenomenon , we utilize the inconsistency to   determine whether the absent modality is crucial   to the overall sentiment polarity . Specifically , we   first combine every two modalities to acquire the   corresponding sentiment label :   L = FC(MHA ( [ I||I ] ) ) ,   m , n∈ { v , a , t } , m̸=n.(9 )   When the sentiment label of the recovered full   modalities is unequal to semantic of the remaining   available modalities , the absent modality can be   considered as the key missing modality . That is , in   the case of ( X , X , X ) , the acoustic modality is   the key missing modality if L̸=L. To obtain   the coherent prediction results , the inconsistency   phenomenon should be mitigated . A straightfor-   ward way to handle the problem of missing key   modality is voting . However , the importance of   each modality is different . As shown in Fig . 3(a ) ,   we propose to assign weights according to their   maximum logical values ( L ):   α = softmax ( [ L||L||L ] ) ,   L = max(softmax ( L ) ) , k∈ { va , vt , at } .   ( 10)2927Then , the aggregated representation with the key   missing modality can be accessed :   E= [ αL||αL||αL ] , ( 11 )   where α , αandαare the corresponding   weights calculated by Eqs . ( 10 ) .   As presented in Fig . 3(b ) , we first feed the in-   put into the backbone network with TF encoder-   decoder . Based on the recovered features , we then   check the semantic consistency between the re-   covered full modalities and the original available   modalities . Once they are not consistent with or   without the absent modality , we integrate TF , AE ,   and MMIN for further decision making . With the   idea that the overall performance of multiple ap-   proaches in ensemble learning would be better than   that of a single one , we combine three extracted   features according to the corresponding attention   weights . Let Hbe a matrix consisting of three vec-   tors[E||E||E]produced by Eq . ( 11 ) .   The final representation ris formed by a weighted   sum of these output vectors :   M = tanh ( H ) ,   β = softmax ( w·M ) ,   r = H·β,(12 )   where wis a trainable parameter vector , and T   is the transpose operator . Thus , the i - th output   ( R ) of our ensemble method can be formulated as   following :   R=/braceleftbiggr , L̸=L   F , otherwise , ( 13 )   where kis the absent modality , and k∈ { v , a , t } .   3.7 Training Objective   The overall training objective ( L ) is expressed   as :   L = L+λL + λL , ( 14 )   where Lis the classification loss , L is   the forward differential loss , L is the back-   ward reconstruction loss , and λandλare the   corresponding weights . We now introduce these   loss terms in details .   Forward Differential Loss ( L ): The for-   ward loss is calculated by the difference between   the pre - trained output ( E ) and the encoder out-   put ( F ) , and the Kullback Leibler divergence lossfunction ( D ) is used :   L = 1   2(D(F , E ) + D(E , F ) ) .   ( 15 )   Backward Reconstruction Loss ( L ): For   the backward loss , we aim to supervise the joint   common vector reconstruction , which is calculated   by the decoder output ( X ) and the processed input   ( X ) .   L = 1   2(D(X , X ) + D(X , X ) ) .   ( 16 )   Classification Loss ( L):We feed the final output   Rinto a fully connected network with the softmax   activation function for the final sentiment classifi-   cation :   ˆp(y|R ) = softmax ( FC(R ) ) ,   ˆy= arg max(ˆp(y|R)),(17 )   where ˆyis the predicted label . To be specific , we   employ the standard cross - entropy loss for this clas-   sification task :   L=−1   N / summationdisplayylogˆy , ( 18 )   where Nis the number of samples , and yis the   true label of the n - th sample .   4 Experiments   In this section , we mainly present the experimental   setup , datasets , baselines , empirical studies and   observations .   4.1 Experimental Setup   Datasets : We evaluate our model on two bench-   mark datasets : CMU - MOSI ( Zadeh et al . , 2016 )   and IEMOCAP ( Busso et al . , 2008 ) . The CMU-   MOSI dataset contains 2199 segments with the   sentiment score in [ -3 , 3 ] ; and the IEMOCAP   dataset contains 5 sessions with 151 videos . In   our experiments , we report three - class ( negative :   [ -3,0 ) , neutral:[0 ] , positive : ( 0,3 ] ) results on CMU-   MOSI , and two - class ( negative:[frustration , angry ,   sad , fear , disappointing ] , positive:[happy , excited ] )   on IEMOCAP .   Baselines : We choose the following baselines   for comparison : AE ( Baldi , 2012 ) , CRA ( Tran   et al . , 2017 ) and MMIN ( Zhao et al . , 2021 ) for   AE - based methods ; MCTN ( Pham et al . , 2019),2928   and TransM ( Wang et al . , 2020 ) for translation-   based methods ; TATE ( Zeng et al . , 2022 ) and the   proposed EMMR for transformer - based methods .   Accuracy ( ACC ) and Macro −F1(M - F1 ) are   used to measure the performance of the models .   The detailed implementation , dataset statistics ,   and hyper - parameter settings are available in the   attached Appendix .   4.2 Overall Results   Table 1 shows the qualitative results with all base-   lines . Our proposed EMMR achieves the best re-   sults on all settings , especially about 8.54 % to   11.12 % improvement in terms of M - F1 on the   CMU - MOSI dataset . The present results are signif-   icant due to the fact that three ensemble approaches   can well handle the inconsistency problem when   missing a key modality , so as to further improve   the robustness . Besides , the performance has a   gradual drop with more absent samples when the   missing ratio increases from 0 to 0.5 . We also   find that MCTN and TransM achieve better per-   formance than AE and CRA , implying that cyclic   translations can better fuse the multimodal informa-   tion from multiple modalities . In addition , TATE   and EMMR outperform other baselines due to the   strong learning ability of the transformer structure .   Another observation is that our proposed EMMR   still performs well when nearly half of samples are   missing , which is caused by the reason that three   ensemble methods can combine their predictions   in a complementary manner .   4.3 Effects of Different Settings   In this subsection , we first conduct the ablation   studies to better understand the influence of dif-   ferent modules . Afterwards , we further evaluatethe performance of our model by replacing several   core components with alternatives .   1 ) Ablation study : We evaluate our model with   several settings : a ) using only one modality ; b )   using two modalities ; c ) removing the pre - trained   network ; and d ) removing the backward reconstruc-   tion module .   According to the results given in Table 2 , it can   be seen that the performance drops sharply with   a single modality , especially when removing the   textual modality . However , similar reductions are   not observed when the visual modality is miss-   ing . These results suggest that the textual modality   may dominate the overall sentiment . Besides , one   striking result to emerge from the data is that the   performance improves when combing two modali-   ties , indicating that multiple modalities can boost   the performance by learning complementary fea-   tures from each other . In addition , referring to the   last two lines , the performance decreases about   9.97 % to 14.39 % with respect to M - F1 and about   7.60 % to 9.12 % on ACC when the pre - trained net-   work is removed , showing the importance of the   forward guidance . Meanwhile , further analysis   suggests that the backward reconstruction module   also provides a good supervision for the final joint   representation learning .   2 ) Effects of different ensemble methods : We   now examine the effectiveness of different ensem-   ble methods . For the comparison purpose , we con-   duct experiments with several settings : a ) using   only the backbone network , b ) combing two ensem-   ble methods , c ) combing three ensemble methods   with the maximum operation , and d ) combing three   ensemble methods with the average operation .   As can be seen in Table 3 , although the back-2929   bone network with TF achieves competitive perfor-   mance , there is still improvement when combining   AE and MMIN . The reason may be that ensem-   ble learning combines knowledge from multiple   models to achieve better predictive performance .   Besides , TF+MMIN outperforms than TF+AE , im-   plying that MMIN can extract better modality fea-   tures than AE . Compared to the average operation ,   our weighted fusion method improves about 1.71 %   to 2.25 % with respect to M - F1 and about 1.17 % to   1.76 % on ACC , validating the effectiveness of the   weighted fusion mechanism .   3 ) Effects of different word embeddings : As   aforementioned , the textual modality may domi-   nate the overall sentiment , and we now evaluate the   performance of different word embedding models .   To this end , we choose Word2vec ( Mikolov et al . ,   2013 ) , Glove ( Pennington et al . , 2014 ) and AL-   BERT ( Lan et al . , 2020 ) as alternative methods to   the pre - trained Bert , and evaluate the respective pre-   diction performance . Here , we set the embedding   size as 128 in Word2vec and choose the cased 840B   tokens of 300 dimension in Glove . All settings   share the same parameters for a fair comparison .   As presented in Fig . 4 , different embedding models   have significant effect on the overall performance ,   where Bert - based methods achieve better results   while the Word2vec model is the worst . These re-   sults altogether provide an important insight that   Bert embeddings result in better word semantic cor-   relations , as it is trained from a large amount of   text corpus .   4 ) Effects of multiple classes : We would also   like to observe the performance of multiple classes   on IEMOCAP . Apart from the general 2 - class re-   sults , the happy , angry , sad and neutral emotions   are chosen as the 4 - class experiment , and the ex-   tra frustration , excited , and surprise emotions are   selected as the 7 - class experiment . Table 4 reveals   that there has been a sharp drop in both M - F1   and ACC with more emotion categories . More   specifically , the performance of the 7 - classes exper-   iment drops by almost half due to the confusion of   multiple categories , and the model is hard to clas-   sify them correctly . Further efforts are needed to   boost the performance under scenarios of multiple   classes .   5 ) Effects of different losses : We further ex-2930   plore the effects of different losses . For the com-   parison purpose , we choose the MAE loss and the   cosine loss as alternative methods to the KL loss .   Fig . 5 presents the training loss curves ( steps rang-   ing from 50 to 300 ) on the CMU - MOSI dataset ,   including three missing rates of 0 , 0.2 , and 0.4 .   It can be observed that the training loss curves in   our method ( Fig . 5(c ) ) fluctuate relatively smoother   than other two loss settings ( Fig . 5(a)-(b ) ) , showing   the good convergence of our setting . Besides , the   training loss curves become more fluctuating with   the increment of the missing rate , especially when   the missing rate is 0.4 . Compared to the cosine sim-   ilarity loss and the MAE loss , our KL divergence   loss leads to the smaller minimum loss values of   4.89 . We then conclude that the KL divergence   loss provides a good assessment of the similarity   between two probability distributions .   4.4 Case Study   To better understand in which conditions the pro-   posed method works , we present several challeng-   ing cases for further analyses . To this end , two   examples are given in Fig . 6 , where blue words   with underline potentially express sentiment polar-   ity , and the missing modality is marked with dotted   red lines .   From the figure , we can find : 1 ) In E1 , all models   generate correct results though the visual modal-   ity is missing . Due to the strong guidance of the   textual word “ amazing ” , the positive polarity is   obviously expressed . This case reveals that the con-   ventional approaches can be well - performed when   existing modalities express the same explicit se-   mantics . 2 ) In E2 , the textual modality expresses   positive polarity , while the visual modality tends   to be negative because of the frown and close lips   on facial features . It is really hard to determine   the polarity when the acoustic modality is missing .   Specifically , AE and CRA misclassify the emo-   tion as negative , and the other approaches except   EMMR all predict positive sentiment in terms of   the dominance of the textual modality . In contrast ,   our method ( EMMR ) first discriminates whether   the inconsistency phenomenon exists , then inte-   grates three methods to acquire better decisions in   a complementary manner .   4.5 Visualization   To further demonstrate the learning ability of differ-   ent ensemble models , we adopt the T - SNE toolkit   to present the learned joint representations in Fig . 7 .   To be specific , we visualize about 1000 vectors with   three ensemble settings on CMU - MOSI , where the   red , the blue , and the green colors denote nega-   tive , neutral and positive respectively . As can be   observed , in Fig . 7(a)-(c ) , all learned vectors are   generally clustered into three categories with TF   as the backbone network . Besides , there are less   outliers with more ensemble approaches , due to the   reason that the errors of one single model can be   compensated by other models . Such phenomenon   also agrees with the observations from Fig . 7(c)-   ( d ) . Furthermore , the clusters in the red and the   green colors are more discrete with bigger missing   rate . We then conclude that the model is hard to   converge with too many absent samples and thus   degrades the performance.29315 Conclusion   In this paper , we focus on mitigating the incon-   sistency phenomenon when a key modality is ab-   sent in MSA . The proposed EMMR first learns   features from remaining modalities via a backbone   encoder - decoder network . Then , we discriminate   the key modality by checking the semantic consis-   tency between the recovered full modalities and the   original available modalities . Afterwards , three en-   semble approaches based on the backbone encoder-   decoder network are utilized to make decisions   when the inconsistency phenomenon exists . Ex-   perimental results and analyses are provided to   demonstrate the effectiveness of our scheme com-   pared with several state - of - the - art methods . Future   research will focus on aggregating different ensem-   ble approaches for a comprehensive analysis .   6 Limitations   We would like to discuss the detailed limitations in   this section . As aforementioned , we integrate three   different encoder - decoder approaches for decision   making when the inconsistency phenomenon exists .   Although it is nontrivial to select the right ensemble   methods and to utilize them correctly , the model   for ensemble learning can be expensive in terms   of both time and space . As can be seen in the   attached Appendix , a comprehensive comparison   of the overall parameters and the testing time has   been carried out , which motivates us to further   optimize the proposed model effectively .   7 Acknowledgements   This work was supported in part by Macau   Science and Technology Development Fund un-   der SKLIOTSC-2021 - 2023 , 0072/2020 / AMJ , and   0022/2022 / A1 ; in part by Research Committee at   University of Macau under MYRG2018 - 00029-   FST , MYRG2019 - 00023 - FST , MYRG2020 - 00101-   FST and MYRG2022 - 00152 - FST ; in part by Natu-   ral Science Foundation of China under 61971476 ;   and in part by Alibaba Group through Alibaba In-   novative Research Program .   References2932   A Network Structure   We present the network structure of the pre - trained   model with full modalities in Fig . 8(a ) , the ensem-   ble AE - based encoder - decoder network in Fig . 8(b ) ,   and the Missing Modality Imagination Network   ( MMIN ) in Fig . 8(c ) .   To be specific , in Fig 8(a ) , three modalities are   first encoded by the Multi - Head Attention ( MHA )   module , and then are concatenated for classifica-   tion . In Fig . 8(b ) , the hidden sizes of full connected   layers are in [ 300 , 256 , 128 , 64 , 128 , 256 , 300 ] .   In Fig . 8(c ) , we adopt 5 Residual Autoencoders   ( RA ) with the same layer settings in AE , where the   encoder outputs are obtained by concatenating the   latent space of 5 RA blocks .   B Implementation Details   All experiments are carried out on a Linux server   ( Ubuntu 18.04.1 ) with a Intel(R ) Xeon(R ) Gold   5120 CPU , 128 G RAM , 8 Nvidia 2080TI and 2   Nvidia 3090 GPUs .   B.1 Datasets Distributions   The detailed distributions on CMU - MOSI and   IEMOCAP are shown in Table 5 . Besides , the   distributions of multiple classes on IEMOCAP are   presented in Table 6.2933   B.2 Hyper - parameters   Following a standardized procedure , we tune our   model by the grid - searching on the training set .   Adam is adopted to minimize the total loss . The   batch size is 32 , the loss weight is set to 0.1 , and   these parameters are summarized in Table 7 .   C Memory and Running Time   For the memory utilization , Fig . 9 presents the   parameters of different ensemble approaches . As   can be observed , the number of parameters dramati-   cally increase when integrating MMIN . The reason   is that MMIN contains 5 residual auto - encoders ,   which are memory costly .   As for the training and testing time , we show   the detailed statistics in Table 8 . Specifically , we   report the training time at 10 epochs and the testing   time for the test dataset on 2080Ti and 3090 GPUs   respectively . It can be seen that the testing time is   acceptable though the training time varies consid-   erably during training . Besides , compared to the   2080Ti GPU , the 3090 GPU spends less time due   to its stronger computational capability . Although   the proposed EMMR boosts the performance , it   can be expensive regarding to both time and space ,   motivating us to further optimize the model effec-   tively.2934