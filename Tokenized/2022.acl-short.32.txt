  Zixuan Li , Saiping Guan , Xiaolong Jin , Weihua Peng , Yajuan Lyu ,   Yong Zhu , Long Bai , Wei Li , Jiafeng Guo , Xueqi ChengSchool of Computer Science and Technology , University of Chinese Academy of Sciences;CAS Key Laboratory of Network Data Science and Technology ,   Institute of Computing Technology , Chinese Academy of Sciences;Baidu Inc.   { lizixuan,guansaiping,jinxiaolong}@ict.ac.cn   { pengweihua,lvyajuan,zhuyong}@baidu.com   Abstract   A Temporal Knowledge Graph ( TKG ) is a   sequence of KGs corresponding to different   timestamps . TKG reasoning aims to predict   potential facts in the future given the histori-   cal KG sequences . One key of this task is to   mine and understand evolutional patterns of   facts from these sequences . The evolutional   patterns are complex in two aspects , length-   diversity and time - variability . Existing mod-   els for TKG reasoning focus on modeling fact   sequences of a ﬁxed length , which can not dis-   cover complex evolutional patterns that vary   in length . Furthermore , these models are all   trained ofﬂine , which can not well adapt to the   changes of evolutional patterns from then on .   Thus , we propose a new model , called Com-   plex Evolutional Network ( CEN ) , which uses   a length - aware Convolutional Neural Network   ( CNN ) to handle evolutional patterns of differ-   ent lengths via an easy - to - difﬁcult curriculum   learning strategy . Besides , we propose to learn   the model under the online setting so that it   can adapt to the changes of evolutional patterns   over time . Extensive experiments demonstrate   that CEN obtains substantial performance im-   provement under both the traditional ofﬂine and   the proposed online settings .   1 Introduction   Temporal Knowledge Graph ( TKG ) ( Boschee et al . ,   2015 ; Gottschalk and Demidova , 2018 , 2019 ; Zhao ,   2020 ) has emerged as a very active research area   over the last few years . Each fact in TKGs is a   quadruple ( subject , relation , object , timestamp ) . A   TKG can be denoted as a sequence of KGs with   timestamps , each of which contains all facts at the   corresponding timestamp . TKG reasoning aims to   answer queries about future facts , such as ( COVID-   19 , New medical case occur , ? , 2022 - 1 - 9 ) .   To predict future facts , one challenge is to dive   deep into the related historical facts , which reﬂectthe preferences of the related entities and affect   their future behaviors to a certain degree . Such   facts , usually temporally adjacent , may carry in-   formative sequential patterns , called evolutional   patterns in this paper . For example , [ ( COVID-19 ,   Infect , A , 2021 - 12 - 21 ) , ( A , Discuss with , B , 2021-   12 - 25 ) , ( B , Go to , Shop , 2021 - 12 - 28 ) ] is an informa-   tive evolutional pattern for the above query implied   in historical KGs . There are two kinds of models to   model evolutional patterns , namely , query - speciﬁc   and entire graph based models . The ﬁrst kind of   models ( Jin et al . , 2020 ; Li et al . , 2021a ; Sun et al . ,   2021 ; Han et al . , 2020a , 2021 ; Zhu et al . , 2021 )   extract useful structures ( i.e. , paths or subgraphs )   for each individual query from the historical KG   sequence and further predict the future facts by min-   ing evolutional patterns from these structures . This   kind of models may inevitably neglect some useful   evolutional patterns . Therefore , the entire graph   based models ( Deng et al . , 2020 ; Li et al . , 2021a )   take a sequence of entire KGs as the input and   encode evolutional patterns among them , which   exhibit superiority to the query - speciﬁc models .   However , they all ignore the length - diversity and   time - variability of evolutional patterns . Length-   diversity : The lengths of evolutional patterns are   diverse . For example , [ ( COVID-19 , Infect , A , 2021-   12 - 21 ) , ( A , Discuss with , B , 2021 - 12 - 25 ) , ( B , Go to ,   Shop , 2021 - 12 - 28 ) ] is a useful evolutional pattern   of length 3 to predict the query ( COVID-19 , New   medical case occur , ? , 2022 - 1 - 9 ) and [ ( COVID-19 ,   Infect , A , 2021 - 12 - 21 ) , ( A , Go to , Shop , 2021 - 12-   30 ) ] is also a useful evolutional pattern of length   2 for this query . Previous models extract evolu-   tional patterns of a ﬁxed length , which can not han-   dle evolutional patterns of diverse lengths . Time-   variability : Evolutional patterns change over time .   For example , ( COVID-19 , Infect , A , 2019 - 12 - 9 )   and(COVID-19 , Infect , A , 2022 - 1 - 9 ) may lead   to different results due to the wide usage of the   COVID-19 vaccines . Previous models learn from290the historical training data , which fail in model-   ing the time - variability of evolutional patterns after   that .   Upon the above observations , we propose Com-   plex Evolutional Network ( CEN ) to deal with   the above two challenges . For length - diversity ,   CEN learns evolutional patterns from historical KG   sequences of different lengths via an Relational   Graph Neural Network ( RGCN ) based KG se-   quence encoder and a length - aware Convolutional   Neural Network ( CNN ) based evolutional represen-   tation decoder . Besides , the model is trained via an   easy - to - difﬁcult curriculum learning strategy incre-   mentally according to the length of KG sequences .   For time - variability , we learn CEN under an online   setting and combine CEN with a temporal regular-   ization unit to alleviate the catastrophic forgetting   problem ( Mccloskey and Cohen , 1989 ) .   In general , this paper makes the following con-   tributions :   •We address , for the ﬁrst time , the problems of   length - diversity and time - variability of evolu-   tional patterns for TKG reasoning .   •For length - diversity , we propose a length-   aware CNN to learn evolutional patterns with   different lengths in a curriculum learning man-   ner . For time - variability , we propose to learn   the model under an online setting to adapt to   the changes of evolutional patterns .   •Experiments demonstrate that the proposed   CEN model achieves better performance on   TKG reasoning under both the traditional of-   ﬂine and the proposed online settings .   2 Related Work   The TKG reasoning task primarily has two settings ,   interpolation and extrapolation . This paper focus   on the extrapolation setting . In what follows , we   will introduce related work on both settings :   TKG Reasoning under the interpolation set-   ting . This setting aims to complete the missing   facts at past timestamps ( Jiang et al . , 2016 ; Leblay   and Chekol , 2018 ; Dasgupta et al . , 2018 ; Garcia-   Duran et al . , 2018 ; Goel et al . , 2020 ; Wu et al . ,   2020 ) . For example , TTransE ( Leblay and Chekol ,   2018 ) extends TransE ( Bordes et al . , 2013 ) by   adding the temporal constraints ; HyTE ( Dasgupta   et al . , 2018 ) projects the entities and relations to   time - aware hyperplanes to generate representationsfor different timestamps . Above all , they can not   obtain the representations of the unseen timestamps   and are not suitable for the extrapolation setting .   TKG Reasoning under the extrapolation set-   ting This setting aims to predict facts at future   timestamps , which can be categorized into two   groups : query - speciﬁc and entire graph based mod-   els . Query - speciﬁc models focus on modeling the   query - speciﬁc history . For example , RE - NET ( Jin   et al . , 2020 ) captures the evolutional patterns im-   plied in the subgraph sequences of a ﬁxed length   speciﬁc to the query . CyGNet ( Zhu et al . , 2021 )   captures repetitive patterns by modeling repetitive   facts . xERTE ( Han et al . , 2020a ) learns to ﬁnd   the query - related subgraphs of a ﬁxed hop num-   ber . CluSTeR ( Li et al . , 2021a ) and TITer ( Sun   et al . , 2021 ) both adopt reinforcement learning to   discover evolutional patterns in query - related paths   of a ﬁxed length . Unlike the query - speciﬁc models ,   entire graph based models encode the latest histor-   ical KG sequence of a ﬁxed - length . RE - GCN ( Li   et al . , 2021b ) captures the evolutional patterns into   the representations of all the entities by model-   ing KG sequence of a ﬁxed - length at lastest a few   timestamps . Glean ( Deng et al . , 2020 ) introduces   event descriptions to enrich the information of the   entities .   3 Problem Formulation   A TKG G = fG ; G ; : : : ; G ; : : : g , where G=   ( V;R;E ) , is a directed multi - relational graph . V   is the set of entities , Ris the set of relations ,   andEis the set of facts at timestamp t. The   TKG reasoning task aims to answer queries like   ( s ; r ; ? ; t)or ( ? ; r ; o ; t)with the historical KG se-   quencefG ; G ; : : : ; Gggiven , where s ; o2V ,   r2 R andtare the subject / object entity , the   relation and the query timestamp , respectively . Fol-   lowing Jin et al . ( 2020 ) , KGs from timestamps   1toT , TtoT , TtoT(T < T < T ) are   used as the training , validation and test sets , respec-   tively . Under the traditional ofﬂine setting , models   are trained only using the training set ( tT ) ,   while under the online setting , the model will be   updated by KGs before t(T < tT ) contin-   ually . Without loss of generality , we describe our   model as predicting the missing object entity .   4 Methodology   We propose CEN to deal with the length - diversity   and time - variability challenges of evolutional pat-291   tern learning for TKG reasoning . Speciﬁcally , CEN   consists of a basic model as well as a curriculum   learning strategy for the former challenge and an   online learning strategy for the latter challenge .   4.1 Basic CEN Model   As shown in Figure 1 , the basic model of CEN con-   tains a KG sequence encoder and an evolutional   representation decoder . The KG sequence encoder   encodes the latest historical KG sequences of differ-   ent lengths to corresponding evolutional represen-   tations of entities . Then , the evolutional represen-   tation decoder calculates the scores of all entities   for the query based on these representations .   KG Sequence Encoder . Its inputs include the   lastest historical KG sequences of lengths from 1   toK , initial representations of entities H2R   and relation representations R2R , where   dis the dimension of the representations . Take   the KG sequence of length k= 2 for example ,   for each KG in the input sequence fG ; Gg ,   it iteratively calculates the evolutional represen-   tations of entities Hat the corresponding times-   tamps t2ft 1 ; tgas follows :   ^H = RGCN ( H;R ; G ) ; ( 1 )   H = SC(^H;H ) ; ( 2 )   where RGCN ( )andSCdenote the shared RGCN   layer and the skip connection unit proposed in   RE - GCN ( Li et al . , 2021b ) . For the initial times-   tamp t 1,His set to H.Ris shared   across timestamps , which is different from RE-   GCN . By reusing the encoder for KG sequences   of different lengths , we obtain Kentity evo-   lution representations at the query timestamp :   fH ; : : : ; H ; : : : ; Hg .   Evolutional Representation Decoder . Multiple   evolutional representations contain evolutional pat-   terns of multiple lengths . To distinguish the inﬂu-   ences of the length - diverse evolutional patterns , we   design a length - aware CNN , which uses Kseparate   channels to model the above Kevolutional repre-   sentations . Speciﬁcally , for a query ( s ; r ; ? ; t ) , the   representations of s(s ; : : : ; s ; : : : ; s ) and r(r )   are looked up from multiple representations of enti-   tiesfH ; : : : ; H ; : : : ; Hgand the shared relation   representations R. For historical KG sequence of   length k , kchannel with Cdifferent kernels of   size2Mis used to decode the concatenation   ofsandr . Speciﬁcally , the feature maps are   calculated as below ,   m(s ; r ; t ) = Conv(w;[s;r]);(3 )   where Convdenotes the 2D convolution op-   eration , w(0c < C ) are the trainable   parameters in ckernel of kchannel and   m(s ; r ; t)2R. After that , it concatenates   the output vectors from Ckernels yielding a vector :   m(s ; r ; t)2R. ForKchannels , it outputs a   list of vectors : [ m(s ; r ; t ) , ... , m(s ; r ; t ) , ... ,   m(s ; r ; t ) ] . Then , each vector is fed into a   shared 1 - layer Fully Connected Network ( FCN )   withW2Ras its parameters and the ﬁ-   nal score of a candidate entity ois the sum of   the logits from multiple evoltional representations : Pm(s ; r ; t)Wo , where ois the evolu-   tional representation of length kforo . Then we   seen it as a multi - class learning problem and use   the cross - entropy as its objective function .   4.2 Curriculum Learning for Length - diversity   Longer historical KG sequences contain more his-   torical facts and longer evolutional patterns , which   is more challenging to learn . Similar to human   learning procedures , the models can beneﬁt from   an easy - to - difﬁcult curriculum . Besides , how to292   choose the maximum length of evolutional patterns   is vital to CEN . Thus , we design the curriculum   learning strategy to learn the length - diverse evolu-   tional patterns from short to long and adaptively   select the optimal maximum length ^K. As shown   at the top of Figure 2 , we start from the minimum   length ^k(^k= 1for example ) and gradually move   on to longer history in the training set . The model   stops the curriculum and gets the optimal ^Kwhen   the MRR metric decreases or the length is up to   maximum length K. Note that , curriculum learn-   ing is conducted under the traditional ofﬂine setting   andModelis used as the pre - trained model for   online learning .   4.3 Online Learning for Time - variability   To handle the time - variability of evolutional pat-   terns , one simple and direct method is to update   the model according to the newly occurred facts .   Thus , as shown in the bottom of Figure 2 , for times-   tamp t+ 1(T < t+ 1 < T),Modelis ﬁne-   tuned to get Modelby predicting the facts in   the KG at the last timestamp Gwith historical KG   sequences as inputs . Furthermore , to balance the   knowledge of new evolutional patterns and the ex-   isting ones , we use a Temporal Regularization unit   ( TR unit ) ( Daruna et al . , 2021 ; Wu et al . , 2021 ) . We   apply an L2regularization constraint between two   temporally adjacent models to smooth the drastic   change of the parameters .   4.4 Analysis on Computational Complexity   We analyze the computational complexity of CEN .   We view the computational complexities of the   RGCN unit and ConvTransE as constants . Then ,   the time complexity of the RGCN at a timestamp   tisO(jEj ) , wherejEjis the maximum number   of facts at timestamps in history . As we unroll m   ( m=^K ^k)sequences , the time complexity of the   KG sequence encoder is ﬁnally O(mjEj ) . Thus ,   the time complexity of CEN is O(mjEj+m).5 Experiments   Experimental Setup . We adopt three widely-   used datasets , ICEWS14 ( Li et al . , 2021b ) ,   ICEWS18 ( Jin et al . , 2020 ) , and WIKI ( Leblay   and Chekol , 2018 ) to evaluate CEN . Dataset statis-   tics are demonstrated in Table 1 . Due to the   space limitation , the CEN model is only com-   pared with the latest models of TKG reasoning :   CyGNet ( Zhu et al . , 2021 ) , RE - NET ( Jin et al . ,   2020 ) , xERTE ( Han et al . , 2020a ) , TG - Tucker ( Han   et al . , 2021 ) , TG - DistMult ( Han et al . , 2021 ) ,   TiTer ( Sun et al . , 2021 ) and RE - GCN ( Li et al . ,   2021b ) . In the experiments , we adopt MRR ( Mean   Reciprocal Rank ) and Hits@{1,3,10 } as the met-   rics for TKG reasoning . We averaged the met-   rics over ﬁve runs . Note that , following Han   et al . ( 2020b ) , we adopt an improved ﬁltered set-   ting where the timestamps of facts are considered ,   called time - aware ﬁltered setting . Take a typi-   cal query ( s ; r ; ? ; t)with answer oin the test   set for example , and assume there is another two   facts(s ; r ; o ; t)and(s ; r ; o ; t ) . Under this time-   aware ﬁltered setting , only owill be considered   as a correct answer and thus removed from the   ranking list of candidate answers .   Implementation Details . In the experiments ,   the optimal minimum lengths of evolutional pat-   terns ^kfor ICEWS14 , ICEWS18 , WIKI are 3 , 3 ,   2 , respectively . The maximum length Kfor all   datasets is set to 10 . For all datasets , the kernel   width Mis set to 3 , and Cis set to 50 . For each fact   ( s ; r ; o ; t ) in the test set , we evaluate CEN on two   queries ( s ; r ; ? ; t)and ( ? ; r ; o ; t ) . The dimension   dof relation representations and entity representa-   tions is set to 200 on all datasets . Adam ( Kingma   and Ba , 2014 ) is adopted for parameter learning   with the learning rate of 0.001 on all datasets . The   number of RGCN layers is set to 2 and the dropout   rate for each layer to 0.2 . For the online setting , we   set the max epochs of the ﬁne - tuning at each times-   tamp to 30 . For predicting G , Gis used as the   validation set . We ﬁne tune the pre - trained CEN   fromT1 + 1 toTand report the results at the test   timestamps ( TtoT ) in Table 3 . The experiments   are carried out on Tesla V100 . Codes are avaliable   at https://github.com/Lee-zix/CEN .   5.1 Experimental Results   Results under the Ofﬂine Setting . The results   under the traditional ofﬂine setting are presented   in Table 2 . CEN consistently outperforms the293   baselines on MRR , Hits@3 , and Hits@10 on all   datasets , which justiﬁes the effectiveness of mod-   eling the evolutional patterns of different lengths .   On ICEWS datasets , CEN underperforms TITer on   Hits@1 because TITer retrieves the answer through   explicit paths , which usually gets high Hits@1 .   Whereas , CEN recalls more answer entities by ag-   gregating the information from multiple evolutional   patterns , which may be the reason for its high per-   formance on Hits@3 and Hits@10 .   Results under the Online Setting . Under the   online setting , the model is updated via historical   facts at the testset . Thus , it can not be directly com-   pared with the baselines designed for the ofﬂine   setting . As shown in Table 3 , on ICEWS datasets   CEN outperforms CEN(-TR ) ( CEN without TR   unit ) , which implies the effectiveness of TR unit to   balance the knowledge of new evolutional patterns   and the existing ones . On WIKI , CEN(-TR ) gets   better performance . It is because that the time in-   terval between two adjacent timestamps in WIKI   ( one year ) is much larger than ICEWS datasets ( one   day ) and contains more time - variable evolutional   patterns . TR unit limits the model to adapt to new   knowledge and is not suitable for this dataset .   Ablation Study . To investigate the contribu-   tions of curriculum learning strategy and the length-   aware CNN , we conduct ablation studies for CENon the test set of ICEWS14 under the traditional   ofﬂine setting , which are shown in Table 4 . CEN(-   CL ) denotes CEN without the curriculum learn-   ing strategy . The underperformance of CEN(-CL )   demonstrates the effectiveness of the curriculum   learning strategy . CEN(-LA ) denotes the model   replacing the length - aware CNN with a traditional   CNN . The underperformance of CEN(-LA ) implies   the effectiveness of the length - aware CNN .   6 Conclusions   In this paper , we proposed Complex Evolutional   Network ( CEN ) for TKG reasoning , which deals   with two challenges in modeling the complex   evolutional patterns : length - diversity and time-   variability . For length - diversity , CEN adopts a   length - aware CNN to learn evolutional patterns of   different lengths and is trained under a curriculum   learning strategy . For time - variability , we explored   a new online setting , where the model is expected   to be updated to new evolutional patterns emerging   over time . Experimental results demonstrate the   superiority of the proposed model under both the   ofﬂine and the online settings .   Acknowledgments   The work is supported by the National Natural Sci-   ence Foundation of China under grants U1911401 ,   62002341 and 61772501 , the GFKJ Innovation Pro-   gram , Beijing Academy of Artiﬁcial Intelligence   under grant BAAI2019ZD0306 , and the Lenovo-   CAS Joint Lab Youth Scientist Project.294References295296