  Yong Xie , Dakuo Wang , Pin - Yu Chen , Jinjun Xiong , Sijia Liuand Sanmi KoyejoUniversity of Illinois Urbana - Champaign , IBMState University of New York at Buffalo , Michigan State University   Abstract   More and more investors and machine learn-   ing models rely on social media ( e.g. , Twit-   ter and Reddit ) to gather real - time informa-   tion and sentiment to predict stock price move-   ments . Although text - based models are known   to be vulnerable to adversarial attacks , whether   stock prediction models have similar vulnera-   bility is underexplored . In this paper , we exper-   iment with a variety of adversarial attack con-   ﬁgurations to fool three stock prediction vic-   tim models . We address the task of adversarial   generation by solving combinatorial optimiza-   tion problems with semantics and budget con-   straints . Our results show that the proposed   attack method can achieve consistent success   rates and cause signiﬁcant monetary loss in   trading simulation by simply concatenating a   perturbed but semantically similar tweet .   1 Introduction   The advance of deep learning based language mod-   els are playing a more and more important role   in the ﬁnancial context , including convolutional   neutral network ( CNN ) ( Ding et al . , 2015 ) , recur-   rent neutral network ( RNN ) ( Minh et al . , 2018 ) ,   long short - term memory network ( LSTM ) ( Hiew   et al . , 2019 ; Sawhney et al . , 2021 ; Hochreiter and   Schmidhuber , 1997 ) , graph neutral network ( GNN )   ( Sawhney et al . , 2020a , b ) , transformer ( Yang et al . ,   2020 ) , autoencoder ( Xu and Cohen , 2018 ) , etc . For   example , Antweiler and Frank ( 2004 ) ﬁnd that com-   ments on Yahoo Finance can predict stock market   volatility after controlling the effect of news . Cook-   son and Niessner ( 2020 ) also show that sentiment   disagreement on Stocktwits is highly related to cer-   tain market activities . Readers can refer to these   survey papers for more details ( Dang et al . , 2020 ;   Zhang et al . , 2018 ; Xing et al . , 2018).Figure 1 : An example of word - replacement adversarial   attack . ( Top ) benign tweet leads Stocknet to pre-   dict stock going UP ; ( Bottom ) adding an adversarial   retweet leads Stocknet to predict stock going DOWN .   It is now known that text - based deep learning   models can be vulnerable to adversarial attacks   ( Szegedy et al . , 2014 ; Goodfellow et al . , 2015 ) . The   perturbation can be at the sentence level ( e.g. , Xu   et al . , 2021 ; Iyyer et al . , 2018 ; Ribeiro et al . , 2018 ) ,   the word level ( e.g. , Zhang et al . , 2019 ; Alzantot   et al . , 2018 ; Zang et al . , 2020 ; Jin et al . , 2020 ; Lei   et al . , 2019 ; Zhang et al . , 2021 ; Lin et al . , 2021 ) ,   or both ( Chen et al . , 2021 ) . We are interested in   whether such adversarial attack vulnerability also   exists in stock prediction models , as these models   embrace more and more human - generated media   data ( e.g. , Twitter , Reddit , Stocktwit , Yahoo News   ( Xu and Cohen , 2018 ; Sawhney et al . , 2021 ) ) . The   adversarial robustness is a more critical issue in   the context of stock prediction as anyone can post   perturbed tweets or news to inﬂuence forecasting   models . For example , a fake news ( “ Two Explo-   sions in the White House and Barack Obama is   Injured ” ) posted by a hacker using the Associated-   Press ’s Twitter account on 04/23/2013 erased $ 136587billion market value in just 60 seconds ( Fisher ,   2013 ) . Although the event does n’t fall into the   category of adversarial attack , it rings the alarm   for traders who use ( social ) media information for   their trading decisions .   To our best knowledge , it is the ﬁrst paper to   consider the adversarial attack in the ﬁnancial NLP   literature . Many attacks modify benign text directly   ( manipulation attack ) and use them as model input ;   However , in our case , adversarial retweets enter the   model along with benign tweets ( concatenation at-   tack ) , which is more realistic as malicious Twitter   users can not modify others ’ tweets . In other words ,   we formulate the task as a text - concatenating attack   ( Jia and Liang , 2017 ; Le et al . , 2021 ): we imple-   ment the attack by injecting new tweets instead of   manipulating existing benign tweets . Our task is   inspired and mimics the retweet function on social   media , and uses it to feed the adversarial samples   into the dataset . Despite various algorithms are pro-   posed to generate manipulation attack , literature   of concatenation attack on classiﬁcation models is   rare , with exceptions Le et al . ( 2021 ) , Song et al .   ( 2021 ) and Wang et al . ( 2020 ) . Our paper provides   extra evidence of their difference by investigating   their performances in the ﬁnancial domain .   The main challenge is to craft new and effective   adversarial tweets . We solve the task by aligning   the semantics with benign tweets so that the poten-   tial human and machine readers ca n’t detect our   adversarial tweets . To achieve that , we consider   the generation task as a combinatorial optimiza-   tion problem ( Zang et al . , 2020 ; Guo et al . , 2021 ) .   Speciﬁc tweets are ﬁrst selected , which are used   as the target of perturbation on a limit number of   words within the tweets . We then examine our   attack method on three ﬁnancial forecast models   with attack success rate , F1and potential proﬁt and   lossas evaluation metrics . Results show that our   attack method consistently achieves good success   rate on the victim models . More astonishingly , the   attack can cause additional loss of 23 % to 32 % if   an investor trades on the predictions of the victim   models ( Fig . 4 ) .   2 Adversarial Attack on Stock   Prediction Models with Tweet Data   Attack model : Adversarial tweets . In the case   of Twitter , adversaries can post malicious tweets   which are crafted to manipulate downstream mod-   els that take them as input . We propose to attackby posting semantically similar adversarial tweets   as retweets on Twitter , so that they could be identi-   ﬁed as relevant information and collected as model   input . For example , as shown in Fig 1 , the origi-   nal authentic tweet by the user wallstreetbet7821   was “ $ BHP announces the demerger of its non-   core assets - details expected to be ﬁlled in on   Tuesday . ” An adversarial sentence could be “ $ BHP   announces the demerger of its non - core assets -   details expected to be exercised in on Tuesday . ” .   The outcome of the victim model switches to nega-   tive prediction from positive prediction when the   retweet is added to the input .   The proposed attack method takes the practi-   cal implementation into its design consideration ,   thus has many advantages . First , the adversarial   tweets are crafted based on carefully - selected rel-   evant tweets , so they are more likely to pass the   models ’ tweet ﬁlter and enter the inference data   corpus . Secondly , adversarial tweets are optimized   to be semantically similar to the original tweets so   that they are not counterfactual and very likely to   fool human sanity checks as well as the Twitter ’s   content moderation system .   Attack generation : Hierarchical perturbation .   The challenge of our attack method centers around   how to select the optimal tweets and the token per-   turbations with the constraints of semantic simi-   larity . In this paper , we formulate the task as a   hierarchical perturbation consisting of three steps :   tweet selection , word selection andword perturba-   tion . In the ﬁrst step , a set of optimal tweets is ﬁrst   selected as the target tweets to be perturbed and   retweeted . For each selected tweet in the pool , the   word selection problem is then solved to ﬁnd one   or more optimal words to apply perturbation . Word   and tweet budgets are also introduced to quantify   the strength of the perturbation .   We consider the word replacemen t and dele-   tion for word perturbation ( Garg and Ramakrish-   nan , 2020 ; Li et al . , 2020 ) . In the former case ,   the ﬁnal step is to ﬁnd the optimal candidate as   replacement . A synonym as replacement is widely   adopted in the word - level attack since it is a natural   choice to preserve semantics ( Zang et al . , 2020 ;   Dong et al . , 2021 ; Zhang et al . , 2019 ; Jin et al . ,   2020 ) . Therefore , we replace target words with   their synonyms chosen from synonym sets which   contain the semantically closest words measured   by the similarity of the GLOVE embedding ( Jin   et al . , 2020).588Mathematical Formulation . We consider a   multimodal stock forecast model f(·)that takes   tweet collections{c}and numerical factors   { p}as input , where tindexes the date when   the data is collected . Peeking into the tweet col-   lection , it contains |c|tweets for date t , namely ,   c={s , s , ... , s } . Each tweet sis a text-   based sentence of length |s| , denoted as s=   ( w , ... , w , ... , w ) , fori= 1 , ... , |c| . A di-   rectional ﬁnancial forecast model takes domains   of tweets and numerical factors as input , and   yields prediction for stocks ’ directional movement   y∈{− 1,1 } :   ˆy = f(c , p ) , ( 1 )   his the looking - back window for historical data .   The hierarchical perturbation can be cast as a   combinatorial problem for tweet selection m , word   selection zand replacement selection u. The   boolean vector mindicates the tweets to be se-   lected . For i - th tweet , vector zindicates the word   to be perturbed . As for the word perturbation task ,   another boolean vector uselects the best replace-   ment . It follows that the hierarchical perturbation   can be formulated as   c= ( 1−m·z)·c+m·z·u·S(c),(2 )   where·denotes element - column wise product ,   m·zindicates the selected words in selected   tweets , m·z·uindicates selected synonyms for   each selected word , and S(·)is a element - wise syn-   onym generating function . Consequently , given   attack lossL , generation of adversarial retweets   can be formulated as the optimization program   minL(c∪c , c|p , f ) , subject to   the budget constraints : a)1m≤b , b)1z≤   b,∀iandc)1u= 1,∀i , j , where bandb   denote the tweet and word budgets . It is worth to   stress that perturbation is only applied to the date   ( t ) when the attack is implemented to preserve the   temporal order .   To solve the program , we follow the convex   relaxation approach developed in ( Srikant et al . ,   2021 ) . Speciﬁcally , the boolean variables ( for tweet   and word selection ) are relaxed into the continuous   space so that they can be optimized by gradient-   based methods over a convex hull . Two main imple-   mentations of the optimization - based attack gen-   eration method are proposed : joint optimization   ( JO ) solver and alternating greedy optimization   ( AGO ) solver . JO calls projected gradient descentmethod to optimize the tweet and word selection   variables and word replacement variables simulta-   neously . AGO uses an alternative optimization pro-   cedure to sequentially update the discrete selection   variables and the replacement selection variables .   More details on the optimization program and the   solvers can be found in Appendix A.   3 Experiments   Dataset & victim models . We evaluate our ad-   versarial attack on a stock prediction dataset con-   sisting of 10,824 instances including relevant   tweets and numerical features of 88 stocks from   2014 to 2016 ( Xu and Cohen , 2018 ) . Three mod-   els ( Stocknet ( Xu and Cohen , 2018 ) , FinGRU   based on GRU ( Cho et al . , 2014 ) and FinLSTM   based on LSTM ( Hochreiter and Schmidhuber ,   1997 ) ) of binary classiﬁcation are considered as   victims in this paper . We apply our attack to in-   stances on which the victim models make correct   predictions .   Evaluation metrics . Attack performance is eval-   uated by two metrics : Attack Success Rate ( ASR )   and victim model ’s F1drop after attack . ASR   is deﬁned as the percentage of the attack efforts   that changes the model output . The two metrics   gauge the efﬁcacy of the attack and its impact on   model performance : More efﬁcient attack leads to   higher ASR and more decline of F1 . Moreover ,   we simulate a Long - Only Buy - Hold - Sell strategy   ( Sawhney et al . , 2021 ; Feng et al . , 2019 ) with vic-   tim models , and calculate the Proﬁt and Loss ( PnL )   for each simulation . Assume a portfolio starts with   initial net value $ 10000 ( 100 % ) , its net value at the   end of test period reﬂects the proﬁtability of the   trading strategy and the underlying model . Conse-   quently , the change in PnLs measures the monetary   impact of our attack . More details on the dataset ,   victim models and evaluation metrics are housed   in Appendix B.   4 Results   Attack performance with single perturbation .   The experiment results for the concatenation at-   tack with word replacement perturbation is shown   in Table 1 ( with tweet and word budgets both as 1 ) .   For both JO and AGO , ASR increases by roughly   10 % and F1 drops by 0.1 on average in compari-   son to the random attack . Such performance drop   is considered signiﬁcant in the context of stock   prediction given that the state - of - the - art prediction589accuracy of interday return is only about 60 % .   Effect of attack budget . We report the effect of   different attack budgets on the attack performance   in Fig . 2 . We observe that the more budgets al-   lowed ( perturbing more tweets and words ) , the bet-   ter the attack performance , but the increase is not   signiﬁcant . It appears that the attack performance   becomes saturated if we keep increasing the attack   budgets . In fact , the attack with budget of one   tweet and one word is the most cost effective , pro-   vided that it introduces minimum perturbation but   achieves a relatively similar ASR .   Manipulation vs concatenation attack . We fo-   cus on concatenation attack in this paper since we   believe it is distinct from manipulation attack . We   investigate the difference by applying the same   method of tweet generation to implement manipu-   lation attack , where the adversarial tweets replace   target tweets instead . The experiment runs with one   word budget and one twee budget , and the results   are reported in Fig . 3 .   It is clear that manipulation attack remarkably   outperforms concatenation attack in terms of ASRand F1 . Even though the success rate of concatena-   tion attack lags behind the state - of - the - art textual at-   tack , the manipulation attack achieves performance   of the same ballpark , which demonstrates the efﬁ-   cacy of optimization - based attack and our solvers .   More importantly , it implies that the attack is not   transferable between the two tasks , documenting   more evidence on language attack transferability   ( Yuan et al . , 2021 ; He et al . , 2021 ) . The bottom line   is that they are two different tasks under different   assumptions . Researchers should take downstream   scenarios into account when develop attack models .   Trading simulation . The ultimate measure of a   stock prediction model ’s performance is proﬁtabil-   ity . Fig . 4 plots the proﬁt and loss of the same   trading strategy with Stocknet as the prediction   model with or without the attack – JO is used to   generate adversarial retweets . For each simulation ,   the investor has $ 10 K ( 100 % ) to invest ; the re-   sults show that the proposed attack method with a   retweet with only a single word replacement can   cause the investor an additional $ 3.2 K ( 75%-43 % )   loss to their portfolio after about 2 years .   5 Conclusion   This work demonstrates that our adversarial attack   method consistently fools various ﬁnancial fore-   cast models even with physical constraints that the   raw tweet can not be modiﬁed . Adding a retweet   with only one word replaced , the attack can cause   32 % additional loss to our simulated investment   portfolio . Via studying ﬁnancial model ’s vulnera-   bility , our goal is to raise ﬁnancial community ’s   awareness of the AI model ’s risks , so that in the   future we can develop more robust human - in - the-   loop AI architecture ( Wang et al . , 2019 ) to cope   with this and other real - world attacks , including   black - box attack , unknown input domains , etc.590References591592593A Mathematical Formation   A.1 Financial Forecast Model   Massive amounts of text data are generated by mil-   lions of users on Twitter every day . Among a vari-   ety of discussion , stock analysis , picking and pre-   diction are consistently one of the trending topics .   And investors often use the Twitter cashtag func-   tion ( a $ symbol followed by a ticker ) to organize   their particular thoughts around one single stock ,   e.g. , $ AAPL , so that users can click and see the   ongoing discussions . Textual data on Twitter is   collectively generated by all of its users via posting   tweets . Financial organizations and institutional   investors often ingest the massive text data in real   time and incorporate them or their latent represen-   tation into their stock prediction models .   We consider the multimodal stock forecast mod-   els that take tweet collections { c}and numer-   ical factors{p}as input , where tindexes the   date when the data is collected . The numerical   factors are usually mined from historical price , fun-   damentals and other alternative data sources . In   this paper , we assume that the domain of numerical   factors is unassailable since they are directly de-   rived from public records . Therefore , the objective   of adversary is to manipulate model output by in-   jecting perturbation to the textual domain { c } .   Peeking into the tweet collection , it contains |c|   tweets for date t , namely , c={s , s , ... , s } .   Each tweet sis a text - based sentence of length   |s| , denoted as s= ( w , ... , w , ... , w ) ,   fori= 1 , ... , |c| . A directional ﬁnancial fore-   cast model takes domains of tweets and numerical   factors as input , and yields prediction for stocks ’   directional movement y∈{− 1,1 } :   ˆy = f(c , p ) , ( 3 )   where his the looking - back window for historical   data .   A.2 Attack Model   Letcbe the perturbed tweet collection at time   tcreated by solving the hierarchical perturbation   problem . To formalize the perturbation task , we   introduce boolean vector variable m∈{0,1 }   to indicate the tweets to be selected . If m= 1 ,   theni - th tweet is the target tweet to be perturbed   and retweeted . Besides , for i - th tweet , vector   z∈{0,1}indicates the word to be perturbed .   As for the word perturbation task , another booleanvector u∈ { 0,1}selects the best replace-   ment . nandnandndenote the maximum   amount of tweets , maximum amount of words in   each tweet , and the amount of synonyms for each   word , respectively . We identify deletion perturba-   tion as a special case of replacement with u= 1   only for padding token , so that the task degenerates   to tweet selection and word selection . Let vector   z∈{0,1}denote ndifferent zvector ,   andu∈{0,1}denote n×ndiffer-   entuvectors . It follows that the hierarchical   perturbation can be deﬁned as   c= ( 1−m·z)·c+m·z·u·S(c )   s.t . 1m≤b ,   1z≤b,∀i ,   1u= 1,∀i , j,(4 )   where·denotes element - column wise product , b   denotes tweet budget , bdenotes word budget and   S(·)is element - wise synonym generating function .   Adversarial retweets are the then passed into   downstream ﬁnancial forecast model f(·)along   with benign tweets . Attack success is achieved if   the adversarial tweets manage to fool the down-   stream model , and change the model output . Fi-   nancial forecast model usually takes observation of   multiple steps as input to appreciate the temporal   dependence . However , adversary can only inject   adversarial retweets at present time . That is , when   run the model on day tto predict price movement   on day t+ 1 , retweets only enter tweet collection   for day t ; collections for days prior to tremain   static . Consequently , generation of successful ad-   versarial retweets is formulated as the following   optimization program :   minL(c∪c , c|p , f )   s.t . constraint in ( 4 ) , ( 5 )   whereLdenotes the attack loss . We adopt the cross-   entropy loss for our attack since it is untargeted   attack ( Srikant et al . , 2021 ) . Other classiﬁcation-   related loss may be applied according to adver-   sary ’s objective . Furthermore , we also add entropy-   based regularization to encourage sparsity of opti-   mization variables ( Dong et al . , 2021 ) .   A.3 Methodology   The challenge of solving program ( 5)lies in the   combinatorial and hierarchical nature . We ﬁrst re-   lax the boolean variables into continuous space so594that they can be solved by gradient - based solvers .   A common workaround for combinatorial optimiza-   tion is to solve an associated continuous optimiza-   tion over convex hull ( Dong et al . , 2021 ; Srikant   et al . , 2021 ) . An computationally efﬁcient fashion   is to optimize over a convex hull constructed with   linear combination of candidate set , and the optimal   replacement goes with word with highest weight   ( Dong et al . , 2021 ) . However , this approach does n’t   ﬁt in the hierarchical tweet and word selection prob-   lem . For example , in order to select the optimal   target word , one need to sum over the embedding   of all words in the tweet , so the tweet collapses into   embedding for one hypothetical word . Similarly ,   different tweets collapse to one hypothetical tweet ,   or one hypothetical word when one jointly selects   tweets and words .   Joint optimization solver ( JO ) . As a remedy ,   we propose a joint optimization solver that com-   bines projected gradient descent and convex hull to   jointly optimize m , zandu . Replacement selec-   tion is optimized over the convex hull :   c= ( 1−m·z)·c+m·z·conv(u , S(c ) ) ,   where   conv(u , S(c ) ) = { /summationdisplayˆuS(w),∀i , j } ,   and   ˆu = exp(u)/summationtextexp(u ) .   The problem of ( 5)is then solved by optimizing   ˆu . Unlike u , mandzare optimized directly via   projected gradient descent ( PGD ) . Moreover , when   mis one - hot vector , it determines the tweets to be   retweeted , and those retweets are then added into   tweet collection . However , mis continuous during   optimization , so we retweet all the collected tweets   and add them into tweet collection , which helps   generate and back - propagate gradients for all the   entries of m. After the optimization is solved , we   map the continuous solution into one - hot vector by   selecting top bhighest m.   Alternating greedy optimization solver ( AGO ) .   Greedy optimization is usually computational inef-   fective since a vast amount of inquiries is required   when we collect large amount of tweets and have   high attack budget . To mitigate the problem , we   alternate the optimization over m , zandu . Theaforementioned convex hull approach is adopted   for ﬁnding optimal u. The difference lies on the   path to solve tweet and word selection problems .   More speciﬁcally , we alternatively search the op-   timal target tweets and words which achieve the   highest increases in prediction loss . For tweet se-   lection , we mimic the physical attack scenario , and   new retweets are added into tweet collection during   the greedy search . Depending on the adversary ’s   objective , different metrics may be used to mea-   sure the importance of each tweet and word . For   example , Alzantot et al . ( 2018 ) use predicting prob-   ability to determine the selection of words ; Ren   et al . ( 2019 ) propose probability weighted word   saliency as criterion for word selection ; Jin et al .   ( 2020 ) calculate the prediction change before and   after deletion as word importance .   B Experimental Settings   B.1 Dataset   We evaluate our adversarial attack on a stock predic-   tion dataset ( Xu and Cohen , 2018 ) . The dataset con-   tains both tweets and historical prices ( e.g. , open ,   close , high , etc ) for 88 stocks of 9 industries : Ba-   sic Materials , Consumer Goods , Healthcare , Ser-   vices , Utilities , Conglomerates , Financial , Indus-   trial Goods and Technology . Since we consider the   task of binary classiﬁcation , data instances are sup-   posed to labelled positive and negative for upward   and downward movement respectively .   Moreover , it is observed that the dataset contains   a number of instances with exceptionally minor   price movements . In practice , minor movement   is hard to be monetized due to the existence of   transaction cost . Therefore , an upper threshold of   0.55 % and a lower threshold of -0.5 % are intro-   duced . Speciﬁcally , stocks going up more than   0.55 % in a day are labeled as positive , those go-   ing down more than -0.5 % are labeled as negative ,   and the minor moves in between are ﬁltered out .   As argued in ( Xu and Cohen , 2018 ) , the particular   thresholds are carefully selected to balance the two   classes .   In addition , the sampling period spans from   01/01/2014 to 01/01/2016 . We split the dataset into   train and test set on a rolling basis . This special pro-   gram improves the similarity between distributions   of train set and test set , which is widely adopted on   temporal dataset . It leaves us 9416 train instances   and 1408 test instances in 7 nonconsecutive pe-   riods . For the text domain , the dataset contains59557533 tweets in total .   B.2 Victim Models   Stocknet . A variational Autoencoder ( V AE ) that   takes both tweets and price as input ( Xu and Cohen ,   2018 ) . Tweets are encoded in hierarchical manner   within days , and then modeled sequentially along   with price features . It consists of three main com-   ponents in bottom - up fashion . Market Information   Encoder ﬁrst encodes tweets and prices to a latent   representation of 50 dimensions for each day . Vari-   ational Movement Decoder infers latent vectors   of 150 dimensions and then decodes stock move-   ments . At last , a module called Attentive Temporal   Auxiliary integrates temporal loss through an atten-   tion mechanism . We train the model on the dataset   from scratch with the same conﬁgurations as Xu   and Cohen ( 2018 ) .   FinGRU . A binary classiﬁer that takes numerical   features and tweets as input . All features are en-   coded sequentially by GRU ( Cho et al . , 2014 ) to ex-   ploit the temporal dependence . The model adopts   the same Market Information Encoder as Stock-   net . Latent representation of tweets and prices are   then fed into a layer of GRU with attention mech-   anism to integrate temporal information . We train   the model with an Adam optimizer ( Kingma and   Ba , 2015 ) and learning rate of 0.005 . The check-   point achieves the best performance on test dataset   among 100 epochs is adopted as the victim model .   FinLSTM . A binary classiﬁer identical to Fin-   GRU , but utilizes LSTM ( Hochreiter and Schmid-   huber , 1997 ) to encode temporal dependence . The   model is trained in the same manner as FinGRU .   B.3 Evaluation Metrics   Following Srikant et al . ( 2021 ) , we evaulate the   attack on those examples in the test set that are cor-   rectly classiﬁed by the target models . It provides   direct evidence of the adversarial effect of the in-   put perturbation and the model robustness . In the   speciﬁc application of ﬁnancial forecast , it makes   more sense to manipulate correct prediction than   incorrect ones . The following two common metrics   are adopted to evaluate attack performance .   Attack Success Rate . ASR is deﬁned as the per-   centage of the attack efforts that make the vic-   tim model misclassify the instances that are origi-   nally correctly classiﬁed . Mathematically , ASR = , where ˆyis the unperturbed model pre-   diction , ˆythe model prediction with perturbation ,   andythe ground - truth label . ASR characterizes   the capability of the attack model , and higher the   ASR , the better the attack .   F1 Score . F1 gauges the prediction performance   of the victim models . Since we only consider the   samples that are correctly predicted , the F1 score in   the case of no attack is 1 . Apparently , the drop of   the F1 score of caused by the perturbation demon-   strates the performance of the attack method . Un-   like ASR , the drops of F1 score gauge the direct   impact on the model performance : more successful   attack leads to lower post - attack F1 score .   Proﬁt and Loss . This widely - used ﬁnancial indi-   cator measures the proﬁtability of a trading strategy .   Assume that the initial net values are $ 10 K ( 100 % ) ,   accumulate proﬁt and loss for each trade , we can   then calculate the ﬁnal net value of the portfolio   andproﬁt and loss . A binary ﬁnancial forecast   model can be exploited in many ways , and sup-   port various trading strategies , which usually lead   to different PnLs . In this paper , we use a sim-   pleLong - Only Buy - Hold - Sell strategy ( Sawhney   et al . , 2021 ; Feng et al . , 2019 ) . More speciﬁcally ,   webuystock(s ) on Day Tif the model predicts   these stocks go up on Day T+ 1,hold for one day ,   andsellthese stocks the next day no matter what   prices will be , and repeat it . We do not short a   stock even if the model predicts a negative move in   the second day .   Besides , when the model makes positive predic-   tion on more than one stocks , the money is evenly   invested to the stock pool of positive prediction .   For example , suppose that we stand on day 4 with   portfolio value $ 12K. If the model gives positive   prediction on 10 of 88 stocks for day 5 , we invest   10 % of the total wealth ( $ 1.2 K ) to each stock , and   sell them at closing prices of day 5 . The process   continues until the end of the test periods , and the   resulting net value of the portfolio is used to calcu-   late the proﬁt and loss of the underlying model .   The buy - hold - sell strategy monetizes the pre-   diction performance of ﬁnancial forecast models   by betting on the their predictions . The PnL re-   ﬂects the proﬁtability of the underlying models ,   even if it is usually inﬂuenced by many other con-   founding factors . Most importantly , the changes of   PnLs caused by perturbation on the victim models   only gauge the monetary consequence of our attack,596ModelASR(% ) F1   NA RA JO AGO NA RA JO AGO   Stocknet 0 3.6 12.1 11.0 1 0.97 0.89 0.89   FinGRU 0 4.0 10.2 10.6 1 0.96 0.85 0.91   FinLSTM 0 11.9 12.1 11.6 1 0.89 0.89 0.89   since all else are equal .   C Supplemental Experiment Results   C.1 Replacement vs deletion perturbation .   We report results for concatenation attack with only   thereplacement perturbation in the main text in   Table 1 . Here we also report results for the dele-   tion perturbation in Table 2 . Attacks conducted   via deletion perturbation in general perform worse   than the results of replacement perturbation . We   observe ASRs via JO and AGO fall by 5.1 % and   4.1 % respectively compared with the replacement   perturbation . Accordingly , F1 slightly increases as   attack performance worsens . There is no signiﬁ-   ca nt difference between the two optimizers ( JO and   AGO ) in the case of deletion perturbation , but JO   is preferable in terms of optimization efﬁciency .   Moreover , we also simulate the trading proﬁt and   loss based on FinGRU and FinLSTM . For the sake   of consistency , the two models are under concate-   nation attack with replacement perturbation . Same   as our main results , the attack is optimized by JO   solver . The simulation results are reported in Figure   5 , which provides further evidence for the potential   monetary loss caused by our adversarial attack . Re-   placement perturbation again outperforms deletion   perturbation in the case of FinGRU and FinLSTM.C.2 Effect of Iteration Number   We experiment with the optimizer to perform gra-   dient descent or greedy search for up to 10 rounds   before yielding the ﬁnal solution . To visualize the   effect of iteration , we plot the loss trajectory and   ASR along with the optimization iterations in Fig-   ure 6 . We also collect the average model loss of   attack instances at each iteration , and then normal-   ize the loss to set the initial loss as 1 . Therefore ,   the loss trajectory visualization reveals the percent-   age loss drop during the optimization . We consider   two different perturbations ( replacement and dele-   tion ) under concatenation attacks . The attack is   optimized with the JO solver .   The three charts on the ﬁrst row of Figure 6   show that optimizations on all three victim models   quickly converge after 4 iterations in our experi-   ment . Accordingly , ASRs rise gradually during the   ﬁrst 4 iterations , but then ﬂattens or even slides   afterward . Such results suggest that our solvers can   ﬁnd the convergence in just a few iterations . There-   fore , it makes our attack computationally effective ,   and insensitive to hyperparameter of iteration num-   ber .   D Regularization on Attack Loss .   The experiment results reported in the main text   are generated with the sparsity regularization . We597   also run ablation experiments that remove sparsity   regularization . The results are consistent with our   conclusion . Furthermore , inspired by ( Srikant et al . ,   2021 ) , we try smoothing attack loss to stabilize the   optimization . We add Gaussian noise to optimiza-   tion variables and evaluate the attack 10 times . The   loss average is then used as the ﬁnal loss for back-   propagation . The results show that loss smoothing   does not contribute to attack performance in our   experiment as it does in Srikant et al . ( 2021 ) .   E Attack Word Analysis   To qualitatively understand what kinds of words   and tweets are being selected in the perturbation   and retweet , we compare our tweet corpus and   the selected word replacements with 15 corpora of   different genres in Brown corpus via Linguistic In-   quiry and Word Count program ( LIWC ) ( Tausczik   and Pennebaker , 2010 ) . As Brown corpus does   not have a ﬁnancial genre , we also use Financial   Phrase Bank ( Malo et al . , 2014 ) . We then run K-   means clustering on these 18 corpora based on the   feature matrix from LIWC . As shown in Figure 7 ,   ﬁnancial corpora ( red ) , Brown general word corpus   ( green ) , and attack words ( blue ) are grouped into   three clusters , indicating the inherent difference of   those text genres . Moreover , we observe that target   words identiﬁed by our solvers ( red “ tweet ” and   blue “ attack words ” dots ) are closer to ﬁnancial   corpora than “ random attack words ” .   F Example of Adversarial Retweet   Table 3 reports 10 adversarial retweets generated in   concatenation attack mode with JO and AGO solver   and replacement perturbation . For all the examples ,   the victim model predicts positive outcomes orig-   inally , and but predicts negative outcomes after   adding the adversarial retweet.598Adversarial Retweets Generated by AGO   Benign tweet : $ BHP announces the demerger of its non - core assets - details expected to be   ﬁlled in on Tuesday .   Adversarial retweet : $ BHP announces the demerger of its non - core assets - details expected   to be exercised in on Tuesday   Benign tweet : Mover and Shakers ... Losers- $ KO $ ABX $ DD . Winners- $ LAND $ CHL   $ BHP .   Adversarial retweet : Shoulder and Shakers ... Losers- $ KO $ ABX $ DD . Winners- $ LAND   $ CHL $ BHP .   Benign tweet : Latest information on # stocks like $ TDS $ DIS $ CPWR $ BLOX Give it a try .   Adversarial retweet : Latest advance on # stocks like $ TDS $ DIS $ CPWR $ BLOX Give it a   try .   Benign tweet : Top Buy Stocks for July 29 : $ AMX , $ EXC , $ NLY , $ ORCL , $ XRX .   Adversarial retweet : Top unsettled Stocks for July 29 : $ AMX , $ EXC , $ NLY , $ ORCL , $ XRX .   Benign tweet : $ JKHY # Stocks you might want to buy $ HRS $ SRCL $ PCLN # singedinvestor .   Adversarial retweet : $ JKHY # Stocks you might conﬁrm to buy $ HRS $ SRCL $ PCLN   # singedinvestor .   Adversarial Retweets Generated by JO   Benign tweet : # Stocks you migh want to Sell $ CERN $ CAT $ PX $ DO Try this http://t.co/   95PUim108L.   Adversarial retweet : # Stocks you migh announce to Sell $ CERN $ CAT $ PX $ DO Try this   http://t.co/95PUim108L.   Benign tweet : The Most Accurate Stock Alert Service Made $ 240,000 Yesterday http://t.co/   8WvnrVmkBS .. $ SNY $ SO $ SOL .   Adversarial retweet : The Most Accurate Stock preserving Service Made $ 240,000 Yesterday   http://t.co/8WvnrVmkBS .. $ SNY $ SO $ SOL .   Benign tweet : Is it breakout time on $ HON $ CF $ LEG $ IBM Give it a try .   Adversarial retweet : Is it appealing time on $ HON $ CF $ LEG $ IBM Give it a try .   Benign tweet : Latest information on # stocks like $ PETM $ UTX $ BRCD $ CI # moneymanage-   ment .   Adversarial retweet : Latest discovery on # stocks like $ PETM $ UTX $ BRCD $ CI # money-   management .   Benign tweet : $ BABA actually showing signs of life ... would love a move back toward 90   although seems unlikely at moment .   Adversarial retweet : $ BABA actually showing signs of life ... would love a move back toward   90 although seems unlikely at playday.599