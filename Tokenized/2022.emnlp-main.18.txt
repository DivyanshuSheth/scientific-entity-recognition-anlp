  Hao LangYinhe ZhengJian Sun Fei Huang Luo Si Yongbin Li   Alibaba Group   { hao.lang , jian.sun , f.huang , luo.si,shuide.lyb}@alibaba-inc.com ,   zhengyinhe1@163.com   Abstract   Out - of - Domain ( OOD ) intent detection is im-   portant for practical dialog systems . To allevi-   ate the issue of lacking OOD training samples ,   some works propose synthesizing pseudo OOD   samples and directly assigning one - hot OOD   labels to these pseudo samples . However , these   one - hot labels introduce noises to the train-   ing process because some “ hard ” pseudo OOD   samples may coincide with In - Domain ( IND )   intents . In this paper , we propose an adaptive   soft pse udolabeling ( ASoul ) method that can   estimate soft labels for pseudo OOD samples   when training OOD detectors . Semantic con-   nections between pseudo OOD samples and   IND intents are captured using an embedding   graph . A co - training framework is further intro-   duced to produce resulting soft labels following   thesmoothness assumption , i.e. , close samples   are likely to have similar labels . Extensive ex-   periments on three benchmark datasets show   that ASoul consistently improves the OOD de-   tection performance and outperforms various   competitive baselines .   1 Introduction   Intent detection is essential for dialogue systems ,   and current methods usually achieve high perfor-   mance under the closed - world assumption ( Shu   et al . , 2017 ) , i.e. , data distributions are static , and   only a fixed set of intents are considered . However ,   such an assumption may not be valid in practice ,   where we usually confront an open - world ( Fei and   Liu , 2016 ) , i.e. , unknown intents that are not trained   may emerge . It is necessary to equip dialogue sys-   tems with Out - of - Domain ( OOD ) detection abil-   ities so that they can accurately classify known   In - Domain ( IND ) intents while rejecting unknown   OOD intents ( Yan et al . , 2020a ; Shen et al . , 2021 ) .   A major challenge for OOD detection is the lack   of OOD samples ( Xu et al . , 2020a ) . In most appli - Figure 1 : A pseudo OOD sample generated by distort-   ing IND inputs ( See more examples in Appendix A ) .   Comparing to the one - hot OOD label , the soft label pro-   duced by ASoul is more suitable for this pseudo OOD   sample since it carries some IND intents .   cations , it is hard , if not impossible , to collect OOD   samples from the test distribution before training   ( Du et al . , 2021 ) . To tackle this issue , various stud-   ies try to synthesize pseudo OOD samples in the   training process . Existing methods include dis-   torting IND samples ( Choi et al . , 2021 ; Shu et al . ,   2021 ; Ouyang et al . , 2021 ) , using generative mod-   els ( Ryu et al . , 2018 ; Zheng et al . , 2020a ) , or even   mixing - up IND features ( Zhou et al . , 2021a ; Zhan   et al . , 2021 ) . Promising results are reported by   training a ( k+ 1)-way classifier ( kIND classes +   1 OOD class ) using these pseudo OOD samples   ( Geng et al . , 2020 ) . This classifier can classify   IND intents while detecting OOD intent since in-   puts that fall into the OOD class are regarded as   OOD inputs .   Previous studies directly assign one - hot OOD   labels to pseudo OOD samples when training the   ( k+ 1)-way classifier ( Shu et al . , 2021 ; Chen and   Yu , 2021 ) . However , this scheme brings noise to   the training process because “ hard ” pseudo OOD   samples , i.e. , OOD samples that are close to IND   distributions , may carry IND intents ( Zhan et al . ,   2021 ) ( See Figure 1 ) . Indiscriminately assigning   one - hot OOD labels ignores the semantic connec-   tions between pseudo OOD samples and IND in-   tents . Moreover , this issue becomes more severe261as most recent studies are dedicated to producing   hard pseudo OOD samples ( Zheng et al . , 2020a ;   Zhan et al . , 2021 ) since these samples are reported   to facilitate OOD detectors better ( Lee et al . , 2017 ) .   Collisions between pseudo OOD samples and IND   intents will be more common .   We argue that ideal labels for pseudo OOD sam-   ples should be soft labels that allocate non - zero   probabilities to all intents ( Hinton et al . , 2015 ;   Müller et al . , 2019 ) . Specifically , we demonstrate   in § 3.2 that pseudo OOD samples generated by   most existing approaches should be viewed as unla-   beled data since they may carry both IND and OOD   intents . Soft labels help capture the semantic con-   nections between pseudo OOD samples and IND   intents . Moreover , using soft labels also conforms   to the smoothness assumption , i.e. , samples close   to each other are likely to receive similar labels .   This assumption lays a foundation for modeling un-   labeled data in various previous works ( Luo et al . ,   2018 ; Van Engelen and Hoos , 2020 ) .   In this study , we propose an adaptive soft pse udo   labeling ( ASoul ) method that can estimate soft   labels for given pseudo OOD samples and thus   help to build better OOD detectors . Specifically ,   we first construct an embedding graph using su-   pervised contrastive learning to capture semantic   connections between pseudo OOD samples and   IND intents . Following the smoothness assump-   tion , a graph - smoothed label is produced for each   pseudo OOD sample by aggregating nearby nodes   on the graph . A co - training framework with two   separate classification heads is introduced to refine   these graph - smoothed labels . Concretely , the pre-   diction of one head is interpolated with the graph-   smoothed label to produce the soft label used to   enhance its peer head . The final OOD detector is   formulated as a ( k+1)-way classifier with adaptive   decision boundaries .   Extensive experiments on three benchmark   datasets demonstrate that ASoul can be used with a   wide range of OOD sample generation approaches   and consistently improves the OOD detection per-   formance . ASoul also helps achieve new State - of-   the - art ( SOTA ) results on benchmark datasets . Our   major contributions are summarized :   1.We propose ASoul , a method that can estimate   soft labels for given pseudo OOD samples . ASoul   conforms to the important smoothness assumption   for modeling unlabeled data by assigning similar   labels to close samples.2.We construct an embedding graph to help   capture the semantic connections between pseudo   OOD samples and IND intents . A co - training   framework is further introduced to produce the re-   sulting soft labels with the help of two separate   classification heads .   3.We conduct extensive experiments on three   benchmark datasets . The results show that ASoul   consistently improves the OOD detection perfor-   mance , and it obtains new SOTA results .   2 Related Work   OOD Detection : OOD detection problems have   been widely investigated in conventional machine   learning studies ( Geng et al . , 2020 ) . Recent neural-   based methods try to improve the OOD detection   performance by learning more robust representa-   tions on IND data ( Zhou et al . , 2021c , 2022 ; Yan   et al . , 2020b ; Zeng et al . , 2021b ) . These repre-   sentations can be used to develop density - based or   distance - based OOD detectors ( Lee et al . , 2018b ;   Podolskiy et al . , 2021 ; Liu et al . , 2020 ; Tan et al . ,   2019 ) . Some methods also propose to distinguish   OOD inputs using thresholds based methods ( Gal   and Ghahramani , 2016 ; Lakshminarayanan et al . ,   2017 ; Ren et al . , 2019 ; Gangal et al . , 2020 ; Ryu   et al . , 2017 ) , or utilizing unlabeled IND data ( Xu   et al . , 2021 ; Jin et al . , 2022 ) .   Pseudo OOD Sample Generation : Some   works try to tackle OOD detection problems by   generating pseudo OOD samples . Generally , four   categories of approaches are proposed : 1.Phrase   Distortion ( Chen and Yu , 2021 ): OOD samples are   generated by replacing phrases in IND samples ; 2 .   Feature Mixup ( Zhan et al . , 2021 ): OOD features   are directly produced by mixing up IND features   ( Zhang et al . , 2018 ) ; 3.Latent Generation ( Marek   et al . , 2021 ): OOD samples are drawn from the   low - density area of a latent space ; 4.Open - domain   Sampling ( Hendrycks et al . , 2018 ): data from other   corpora are directly used as pseudo OOD samples .   With these pseudo OOD samples , the OOD de-   tection task can be formalized into a ( k+ 1)-way   classification problem ( kis the number of IND in-   tents ) . Our method can be combined with all the   above OOD generation approaches to improve the   OOD detection performance .   Soft Labeling : Estimating soft labels for inputs   has been applied in a wide range of studies such   as knowledge distillation ( Hinton et al . , 2015 ; Gou   et al . , 2021 ; Zhang et al . , 2020 ) , confidence cal-262   ibration ( Müller et al . , 2019 ; Wang et al . , 2021 ) ,   or domain shift ( Ng et al . , 2020 ) . However , few   studies try to utilize this approach in OOD detec-   tion methods . Existing approaches only attempt   to assign dynamic weights ( Ouyang et al . , 2021 )   or soft labels to IND samples ( Cheng et al . , 2022 ) .   Our method ASoul is the first attempt to estimate   soft labels for pseudo OOD samples .   Semi - Supervised Learning : Our work is also   related to semi - supervised learning ( SSL ) since   they all attempt to utilize unlabeled data and share   the same underlying smoothness assumption ( Wang   and Zhou , 2017 ; Lee et al . , 2013 ; Li et al . , 2021 ) .   Moreover , the co - training framework in ASoul also   helps to enforce the low - density assumption ( a vari-   ant of the smoothness assumption ) ( Van Engelen   and Hoos , 2020 ; Chen et al . , 2022 ) by exploring   low - density regions between classes .   3 Background   3.1 Problem Definition   OOD intent detectors aim to classify IND intents   while detecting OOD inputs . Concretely , given k   known IND intent classes I={I } , the training   setD={(x , y)}only contains IND samples ,   i.e. ,xis an input , and y∈ I is the label of x.   The test set ¯D= { ( ¯x,¯y)}consists both IND and   OOD samples , i.e. , ¯y∈ I ∪ { I } , in which I   is a special OOD intent class . For a testing input   ¯x , an OOD detector should classify the intent of   ¯xif¯xbelongs to an IND intent or reject ¯xif¯x   belongs to the OOD intent .   3.2 Analyzing Pseudo OOD Samples   Recent works have demonstrated that “ hard ” OOD   samples , i.e. , OOD samples akin to IND distribu-   tions , are more efficient in improving the OOD   detection performance ( Lee et al . , 2018a ; Zheng   et al . , 2020a ) . Promising performances are ob-   tained using these hard samples on various bench-   marks ( Zhan et al . , 2021 ; Shu et al . , 2021 ) .   However , we notice that hard pseudo OOD sam-   ples used in previous approaches may coincide with   IND samples and carry IND intents . Besides Fig-   ure 1 , we further demonstrate this issue by visu-   alizing pseudo OOD samples produced by Zhan   et al . ( 2021 ) . Specifically , pseudo OOD samples   are synthesized using convex combinations of IND   features . Figure 2 shows the results on the Banking   dataset ( Casanueva et al . , 2020 ) when 25 % intents   are randomly selected as IND intents . It can be   seen that some pseudo OOD samples fall into the   cluster of IND intents , and thus it is improper to   assign one - hot OOD labels to these samples .   The above issue is also observed in other pseudo   OOD sample generation approaches . Specifi-   cally , we implement the phrase distortion ap-   proach proposed by Shu et al . ( 2021 ) and employ   crowd - sourced workers to annotate 1,000 gener-   ated pseudo OOD samples . Results show that up   to 39 % annotated samples carry IND intents ( see   Appendix A for more examples).2634 Method   4.1 Overview   In this study , we build the OOD intent detector   following three steps : 1 . Construct a set of pseudo   OOD samples D ; 2 . Estimate a soft label for   each sample x∈ D ; 3 . Obtain a ( k+ 1 ) -way   classifier and learn a decision boundary for each   class to build an OOD detector . A testing input xis   identified as OOD if xbelongs to the OOD intent   Iorxis out of all decision boundaries .   Before applying ASoul , we assume a set of   pseudo OOD samples Dare already generated   using existing approaches . Figure 3 shows an   overview of ASoul . Specifically , a shared utter-   ance encoder fencodes each input x∈ D∪ D   into a representation , and an embedding projection   head hconstructs an embedding graph on these   representations . A co - training framework is also   implemented using two ( k+ 1)-way classification   heads gandg , and the prediction of one head is   used to enhance soft labels of the peer head .   Note that ASoul is independent of specific meth-   ods to produce pseudo OOD samples in D. In this   study , we test various approaches to obtain D.   4.2 Embedding Graph   Embedding Space : An embedding space is main-   tained in ASoul to capture semantic of input sam-   ples . Specifically , for an input x , an encoder f   is used to convert xinto a representation vector ,   then a projection head his used to map f(x)into   an L2 normalized embedding z = h[f(x)]to   construct the embedding space . To capture better   semantic representations , a supervised contrastive   loss ( Khosla et al . , 2020 ; Gunel et al . , 2020 ) L   is optimized on labeled IND samples in D :   in which S(i)represents samples that share the   same label with xin the current batch , A(i)rep-   resents all samples in the current batch except x ,   Φmaps an input xto its corresponding embedding   ( i.e. ,Φ(x ) = h[f(x ) ] ) , and t > 0is a scalar that   controls the separation of classes . Lcaptures   the similarities between examples in the same class   and contrast them with the examples from different   classes ( Gunel et al . , 2020 ) .   Graph - Smoothed Label : After obtaining the em-   bedding space , we construct a fully connectedunidirectional embedding graph Gusing samples   inD = D∪ D. Specifically , we first map   each sample x∈ Dinto an embedding z , i.e. ,   z= Φ ( x ) , and then use all these embeddings as   nodes for G. Every two nodes zandzinGare   linked with an edge . Moreover , we also assign a   prior label l(x)∈Rto each sample x∈ D   to represent its annotation , i.e. , for an IND sam-   plex∈ D , l(x)is defined as the one - hot label   corresponding to y , and for a pseudo OOD sample   x∈ D , l(x)is defined as the one - hot OOD label   corresponding to I.   For each OOD sample x∈ D , a graph-   smoothed label l(x)is obtained by aggregating   adjacent nodes on G. Specifically , to conform to   the smoothness assumption , we try to minimize the   following distance when determining l(x ):   where 0≤α≤1is a scalar , dis a distance func-   tion , τ > 0is a scalar temperature . The second   term in Eq . 2 enforces the smoothness assumption   by encouraging l(x)to have similar labels with   its nearby samples , whereas the first term tries to   maintain l(x)to meet its original annotation l(x ) .   For simplicity , we implement das the Euclidean   distance here , and thus minimizing Eq . 2 yields :   Note that the result we derived in Eq . 3 fol-   lows most previous graph - smoothing approaches in   semi - supervised learning ( Van Engelen and Hoos ,   2020 ) . To the best of our knowledge , we are the   first to apply this scheme to OOD detection tasks .   4.3 Co - Training Framework   To further enforce the smoothness assumption , a   co - training framework is introduced in ASoul to   learn better soft labels using l(x ) . Specifically , we   implement two classification heads gandgon top   of the shared encoder f. Each classification head   gmaps the output of fto a ( k+ 1 ) dimensional   distribution , i.e , g[f(x)]∈R(i= 1,2 ) , and a   classification loss is optimized on IND samples:264 in which CEmeasures the cross - entropy between   two distributions .   Besides optimizing L , a co - training process   is implemented to refine l(x)for each x∈ D.   Specifically , a soft label l(x)(orl(x ) ) is pro-   duced by interpolating l(x)with the prediction of   one classification head g(org ) , and the resulting   soft label is used to optimize another head g(or   g ) . Concretely , the following co - training loss is   optimized :   where 0≤β≤1is a weight scalar . Different   dropout masks are used in gandgto prompt the   diversity required by co - training . Note that as indi-   cated by Lee et al . ( 2013 ) and Chen et al . ( 2022 ) ,   the co - training loss L favors low density sepa-   ration between classes , and thus it helps to enforce   the low - density assumption when training g.   The overall training loss for our method is :   L = L+L+L ( 6 )   4.4 OOD Detection   In the inference phase , we directly use the averaged   prediction of gandgto implement the OOD   detector g(y|x)∈R.   Moreover , an adaptive decision boundary ( ADB ) is   learnt on top of g(y|x)to further reduce the open   space risk ( Zhou et al . , 2022 ; Shu et al . , 2021 ) .   Specifically , we follow the approach of Zhang et al .   ( 2021 ) to obtain a central vector cand a decision   boundary scalar bfor each intent class I∈ I ∪   { I } . In the testing phase , the label yfor each   input xis obtained as :   y=/braceleftigg   In this way , we can classify IND intents while re-   jecting OOD intent .   5 Experiments   5.1 Datasets   Following most previous works ( Zhang et al . , 2021 ;   Shu et al . , 2021 ) , we use three benchmark datasets :   CLINC150 ( Larson et al . , 2019 ) contains 150 IND   intents and one OOD intent . We follow Zhan et al .   ( 2021 ) to group all samples from the OOD intent   into the test set ; StackOverflow ( Xu et al . , 2015 )   contains 20 classes with 1,000 samples in each   class ; Banking ( Casanueva et al . , 2020 ) contains   77 intents in the banking domain . Standard splits   of above datasets is followed ( See Table 1 ) .   5.2 Implementation Details   Our encoder fis implemented using BERT ( De-   vlin et al . , 2018 ) with a mean - pooling layer . The   projection head h , classification heads g1and   gare implemented as two - layer MLPs with the   LeakyReLU activation ( Xu et al . , 2020b ) . The op-   timizer AdamW and Adam ( Kingma and Ba , 2014 )   is used to finetune BERT and all the heads with a   learning rate of 1e-5 and 1e-4 , respectively . We use   τ= 0.1,α= 0.11andβ= 0.9 in all experiments .   All results reported in our paper are averages of 10   runs with different random seeds . See Appendix B   for more implementation details . Note that ASoul   only introduces little computational overhead com-   pared to the vanilla BERT model ( See Appendix   D. ) , and we detail how to choose important hyper-   parameters for ASoul in Appendix E.   5.3 Experiment Setups and Baselines   Following ( Zhang et al . , 2021 ; Zhan et al . , 2021 ;   Shu et al . , 2021 ) , we randomly sample 25 % , 50 % ,   and 75 % intents as the IND intents and regard all re-   maining intents as one OOD intent I. Note that   in the training and validation process , we only use   samples from the IND intents . Hyper - parameters   are searched based on IND intent classification per-   formances on validation sets .   To validate our claim that ASoul is independent   of specific methods to produce D. We tested the   performance of ASoul with four pseudo OOD sam-   ple generation approaches : 1 . Phrase Distortion   ( PD ): follows Shu et al . ( 2021 ) to generates OOD   samples by distorting IND samples ; 2 . Feature   Mixup ( FM ): follows Zhan et al . ( 2021 ) to pro-   duce OOD features using convex combinations of265   IND features ; 3 . Latent Generation ( LG ): follows   Zheng et al . ( 2020a ) to decode pseudo OOD sam-   ples from a latent space ; 4 . Open - domain Sampling   ( OS ): follows Zhan et al . ( 2021 ) to use sentences   from other corpora as OOD samples . Each ap-   proach mentioned above associates with one of the   four categories listed in § 2 .   Moreover , we also applied the above pseudo   OOD sample generation approaches with the previ-   ous SOTA method that uses one - hot labeled pseudo   OOD samples ( Shu et al . , 2021 ) . Specifically , a   ( k+ 1)-way classifier is trained by optimizing the   cross - entropy loss on D∪Dusing one - hot labels ,   and the ADB approach presented in § 4.4 is used to   construct the OOD detector .   We also compared our method to other competi-   tive OOD detection baselines : MSP : ( Hendrycks   and Gimpel , 2017 ) utilizes the maximum Softmax   probability of a k - way classifier to detect OOD in-   puts ; DOC : ( Shu et al . , 2017 ) employs k1 - vs - rest   Sigmoid classifiers and use the maximum predic-   tions to detect OOD intents ; OpenMax : ( Bendale   and Boult , 2016 ) fits a Weibull distribution to the   logits and re - calibrates the confidences with anOpen - Max Layer ; LMCL : ( Lin and Xu , 2019 ) in-   troduces a large margin cosine loss to maximize the   decision margin and uses LOF as the OOD detec-   tor;ADB : ( Zhang et al . , 2021 ) learns an adaptive   decision boundaries for OOD detection ; Outlier :   ( Zhan et al . , 2021 ) mixes convex interpolated out-   liers and open - domain outliers to train a ( k+1)-way   classifier ; SCL : ( Zeng et al . , 2021a ) uses a super-   vised contrastive learning loss to separate IND and   OOD features ; GOT : ( Ouyang et al . , 2021 ) shapes   an energy gap between IND and OOD samples .   ODIST : ( Shu et al . , 2021 ) generates pseudo OOD   samples with using a pre - trained language model .   For fair comparisons , all baselines are imple-   mented with codes released by their authors , and   use BERT as the backbone . For threshold - based   baselines , 100 OOD samples are used in the vali-   dation to determine the thresholds used for testing .   See Appendix C for more details about baselines .   5.4 Metrics   Following Zhang et al . ( 2021 ) ; Zhan et al . ( 2021 ) ;   Shu et al . ( 2021 ) , we use overall accuracy ( Acc-   All ) and macro F1 - score ( F1 - All ) calculated over266   all intents ( IND and OOD intents ) to evaluate the   OOD detection performance . We also calculate   macro F1 - scores over IND intents ( F1 - IND ) and   OOD intent ( F1 - OOD ) to evaluate fine - grained   performances .   5.5 Results   Table 2 shows the OOD detection performance as-   sociated with different pseudo OOD sample gener-   ation approaches . Specifically , results marked with   “ ASoul ” measures the performance of our method ,   while results marked with “ Onehot ” correspond   to the performance of the previous SOTA method   ( Shu et al . , 2021 ) that uses one - hot labeled samples .   We can observe that : 1.ASoul consistently out-   performs its one - hot labeled counterpart with large   margins . This validates our claim that ASoul can   be used to improve the OOD detection performance   with different pseudo OOD sample generation ap-   proaches ; 2.“hard ” pseudo OOD samples yield   byFMlead to sub - optimal performance when as - signed with one - hot labels ( i.e. , FM+Onehot gener-   ally under - performs PD+Onehot ) , while it achieves   the best performance when combined with ASoul .   This demonstrates that assigning one - hot labels to   hard pseudo OOD samples introduces noise to the   training process and ASoul helps to alleviate these   noises . 3.Although OOD samples yielded by the   open - domain sampling approach are usually dis-   joint from the training task , they still benefit from   ASoul . We suppose this is because the soft labels   produced by ASoul prevent the OOD detector from   becoming over - confident , which is important to   improve the OOD detection performance .   Table 3 shows the performance of all baselines   and our best method FM+ASoul . It can be seen   that FM+ASoul significantly outperforms all base-   lines and achieve SOTA results on all three datasets .   This validates the effectiveness of ASoul in improv-   ing the OOD detection performance . We can also   observe large improvements of ASoul when labeled   IND datasets are small ( i.e. , in 25 % and 50 % set-267tings ) . This demonstrates the potential of ASoul   to be applied in practical scenarios , particularly in   the early phases of the development that we usually   need to handle a large number of OOD inputs with   limited IND intents ( Zhan et al . , 2021 ) .   5.6 Ablation Study   Ablation studies were performed to verify the effect   of each component in ASoul : We tested following   variants : 1 . ASoul - CT removes the co - training   framework , i.e. , only one classification head gis   implemented without the co - training process . In   this variant , the loss shown in Eq.6 is optimized by   moving gand setting β= 1 in Eq.5 . 2 . ASoul-   GSremoves the graph - smoothed labels , i.e. , the   embedding graph is not constructed . In this variant ,   losses shown in Eq.4 and 5 are optimized and l(x )   in Eq.5 is replaced with the one - hot prior label   l(x ) . 3 . USoul employs uniformly distributed   soft labels for samples in D. In this variant , the   soft label l(x)in Eq.5 is obtained by uniformly   reallocating a small portion of OOD probability to   OOD intents . 4 . KnowD implements a knowledge   distillation process to obtain soft labels , i.e. , a k-   way IND intent classifier is first trained on Dand   its predictions are interpolated with the one - hot   OOD label to obtain the soft label l(x)in Eq.5 .   All above variants are tested with two ap-   proaches to produce D : PD and FM . Results in   Table 4 indicate that our method outperforms all   ablation models . We can further observe that : 1 .   soft - labels obtained using other approaches degen-   erate the model performance by a large margin .   This shows the effectiveness of the soft labels pro-   duced by ASoul . 2.graph - smoothed labels bring   the largest improvement compared to other compo-   nents . This further proves the importance of mod-   eling semantic connections between OOD samples   and IND intents .   5.7 Feature Visualization   To further demonstrate the effectiveness of ASoul ,   we visualized the features learnt in the penulti-   mate layer of OOD detectors that are trained us-   ing one - hot labels or soft labels . We use the best   performing pseudo OOD samples generation ap-   proach ( i.e. , FM ) in this analysis . Results shown   in Figure 4 demonstrate that soft labels produced   by ASoul help the OOD detector learn better repre-   sentations compared to one - hot labels . The learnt   feature space is smoother and representations for   IND and OOD samples are more separable . This   validates our claim that ASoul helps to conform to   the smoothness assumption and improves the OOD   detection performance .   6 Conclusion   In this paper , we first analyze the limitation of ex-   isting OOD detection approaches that use one - hot   labeled pseudo OOD samples . Then we propose   a method ASoul that can estimate soft labels for   given pseudo OOD samples and use these soft la-   bels to train better OOD detectors . An embedding   space is constructed to produce graph - smoothed   labels to capture the semantic connections between   OOD samples and IND intents . A co - training   framework further refines these graph - smoothed la-   bels . Experiments demonstrate that our method can   be combined with different pseudo OOD sample   generation approaches , and it helps achieve SOTA   results on three benchmark datasets . In the future ,   we plan to apply our method in other tasks , such as   Text - to - SQL parsers ( Hui et al . , 2021 ; Wang et al . ,   2022 ; Qin et al . , 2022 ) or lifelong learning ( Dai   et al . , 2022 ) .   Limitations   We identify the major limitation of this work is   its input modality . Specifically , our method is lim-   ited to textual inputs and ignores inputs in other   modalities such as vision , audio , or robotic features .   These modalities provide valuable information that   can be used to better OOD detectors . Fortunately ,   with the help of multi - modal pre - training models   ( Radford et al . , 2021 ; Zheng et al . , 2022 ) , we can   obtain robust features well aligned across differ-   ent modalities . In future works , we will try to   model multi - modal contexts for OOD detection   and explore better pseudo OOD sample generation   approaches.268   Another limitation of this work is the pre-   training model used in experiments : a model pre-   trained on dialogue corpora is expected to yield bet-   ter performance ( He et al . , 2022c , a , b ; Zhou et al . ,   2021b ; Wang et al . , 2020 ; Zheng et al . , 2020b ) .   Moreover , it is reported that better OOD detection   performance can be obtained if we can extract more   robust features for IND tasks ( Vaze et al . , 2021 ) .   Our method can be readily applied to other feature   extractors that are better performed on dialogues .   Ethics Statement   This work does not present any direct ethical issues .   In the proposed work , we seek to develop a general   method for OOD intent detection , and we believe   this study leads to intellectual merits that benefit   from a reliable application of NLU models . All   experiments are conducted on open datasets .   References269270271272   A More Examples of Pseudo OOD   Samples   This appendix shows more pseudo OOD samples   that are generated using existing approaches .   Besides Figure 2 , we also visualize pseudo OOD   samples produced by Zhan et al . ( 2021 ) on the   CLINC150 ( Larson et al . , 2019 ) dataset ( Figure   5 ) and the StackOverflow ( Xu et al . , 2015 ) dataset   ( Figure 6 ) , when 25 % intents are randomly selected   as IND intents . Specifically , Zhan et al . ( 2021 ) pro-   poses to generate features of pseudo OOD samples   by mixing up IND features . Pseudo OOD samples   we demonstrate in this analysis are obtained using   the code released by Zhan et al . ( 2021 ) . As shown   in Figure 5 and 6 , some pseudo OOD samples fall   into the cluster of IND intents , and thus we argue it   is improper to assign one - hot OOD labels to these   samples .   Furthermore , we demonstrate more cases of   pseudo OOD samples generated by the method   proposed by Shu et al . ( 2021 ) on the CLINC150   ( Table 5 ) , StackOverflow ( Table 6 ) , and Banking   ( Table 7 ) datasets . Specifically , these pseudo OOD   samples are generated by replacing phrases in IND   samples and use a pre - trained language model to   filter these samples . As shown in Table 5 , 6 , and 7 ,   some of the generated pseudo OOD samples carry   IND intents since the replaced phrase may be an   synonyms of the original phrase .   B More Implementation Details   We use the BERT model ( bert - base - uncased ) pro-   vided in the Huggingface ’s Transformers library   ( Wolf et al . , 2020 ) to implement f. Following   ( Zhang et al . , 2021 ) , we add an averaging - pooling   layer on top of BERT to obtain the representation   of each input utterance . The projection head h ,   classification heads g1andgare implemented as   a two - layer MLP with the LeakyReLU activation   ( Xu et al . , 2020b ) , where the feature dimension is   1024 and the projection dimension is 128 . Follow-   ing ( Zhan et al . , 2021 ) , We use AdamW ( Kingma   and Ba , 2014 ) to fine - tune BERT using a learning   rate of 1e-5 and Adam ( Wolf et al . , 2019 ) to train   the MLP heads using a learning rate of 1e-4 with   early stopping . When learning the adaptive deci-   sion boundaries ( Zhang et al . , 2021 ) , the trained   model is fixed and we used a learning rate of 0.05 .   We tried batch size of { 100 , 200 } for IND samples   and { 100 , 500 , 600 , 800 } for OOD samples . All   hyper - parameters are tuned according to the classi-   fication performance over the IND samples on the   validation set . We find that t = τ= 0.1,α= 0.11   andβ= 0.9work well with all datasets . We use   a dropout rate 0.6 for the two classification heads .   Each result is an average of 10 runs with differ-   ent random seeds , and each run is stopped when   we reach a plateau on the validation loss . ALL273274   experiments were conducted in the Nvidia Tesla   V100 - SXM2 GPU with 32 G graphical memory .   Our model contains 112.06 M model parameters .   C More Details about Baselines   Baseline results ( MSP , DOC , OpenMax , LMCL ,   and ADB ) are copied from ( Zhang et al . , 2021 ) . Re-   sults of the baseline Outlier are copied from ( Zhan   et al . , 2021 ) . Results of the baseline ODIST are   copied from ( Shu et al . , 2021 ) . For above men-   tioned baselines , we also re - implement their meth-   ods using their release codes . The results repro-   duced by our experiments match the results re-   ported in their original paper . So we copied the   highest reported results of these baselines from pre-   viously published papers . Significant tests between   our method and all these baselines are carried out   based on our implementations . We get the baseline   results ( SCl and GOT ) by running their released   codes , and use 100 OOD samples in the validation   to determine the thresholds for testing .   D Computational Cost Analysis   We compare the training cost of our method when   using one - hot labels or soft labels produced by   ASoul . Pseudo OOD samples used in this analysis   are generated using the best performing method   FM , and we use the CLINC150 dataset for thisanalysis . As shown in Table 8 , ASoul only intro-   duces marginal parameter overhead for the pro-   jection head and the classification head . We can   also observe that using ASoul only introduces little   time overhead compared to the one - hot labeling   approach .   E Effect of Hyper - parameters   We analyzed the most important hyper - parameters   of ASoul : temperature τin graph - based smooth-   ing and dropout rate to the classification heads in   co - training . We conduct experiments to show their   effects on the CLINC150 dataset under the 25 %   setting . We use the best performing pseudo OOD   sample generation approach ( i.e. , FM ) in this anal-   ysis .   Temperature : We set τto { 0.1 , 0.5 , 1 , 5 , 10 , 15 ,   20 } respectively , and demonstrate the performance   change . Note that small τmakes distribution over275   the embedding graph more shape ( concentrating   on nearest neighbors ) , while large τforms smooth   distributions .   Results are shown in Figure 7 ( left ) . With the   increase in temperature , the OOD detection per-   formance tends to decrease . τ= 0.1achieves the   highest F1 - ALL score of 84.11 % . This suggests   that a small temperature makes ASoul focus more   on neighbors and gain better performance .   Dropout Rate : We compare the performance of   dropout rates to the classification heads by adjust-   ing the rate from 0 to 0.7 with an interval of 0.1 .   Results are shown in Figure 7 ( right ) . The per-   formance first increases and then decreases as the   dropout rate increases . In the begging phase , us-   ing a high dropout rate introduces more diversity   required by co - training , and thus the OOD de-   tection performance improves . However , using   a higher dropout rate introduces much noise to the   co - training process , and thus downgrades the OOD   detection performance .   F More Evaluation Metrics   We also calculate micro F1 - scores over all intents   ( IND and OOD intents ) for our best - performing   method FM+ASoul and one of our strongest base-   lines Outlier on the CLINC150 dataset . As shown   in Table 9 , FM+ASoul still outperforms the base-   line on the micro F1 - score.276