  Mat¯ıss Rikters , Marili Tomingas , Tuuli Tuisk , Valts Ernštreits , Mark FishelUniversity of Tartu   { matiss.rikters , tuuli.tuisk , marili.tomingas , fishel}@ut.eeUniversity of Latvia   valts.ernstreits@lu.lvUniversity of Copenhagen   Abstract   Livonian is one of the most endangered languages   in Europe with just a tiny handful of speakers and   virtually no publicly available corpora . In this pa-   per we tackle the task of developing neural machine   translation ( NMT ) between Livonian and English ,   with a two - fold aim : on one hand , preserving the   language and on the other – enabling access to   Livonian folklore , lifestories and other textual in-   tangible heritage as well as making it easier to   create further parallel corpora . We rely on Livo-   nian ’s linguistic similarity to Estonian and Latvian   and collect parallel and monolingual data for the   four languages for translation experiments . We   combine different low - resource NMT techniques   like zero - shot translation , cross - lingual transfer and   synthetic data creation to reach the highest possible   translation quality as well as to ﬁnd which base lan-   guages are empirically more helpful for transfer to   Livonian . The resulting NMT systems and the col-   lected monolingual and parallel data , including a   manually translated and veriﬁed translation bench-   mark , are publicly released via the OPUS corpora   collection and Huggingface model repository .   1 Introduction   Many state - of - the - art natural language processing   tasks have reached admirable quality on languages   with abundant linguistic resources ( Vaswani et al . ,   2017 ; Conneau et al . , 2018 ; Devlin et al . , 2019 ) .   Furthermore , some neural language models and   translation systems have been created for 100 and   more languages ( e.g. Conneau et al . , 2020 ; Fan   et al . , 2021 ) . However smaller , less or not at all   spoken languages continue to struggle not only in   terms of applicable computational approaches , but   more critically - in terms of usable resources for   training natural language processing ( NLP ) models   or even just linguistic exploration . In this paper we set the goal of developing ma-   chine translation between English and Livonian .   Currently there are just over 20 ﬂuent speakers of   the language ( Ernštreits , 2016 ) . Although some   digital linguistic resources exist for Livonian ( in-   cluding a dictionary with example sentences and   a written monolingual corpus , Ernštreits , 2016 ) ,   there is virtually no open parallel corpora between   English and Livonian , with the single exception of   35 parallel sentences in the OPUS Tatoeba corpus   ( Tiedemann , 2020 ) .   At the same time , cross - lingual transfer learning   has recently helped improve the performance of   several low - resource NLP tasks with the support   of related languages ( e.g. Conneau et al . , 2018 ; Hu   et al . , 2020 ) . This also includes zero - shot trans-   lation ( Johnson et al . , 2017 ) , the ability of mul-   tilingual NMT systems to translate between seen   languages that were not represented in the parallel   training data as a pair . The case of Livonian is es-   pecially interesting in this regard , as there are two   different sources of such support : on one hand , it is   a Uralic language , closely related to Estonian and   Finnish . On the other hand , Livonian has taken part   in forming Latvian language and Livonian speakers   have historically co - existed side - by - side with Lat-   vian speakers . As a result of mutual inﬂuence these   two languages also share a number of grammatical ,   lexical and orthographic similarities .   Our main contributions are two - fold . First ,   we collected the majority of digitally available   translation examples including Livonian into a   small parallel corpus ( just over 10000 sentence   pairs ) of mostly Livonian - Latvian and Livonian-   Estonian sentence translations with very few ( 1000 )   Livonian - English examples . In order to create a   clean benchmark for evaluating translation qual-   ity we selected a portion ( about 10 % ) of this   corpus and had it manually translated into Lat-   vian / Estonian / English so that each sentence would508Source LIV - ENG LIV - EST LIV - LAT   Dictionary examples – 10 690 / 44 854 / 44 499 10 690 / 44 854 / 44 975   Latvian constitution 686 / 11 198 / 15 499 719 / 11 454 / 10 314 719 / 11 454 / 11 002   JEFUL abstracts – 187 / 2 878 / 2 846 176 / 2 723 / 3 434   Facebook posts 231 / 2 759 / 3 656 8 / 124 / 122 232 / 2 744 / 2 738   livones.net texts 169 / 2 741 / 3 660 92 / 1 969 / 1 867 333 / 4 449 / 4 433   Stalte ABC book – 1 340 / 9 382 / 9 195 1 340 / 9 382 / 9 398   Trilium , poetry book – 222 / 3 543 / 3 321 223 / 3 512 / 3 539   Eduard Vääri book – 877 / 10 337 / 9 763 –   Total 1 086 / 16 698 / 22 815 14 135 / 84 541 / 81 927 13 713 / 79 118 / 79 519   have all four manually veriﬁed translations .   The second half of our work focuses on neural   machine translation ( NMT , Vaswani et al . , 2017 ) ,   mainly targeting Livonian $ English . We explore   several options of coping with the extremely low-   resource settings and use Estonian and Latvian for   cross - lingual transfer . Our experiments answer the   following research questions :   1.Can we achieve machine translation for   Livonian $ English at a usable level ?   2.Which base language suits better for serving   as base for cross - lingual transfer to Livonian ,   Estonian or Latvian ?   3.Does zero - shot multilingual translation de-   liver better translation quality than pivot-   translation through Estonian or Latvian ?   Next we brieﬂy describe the Livonian Language   in Section 2 , then introduce the collected paral-   lel and monolingual data in Section 3 . Section 4   provides the details of our NMT experiments and   Section 5 concludes the paper .   2 The Livonian Language   Livonian ( ISO 639 - 3 : liv ) is a Finnic language   indigenous to Latvia and belonging to the Uralic   language family . During the 12th century Livonian   was spoken across great territories in Latvia around   the Gulf of Riga . Over time , Livonian areas gradu-   ally became Latvian - speaking . In the 19th century ,   Livonian still had approximately 2500 speakers , bythe mid-20th century around 1500 speakers . Nowa-   days Livonian is listed in UNESCO ’s Atlas of the   World ’s Languages in Danger as a critically endan-   gered language ( Moseley , 2014 ) . According to the   2011 census , there are 250 Livonians in Latvia . Al-   though there are just over 20 people who can speak   the language , the Livonian community is active in   preserving and developing the Livonian heritage   ( Ernštreits , 2016 ) and language plays a key role in   this process ( Ernštreits and Klava , 2020 ) .   The Livonian language developed in the contact   area of Baltic and Finnic languages . Livonian and   Latvian share a similar geographical location over   a prolonged period of time , as a result of which   they both contain traces of contact . Next to other   loanwords , the Livonian loanword strata consists   of words borrowed from Latvian ( Suhonen , 1973 ;   Winkler , 2014 ) and vice versa . The most obvious   Latvian inﬂuence on Livonian grammar is found   in the Livonian case system ( Ernštreits and K lava ,   2014 ) . Livonian has the prosodic characteristics   typical of a Finnic language such as word - initial   stress and the phonological opposition of short and   long phoneme duration . It is the only Finnic lan-   guage that differentiates lexical tones – the plain   tone and the broken tone or stød – and therefore   shares similar characteristics with Latvian as well   as Danish ( Tuisk , 2016 ) .   3 Collected Data   The ﬁrst step in developing ( supervised ) machine   translation is collecting parallel data . While there   was no pre - existing open parallel corpus with Livo-   nian , we used all the possible sources of transla-   tions . This was limited to already digital resources ,   future work might include texts extracted by scan-   ning older books and other materials.509LV!EN ET!EN ETLV!EN EN - ET - LV Google Neurotolge   ET 30.91 28.42 24.17 34.38 29.91   LV 25.18 25.26 20.77 31.54 25.92   LIV 2.20 3.22 2.66 13.29 - -   Tuned   LIV!EN 3.19 5.59 5.39 14.69 - -   EN!LIV - - - 8.59 - -   The main sources of data included Livonian-   Latvian as well as Livonian - Estonian translations .   Thus we use these two languages as base for cross-   lingual transfer and e.g. leave Finnish out , as there   was no data for it .   The sources of data included :   •the Constitution of the Republic of Latvia ,   translated into 9 languages , including Livo-   nian , Estonian and English ,   •a database of dictionary entries , phrases and   example sentences from the University of   Latvia Livonian Institute ’s website , with ex-   ample sentences in Livonian , Estonian and   Latvian   •the Livonian Institute ’s Facebook page posts ,   partially parallel between our 4 languages   •books ( Stalte , 2011 ; Kurs and et al . , 2016 ;   Ernštreit et al . , 2020 ) with prefaces and con-   tent in Livonian - Estonian or Livonian - Latvian   •and abstracts from the Journal of Estonian and   Finno - Ugric Linguistics ’ ( JEFUL ) Special Is-   sues on Livonian Studies ( 2014 , 2016 , 2018 )   in Livonian , Estonian and English .   Concerning sentence alignment , the dictionary   examples consisted of already aligned Livonian   sentences . We aligned the rest of the data manu-   ally with the help of language experts – ﬁrst on   paragraph level , then on sentence level . The result-   ing amount of sentences in the resulting dataset is   shown in Table 1 .   We separated balanced portions of development   ( 503 sentences ) and evaluation ( 749 sentences )   splits from the full dataset . The splits are balanced   in terms of the original source of the texts to resem-   ble proportions from the remaining training data . We hired professional translators to create trans-   lations for any missing parts so that these splits   would be parallel between all four languages . We   further turned to experts of the Livonian language   to make sure that the newly created translations   truly convey the meaning of the original text as a   quality control measure . The resulting benchmark   and the whole corpus is published in the OPUS col-   lection . We also share the ﬁnal translation model   after four iterations of backtranslation .   4 Machine Translation Experiments   Having just over 10;000parallel examples consti-   tutes extremely low - resource settings for neural   machine translation . Added to this , the number   of monolingual Livonian sentences ( about 40;000 )   is also too small for approaches like unsupervised   machine translation ( Artetxe et al . , 2018 ; Lample   et al . , 2018 ) .   We implement the support of neighboring and   related languages ( Estonian and Latvian ) via multi-   lingual machine translation ( Johnson et al . , 2017 ) .   As a ﬁrst step the model is pre - trained with the   larger languages ( Estonian , Latvian , English ) and   then used as base for following experiments .   We also perform iterative back - translation ( Pin-   nis et al . , 2018 ) to make use of the large amounts of   monolingual news data in EN / ET / LV , and our lim-   ited amount of monolingual data in LIV . We trans-   late the 40k LIV sentences and different batches   of 200k sentences from the other languages into   all directions , ﬁlter the translations using simple   heuristic ﬁlters ( Rikters , 2018 ) , and use a mix of   all back - translated data with an equal amount of   random clean parallel data ( including all data in-   volving Livonian ) to ﬁne - tune the base model.510Base Tuned BT1 BT2 BT3 BT4   ET - EN 24.17 23.68 23.97 24.80 25.05 26.17   LV - EN 20.77 18.90 19.29 20.95 20.52 21.53   LIV - EN 13.29 14.69 16.19 17.41 18.15 19.01   EN - ET 17.00 16.87 18.58 19.37 18.95 19.48   LV - ET 18.38 19.55 19.72 19.93 20.68 22.38   LIV - ET 15.08 17.76 20.05 21.61 21.78 23.05   EN - LV 16.57 17.94 17.17 19.58 19.49 20.85   ET - LV 18.51 21.16 20.92 21.01 21.96 23.44   LIV - LV 15.05 17.55 21.25 22.99 23.68 25.24   EN - LIV 4.19 8.59 9.96 10.49 10.88 11.03   ET - LIV 4.01 13.00 14.43 15.24 16.09 16.49   LV - LIV 4.84 13.67 15.18 16.25 16.77 17.65   4.1 Technical Setup   We used FairSeq ( Ott et al . , 2019 ) to train trans-   former architecture models with 6 encoder and   decoder layers , 8 transformer attention heads per   layer , word embeddings and hidden layers of size   512 , dropout of 0.3 , maximum sentence length   of 128 symbols , and a batch size of 1024 words .   All models were trained until they reached con-   vergence ( no improvement for 10 checkpoints ) on   development data . We used Sentencepiece ( Kudo   and Richardson , 2018 ) to create shared vocabular-   ies of size 25,000 , and SacreBLEU(Post , 2018 )   to generate BLEU scores ( Papineni et al . , 2002 ) for   translations .   Base models were trained on LV ! EN , ET ! EN ,   ET+LV ! EN data , and a multilingual model us-   ing the tagged approach ( Johnson et al . , 2017 ) for   translating in all directions between EN / ET / LV lan-   guages . The base models were then used as ini-   tialization for tuning on Livonian - English parallel   data .   For training the base models we used all avail-   able parallel data from Opus ( Tiedemann and Ny-   gaard , 2004 ) . To facilitate further use of the base   models for tuning on Livonian data , all Livonian   sentences were used in addition to other data when   creating the shared vocabularies . Finally , we used   the highest - scoring tuned model to perform per-   formed backtranslation on the monolingual LIV   data to generate additional training data for train-   ing the ﬁnal models.4.2 Results   Table 2 shows the results of MT experiments . All   BLEU scores are calculated for translations of our   evaluation set . We compare the base single direc-   tion MT models to our multidirection model , as   well as online translations from Google Translate   and Neurotolgeto evaluate performance from ET   and LV into EN . While the multilingual model   was noticeably weaker , the others hold compara-   ble results to the online systems . However , when   attempting to perform zero - shot translation from   LIV into EN , ET ! EN outperforms LV ! EN ( 3.22   vs. 2.20 ) , and the multilingual model achieved a   very respectable BLEU score 13.29 .   We then turned to tuning each of these mod-   els with LIV - EN data mixed 1:1 with a random   equal amount of the original training data for each   of the models . In the case of the multilingual   model , we also added LV / ET - LIV data to the mix .   This improved all scores by 1 - 3 BLEU points ,   but the multilingual model remained on top with   14.69 for LIV ! EN . In order to perform back-   translation models for both directions are required ,   so we scored the tuned multilingual model on the   EN!LIV data as well , reaching 8.59 BLEU .   For comparison we also used the same tuned   multilingual model to perform pivotal translation   by ﬁrst translating into ET or LV and then into   the desired target language . In all four cases the   pivot translation quality dropped when compared   to direct translation by the same model , so we did   not further pursue this line of experiments . An511LIV - EN EN - LIV   Facebook 19.28 13.55   Livones.net 19.67 15.91   Dictionary 7.73 10.60   Trilium 19.88 14.50   Stalte 13.88 9.47   JEFUL 8.02 5.10   Satversme 24.49 7.69   interesting observation , was that pivoting through   ET achieved a higher BLEU score than LV when   translating into EN ( 13.66 vs. 11.24 ) , but slightly   lower when translating into LIV ( 7.99 vs. 8.56 ) .   Results for four rounds of BT iterations are com-   piled in Table 3 . The model clearly improves not   only in the main language pair of EN $ LIV , but in   all other translation directions as well .   To answer the research questions , posed in the   introduction , it seems that the resulting transla-   tion quality is still far from being usable . Com-   parisons between the base languages have shown   slight preference towards Estonian over Latvian .   Pivot - translation trough Estonian or Latvian un-   derperforms direct Livonian $ English translation   trained in a zero - shot / few - shot manner .   4.3 Detailed Analysis   Table 4 shows BLEU scores of the separate parts   of the evaluation corpus . Since most of the training   data for EN - LIV comes from Satversme ( Latvian   Constitution ) , it is very clear why that part scores   higher than others . The dictionary entries are over-   all far shorter in length than the other parts and   often consist of few - word phrases , making them   unfavorable to BLEU by deﬁnition .   The posts from Facebook and Livones.net are   more general in their language and therefore more   similar to data from the training set . However , the   Trilium and Stalte books are written in a more liter-   ary language , making them slightly more challeng-   ing to translate . Finally , the very domain - speciﬁc   part from JEFUL abstracts seems to be the most   difﬁcult to translate into English .   5 Conclusion   In this paper we presented a novel dataset for the   highly endangered Livonian language , which canbe useful for machine translation , language mod-   elling and many other natural language processing   and computational linguistic research tasks .   In our experiments we show how far one can   get in training modern machine translation models   with very scarce data , and which languages are   more suitable for transfer learning when working   with Livonian data . While perhaps not being usable   as - is in any kind of production scale , the achieved   ﬁnal BLEU scores of 19.01 for Livonian ! English   and 11.03 for English ! Livonian show that some   transfer of meaning can still be achieved with the   currently available resources .   In the future we are planning to experiment with   cross - lingual transfer from other languages , like   the resource - rich Finnish as well as resource - poor   Finno - Ugric languages like Võru and Sami ( Tars   et al . , 2021 ) . Given the limited amount of exist-   ing monolingual Livonian data , generating syn-   thetic Livonian data with other means besides back-   translation might be helpful : for example , forward-   translation or using GPT - like language models .   Finally , work on the already collected Livonian   monolingual and parallel data is ongoing at the   Institute of the Livonian Language . Adding En-   glish translations to the lexical items and example   sentences is an ongoing effort and will evaluate   in practice , if the MT systems created as part of   the current work can facilitate that . One of the   key focuses is also manually verifying the data and   making sure the existing corpus contains correct   Livonian texts and their translations   Acknowledgements   This work has received funding from the “ European   Social Fund via IT Academy programme , ” Esto-   nian Ministry of Education and Research ( grant   SHVEE21397 ) , the Estonian Research Council   ( grant GHVEE22112J ) , and the State Research Pro-   gramme “ Latvian Studies for the Development of   a Latvian and European Society ” project “ Mul-   tifunctional dictionary of Livonian ” ( No . VPP-   LETONIKA-2021/2 - 0002 ) .   References512513514