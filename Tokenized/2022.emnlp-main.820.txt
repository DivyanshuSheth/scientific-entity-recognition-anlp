Denis Emelin , Daniele Bonadiman , Sawsan Alqahtani , Yi Zhang , and Saab MansourUniversity of Edinburgh , denis.emelin@gmail.comAWS AI Labs , { dbonadim , yizhngn , saabm}@amazon.comPrincess Nourah Bint Abdulrahman , saalqhtani@pnu.edu.saNational Center of AI , sawalqahtani@nic.gov.sa   Abstract   Pre - trained language models ( PLM ) have ad-   vanced the state - of - the - art across NLP applica-   tions , but lack domain - specific knowledge that   does not naturally occur in pre - training data .   Previous studies augmented PLMs with sym-   bolic knowledge for different downstream NLP   tasks . However , knowledge bases ( KBs ) uti-   lized in these studies are usually large - scale and   static , in contrast to small , domain - specific , and   modifiable knowledge bases that are prominent   in real - world task - oriented dialogue ( TOD ) sys-   tems . In this paper , we showcase the advan-   tages of injecting domain - specific knowledge   prior to fine - tuning on TOD tasks . To this end ,   we utilize light - weight adapters that can be eas-   ily integrated with PLMs and serve as a repos-   itory for facts learned from different KBs . To   measure the efficacy of proposed knowledge   injection methods , we introduce Knowledge   Probing using Response Selection ( KPRS ) – a   probe designed specifically for TOD models .   Experimentson KPRS and the response gen-   eration task show improvements of knowledge   injection with adapters over strong baselines .   1 Introduction   Pre - trained language models ( PLMs ) , such as   BERT ( Devlin et al . , 2018 ) , BART ( Lewis et al . ,   2020 ) , GPT ( Brown et al . , 2020 ) , and XLNet ( Yang   et al . , 2019 ) , have advanced the state - of - the - art of   various natural language processing ( NLP ) tech-   nologies and demonstrated an exceptional ability   to store and utilize linguistic , factual , and com-   monsense knowledge . Consequently , PLMs form   the backbone of many recent NLP applications   and have been successfully employed as modu-   lar components in the context of task - oriented dia-   logue ( TOD ) , responsible for sub - tasks includingFigure 1 : A high - level representation of the KB - adapter   architecture ( decoder only , for clarity ) . Adapter states   are fused with the hidden states of the PLM to produce   a knowledge - informed predictive distribution . Dashed   elements are used only if multiple adapters are active .   dialogue state tracking and response generation   ( Hosseini - Asl et al . , 2020 ; Lee et al . , 2021 ) .   Since they are exposed to large quantities of   general data during training , PLMs store a wide   variety of diverse and general knowledge in their   parameters ( Petroni et al . , 2019 ) such as capitals of   nations , biographical details of famous individuals ,   and other facts of varying granularity . Commer-   cially deployed TOD systems , however , typically   require access to more restricted , domain - specific   categories of knowledge in order to produce in-   formative and factually accurate responses to user   queries . Such information may include addresses   of particular local attractions , detailed restaurant   menus , train routes , or ticket prices , and is unlikely   to be found in the PLM ’s training data . Due to its   specialized nature , this knowledge is often stored in   external knowledge bases ( KBs ) that are accessed   at run - time by TOD systems via external queries.11962This process introduces additional complexity   into the dialogue model design and requires imple-   menting KB queries and code wrappers as part of   system setup , causing a substantial overhead espe-   cially for non - experts . Querying external KBs can   also be disadvantageous when the KB is small , or   is not changing in real time ( as is the case with   catalogs , restaurants ’ menus , etc ) . We identify the   decoupling of domain - specific knowledge from the   dialogue model as a shortcoming to be remedied   and instead propose to inject this knowledge di-   rectly into the model ’s parameters . This eliminates   the need for querying external KBs , streamlining   the creation and deployment of TOD systems .   Injecting domain - specific information into TOD   systems that can guide and inform model behav-   ior and may be subsequently updated and modi-   fied by the user is not a trivial task . Ideally , this   should be accomplished in a manner that is effi-   cient , architecture - agnostic , and compatible with   off - the - shelf PLMs . In order to satisfy these re-   quirements , we adopt light - weight adapter net-   works as repositories of domain - specific knowl-   edge ( KB - adapters for short ) . Such adapters can   be trained to memorize KB factsand integrated   into pretrained PLMs through the fusion of hidden   representations , as illustrated in Figure 1 . Our work   is in line with past studies that demonstrated the   utility of adapters as stores of factual and linguis-   tic knowledge outside of TOD ( Wang et al . , 2020 ) .   Importantly , injecting knowledge into TOD models   through adapters is computationally less demand-   ing than injecting domain - specific facts by fine-   tuning entire dialogue models on synthetic data , as   explored in ( Madotto et al . , 2020 ) , which facilitates   efficient updating of the injected knowledge .   To quantify the success of the knowledge injec-   tion procedure , we develop the Knowledge Probing   using Response Selection ( KPRS ) task and bench-   mark ( see § 3 ) . KPRS leverages contrastive dia-   logue response pairs to probe the extent of memo-   rization of domain - specific facts by the evaluated   dialogue model , whereby one response is consis-   tent with the corresponding KB , while the other   is not . To our knowledge , both KPRS and the use   of adapters for domain - specific knowledge injec-   tion in TOD represent novel contributions of our   work . We conduct experiments that evaluate PLMs   equipped with domain - specific KB - adapters on the   KPRS benchmark as well as the more conventionalresponse generation ( RG ) task , comparing them   against strong baselines .   Our contributions can be summarized as follows :   •We define and implement adapter - based meth-   ods for injecting highly specific and retriev-   able domain knowledge into TOD models   •We design and develop the KPRS probing task   that can be used to evaluate the effectiveness   of knowledge injection for TOD systems   •We show that PLMs with KB - adapters are   usually preferable to knowledge - unaware and   sequentially - finetuned PLMs for TOD   2 KB - Adapters for Domain - Specific   Knowledge Injection   We conceptualize KB adapters as repositories of   domain - specific information that guide the PLMs ’   predictions to be consistent with KB contents . The   proposed knowledge injection process is divided   into two stages : ( 1 ) Memorization : adapters are   trained to memorize domain - specific KB facts ; ( 2 )   Utilization : PLMs are trained to leverage adapters   when reasoning about entities and their attributes .   During the memorization stage , adapters are con-   nected to the frozen PLM and tasked with recon-   structing corrupted KB facts , thereby memorizing   associations between entity and attribute mentions .   During the utilization stage , the PLM ( now un-   frozen ) is given access to frozen adapters and learns   to leverage their memorized knowledge to make   more accurate predictions on downstream tasks   such as RG . As a result , PLMs can generalize to   unseen inputs by virtue of their domain - general pre-   training while receiving domain - specific guidance   in their predictions by the knowledge encoded in   adapter representations .   When training KB - adapters , we allocate a single   adapter for each individual domain KB ( e.g. ho-   telorrestaurant ) . This results in shorter training   times per adapter and ( if needed ) facilitates effi-   cient re - training of adapters to reflect changes in   the associated KBs . This allows for a straight-   forward extension of TOD systems equipped with   KB - adapters to new domains , as this only requires   training a single , new domain - specific adapter that   can be used in concert with existing ones . Never-   theless , we also consider a setting where we train a11963   single , mixed - domain adapter on the concatenation   of all KBs in our experiments ( see § 5.5 ) .   2.1 System Overview   Unlike the vast amounts of data used to pre-   train PLMs , information stored in KBs is usu-   ally structured and does not resemble natural lan-   guage expressions . Figure 2 shows a single KB   entry ( or fact ) from the MultiWOZ 2.2 dataset   ( Budzianowski et al . , 2018 ; Ye et al . , 2021 ) . Since   KB - adapters need to be compatible with PLMs and   their internal representations , we therefore convert   KB entries prior to the memorization stage from   their initial format into declarative statements of   varying complexity ( § 2.2 ) . Each statement men-   tions exactly one entity ( e.g. a restaurant ’s name )   and one or more entity attributes ( e.g. the types of   cuisine served by a restaurant ) . Each statement is   subsequently corrupted by masking out a single at-   tribute . By denoising the input sequence , adapters   learn to correlate entities with their attributes , ef-   fectively memorizing entire KBs with high accu-   racy ( § 2.3 ) . The obtained KB - adapters are utilized   to guide PLMs ’ predictions during fine - tuning on   downstream TOD tasks ( § 2.4 ) .   In our experiments , BART ( Lewis et al . , 2019 )   is chosen as the PLM that forms the backbone of   the adapter - augmented TOD model , due to its com-   petitive performance on generative tasks . While   the proposed knowledge injection approach is ag-   nostic to the choice of particular PLM , we leave   such validation for future work .   We employ bottleneck adapters ( Houlsby et al . ,   2019 ) due to their established effectiveness and   insert them after the final layer of the encoder and   decoder .   The PLM ’s hidden state given to the adapter as   input is combined with the adapter ’s output using   a weighted fusion function which is a linear trans-   formation of the PLM ’s hidden state followed by a   softmax activation that produces the fusion weights .   This allows the final model to dynamically adjust   the extent to which adapter knowledge is used at   each prediction step . In this work , we ran two sets   of experiments by applying this gating function to   either the logits obtained from both the PLM and   the adapters , or to their pre - logit hidden states .   We train a single encoder and a single decoder   adapter per domain ( hyper - parameter settings are   reported in Appendix C ) .   2.2 From KB Facts to Declarative Statements   Previous studies that investigated knowledge injec-   tion methods often use relational tuples to repre-   sent individual facts contained within a KB , e.g.   where an entity is connected to one of its at-   tributes via the relevant relation : [ Pizza Hut   City Centre , food , Italian ] . While   this knowledge representation format has been   found to be effective in the past , our preliminary   studies indicated that the mismatch between the   natural language input format expected by a PLM   and the structured tuple causes slight performance   degradation . Hence , we choose to represent indi-   vidual KB entries as natural language statements11964   that are fully consistent with the data seen by the   PLM during pretraining .   There are several intuitive ways in which a KB   entries can be translated into natural language state-   ments . Referring again to Figure 2 , we consider ( 1 )   atomic statements , where each statement mentions   the entity and one of its attributes , connected by the   attribute ’s relation , and ( 2 ) composite statements   where each statement communicates the entirety   of the entry , covering all provided entity attributes   and relations . Table 1 illustrates both formats based   on the MultiWOZ KB entry in Figure 2 . All state-   ments are derived by filling - in pre - defined , human-   authored templates with the appropriate entity and   attribute values . Designing the templates intro-   duces minimal overhead , as they reuse attribute   designations where possible and do not introduce   any information beyond the contents of KB entries .   The exhaustive list of templates used in our experi-   ments is provided in Tables 9 and 10 . During the   memorization stage , KB - adapters are trained on a   mixture of all atomic and composite facts , so as to   familiarize the TOD model with different represen-   tations of the same information .   2.3 Memorization Stage   Following the construction of natural language rep-   resentations of KB facts , the memorization stage   involves training adapters to memorize and recall   KB information . As shown on the leftin Figure 3 ,   the adapter - augmented PLM learns to reconstruct   masked declarative statements that are derived from   KB contents , whereby the weights of the PLM   itself are kept frozen – only adapter parameters   are being updated . By filling - in masked tokens ,   adapters learn correlations between entities ( e.g.   hotel names ) and their attributes ( e.g. phone num-   bers ) . Adapter training resembles masked language   modeling and is easy to implement and scale .   2.4 Utilization Stage   After the memorization stage , PLMs are trained to   leverage the domain - specific knowledge encoded in   adapter representations with the goal of producing   more accurate predictions on a downstream task ,   such as RG , as illustrated on the right in Figure 3 .   Throughout this fine - tuning process , adapter param-   eters are kept frozen so as to preserve the domain-   specific knowledge injected during the memoriza-   tion stage . PLM parameters , on the other hand ,   are unfrozen to allow the model to learn to exploit   adapter representations.119653 Knowledge - Probing using Response   Selection ( KPRS ) Benchmark   In this study , we investigate the ability of language   models to verify and retrieve domain - specific facts   within the TOD setting . To this end , we propose the   " Knowledge- Probing using Response Selection "   ( KPRS ) task and the associated benchmark . KPRS   allows us to examine whether domain - specific   knowledge , such as entities and their attributes ,   that is stored within the parameters of the evaluated   model can be successfully accessed and guide the   model ’s predictions . Being knowledgeable about   domain - specific entities in this manner can benefit   dialogue models when reasoning about and reply-   ing to user queries . We show this to be the case for   the response generation task in § 5.3 .   KPRS is a contrastive evaluation benchmark that   measures whether the probed model has memo-   rized and can accurately retrieve domain - specific   knowledge contained within a specified KB . It is   derived from MultiWOZ 2.2 dialogues ( Zang et al . ,   2020 ) ( development and test portions only ) and   covers four domains : restaurant , hotel , attraction ,   andtrain . Given a dialogue context , the task pre-   sented to the evaluated model is to score responses   that are either compatible or incompatible with the   information contained in the KB .   Importantly , KPRS should not be regarded as a   stand - alone evaluation task , but rather as a probing   mechanism that can offer informative insights into   a model ’s ability to access domain - specific facts   stored within its parameters , similar to other knowl-   edge probes , e.g. ( Petroni et al . , 2019 ) . Specifically ,   a fact - aware model should be able to distinguish   between an appropriate ( " reference " ) dialogue   response that is compatible with the knowledge   base information from an inappropriate ( " dis-   tractor " ) response that contradicts the domain-   specific knowledge . By design , the two responses   are minimally different – identical except for at-   tribute values associated with entities described in   the KB , such as restaurant names or departure times   of trains . Hence , to identify the correct dialogue re-   sponse , a model must be able to distinguish values   that are compatible with domain - specific informa-   tion from those that are not .   3.1 Benchmark Design   In order to derive KPRS from MultiWOZ 2.2 de-   velopment and test set dialogues , we ( 1 ) extract   dialogue contexts that precede a system responsethat contains a mention of an entity from the KB or   its attributes , and ( 2 ) perturb the corresponding sys-   tem response to make it incompatible with the KB   by modifying said entity and attribute mentions .   Different perturbation strategies are used for dif-   ferent types of attribute slots . For phone numbers , a   single digit is randomly changed . For integers ( e.g.   denoting the price of a train ticket ) , we randomly   increment or decrement the numbers by a small   amount . For other slot types , distractor values are   chosen so that they differ from the reference value   while producing inadmissible responses . Distrac-   tors are chosen adversarially , i.e. , candidates are   sampled from the KB until the perturbed response   becomes incompatible with the domain - knowledge   and the dialogue context up to the response , while   also achieving a lower sentence - level perplexity   than the reference response according to a filter-   LM ( BART - Large ) . The latter is to ensure the   well - formedness and plausibility of the perturbed   responses . To guarantee that the perturbed response   is indeed unsuitable , we make sure that the selected   distractor does not share attriutes that have been   mentioned in the dialogue context with the replaced   slot value .   Figure 4 shows examples included in the KPRS   benchmark . Each KPRS sample contains the di-   alogue context that includes reference dialogue   states , and two response options – reference re-   sponse and distractor response . Overall , the   KPRS benchmark dataset includes 3,055 samples   ( 1,711 single - domain , 1,324 multi - domain ) . Sam-   ples had been derived from 831 unique dialogues /   1,997 unique dialogue contexts . On average , 3.65   samples were obtained from each individual dia-   logue / 1.52 samples from each individual dialogue   context .   4 Experimental Setup   4.1 Knowledge Base Resource   Throughout our experiments , we use MultiWOZ   2.2 ( Zang et al . , 2020 ) which contains several rel-   atively small - scale domain - specific KBs that are   aligned with task - oriented dialogues . After fil-11966   tering out KBs with missing information , we are   left with four domains : restaurant , hotel , attrac-   tion , and train . Table 2 shows the number of facts   available per domain . Note the substantial gap in   the number of facts where trains is approximately   25X to 66X larger than the other domains .   4.2 Intrinsic Evaluation   To examine whether they can accurately retrieve the   injected KB facts , we task knowledge - augmented   PLMs with reconstructing masked facts , using in-   puts of the same format as described in § 2.2 . Since   this task measures success as a model ’s ability to   memorize and recall learned KB information rather   than generalize it to unseen inputs , we evaluate our   models on the same set of data as was used for   knowledge injection as part of the memorization   stage . Memorization accuracy is employed as the   evaluation metric , representing the number of facts   that have been correctly reconstructed . We refer to   this task as fact memorization task .   4.3 Downstream Evaluation   Additionally , we evaluate our models on the KPRS   probe ( § 3 ) as well as the response generation ( RG )   task . While KPRS directly estimates models ’ pref-   erence for dialogue continuations that are either   consistent or inconsistent with KB information , RG   examines model ’s ability to integrate the injected   KB knowledge into the generated response as part   of the TOD pipeline .   For KPRS , we fine - tune BART - large on the   training data for each domain , using correct re-   sponses as targets , and evaluate subsequent model   performance on the KPRS benchmark . An aug-   mented PLM that can accurately access the injected   domain - specific facts is expected to assign a higher   likelihood to the reference response , compared to   the permuted distractor . Response selection accu-   racy is used as the evaluation metric , defined as   ( c / N ) , where Nis the total number of contrastive   sentence pairs and cis the number of pairs in which   the reference response ( i.e. the one consistent with   the KB ) is assigned lower perplexity by the model .   For RG , given a dialogue context , models must   generate a response that is consistent with KB facts   without performing external KB queries . To test   the model ’s ability for fact retrieval , we use un-   weighted mean of two informative metrics : inform   rate ( n / N ) and success rate ( m / N ) ( Zang et al . ,   2020 ) , where Nis the total number of turns in the   test set , nis the number of turns in which the enti-   ties generated by the model are all consistent with   the KB , and mis the number of turns in which the   model generation provides at least as much of the   user - requested information as the gold response .   4.4 Baselines   We compare the performance of the knowledge-   injected model with two baselines : ( 1 ) BART - large   without any knowledge augmentation ; ( 2 ) BART-   large that has been sequentially fine - tuned on each   KB ( Seq - BART ) . We fine - tune all models on the   downstream task prior to the downstream evalua-   tion .   5 Results & Analysis   We examine the models ’ ability to memorize and   retrieve facts learned from the knowledge base in   § 5.1 and the impact of knowledge injection on   downstream tasks in § 5.2 and § 5.3 . Models were   evaluated in the single - domain setting where only   one single adapter corresponding to the specified   domain was active at evaluation time with test sam-   ples belonging exclusively to the adapter domain   ( a multi - domain setting is discussed in § 5.5 )   5.1 Fact Memorization   As discussed in § 4.2 , we evaluate whether the   knowledge - augmented model is able to success-   fully denoise masked facts seen during training ,   thus testing its memorization capabilities . Table   3 shows the results of the fact memorization task   for BART equipped with KB - adapters . The memo-   rization accuracy is generally very high across all   domains and appears to correlate with KB size.11967   5.2 Knowledge - Probing using Response   Selection ( KPRS )   Table 4 reports the performance of the knowledge-   augmented PLM compared to baselines introduced   in § 4.4 . We found that injecting domain - specific   knowledge into the PLM significantly improves   KPRS accuracy – by 9 - 15 % – compared to BART .   The largest improvement can be observed in the   train domain , which is at odds with the fact mem-   orization results ( § 5.1 ) , where our model under-   performed on that domain . As such , while perfect   memorization of a of all facts contained within a   large KBs remains a challenge in the current train-   ing setup , the domain knowledge embedded within   the adapter network can nevertheless be effectively   exploited by the PLM .   5.3 Response Generation ( RG )   Presumably , having access to the domain knowl-   edge stored in KB - adapters should enable a PLM   to generate responses that are more consistent with   the respective KBs . Table 5 reports the results for   our RG experiments , providing empirical support   for this hypothesis . Interestingly , a large discrep-   ancy can be observed for the hotel domain between   the two examined representation fusion techniques   ( ada - logit that combines PLM and adapter repre-   sentations at the logit level vs. ada - hidden that   combines their pre - logits hidden states ) . We hy-   pothesise that this is , at least in part , due to the hotel   KB containing a small number of facts , which may   have caused instability during training . Accord-   ingly , although knowledge injection can clearly   benefit generation of factual system responses in   both the single - domain setting , the extent of the   improvements is contingent on the target domain   and its properties , as is the best - performing repre-   sentation combination function .   Table 6 provides estimates of RG quality accord-   ing to BLEU . Overall , we see minor to substantial   improvements with respect to the BLEU metric   over the baseline lacking KB - adapters . This can   be taken as further evidence in support of the ef-   fectiveness of the proposed knowledge injection   methodology . However , it should be noted that the   extent of the observed improvements varies across   domains and representation combination functions .   5.4 Randomly - initialized Adapters   We investigate how equipping PLMs with our pro-   posed KB - adapters compares to equipping them   with randomly - initialized adapters during the fine-   tuning stage ( a setting to which we refer as rand-   BART ) . This effectively isolates the impact of   knowledge injection on the KPRS and RG perfor-   mance , by factoring out the increased model ca-   pacity due to the additional parameters introduced   by the adapters . Table 7 shows the experimen-   tal results for both tasks . We find that injecting   domain - specific knowledge into the PLM does in-   deed significantly improve KPRS performance – by   6 - 15 % – compared with rand - BART , thus further   validating our approach .   5.5 Integration of Multiple Knowledge Bases   The modular nature of of the proposed knowledge-   injection method allows us to equip PLMs with   multiple adapters , with each adapter encoding in-   formation from a different domain . This enables   the augmented PLM to access facts from differ-   ent domains simultaneously , without running the   risk of catastrophic forgetting , whereby informa-   tion from one domain overwrites previously ac-   quired domain - specific knowledge , e.g. as a result   of sequential fine - tuning . Aligned with our mo-   tivation to allow users to easily add and modify11968   KBs in practical settings , we investigate whether   our proposed system can effectively integrate in-   formation from multiple adapters . We utilize the   same representation combination functions as de-   scribed in § 2.1 , generalizing them to an unbound   number of adapters by computing normalized fu-   sion weights for each adapter and the PLM itself .   In this multi - domain setting , multiple adapters are   active simultaneously , while test samples are drawn   from all four studied domains .   Tables 4 and 5 report multi - domain results for   KPRS and RG in the multi column . For both tasks ,   we observe clear improvements compared to base-   line models when providing the model with ac-   cess to all domain - specific adapters simultaneously .   However , we note that the gap between the adapter-   augmented PLM and the best - performing baseline   is much smaller compared to single - domain experi-   ments where the model only has access to a single ,   relevant adapter ( 1.9 % vs. 12.25 % on average for   KPRS and 8.1 % vs. 11.6 % on average for RG ) .   One reason for the limited improvements ob-   served in the multi - domain setting could be the   PLM ’s inability to correctly identify adapters corre-   sponding to the dialogues ’ domains and to promote   their representations . The more pronounced gains   observed in the single - domain setting – where the   model does not have to chose between multiple   adapters – appears to support this interpretation .   To verify our hypothesis , we preclude the need   for adapter selection by instead training a single   adapter on the concatenation of facts from all four   domains , which preserves the multi - domain setting .   Evaluating the performance of the resultant model   on KPRS , we observe improvements over the mul-   tiple adapters setting , with ada - logis obtaining an   accuracy of 83.0 % and ada - hidden reaching 85.9 % ,   thus improving over the best - performing baselineby a substantial 9.4 % . This , however , comes at   the expense of increased training time during the   memorization stage and a significant reduction in   flexibility for the addition of new KBs ( which will   require costly re - training the single , multi - domain   adapter rather than simply introducing a new single-   domain adapter ) .   It may be possible to improve the performance   of PLMs equipped with multiple single - domain   adapters by implementing more expressive com-   bination representation functions or by adjusting   the training regime . We regard as a promising re-   search direction that could more effectively extend   the flexibility of adapter - based knowledge injection   to more complex dialogue settings .   6 Related Work   6.1 Knowledge Injection   Our work contributes to the growing body of re-   search that explores strategies for introducing exter-   nal knowledge into the internal reasoning processes   of PLMs , with the aim of aligning their predic-   tions with respective knowledge sources ( Colon-   Hernandez et al . , 2021 ) . Previous work in this   area incorporated linguistic ( Lauscher et al . , 2019 ;   Wang et al . , 2020 ) , factual ( Wang et al . , 2020 ;   Agarwal et al . , 2020 ) , and commonsense ( Lauscher   et al . , 2020 ) knowledge into pretrained models ,   with studies differing in the exact format of the   injected knowledge and potential modifications to   the PLMs ’ architecture . Nevertheless , injection of   highly specific , fine - grained , tabular information   commonly associated with TOD ( as exemplified   by MultiWOZ 2.2 KBs ) has so far received limited   attention , both within dialogue literature and be-   yond . The use of natural language statements as the   primary mechanism for injecting external informa-   tion into PLMs has been previously considered in   works such as ( Lu et al . , 2021 ) , who trained a gen-   erative model to transform knowledge triplets into   declarative statements . We rely on template - based   generation , instead , to account for the relatively   small size of our KBs , the highly structured nature   of KB entries , and the lack of natural language   sequences that can be trivially aligned with KB   contents .   6.2 Knowledge - Grounded Dialogue   Of particular relevance to our work is the study by   ( Madotto et al . , 2020 ) who fine - tune all parameters   of a PLM on synthetic dialogues constructed so as11969to communicate all information contained within   a TOD KB . The limitations of their approach , as   noted by its authors , are that the synthetic dialogues   are noisy and any subsequent updates to the in-   jected KB information require finetuning the entire   model anew which is computationally demanding .   We address both issues by relying on grammati-   cally sound templates during knowledge injection   and by leveraging light - weight adapters that can be   updated for a small fraction of cost incurred by up-   dating the full PLM . The Adapter - Bot introduced in   ( Lin et al . , 2021 ) is likewise related to our models   in that it employs adapters in the context of TOD .   However , rather than training adapters to memorize   KB content that can be exploited by the dialogue   model without additional supervision , the authors   rely on knowledge - aligned dialogues to introduce   domain - specific information into their model which   may not always be available . More recently , ( Fan   et al . , 2021 ) proposed equipping transformer mod-   els with specialized modules that fetch embedded   information from external resources , integrating   it into the model ’s reasoning process . While the   authors apply their model to dialogue generation ,   their work differs substantially from ours , as they   do not consider the task - oriented setting or struc-   tured KBs ( instead using training set utterances and   Wikipedia excerpts ) . However , combining knowl-   edge memorization and differential information re-   trieval is a promising direction for future research .   Moreover , external knowledge has found applica-   tion in dialogue literature outside of directly guid-   ing response generation . For instance , ( Lertvit-   tayakumjorn et al . , 2021 ) annotated dialogue data   with constraint violations based on valid links be-   tween entities as specified in the corresponding   KBs . Similar to KPRS , detection of constraint   violations can be regarded as a probing task that   provides insights about the ability of a dialogue   model to reason about KB entities .   7 Limitations   One of the main limitations of the presented ap-   proach is its reliance on manually constructed   fact templates . We experimented with fine - tuning   KG - adapters directly on < ent 1 , rel , ent 2 > KB   triples , but found that the use of templates improves   the ability of models to apply the memorized knowl-   edge in downstream applications . In light of this ,   possible future extensions of our work may include   creation of domain - agnostic strategies for knowl - edge injection that do not necessitate manual design   of templates for each new domain .   Another limitation comes from the fact that the   proposed approach is suitable only for static and   pseudo - dynamic KBs , i.e. that can change periodi-   cally , such as a seasonal menu or a database of cars   manufactured by a company . However , it is not   suited for real - time databases ( e.g. databases that   store the availability of rooms in a hotel ) since for   every KB change the corresponding adapter needs   to be retrained in order to be updated .   Additionally , while injecting knowledge into the   language model has been shown to be effective for   making it available during fine - tuning on down-   stream tasks , the knowledge stored in the adapters ’   parameters might not be accurate enough for cer-   tain real world applications due to the imperfect   fact memorization we observed in our experiments .   Finally , the introduced KPRS task only evalu-   ates the extent to which a model can access factual   information stored in its parameters . It does not   not assess the model ’s ability to understand and   use this knowledge for complex reasoning tasks ,   e.g. counting the number of cars in a specific price   range , or listing the items on a menu that do not   contain a certain ingredient . This could be an ex-   citing direction for future research .   8 Discussion and Conclusion   In this study , we proposed a method for tightly in-   tegrating external knowledge with the internal rep-   resentations of PLMs by storing domain - specific   information within light - weight adapter networks   that guide model predictions . Such adapters can   memorize KB contents with high accuracy , which   decreases slightly for larger KBs . An important   contribution of our work is the KPRS probe de-   signed to measure the ability of TOD models to rea-   son about KB entities and their attributes . As part   of our experiments , we showed that KB - adapters   clearly benefit the identification and generation of   TOD responses that are consistent with dialogue   history and relevant KB entries , and showcased   the advantages of using adapters for knowledge   injection as opposed to sequential fine - tuning .   Our investigation demonstrates that dialogue   models can access domain - specific knowledge   without having to query external KBs . This is an   important finding as it can pave the way towards   reducing the query engineering overhead in chatbot   design , thus lowering the entry barrier for develop-   ing and deploying real - world TOD systems.11970References1197111972A Atomic vs. Compositional Fact   Formats   While developing the memorization stage of the   knowledge injection process , we compared the rela-   tive utility of representing KB facts as either atomic   or compositional statements , as measured by the   memorization accuracy attained by the adapter-   augmented PLM . The results of this pilot exper-   iment are summarized in Table 8 , which paints a   mixed picture . While atomic statements result in   stronger memorization for the restaurant , hotel ,   andattraction domains , compositional statements   are substantially more effective in the trains do-   main . We therefore decided to combine both for-   mats for our main set of experiments , as the resul-   tant mixture shows reasonable performance across   all domains . Furthermore , exposing the model to   different surface forms of the same underlying in-   formation is expected to enable better generaliza-   tion for downstream tasks .   B Ethical Considerations   Injection of external knowledge into dialogue mod-   els may have both ethical and legal implication , if   said knowledge contains personal identifiable in-   formation ( PII ) , such as social security numbers of   addresses of private individuals . Such information   would be memorized by the adapter - augmented   model and potentially exposed during response   generation , if there are no additional safeguards   in place to prevent this scenario . For this reason ,   it is crucial to curate the memorized KBs by re-   moving any and all instances of PII prior to the   memorization stage .   C Hyper - parameters   All models were trained on V100 GPUs , using the   PyTorch implementation of the BART - Large model   distributed as part of the HuggingFace Transform-   ers library ( Wolf et al . , 2019 ) . The training loop em - ployed the AdamW ( Loshchilov and Hutter , 2017 )   optimizer . By conducting a grid search , we empiri-   cally determined that a learning rate ( LR ) of 3e   worked best for fine - tuning RG models and LR of   1eyielded best results for KPRS . For knowledge   injection , LR of 3ewas found to be effective .   In all cases , LRs were kept constant across all do-   mains . For all domains and experiments , we re - use   the same bottleneck adapter configuration , by set-   ting the size of the hidden layer to 769 . All models   were trained until convergence by terminating train-   ing after 10epochs during which no improvement   had been observed on the development set .   D Fact Templates   This section provides a complete , exhaustive list of   all templates used in the generation of declarative   statements derived from the MultiWOZ 2.2 KB   facts.1197311974