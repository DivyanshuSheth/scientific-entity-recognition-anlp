  Hyounghun KimAbhay ZalaMohit Bansal   UNC Chapel Hill   { hyounghk , aszala , mbansal}@cs.unc.edu   Abstract   As humans , we can modify our assumptions   about a scene by imagining alternative objects   or concepts in our minds . For example , we can   easily anticipate the implications of the sun be-   ing overcast by rain clouds ( e.g. , the street will   get wet ) and accordingly prepare for that . In   this paper , we introduce a new dataset called   Commonsense Reasoning for Counterfactual   Scene Imagination ( CSI ) which is designed   to evaluate the ability of AI systems to rea-   son about scene change imagination . To be   specific , in this multimodal task / dataset , mod-   els are given an image and an initial question-   response pair about the image . Next , a counter-   factual imagined scene change ( in textual form )   is applied , and the model has to predict the new   response to the initial question based on this   scene change . We collect 3.5 K high - quality   and challenging data instances , with each in-   stance consisting of an image , a commonsense   question with a response , a description of a   counterfactual change , a new response to the   question , and three distractor responses . Our   dataset contains various complex scene change   types ( such as object addition / removal / state   change , event description , environment change ,   etc . ) that require models to imagine many dif-   ferent scenarios and reason about the changed   scenes . We present a baseline model based on   a vision - language Transformer ( i.e. , LXMERT )   and ablation studies . Through human evalua-   tion , we demonstrate a large human - model per-   formance gap , suggesting room for promising   future work on this challenging , counterfactual   multimodal task .   1 Introduction   Anticipating what would happen when there is a   condition change in a situation is an important abil-   ity as it allows preparation for the implications ofthe change . For example , when swimming in the   sea on a clear day , you might feel safe . However , if   someone told you a storm warning has been issued   and dark clouds are coming in soon , you would   know that it is no longer safe to swim and return   to land . It will be also very useful to have AI   systems that could reason about the implications   of such scenario changes and provide appropriate   guidance / warnings ; however , current AI systems   will have a hard time performing such counterfac-   tual commonsense reasoning .   Many efforts have been made to teach machines   how to reason about images ( Antol et al . , 2015 ;   Zhu et al . , 2016 ; Johnson et al . , 2017 ; Hudson and   Manning , 2019 ) and videos ( Tapaswi et al . , 2016 ;   Jang et al . , 2017 ; Zhu et al . , 2017 ; Lei et al . , 2018 ) .   This area has been built upon further by efforts to   teach machines to use commonsense knowledge   when analyzing visual scenes ( Pirsiavash et al . ,   2014 ; Wagner et al . , 2018 ; Zellers et al . , 2019 ; Park   et al . , 2020 ) . Through these efforts , many AI sys-   tems have reached near human - level performance   on scene understanding tasks . On the other hand ,   more complex reasoning on scene ‘ changes ’ has   been less explored . Sampat et al . ( 2021 ) applies   simple condition manipulations ( e.g. , “ Paint the   small green ball with cyan color ” ) on synthetic   images in a visual question answering setup . How-   ever , this task is based on simple block objects   that might not require complex implicit reasoning .   Thus , complicated counterfactual commonsense   reasoning on scene changes on real - world images   and situations remains widely unexplored .   Therefore , in this paper , we introduce a   new dataset called Commonsense Reasoning for   Counterfactual Scene Imagination ( CSI ) to   evaluate the commonsense reasoning ability of   agents about counterfactual visual scenes imagined   via textual descriptions . To be specific , one data   instance in our CSIdataset consists of an im-   age , an initial question - response pair , an imagined911   visual scene change , and a new response with three   distractors . The question is about commonsense   which can be inferred from the image and the initial   response includes a reasoning / justification for its   answer . The imagined visual scene change is a tex-   tual description of what to modify in the scene to   alter the conditions . The new response follows the   same format as the initial response , but should be   influenced by the imagined change ( see Figure 1 ) .   A model for this task needs to take this context   information as input and try to predict the correct   new response among other distractors . The distrac-   tors look similar to the correct new response but   have subtle differences and are semantically dif-   ferent from the correct new response , thus a good   model on this challenging new multimodal task   can not take shortcuts and needs to fully understand   what each choice means based on the context . For   example , as shown in Figure 1 , given an image ,   the initial question - response pair ( “ Is the railway   line safe ? ” -“Yes because there are safety lights   and crosswalk signs ” ) , and the scene change ( “ add   a train to the tracks . ” ) , models should choose the   correct new response ( “ no . although there are   safety lights and crossing gates , they do n’t appear   to be working and there is a train coming . " ) among   other distractors ( “ no . although there are safety   lights and crossing gates , there is a power outage   and there is a train coming . ” , etc . ) . To solve this   problem , models need to be able to understand the   implications of an incoming train and how safety   lights and gates operate at a railroad crossing .   We collect 3.5 K high - quality and challenging   data instances for this new multimodal reasoning   task via a crowd - sourcing annotation platform . To   collect each data instance and to help reduce in-   dividual crowd - worker load , we break the task up   into three separate phases : the question collectionphase , the scene change collection phase , and the   distractor collection phase . During the distractor   collection phase , to help avoid unexpected biases   such as text - only , we implement a modified version   of Human - And - Model - in - the - Loop Enabled Train-   ing ( HAMLET ) adversarial data collection ( Nie   et al . , 2020 ) for the validation and test splits . We   deploy the model trained on only the textual data   and allow annotators to test their distractors against   the model as they write ( see Figure 2 ) .   Our CSIdataset features several diverse   types of imagined scene changes ( object addi-   tion / removal , object state changes , etc . ; see Sec . 5.2   for the full change type list and examples ) which   requires to deeply understand the contexts , making   the task very challenging . For example , to under-   stand the scene change of “ Add another person to   the dock ... ” , the model should figure out what a   dock is , where it is located in the image and be able   to add one more person onto it via imagination .   As a baseline model for this new multimodal rea-   soning task , we employ a vision - language Trans-   former ( based on LXMERT ( Tan and Bansal ,   2019 ) ) which computes vision and language feature   matching scores via multi - head self - attention layers   followed by cross - modal attention layers , and we   report ablation studies on input modality and scene   change types . We also show a large human - model   performance gap allowing more effective future   work from the community on this new challenging   multimodal task on commonsense reasoning for   imagined counterfactual scene changes .   2 Related Work   Visual Question Answering . There have been   many efforts to teach machines how to reason about   images ( Antol et al . , 2015 ; Zhu et al . , 2016 ; John-   son et al . , 2017 ; Hudson and Manning , 2019 ) and912videos ( Tapaswi et al . , 2016 ; Jang et al . , 2017 ; Zhu   et al . , 2017 ; Lei et al . , 2018 ) , and in some of these   tasks , machine performance is approaching human   levels . Although these tasks require a complicated   reasoning process , they provide very explicit con-   text to solve the problems and might not be enough   to evaluate the ability to reason about implicit as-   pects ( i.e. , commonsense ) .   Visual Commonsense Reasoning . Another ac-   tively explored line of study has been on visual   commonsense reasoning ( Pirsiavash et al . , 2014 ;   Wagner et al . , 2018 ; Zellers et al . , 2019 ; Park et al . ,   2020 ) . In addition to using the provided clues   in the context , these tasks require commonsense   knowledge to reason about given problems , mak-   ing these tasks more challenging since machines   should be equipped with prior or external informa-   tion . However , these tasks handle static scene un-   derstanding for which contexts and conditions are   not changed during the reasoning process . On the   other hand , our proposed CSIintroduces an ad-   ditional dimension of difficulty by integrating imag-   ined scene changes in the context . Moreover , the   changes in our CSIdataset are imagined ( tex-   tually ) and counterfactual , so imagination - based   commonsense is required for the reasoning .   Textual Scene Change . Recent effort has been   made on visual understanding by requiring mental   simulation of changes to the scene ( Sampat et al . ,   2021 ) . These tasks require simulating change with-   out any visible result , hence increasing the diffi-   culty of VQA tasks . They , however , have been   completed in the simpler context of basic shapes   and objects and simple questions ( E.g. “ How many   blue objects will be present in this scene ? ” ) . Our   CSIdataset is based on complex real - world im-   ages / situations requiring commonsense reasoning   about imagined counterfactual scene changes , al-   lowing for evaluation of the ability to anticipate the   implications of complex situation changes , thus ,   future events .   3 Task   Given a real - world image , models should predict   a new response conditioned on the initial question-   response pair and the imagined counterfactual   scene change .   Initial Question and Response . The initial   question - response pair is created only from a given   image . The question and response themselves re-   quire quite an amount of commonsense reasoning   to understand . For example , to understand the re-   sponse to the question in Figure 1 ( “ Is the railway   line safe ? ” ) , models should know that the ‘ safety   lights ’ and‘crosswalk signs ’ are devised for keep-   ing people safe around the railway ( “ Yes because   there are safety lights and crosswalk signs ” ) .   Imagined Counterfactual Scene Change . The   imagined counterfactual scene change is a textual   description that modifies the scene in the image .   The change affects the reasoning process of the   initial question and response , and provides a new   context for the new response ( “ add a train to the   tracks . ” ) .   Response on the Scene Change . Models should   respond to the initial question with a proper rea-   son based on the imagined counterfactual scene   change . The task is a multi - choice setup to pick   the correct response among other distractors ( “ no .   although there are safety lights and crossing gates ,   they do n’t appear to be working and there is a   train coming . ” ) . To choose the correct response ,   models should understand what the implications   and safety concerns of an incoming train are and   that the safety lights should be turning on and the   crossing gates should be closing when a train is in   proximity .   4 Dataset   OurCSIdataset is composed of 3.5Kimages   paired with a commonsense question - response pair ,   a description of an imagined counterfactual change   to the image , a new response to the question based   on the effect of the described change , and then   three distractor responses to the question ( all text   is in English).913We employ annotators from the crowd - sourcing   platform Amazon Mechanical Turk . Our data col-   lection is broken into three separate phases ( ques-   tion , change , and distractor ) in order to reduce the   workload for each worker . In the question phase ,   workers are asked to select an image ( from three   random images ) to use , write a commonsense ques-   tion and then respond to it . In the change phase ,   they are asked to describe a counterfactual scene   change for the image and then write a new response   to the initial question . Lastly , in the distractor   phase , they are asked to write three distractor re-   sponses for the question .   Commonsense Question Collection . To collect   the initial question and response , we present three   images to the workers and then ask them to choose   the one that they want to use ( images are taken   from Visual Genome ( Krishna et al . , 2017 ) ) . Then   using that image , they should come up with a com-   monsense question about the image . We define a   commonsense question as a question that requires   logical thought and understanding of what is hap-   pening in the image to be able to answer . Then   workers are asked to write a response to their ques-   tion ( the initial response ) . A response consists of   two parts , an “ answer ” that is a direct answer to   the question ( e.g. “ Yes , ... ” ) and then a “ justifica-   tion ” that uses visual clues from the image to prove   the answer is correct ( e.g. “ ... , because everyone   is wearing shorts and short - sleeved shirts and a   woman can be seen wearing sunglasses . ” ) . See   Appendix for the collection interface .   Counterfactual Scene Change Collection . In   this phase , workers are given the image chosen   from the previous commonsense question collec-   tion phase and the corresponding initial common-   sense question - response pair . Then workers are   asked to describe a counterfactual scene change   for the image and write a new response to the   question based on that scene change ( the new re-   sponse ) . To help ensure that workers describe a   reasonable counterfactual scene change , we pro-   vide two guide templates for them to follow when   they write . Workers are asked to select the guide   template that they believe makes the most sense for   them to use for each data instance ( see Appendix   for collection interface and guide template details ) .   Distractor Collection . Workers are given the im-   age , the initial commonsense question - responsepair , as well as the counterfactual scene change and   new response . Then they are told to write three   distractor responses that are similar to the new re-   sponse but incorrect . To help ensure the distractors   pose a challenge but are still distinct , we pre - fill the   worker ’s textboxes with the new response . Then   they are told to edit the text enough so the answers   become false and distinct .   HAMLET Data Collection . To avoid having un-   expected biases such as context+response bias in   our textual data , when collecting distractors for the   validation and test splits , we implement a HAM-   LET style collection ( see Figure 2 ) . We deploy   the model trained only with textual data and allow   workers to test their distractors directly against the   model in real - time and check whether they are able   to fool it . Workers are also permitted to edit the   new response from the previous collection phase if   it helps make distractor writing better ( they must   maintain the original meaning / intent of the new   response if they choose to edit ) .   Data Verification . At each collection phase , we   ask workers to verify the previous phase ’s work . If   the previous set of work is not good , workers are   given a place to flag and describe the reason for   flagging . This reasoning is manually reviewed and   if it is fair , then that data is removed and prevented   from progressing to the next phase .   Worker Qualifications and Payment . For all 3   phases , workers are required to pass certain qual-   ifications before they could begin . As all of the   phases require reading and writing English , they   were required to be from native English - speaking   countries . Workers were also required to have at   least 1,000 approvals from other tasks and a 95 %   or higher approval rating . Then for each phase , we   require workers to pass a qualification test that tests   their understanding of their task at each phase . See   Appendix for worker totals and pay ( + bonus ) rates .   5 Data Analysis   We collect 3.5 K task instances ( 3.5 K images , ini-   tial questions - response pairs , scene changes , new   responses , and 10.5 K distractors ) .   5.1 Statistics   Length . Lengths of each part of the data instances   are shown in Table 1 . While the lengths of ques-   tions are relatively short , the lengths of responses   and the changes are long . This means that question914   itself does not contain detailed clues and models   should figure out which information is needed to   answer the question . On the other hand , the long re-   sponses contain reasons to justify their answers and   require models to deeply understand the reasoning   process to solve the problem . Furthermore , models   should also carefully read the long textual scene   change to capture all the condition modifications   and apply them to images .   Vocabulary . Among all data instances in our   CSIdataset , there are 9,946 total unique words .   Within the commonsense questions , initial re-   sponses , scene changes , new responses , and the   distractors , there are 3,261 / 4,397 / 4,637 / 5,318 /   6,404 unique words , respectively . The unique word   count reflects what is shown by the lengths . Ques-   tions are on average the shortest part of each data in-   stance and they have the fewest unique words . The   new responses and distractors have long lengths   and high unique word counts . The high unique   word count for the distractors shows their diversity .   Figure 4 shows the most commonly occurring key-   words in our dataset . Many of the words are related   to people and directional positioning .   5.2 Scene Change Type .   Different imagined scene change types are present   in our CSIdataset . Imagined scenes changes   describe a change ( with counterfactual thought ) to   the image by applying various properties . Some   of these scene change types include object addi-   tion / removal , object state changes , environment   changes , etc . ( see Figure 3 for some scene change   types and their examples ; see Appendix for a figure   with a complete list of all the types with examples ) .   These scene change types , while they are seemingly   easy to visualize , require a complex understanding   of the effect of the change on other elements in the   scene . See Figure 5 for type frequencies .   Human / Object Addition . These two scene   change types involve introducing new hu-   man(s)/object(s ) into the image that was not there   prior ( “ A bunch of old men are standing next to   the birds ... ” /“There are tears in his eyes ... ” ) .   The object addition scene change type is the most   commonly appearing one .   Human / Object Removal . These two scene change   types involve removing human(s)/object(s ) that are   visible in the image ( “ ... remove the workers ... ” /   “ Remove the two people ’s coats ” ) .   Object Replacement . This scene change type in-   volves removing object(s ) from the image and re-   placing them with something else ( “ ... replace the   plates of fruit by plates of dog biscuits ... ” ) .   Object Relocation . This scene change type in-   volves re - positioning object(s ) . Rather than chang-   ing it directly , this type changes its relation to other   objects ( “ space the zebras out . move them a little915   further away ” ) .   Object State Change . This scene change type   involves altering the state of object(s ) present in   the image ( “ ... change her luggage to all have a   Burberry pattern ... ” ) . The alteration of object(s )   can occur in various forms such as changing color ,   size , shape , and orientation ( e.g. , opening a door ) .   Event Description . This scene change type in-   volves the creation of an event or a description of   motion or interaction between objects in the image .   This type includes human actions and changes to   human emotions ( “ A pack of lions are approaching   the sheep . ” ) .   Environment Change . This scene change type   involves changes that cause large - scale changes to   the entire environment either by drastically altering   the current environment , creating a new environ-   ment , or causing changes in the weather ( “ there is   very thick dust everywhere ” ) .   Complex Changes . We define a complex change   as a change that contains three or more different   scene change types . For example , “ someone is   throwing snow ball at her ” this change introduces   a new human , a new object , and defines an inter-   action between all these and involves someone al-   ready present in the image . These complex changes   require much thought to understand their full effect   and implications . Complex changes make up about   30 % of our dataset . See Table 2 for change types   per instance statistics .   6 Models   We employ a vision - language Transformer as the   base architecture of our baseline model for the   CSItask . To be specific , we use LXMERT ( Tan   and Bansal , 2019 ) to compute the score of each   context - response pair given an image feature , and   select one with the highest score among them .   We employ Faster R - CNN ( Ren et al . ,   2015 ) to extract object - level visual features   O = { o , o , ... , o}and bound boxes   B={b , b , ... , b}from an image I , where N   is the number of detected object features . For tex-   tual feature encoding we use BERT ( Devlin et al . ,   2019 ) as it is used in LXMERT . We concatenate all   the textual data , i.e. , question Q={q , ... , q } ,   initial response R={r , ... , r } , scene   change C={c , ... , c } , and new response   R={r , ... , r}along with [ CLS ]   and [ SEP ] tokens to create a sequence W=   { [ CLS ] , Q,[SEP ] , R,[SEP ] , C,[SEP ] , R,[SEP ] }   where N , N , N , andNare the lengths of   question , initial response , scene change , and new   response , respectively .   O , B = FRCNN ( I ) ( 1 )   ˆO = Linear([[V - Tok];O ] ) ( 2 )   ˆB = Linear([[V - Tok];B ] ) ( 3 )   ˆV = Linear([ˆO;ˆB ] ) ( 4 )   L = Emb(W),ˆL = TF(L ) ( 5 )   where Linear , Linear , and Linearare linear   layers . [ V - Tok]and[V - Tok]are visual token at-   tached to object and bounding box sequences ( like   [ CLS ] for a language sequence ) , respectively , and   [ ; ] is concatenation operation along the token-   dimension and [ ; ] is along feature - dimension .   TFis a language Transformer ( Vaswani et al . ,   2017 ) which consists of self - attention layers . The   ith attention head in the lth layer ais computed   this way :   a = Softmax ( QK   √d)V ( 6 )   Q = WH , K = WH , V = WH   ( 7 )   H= [ a;a; ... ;a ] ( 8)   where W , W , andWare trainable parameters ,   Nis the number of attention head , and dis the916   dimension of each attention head . Then , ˆVand   ˆLare fed to the cross - attention layers : ¯V , ¯L=   TF(ˆV , ˆL ) , where TFis cross - attention layers   of vision and language Transformer which consists   of self - attention layers as well as cross - attention   layers . Scores are computed between visual feature   and each of the 4 language features ( 1 ground - truth   and 3 distractors ) pair : s = Linear ( ¯V∗¯L ) ,   where ∗is the element - wise product , ˆVis the vi-   sual token ( i.e. , [ V - Tok ] ) that is attached in the   input layer , and ˆLis the first token ( i.e. , [ CLS ] )   ofk - th language feature . The model compares the   4 scores to select the pair with the highest score as   the final answer . The loss is computed by cross-   entropy : L=−/summationtextlogp(s ) , where sis a score   for the ground - truth pair .   7 Experiments   Data Splits . We split the dataset into   1,924/800/800 ( train / val / test ) .   Training Details . We use 768 as the hidden size   and use Adam ( Kingma and Ba , 2015 ) as the op-   timizer , setting the learning rate to 1×10 . See   Appendix for more details .   Human Upper Bound Evaluation Setup . We   conduct a human evaluation of our CSItask to   estimate the upper bound that models can reach .   We take 50 samples from the validation split and   ask two experts to complete the task and average   their scores .   Scene Change Types . We collect the type of the   Scene Change for the validation set . Two experts   are shown each change and then asked to label it   into one or more types . See Figure 5 for the change   types .   Multi - Task / Contrastive Learning . To exploit   extra commonsense reasoning information , we   explore multi - task learning ( MTL ) with a large-   scaled visual commonsense reasoning dataset ,   VCR ( Zellers et al . , 2019 ) dataset through alter-   nating mini - batch training . In one mini - batch , the   model is trained on our CSIdataset , and in the   next , the model is trained on the VCR dataset , and   so on . Also , we try contrastive learning to explore   potential improvement . Specifically , we compute   matching scores between each visual token and   [ CLS ] token of each ground truth text feature in a   mini - batch , and compute contrastive loss .   8 Results   Modality Ablation . We build models with differ-   ent input modalities and conduct an ablation study .   As shown in Table 3 , the Response - Only model   ( which only takes the new response / distractors as   input ) does not do well ( row 1 ) . The TC - Response   model ( which takes all text data as input ) obtains a   better score than the Response - Only model ( row 1   and 2 ) , but still performs poorly . The Full model   ( which takes the full image and text data as input )   does best ( row 3 ) , meaning models need all the917   visual and textual input to perform reasonably .   Human Evaluation . We conduct a human eval-   uation to check the upper performance bound for   theCSItask . As shown in row 4 of Table 3 ,   the score is quite high , indicating a large room for   improvement from future work .   Scene Change Types . As shown Table 4 , our   model shows balanced scores over all scene change   types in general , however , comparing the addition   and removal types ( row 1 and 2 for object , row   6 and 7 for human ) , the performance on removal   types is lower than addition types . That is possibly   because removing something from an image might   be harder to imagine .   Number of Scene Change Types . As shown Ta-   ble 5 , instances with a single scene change type   seem to be relatively easier to address than ones   with multiple scene change types . This might im-   ply that multiple scene changes make the reasoning   process more complex and challenging .   Multi - Task / Contrastive Learning . As shown   in row 1 of Table 6 , multi - task training with VCR   does not seem to help improve performance on our   CSIdataset , implying our dataset is challenging   to address and requires a more complex reasoning   process . The performance of the contrastive learn-   ing ( row 2 ) is also very close to the Full model ’s   ( row 3 in Table 3 ) , meaning more advanced ap-   proaches might be needed to tackle our CSI   dataset / task .   Output Examples . As shown in the upper example   of Figure 7 , our model predicts the correct response   by understanding the implication of “ steep slopes ”   in the change . In the bottom example , our model   fails to understand that “ there is a shark ” must   mean the shark is in the water ( as sharks live in   the water ) , and choose a wrong response . We also   split changes into sub - parts and compute scores for   each part to see on which part the model focuses to   answer questions . As shown in Figure 8 , the model   looks at “ Add labels to the spines of all the books ”   to choose the answer .   9 Conclusion   We introduced a challenging counterfactual com-   monsense reasoning task / dataset called CSI   which features imagined counterfactual scene   changes requiring models to imagine the changed918   situation to answer questions . We collected 3.5 K   high - quality instances that consist of an image ,   an initial question - response pair on the image ,   an imagined scene change , and a new response   ( with three distractors ) . The scene changes have   different challenging types ( such as object ad-   dition / removal / replacement , environment change ,   etc . ) . We presented a baseline model as a start-   ing point with useful ablation studies and showed   a large human - model performance gap allowing   useful future works .   Acknowledgments   We thank the reviewers for their helpful com-   ments . This work was supported by NSF Award   1840131 , ARO Award W911NF2110220 , DARPA   MCS Grant N66001 - 19 - 2 - 4031 , and a Google Fo-   cused Award . The views contained in this article   are those of the authors and not of the funding   agency .   References919   A Data Collection   We implement different interfaces for our data col-   lection . The commonsense question collection in-   terface allows for workers to choose which image   they would like to use when making the question , as well as an object to focus on ( Figure 9 ) . The   counterfactual scene change collection and the dis-   tractor collection interfaces ( Figure 10 and Fig-   ure 11 ) feature a verification checkbox . Workers   can check the box if the quality of the data from the   previous phase is poor . If it is flagged , the reason   is reviewed . If the reasoning is valid , the instance   is removed from the dataset / no longer progressed   through the collection phases .   A.1 Counterfactual Change Collection   templates   The first guide template is “ Keep A , Flip B ” and   the second is “ Flip A , Keep B ” ( where ‘ A ’ means   answer and ‘ B ’ means justification ) . For “ Keep A ,   Flip B ” , workers are told to describe a change that   results in the “ answer ” part of initial response to be   the same , but with a different “ justification ” part   ( E.g. “ yes because people are wearing jackets and   winter clothes . ” →“yes because you can see some   snow ... ” ) . In the change they write , they should   negate / remove the “ justification ” part of initial re-   sponse and add something that could be used for a   new “ justification ” . For “ Flip A , Keep B ” , workers   are told to describe a change that results in the op-   posite “ answer ” . The change should also modify   the context so that the initial response “ justifica-   tion ” part is true , but is no longer valid in proving   the answer and a new “ justification ” part is needed .   ( e.g. , “ no , as you can see the man is not soaking   wet . ” →“yes , the man is n’t wet and he is under a   structure , however ... ” ) .   A.2 Worker Totals and Payment   We had a total of 182 , 97 , 194 workers pass testing   for question collection , change collection , distrac-   tor collection , respectively . For the question collec-   tion phase and the change collection phase , work-   ers are paid 0.35 USD per instance they complete   ( each takes about 2 minutes ) . As the distractor col-   lection phase is faster and easier , workers are paid   0.30 USD per instance ( takes around 1.5 minutes ) .   In all three phases , an additional bonus of 0.02   USD is given for each high - quality instance they   completed , and then for every subsequent group   of 25 high - quality instances completed , the bonus   per instance is increased by 0.01 USD ( 0.02 USD   bonus per instance for the first 25 , 0.03 USD bonus920for the next 25 , 0.04 USD bonus for the next 25 ,   and so on ) . Since there is no limit on how much a   worker can write , they can keep stacking the bonus   as much as they want . All the payments are at a   reasonable hourly rate of 11 - 12 USD .   B Scene Change Types   The scene change types , while they are seemingly   easy to visualize , require a complex understanding   of what effect the change has on other elements   in the scene . The Object Addition scene change   type ( the most commonly occurring one ) involves   introducing new object(s ) into the image that was   not there prior . The Object State Change scene   change type involves altering the state of object(s )   present in the image . The alteration of object(s )   can take place in various forms such as changing   color , size , shape , and orientation ( e.g. , opening a   door ) . The Event Description scene change type   involves the creation of an event or a description of   motion or interaction between objects in the image .   Please see Figure 12 for the full list of the scene   change types and examples .   C Training Details ( Reproducibility )   All the model experiments are conducted on a   Ubuntu 16.04 system using the NVIDIA GeForce   GTX 1080 Ti GPU and Intel Xeon CPU E5-   2630 . We employ PyTorch1.4 ( Paszke et al . ,   2017 ) to build our models . We run models up   to 50 epochs ( each epoch takes around 8 mins )   and choose the best ones based on the validation   split evaluation . We use 768 as the hidden size   and use Adam ( Kingma and Ba , 2015 ) as the   optimizer , setting the learning rate to 1×10 .   We initialize the language layer with the pre-   trained BERT weights and cross - attention layers   with the pretrained LXMERT weights . We use   1234/2345/3456 as the random seed values . The   number of trainable parameters of our full model   is 173M. We employ accuracy as the evaluation   metric . We use manual hyperparameter tuning   ( e.g , learning - rate= { 1×10 , ... , 1×10 } , num-   of - cross - layer={1 , 2 , ... , 5 } , batch - size={2,4,6,8 } ,   etc . ) based on validation scores . We use the im-   plementation of Yang et al . ( 2017 ) for the Faster   R - CNN ( Ren et al . , 2015 ) model . The evaluation   splits of our CSIdataset are not overlapped   with the training split of the Faster R - CNN.D Potential Risk   Potential models trained on our dataset may learn   misleading information accidentally and create un-   safe suggestions ; therefore , careful use is required   when deploying models in a real - world applica-   tion.921922923