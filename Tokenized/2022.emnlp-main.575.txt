  Pantea HaghighatkhahAntske FokkensPia Sommerauer   Bettina SpeckmannKevin Verbeek   ♢ TU Eindhoven , Department of Mathematics and Computer Science   ♣ Vrije Universiteit Amsterdam , Computational Linguistics Text Mining Lab   Abstract   Bias elimination and recent probing studies   attempt to remove specific information from   embedding spaces . Here it is important to   remove as much of the target information as   possible , while preserving any other informa-   tion present . INLP is a popular recent method   which removes specific information through   iterative nullspace projections . Multiple itera-   tions , however , increase the risk that informa-   tion other than the target is negatively affected .   We introduce two methods that find a single tar-   geted projection : Mean Projection ( MP , more   efficient ) and Tukey Median Projection ( TMP ,   with theoretical guarantees ) . Our comparison   between MP and INLP shows that ( 1 ) one MP   projection removes linear separability based on   the target and ( 2 ) MP has less impact on the   overall space . Further analysis shows that ap-   plying random projections after MP leads to the   same overall effects on the embedding space as   the multiple projections of INLP . Applying one   targeted ( MP ) projection hence is methodolog-   ically cleaner than applying multiple ( INLP )   projections that introduce random effects .   1 Introduction   Word embedding spaces can contain rich informa-   tion that is valuable for a wide range of NLP tasks .   High quality word embeddings should capture the   semantic attributes associated with a word ’s mean-   ing . Though we can establish that points repre-   senting words with similar semantic attributes tend   to be close to each other , it is challenging to rea-   son which attributes are captured to what extent   and , in particular , which dimensions capture these   attributes ( Sommerauer and Fokkens , 2018 ) . But   even though we do not ( yet ) know exactly which   attributes are represented in which way , we nev-   ertheless may want to ensure that one particular   attribute is no longer present in the embedding . For   example , because this attribute is a protected at-   tribute such as gender which can lead to harmfulbias , or because we want to test how the attribute   was affecting a system in a probing setup .   There are various approaches to remove a par-   ticular attribute from an embedding . Clearly it   is important to remove as much of the target at-   tribute as possible while preserving other informa-   tion present . Arguably linear projections are one of   the least intrusive methods to transform an embed-   ding space . Iterative nullspace projection ( Ravfo-   gel et al . , 2020 , INLP ) is a recent popular method   which follows this paradigm and uses multiple lin-   ear projections . INLP achieves linear guarding of   the protected attribute , that is , a linear classifier can   no longer separate instances that have the attribute   from instances that do not .   However , it remains unclear to what extent INLP   affects the remainder of the embedding space . In   general it requires 10 - 15 iterations ( projections ) to   achieve linear guarding ; it is hence likely that other   attributes are negatively affected as well . This is   particularly problematic in settings where INLP is   used to determine what impact a specific attribute   has on overall systems .   In this paper , we introduce two methods that   find a single targeted projection which achieves   linear guarding at once . Specifically , our Mean   Projection [ MP ] method uses the mean of the   points in each class to determine the projection   direction . The mean is more robust to unbalanced   class distributions than INLP . The mean can , how-   ever , be overly sensitive to outliers . We prove that   our second method , the Tukey Median Projection   [ TMP ] , finds nearly worst - case optimal projections   for any input . Unfortunately , computing the Tukey   median ( Herbert Edelsbrunner , 1987 ) is compu-   tationally expensive in high dimensions . In our   experiments we hence compared only MP to INLP .   Specifically , we carried out the gender debiasing   experiments of Ravfogel et al . ( 2020 ) with both   methods . They show that   1.MP only needs one projection for linearly8395guarding gender where INLP needs 10 - 15 .   2.MP has less impact on other aspects of the   embedding space .   INLP projections improve simlex scores and reduce   WEAT scores more than MP . A priori it is unclear   why their many projections should have this effect .   We investigated and show that the same improve-   ments appear after applying random projections   ( either after MP or after the first INLP projections ) .   Applying one MP projection to linearly guard an   attribute is hence methodologically cleaner than   applying multiple ( INLP ) projections .   2 Related Work   Multiple methods for removing bias from embed-   dings have been suggested . Bias can be addressed   at the level of the training data ( Zhao et al . , 2018a ) ,   the training process ( Zhang et al . , 2018 ; Madras   et al . , 2018 ) , and the resulting model itself ( Ravfo-   gel et al . , 2020 ; Bolukbasi et al . , 2016 ; Vargas and   Cotterell , 2020 ) . Debiasing an existing model has   the clear advantage that it can be done with rela-   tively little data and that the model does not need to   be retrained . In this paper , we focus on removing   bias through transforming the embedding space .   Transformations of embedding spaces can be per-   formed by means of linear projections ( Bolukbasi   et al . , 2016 ) , multiple linear projections ( Ravfo-   gel et al . , 2020 ) , or via non - linear kernels ( Vargas   and Cotterell , 2020 ) . Ravfogel et al . ( 2020 ) intro-   duce a method called Iterative Nullspace Projection   ( INLP ) where they attempt to remove the bias by   projecting points iteratively . Our methods achieve   linear guarding after a single linear projection . As   such we directly improve upon the INLP method ,   which we describe in detail in Section 3 . In the   remainder of this section , we focus on more recent   post - training approaches and applications of INLP .   Similar to Ravfogel et al . ( 2020 ) , Ravfogel et al .   ( 2022 ) aim to find a linear subspace of the data   such that removing that subspace using projection   removes bias in the data optimally . Doing so nec-   essarily requires a metric to measure how well bias   has been removed by a specific projection . Rav-   fogel et al . ( 2022 ) use the classification loss of   various classifiers as metrics . That is , a higher   classification loss after projection corresponds to   better bias removal . This directly translates into a   minimax optimization problem , which the authors   refer to as a minimax game . The authors presentdifferent strategies to solve this optimization prob-   lem for their chosen classifiers . A similar strategy   was previously described by Haghighatkhah et al .   ( 2021 , 2022 ) . Here the corresponding minimax op-   timization problem is referred to as “ maximizing   inseparability ” . Haghighatkhah et al . ( 2022 ) show   that this problem can be solved efficiently under   certain convexity assumptions on the metric .   Zhang et al . ( 2022 ) independently developed a   projection method which is very similar to our MP .   Their method also uses class means to find the   projection direction , but proceeds via a projection   to the origin , and hence needs one additional pro-   jection . The goal of the paper , however , is quite   different , namely the study of human brain reac-   tions to syntactic and semantic features of words .   As such , it does not include a systematic compar-   ison to INLP or a comprehensive analysis of the   impact on the embedding space .   Shao et al . ( 2022 ) in recent and unpublished   work compute linear projection vectors by mini-   mizing the covariance between biased word vectors   and the protected attribute . They generally need   two projections to achieve comparable or better   performance to INLP . The paper does not report on   exactly the same experiments as we do , but for all   experiments reported in both papers , our method   MP performs similarly or better .   Dev et al . ( 2021a ) use a different kind of linear   transformation on embedding spaces , namely ro-   tation . Their goal is to disentangle two particular   attributes , such as gender and occupation . To do so ,   they rotate the embedding space in such as way that   the subspaces corresponding to the two attributes   become orthogonal . On the positive side , their ap-   proach does not remove a dimension and hence ar-   guably retains more information in the embedding .   However , it will not remove all bias with respect   to gender , but only gender bias with respect to a   single specified attribute , e.g. , occupation . More   generally , it will remove the interaction between   the two specified attributes and not actually com-   pletely remove an attribute from the embedding .   INLP has recently gained importance for probing   studies . Probing has been criticized because ( 1 )   results are difficult to interpret , and ( 2 ) it is usually   not possible to test whether the target attribute is   also relevant for downstream tasks . Elazar et al .   ( 2021 ) propose amnesic probing , which employs   INLP to remove the target attribute and then tests   change in performance of the adapted embeddings8396on downstream tasks . INLP has since been used   for this purpose in several other studies ( Celikkanat   et al . , 2020 ; Nikoulina et al . , 2021 ; Babazhanova   et al . , 2021 ; Dankers et al . , 2022 ; Gonen et al . ,   2022 ; Lovering and Pavlick , 2022 , e.g. ) . When   using a projection - based removal method such as   INLP or our MP in a probing setup , it is particularly   important to ensure that all other information is   preserved . If this is not the case , the probing study   may lead to misleading conclusions . We hence   recommend future such studies to consider using   MP instead of INLP .   3 Projection Methods   In this section we introduce our two new projection   methods MP and TMP . Furthermore , we theoreti-   cally analyze their relative performance when ( lin-   early ) debiasing word embeddings , also in compar-   ison to the existing method INLP . Here we focus on   binary classification for ease of explanation . Both   methods can however also be used for multi - class   classification ( see Section 4.1 ) and then require   n−1projections for nclasses . We start with a   formal description of the problem we study .   Our input is a set of word embedding vectors in   R. We interpret these vectors as a set of points   P={p , . . . , p}inRand often use the term   “ point ” when referring to an embedding vector .   Every point ( word ) has an associated set of dis-   crete attributes ( A={a , . . . , a } ) . Let abe the   attribute we aim to remove . For simplicity , we   assume that ais a binary attribute with values   { −1,+1 } . We denote the two resulting classes   of points as P={p∈P|a=−1}and   P={p∈P|a= +1 } . We want to find   a transformation Pof our point set Psuch that   any linear classifier Ctrained on Pto classify a   can not significantly outperform a classifier that la-   bels by the majority class . That is , Pislinearly   guarded with respect to a.   In the following we consider only transforma-   tions which consist of one or more projections . Let   pbe a point in P. We define its projection p   along a unit vector wasp = p−(p·w)w . The   projection along the vector wmaps points to the   hyperplane Hwhich is orthogonal to w(H⊥w )   and contains the origin .   To evaluate how well INLP , MP , and TMP do in   terms of linear guarding , we consider the number   of misclassifications with respect to aby the best   possible linear classifier after a single projection;the higher the number of misclassifications , the   better the method performs . If a single projection is   sufficient to achieve linear guarding , then arguably   the semantic encoding of other attributes in our   word embeddings are preserved as well as possible .   From a theoretical perspective , TMP is the most   effective method ; it increases the number of mis-   classifications the most . However , it is costly to   compute exactly for data in 300 + dimensions . MP   is not as effective in theory as TMP , but it is more   effective than INLP . Furthermore , MP is very easy   to compute and appears to be very effective in prac-   tice . Hence , we evaluate the efficacy of MP exten-   sively in Section 4 and recommend to use MP for   linear guarding in practice .   3.1 INLP   Iterative Nullspace Projection ( Ravfogel et al . ,   2020 , INLP ) debiases by iteratively projecting   along a vector computed by a linear classifier . Here   we assume that this linear classifier is a linear Sup-   port Vector Machine ( SVM ) , as this is the main   classifier used in their paper . In that setting , at each   iteration , INLP trains an SVM to classify ain the   point set P. Since ais binary , the result of the   SVM is a vector w(along with a single real value ,   which we may ignore ) . The input points are then   projected along wand the resulting point set is used   as the input for the next iteration .   IfPcan be separated from Pwith a hyper-   plane , then the vector wis the normal of a sepa-   rating hyperplane and indicates the direction along   which there is the largest gap between PandP :   the SVM margin . If PandPcannot be sep-   arated by a hyperplane , then the classifier allows   misclassifications for a certain penalty , but other-   wise still maximizes the margin . In this setting ,   SVM uses a parameter that controls the trade - off   between misclassifications and the margin .   Analysis . The vector wused in the projection es-   sentially maximizes the gap between PandP ,   and hence it is determined only by the points on the   “ outside ” of PandP. Specifically , if Pand   Pcan be separated , then the vector wcan be de-   termined solely by the points on the convex hulls   ofPandP , and is not influenced by the points   that are interior to the convex hulls . If PandP   are not separable , then wwill be determined by the   points on the convex hulls of the correctly classified8397   points . Thus , if the number of misclassifications is   small , then many of the “ more interior ” points of   PandPstill do not contribute to determining   the projection vector w.   Haghighatkhah et al . ( 2022 ) show that the pro-   jection along wdoes eliminate the existence of   a perfect linear classifier after projection ( that is ,   there must be at least one misclassification ) , but   this is by far not sufficient for linear guarding . We   claim that we must also consider the points interior   to the convex hulls of PandP , if we wish to   obtain an effective projection for linear guarding .   We illustrate this claim with Figure 1 , where P   andPare colored red and blue , respectively . The   black line indicates the hyperplane learned by a   linear SVM and wis the corresponding vector . The   points at the top are distributed roughly evenly in   the convex hull of their class ( the colored polygon ) .   Hence the projection along wis very effective for   linear guarding . The points at the bottom are dis-   tributed unevenly in the same convex hulls . The   same projection along wis now not very effective :   red and blue points can still be separated fairly well   by a linear classifier with relatively high accuracy .   We observe that the distribution of all points   must be taken into account to compute a projec-   tion that is effective for linear guarding . Our two   methods ( MP and TMP ) explore different ways of   incorporating the distribution of the interior points   when constructing the projection vector w.   3.2 Mean Projection ( MP )   Our general goal is to make the distribution of the   points in PandPas similar as possible after theprojection ; that makes it difficult to distinguish the   two sets using a linear classifier . One of the most   characteristic values of a distribution is its mean .   Therefore , in the Mean Projection method we en-   sure that the means of PandPare identical   after projection . Specifically , let µbe the mean of   Pand let µbe the mean of P. We choose the   projection vector simply as w=µ−µ. Note   thatµandµ(and hence w ) can easily be com-   puted efficiently by summing up the coordinates   of the points in each point set and dividing by the   number of points in that set .   Analysis . MP tends to be very effective , since the   majority of the points are typically concentrated   around their mean . Figure 2 compares INLP ( top )   and MP ( bottom ) in a scenario where MP clearly   outperforms INLP with respect to linear guard-   ing . However , we can also directly see a weak-   ness of MP : the mean of a point set can be pulled   into some direction by ( few ) outliers . Figure 4   ( left ) shows another example of this phenomenon .   Hence , there exist theoretical instances where MP   performs quite poorly with respect to linear guard-   ing . However , we demonstrate in Section 4 that   MP is more effective than INLP in practice .   3.3 Tukey Median Projection ( TMP )   As illustrated above , the mean can be influenced by   outliers . Ideally , we would hence like to identify   a “ center point ” for each point set that has roughly   the same number of points in every “ direction ” . In   1D this center point is known as the median . We   therefore consider a higher - dimensional version of   the median as our center point.8398   LetPbe a point set in Rand let q∈Rbe an-   other point which is not necessarily in P. The   Tukey depth t(q)ofqwith respect to Pis the   smallest number of points in Pin any closed half-   space bounded by a hyperplane in Rthat passes   through q. In Figure 3 , qis a point with Tukey   depth 3andqis a point with Tukey depth 5 . A   Tukey median τof a point set Pis a point q∈R   with the maximum Tukey depth with respect to P   among all points in R. Point qin Figure 3 is a   Tukey median of the black points .   Now let τbe a Tukey median of Pand let   τbe a Tukey median of P. Then the projection   vector of the Tukey Median Projection method is   simply w = τ−τ .   Analysis . Figure 4 contrasts MP and TMP . The   mean of the blue point set is clearly not in the cen-   ter of the majority of the points due to the outliers .   As a result , the projection of MP is not very effec-   tive for linear guarding . The Tukey median of the   blue point set , however , remains centered near the   majority of the points and hence TMP is effective .   One may wonder if there is also an example   where TMP performs poorly . We can in fact prove   that TMP in general performs quite well for linear   guarding . Specifically , we can show that the num-   ber of misclassifications after TMP is at least the   minimum of the Tukey depths of τandτ . It   is known that , for every point set PinRwith   npoints , the Tukey median with respect to P   has Tukey depth at least / ceilingleftig / ceilingrightig   ( see , e.g. , HerbertEdelsbrunner ( 1987 ) ) . Finally , we can show that   there exist point sets PandPsuch that , after   any projection along a single vector , the number of   misclassifications is at most O(n / d ) . Thus , TMP is   asymptotically worst - case optimal for maximizing   the number of misclassifications after projection .   The exact theorem statements and their proofs can   be found in Appendix A.   Unfortunately , TMP has one major drawback :   computing the Tukey median of a set of points   is computationally expensive in high dimensions .   Although it is possible to compute an approximate   Tukey median efficiently , the Tukey depth of this   approximation may be significantly worse than that   of the Tukey median ( namely , O(n / d ) ) . Hence ,   we generally recommend to use MP in practice .   4 Experiments   In this section , we present our main experimental   results . We first describe the outcome of the origi-   nal INLP experiments and how our results compare   ( Section 4.1 ) . We then outline the additional ex-   periments we carried out to gain more insight into   surprising results of the original INLP experiments   as well as those of our own method ( Section 4.2 ) .   4.1 Original Experiments   We compare the performance of INLP and MP on   the gender bias experiments reported in Sections   6.1 and 6.3 in Ravfogel et al . ( 2020 ) . We carried   out all experiments with the original ( INLP ) and   our new ( MP ) method . We could successfully re-   produce Ravfogel et al . ’s 2020 results . Since the   results were nearly identical , we report the INLP re-   sults from the original paper . For reasons of space ,   this section only contains the intuition and main   results . We provide a self - contained description8399Experiment INLP MP Interpretation of results   Linear Guarding acc . 34.9 % 34.14 % Similar   non - linear Classification acc . 85.0 % 81.6 % MP slightly better   Effect on Word Neighborhoods - - MP better ( more stable neighborhoods )   Embedding Space simlex-999 corr . 0.489 0.373 INLP better ( * )   WEAT 6 0.008 0.173 INLP better ( * )   WEAT 7 0.084 0.191 INLP better ( * )   WEAT 8 -0.310 0.110 MP better   Bias - by - neighbor 73.4 % 74.5 % Similar   Gender in the wild BOW acc . 77.1 % 76.7 % Similar   Gender in the wild FastText acc . 73.6 % 75.6 % Similar   Gender in the wild BERT acc . 74.7 % 75.2 % Similar   Gender in the wild BOW TPR - GAP 0.111 0.001 MP better   Gender in the wild FastText TPR - GAP 0.103 0.092 Similar   Gender in the wild BERT TPR - GAP 0.065 0.083 % Similar   in Appendix B , where all experimental details can   be found . We use the same settings and metrics as   Ravfogel et al . ( 2020 ) , unless specified otherwise .   Table 1 summarises the results in this section .   General Settings . We use the GloVe word em-   beddings ( Zhao et al . , 2018b)and limit the dataset   to the 150,000 most common words . We create   the same classes of male , female and neutral em-   beddings as Ravfogel et al . ( 2020 ) following their   approach . A male vector ⃗Mis defined as ⃗he−⃗she   and a female vector ⃗Fas⃗she−⃗he . Our male   dataset consists of the 7500 data points closest to   ⃗Mand our female dataset to the 7500 data points   closest to ⃗F. We use the same random selection of   7500 neutral words with a cosine similarity of less   than 0.3 to ⃗Mas Ravfogel et al . ( 2020 ) .   We include experiments on two classes ( femi-   nine andmasculine ) and on three classes ( feminine ,   masculine andneutral ) . The INLP method uses   the datasets to train SVM classifiers as described   above . For the MP method , let ⃗ v,⃗ vand⃗ vbe   the mean of respectively feminine , masculine and   neutral labeled points of a given set D. Then in   experiments on two classes the mean projection   method uses the ⃗ v−⃗ vvector for projection .   For experiments with all three classes , we use both   ⃗ v−⃗ vand⃗ v−⃗ vvectors for projection .   Linear Guarding . We first compare the process   of obtaining linear guarding using INLP and MP .   Figure 4 illustrates the decrease in accuracy of a   linear classifier trained to identify gender . The   Mean Projection method brings down the accuracy   to 34.18 % . It takes INLP 12 iterations to reach a   comparable result of 34.9 % or at least 6 iterations   to reach 39.9 % accuracy . Figure 8 in Appendix B   shows a similar pattern for binary classification ,   where MP reaches 50.6 % and INLP needs 14 itera-   tions to drop to 50.51 % .   Classification . Both methods aim to remove lin-   early encoded information . Ravfogel et al . ( 2020 )   test to what extent the non - linear encoding of gen-   der remains intact by running a 1 - hidden - layered   MLP with ReLU activation and report 85.0 % after   35 iterations with INLP . After a single MP projec-   tion , accuracy of the MLP drops to 81.6%.8400Effect on the Embedding Space . Ravfogel et al .   ( 2020 ) show changes in the three nearest neighbors   of 40 randomly selected words and 22 gendered   given names ( see Tables 6 and 7 in Appendix D ) .   MP keeps these environments more stable changing   8 out of 120 neighbors compared to 43 for INLP for   random words . MP changes 24 and INLP 56 tokens   out of 66 neighbors of the given names . We also   observe that 14 of the 24 changes are other given   names ( 5 of which of opposite gender ) . With INLP ,   46 new tokens are not regularly spelled names .   Ravfogel et al . ( 2020 ) also investigate how INLP   impacts semantic similarity scores on multiple   datasets reporting an increase of results , e.g. from   0.373 to 0.489 on simlex-999 . Applying MP has   less impact with a result of 0.385 . This confirms   that MP has less impact on the overall space , but   also raises the question whether the additional   changes caused by INLP ’s extra projections is a   positive effect . We investigate this in Section 4.2 .   WEAT . Caliskan et al . ( 2017 ) evaluate bias in   embeddings by comparing the distance of known   stereotypical terms to terms that are either explic-   itly male or explicitly female . A higher WEAT   score means that stereotypical terms are indeed   closer to their stereotyped gender . Like Ravfogel   et al . ( 2020 ) we use gendered names for represent-   ing attributes and take the targets of WEAT 6 , 7 , and   8 . MP achieves WEAT scores of 0.173 , 0.191 and   0.110 respectively . The first INLP iteration yields   scores of 0.278 , 0.347 , 0.203 and the full 35 iter-   ations reach 0.008 , 0.084 and -0.310 respectively .   We investigate this in Section 4.2 .   Bias - by - neighbor . Gonen and Goldberg ( 2019 )   propose an evaluation that checks whether the 100   nearest neighbors of a term after debiasing carried   the same gender bias before debiasing . Ravfogel   et al . ( 2020 ) show that INLP reduces the gender   bias of Bolukbasi et al . ’s 2016 set of stereotypical   professions from 85.2 % to 73.4 % . MP reaches a   comparable reduction ( 74.5 % ) .   TPR - GAP : “ gender in the wild ” . De - Arteaga   et al . ( 2019 ) propose an approach that measures to   what extent debiasing methods can remove gender   bias from a system that predicts occupations based   on biographies . A fair system should have equal   performance for members of different classes and   not amplify a bias that is present in the label distri-   bution ( Hardt et al . , 2016 ) . In the case of gender ,   the system should perform equally well predict - ing occupations such as surgeon , caretaker , secre-   tary or marine , regardless of whether the biograph-   ical texts are about men or women . De - Arteaga   et al . ( 2019 ) use the GAPscore to measure   this . The GAP , e.g. , quantifies to what extent a   given occupation is more probable to be predicted   correctly for biographies of women compared to   biographies of men . A good debiasing approach   should obtain a GAPscore that is close to   zero while maintaining the classification accuracy   that was obtained before debiasing .   Instead of directly debiasing embeddings , we de-   biase representations of entire biographies within   the occupation classification system . Like Ravfo-   gel et al . ( 2020 ) , we use logistic classifiers that take   one of three representations of the biographies as   input : ( 1 ) one - hot BOW , ( 2 ) averaged FastText em-   beddings ( Joulin et al . , 2017 ) and ( 3 ) the last hidden   state of BERT ( Devlin et al . , 2019 ) . The projections   are applied using Pedregosa et al . ( 2011 ) .   In both approaches , biography representations   are debiased on the basis of their gender nullspace   for each of the 28 occupations . For the MP setup ,   we create a mean projection for every occupation   oby identifying the projection vector Pbased on   the mean of all female and the mean of all male   biographies with occupation o. The INLP setup   uses logistic regression in 100 iterations for the   BOW representations , 150 linear SVM iterations   for FastText representations and 300 linear SVM   iterations of for the BERT .   Overall , results of both methods are comparable .   INLP maintains a higher accuracy on identifying   professions for one - hot BOW ( 77.1 % vs 76.7 % ) ,   where MP has higher accuracy for FastText ( 75.6 %   vs 73.6 % ) and BERT ( 75.2 % vs. 74.7 % ) . For BOW ,   the GAP score drops by 99.4 % when using MP   compared to 35 % for INLP . Differences for other   representations are smaller : MP reduces GAP by   49.5 % on FastText compared to INLP ’s 43.4 % . For   the BERT model , INLP outperforms MP reducing   the GAP by 64.3 % compared to MP ’s 52.2 % . See   Table 5 in Appendix B for the full results .   Summary . In general , we observe that a single   MP projection achieves linear guarding where mul-   tiple INLP projections are needed and that the rest   of the space remains more stable . The improve-   ment of similarity results , as well as INLP ’s results   on WEAT , raise further questions . Ravfogel et al .   ( 2020 ) hypothesize that the improvied similarity re-   sults may be due to a significant gender component8401 in embeddings that does not correlate with human   similarity judgment ( Ravfogel et al . , 2020 , p. 7253 ) .   Together with the increased drop in WEAT , this   may point to 35 INLP iterations removing more   gender information than the single MP projection .   This is countered by the result of the non - linear   classifier where MP induced a larger decrease than   INLP . We investigate the results on similarity and   WEAT further in the next subsection .   4.2 Diving Deeper   Simlex-999 . We first dive into the impact of   INLP on simlex-999 ( Hill et al . , 2015 ) . Figure 5   illustrates the changes in similarity scores ( Corre-   lation ) after every iteration of INLP compared to   MP ( one projection ) . We observe that the scores   mainly increase between the 8th and 14th itera-   tion , remaining relatively stable before and after-   wards . Going back to Figure 4 , we observe that   this increase thus starts when the INLP projections   have almost dropped to majority class accuracy , i.e.   linear guarding . The main increase in similarity   scores thus occurs after gender encoding has been   removed , which could imply that the increased re-   sult is not related to gender . We investigate this by   comparing the impact of INLP iterations to itera-   tions that project the dataset along random vectors .   We compare three scenarios : directly applying   35 iterations with random projections to the origi-   nal model [ Random ] , adding 34 random projection   iterations after one MP projection [ MP+R ] and   adding 27 random projection iterations to 8 INLP   projections ( the point where the score starts to in-   crease ) [ INLP-8+R ] . We carry out 500 runs of this   experiment and report the 95 % confidence interval   of similarity correlation scores for each setting in95 % CI Mean Std .   INLP-8+R [ 0.47,0.50 ] 0 .486 0 .009   MP+R [ 0.46,0.50 ] 0 .478 0 .009   Random [ 0.43,0.46 ] 0 .447 0 .009   Table 2 . Running 35 iterations of INLP increased   the semantic similarity score from 0.373 to 0.489 .   This improvement falls within the confidence in-   terval of MP+R and INLP-8+R. Results of random   projections only [ Random ] do not reach this score ,   but still clearly improve compared to the original   0.373 with a mean score of 0.447 . We thus con-   clude that the improvement in similarity scores are   due to reducing dimensions in general rather than   removing ( partial ) representations of gender .   WEAT . We investigate the WEAT scores in a   similar manner . We first inspect the impact on the   WEAT score per INLP iteration and then compare   this to the impact of projections along weighted   random vectors . Figure 6 illustrates the impact of   applying INLP for 35 iterations ( blue line ) and 34   random projection iterations applied after applying   MP method ( 500 runs ) . Recall that an ideal WEAT   score would be close to zero . We observe that   MP+R on average ends up with an equal score for   WEAT 6 , a slightly higher positive ( thus worse )   score for WEAT 7 and close to zero for WEAT 8   where INLP results in a negative score .   We also compare the effect of applying ran-   dom projections after 8 INLP iterations . INLP-   8+R shows similar results as MP+R. Applying ran-   dom projections from the start [ Random ] leads to   slightly increasing WEAT scores in most cases ( see   Figures 9 and 10 in Appendix C ) . This implies ne-   cessity of the first step in removing gender to make   a reduction of WEAT by random projections .   We now turn back to what this means for iter-   ative nullspace projections . When inspecting the   blue lines in Figure 6 , we observe that all WEAT   scores initially drop to the same level as with MP   after 2 - 4 iterations and then increase again . Be-   tween 20 and 25 iterations we observe a sharp drop ,   even flipping to a bias in the opposite direction for   WEAT 8 . These patterns do not reveal a consistent   positive impact of applying additional nullspace   projections . Ethayarajh et al . ( 2019 ) report that   results obtained by applying WEAT are brittle and   that statistically significant results in opposite di-   rections can be obtained depending on the attribute8402   words selected . They show this in a highly simpli-   fied setting ( using only one attribute word at the   time ) . Nevertheless , the WEAT sets are relatively   small ( 8 attributes and targets per set ) and some of   the results we see could be the effect of the specific   selection of terms in the set . Overall , this makes   the results even more difficult to interpret . We can   say , however , that a single MP and the first INLP   projections seem beneficial for decreasing WEAT   and there is no evidence that continuing iterations   of INLP further removes gender bias .   Summary . Our further investigations showed   that ( 1 ) increases in simlex-999 scores occur very   locally after gender has been removed and that ( 2 )   both for similarity and WEAT , random projections   after MP or a limited number of INLP iterations   lead to similar results as 35 INLP iterations . We   therefore conclude that the side effects of continu-   ing to apply INLP are not related to the overall goal   of removing encoding of gender , but rather related   to the overall effect of dimension reduction .   5 Conclusion   This paper started from the idea that one targeted   projection results in similar linear guarding and   more stability of the remaining space compared to   iterative nullspace projections . We proposed two   methods to find such projections : Mean Projec-   tion ( MP ) and Tukey Median Projection ( TMP ) .   We compared performance of Mean Projection ,   which is still susceptible to outliers but more ef-   ficient to compute than TMP , to the gender based   experiments using 35 Iterative Nullspace Projec-   tions ( INLP ) reported in Ravfogel et al . ( 2020 ) .   Our results show that MP obtains comparable   linear guarding in one projection where INLP re-   quires multiple iterations . They also confirm thatthe rest of the space remains more stable through   fewer changes in nearest neighbors of randomly   chosen words and similarity scores that are closer   to the original scores compared to INLP . Two re-   sults led to further questions : similarity scores im-   proved after applying INLP and INLP resulted in   better WEAT scores than MP . We conducted addi-   tional experiments to test whether the extra debias-   ing iterations performed in INLP end up removing   more subtle representations of gender bias that are   missed by the single MP iteration .   The results show that it is unlikely that INLP   can indeed remove more subtle representations of   bias for two reasons : ( 1 ) we observed that most   effects occur once linear guarding has already been   achieved . ( 2 ) More importantly , similar perfor-   mance is obtained by running random projections   after either MP or the first 8 INLP iterations . We   therefore conclude that these additional effects are   not related to removing representations of the tar-   geted attribute , but rather a side effect of reducing   the dimensionality of the space . This leads us to the   overall conclusion that a single targeted projection   is indeed preferable over iterative nullspace pro-   jections when aiming to remove an attribute . This   finding is particular important for the recent line of   research that uses INLP for interpretability : these   studies test the effect of removing a target attribute   and their conclusions should not be confounded by   other changes to the space .   Our theoretical findings in Section 3 suggest that   MP might produce poor results for skewed data .   Hence we plan to analyze MP more rigorously on   synthetic data , specifically , data where the points   are not centered around the mean . In this way   we hope to identify scenarios where MP produces   poor projections ; subsequently we can test if TMP   produces better projections for the same scenarios.84036 Limitations   The methods we described and evaluated in this   paper have the following limitations .   Dependence on labelled attribute data . The   results of all projection methods ( INLP , MP and   TMP ) directly depend on the representativeness of   the labelled data points that are used to identify   the projections . All methods would suffer from   non - representative points . In addition , outliers can   hamper the effectiveness of MP .   Binary gender . The binary perspective on gender   used in our experiments does not reflect the reality   of non - binary gender identities . These experiments   focus on gender bias in the form of stereotypical   associations with binary gender identities . The un-   derrepresentation of non - binary gender references   ( e.g. singular they , them in English ) is another form   of bias that also affects NLP systems . Recent work   has shown that current NLP technologies indeed   have difficulties dealing with non - binary gender   references ( Dev et al . , 2021b ; Brandl et al . , 2022 ,   e.g. ) . To our knowledge , the question of whether   language models also contain stereotypes around   non - binary gender has not been addressed yet . If   such bias is indeed present , data sparseness is likely   to pose a problem for the methods described in this   paper .   Suitability for language with grammatical gen-   der is unclear For the application of gender bias ,   we note that all experiments are run on English .   In particular for languages with grammatical gen-   der , it is unclear whether these projections would   be able to identify semantic gender bias correctly   while avoiding to remove grammatical characteris-   tics of the language : words with the same seman-   tic gender will almost always also have the same   grammatical gender . Projections are likely to re-   move this highly distinctive feature which is also   a grammatical property . Its removal may impact   downstream applications .   Linear guarding only . The methods described   here aim only at ( and achieve only ) linear guard-   ing . This means that non - linear representations of   the attributes remain present in the data ( e.g. the   one - hidden layered perceptron still achieves an ac-   curacy of 85.0 % after 35 INLP iterations and 81.6 %   after applying MP on binary classification).7 Ethics   We applied our method to gender debiasing . The   approach aims to remove bias which can be seen   as helping to address an ethical issue , rather than   causing one . Nevertheless , we feel it is important   to point out the following . When using the meth-   ods discussed in this paper to remove a protected   attribute , with the idea to avoid harmful bias , the   limitations outlined above must be taken into ac-   count . This concerns both potential limitations   of the effectiveness of the approach and the treat-   ment of gender as a binary variable . Concerning   effectiveness , this means considering the fact that   ( 1 ) non - linear representations are not addressed by   these methods and ( 2 ) the success of the approach   is directly dependent on the quality of data used to   identify the projections . Concerning the treatment   of non - binary gender , it should be kept in mind that   ( 1 ) to our knowledge , not much is known yet about   stereotypical representations of non - binary gender   in language models ( 2 ) it is known that current NLP   methods experience difficulties in dealing with non-   binary gender . In general , debiasing methods must   always be carefully evaluated to avoid that users of   a system assume the problem is solved , when this is   not ( completely ) the case . Ideally , such evaluation   should look beyond the scope of the target . When   dealing with gender , this should include looking   at what models are doing with non - binary gender   references .   In practice , the considerations outlined above   mean the following : We do not claim that any of   the approaches presented in this paper can fully re-   move bias from embedding representations . When   using debiased embeddings as part of a system ,   we strongly advise to conduct a critical evaluation   with respect to potentially remaining bias using   data that are representative of the use - case . This is   particularly important if the use - case encompasses   the potential for discrimination ( e.g. automatic CV   analysis ) .   References840484058406A Tukey Median Projection   Theorem 1 . Letqbe a point with Tukey depth   t(q)with respect to Pand let qbe a point   with Tukey depth t(q)with respect to P. Then   the projection of Palong vector w = q−qen-   sures that any linear classifier must make at least   min(t(q ) , t(q))misclassifications after projec-   tion .   Proof . Letτbe the Tukey medians of PandP   after projection ( by construction , these Tukey medi-   ans have been projected onto the same point ) . Now   letHbe the hyperplane corresponding to some   linear classifier after projection . Let Hbe the   hyperplane obtained by shifting Hto contain the   point τ . LetHbe the halfspace bounded by H   that contains the majority of Pafter projection ,   and let Hbe the other halfspace bounded by H.   By construction of τ , there must be at least t(q )   points of PinHand at least t(q)points of   PinH , which are misclassified by the linear   classifier defined by H. By shifting the hyper-   plane back from HtoH , we can see that either   the misclassified points of Por the misclassified   points of Premain misclassified by the linear   classifier defined by H. Thus , any linear classifier   must misclassify at least min(t(q ) , t(q))points   after projection by TMP .   We can show that TMP is asymptotically worst-   case optimal in minimizing the number of misclas-   sifications after projection . For that we need the   following technical lemma .   Lemma 1 . Let∆be the regular d - dimensional   simplex embedded in Rsuch that the center of   ∆lies at the origin and the d+ 1vertices of ∆ ,   represented by the vectors v , . . . , v , are at unit   distance from the origin . For any point p∈R ,   there exist a unit vector rsuch that ( v·r)≤   ( p·r)−for at least dvertices of ∆.   Proof . As the vectors v , . . . , vspan the en-   tirety of R , we can write pas an affine combina-   tionp=/summationtextαv , where / summationtextα= 1 . With-   out loss of generality , let αbe the largest coeffi-   cient among all αfor1≤i≤d+ 1 . We pick   r = v. Since ∆is a regular simplex , it is known   that(v·v ) = forv̸=v . Using the linearityof the dot product , we now get the following :   ( p·r ) = /summationdisplayα(v·r )   = α−1   d / summationdisplayα   ≥α−1   d / summationdisplayα   = α(1−d   d )   = 0 .   On the other hand we have that ( v·r ) = for   allv̸=v , and hence the stated inequality holds   for all v̸=v .   We can now prove our main result .   Theorem 2 . For any d > 0andn≥m > 0 , there   exist point sets Pofmpoints and Qofnpoints   inR , such that for any projection of PandQ   along a unit vector w , there exists a hyperplane   HinRwith at least / floorleftig / floorrightig   points of Pon one   side of Hand all points of Qon the other side of   Hafter projection .   Proof . Lete , . . . , ebe the basis vectors span-   ningR. We first prove the statement for the   case that m = d+ 1 . Specifically , let Pbe formed   by the vertices of the regular d - dimensional sim-   plex ( as in Lemma 1 ) centered at the origin and   restricted to the d - dimensional subspace spanned   by the first dbasis vectors e , . . . , e. Furthermore ,   letQbe an arbitrary set of npoints such that all   points are within Euclidean distance less than εof   the center point q= ( 0 , . . . , C ) ( for some C > 0   andε > 0 ) inR.   Letwbe any unit projection vector . We write   wasw = αe+βz , where zis a unit vector   in the subspace spanned by e , . . . , e(such that   we have α+β= 1 ) . Let qbe the center of   Qafter projection along w. It is easy to see that   PandQare linearly separable after projection if   ∥q∥ ≥1+ε(the center of Premains at the origin   after projection ) . We have that :   q = q−(w·q)w   = Ce−αC(αe+βz )   = eC(1−α)−αβCz .   Since zis independent from ewe get that   ∥q∥ ≥C(1−α ) = Cβ , and hence ∥q∥ ≥84071 + εifβ≥. We may therefore assume that   β < .   Now let xbe the d - dimensional point obtained   by omitting the ( d+ 1)coordinate of q. We   apply Lemma 1 to Pwithp = xto obtain a cor-   responding unit vector r. We extend rwith an   additional coordinate with the value 0to obtain the   ( d+ 1 ) -dimensional vector R= ( r,0 ) . We then   define the hyperplane Has the hyperplane that sat-   isfies ( p·R ) = ( q·R)−εfor points p∈R.   We now show that Hhas the desired properties .   Letube one of the dpoints of Psuch that ( u ·   r)≤(x·r)− , and let ube the point obtained   by projecting ualong w. We get that :   u = u−(w·u)w   = u−β(z·u)w   = u−βw ,   where β∈[−β , β ] . By construction of x , we   also get that ( x·r ) = ( q·R ) . We then get the   following :   ( u·R ) = ( u·R)−β(w·R )   = ( u·r)−ββ(z·R )   ≤(u·r ) + β   ≤(x·r ) + β−1   d   = ( q·R ) + β−1   d.   Thus , if β−<−ε , then ( u·R)<(q·R)−ε .   Since β < , we can choose C= 4dand   ε = to ensure this property , as then−<−=−ε .   Now let vbe one of the points of Q , and let   vbe the point obtained by projecting valong   w. Since the projection along wcan only shrink   distances , we get that ∥v−q∥ ≤ ∥ v−q∥ < ε .   This implies that ( ( v−q)·R)>−ε , which can   be rewritten as ( v·R)>(q·R)−ε . As a result ,   dpoints of Pare on one side of Handnpoints of   Qare on the other side of H , as required .   IfPcontains m̸=d+ 1points , then we can   simply follow the construction above and distribute   the points arbitrarily close to the vertices of the   regular simplex , such that there are at at most / ceilingleftig / ceilingrightig   points around each vertex . As a result , n   points of Qwill be on one side of Hand at least   m−/ceilingleftig / ceilingrightig   = /floorleftig / floorrightig   points of Pwill be on the   other side of H , which completes the proof . Corollary 1 . For any d > 1andn≥m > 0 , there   exists a set of points PinRwith|P|=mand   |P|=nsuch that , for any projection of Palong   a single unit vector w , the number of misclassifi-   cations of the best possible linear classifier after   projection is at most / ceilingleftbig / ceilingrightbig   .   Proof . Choose Pand the binary attribute asuch   thatPandPmatch PandQin the statement of   Theorem 2 ( note that the theorem has to be applied   with dimension d−1 ) . Then , for any projection of   Palong a single vector , there exists a hyperplane   Hsuch that / floorleftig / floorrightig   points of Pare on one   side of Hand all points of Pare on the other   side of H. Thus , the linear classifier defined by   Hmisclassifies at most / ceilingleftbig / ceilingrightbig   points , and hence the   best possible linear classifier must perform at least   as well .   We now return to the number of misclassifica-   tions caused by TMP . It is known that , for every   point set PinRwithnpoints , the Tukey median   with respect to Phas Tukey depth at least / ceilingleftig / ceilingrightig   .   As a result , by using the projection of TMP , any   linear classifier must make at least / ceilingleftig / ceilingrightig   misclas-   sifications after projection by Theorem 1 , where m   is the size of the smallest set among PandP.   In the worst - case , this nearly matches the upper   bound of / ceilingleftbig / ceilingrightbig   according to Corollary 1 .   B Experiments   For convenience , we provide a detailed self-   contained description of the experiments here . The   first paragraph is an exact repetition ( included here   for convenience ) . All others are extended versions   of the one included in the main text . This version   can be read either instead of or next to the shorter   version in the main text .   General Settings . We use the GloVe word em-   beddings ( Zhao et al . , 2018b)and limit the dataset   to the 150,000 most common words . We create   the same classes of male , female and neutral em-   beddings as Ravfogel et al . ( 2020 ) following their   approach . A male vector ⃗Mis defined as ⃗he−⃗she   and a female vector ⃗Fas⃗she−⃗he . Our male   dataset consists of the 7500 data points closest to   ⃗Mand our female dataset to the 7500 data points   closest to ⃗F. For the neutral dataset we use Rav-   fogel et al . ’s 2020 seed to obtain the same random8408selection of 7500 words with a cosine similarity of   less than 0.3 to ⃗M.   We include experiments on two classes ( femi-   nine andmasculine ) and on three classes ( feminine ,   masculine andneutral ) . The INLP method uses   the datasets to train SVM classifiers as described   above . For the MP method , let ⃗ v,⃗ vand⃗ vbe   the mean of respectively feminine , masculine and   neutral labeled points of a given set D. Then in   experiments on two classes the mean projection   method uses the ⃗ v−⃗ vvector for projection .   For experiments with all three classes , we use both   ⃗ v−⃗ vand⃗ v−⃗ vvectors for projection .   Linear Guarding . The first set of experiments   illustrates the process of gender information being   removed from embeddings using each method . We   apply the INLP and MP algorithms to the data la-   beled feminine , masculine and neutral described   above and investigate to what extent a linear clas-   sifier can still identify the original gender of the   word . The results of this classifier should decrease   as gender information is removed from the set . For   INLP , we use a L2 - regularized SVM with the same   parameters and random seeds as Ravfogel et al .   ( 2020 ) . We can observe changes over the course of   performing multiple projections for INLP . For MP ,   only a single projection is needed .   We test the classifier on the same train , test and   development set as Ravfogel et al . ( 2020 ) . The   dataset contains three classes ( feminine , maschu-   line and neutral ) . Like Ravfogel et al . ( 2020 ) , we   report the results for all three classes as well as two   classes ( male and female ) . Since all classes are   equally distributed , we report on the classifiers ac-   curacy . A set of completely debiased embeddings   should yield a result that is equal to chance .   Figure 7 presents the results of 35 iterations of   INLP and the single iteration of MP on three classes   of the data . Before applying projections , a linear   classifier achieves perfect classification . The mean   projection method brings down the accuracy to   34.18 % . It takes INLP 12 iterations to reach a com-   parable result of 34.9 % or at least 6 iterations to   reach 39.9 % accuracy . We repeat the experiment   on two classes ( masculine and feminine ) and pro-   vide the results in Figure 8 . Here after applying the   MP method , an accuracy of 50.6 % is reached while   INLP needs 14 iterations to get down to 50.51 %   accuracy . These results show that with MP , one   projection is enough whereas multiple projections   are needed to achieve a similar result with INLP .   100   80   60   40   20   Accuracy ( % )   # projections   10   5   15   20   25   30   35   0   MP   INLP   The results of INLP stabilizes at approximately the   same result as MP ’s single projection .   Classification . Both methods only aim to remove   linearly encoded information . We compare to what   extent they leave non - linear encoding of gender   in tact by running a 1 - hidden - layered MLP with   ReLU activation . This MLP manages to identify   gender with 85.0 % after 35 iterations . After a sin-   gle MP projection , accuracy of the MLP drops to   81.6 % . Overall these results confirm that MP needs   a single projection to achieve equal linear guard-   ing as multiple INLP projections and a comparable   ( slightly better ) result on the remaining non - linear   encoding .   Clustering . Another way of assessing the debi-   asing methods is to test to what extent the embed-   dings can still form clusters representative of the   male and female class . If the bias has been removed   successfully , the clusters should no longer reflect   gender bias information . We use the V - measure   ( Rosenberg and Hirschberg , 2007 ) to assess to what   extent the two classes are intertwined . This mea-   sure is the harmonic mean of two components : ho-   mogeneity ( reflecting how many points in a cluster8409belong to the same class ) and completeness ( re-   flecting how many points of a class ended up in   the same cluster ) . The homogeneity component   assesses to what extent samples of a single cluster   have the same class i.e. are similar . Complete-   ness on the other hand measures to what extent   data points with the same labels are in the same   cluster . A perfect V measure ( score 1.0 ) indicates   perfect clustering with respect to the gold labels ,   where equal distribution of class members from all   classes over all clusters yields a score of 0 . We   apply K - means clustering with K= 2to the male   and female gendered words in the test split , then   we calculate the V - measure .   We use the 2000 most biased female and male   words as Ravfogel et al . ( 2020 ) suggests . Using   the MP method reduces the V - measure to 0.53 %   after a single projection . The V - measure reaches   0.67 % after applying the INLP method with all 35   iterations on the this set .   Exploring Neighbors . We inspect changes in the   direct environment of 40 words randomly selected   by Ravfogel et al . ( 2020 ) as well as their selection   of 22 gendered given names . If a debiasing method   is targeted , it should not affect the neighbors of the   randomly selected words and only lead to changes   in the neighborhood of the words that should be   affected by debiasing ( in this case the 22 gendered   given names , where new name of the opposite gen-   der may appear ) .   When applying MP , only 8 out of 120 neighbors   of random words changed , compared to 43 after   changes caused by INLP . For given names , MP   yielded 24 changes out of 66 compared to 56 for   INLP . Overall , it seems that INLP leads to more   changes in the neighborhoods of words targeted by   debiasing as well as other words .   Upon manual inspection , we observed that MP   mainly leads to names being replaced by other   given names in the neighborhood of gendered   names ( 14 times , 5 times a name of opposite gen-   der ) . INLP ’s new contexts contain more common   nouns and rare non - given names ( 46 tokens that end   up in the immediate context of a gendered name   are not regularly spelled given names ) . Another   noticeable difference is that MP appears to have   moved the name Ariel to its interpretation of a loca-   tion , whereas it ended up near other terms related   to Disney after applying INLP . The full results can   be found in Tables D and 7 in Appendix D.Similarity Experiments Word debiasing meth-   ods should only affect information that reflects the   bias and leave the rest of the space unchanged . We   investigate the effects of both debiasing methods on   three word similarity datasets , namely , simlex-999 ,   Sim353 ( both relatedness and similarity dataset )   and Mturk-771 . The datasets can serve as a re-   flection of how the debiasing methods affect the   semantic space . While it is possible that the sim-   ilarity datasets contain gendered words , it can be   assumed that the majority of word pairs does not   have an explicit gendered meaning . We verify this   assumption by means of manual analysis of the   simlex-999 pairs and found 62 pairs where one or   both terms had a meaning that explicitly contains   gender . Our manual annotations can be found in   our Github repository . We report the Spearman   correlation between the similarity scores given by   the annotators and the cosine distance before and   after debiasing with INLP and MP in Table 3 .   The results on these similarity tests remain rela-   tively stable after applying MP , whereas we see a   clear increase in correlation sores after INLP is ap-   plied . This result confirms that the overall embed-   dings change less when applying MP compared to   INLP . The observed improvement caused by INLP   indicate that more research is needed to determine   how INLP affects the entire semantic space . If iter-   active projections can improve the overall quality ,   the additional effect they have on the space may   actually be desirable . In particular , Ravfogel et al .   ( 2020 ) hypothesize that this increase may be due   to words in the datasets containing a gender com-   ponent which is not perceived by humans , but do   not investigate the matter further . We further ex-   plore this possibility in our additional experiments   described in Section 4.2 ( see main content above ) .   WEAT . Caliskan et al . ( 2017 ) propose the Word   Embedding Association Test ( WEAT ) that can mea-   sure bias inferred by the semantic similarity be-   tween groups of words . We have two groups of8410target words for instance T={programmer , pro-   fessor , engineer , . . . } , T={nurse , teacher , librar-   ian , . . . } and two set of attribute words A= {   man , male , masculine , . . . } , A={woman , fe-   male , feminine , . . . } . If the word embeddings rep-   resenting these target words are not biased , then   the relative similarities between the target words   ( T , T ) and attributes ( A , A ) should be equiva-   lent . In other words : words such as secretary and   programmer should not be more similar to either   of the two groups of gendered attributes .   WEAT measures the association between the tar-   get groups and attributes : a biased representation   is expected to maintain this association ( reflected   by a high score ) , whereas WEAT scores on repre-   sentations with low to no bias should be close to   zero . A WEAT score of 0 indicates that words from   the target groups are , on average , equally strongly   associated with AandA. Like Ravfogel et al .   ( 2020 ) , we follow Gonen and Goldberg ( 2019 ) and   represent the attributes through gendered names   rather than attributes . We then take the target words   of the same the three tests used by Ravfogel et al .   ( 2020 ) ( WEAT 6 , WEAT 7 andWEAT 8 ) in Table 4 .   WEAT ( 6 ) includes targets words referring to career   and family attributes , WEAT ( 7 ) has target words   related to math and art and WEAT ( 8) has science   and art target words .   Both MP and INLP reduce the WEAT scores .   ForWEAT 6 and7 , 35 INLP projections lead to   the largest reduction . For WEAT 8 , MP provides   the best results followed by a single INLP itera-   tion ( rather than the full 35 ) . The negative value   ofWEAT 8 indicates a stronger bias in opposite di-   rection that the remaining bias present after the   first INLP iteration or after the MP projection .   This leads us to wonder how to interpret these   results . We therefore investigate them further in   Section 4.2 .   Bias - by - neighbor . Gonen and Goldberg ( 2019 )   show that even if a debiasing method manages   to remove a biased vector from explicitly gender   words , it may still be close to other words with   the same stereotypical connotation ( e.g. nurse re-   mains close to receptionist andteacher ) . The bias-   by - neighbors measure captures such remaining   bias by providing the percentage of the 100 closestOriginal   WEAT 6 WEAT 7 WEAT 8   0.738 0.584 0.467   INLP-35   WEAT 6 WEAT 7 WEAT 8   0.008 ( -98 % ) 0.084 ( -86 % ) |-0.310| ( -34 % )   INLP-1   WEAT 6 WEAT 7 WEAT 8   0.278 ( -62 % ) 0.347 ( -41 % ) 0.203 ( -56 % )   MP   WEAT 6 WEAT 7 WEAT 8   0.173 ( -76 % ) 0.191 ( -66 % ) 0.110 ( -76 % )   words that were male - biased in the original dataset .   For completely debiased word embeddings , this   percentage should be around 50 % ( with half of the   words being ( slightly ) biased to one gender and the   other half of the words to the other ) . This measure   is applied to a set of biased professions provided   by Bolukbasi et al . ( 2016 ) , which originally has a   bias score of 85.2 % . INLP reduces this score to   73.4 % and MP to 74.5 % . Both methods thus yield   comparable results that reveal that bias is reduced   but not completely removed .   TPR - GAP : “ gender in the wild ” . De - Arteaga   et al . ( 2019 ) propose an approach that considers the   impact of bias on downstream classification tasks .   The approach measures to what extent debiasing   methods can remove gender bias from a system   that predicts a person ’s occupation based on a biog-   raphy describing them . A fair system should have   equal performance for members of different classes   ( Hardt et al . , 2016 ) . Specifically , it should not am-   plify a bias that is present in the label distribution .   In the case of gender , the system should perform   equally well predicting stereotypically gendered   occupations such as surgeon , caretaker , secretary   or marine , regardless of whether the biographical   texts are about men or women . De - Arteaga et al .   ( 2019 ) use the GAPscore to measure to what   degree the performance of a classification system   is impacted by bias . The score is calculated as fol-   lows : TPR(Equation 1 ) is the true positive rates   for a given profession ( y ) and gender ( g ) . TPR-8411GAP Gapis the difference ( gap ) between true   positive rates ( TPR ) of gender gand its opposite   gender ∼gin a given occupation y(Equation 2 ) .   In order to calculate a single measure for bias in all   occupations Romanov et al . ( 2019 ) take the root-   mean square of the TPR - GAPs for all occupations   ( Equation 3 ) .   TPR = P[ˆY = y|G = g , Y = y ] ( 1 )   Gap = TPR−TPR ( 2 )   GAP=/radicaligg   1   |C|/summationdisplay(GAP)(3 )   We obtain 393,423 biographies from Ravfogel   et al . ( 2020 ) which is a subset of the original corpus   of De - Arteaga et al . ( 2019 ) describing people with   28 different occupations . We split the data in the   same 65 % training , 10 % development and 25 % test   splits as used by De - Arteaga et al . ( 2019 ) and Rav-   fogel et al . ( 2020 ) . Like Ravfogel et al . ( 2020 ) , we   use logistic classifiers that take one of three repre-   sentations of the biographies as input : ( 1 ) one - hot   BOW , ( 2 ) averaged FastText embeddings ( Joulin   et al . , 2017 ) and ( 3 ) the last hidden state of BERT   over the [ CLS ] token .   In this setup , debiasing projections are applied as   as follows : For INLP , each of the three representa-   tions is debiased by training a linear classifier on all   28 occupation classes and using the learned vector   to calculate the nullspace . Logistic regression in   100 iterations is used for the BOW representations ,   150 linear SVM iterations for FastText represen-   tations and 300 linear SVM iterations for BERT .   We use Scikit Learn ( Pedregosa et al . , 2011 ) for all   classification approaches . For the MP setup , we   create a mean projection for every occupation o   ( 28 in total ) by identifying the projection vector P   based on the mean of all female and the mean of   all male biographies with occupation o.   We report the accuracy of predicting the cor-   rect profession ( Acc . ) , the root - mean - square of the   GAPscores of all professions ( GAP )   and the correlation between percentage of women   in a given profession and the respective GAP   scores ( Corr . ) . If debiasing is successful , the clas-   sification accuracy should remain high ( comparedto before debiasing ) , while the GAP score should   decrease . We measure the correlation between un-   derpredicting women ( the GAPscore ) and the   true percentage of women in the set of professions .   A lower correlation is preferable . The intuition   behind measuring the correlations in this way is   to measure the degree to which bias is amplified   compared to the distribution of men and women   in a profession . For example , a difference of 5 %   can have different implications depending on the   original distribution : It is worse if the predicted   percentage of females in a profession goes down to   15 % when the true percentage is 20 % compared to   a true percentage of 48 % going to 43 % .   The results presented in Table 5 show that over-   all results of INLP and MP are comparable . MP   retains higher accuracy compared to INLP . MP re-   duces the GAPmuch more for one - hot BOW ,   slightly more for FastText embeddings and slightly   less for BERT . INLP reduces the correlation a bit   more for both FastText and BERT .   Original   Representation Acc . GAP Corr .   one - hot BOW 77.6 % 0.182 0.895   FastText 77.9 % 0.172 0.891   BERT 74.7 % 0.153 0.852   INLP   Representation Acc . GAP Corr .   one - hot BOW 77.1 0.111 0.65   FastText 73.6 % 0.103 0.493   BERT 74.7 % 0.065 0.353   MP   Representation Acc . GAP Corr .   one - hot BOW 76.67 0.001 0.58   FastText 75.6 % 0.092 0.522   BERT 75.2 % 0.087 0.3958412C Additional Results of Diving Deeper   This appendix provides additional results on the   WEAT scores . Figure 9 presents the result of ap-   plying random projection iterations after 8 INLP it-   erations . Figure 10 illustrates when random projec-   tions are applied to the original data ( without first   applying projections for removing gender ) . These   figures illustrate that random projections after 8   INLP iterations mostly lead to a decrease in WEAT   score , whereas applying random projection directly   to fully biased data increases the scores in the far   majority of the cases.84138414D Changes in the Embedding Space of GloVe84158416