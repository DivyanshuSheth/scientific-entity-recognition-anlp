  Eleftheria Briakou andMarine Carpuat   Department of Computer Science   University of Maryland   College Park , MD 20742 , USA   ebriakou@cs.umd.edu , marine@cs.umd.edu   Abstract   Synthetic translations have been used for a   wide range of tasks primarily as a means   of data augmentation . This work explores , in-   stead , how synthetic translations can be used   torevise potentially imperfect reference trans-   lations in mined bitext . We ﬁnd that syn-   thetic samples can improve bitext quality with-   out any additional bilingual supervision when   they replace the originals based on a semantic   equivalence classiﬁer that helps mitigate   noise . The improved quality of the revised bi-   text is conﬁrmed intrinsically via human evalu-   ation and extrinsically through bilingual induc-   tion andtasks .   1 Introduction   While human - written data remains the gold stan-   dard to train Neural Machine Translation ( )   and Multilingual models , there is growing   evidence that synthetic bitext samples — sentence-   pairs that are translated by — beneﬁt a wide   range of tasks . They have been used to enable   semi - supervisedtraining from monolingual   data ( Sennrich et al . , 2016a ; Zhang and Zong ,   2016 ; Hoang et al . , 2018 ) , to induce bilingual   lexicons ( Artetxe et al . , 2019 ; Shi et al . , 2021 ) ,   and to port models trained on one language to an-   other ( Conneau et al . , 2018 ; Yang et al . , 2019 ) .   While synthetic bitexts are useful additions to   original training data for downstream tasks , it re-   mains unclear how they differ from naturally oc-   curring data . Some studies suggest that synthetic   samples might be simpler and easier to learn ( Zhou   et al . , 2020 ; Xu et al . , 2021 ) . Recognizing that nat-   urally occurring bitext can be noisy , for instance ,   when they are mined from comparable monolin-   gual corpora ( Resnik and Smith , 2003 ; Fung and   Yee , 1998 ; Esplà et al . , 2019 ; Schwenk et al . , 2021 ) ,   we hypothesize that synthetic bitext might also di-   rectly improve the equivalence of the two bitext   sides . Thus synthetic samples might be useful notonly for data augmentation but also to revise poten-   tially noisy original bitext samples .   In this paper , we present a controlled empiri-   cal study comparing the quality of bitext mined   from monolingual resources with a synthetic ver-   sion generated via . We focus on the widely   used WikiMatrix bitexts for a distant ( i.e,- )   and a similar language - pair ( i.e,- ) , since it   has been shown that this corpus contains a signiﬁ-   ca nt proportion of erroneous translations ( Caswell   et al . , 2021 ) . We generate synthetic bitext by trans-   lating the original training samples usingsys-   tems trained on the bitext itself and therefore do not   inject any additional supervision in the process . We   also consider selectively replacing original samples   with forward and backward synthetic translations   based on a semantic equivalence classiﬁer , which   is also trained without additional supervision .   We show that the resulting synthetic bitext im-   proves the quality of the original intrinsically using   human assessments of equivalence and extrinsi-   cally on bilingual induction ( ) andtasks .   We present an extensive analysis of synthetic data   properties and of the impact of each step in its gen-   eration process . This study brings new insights into   the use of synthetic samples in . First , intrin-   sic evaluation shows that synthetic translations , in   addition to “ normalizing ” the bitext ( Zhou et al . ,   2020 ; Xu et al . , 2021 ) , could potentially provide   reference translations that are more semantically   equivalent to the source than the original ones .   Furthermore , the improved bitext provides more   useful signals fortasks and training in two   settings ( training from scratch ; continued training ) ,   as conﬁrmed by our extrinsic evaluations . Finally ,   ablation analyses that compare different ways to   combine synthetic translations show that using both   translation directions andﬁltering using semantic   equivalence is key to improving bitext quality and   calls for further exploration of best practices for   using synthetic translations in tasks.47532 Background   Synthetic Translations Generating synthetic   translations has mainly been studied as a means   of data augmentation for through forward   translation ( Zhang and Zong , 2016 ) or back-   translation ( Sennrich et al . , 2016a ; Marie et al . ,   2020 ) of monolingual resources . Moreover , re-   cent lines of work use synthetic translations to   augment the original parallel data : Nguyen et al .   ( 2020 ) diversify the parallel data via translating   both sides using multiple models and then merging   them with the original to train a ﬁnal model ;   Jiao et al . ( 2020 ) employ a similar approach to   rejuvenate inactive examples that contribute the   least to the model performance . Sequence - level   knowledge distillation ( Kim and Rush , 2016 ) can   also be viewed as replacing original bitext with   synthetic translations . While its original goal was   to guide the training of a student model of small   capacity with the output of a teacher of high capac-   ity , distillation is also necessary to effectively train   some categories ofarchitectures such as non-   autoregressive models ( Gu et al . , 2018 ) . While it is   not entirely clear why synthetic distilled samples   are superior to original bitext in this case , recent   studies suggest that the synthetic samples are sim-   pler and thus easier to learn from ( Zhou et al . , 2020 ;   Xu et al . , 2021 ) .   Synthetic Data Selection Prior work covers a   wide spectrum of different selection strategies on   top of synthetic translations generated from mono-   lingual samples . Each of them focuses on identify-   ing samples with speciﬁc properties : Axelrod et al .   ( 2011 ) sample sentences that are most relevant to   a target domain with the goal of creating pseudo   in - domain bitext ; Hoang et al . ( 2018 ) generate syn-   thetic parallel data iteratively from increasingly bet-   ter back - translation models for improving unsuper-   vised ; Fadaee and Monz ( 2018 ) focus on the   diversity of synthetic samples and sample synthetic   translations containing words that are difﬁcult to   predict using prediction losses and frequencies of   words . By contrast , our empirical study investi-   gates whether synthetic translations can be used to   selectively replace original references to improve   bitext quality rather than augmenting it .   Bitext Quality Mining bitext from the web re-   sults in large - scale corpora that are usually col-   lected without guarantees about their quality . For   instance , they contain noisy samples , rangingAlgorithm 1 Revising Bitext : Given a bitext D=   ( S;T ) , a divergent scorer R , and a margin score t ,   return revised bitext ~D   from untranslated sentences to sentences with no   linguistic content ( Khayrallah and Koehn , 2018 ;   Caswell et al . , 2020 ) . Some of this noise is   typically ﬁltered out automatically using heuris-   tics ( Ramírez - Sánchez et al . , 2020 ) or model   scores ( Junczys - Dowmunt , 2018 ; Koehn et al . ,   2019 ) . Yet , even after this noise ﬁltering , a   wide range of the remaining samples contains   ﬁne - grained semantic divergences ( Briakou and   Carpuat , 2020 ) . Our past work explored strategies   to mitigate the impact of these divergences on   models by incorporating divergence tags as token-   level factors ( Briakou and Carpuat , 2021 ) , and de-   signing an approach to automatically edit divergent   samples with noisy supervision from monolingual   resources ( Briakou et al . , 2021 ) . By contrast , this   work explores whether synthetic translations can be   used to replace potentially ﬁne - grained divergences   using only the bitext we seek to revise .   3 Approach   This section describes the methods and data we use   to produce revised bitexts for our empirical study.47543.1 Methods for Revising Bitext   We rely on established techniques that can be ap-   plied using only the bitext that we seek to revise .   First , we train models on the original bitext   to translate in both directions . For each original   sentence - pair , we generate a pool of synthetic trans-   lations using and apply a divergence ranking   criterion to decide whether and how to replace the   original references with a better translation . Algo-   rithm 1 gives an overview of the process , and we   describe each step below .   Generating synthetic translations We train modelsMandMon the original   bitext to translate in each direction ( lines 2 - 3 ) . For   each sentence - pair , they are used to generate two   candidates for replacement by forward and back-   ward translation ( lines 6 - 7 ): ( S;M(S ) ) and   ( M(T);T ) . As a result , models trans-   late the exact same data that they are trained on .   We thus expect translation quality to be high , and   that local errors in the original bitext might be cor-   rected by the translation patterns learned by   models on the entire corpus .   Selective Replacement We propose to replace   an original pair by a candidate only if the candi-   date is predicted to better convey the meaning of   the source than the original , which we refer to as   thesemantic equivalence condition . We implement   this by ranking the original sample ( S;T ) , its re-   vision by forward translation ( S;M(S ) ) and   its revision by back - translation ( M(T);T ) ,   according to their degree of semantic equivalence .   If none of the synthetic samples score higher than   the original , it is not replaced ( line 17 ) . Otherwise ,   the original is replaced by the highest scoring syn-   thetic sample ( lines 10 - 15 ) . As a result the cardi-   nality of the bitext remains constant . The semantic   equivalence condition ( dandd(lines 8 - 9 ) ) is   implemented using divergentm , a divergent   scorer introduced in our prior work ( Briakou and   Carpuat , 2020 ) that is trained on synthetic samples   generated by perturbations of the original bitext   ( e.g. , deletions , lexical or phrasal replacements )   performed without any bilingual information .   3.2 Experimental Set - Up   Bitext We evaluate the use of synthetic trans-   lations for revising bitext on two language pairs   of the WikiMatrix corpus ( Schwenk et al . , 2021 ) .   WikiMatrix consists of sentence - pairs mined fromWikipedia pages using language agnostic sentence   embeddings ( ) ( Artetxe and Schwenk , 2019 ) .   Prior work indicates that , as expected , the cor-   pus as a whole comprises many samples that are   not exact translations : Caswell et al . ( 2021 ) re-   port that for more than half of the audited low-   resource language - pairs , mined pairs are on av-   erage misaligned ; Briakou and Carpuat ( 2020 )   ﬁnd that 40 % of a random sample of the English-   French bitext are not semantically equivalent , and   include ﬁne - grained meaning differences in ad-   dition to alignment noise . We focus on bitexts   with fewer than one million sentence pairs in   Greek$English ( $ , with 750;585 pairs )   and Romanian$English ( $ , with 582;134   pairs ) , because improving bitext is particularly   needed in this data regime . In much higher re-   source settings , ﬁltering strategies might be sufﬁ-   cient as there might be more high quality samples   overall . In much lower resource settings , the data   is likely too noisy or too small to effectively revise   bitexts using . We ﬁlter out noisy pairs in the   training data using bicleaner ( Ramírez - Sánchez   et al . , 2020 ) so that our empirical study excludes   the most obvious forms of noise , and focuses on   the harder case of revising samples that standard   preprocessing pipelines consider to be clean .   Preprocessing We use Moses ( Koehn et al . ,   2007 ) for punctuation normalization , true - casing ,   and tokenization . We learn 32Ks ( Sennrich   et al . , 2016b ) per language using subword - nmt . Models We use the base Transformer archi-   tecture ( Vaswani et al . , 2017 ) and include details on   the exact architecture and training in Apendix C.   Selective Replacement The divergence ranking   models are trained using our public implemen-   tation of divergentm ( Briakou and Carpuat ,   2020).Synthetic divergences are generated start-   ing from the 5;000top scoring WikiMatrix sen-   tences based on score ( i.e. , seed equiva-   lents ) . We ﬁne - tune the “ -Base Multilingual   Cased ” model ( Devlin et al . , 2019 ) and set the mar-   gin equal to 5as per our original implementation .   We use the same margin value for the margin score   of Algorithm 1.4755   4 Intrinsic Evaluation of Bitext Quality   4.1 Human evaluation   We ask 3bilingual speakers to evaluate the quality   of the - bitexts . Given an original source sen-   tence , they are asked to rank the original target and   the candidate target in the order of their equivalence   to the source . They are asked “ Which sentence con-   veys the meaning of the source better ? ” , and ties   are allowed . A random sample of 100pairs from   forward and backward MT is annotated .   As can be seen in Table 2 , 60 % of syn-   thetic candidates are better translations of the Wiki-   Matrix reference , which conﬁrms the potential   of for improving over original translations .   Further ablations conﬁrm the beneﬁts of select-   ing these synthetic candidates with the seman-   tic equivalence condition . When the divergent   scorer ranks a candidate higher than the original   by a small margin ( i.e. , 0d5givend=   R(S;M(T)) R(S;T ) ) ) , human evalua-   tion shows that the candidate is actually better than   the original only 51 % of the times . When using our   exact semantic equivalence condition ( d>5 ) , can - Candidate set % Equivalized Kendall ’s t 60:0 % 0 : 321   d<0 26 : 4 % 0 : 157   0d5 51 :0 % 0 : 234   d>5 87:5 % 0:688   didates are judged as more equivalent than the orig-   inal87:5%of the times , and annotations within this   set have a stronger agreement ( i.e. , 0:688Kendall ’s   t ) . This indicates that the condition d>5identiﬁes   more clear - cut examples of synthetic translations   that ﬁx semantic divergences in the original data   and can be thus used for selective replacement of   imperfect references by better quality translations .   Further inspection of the annotations reveals that   most source - target WikiMatrix examples contain   ﬁne meaning differences ( 56 % ) . In those cases ,   we observe that most of the content between the   sentences is shared , but either small segments are4756   mistranslated ( e.g. , “ London ” instead of “ Athens ”   in the ﬁrst example of Table 1 ) , or some informa-   tion is missing from either side of the pair ( e.g. , “ all   six ” missing from the target side in the third exam-   ple of Table 1 ) . Furthermore , more coarse - grained   divergences are found less frequently ( 12%)—in   those cases , we notice that sentences are usually   either topically related or structurally similar ( e.g. ,   length , syntax ) with a few anchor words ( e.g. , last   example in Table 1 ) . Finally , 32 % of the times the   original WikiMatrix pairs are perfect translations   of each other .   4.2 How do synthetic translations differ from   originals ?   Figure 1 presents the distribution of lexical differ-   ences ( i.e. , computed using LeD — a score that cap-   tures lexical differences based on the percentages   of tokens that are not found in two sentences ( Niu   and Carpuat , 2020 ) ) between original and synthetic   translations ( in ) for candidates that replace and   do not replace the originals . First , we observe   that a substantial amount of synthetic translations   that do not replace original references ( 40 % ) cor-   responds to small LDscores ( < 0:1 ) , suggesting   that the equivalence criterion could fall back to the   original sentence not because of the poor quality   of candidate references , but rather due to them be-   ing already close to the originals . Furthermore , all   synthetic translated instances are represented in al-   most all bins , with fewer instances found on the   extreme bins of > 0:7LDscores . Finally , syn-   thetic translations that replace original references   are mostly concentrated within the range [ 0:2;0:6 ]   of LeD scores . This indicates that they share lexical   content with the original , which further supports   the hypothesis that synthetic translations revise ﬁne-   grained meaning differences in WikiMatrix in ad-   dition to alignment noise .   4.3 How does the revised bitext differ from   the original ?   Table 3 presents differences in statistics of the orig-   inal vs. revised WikiMatrix - bitexts to shed   more light on the impact of selectively using syn-   thetic translation for bitext quality improvement .   The reﬁned bitext exhibits higher coverage ( i.e. ,   ratio of source words being aligned by any target   words ; rows 5and13 ) and smaller complexity ( i.e. ,4757the diversity of target word choices given a source   word ( Zhou et al . , 2020 ) ) compared to the original   bitext . Moreover , the use of synthetic translations   introduces small decreases in the lexical types cov-   ered in the ﬁnal corpus ( i.e. , rows 3and11 ) , which   is expected as the additional coverage in the orig-   inal corpus might be a result of divergent texts .   Those observations are in line with prior work that   seeks to characterize the nature of synthetic trans-   lations used in other settings , such as knowledge   distillation ( Zhou et al . , 2020 ; Xu et al . , 2021 ) .   While ﬁxing divergent references contributes to   this simpliﬁcation effect , translations might   also reinforce unwanted biases from the original   bitext . For instance , the distribution of two gram-   matical gender pronouns on the English side is a   little more imbalanced in the improved bitext than   in the original ( rows 6 - 7and14 - 15),likely due to   gender bias in ( Stanovsky et al . , 2019 ) . This   calls for techniques to mitigate such biases ( Saun-   ders and Byrne , 2020 ; Stafanovi ˇcs et al . , 2020 ) for and other downstream tasks .   5 Extrinsic Evaluation of Bitext Quality   Our previous analysis suggests that selective re-   placement of divergent references with synthetic   translations results in bitext of improved quality ,   with reduced level of noises and easier word - level   mappings between the two languages , when com-   pared to the original WikiMatrix corpus . To better   understand how those differences impact down-   stream tasks , we contrast the improved bitext with   the original through a series of extrinsic evaluations   for - and - languages that rely on paral-   lel texts as training samples ( see § 5.2 ) . First , we   focus on the recent state - of - the - art unsupervisedapproach of Shi et al . ( 2021 ) that relies on   word - alignments of extracted bitexts . Second , we   follow the recent bitext quality evaluation frame-   works adopted by the “ Shared Task on Parallel Cor-   pus Filtering and Alignment ” ( Koehn et al . , 2020 )   and built neural machine translation systems from   scratch and by continued training on a multilingual   pre - trained transformer model . Finally , we conduct   extensive ablation experiments to test the impact of   using synthetic translations without the semantic   equivalence condition and contrast with familiar   techniques used by prior work ( see § 5.3).5.1 Experimental Set - Up The task ofaims to induce a bilingual   lexicon consisting of word translations in two lan-   guages . We experiment with the recently proposed   method of Shi et al . ( 2021 ) that combines extracted   bitext and unsupervised word alignment to perform   fully unsupervised induction based on extracted   statistics of aligned word pairs . The induced lexi-   cons are evaluated based on ( Lample et al . ,   2018 ) consisting of 45;515and80;815dictionary   entries for - and- , respectively . We   extract word alignments using m -based Sima-   lign(Jalili Sabet et al . , 2020 ) and statistics based   on the implementation of Shi et al . ( 2021 ) . We experiment withtasks following   two approaches : ( 1 ) training standard transformer   seq2seq models from scratch ; ( 2 ) continued train-   ing for mT5 ( Xue et al . , 2021 ) , a multilingual pre-   trained text - to - text transformer . We evaluate trans-   lation quality with ( Papineni et al . , 2002 )   on the ofﬁcial development and test splits of the corpus ( Qi et al . , 2018).For ( 1 ) we follow   the experimental settings described in § 3.2 . For ( 2 )   we initialize the weights of transformer with “ mT5-   small ” which consists of 300 M parameters , . We   use thesimpletransformers implementation .   We ﬁne - tune for up to 5epochs and include the   parameter settings in Appendix D.   Ablation Settings We compare the models   trained on the variants of the synthetic bitext to iso-   late the impact of replacement criteria and different   candidates . For the former , we experiment with   therejuvenation approach of Jiao et al . ( 2020 ) that   replaces original references with forward translated   candidates for the 10 % least active original samples   measured by probability scores . Moreover ,   we experiment with forward andbacktranslation   baselines trained on bitexts that consist solely from   target- or source - side candidate sentences ( i.e. , orig-   inal references are entirely excluded ) and with ab-   lations that consider either forward or backward4758All Low Medium High Precision Recall F1 rate Precision - nOriginal 76:258:1 65:9 6:7 % 59:4 76:6 81:4   Revised 77:658:666:87:5 % 60:478:481:6 - nOriginal 89:2 69 : 4 78:1 15:8 % 78:6 86:9 87:1   Revised 90:871:379:816:5 % 80:087:586:9   candidates for the proposed semantic equivalence   condition . Finally , we consider two alternatives   to the semantic equivalence condition based on   divergent scores : the ranking condition replaces a   candidate if it scores higher than the original ( i.e. ,   margin with d= 0 ) and the thresholding condi-   tion adds the additional constraint that candidates   should rank higher than a threshold to replace the   original pair .   5.2 Extrinsic Evaluation Results Table 4 presents results for unsupervised   on the gold - standard dictionaries , for-   and- . Across languages , the revised bitexts   induce better lexicons compared to the original   WikiMatrix . Crucially , improvements are reported   both in terms of Recall — which connects to the ob-   servation that the revised bitext exhibits higher cov-   erage than the original and in terms of Precision —   which connects to the noise reduction effect that   impacts the extracted word alignments . Addition-   ally , a break - down on the Precision of the induced   lexicons binned by the frequency of source-   side entries ( i.e. , last 3columns in Table 4 ) reveals   that the improvements come from better induction   of low- and medium - frequency words , which we   expect are more sensitive to noisy misalignments   that result from divergent bitext . Finally , those im-   provements are reported despite the small increase   of the rate in the revised lexicons that results   from the decrease in the lexical types covered in it ,   as mentioned in the analysis ( i.e. , § 4.3 ) .   Furthermore , following the advice of Ke-   mentchedjhieva et al . ( 2019 ) who raise concerns onevaluations based on gold - standard pre - deﬁned   dictionaries , we accompany our evaluation with   manual veriﬁcation to conﬁrm that our conclusions   are consistent with those of the automatic evalu-   ation . Concretely , we manually check the false   positives induced translation pairs from the origi- ! 28:15 29:63 ! 27:08 27:89 ! 23:68 24:54 ! 20:65 20:84   nal vs. the improved bitext . We found that 65=80   arefalse false positives ( due to incompleteness of   pre - deﬁned dictionaries ) for the improved bitext   and51=80for the original ( see Appendix F for   the complete list ) . This conﬁrms that the metric   improvements we observe are meaningful and sug-   gests that the improved bitext help learn better map-   pings between source and target words . Table 5 presents translation quality ( )   on$and$tasks fortraining from   scratch and Figure 2 shows translation quality of4759   mT5 continued training across epochs . Across   tasks and settings , the revised bitext yields bet-   ter translation quality than the original WikiMatrix   data . The consistent improvements we observe   across the two settings suggest that the properties   of the synthetic translations that replace original   samples and bring those improvements are invari-   ant to speciﬁc models . Moreover , the magnitude   of improvements is larger in the continued train-   ing setting compared to training from scratch ( e.g. ,   +0:8vs.+1:5 , for!;+0:2vs .   +1:5 , for ! ) . The latter suggests that im-   provements from using synthetic samples do not   only come from the normalization effect ( i.e. , syn-   thetic samples are easier to model by ) but   also connect to the reduced noise in the training   samples . This further complements our hypothesis   that synthetic translations can improve the quality   of imperfect references that should , in principle ,   yield noisy training signals — and thus impact the   resulting quality — of differentmodels .   5.3 Ablation Study   Table 6 compares the translation quality ( ) of systems trained on different synthetic trans-   lations . By forcing the semantic equivalence con-   dition when deciding whether a synthetic transla-   tion replaces an original , we revise 50 % of the lat-   ter yielding the best results across directions withsigniﬁcant improvements ( i.e , increases do not lie   within 1stdev of the original ’s bitext performance )   of+0:81 ( ! , row 9 ) and +1:49 ( ! ,   row18 ) points over the original bitext .   Impact of semantic equivalence condition Ta-   ble 6 shows that naively disregarding the original   references and training only on synthetic trans-   lations gives mixed results : training on forward-   translated references only ( i.e. , row 2 ) gives small   improvements ( +0:36 ) over the model trained on   WikiMatrix for ! , while it performs compa-   rably to it for!(i.e . , row 11 ) . On the other   hand , training on backward data only ( i.e. , row 12 )   improves by a small margin ( +0:23 ) for   intowhile it hurts when translating into(i.e . , row 3 ) . This indicates that the good quality   of the synthetic translations can not be taken for   granted and motivates replacing original pairs un-   der conditions that account for semantic controls .   The latter is further conﬁrmed by results on the   rejuvenation baseline : replacing candidates for the   10 % of the most inactive WikiMatrix samples re-   sults in small and insigniﬁcant increases in   when compared to models trained on original Wiki-   Matrix data ( i.e. , rows 1 - 4and10 - 13 ) . This indi-   cates that rejuvenation might not be well - suited to   lower resource settings than the ones it was origi-   nally tested on ( Jiao et al . , 2020 ) . The rejuvenation   technique might be affected by the decreased4760quality and calibration in lower resource settings .   By contrast , using synthetic translations with se-   mantic control mitigates their impact .   Finally , all three semantic control variants based   on divergent scores yield bitexts that improve   compared to the original WikiMatrix ( i.e. , rows 5-   8and14 - 18 ) . Among them , the margin condition   is the most successful , followed by the threshold-   ingvariant . The breakdown of training statistics   reveals the reason behind their differences : the   thresholding condition is a more strict constraint   as it only allows synthetic candidates to replace the   original pairs if they are predicted as exact equiv-   alents , allowing for fewer revisions of divergent   pairs in WikiMatrix . By contrast , the condition   based on margin is a contrastive approach that al-   lows for more revisions of the original data ( i.e. , a   candidate might be a more ﬁne - grained divergent of   the source ) . The ranking criterion is the least suc-   cessful method — this is expected as the divergence   ranker is not trained as a regression model .   Impact of bi - directional candidates Consid-   ering both forward ( F ) and backward ( B )   translated candidates during selective replacement   yields to further improvements ( 0:22 - 0:44points )   over bitext induced by the semantic equivalence   condition with candidates from a single   model ( i.e. , rows 7 - 9and16 - 18 ) . When forward   and backward candidates are considered indepen-   dently , they replace 34 37 % of the original pairs ;   in contrast , when considered together , they replace   50 % of original WikiMatrix pairs . As a result ,   there is no perfect overlap between the original   pairs replaced by the forward vs. backward model ,   which motivates the use of both to revise more di-   vergences in WikiMatrix . This ﬁnding raises the   question of whether using synthetic translations   from both directions might beneﬁt other scenarios ,   such as knowledge distillation .   6 Conclusion   This paper explored how synthetic translations can   be used to revise bitext , using models trained   on the exact same data we seek to revise . Our exten-   sive empirical study surprisingly shows that , even   without access to further bilingual data or super-   vision , this approach improves the quality of the   original bitext , especially when synthetic transla-   tions are generated in both translation directions   and selectively replace the original using a seman-   tic equivalence criterion . Speciﬁcally , our intrinsicevaluation showed that synthetic translations are   of sufﬁcient quality to improve over the original   references , in addition to “ normalizing ” the bitext   as suggested by prior work and corpus level statis-   tics ( Zhou et al . , 2020 ; Xu et al . , 2021 ) . Extrinsic   evaluations further show that the replaced synthetic   translations provide more useful signals for   tasks and training in two settings ( i.e. , train-   ing from scratch and continued training ) .   These ﬁndings provide a foundation for further   exploration of the use of synthetic bitext . First ,   we focused our empirical study on language pairs   and datasets where revising bitexts is the most   needed and most likely to be useful : the resources   available for these languages are not so large that   mined bitext can simply be ignored or ﬁltered   with simple heuristics , yet there is enough data   to build systems of reasonable quality ( i.e. ,   600 K segments for- , and750 K for- ) . While in principle , selective replacement   of divergent references with synthetic translations   should port to high - resource settings , where   is as good or better than for the languages con-   sidered in this work , other techniques are likely   needed in low - resource settings where qual-   ity is too low to provide reliable candidate trans-   lations . Second , having established that the re-   vised bitext improves the quality of the original   bitext in isolation , it remains to be seen how to   best revise bitexts in more heterogeneous scenar-   ios with diverse sources of parallel or monolin-   gual corpora . Overall , as synthetic data gener-   ated by is increasingly used to improve cross-   lingual transfer in multilingual NLP , our study mo-   tivates taking a closer look at the properties of   synthetic samples to better understand how they   might impact downstream tasks beyond raw perfor-   mance metrics . All bitexts are available at : .   Acknowledgements   We thank Marjan Ghazvininejad , Luke Zettle-   moyer , Sida Wang , Sweta Agrawal , Jordan Boyd-   Graber , Pedro Rodriguez , the anonymous review-   ers and the lab at for helpful comments .   This material is based upon work supported by   the National Science Foundation under Award No .   1750695 . Any opinions , ﬁndings , and conclusions   or recommendations expressed in this material are   those of the authors and do not necessarily reﬂect   the views of the National Science Foundation.4761References476247634764A Details on bitext analysis   Complexity We follow Zhou et al . ( 2020 ) and   compute the corpus complexity as a measure of   translation uncertainty . Concretely , having access   to an alignment model ( here , fast - align ) , the   complexity of a corpus dis computed by averaging   the entropy of target words yconditioned on the   sourcex , L(d ) = PH(yjx ) .   Coverage We follow Tu et al . ( 2016 ) and mea-   sure the coverage of each source - target parallel pair   as the ratio of source words being aligned to tar-   get words , having access to an alignment model   ( here , fast - align ) . We compute the coverage   for source - target and target - source bitexts sepa-   rately . Corpus - level statistics correspond to average   sentence - level results .   Grammatical Gender Pronouns The complete   lists of grammatic gender pronouns we use for   are : [ o , tou , ton , autìc , autoÔ , autìn , ekèinoc ,   ekèinou , ekeÐnon , opoÐoc , opoÐou , opoÐon ] and   [ h , thc , thn , aut   n , aut   c , aut   n , ekèinh , ekèinhc ,   ekeÐnhn , opoÐa , opoÐac , opoÐan ] .   Lexical Differences ( LeD ) We follow ( Niu and   Carpuat , 2020 ) and compute the Lexical Differ-   ences score between two sentences SandSas   the percentage of tokens that are not found in both ,   LeD= ( ) + .   B Result on development sets   Table 7 presents results on the main and secondary tasks on developments sets . The reﬁned   bitext leads to consistent and signiﬁcant improve-   ments in across language - pairs and transla-   tion directions .   CSockeye2 conﬁguration details   We use the base Transformer architecture ( Vaswani   et al . , 2017 ) . with embedding size of 512 , trans-   former hidden size of 2;048,8attention heads , 6   transformer layers , and dropout of 0:1 . Target em-   beddings are tied with the output layer weights . We   train with label smoothing ( 0:1 ) . We optimize with   Adam ( Kingma and Ba , 2015 ) with a batch size of   4;096tokens and checkpoint models every 1;000   updates . The initial learning rate is 0:0002 , and it is   reduced by 30 % after 4checkpoints without valida-   tion perplexity improvement . We stop training after   20checkpoints without improvement . We selectTable 6 ! !   1 : 25:500:15 10 : 27 : 980:18   2 : 25:520:07 11 : 27 : 920:15   3 : 24:550:25 12 : 27 : 700:15   4 : 25:350:14 13 : 27 : 990:15   5 : 25:270:41 14 : 28 : 360:13 *   6 : 25:660:05 * 15 : 28:340:18 *   7 : 25:730:14 * 16 : 28:660:14 *   8 : 25:710:19 * 17 : 28:650:27 *   9 : 25:910:09 * 18 : 29:000:26 *   Table 5 ! !   1 : 21:940:11 3 : 24 : 980:16   2 : 22:050:03 * 4 : 26:110:20 *   the best checkpoint based on validation ( Pa-   pineni et al . , 2002 ) . All models are trained on a   single GeForce1080 . Tables 8 presents   details of training with Sockeye2 .4765   D mt5 conﬁguration details   Tables 9 presents details of continued training of   mT5 onSimpleTransformers .   E Data Statistics   Table 10 presents data statistics for WikiMatrix   training data , and evaluation sets .   F Manual inspection of   Table 12 presents manual analysis results on False   Positives entries of the evaluation set for the - language - pair .   G Streamlining equivalization   Based on ablation analysis presented in Table 6 the   best equivalization strategies consider candidates   from two models trained independently to   translate in opposite directions . In Table 11 we   show how our approach yields comparable results   by replacing the two uni - directional models ( - ) with a single bi - directional model ( - )   while reducing training by 30%.4766