  Hui Wuand Xiaodong ShiDepartment of Artiﬁcial Intelligence , School of Informatics , Xiamen University , ChinaNational Institute for Data Science in Health and Medicine , Xiamen University , ChinaKey Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural   Heritage of Fujian and Taiwan ( Xiamen University ) , Ministry of Culture and Tourism , China   huistudent@stu.xmu.edu.cn , mandel@xmu.edu.cn   Abstract   Cross - domain sentiment analysis has achieved   promising results with the help of pre - trained   language models . As GPT-3 appears , prompt   tuning has been widely explored to enable bet-   ter semantic modeling in many natural lan-   guage processing tasks . However , directly   using a ﬁxed predeﬁned template for cross-   domain research can not model different distri-   butions of the [ MASK ] token in different do-   mains , thus making underuse of the prompt   tuning technique . In this paper , we propose a   novel Adversarial SoftPrompt Tuning method   ( AdSPT ) to better model cross - domain sen-   timent analysis . On the one hand , AdSPT   adopts separate soft prompts instead of hard   templates to learn different vectors for differ-   ent domains , thus alleviating the domain dis-   crepancy of the [ MASK ] token in the masked   language modeling task . On the other hand ,   AdSPT uses a novel domain adversarial train-   ing strategy to learn domain - invariant repre-   sentations between each source domain and   the target domain . Experiments on a publicly   available sentiment analysis dataset show that   our model achieves new state - of - the - art results   for both single - source domain adaptation and   multi - source domain adaptation .   1 Introduction   In recent years , with the emergence of a series of   large - scale pre - trained language models ( PLMs ) ,   such as GPT ( Radford et al . , 2018 , 2019 ) , BERT   ( Devlin et al . , 2019 ) , and RoBERTa ( Liu et al . ,   2019 ) , ﬁne - tuning PLMs has achieved promising   results on a wide range of natural language pro-   cessing ( NLP ) tasks . However , as PLMs become   larger and larger , ﬁne - tuning larger PLMs becomes   more challenging in most real - world applications .   More recently , Brown et al . ( 2020 ) show that de-   signing task descriptions ( a.k.a . prompts ) can make   accurate predictions without updating any of theFigure 1 : How domain discrepancy affects prompt tun-   ing . Examples of a book review on the top and a video   review on the bottom .   parameters of GPT-3 ( which has 175B parameters ) .   This inspires a new PLM - tuning method named   “ prompt tuning ” . Such prompt tuning method   has achieved state - of - the - art results on text clas-   siﬁcation and natural language inference ( Schick   and Schütze , 2020 ; Schick et al . , 2020 ; Gao et al . ,   2020 ) , relation classiﬁcation ( Han et al . , 2021 ) , and   natural language generation ( Li and Liang , 2021 ) .   It is common to use a predeﬁned template ( e.g. ,   “ It was [ MASK ] . ” ) in prompt tuning for binary   sentiment analysis , and the classiﬁcation results of   positive or negative depend on the probabilities of   predeﬁned label words ( e.g. , “ { good , bad } ” ) in the   masked language modeling ( MLM ) task . However ,   the distributions of MLM prediction results can   be different for different domains . An example is   shown in Figure 1 , the discrepancy between book-   domain review and video - domain review leads to   different possibilities of label words . The high-   frequency label word in book - domain review is   “ useful ” , and video - domain review is “ real ” , neither   of which is in the predeﬁned “ { good , bad } ” . There-   fore , it is unreasonable to predict predeﬁned label   words with ﬁxed templates ( a.k.a . hard prompts )   for different domain datasets .   The intuition is that the feature distributions cor-   responding to the [ MASK ] position learned from   the hard prompt are distinct among different do-2438mains . And the discrepancy among different do-   mains can have serious effects on the cross - domain   setting where we train a classiﬁer on source domain   data , e.g. , the book reviews , and test it on the target   domain , e.g. , the video review . So domain adapta-   tion ( Ben - David et al . , 2007 ; Mansour et al . , 2009 )   based on cluster hypothesis ( Zhu and Goldberg ,   2009 ) becomes a key point of the cross - domain   research .   In order to improve the cross - domain sentiment   analysis with the help of PLMs , we propose Ad-   SPT : an Adversarial SoftPrompt Tuning method ,   which sheds new light on solving the domain adap-   tation problem . Speciﬁcally , we use soft prompts   composed of multiple learnable vectors and the   [ MASK ] token instead of hard templates for tun-   ing . For different domains , we use independent   soft prompts to represent domain - speciﬁc informa-   tion , thus making them have the domain - aware   knowledge . With different domain soft prompts ,   the MLM head classiﬁer can mitigate the domain   discrepancy of the [ MASK ] token . To enhance   the effectiveness of the target domain , we design   a novel adversarial training strategy to learn the   domain - invariant knowledge of the [ MASK ] token ,   which can be seen as a two - player minimax game   between the target domain and each source domain   under multi - source domain adaptation setting . As a   result , the collaborative effect of soft prompt tuning   and domain adversarial training can more properly   predict the feature distribution of the [ MASK ] to-   ken on the ground of domain - speciﬁc soft prompts   and the domain invariance of the [ MASK ] token .   In experiments , we evaluate on a publicly avail-   able sentiment analysis dataset for both single-   source domain adaptation and multi - source domain   adaptation . Our results show the effectiveness   of collaboratively leveraging domain - speciﬁc soft   prompts tuning and domain adversarial training . To   summarize , the main contributions of this work are   as follows :   ( 1 ) In prompt tuning , we adopt separate soft   prompts to learn embeddings enriched with the   domain knowledge , thus alleviating the domain   discrepancy of the [ MASK ] position .   ( 2 ) We design a novel adversarial training strat-   egy to learn the domain - invariant representation of   the[MASK ] position .   ( 3 ) Experiments on the Amazon reviews dataset   show our method AdSPT obtains the average ac-   curacy 93:14 % ( 0:46absolute improvement ) undersingle - source domain adaptation and the average   accuracy 93:75 % ( 0:81absolute improvement ) un-   der multi - source domain adaptation .   2 Related Work   Prompt tuning . Fine - tuning PLMs with task-   speciﬁc heads on downstream tasks has become   the main paradigm and yields strong performance   on many NLP tasks ( Peters et al . , 2018 ; Devlin   et al . , 2019 ; Radford et al . , 2019 ) . But there is   a big gap between the ﬁne - tuning objectives of   downstream tasks and the pre - training objectives   of PLMs , which could limit the exploitation of   knowledge in PLMs ( Liu et al . , 2021b ) . Subse-   quently , GPT-3 ( Brown et al . , 2020 ) brings a new   paradigm “ prompt tuning ” for downstream tasks ,   which leverages natural - language prompts and task   demonstrations as context to make downstream   tasks similar to language modeling .   Early works explore manually deﬁned templates   ( a.k.a . hard templates ) for text classiﬁcation and   natural language inference ( Schick and Schütze ,   2020 , 2021 ) . However , suitable templates require   strong domain knowledge . Therefore , some auto-   matically generated hard templates are explored   ( Shin et al . , 2020 ; Gao et al . , 2020 ; Ben - David   et al . , 2021 ) . Since prompt construction is to   ﬁnd a method that allows PLMs to effectively per-   form downstream tasks , it is not necessary to limit   templates to human - interpretable natural language .   Some works attempt to perform prompting directly   with several learnable vectors , such as soft prompt   ( Lester et al . , 2021 ; Vu et al . , 2021 ) , preﬁx - tuning   ( Li and Liang , 2021 ) and P - tuning V2 ( Liu et al . ,   2021a ) . Moreover , Schick et al . ( 2020 ) explore   automatically identifying label words . Hu et al .   ( 2021 ) use an external knowledge base to expand   label words . This paper focuses on improving the   cross - domain sentiment analysis via different soft   prompts of different domains .   Domain Adaptation . Research on domain adap-   tation ( DA ) uses labeled or unlabeled target data   to transfer labeled source information to a speciﬁc   target domain ( Pan and Yang , 2009 ; Mansour et al . ,   2009 ) . Popular methods for unsupervised DA are   based on domain discrepancy optimizing based on   adversarial training ( Ganin et al . , 2016 ; Zhao et al . ,   2018 ; Saito et al . , 2018 ) . As for cross - domain sen-   timent analysis , some early works use pivot - based   methods to capture the shared feature representa-   tion of different domains ( Yu and Jiang , 2016 ; Ziser2439and Reichart , 2018 ; Li et al . , 2018 ; Peng et al . ,   2018 ) . Some other works adopt different adversar-   ial learning methods to learn the domain - common   sentiment knowledge ( Li et al . , 2017 ; Qu et al . ,   2019 ; Li et al . , 2019 ) .   Recently , with the promising performance of   PLMs in NLP , many works on cross - domain sen-   timent analysis focus on how to improve lan-   gange model pre - training and ﬁne - tuning , e.g. , Du   et al . ( 2020 ) use a target domain MLM task and   a domain - distinguish task in pre - training ; Zhou   et al . ( 2020 ) utilize several pre - training tasks based   on existing lexicons and annotations . Different   from these works , our method is the ﬁrst to use the   combination of soft prompt tuning and adversarial   training to solve the DA problem .   3 Problem Formulation   In this paper , we study cross - domain sentiment   analysis in the unsupervised domain adaptation set-   ting which contains two scenarios : a source domain   and a target domain or multiple source domains   and a target domain . Given m(m1)source   domains , the l - th ( l2[1;:::;m ] ) source domain   contains an annotated dataset S = fx;yg ,   where x= [ w;:::;w]is a input sentence with   nwords , yis the corresponding polarity label ,   andNrepresents the number of examples of the   l - th source domain . In the target domain , there   is an unannotated dataset T = fxg , where   x= [ w;:::;w]is an unlabeled sentence of the   target domain and Nis the number of the unla-   beled data . The goal of cross - domain sentiment   analysis is to learn a function Fthat could both   retain in - domain knowledge for different domains   and also learn the domain invariance between the   target domain and each source domain to better   predict the polarity of unlabeled sentences from the   target domain .   4 Method   In this section , we ﬁrst introduce a soft prompt tun-   ing method for sentiment classiﬁcation that utilizes   soft prompts to capture domain - speciﬁc knowl-   edge . Then we present a domain adversarial train-   ing method for domain adaptation . Finally , we   describe the overall learning procedure.4.1 Soft Prompt Tuning for Sentiment   Classiﬁcation   Prompt tuning is an approach to add extra informa-   tion for PLMs by reformulating downstream tasks   as cloze questions . The primary components in-   clude a template and a set of label words , where   the template is a background description of current   task and the label words are the high - probability vo-   cabulary predicted by PLMs in the current context .   In the binary sentiment classiﬁcation , we denote   the input sentence as x= [ w;:::;w ] , the out-   put label as y. Herey2Y , and the label space   Y = fpositive;negativeg .   Prompt tuning formalizes the classiﬁcation task   into a MLM task . Given a PLM Mand its vocab-   ularyV , a prompt consists of a template function   T()that converts the input sentence xto a prompt   inputx = T(x)with the [ MASK ] token and   a set of label words VV , which are connected   with the label space through a mapping function   v : Y 7 ! V. As shown in Figure 2 , the soft   prompted input x contains the embeddings   of the original sentence e(x),klearnable vectors   [ h ; : : : ; h ] , the embedding of the [ MASK ] to-   kene(\[MASK ] " ) , and the embeddings of two   positional tokens e(\[CLS ] " ) ande(\[SEP ] " ) . So   the actual input ofMis represented as :   x =    e(\[CLS]");e(x);h ; : : : ; h ;   e(\[MASK ] " ) ; e(\[SEP]") ( 1 )   where e()represents the embedding function of   M.   Here we can denote a PLM Mas a function   mapping from x to the feature representation   and vocabulary distribution of the [ MASK ] token ,   represented as :   h;s = M(x ) ( 2 )   where h2Rands2Rare the   hidden representation and vocabulary distribution   of the [ MASK ] token respectively , and s =   f(h ) is obtained by the MLM head function   f.   The probability p(yjx)is formalized accord-   ing to the distribution of the label word w2V   w.r.t . the [ MASK ] position . In binary sentiment   classiﬁcation , we set the label words as V=2440   fgood;badg . So ,   p(yjx ) = p(V [ MASK]jx )   = exp(s ( V))Pexp(s ( V))(3 )   Given an annotated dataset S = fx;yg , the   training objective for soft prompt tuning is obtained   using the binary cross - entropy loss ,   L(S; )   =  X   logp(yjx )   + log(1 p(yjx))(4 )   where ^yrepresents the ground truth label ranging   from 1as the positive label and 0as the negative   label).represents the overall trainable pa-   rameters of the PLM M , several learnable vectors   pand the MLM head function f.   4.2 Domain Adversarial Training   For the same task in different domains , domain ad-   versarial training can not only transfer the generic   knowledge from source domains to the target do-   main , but also train more domain - aware classiﬁers .   As shown in Figure 2 , domain adversarial train-   ing aims to make the feature distributions of the   [ MASK ] position from different domains closer . More intuitively , it will encourage the MLM head   classifer to obtain domain - invariant features across   domains .   Based on the hidden representation h by   the PLM , the detailed process of domain adver-   sarial training is as follows : given m(m1 )   source domains , we assume that between each   source domainS(l2[1;:::;m ] ) and the target   domainThave a domain discriminative function   g : R!D that discriminates between the source   domain and the target domain , where the domain   label set is represented as D = f0;1g,0is the   source domain label , and 1is the target domain la-   bel . To this end , there are mdomain discriminators ,   denoted as g = fgg .   Given an input example xfrom either the l - th   ( l2[1;:::;m ] ) source domain or the target do-   main , we ﬁrst obtain the task - speciﬁc head repre-   sentation h byMand then model the prob-   abilityp(djx)for discriminating the domain label   d2D as :   p(djx ) = exp(g(h ) ) Pexp(g(h ) ) ( 5 )   Givenmsource domain dataset ^S = fSg=   ffxggand a target domain dataset T=   fxg , whereNis the number of samples in   thel - th source domain and Nis the number of   samples in the target domain , the domain discrimi-   native objective is to minimize the following cross-2441entropy loss ,   L ( ^S;T; )   =  XX   logp(djx )   + log(1 p(djx))   ( 6 )   where ^drepresents the truth domain label and   represents the overall trainable parameters   of the PLMM , several learnable vectors pandm   domain discriminators g.   The domain adversarial training among m   source domains and the target domain can be seen   as a two - player minimax game where the domain   classiﬁers g = fggtend to minimize the do-   main discrimination loss so as to make the domain   discriminators strong while the PLM Mtends to   maximize the domain discrimination loss so as to   weaken the domain discrimination .   Formally , the domain adversarial training objec-   tive w.r.t . to g , pandMcan be represented as :   maxminL ( ^S;T; ) ( 7 )   4.3 Learning Procedure   Joint training objective . Givenmsource do-   mains ^Sand a target domain T , the sentiment   classiﬁer and the domain discriminator are jointly   trained for optimizing the PLM M , soft prompt   embeddings p , MLM head function fand domain   discriminators g , and the ﬁnal training objective is   formally represented as :   min   L(S; )    minL ( ^S;T; ) 	  ( 8)   whereis a trade - off parameter . The sentiment   classiﬁcation objective L and the domain dis-   crimination objective L are deﬁned in Eq .   ( 4 ) and Eq . ( 6 ) , respectively .   Training procedure . The iterative training pro-   cedure is summarized in Algorithm 1 . In each iter-   ation , the input samples of each source domain are   ﬁrst used for training the PLM M , several learn-   able vectors pand the MLM head function f. The   sentiment classiﬁcation loss is computed in line 5 .   Then the samples of each source domain and theAlgorithm 1 Training Process of AdSPT .   target domain are mapped to different domain dis-   criminators to train the PLM M , several learnable   vectorspand the domain discriminator g. The   corresponding domain discrimination loss is com-   puted in line 6 . The sentiment classiﬁcation loss is   used for updating the parameters of the PLM , sev-   eral learnable vectors and the MLM head function   ( line 7 , 10 ) . The domain discrimination loss is used   for updating the parameters of the PLM , several   learnable vectors and the domain discriminators .   Obviously , the parameters of the PLM and several   learnable vectors be updated together by the above   two losses .   5 Experiments   In this section , we conduct experiments to evaluate   the effectiveness of our methods . Our experiments   are carried out on single - source domain adapta-   tion and multi - source domain adaptation settings ( x   5.3 ) . In addition , we also investigate how different   components in the model impact the performance   of cross - domain sentiment analysis with different   settings .   5.1 Experimental Setup   Dataset . We evaluate on the Amazon reviews   dataset ( Blitzer et al . , 2007 ) , which has been   widely used for cross - domain sentiment classiﬁ-   cation . This dataset contains reviews of binary   categories from four domains : Books ( B ) , DVDs2442   ( D ) , Electronics ( E ) and Kitchen appliances ( K ) .   Each domain has totally 2,000 manually labeled   reviews . We use different settings for single - source   domain adaptation and multi - source domain adap-   tation . For each domain , there are 2000 labeled re-   views , including 1000 positive and 1000 negative ,   and4000 unlabeled reviews . Following previous   work ( Ruder and Plank , 2017 ) , we randomly select   a small part ( 20 % ) of examples in each domain as   the development set to save the best training model   and perform a 5fold cross - validation .   In single - source domain adaptation , we follow   previous work ( Ziser and Reichart , 2018 ) to con-   struct 12cross - domain sentiment analysis tasks   ( corresponding to 12ordered domain pairs ) . In   multi - source domain adaptation , we choose three-   domain data as multiple source domains and the   remaining one as the target domain , e.g. , “ BDE !   K ” . So there are 4combinations , corresponding to   4tasks .   Training details . In the Amazon reviews exper-   iments , we adopt a 12 - layer Transformer ( Vaswani   et al . , 2017 ; Devlin et al . , 2019 ) initialized with   RoBERTa ( Liu et al . , 2019 ) as the PLM . Dur-   ing the training , we train with batch size of 2for10   epoches . The optimizer is Adam with learning rate   2efor the PLM optimization and 5efor opti-   mizing domain discriminators . All experiments are   conducted with an NVIDIA GeForce RTX 2080   Ti.5.2 Baselines   We compare our method against 2state - of - the - art   methods , and also design several variants of ﬁne-   tuning and prompt tuning as baselines to demon-   strate the effectivenss of adversatial training strat-   egy in soft prompt tuning for DA .   ( 1)BERT - DAAT ( Du et al . , 2020 ): Use BERT   post - training for cross - domain sentiment analysis   with adversarial training .   ( 2)SENTIX(Zhou et al . , 2020 ): Pre - train a   sentiment - aware language model by several pre-   training tasks .   ( 3)Fine - tuning : Standard ﬁne - tuning vanilla   PLMs in the source domain labeled data , which   use the hidden representation of [ CLS ] for classiﬁ-   cation .   ( 4)Fine - tuning + AT : Add the adversarial train-   ing operating on standard ﬁne - tuning vanilla PLMs .   ( 5)Prompt - tuning(Hard ) : Use a manually de-   ﬁned template “ It is [ MASK ] ” for prompt - tuning .   ( 6)Prompt - tuning(Hard ) + AT : Add the adver-   sarial training operating on Prompt - tuning(Hard ) .   Following previous work ( Du et al . , 2020 ; Zhou   et al . , 2020 ) , we adopt the accuracy to evaluate the   performance .   5.3 Main Results   Main results contain results of single - source do-   main adaptation ( Table 1 ) and multi - source domain   adaptation ( Table 2).2443   Results of Single - source Domain Adaptation .   Table 1 shows our main experimental results under   single - source domain adaptation . We can observe   that our method AdSPT outperforms all other meth-   ods in most of single - source domain adaptation .   Compared with previous state - of - the - art meth-   ods , AdSPT is signiﬁcantly superior to BERT-   DAAT and SENTIXon average ( 3:02absolute   improvement and 0:46absolute improvement , re-   spectively ) . More speciﬁcally speaking , prompt-   tuning methods achieve better results than BERT-   DAAT on most of single - source domain adaptation .   This indicates that prompt tuning can stimulate   pre - encoded knowledge in PLMs to solve the DA   problem . But the performance of PT(H)and   PT(H ) + AT is lower than that of SENTIX   on average ( 91:12 % v.s.92:68 % and92:06 % v.s.   92:68 % ) , showing that the feature representation   of the [ MASK ] token in hard prompt tuning learns   more domain knowledge of source domains , which   leads to degraded performance on the target do-   main . Conversely , PT(S)is comparable to   SENTIXon average ( 92:45 % v.s.92:68 % ) and   AdSPT achieves better results than SENTIX   on average ( 0:46absolute improvement ) . It shows   that soft prompt tuning not only learns domain-   aware continuous vectors , but also weakens the   domain discrepancy of the feature distribution of   the[MASK ] position . In addition , prompt - tuning   methods are consistently superior to FTandFT +   AT , either using a hard prompt , or soft prompt .   In prompt - tuning , soft prompt tuning methods   achieve better performances than corresponding   hard prompt tuning methods ( 1:33absolute im-   provement and 1:08absolute improvement , respec-   tively ) . This indicates these separate soft prompts   can ﬂexibly learn in - domain knowledge of different   domains , which makes the feature representation   of the [ MASK ] token more suitable for predicting   the predeﬁned label words . So soft prompt is more   applicable to the DA problem than a hard prompt .   When we add a domain adversarial training oper - ation on soft prompt tuning , AdSPT achieves the   new start - of - the - art result on average . It shows that   the domain adversarial training strategy can en-   hance the domain - invariant feature of the [ MASK ]   token among different domain datasets .   Results of Multi - source Domain Adaptation .   Table 2 shows our main experimental results under   multi - source domain adaptation .   Compared with ﬁne - tuning methods , variants of   prompt tuning achieve better performances ( over at   least0:55absolute improvement on average ) . This   is mainly because prompt tuning uses the feature   representation of [ MASK ] token for classiﬁcation ,   rather than the feature representation of [ CLS ] to-   ken . On the one hand , ﬁne - tuning is difﬁcult to   train the domain - speciﬁc classiﬁer accurately from   scratch on the unlabeled dataset . On the other hand ,   prompt tuning is used to classify by predicting the   feature distribution of the [ MASK ] token in the   set of label words , which can activate some prior   knowledge in PLMs .   Compared with hard prompt tuning methods ,   soft prompt tuning methods achieve signiﬁcant im-   provements on average ( 92:94 % v.s.91:39 % and   93:75 % v.s.92:94 % ) . Constructing the sophis-   ticated hard template not only requires expertise   knowledge and time , but the uniﬁed predeﬁned   hard template leads to the domain discrepancy of   the feature representation of the [ MASK ] position   that is unsuitable for multi - domain adaptation .   Besides , PT(H ) + AT achieves a better re-   sult than PT(H)on average ( 0:61absolute   improvement ) , which shows the domain adversar-   ial training can obtain domain - invariant features   among different domains by domain discriminators   for DA . So when adding the domain adversarial   training into soft prompt tuning , AdSPT achieves   the best results under multi - source domain adap-   tation setting . This shows the effectiveness of the   collaboration of soft prompt tuning and the domain   adversarial training strategy . In the domain ad-2444   versarial training , using the feature representation   of the [ MASK ] token to obtain domain invariance   is better for predicting the predeﬁned set of label   words .   5.4 Analysis   Multi - source v.s. Single - source . We make   more detailed comparisons to explore the effect of   multi - source domain adaptation and single - source   domain adaptation settings . Figure 3 illustrates the   inﬂuence of multi - source and single - source on the   predicted results of the same target domain . When   the target domain is “ E ” , “ D ” , or “ B ” , multi - source   achieves better results in the target domain than   single - source , showing that in most cases , multi-   source domain adaptation is superior to single-   source domain adaptation in cross - domain research .   However , when the target domain is “ K ” , the re-   sult of “ E!K ” is superior to that of “ BDE !   K ” ( 94:75 % v.s.93:75 % ) . It is mainly because the   feature distribution of “ E ” and “ K ” is closer .   Effect of Soft Prompts . As stated in previous   works ( Gao et al . , 2020 ) , the choice of hard tem-   plates may have a huge impact on the performance   of prompt tuning . In this subsection , we carry out   experiments in “ BDE ! K ” and “ B!K ” respec-   tively to investigate the inﬂuence of different soft   prompts under multi - source domain adaptation and   single - source domain adaptation settings .   As shown in Figure 4 , we use 6 different soft   prompts ( by changing the number of prompt to-   kensk ) . The results demonstrate that the choice   of templates exerts a considerable inﬂuence on the   performance of prompt tuning . For soft prompts ,   surprisingly , prompt tuning yields the best result   with the fewest special tokens . Here k= 3 .   6 Conclusion   In this paper , we proposed a novel Adversarial   SoftPrompt Tuning method ( AdSPT ) for cross-   domain sentiment analysis . Firstly , we use domain-   speciﬁc soft prompts instead of hard templates to   represent domain - speciﬁc knowledge . The domain-   speciﬁc soft prompts can alleviate the domain dis-   crepancy w.r.t . the [ MASK ] representations by   MLM task . Meanwhile , we also design a novel   adversarial training strategy to learn the domain-   invariant knowledge of the [ MASK ] token among   different domains . Experiments on the Amazon re-   views dataset achieve state - of - the - art performance.2445Acknowledgements   We thank the anonymous reviewers for their helpful   comments and suggestions . This work is supported   by the Project of Technological Innovation 2030   “ New Generation Artiﬁcial Intelligence ” ( Grant no .   2020AAA0107904 ) , the Major Scientiﬁc Research   Project of the State Language Commission in the   13th Five - Year Plan ( Grant nos . WT135 - 38 ) , and   the Key Support Project of NSFC - Liaoning Joint   Foundation ( Grant no . U1908216 ) .   References24462447