  Longxu Dou , Yan Gao , Xuqi Liu , Mingyang Pan , Dingzirui Wang ,   Wanxiang Che , Min - Yen Kan , Dechen Zhan , Jian - Guang LouHarbin Institute of TechnologyMicrosoft Research AsiaNational University of Singapore   { lxdou , xqliu , mypan , dzrwang , car}@ir.hit.edu.cn , dechen@hit.edu.cn ,   { yan.gao , jlou}@microsoft.com , kanmy@comp.nus.edu.sg   Abstract   In this paper , we study the problem of   knowledge - intensive text - to - SQL , in which   domain knowledge is necessary to parse ex-   pert questions into SQL queries over domain-   specific tables . We formalize this scenario by   building a new Chinese benchmark K SQL   consisting of domain - specific questions cov-   ering various domains . We then address this   problem by presenting formulaic knowledge ,   rather than by annotating additional data exam-   ples . More concretely , we construct a formu-   laic knowledge bank as a domain knowledge   base and propose a framework ( RGP )   to leverage this formulaic knowledge during   parsing . Experiments using RGPdemon-   strate a significant 28.2 % improvement overall   on K SQL .   1 Introduction   Text - to - SQL translates user queries into executable   SQL , greatly facilitating interactions between users   and relational databases . Along with the release   of large - scale benchmarks ( Zhong et al . , 2017 ; Yu   et al . , 2018 , 2019a , b ) and developments in model   design ( Wang et al . , 2020a ; Cao et al . , 2021 ) , text-   to - SQL works are now achieving promising results   in both research and practical applications ( Zeng   et al . , 2020 ) .   However , in the professional application of text-   to - SQL , such as in the data analysis of financial   reports , models require external knowledge to map   the expert query with the domain - specific database .   Take the financial query for example : What ’s the   EBITof Walmart ? , where the underlying database   has component columns that can be used to calcu-   late the EBIT . We treat this problem as knowledge-   intensive text - to - SQL , where domain knowledge   is highly necessary to parse expert questions overFigure 1 : Harnessing RGPwith formulaic knowl-   edge for knowledge - intensive text - to - SQL with three   steps : ( 1 ) Retrieval the formulaic knowledge ; ( 2 )   Grou nd the concept of formulaic knowledge ; ( 3 ) Parse   the question .   domain - specific tables . This problem prevents text-   to - SQL techniques from being fielded in novel ,   professional applications to assist the experts in   processing data .   Traditional approaches would address this prob-   lem by annotating specific question / SQL pairs on   a target domain ( Wang et al . , 2015 ; Herzig and   Berant , 2019 ) . Then such mappings are induced   during the training process . This approach does   work but has the drawback that any induced infor-   mation is both fragile andexpertise - heavy : such   knowledge does not port across domains and re-   quires expert knowledge to craft .   We propose to solve this problem by modeling   how a non - expert person might tackle this prob-   lem . When meeting unseen examples ( as in the   EBIT case above ) , they may first search for the re-   lated mathematical formulas from public resources ,   then ground the concepts referenced in the formu-   las with schema elements presented in their partic-   ular databases . This process leverages common ,   encoded formulaic knowledge that are already de-   scribed in publicly - available resources such as tu-5240torials , textbooks , encyclopedias , and references .   Inspired by this , we propose to address the   knowledge - intensive text - to - SQL through formu-   laic knowledge which provides the evidence of   mapping from domain - specific phrases presented   in questions to actual SQL operations over schema   elements . More concretely , we define a taxonomy   of three types of formulaic knowledge : calcula-   tion , union , and condition , each corresponding to   a particular snippet of SQL . Then we propose R-   GP , a text - to - SQL framework ( Fig . 1 ) , con-   sisting of three stages : ( 1 ) Retrieve the formulaic   knowledge from formulaic knowledge bank as an   external knowledge source ; ( 2 ) Grou nd the concept   of formulaic knowledge to the schema elements   ( e.g. ,Exports toShip_Out ) ; ( 3 ) Parse the results   with the question , schema , and grounded formu-   laic knowledge . The external formulaic knowledge   bank imbues RGPwith formulaic knowledge ,   making it knowledgeable .RGPis also ex-   tensible because updating the formulaic knowledge   bank does not require retraining any modules .   Moreover , we construct a Chinese benchmark   K SQL , to examine the effectiveness of R-   GPframework . It advances the existing   knowledge - intensive text - to - SQL beyond the previ-   ous work ( Wang et al . , 2020b ; Zhao et al . , 2022 ) by   considering more SQL operations and challenging   domains . Experimental results demonstrate the R-   GPwith formulaic knowledge would improve   the performance by 23.4 % overall . Furthermore ,   we classify error cases into three classes , which are   resolvable by advancing the corresponding mod-   ule of RGP . Finally , we discuss the potential   future work such as expanding the scope of knowl-   edge and advancing RGP model design .   Our contributions are summarised as follows :   •To the best of our knowledge , we are the first   to explore knowledge - intensive text - to - SQL   and propose a challenging Chinese benchmark   K SQL , which requires domain - specific   knowledge .   •We propose a novel framework RGP   to address knowledge - intensive text - to - SQL   by retrieving and grounding formulaic knowl-   edge , which is knowledge - extensible .   •Experimental results demonstrate the effec-   tiveness of RGP with formulaic knowl-   edge which achieves 28.2 % overall improve-   ment on K SQL.2 Knowledge - Intensive Text - to - SQL   2.1 Problem Analysis   After studying the real cases in professional data   analysis , we roughly categorize the required knowl-   edge for knowledge - intensive text - to - SQL into   three classes : ( 1 ) linguistic knowledge enables the   model to adapt to linguistic diversity ; ( 2 ) domain   knowledge allows the model to perceive domain-   specific sayings and concepts ; ( 3 ) mathematical   knowledge yields the specific SQL operations ( e.g. ,   Density phrase to division operation ) . These three   sets of knowledge jointly provide the evidence of   mapping from domain - specific phrases of questions   to actual SQL operations over schema elements .   However , most text - to - SQL researches focus on   general scenario ( Yu et al . , 2018 ; Zhong et al . ,   2017 ) , where linguistic knowledge is mainly re-   quired . Recently , Wang et al . ( 2020b ) and Zhao   et al . ( 2022 ) promote text - to - SQL to more chal-   lenging scenarios via involving the calculation   questions . In this paper , we further explore the   knowledge - intensive text - to - SQL by considering   more operations ( e.g. , calculation , union , and condi-   tion ) with more challenging domains which require   all these three classes of knowledge .   2.2 Challenge   Despite that pre - trained language models con-   tain linguistic knowledge , they lack domain   knowledge and mathematical knowledge . There-   fore , the model would meet two problems : ( 1 )   do n’t know which operations to use : if an   operation ( e.g. ,density = total number / space )   has never occurred in training data , the model   rarely employ this unseen operation during   the inference ; ( 2 ) do n’t know how to adapt   operations : the model would fail to generalize   the operation across domains . For instance ,   the model can not generalize the calculation of   Population Density ( number of people / land area )   toCar Density ( number of cars / parking lot area ) .   Accordingly , we consider that the vanilla pre-   trained language model is ( 1 ) narrow since it   only supports the limited operation and ( 2 ) in-   efficient since it ca n’t generalize the operation   across domains . However , it ’s time - consuming and   expertise - heavy to directly increase the amount of   annotated data examples . In contrast , we address   this challenge from the view of formulaic knowl-   edge in Sec 3 , which is more knowledge - extensible.52412.3 K SQL Benchmark   To uncover the knowledge - intensive text - to-   SQL problem and advance the research , we con-   struct a challenging Chinese text - to - SQL bench-   mark named K SQL . Roughly , it consists of   two parts : training / dev sets built on the existing   DuSQL ( Wang et al . , 2020b ) dataset and a newly   constructed test set on three professional domains   with discovered knowledge in DuSQL .   2.3.1 Building Training / Dev Set on DuSQL   We build the training / dev set of K SQL based   on the existing DuSQL , a Chinese multi - table   text - to - SQL benchmark . We categorize its 200   databases into 16 domains like sports , energy ,   health care , foods , etc . Given the high quality   of DuSQL schema and broad domain coverage ,   it ’s a satisfactory start - point to build a challeng-   ing knowledge - intensive text - to - SQL benchmark .   However , the domain - specific question is not well   included in DuSQL , where most of the questions   could be answered easily without relying on exter-   nal knowledge and only considers one SQL oper-   ation ( i.e. , calculation ) . Given that , we extend the   original DuSQL by adding more domain - specific   questions and involving more operations in both the   train set and the dev set . Eventually , K SQL   expands the size of DuSQL train set from 22,521   to 23,157 and the dev set from 2,482 to 2,731 .   2.3.2 Building Test Set from Scratch   To simulate the professional data analysis scenario ,   we create a challenging test set covering three do-   mains ( finance , estate , and transportation ) . These   three domains have high data analysis requirements   in real life . Different from the train / dev sets , we   construct the test set from the scratch by : ( 1 ) col-   lecting the domain - specific tables , and ( 2 ) annotat-   ing the domain - specific questions and correspond-   ing SQL queries .   Table Collection . For collecting table schema ,   we collect the tables from the following source :   ( 1 ) the public annual reports of the company ( 2)the industry reports ( 3 ) academic papers ( 4 ) the   statistical reports released by the government . To   ensure the table quality , we conduct several pre-   processing procedures . Firstly , we convert matrix   tables ( present in annual reports ) into relational   tables to make the question SQL - answerable . Next ,   to ensure the table data quality , we conduct data   cleaning ( e.g. , filtering out the irrelevant columns   to simplify the table structure , and normalizing the   headers to reduce the noise ) . Finally , to avoid data   privacy issues , we conduct value anonymization   ( e.g. , removing direct identifiers and anonymizing   geo - related data ) .   Question Annotation . It ’s challenging for an-   notators to propose the domain - specific questions   without background knowledge . Thus , we   train the annotators first about the domain - specific   knowledge via ( 1 ) collecting the jargon ( i.e. , ab-   breviation , terminology ) from the domain - specific   open resources , which are widely adopted by do-   main experts ( e.g. , EBIT for finance ) but unusual   for a layperson ; ( 2 ) to mimic the domain expert by   asking questions using the jargon with the above   materials .   After that , the annotators would annotate the   questions and SQL with the following criteria : ( 1 )   be faithful to the given table ( i.e. , do n’t exceed the   scope of table columns and table content ) ; ( 2 ) not   be directly answerable by the single element of the   table but could be answered by the operation over   existing columns ; ( 3 ) limited to first - order opera-   tion ( i.e. , excludes multi - hop questions like ‘ What   is the gross profit ? ’ , where the table only contains   ‘ Sales ’ , ‘ Average Price ’ and ‘ Cost of Goods Sold ’   so that model needs to compute the ‘ revenue ’ first ) .   2.3.3 Dataset Quality and Data Statistic   To guarantee the data quality , we conduct a multi-   rounds check . Finally , the inter - agreement of an-   notators reaches 94.7 % . During each round , we   ask each annotator to review others ’ annotations   based on the criteria ( stated above ) , then ask them   to further improve annotations that do not meet the   criteria . As shown in Tab.1 , the test set contains 288   databases and 2,580 questions . Notably , all these   challenging data examples in the test set could be   covered by 380formulaic knowledge , which will   be discussed in Sec . 3.5242   3 Approach : Formulaic Knowledge   3.1 Motivation   When meeting unseen examples , the human may   first search the related mathematical knowledge   or domain knowledge from textbooks or encyclo-   pedias . As shown in Fig . 2 , the information of   calculation of EBIT is returned in both textual and   formulaic format . Intuitively , the formulaic for-   mat is preferred because it ’s ( 1 ) more concise and   precise : for instance , a adds b times c is more am-   biguous than a+b*c or(a+b)*c ; ( 2 ) easy to obtain :   most description of calculation is stored in a formu-   laic format in the textbook , tutorials , and academic   paper ; ( 3 ) SQL parser friendly : the formulaic for-   mat is closed to the snippet of SQL then easily for   the parser to generate .   3.2 Formulaic Knowledge for Text - to - SQL   Following this idea , we focus on three categories   of operations ( Fig . 3 ): calculation , union , and   condition . Besides the popular calculation knowl-   edge , we also consider the taxonomy information   asunion knowledge and the judgment standard as   condition knowledge . The design insight here is   that the left part is the name of the knowledge item ,   and the right part expresses its semantic meaning   represented by operations over concepts . Note thatall operations are consistent with SQL grammar ,   making it closer to SQL query . Besides the entity ,   the left part of formulaic knowledge might also be   the SQL function ( e.g. , NOW ( ) ) or constant ( e.g. ,   threshold of Real Estate Bubble ) .   3.3 Formulaic Knowledge Bank   We further build a formulaic knowledge bank with   1,954 formulaic knowledge items , which supports   19 domains involved in K SQL . Importantly ,   the bank covers all these examples of K SQL   as shown in Tab . 2 . Note that this bank is a   domain - related resource , not one tied to the spe-   cific database . Thus , this bank is more general   and could be utilized in other applications natural   language applications ( e.g. , question answering ) .   Criteria The design of the formulaic knowledge   follows three criteria : ( 1 ) Only the first - order ( flat )   formulaic knowledge is considered ( i.e. , the con-   cept in the formulaic item should be align - able to   the schema elements rather than another formulaic   item ) ; ( 2 ) The stored formulaic knowledge should   be both faithful ( i.e. , acknowledged by the expert )   and standardized ( i.e. , shared at the domain level ) ;   ( 3 ) The formulaic knowledge should be domain-   level ( i.e. , not tied to the specific schema elements ) .   Collection We collect the formulaic knowledge   from the following public resource : ( 1 ) Baidu   Wenku , the platform where the domain experts   usually share the domain knowledge of various   domain ; ( 2 ) CNKI , China ’s largest academic web-   site ; ( 3 ) the data analysis websites of a specific   domain , like ESPN for sports and Yahoo for fi-   nance . We also collect some knowledge from the   English resource and let annotators translate this   domain knowledge into Chinese .   Abstraction To make the formulaic knowledge   more generic , we propose to accumulate the for-   mulaic knowledge at the domain level instead of   database - specific . Specifically , we abstract the con-   cept of formulaic knowledge before storing them in   the knowledge bank , which indicates the operation   over concept rather than specific schema . For ex-   ample , we would extract the formulaic knowledge   from ‘ People Density in China 2020 = total num-   ber of Chinese in 2020 / Chinese Land Area ’ to   ‘ People Density = total number of People / Area’.5243   Consequently , only ONE formulaic knowledge is   required to address MANY schema elements to   calculate the density of animals / cars / shops .   Mapping within K SQL We further exam-   ine the overlap between formulaic knowledge bank   andK SQL benchmark . As stated in Sec 2.3.3 ,   all questions from K SQL are covered by for-   mulaic knowledge banks . Specifically , there are   1,954 knowledge items in the bank , and 891 items   are used for answering the K SQL questions   as shown in Table 2 . Especially , there are extra   1,063 knowledge items beyond K SQL which   could support future work in applying formulaic   knowledge .   4 RGP Framework   To address the knowledge - intensive text - to - SQL   problem , we propose a novel framework named   RGP , consisting of three stages : ( 1 ) Retrieve   the formulaic knowledge from the formulaic knowl-   edge bank as an external knowledge source ; ( 2 )   Grou nd the concept of formulaic knowledge to   the schema elements ( e.g. ,Exports toShip_Out ) ;   ( 3)Parse the results with the question , schema ,   and grounded formulaic knowledge . As shown in   Fig . 4 , RGPconsists of three models : re-   triever , grounding model , and parser . We will give   a brief introduction of each model in the follow-   ing.4.1 Retriever Model   The goal of the retriever is to extract the rele-   vant formulaic knowledge items from the formu-   laic knowledge bank ( Fig . 4 ) . The challenge is   the fine - grained modeling of the formulaic knowl-   edge to disambiguate the ones with the same intent   but differing in operation over concepts , such as   calculating EBIT in different ways . We directly   utilize the off - the - shelf Dense Passage Retriever   ( DPR ) ( Karpukhin et al . , 2020 ) which was origi-   nally designed for open - domain QA . It employs a   bi - encoder architecture to learn the dense represen-   tation of sentences and passages , then it computes   the dot - product between the representations as the   similarity score .   To adapt the DPR in the formulaic knowledge re-   trieval task , we treat the formula knowledge bank as   the passage candidate and concatenate the question   with flattened schema ( separated by special token   ‘ | ‘ ) to enrich the semantics of the question . Then   we follow the standard DPR training procedure to   optimize the bi - encoder . Specifically , during the   training process , we derive the positive knowledge   items from K SQL annotation and sample five   negative examples from the formulaic knowledge   bank . During the inference process , we first cache   the embedding of formulaic knowledge items , then   leverage the FAISS algorithm ( Johnson et al . , 2017 )   to rank each formulaic knowledge item .   4.2 Grounding Model   Given the retrieved knowledge items , the goal of   the grounding model is to edit the formulaic knowl-5244   edge items w.r.t specific schema through ( 1 ) remov-   ing the irrelevant concept and ( 2 ) instantiating the   concept with the schema elements . The main chal-   lenge is the expensive annotations of grounding   ( i.e. supervision ) . Therefore , the weakly super-   vised grounding approaches would be more suit-   able . Specifically , we leverage the Erasing - then-   Awakening ( ETA ) model proposed by ( Liu et al . ,   2021 ) , which was originally designed for ground-   ing the entity from the knowledge base to the entity   mentioned in the question . The output of ETA is a   confidence matrix , indicating the possible ground-   ing relations between entity mentions and entities .   To adapt the ETA in the formulaic knowledge   grounding task , we treat each knowledge item as   the ‘ question ’ and attempt to figure out which spe-   cific schema elements are grounded in the knowl-   edge item . Specifically , it ’s determined by a hyper-   parameter Hto indicate the threshold of confi-   dence ( whether it ’s grounded and which one it ’s   grounded ) . As shown in Fig . 4 , we filter the concept   ( cross outed parts ) under the confidence threshold   Hand replace the concept with aligned elements   ( green parts ) .   4.3 Parser Model   The goal of the parser is to predict the executable   SQL according to question and database schema .   The main challenge is how to model the database   structure to infer the implicit schema mentioned ,   and how to make use of the grounded knowl-   edge ( i.e. , knowledge - fusion ) to leverage grounded   knowledge . We are inspired by the recent progressin adopting the large pre - trained language model in   semantic parsing problems . For instance , ( Scholak   et al . , 2021 ; Shin et al . , 2021 ; Dou et al . , 2022 ;   Xie et al . , 2022 ) achieves excellent performance   on several semantic parsing tasks under the sim-   ple pretrained language model framework , such as   BART ( Lewis et al . , 2020 ) and T5 ( Raffel et al . ,   2020 ) .   Given that , we propose to adopt UniSAr ( Dou   et al . , 2022 ) as the base parser in this work . It im-   proves the vanilla BART with three non - invasive   extensions and achieves SOTA or competitive per-   formance on seven text - to - SQL benchmarks . Con-   cretely , the input of the model is the concatena-   tion of the question , serialized schema , and re-   trieved formulaic knowledge . We propose that the   parser should correctly adopt the grounded formu-   laic knowledge during SQL generation .   5 Experimental Results and Analysis   To evaluate our approach : RGPwith exter-   nal formulaic knowledge bank , we conduct several   experiments on K SQL benchmark . We report   both the overall results of the pipeline and the fine-   grained results of each module . We also conduct   error analysis and categorize the bad cases into   three main classes . Note that we report the average   experimental results of each setting during three   runs.5245   5.1 Experimental Setup   The retriever returns the top-3 retrieved formu-   laic knowledge items from the bank . The ground-   ing model further aligns the concept in formulaic   knowledge into schema elements and the decision   threshold His0.6which is decided empirically .   The parser receives the grounded knowledge , table   schema , and user query as the input and then out-   puts the SQL . For the parsing baseline , we adopt   UniSAr ( Dou et al . , 2022 ) as the vanilla parser .   5.2 Overall Results   As shown in Tab . 3 , we could observe that : ( 1 )   RGPexceeds the vanilla model by 28.2 % ,   which indicates the effectiveness of using formu-   laic knowledge ; ( 2 ) grounding the formulaic knowl-   edge improves the RGPby9.0 % ; ( 3 ) the or-   acle formulaic knowledge ( retrieve correctly and   grounding correctly ) reaches the upper bound of   RGP74.8 % , which implies the potential im-   provement room for K SQL.5.3 Fine - grained Results   We compare the retriever and grounding model   with other baselines , on both the dev set and the   test set of K SQL in the finance domain , to   examine the performance in general and domain-   specific scenarios .   Retriever We compare the retriever of R-   GP(bi - encoder ) with BM-25 ( Robertson and   Zaragoza , 2009 ) . The evaluation metric is the re-   call score over retrieved results . We observe that   the finance domain is more challenging than the   general domain ( dev split ) since it contains many   homogeneous formulaic knowledge items that ex-   press the same intention in the left part but with   different computation ways in the right part . For   example , there are two ways to compute the ‘ EBIT ’   in Fig . 4 .   Grounding We compare the grounding model   ofRGPwith the fuzzy string match - based   method . Following the previous work ( Lei et al . ,   2020 ; Liu et al . , 2021 ) , we report the micro - average   precision , recall , and F1 - score . We could observe   that : ( 1 ) the model - based grounding improves the   performance by 5.1 % and 10.6 % respectively ; ( 2 )   the domain - specific data like Finance poses more   challenging cases than the general domain , where   finance is behind the dev by about 27.0 % .   5.4 Error Analysis   We sample 300 cases from the dev split and 100   cases from finance / estate / transportation in the test   split respectively ( 600 in total ) for error analysis .   Vanilla Model Error We first compare the cor-   rect case of RGPwhile predicted incorrectly   by the vanilla model . As the example in the first   part of Fig . 5 , the vanilla model is unable to pre-   dict the unseen operation during training . In con-   trast , the grounded formulaic knowledge enables5246   RGPto predict the operation over schema   elements correctly .   Then we categorize the error of RGPinto   three main classes and list their percentage in Fig . 5 .   Finally , we discuss the potential future work in   improving each part of RGP . An advantage   ofRGPis the decoupled framework could   track each type of bad case individually , avoiding   the catastrophic forgetting problem .   Retrieval Error About 43 % errors are attributed   to the retriever where the model does n’t get the   correct knowledge from bank since it ca n’t distin-   guish the semantic difference between the closed   formulaic knowledge items . Future work should   improve its distinguishing ability by fine - grained   modelings , like attention mechanism Huang et al .   ( 2019 ) .   Grounding Error About 41 % errors are caused   by incorrect grounded knowledge where the model   does n’t learn the knowledge by alignment since   it ca n’t correctly align the concept to schema ele-   ments . Future work should focus on how to derive   the grounding information under weak supervisionor even without supervision . It would greatly allevi-   ate the severe annotation effort in specific domains .   Parsing Error There are still 8 % error cases   caused by parsing , where the formulaic knowledge   is correctly retrieved and grounded but the parser   stilldoesn’t use the grounded knowledge in gen-   eration well . Future work should improve it by   explicitly modeling the copy process of knowledge   from the input to the SQL snippet position , such as   implementing the additional gate mechanism .   Other Error The remaining 8 % errors are about   the SQL generation , such as the GROUP - BY or   nested SQL . Since it ’s not our main focus , we ig-   nore these cases in Fig . 5 for brevity .   6 Discussion   Is formulaic knowledge better than textual   knowledge for text - to - SQL ? In Sec.3.1 , we ar-   gue that formulaic knowledge is preferred over tex-   tual knowledge intuitively . Empirically , we con-   duct the experiments by the following steps : ( 1 )   transforming the formulaic knowledge to textual5247knowledge through annotators ; ( 2 ) training the re-   triever and parser with textual knowledge under the   same experiment setting as formulaic knowledge .   Experimental results reveal that textual knowledge   receives an overall performance degradation of   13.6 % compared with Table 3 . We conclude that   RGPprefers formulaic knowledge since it ’s   more close to the SQL snippets or schema repre-   sentation . Moreover , formulaic knowledge is both   precise and concise . In contrast , textual knowledge   is redundant and much more diverse in expressing   the equivalent meaning .   What ’s the cost of collecting formulaic knowl-   edge ? During the collection process of formulaic   knowledge bank ( 19 domains ) , we found most do-   mains have the public knowledge resource . More-   over , the effort spent on collection formulaic knowl-   edge is also acceptable compared with annotating   data examples . For example , we spent 4 hours in   collecting 219formulaic knowledge in the finance   domain , which is far more effective than annotat-   ing the equivalent data examples . Eventually , for-   mulaic knowledge improves the performance by   35.0 % without retraining the model as shown in   Table 3 ( from 8.7 % to 43.7 % ) .   How to expand the scope of formulaic knowl-   edge further ? In this paper , we mainly focus   on domain knowledge and mathematical knowl-   edge and transfer them into formulaic knowledge   format for model learning . Other types of knowl-   edge would improve the knowledge - intensive text-   to - SQL further , such as the commonsense knowl-   edge ( e.g. , water freezing point : temperature=0 ° C )   or personalized information ( e.g. ,favourite food :   Tiramisu ) . Thus , we could package these types of   knowledge into a formulaic format in future work .   7 Related Work   7.1 Domain Generalization of Text - to - SQL   To be applicable in real scenarios , a text - to - SQL   model should generalize to new domains with-   out relying on expensive domain - specific labeled   data . Previous work has shown that current text-   to - SQL usually fails on domain generalization sce-   narios ( Finegan - Dollak et al . , 2018 ) . Recent ap-   proaches track this problem including data synthe-   sis ( Yin et al . , 2021 ) , meta - learning ( Wang et al . ,   2021 ) and encoder pretraining ( Yin et al . , 2020 ;   Herzig et al . , 2020 ) . Most recently , Zhao et al.(2022 ) proposed to adopt schema expansion and   scheme pruning to preprocess the table schemas .   We highlight that compared with the schema-   expansion approach , the advantage of our ap-   proach ( RGPwith formulaic knowledge ) is   the broad knowledge scope : we not only consider   the calculation knowledge but also union knowl-   edge and condition knowledge . Moreover , our ap-   proach is extensible with an external and maintain-   able formulaic knowledge bank .   7.2 Retrieval Enhanced Semantic Parsing   There has been a recent trend toward leveraging   retrieval - enhanced methods in various NLP tasks   such as machine translation ( Cai et al . , 2019 ) and   question answering ( Karpukhin et al . , 2020 ) . Sim-   ilar with RGP , previous work ( Gupta et al . ,   2022 ; Pasupat et al . , 2021 ) leverage a retrieval step   to provides examples as the context of input for   seq2seq model learning .   However , our approach differs in two ways : ( 1 )   our retrieval object is grounded formulaic knowl-   edge which contains more condensed information   than data example ; ( 2 ) prior work directly leverage   the retrieved results . We leverage the grounding   model to edit the retrieved formulaic knowledge to   make it more relevant to the question and schema .   8 Conclusion and Future Work   This paper explores formulaic knowledge to ad-   dress the knowledge - intensive text - to - SQL prob-   lem , which would advance the professional appli-   cation of text - to - SQL such as data analysis for do-   main experts . First , we analyze the challenge of   knowledge - intensive text - to - SQL and construct a   new challenging benchmark K SQL . Then we   propose to address this problem from the view of   formulaic knowledge . Concretely , we propose a   simple framework RGPto leverage an exter-   nal formulaic knowledge bank . Experimental re-   sults reveal that RGPwith formulaic knowl-   edge achieves the 28.2 % improvements overall .   We further discuss three directions in improv-   ing the RGPvia analyzing different types   of bad cases : ( 1 ) iterative filling in the blank of   formulaic knowledge bank ; ( 2 ) mitigating the gap   between formulaic knowledge and specific schema   via improving the grounding model ; ( 3 ) driving the   parser to fully make use of more complicated ( e.g. ,   commonsense ) formulaic knowledge.5248Ethical Considerations   This work presents K SQL , a free and open   dataset for the research community to study   the knowledge - intensive text - to - SQL problem .   Data in K SQL are constructed based on   DuSQL ( Wang et al . , 2020b ) , a free and open   cross - database Chinese text - to - SQL dataset . We   also collect formulaic and table data from CNKI   and Baidu Wenku , which are also free and open   for academic usage . The content of the table is   anonymized to address the privacy issue . To anno-   tate the K SQL , we recruit 3 Chinese college   students ( 1 female and 2 males ) . Each student is   paid 4 yuan ( $ 0.6 USD ) for annotating the ( SQL ,   question ) pairs and 2 yuan ( $ 0.3USD ) for collect-   ing the formulaic knowledge items . This compen-   sation is determined according to the prior simi-   lar dataset construction ( Guo et al . , 2021 ) . Since   all question sequences are collected against open-   access databases or public tables , there is no pri-   vacy issue .   Limitations   ( 1)K SQL is built based on DuSQL , a Chinese   large - scale text - to - SQL dataset . Thus the language   coverage of this paper is limited to Chinese . We   leave the extension to other languages for future   work . ( 2 ) For the scope of formulaic knowledge ,   we mainly address three types of knowledge to   associate with each SQL phrase : calculation , union ,   and condition . Some types of knowledge are under-   explored such as commonsense knowledge . ( 3 ) For   the model design of RGP , we build it from   improving many existing works . Despite achieving   promising evaluation results , the case studies reveal   that many challenging remains during the retrieval ,   grounding , or parsing .   Acknowledgement   We thank all anonymous reviewers for their con-   structive comments . Wanxiang Che was supported   via the grant 2020AAA0106501 and NSFC grants   62236004 and 61976072 . Dechen Zhan is the cor-   responding author .   References524952505251A Details of Formulaic Knowledge Bank   A.1 Knowledge Source   We construct the formulaic knowledge bank across   19 domains following K SQL and 1 misc do-   main . The misc domain stores the infrequent or   general knowledge items in K SQL , such as   the calculation of density , and speed . In the fol-   lowing , we will briefly analyze the collected bank .   A.2 Statistic Across Domain   Different domains have different amounts of pub-   licly available data online . As shown in Fig . 6 , not   unsurprisingly , finance and estate share the most   plentiful publicly available resource .   A.3 Distribution within Domain   We also observe the different distribution of knowl-   edge across domains . If the domain focus on cal-   culation ( e.g. , finance report and fund ) , we assume   the data analysis tends to be more objective , which   is easier for model learning . If the domain focus   oncondition ( e.g. , estate and awards ) , we assume   the data analysis tends to be more subjective since   it ’s more challenging in learning semantics .   B Implementation Details of RGP   Retriever We implement the retriever based   on the code of Karpukhin et al . ( 2020 ) . We   adopt the Chinese BERT - wwm - ext ( Cui et al . ,   2021 ) as pretrained encoder . It would return   the top-3 retrieved formulaic knowledge . Future   work could improve the negative sampling by in-   batch sampling or BM25 - based sampling following   Karpukhin et al . ( 2020 ) .   Grounding Model The code of ETAis not re-   leased at the time of submission of this paper . We   re - implement the ETA model based on the paper   using pytorch ( Paszke et al . , 2019 ) . We evaluate   our implemented model with the original model on   S -L(Lei et al . , 2020 ) to examine whether the   re - implemented model works . Our model achieves   82.1 % column F1 score where Liu et al . ( 2021 )   reported 82.5 % . The experiments on K SQL   also employ the Chinese BERT.Parser We build the paper based on the code   of Dou et al . ( 2022)We choose the mBART-   CC25as the base model to fine - tune . Following   the vanilla model , we build the input of parser as   follows : [ schema ] | [ grounded formulaic knowl-   edge ] | [ question ] , where ‘ |’is the delimiter across   different parts .   Resource and Tools For tokenization , we em-   ploy Stanza ( Qi et al . , 2020 ) considering its excel-   lent performance . For the retriever and grounding   model , we import the BERT model with Trans-   former library ( Wolf et al . , 2020 ) . For parser mode ,   we preprocess the data and fine - tune the mBART   with fairseq framework ( Ott et al . , 2019 )   Device and Training Time We conduct all these   experiments on one NVIDIA TESLA V100 - 32 GB   GPU . The training of the retriever , grounding   model , and parser takes about 4 hours , 3 hours , and   8 hours respectively . The minimum device require-   ment is NVIDIA TESLA P100 - 16 G to fine - tune   mBART .   Hyper - parameters All the hyper - parameters are   kept the same as cited paper of each model . The   only difference is the batch size of the retriever   and grounding model , we turn it into the maximum   number to fit in the NVIDIA TESLA V100 - 32 G   GPU.52525253