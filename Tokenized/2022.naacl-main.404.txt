  Yiren Jian   Dartmouth College   yiren.jian.gr@dartmouth.edu   Chongyang Gao   Northwestern University   cygao@u.northwestern.eduSoroush Vosoughi   Dartmouth College   soroush@dartmouth.edu   Abstract   Few - shot language learners adapt knowledge   from a pre - trained model to recognize novel   classes from a few - labeled sentences . In such   settings , fine - tuning a pre - trained language   model can cause severe over - fitting . In this pa-   per , we propose an Embedding Hallucination   ( EmbedHalluc ) method , which generates auxil-   iary embedding - label pairs to expand the fine-   tuning dataset . The hallucinator is trained by   playing an adversarial game with the discrim-   inator , such that the hallucinated embedding   is indiscriminative to the real ones in the fine-   tuning dataset . By training with the extended   dataset , the language learner effectively learns   from the diverse hallucinated embeddings to   overcome the over - fitting issue . Experiments   demonstrate that our proposed method is ef-   fective in a wide range of language tasks , out-   performing current fine - tuning methods . Fur-   ther , we show that EmbedHalluc outperforms   other methods that address this over - fitting   problem , such as common data augmentation ,   semi - supervised pseudo - labeling , and regular-   ization . The code will be made available at :   https://github.com/yiren-jian/EmbedHalluc .   1 Introduction   Fine - tuning a pre - trained language model ( LM ) on   a downstream task with the labeled data has been   the de facto approach in many NLP tasks ( Wang   et al . , 2019 ; Devlin et al . , 2019 ) . Conventional fine-   tuning has been shown to be effective when a few   thousands of labeled examples are available . Data   augmentation ( Wei and Zou , 2019 ) , regularization   ( Lee et al . , 2019 ) and re - initialization ( Zhang et al . ,   2021 ) further improve the results .   However , the performance drops drastically   when the number of examples falls to only a few   dozens . Experiments from recent work ( Gao et al . ,   2021 ) have shown that fine - tuning performs poorly   in the setting where only 16 examples per class aregiven . Indeed , tuning a language model with hun-   dreds of millions of parameters ( e.g. , BERT - large   has 300 M parameters ) with only a few examples   inevitably faces the over - fitting problem .   Prior work have proposed regularization meth-   ods to overcome this problem ( Lee et al . , 2019 ;   Zhang et al . , 2021 ) . However , we show in our ex-   periments that these methods fail in extreme data   scarce setting . We speculate that the key to solve   this issue is by data augmentation .   Current common text data augmentation meth-   ods , such as EDA ( Wei and Zou , 2019 ) ( which have   been used in recent few - shot learning papers ( Wei   et al . , 2021 ; Basu et al . , 2021 ) ) and AEDA ( Karimi   et al . , 2021 ) operate at the lexical level , which while   resulting in human readable texts , lead to limited   diversity due to the discrete nature of the lexical   space . In this work , we propose to use a generative   augmentation method at the embedding space for   few - shot learning . The underlying hypothesis is   that the intra - class relation of the observed exam-   ples can be modeled and that this can be learned   from a few - samples to hallucinate diverse unseen   examples . To be specific , we adapt a conditional   Wasserstein Generative Adversarial Network ( cW-   GAN ) ( Arjovsky et al . , 2017 ) as our hallucinator   to hallucinate embeddings of sentences . By ob-   serving the real embeddings of examples from the   fine - tuning dataset , the cWGAN plays an adversar-   ial game to hallucinate embeddings that can fool   the discriminator , while the discriminator is try-   ing to classify the fake embeddings from the real   ones . Once the halluciantor is trained , we condi-   tion it on labels to generate diverse embeddings at   each fine - tuning step . This effectively extends the   fine - tuning dataset with diverse embedding - label   pairs which carry intra - class variation that can be a   useful learning signal for the language learner .   We evaluate our method , called Embedding Hal-   lucination ( Embedhalluc ) , on 15 tasks and show   that it generally improves over recent fine - tuning5522methods . We further experimentally show the   overall superiority of EmbedHalluc when compar-   ing to regularization methods proposed to address   the problem of over - fitting during fine - tuning of   LMs , such as Mixout ( Lee et al . , 2019 ) and Re - Init   ( Zhang et al . , 2021 ) . Finally , since our method   is a form of data augmentation , we also compare   EmbedHalluc to a common data augmentation tech-   nique EDA , and semi - supervised learning where   unlabeled data is already available .   2 Related Work   Fine - tuning of Language Models . Better fine-   tuning of language models can be achieved by   proper initialization ( Dodge et al . , 2020 ) , regular-   ization ( Lee et al . , 2019 ) or prompts ( Schick and   Schütze , 2021 ) . Other tricks include bias correc-   tion in optimizer and re - initialization of top layers   in Transformer ( Zhang et al . , 2021 ) . Instead of   fine - tuning all parameters in a model , other work   explore only learning a few vectors ( Lester et al . ,   2021 ; Li and Liang , 2021 ; Guo et al . , 2021 ) or a   few additional parameters ( Houlsby et al . , 2019 ) .   Hallucination Methods . Feature Hallucination   of examples is first introduced for visual recog-   nition ( Hariharan and Girshick , 2017 ) by meta-   learning ( Wang et al . , 2018 ) , variational inference   ( Luo et al . , 2021 ; Lazarou et al . , 2022 ) , and adver-   sarial learning ( Li et al . , 2020 ; Tjio et al . , 2022 ) .   Label Hallucination ( Jian and Torresani , 2022 ) as-   signs soft pseudo - labels for unlabelled images to   extend the fine - tuning few - shot dataset .   Learning from limited labeled data ( few - shot   learning ) in Computer Vision is usually achieved by   meta - learning ( Ren et al . , 2018a , b ; Jian et al . , 2020 ;   Jian and Gao , 2021 ) or transfer learning ( Tian et al . ,   2020 ) . In NLP , few - shot learning has been success-   fully applied to machine translation ( Arthaud et al . ,   2021 ) , abstract summarizing ( Fabbri et al . , 2021 ) ,   question and answering ( Hua et al . , 2020 ; Ram   et al . , 2021 ) , and entity recognition ( de Lichy et al . ,   2021 ; Tong et al . , 2021 ; Ding et al . , 2021 ) , by meta   learning ( Li and Zhang , 2021 ; Bansal et al . , 2020 ;   Sharaf et al . , 2020 ) , data augmentation ( Wei et al . ,   2021 ; Wei and Zou , 2019 ; Karimi et al . , 2021 ; Jian   et al . , 2022 ) , and prompts ( Gao et al . , 2021 ; Tam   et al . , 2021 ) .   Our method is a generative data augmentation   method in the embedding space . Different from   ( Wei et al . , 2021 ) which uses EDA ( Wei and Zou ,   2019 ) to augment examples at the discrete input   space , we hallucinate auxiliary examples at the em-   bedding space . Our method shares similarity to   FDA ( Kumar et al . , 2019 ) , which is also a genera-   tive data augmentation method , but at the feature   space . Also , different from FDA which is focused   on two intent classification tasks , our method can   be applied to a wide - range of NLP task as shown   by our experiments on 15 diverse tasks .   3 Method   3.1 Conditional Wasserstein GAN   GAN ( Goodfellow et al . , 2014 ) has led the revo-   lution of generative models to achieve impressive   results in synthesizing images ( Zhu et al . , 2017 )   and higher dimensional data ( Wang et al . , 2020 ) .   Wasserstein GAN ( WGAN ) ( Arjovsky et al . , 2017 )   uses the Wasserstein distance as the objective func-   tion to stabilize the training of GAN .   Our hallucinator is trained under the conditional   WGAN framework . After the training , we use it to   generate pseudo - embeddings of examples by feed-   ing it with random noisy vectors zsampled from   N(0,1)and the corresponding condition class la-   belsc . The hallucinated embeddings s , in   principal , are indiscriminative to the embeddings   of observed examples in that class .   3.2 Fine - tuning with Hallucinated Embedding   For a single input sentence , we first pass it through   the embedding layer to get the sentence embedding   s. We then concatenate swiths(c)to5523form a batch of mixture of real and fake embed-   dings [ s , s(c ) ] . The encoder learns from   the batch with the corresponding labels [ c , c ] .   Label Calibration . The hallucinated embed-   dings(c)is conditioned on its label c. How-   ever , this hard label may not best represent the class   information of the hallucinated embedding . We   propose Label Calibration ( LabelCalib ) by pseudo-   labeling from a teacher model F ( LMin   Algorithm 1 ) , where F is first fine - tuned on   the original training set ( without augmentation ) .   The soft - label of the embedding s(c)is then   c = F(s(c ) ) . Finally , the lan-   guage model Mlearns from the hallucinated em-   bedding by KL - divergence   L = KL(M(s(c ) ) , c)(1 )   The total loss of our method is   L = L+L ( 2 )   where L is the loss learning from real   embedding - label pairs . The pseudo - code for fine-   tuning of few - shot language learners with halluci-   nated embeddings is shown in Algorithm 1 .   Note that baselines considered in this paper use   total loss L = L. Computing L requires   one additional forward pass of the hallucinator and   one more forward pass and backward pass of the   language model . Thus , our method has about ×2   computational overhead compared to the baselines .   4 Experiments   4.1 Evaluation Datasets and Protocol   We evaluate our method on 15 classification tasks .   The evaluations are conducted by averaging results   on 5 different train test splits . We sample 16 exam-   ples per class to form a training set and construct a   validation set with the same size as the training set .   4.2 Training Details for Embedding   Hallucinators   The training of Embedding Hallucinators involves   training a generator and discriminator in the cW-   GAN framework . The generator is a 4 - blocks   model , with each block containing a FullyConnect   layer followed by a BatchNorm and LeakyReLU .   The hidden dimensions of the generator are   128,256,512,1024 . The hallucinated embeddings ,   i.e. , outputs of the generator are tensors of L×1024 ,   where the length of the generated embeddingsAlgorithm 1 Our method : EmbedHallucMax _ Step = 1000 , LM : Language model , H : Emebedding hallucinator ( pre - trained),Train _ Set : Training set , Sample : Randomly sampling function , CE : Cross Entropy loss , KL : KL - divergence loss.fori inMax _ Step do▷Training LM sent , y = Sample ( Train _ Set ) output = LM(sent ) L = CE(output , y ) L.backward ( ) optimizer.step ( ) end forfori inMax _ Step do▷Training LM sent , y = Sample ( Train _ Set ) embed = H(N(0,1 ) ) , c )   ▷Learning from real text output = LM(sent ) L = CE(output , y ) L.backward ( ) optimizer.step ( )   ▷Learning from hallucination prob = LM(embed ) output = LM(embed ) L = KL(prob , output ) L.backward ( ) optimizer.step ( ) end forreturn LM   Lis set to be 128 . The discriminator is a 3-   blocks model , each bock having a sequence of   FullyConnect - BatchNorm - LeakyReLU with the   same hidden dimension of 512 .   We train the Embedding Hallucinators for 150   epochs using a batch size of 64 , the Adam opti-   mizer ( β= ( 0.5,0.999 ) ) , and a learning rate of   0.0002 . The real embeddings are collected from   the language few - shot training set by passing text   into the embedding layer of the language model .   We apply gradient penalty with weight of loss 100   for training the cWGAN .   4.3 Training Details for Few - Shot Language   Learners   We draw two mini - batches during the training of   our few - shot language learners , i.e. , one from the   real language few - shot training set , another one by5524sampling the hallucinators ( see Algorithm 1 ) .   To fairly compare our method with baselines and   other methods , when learning with real sentences ,   we use the same learning rate of 1e(further jus-   tification of using this learning rate can be found in   Appendix D ) . Our method learns from hallucinated   embeddings with a grid search of learning rate of   1e,5e,1e , and batch size of 4,6,8 . We use   the same search for EDA ( Wei and Zou , 2019 ) and   semi - supervised pseduo - labeling ( SSL ) when learn-   ing with additional augmented or pseudo - labeled   data .   The models are selected based on the validation   accuracy every 100 steps . Finally , results are re-   ported by testing the models on the testing dataset .   The algorithm is implemented in PyTorch-1.10 and   experiments are conducted on Nvidia RTX-6000   and RTX - A6000 GPU .   4.4 Main Results on 15 Tasks   We compare our method EmbedHalluc ( w/o or w/   LabelCalib ) using RoBERTa - large on 15 tasks with   two fine - tuning methods : conventional ( Table 1 )   and prompt - based fine - tuning ( Table 2 ) . Results   for BERT - large - cased can be found in Appendix B.   In conventional fine - tuning , EmbedHalluc im-   proves over the baseline in 14 tasks , only   marginally under - performs in SST-5 ( 40.3 vs. 40.6   of baseline ) . When combining with LabelCalib ,   our method outperforms in all tasks . When apply-   ing to prompt - based fine - tuning , while our method   under - performs in MNLI , MNLI - mm and RTE , it   outperforms for all other tasks , with substantial   improvements over the baseline in CoLA , TREC ,   QNLI , MRPC .   The relatively smaller improvements for prompt-   based methods may be due to the inconsistency and   randomness in the learning process since we have   to insert [ mask ] token to a random position in the   hallucinated embedding s , for the calculation   of the loss . Whereas , in conventional fine - tuning ,   the[CLS ] token is always appended to the begin-   ning of s and the classification is performed at   the[CLS ] token .   4.5 Comparing to EDA and SSL   Since our method is a generative data augmenta-   tion ( DA ) method , we compare it to another DA   method EDA . We also consider semi - supervised   learning ( SSL ) which relies on unlabeled data ( 64   examples per class in our experiments ) . We ap-   ply pseudo - labeling ( Cascante - Bonilla et al . , 2021 )   for SSL , i.e. , we first fine - tune the model with the   few - shot training set and use the fine - tuned model   to pseudo - label the unlabeled data , finally we fine-   tune the model again with the few - shot training set   combined with the pseudo - labeled set .   EDA edits the input sentences by applying syn-   onym replacement , random swap , random deletion   and random insertion for a default 10 % ( α ) of to-   kens . EDA either greatly change the sentence with   a large αor fails to introduce substantial variations   ( which is crucial in the extreme low data setting )   of inputs with a small α . Since it operates in the   continuous embedding space , EmbedHalluc hallu-   cinates diverse embeddings that follow the distribu-   tion of few - shot set . Thus , we observe in Table 3   that EmbedHalluc is overall superior to EDA .   EmbedHalluc is still competitive when compar-   ing against SSL which assumes to have additional   64 examples per class from the task distribution .   4.6 Negative Results from Regularizations   Our method can also be viewed as an implicit regu-   larization method . Thus , we also compare to two5525   latest methods for better fine - tuning language mod-   els with regularization . Zhang et al . ( 2021 ) find   that fine - tuning can be achieved by : correcting   bias in the optimizer , re - initialization of top lay-   ers , and training longer . Correcting bias in the   optimizer is already fixed by the default optimizer   in Huggingface Transformer and training longer   surely will lead to further over - fitting in our ex-   treme data scarce scenario . Thus , we consider re-   initialization ( Re - Init ) of top layers as one of our   comparisons . We further compare against Mixout   ( Lee et al . , 2019 ) , which is shown to be an effective   regularization when fine - tuning with a few thou-   sand examples . We used the public code for both   of these methods . Since we adapt their code to   our extreme data deficient setting , we re - search the   hyper - parameters of both methods ( including their   suggested values ) . For Re - Init , we search the top   1,2,3,4,5 layers ; and for Mixout , we search mixout   rate from 0.1,0.2 , ... , 0.9and report their best re-   sults in Table 4 , using RoBERTa - large . Results for   BERT - large - cased can be found in Appendix C.   We find that those two methods fail to alleviate   the over - fitting problem in such extreme setting ,   though they have been to be effective when given a   few thousands examples .   5 Comparing to Adversarial Training   Adversarial training adds noise into the training   data to increase the robustness of a model . It has   been shown that adversarial training can also im-   prove the performance of language models . Here ,   we compare EmbedHalluc to two recent adversar-   ial training methods , freeLB ( Zhu et al . , 2020 ) and   SMART ( Jiang et al . , 2020 ) adapted to our setting .   For freeLB , we use the publicly available code and   suggested hyper - parameters for each task . In ad-   dition to the default batch size and learning rate   used in the baseline fine - tuning and EmbedHalluc ,   we also search additional batch sizes and learning   rates for freeLB . We use the default setting for   SMART . As shown in Table 5 , with one excep-   tion , our method largely outperforms freeLB and   SMART .   6 Limitations   While EmbedHalluc works well empirically , it re-   lies on hallucinating non - interpretable embeddings   to facilitate the learning process . Besides , the learn-   ing of cWGAN requires careful human attention to   maintain a stable training .   7 Conclusion   In this paper , we introduce an embedding halluci-   nation method for data augmentation for few - shot   learning , based on cWGAN . The proposed method   improves over the baselines in 15 tasks and outper-   forms a common augmentation method , and two   recent regularization methods.55268 Ethics Statement   As far as we are aware , our proposed work does   not have any explicit ethical concerns . However ,   our work relies on pre - trained language models ,   which have been shown to be biased in prior work   ( Liang et al . , 2021 ) . As such , users of such models ,   specially for sensitive applications , should be aware   of and if possible address such issues .   References552755285529A Best Learning Rate for   RoBERTa - prompt   Here , we provide best learning rates ( LR , searched   from1e,5e,1eas discussed in main paper )   forL of EmbedHalluc for each task used in   RoBERTa - large prompt - based fine - tuning .   B EmbedHalluc with BERT   In addition to the experiments using RoBERTa   shown in the main paper , here we show the results   of BERT - large - cased with conventional fine - tuning   as a further check on robustness of our method with   respect to the choice of model . Table B.1 shows the   results of the experiments . EmbedHalluc outper-   forms the baseline across 14 of the 15 tasks with   an average improvement of 2.43 over the baseline .   C Regularization Methods with BERT   Besides the experiments with RoBERTa - large   shown in the main paper , we present Re - Init and   Mixout using BERT - large - cased in this section .   The results are shown in Table C.1.Qualitatively similar to what we observe with ex-   periments using RoBERTa - large in the main paper ,   Re - Init and Mixout fail to outperform EmbedHal-   luc in most tasks , with the exceptions of SNLI and   QNLI .   D Learning Rate for Baselines   The baseline has only one loss L , whereas we   are learning with an additional loss L , making   the total loss to be L+L. The learning rate   forLin the baselines and ours are kept the same .   Note that we do not search for this learning rate for   our method . We choose 1e , which is the most   common learning rate to finetune BERT / RoBERTa .   As we show in Table D.1 , this learning rate pro-   duces reasonably good results for the baselines ,   being the best for 13 tasks and only marginally   under - performing in the other 2 tasks . The results   in Table D.1 are generated by running the baselines   with a batch size of 2 and different learning rates   1e,2e,5esuggested by Gao et al . ( 2021).5530