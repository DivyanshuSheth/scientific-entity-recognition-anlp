  Daniel Hershcovich   Department of Computer Science   University of Copenhagen   dh@di.ku.dkNicolas Webersinke Mathias Kraus   FAU Erlangen - Nuremberg   { nicolas.webersinke ,   mathias.kraus}@fau.de   Julia Anna Bingler   ETH Zurich   binglerj@ethz.chMarkus Leippold   University of Zurich   markus.leippold@bf.uzh.ch   Abstract   The climate impact of AI , and NLP research   in particular , has become a serious issue given   the enormous amount of energy that is increas-   ingly being used for training and running com-   putational models . Consequently , increasing   focus is placed on efﬁcient NLP . However ,   this important initiative lacks simple guide-   lines that would allow for systematic climate   reporting of NLP research . We argue that this   deﬁciency is one of the reasons why very few   publications in NLP report key ﬁgures that   would allow a more thorough examination of   environmental impact , and present a quantita-   tive survey to demonstrate this . As a remedy ,   we propose a climate performance model card   with the primary purpose of being practically   usable with only limited information about ex-   periments and the underlying computer hard-   ware . We describe why this step is essential   to increase awareness about the environmental   impact of NLP research and , thereby , paving   the way for more thorough discussions .   1 Introduction   As Artiﬁcial Intelligence ( AI ) , and speciﬁcally Nat-   ural Language Processing ( NLP ) , scale up to re-   quire more computational resources and thereby   more energy , there is an increasing focus on ef-   ﬁciency and sustainability ( Strubell et al . , 2019 ;   Schwartz et al . , 2020 ) . For example , training a   single BERT base model ( Devlin et al . , 2019 ) re-   quires as much energy as a trans - American ﬂight   ( Strubell et al . , 2019 ) . While newer models are ar-   guably more efﬁcient ( Fedus et al . , 2021 ; Borgeaud   et al . , 2022 ; So et al . , 2022 ) , they are also an order   of magnitude larger , raising environmental con-   cerns ( Bender et al . , 2021 ) . The problem will only   worsen with time , as compute requirements double   every 10 months ( Sevilla et al . , 2022).Figure 1 : Example usage of our proposed climate per-   formance model card ( § 5 ) , on the Hugging Face Hub .   This problem has been recognized by the NLP   community , and a group of NLP researchers has re-   cently proposed a policy documentof recommen-   dations for efﬁcient NLP , aiming to minimize the   greenhouse gas ( GHG ) emissionsresulting from   experiments done as part of the research . This pro-   posal is part of a research stream aiming towards   Green NLP andGreen AI ( Schwartz et al . , 2020 ) ,   which refers to “ AI research that yields novel re-   sults while taking into account the computational   cost , encouraging a reduction in resources spent . ”   While the branding of NLP and AI research   asgreen has raised some awareness of the envi-   ronmental impact , the large majority of NLP re-   searchers are still not aware of their environmental   impact resulting from training and running of large   computational models . This also explains why a2480research stream in a similar direction ( see § 2.1 ) , in   which software tools are proposed to measure car-   bon footprint while training models ( Lacoste et al . ,   2019 ; Henderson et al . , 2020 ; Anthony et al . , 2020 ;   Lottick et al . , 2019 ) , have not been adopted by the   community to a large extent ( see § 3 ) . However , we   claim that climate awareness is essential enough to   be promoted in mainstream NLP ( rather than only   as a niche ﬁeld ) and that positive impact must be   an inherent part of the discussion ( Rolnick et al . ,   2019 ; Stede and Patz , 2021 ) . Ideally environmental   impact should always be taken into consideration ,   when deciding on which experiments to carry out .   We aim to simplify climate performance report-   ing in NLP while at the same time increasing aware-   ness to its intricacies . Our contributions are :   •We conduct a survey of environmental impact   statements in NLP literature published in the   past six years ( § 3 ) . This survey is conducted   across ﬁve dimensions that directly inﬂuence   the environmental impact .   •We delineate the different notions of “ efﬁ-   ciency ” common in the literature , proposing   a taxonomy to facilitate transparent report-   ing , and identify ten simple dimensions across   which researchers can describe the environ-   mental impact resulted by their research ( § 4 ) .   •We propose a climate performance model card   ( § 5 ) with the main purpose of being practi-   cally usable with only limited information   about experiments and the underlying com-   puter hardware ( see Figure 1 ) .   2 Background   2.1 Automating Reporting   Several tools automate measurement and reporting   of energy usage and emissions in ML . Lacoste et al .   ( 2019 ) introduced a simple online calculatorto   estimate the amount of carbon emissions produced   by training ML models . It can estimate the carbon   footprint of GPU compute by manually specifying   hardware type , hours used , cloud provider , and re-   gion . Henderson et al . ( 2020 ) presented a Python   packagefor consistent , easy , and more accurate   reporting of energy , compute , and carbon impactsof ML systems by estimating them and generat-   ing standardized “ Carbon Impact Statements . ” An-   thony et al . ( 2020 ) proposed a Python packagethat   also has predictive capabilities , and allows proac-   tive and intervention - driven reduction of carbon   emissions . Model training can be stopped , at the   user ’s discretion , if the predicted environmental   cost is exceeded . Schmidt et al . ( 2022 ) actively   maintain a Python packagethat , besides estimat-   ing impact and generating reports , shows develop-   ers how they can lessen emissions by optimizing   their code or by using cloud infrastructure in geo-   graphical regions with renewable energy sources .   Bannour et al . ( 2021 ) surveyed and evaluated these   tools and others for an NLP task , ﬁnding substantial   variation in the reported measures due to different   assumptions they make . In summary , automated   tools facilitate reporting , but they do not substitute   awareness and should not be trusted blindly .   2.2 Greenwashing   While branding NLP and AI research as green in-   creases awareness of the environmental impact ,   there is a risk that the current framing , which ex-   clusively addresses efﬁciency , will be perceived   as the solution to the problem . Of course , we at-   tribute benevolent motives to the authors of the pro-   posed policy document . Nevertheless , we would   like to avoid a situation analogous to a common   phenomenon in the ﬁnancial ﬁeld , where compa-   nies brand themselves as green orsustainable for   branding or ﬁnancial reasons , without implement-   ing proportional measures in practice to mitigate   the negative impact on the environment ( Delmas   and Burbano , 2011 ) . This malpractice is analo-   gous to greenwashing . While this is a general   term , one aspect of greenwashing is “ a claim sug-   gesting that a product is green based on a narrow   set of attributes without attention to other impor-   tant environmental issues ” ( TerraChoice , 2010 ) .   Our motivation is in line with the EU Commis-   sion ’s initiative to “ require companies to substanti-2481ate claims they make about the environmental foot-   print of their products / services by using standard   methods for quantifying them . ”While Schwartz   et al . ( 2020 ) certainly do not argue that efﬁciency   issufﬁcient for sustainability , this notion , which   is potentially implied by the green branding , is   misleading and even harmful : regardless of the   extent of reduction , resources are still consumed ,   and GHGs are still emitted , among other negative   effects . The efﬁciency mindset aims , at best , to   prolong the duration of this situation . However ,   scaling up the performance of AI to satisfy the in-   creasing demands from consumers risks ignoring   the externalities incurred . Concepts such as reci-   procity with the environment , which are central in   some indigenous worldviews ( Kimmerer , 2013 ) ,   are absent from the discourse .   2.3 Carbon Offsetting   A common perception is that carbon neutrality   can be achieved by compensating for emissions   by ﬁnancial contributions , a practice referred to as   carbon offsets . This approach is problematic and   controversial : the level of carbon prices required to   achieve climate goals is highly debated ( Hyams and   Fawcett , 2013 ) . The Intergovernmental Panel on   Climate Change ( IPCC ) and various international   organizations like the International Energy Agency   ( IEA ) clearly state that mitigation activities are es-   sential . Compensation activities will be necessary   for hard - to - abate - sectors , once all other technolog-   ical solutions have been implemented , and where   mitigation is not ( yet ) feasible . Moreover , eco-   nomic dynamic efﬁciency requires investments in   decarbonization technologies to keep the climate   targets within reach . Compensation activities , es-   pecially in the afforestation area , delay the needed   investments . This delay might exacerbate the like-   lihood of crossing climate tipping points and/or   yields to a disorderly transition to a decarbonized   economy ( European Systemic Risk Board , 2016 ) .   3 Survey of Climate Discussion in NLP   The issue of environmental impact is more general   and not limited to NLP , but relevant to the entire   ﬁeld of AI : Schwartz et al . ( 2020 ) surveyed pa-   pers from ACL , NeurIPS , and CVP . They noted   whether authors claim their main contribution to   improving accuracy or some related measure , an   improvement to efﬁciency , both , or other . In all the   conferences they considered , a large majority of   the papers target accuracy . However , we claim that   the issue is more complex , and it is not sufﬁcient   to consider only the “ main contribution . ” Every   paper should ideally have a positive impact or pro-   vide sufﬁcient information to discuss meaningful   options to reduce and mitigate negative impacts .   3.1 Quantitative Analysis   We analyze the statistics of papers in * ACL venues   from 2016–2022 by downloading them from the   ACL Anthology . However , instead of focusing   on the main contribution , we look for any discus-   sions on climate - related issues . We identify ﬁve   dimensions in our study sample and create a regu-   lar expression pattern to match text for each ( see   Appendix A ) . These dimensions are public model   weights , duration of model training or optimization ,   energy consumption , the location where computa-   tions are performed , and GHG emissions . If the pat-   tern matches the text of a paper at least once , we   consider that paper as discussing the corresponding   category . We derive the proportions of papers by   dividing the number of papers discussing a cate-2482   gory by the number of deep learning - related pa-   pers . We only consider deep learning - related pa-   pers , as for these papers , climate - related issues are   of much higher relevance than for those using other   approaches ( Strubell et al . , 2019 ) .   Figure 2 shows our ﬁndings . In general , re-   searchers discuss climate - related issues more and   more in their work . For instance , the proportion   of papers that publish their model weights has al-   most quadrupled from about 1 % in 2017 to more   than 4 % in 2022 . We also ﬁnd an increase in the   proportion of papers that provide information on   emissions or energy consumption . Nevertheless ,   the proportion for these categories remains low .   3.2 Manual Annotation   To complement our automatic pattern - based search   approach , we also manually annotate a random   sample of 100 papers from EMNLP 2021for the   same ﬁve dimensions as before . Table 1 shows   the proportions . Borderline cases are counted as   “ reported ” for an optimistic estimate . This leads to   the proportions of papers publishing model weights   ( 13 % ) and the duration of model training or opti-   mization ( 28 % ) being much higher than with our   automatic approach , which can not judge border-   line cases and is thus more restrictive . Still , these   proportions are at a low level . The proportion of   papers reporting on the location , energy consumed   and GHG emitted are in line with the results from   our pattern - based search .   3.3 Qualitative Survey   We examine article contents to ensure precision and   to elaborate on existing practices . We review pa-   pers reporting on at least one dimension according   to our pattern - based search or our manual analy-   sis . Interestingly , many papers provide information   in the context of reproducibility , publishing code   but not necessarily model weights and reporting   computation time only for speciﬁc steps .   As examples for speciﬁc papers that go beyond   what is usually expected in terms of reporting , An-   derson and Gómez - Rodríguez ( 2021 ) evaluate bothaccuracy and efﬁciency in dependency parsers , ﬁnd-   ing that different approaches are preferable depend-   ing on whether accuracy , training time or inference   time are prioritized . Lakim et al . ( 2022 ) provide   a detailed holistic assessment of the carbon foot-   print of an Arabic language model , considering the   entire project , including data storage , researcher   travel , training and deployment .   Our ﬁndings highlight the need to raise aware-   ness of climate - related issues further and ﬁnd a sim-   ple but effective way to report them transparently .   Besides awareness and facilitation , incentives to   address these issues could be a complementary ap-   proach . However , in the rest of this paper we focus   on the former “ intrinsic ” motivation factors , leav-   ing “ extrinsic ” motivation factors to future work .   4 Towards Actionable Awareness   Efﬁciency ( alongside accuracy ) has been one of the   main objectives in NLP ( and computer science in   general ) long before its environmental aspects have   been widely considered . In general , it refers to the   amount of resources consumed ( input ) in order to   achieve a given goal , such as a speciﬁc computation   or accuracy in a task ( output ) . Different deﬁnitions   of efﬁciency correspond to different concepts of   input and output . It is crucial to ( 1 ) understand the   different concepts , ( 2 ) be aware of their differences   and consequently their climate impact , and ( 3 ) con-   verge towards a set of efﬁciency measures that will   be applied for comparable climate performance   evaluation in NLP research .   4.1 Related Work in NLP and AI   Strubell et al . ( 2019 ) quantify the ﬁnancial and en-   vironmental cost of various NLP models , exposing   substantial costs from model development and not   just ﬁnal model training . They recommend report-   ing training time and hyperparameter sensitivity ,   and prioritizing efﬁcient hardware and algorithms .   Schwartz et al . ( 2020 ) compare several efﬁciency   measures , focusing on input or resource consump-   tion : COeq emission , electricity usage , elapsed   real time , number of parameters , and FPO ( ﬂoating-   point operations ) . They suggest FPO as a concrete ,   reliable measure for climate - related efﬁciency that   does not depend on the underlying hardware , lo-   cal electricity infrastructure , or algorithmic details .   They suggest measuring efﬁciency as a trade - off be-   tween performance and training set size to enable   comparisons with small training budgets.2483Henderson et al . ( 2020 ) show that FPOs “ are not   adequate on their own to measure energy or even   runtime efﬁciency . ” They recommend reporting   various key ﬁgures , providing an automatic tool .   Alongside improvements in measurement meth-   ods , AI computations increasingly utilize cloud in-   frastructures , hindering transparency . Dodge et al .   ( 2022 ) provide a framework to measure carbon in-   tensity in cloud instances , ﬁnding that data center   region and time of day play signiﬁcant roles .   Finally , Wu et al . ( 2022 ) highlight the role of   system hardware development in AI environmental   impact , encouraging a holistic perspective .   4.2 Adopting Principles from Finance   The Greenhouse Gas Protocolis a widely used   reporting framework for corporates . However ,   this standard does not foresee , so far , an explicit   ICT ( information and communications technology )   component . We build on the general principles   of the GHG Protocol ( relevance , completeness ,   consistency , transparency , and accuracy ) to pro-   pose principles for improving climate - related per-   formance reporting of AI . While the Greenhouse   Gas Protocol focuses on GHG emissions , we pro-   pose a more general framework corresponding to   the different concepts of efﬁciency . We , therefore ,   replace the term GHG emissions with the term   climate - related performance assessments .   Relevance Ensure the climate - related perfor-   mance assessment appropriately reﬂects the   climate - related performance of training , evalu-   ation and deployment , and serves the decision-   making needs of users — both internal and ex-   ternal to the research group . Consider both   factors inherent to the model ( e.g. , number of   parameters ) and model - external factors ( e.g. ,   energy mix ) .   Completeness Account for and report on all rele-   vant climate - related performance assessment   items , using standardized model cards ( see § 5 )   to ensure accessibility to relevant information .   Disclose and justify any speciﬁc exclusions or   missing information , and explain which data   input would be required to provide it . Statehow you will deal with the missing informa-   tion in the future to reduce information gaps .   Consistency Use consistent methodologies to   make meaningful comparisons of reported   emissions over time . Transparently document   any changes to the data , inventory boundary ,   methods , or other relevant factors in the time   series . Use readily - available emission calcula-   tion tools to ease comparison with other mod-   els . If you decide not to use available tools ,   explain why you deviate from available tools   and report your assumptions about the energy   mix , the conversion factors , and further as-   sumptions required to calculate model - related   emissions .   Transparency Address all relevant issues factu-   ally and coherently to allow reproducible mea-   surement of climate - related performance by   independent researchers . Disclose any rel-   evant assumptions and refer to the account-   ing and calculation methodologies and data   sources used .   Accuracy of reporting Achieve sufﬁcient accu-   racy of the quantiﬁcation of climate - related   performance to enable users to make decisions   with reasonable assurance as to the integrity of   the reported information . Ensure that you re-   port on the climate - related performance , even   if you are in doubt about the accuracy . If in   doubt , state the level of conﬁdence .   4.3 Actions Towards Improvement   Reporting climate - related performance is not a goal   on its own . Instead , it should be a means to raise   awareness and translate it into actionable climate-   related performance improvements when training   and deploying a model . In addition , climate - aware   model performance evaluations should ensure that   downstream users of the technology can use the   model in a climate - constrained future . Researchers   should aim for climate - resilient NLP and algo-   rithms to unlock long - term positive impacts . How   to future - proof AI and NLP models should become   an essential consideration in setting up any project .   The overall process of integrating these consider-   ations would use enhanced transparency to unlock   actionable awareness . Reporting on climate - related   model performance should put researchers in a po-   sition to reﬂect on their setup and take immediate   action when training the next model . To support2484this reﬂection for the researchers , the following   proposes our climate performance model card .   5 Climate Performance Model Cards   Since 2020 , NeurIPS requires all research papers   to submit broader impact statements ( Castelvec-   chi et al . , 2021 ; Gibney , 2020 ) . NLP conferences   followed suit and introduced optional ethical and   impact statements , starting with ACL in 2021 .   Leins et al . ( 2020 ) discuss what an ethics assess-   ment for ACL should look like but focus solely on   political and societal issues . Tucker et al . ( 2020 ) an-   alyze the implications of improved data efﬁciency   in AI but only discuss the societal aspect of access   in research and industry , leaving environmental is-   sues unexplored . Mitchell et al . ( 2019 ) introduced   model cards to increase transparency about data   use in AI , similarly due to societal issues . We pro-   pose extending impact statements and model cards   to include information about the climate - related   performance of the development and training of   the model , improvements compared to alternative   solutions , measures undertaken to mitigate nega-   tive impact , and importantly , about the expected   climate - related performance of reusing the model   for research and deployment .   Our proposed model card also includes any pos-   itive impact on the environment . A large direct   negative impact does not rule out net positive im-   pact due to contribution to downstream environ-   mental efforts . While net impact can not be mea-   sured objectively , since it depends on priorities and   projections on the future use of the technology , we   can set a framework for discussing this complex   issue , providing researchers with the best practices   to inform future researchers and practitioners .   Table 2 shows our proposed sustainability model   card , structured into a minimum card and an ex-   tended card . The minimum card contains very ba-   sic information about the distribution of the model ,   its purpose for the community , and roughly the   computational work that has been put into the op-   timization of the models . The extended card then   includes the energy mix to compute the COeq   emissions . In total , our sustainability model card   contains eleven elements :   1.Publicly available artefacts . In recent years ,   NLP researchers often make their ﬁnal model   available for the public . This trend came up   to increase transparency and reprehensibil-   ity , yet , at the same time , it avoids the ne-   cessity to train frequently used models multi-   ple times across the community ( Wolf et al . ,   2020 ) . Thus , by publishing model ( weights ) ,   computational resources and thereby COeq   emissions can be reduced .   2.Duration — training of ﬁnal model . This   ﬁeld denotes the time it took to train the ﬁ-   nal model ( in minutes / hours / days / weeks ) . In   case , there are multiple ﬁnal models , this ﬁeld   asks for the training time of the model which   has been trained the longest .   3.Duration of all computations . The dura-   tion of all computations required to produce   the results of the research project is strongly   correlated with the COeq emissions . Thus ,   we want to motivate NLP researchers to vary   model types and hyperparameters reasonably .   While determining the beginning of a project   and deciding what counts as an experiment   are in many cases difﬁcult and subjective , we   claim that an estimate of this quantity , along   with a transparent conﬁdence margin , is better   than leaving it unreported.24854.Power of hardware . Besides the duration of   training , the power of the main hardware is a   driving factor for COeq emissions . Depend-   ing on the implementation , the majority of   energy is consumed by CPUs or GPUs . We   ask researchers to report the power in watts of   the main hardware being used to optimize the   model . For the sake of simplicity , we ask to   specify the peak power of the hardware , for   which the sum of the thermal design power   ( TDP ) of the individual hardware components   is a reasonable proxy . The manufacturers pro-   vide this information e.g. on their website .   We want to underline again , that this model   card ’s objective is not to have the most pre-   cise information but rather to have a rough   estimate about the power .   5.Geographical location . The energy mix ( the   COeq emissions per watt consumed ) depends   on the geographical location . Thus , it is im-   portant to report where the model was trained .   6.Energy mix at geographical location . To   compute the exact COeq emissions , the en-   ergy mix at the geographical location is re-   quired . Organizations such as the Interna-   tional Energy Agency ( IEA)report these   numbers .   7.COeq emissions of the ﬁnal model . This   ﬁeld describes an estimation for the emitted   COeq . Given the time for the computation   ( see item 3 ) , the power , and the energy mix ,   the total COeq emissions for the research can   be calculated by   ComputationTime ( hours ) ×   Power ( kW ) ×   EnergyMix ( gCOeq / kWh ) =   gCOeq .   Although awareness of the factors that af-   fect COeq emissions is important , we rec-   ommend using automated tools for the actual   calculation ( see § 2.1).8.Total COeq emissions . Similar to the previ-   ous item , this ﬁeld describes the total COeq   emitted during the training of all models . The   calculation is equivalent to item 8 .   9.COeq emissions for inference . Given that a   model might be deployed in the future , the ex-   pected COeq emissions in use of the model   can be of value . To assure comparison be-   tween models , we ask the authors to report   the average COeq emission for the inference   of one sample . For a dataset of nsamples , it   can be calculated by   1 / n×InferenceTime ( hours ) ×   Power ( kW ) ×   EnergyMix(gCOeq / kWh ) =   gCOeq .   10.Positive environmental impact . NLP tech-   nologies begin to mature to the point where   they could have an even broader impact and   support to address major problems such as cli-   mate change . In this ﬁeld , authors can state   the expected positive impact resulting from   their research . In case that the underlying   work is not likely to have a direct positive im-   pact , authors can also categorize their work   into “ fundamental theories ” , “ building block   tools ” , “ applicable tools ” , or “ deployed appli-   cations ” ( Jin et al . , 2021 ) , and discuss why   their work could set the basis for future work   with a positive environmental impact .   11.Comments . The objective of this climate per-   formance model card is to collect the most   relevant information about the computational   resources , energy consumed , and COeq emit-   ted that were the result of the conducted re-   search . Comments can include information   about whether a number is likely over- or un-   derestimated . In addition , this ﬁeld can be   used to provide the reader with indications   of possible improvements in terms of energy   consumption and COeq emissions .   6 Discussion   AI and NLP research are behind in incorporating   sustainability discourse in the discussion . In the   ﬁeld of ﬁnance , an increasing amount of compa-   nies worldwide are soon required to state their en-   vironmental and broader sustainability - related im-   pacts and/or commitments in their annual reports,2486mostly following the recommendations laid out by   the Task Force on Climate - related Financial Disclo-   sures ( TCFD ; Financial Stability Board , 2017 ) .   Responsibility and accountability . Signiﬁcant   differences exist between annual reports and re-   search papers : companies are increasingly asked   to take responsibility for their actions and are held   accountable to their commitments by stakeholders ,   while researchers can shake off responsibility by   transferring it to practitioners who use technology   based on their research . Researchers are thus never   held responsible for committing to reducing neg-   ative environmental impact unless they choose to   submit their work to speciﬁc workshops or confer-   ence tracks on sustainable and efﬁcient NLP . How-   ever , there are no best practices on what they can do   to help those who are responsible for committing to   sustainability — what information is necessary for   accurate reporting and informed decision making ?   Extrapolation to indirect impact . The quantiﬁ-   cation of indirect impact during reuse and deploy-   ment of artifacts developed in research is complex   and can only be estimated . We , therefore , expect   that this discussion in environmental impact state-   ments will be more abstract and harder to assess .   As a framework , we propose borrowing the no-   tion of scopes from corporate GHG accounting   ( Patchell , 2018 ) , where scopes 1 , 2 and 3 corre-   spond , respectively , to direct emissions ( not appli-   cable to NLP research ) ; indirect emissions from   operations , e.g. , due to energy consumption ( very   common in NLP research ) ; and indirect emissions   upstream or downstream the value chain . For our   case , we suggest the following scopes :   1.Emissions generated during experiments   for the paper itself , usually electricity   consumption - related .   2.Impact on other researchers and practitioners   in reducing emissions using the technology .   3.The use of the technology for reducing emis-   sions or other positive impact .   Note that these correspond , respectively , to scopes   2 , 3 and 3 in the GHG Protocol mentioned above .   Multi - objective optimization . Performance   should not only be assessed in terms of output , but   also inputs required to obtain a certain outcome .   Based on this principle , performance evaluation   should be based on both model performance   and climate performance ( cf . Table 3 ) . This can   take the form of explicitly introducing climate   performance into the objective function for   optimization ( Puvis de Chavannes et al . , 2021 ) and   in benchmarking ( Ma et al . , 2021 ) .   Positive impact . NLP is relevant in several as-   pects to the UN sustainable development goals   ( Vinuesa et al . , 2020 ; Conforti et al . , 2020 ; Swar-   nakar and Modi , 2021 ) . Jin et al . ( 2021 ) deﬁned a   framework for the social impacts of NLP , of which   environmental impacts are a special case . They de-   ﬁne an impact stack consisting of four stages , from   ( 1 ) fundamental theory to ( 2 ) building block tools   and ( 3 ) applicable tools , and ﬁnally to ( 4 ) deployed   applications . Furthermore , they identify questions   related to sustainable development goals for which   NLP is relevant . They categorize Green NLP as   relevant only to the particular goal of “ mitigating   problems brought by NLP , ” by minimizing direct   impact as part of technology development . How-   ever , we claim that Green NLP must be viewed   more broadly . For example , Rolnick et al . ( 2019 )   discuss how machine learning can be used to tackle   climate change , listing several ﬁelds with identi-   ﬁed potential . For NLP , they mention the impact   on the future of cities , on crisis management , in-   dividual action ( understanding personal footprints ,   facilitating behavior change ) , informing policy for   collective decision - making , education , and ﬁnance .   Stede and Patz ( 2021 ) note that the topic of climate   change has received little attention in the NLP com-   munity and propose applying NLP to analyze the   climate change discourse , predict its evolution and   respond accordingly . Indeed , NLP is increasingly   being used to analyze sustainability reports and   environmental claims , facilitating enforcement of   reporting requirements ( Luccioni et al . , 2020 ; Bin-   gler et al . , 2021 ; Stammbach et al . , 2022).24877 Recommendations   As pointed out by Schwartz et al . ( 2020 ) , a compar-   ison between research and researchers from various   locations and with various prerequisites can be dif-   ﬁcult . Therefore , we want to point out rules of   thumb that , in our opinion , should be followed by   the authors of papers , as well as from reviewers   who assess the quality thereof .   Doincrease transparency . With our climate per-   formance model card , we aim to provide guidelines   that give concrete ideas on how to report energy   consumption and COeq emissions . Our model   card , on purpose , still allows for ﬂexibility so that   authors can change it to their respective setup . In   case of high CPU usage , the authors can simplify   their calculation of energy consumption by only   looking at the CPU power ; in the case of the GPU ,   it can simply be based on the GPU . Our main goal   is transparency for users and increased awareness   for modelers and researchers . Hence , transparency   is to be weighted over accuracy .   Douse the model cards to enable research institu-   tions and practitioners to report on their climate per-   formance and GHG emissions . An increasing num-   ber of ﬁrst - moving research labs and institutes have   started to account for their GHG emissions from   direct energy use and ﬂying , and intend to include   their ICT emissions ( e.g. , ETH Zurich , 2021 ; UZH   Zurich , 2021 ) . However , harmonized approaches   are still lacking . Use the model cards to road - test   how far they could support your institutions ’ GHG   and climate impact reporting .   Do not use our model card for assessing research   quality . The value of research is often only clear   months or years after publication . Thus , the ra-   tio between emitted COeq and contribution to the   NLP community can not be measured accurately .   Additionally , the emitted COeq depends on the   hardware used for the computations . Researchers   working with less energy - efﬁcient hardware would   have a disadvantage if the emitted COeq were be-   ing used for assessing the quality . However , consid-   ering the energy efﬁciency of model performance   might indirectly reduce a Global North – South bias ,   given that access to computational power is not   evenly distributed across the World . Hence , tar-   geting energy efﬁciency and reducing the compu-   tational power required to train and run models   might mitigate some concerns on the inequality of   research opportunities .   Do not report your voluntary ﬁnancial climateprotection contributions as emission offsetting .   While emission offsetting used to be hailed as   an efﬁcient way to reduce global greenhouse gas   emissions , this notion had to be revised with up-   dated climate science consensus , at the latest with   the IPCC ’s Special Report on Global Warming of   1.5C from 2018 ( Masson - Delmotte et al . , 2018 ) .   Related to this aspect , do not communicate rela-   tive ( efﬁciency - related ) improvements as absolute   climate - related performance improvements .   Do not use this model card to assess net climate-   related impacts . AI as an enabler for higher - order   effects , for example , for climate - neutral economies   and societies , is an important topic , which is , how-   ever , not in our scope . Instead , our approach aims   to increase transparency about every model ’s ﬁrst   order effects , be the model designed for societal   change ( or any other higher - order effect ) or not .   8 Conclusion   We argued that branding efﬁcient methods in NLP   asgreen orsustainable is insufﬁcient and that due   to the importance of the issue , climate awareness   must be promoted in mainstream NLP rather than   only in niche areas . We conducted a survey of   climate discussion in NLP papers and found that   climate - related issues are increasingly being dis-   cussed but are still uncommon . We proposed ac-   tionable measures to increase climate awareness   based on experience from the ﬁnance domain and   ﬁnally proposed a model card focusing on report-   ing climate performance transparently , which we   encourage NLP researchers to use in any paper .   While our discussion , survey , and recommenda-   tions are aimed towards the NLP community , much   is applicable to other AI ﬁelds . Indeed , speciﬁc rec-   ommendations have been made for machine learn-   ing ( Henderson et al . , 2020 ; Patterson et al . , 2022 )   and medical image analysis ( Selvan et al . , 2022 ) ,   for example . Concurrently , Kaack et al . ( 2022 )   propose a system - level roadmap addressing both   GHG emissions and use of AI for climate change   mitigation holistically . Our focus on NLP enabled   us to be more speciﬁc about relevant modeling   components in our model card , as they are com-   monly used in NLP work . Furthermore , framing   our arguments within the discourse initiated in the   NLP community allowed us to address the speciﬁc   points raised in this discussion so far , and highlight   speciﬁc avenues for positive impact.24889 Limitations   While climate awareness is necessary for including   environmental considerations in decisions made   during NLP research work , it is not sufﬁcient for   behavior change , namely , concrete actions by re-   searchers and practitioners to reduce their negative   impact and potentially contribute positively : as evi-   dent in various other societal issues , values do not   necessarily determine behavior ( Boström , 2020 ) .   Instead , climate - responsible behavior must also be-   come “ the new normal ” for it to be mainstream .   Awareness is only the ﬁrst step in reaching that   goal ( Lockie , 2022 ) .   Furthermore , the climate awareness model card   we propose requires less precise details than ex-   isting reporting tools ( Lacoste et al . , 2019 ; Hen-   derson et al . , 2020 ; Anthony et al . , 2020 ; Schmidt   et al . , 2022 ) , which could limit its usefulness for   informed decision making . However , as we claim   in the paper , quantifying uncertainty may mitigate   over - reliance on this information , which would oth-   erwise possibly simply not have been reported at   all .   Finally , if climate reporting becomes mandatory   in NLP , it can actually be used for greenwashing if   it entails ﬁnancial or other incentives and if there is   no control mechanism to check for honesty of the   researchers . This is analogous to the situation in the   corporate world , and can possibly be counteracted   similarly , e.g. , using ClimateBert .   References248924902491A Patterns for Quantitative Analysis   The following are the regular expression patterns   applied to identify papers according to the dimen-   sions described in § 3.1 .   Public model weights :   ( ( ( model | w e i g h t ) ( w i l l be | i s ) ? | (   models | w e i g h t s ) ( w i l l be | a r e )   ? ) ( p u b l i c | a v a i l a b l e | u p l o a d |   made a v a i l a b l e | made p u b l i c |   p r o v i d e d ( a t | under | on ) ) ) | ( (   p u b l i s h | u p l o a d ) [ a−zA−Z0 −9 ,   ] { 0 , 2 0 } ( model ( s ) ? | w e i g h t ( s ) ? ) )   | ( make [ a−zA−Z0 −9 , ] { 0 , 2 0 } (   model ( s ) ? | w e i g h t ( s ) ? ) (   a v a i l a b l e | p u b l i c ) ) | ( p r o v i d e [ a   −zA−Z0 −9 , ] { 0 , 2 0 } ( model ( s ) ? |   w e i g h t ( s ) ? ) ( a t | under | on ) )   Duration of model training or optimization :   ( ( ( p r e ( − ) ? ) ? t r a i n ( i n g | ed ) ? |   o p t i m i z e | o p t i m i z a t i o n | ( f i n e ( − )   ? ) ? t u n ( e | ed | i n g ) ) ( [ a−zA−Z0 −9 ,   ] { 0 , 2 0 } ) ( f o r | t ook | t a k e ( s ) ? )   ( [ a−zA−Z0 −9 , ] { 0 , 2 0 } ) ( s e c o n d s |   minute | hour | day | week | month ) + ) |   h o u r s of c o m p u t a t i o n   Energy consumption :   ( e n e r g y | power | e l e c t r i c i t y ) (   consumption | usage ) | ( i s | of | a t )   [ 1 −9]{1}[0 −9]{2 , 5 } ( w a t t ( s ) ? | (   k ) ? w ) | pue   Location where computations are performed :   ( ( d a t a ? c e n t e r | ( a | t h e ) c l o u d | (   v i r t u a l | gpu ) machine | computer   c l u s t e r | hpc ) ( i s ) ? ( a t | i n ) ) | (   c l o u d | a z u r e | g o o g l e | aws ) ( [ a−zA−   Z0 −9 , ] { 0 , 2 0 } ) r e g i o n   GHG emission :   ( co2 ( e | eq ) ? | ghg | c a r b o n ) (   f o o t p r i n t | e m i s s i o n ( s ) ? | e m i t t e d   | o f f s e t ( t i n g ) ? )   The patterns were applied to the full paper text   ( including abstract , main contents and appendices ,   ignoring capitalization ) for deep - learning - related   papers identiﬁed by matching the following pattern :   deep l e a r n i n g | n e u r a l network | l s t m   | r e c u r r e n t n e u r a l network | rnn |   t r a n s f o r m e r | mlp | c o n v o l u t i o n a l   n e u r a l network | cnn | g p t   B Example Model Card   Table 4 provides an example climate performance   model card according to the guidelines proposed in   this paper . The model is ClimateBert , a language   model which was ﬁnetuned on climate - related text   ( Webersinke et al . , 2021 ) . The same information is   provided on Hugging Face , illustrated in Figure 1 .   Further information about each ﬁeld is provided in   the following :   1.All weights of the ﬁnal model are publicly   available on https://huggingface .   co / climatebert . The paper proposes a   ﬁne - tuned language model on climate - related   text . Thus , the proposed models are speciﬁc   to a ﬁeld and not task agnostic .   2.The duration for optimizing the ﬁnal model   was around 8 hours . Note , that the paper pro-   poses four ﬁnal models but this ﬁeld should   only mention the optimization time for one   model .   3.In total , we estimate the duration for all com-   putations to be 12 days (= 288 hours ) . This   estimation is likely pessimistic , i.e. , the du-   ration for all computations was likely lower .   However , we want to point out again that this   model card values transparency over accuracy .   4.The main hardware used for training were 2   x NVIDIA RTX A5000 with each GPU tak-   ing 230 watts . We add another 120 watts for   the remaining hardware which would not be   required by our model card .   5.The models were all trained on servers in Ger-   many .   6.The energy mix is roughly 470   gCOeq / kWh.24927 . Calculating   8hours×0.7kW×470gCOeq / kWh   leads to 2.63 kg COeq emissons .   8 . Calculating   288hours×0.7kW×470gCOeq / kWh   leads to 94.75 kg COeq emissons .   9.A pass of 100,000 samples through the pro-   posed model took 0.187 hours on the same   server ( using a batch size of 512 ) . We then   calculate   0.187   100,000hours×0.7kW×470gCOeq / kWh   = 0.62mgCOeq   as the emission for the inference of one sam-   ple .   Positive impact . The proposed language model   on its own does not directly have a positive en-   vironmental impact . However , it can be used   to train more accurate NLP models on climate-   related downstream tasks . For instance , question-   answering systems for climate - related topics or   greenwashing detectors could beneﬁt from this pre-   trained language model . This work can therefore be   categorized as a “ building block tools ” following   Jin et al . ( 2021 ) , as it supports the training of NLP   models in the ﬁeld of climate change and , thereby ,   have a positive environmental impact in the future .   Possible improvements . Block pruning is a   method which drops a large number of attention   heads in transformer models while only decreas-   ing model performance slightly ( Lagunas et al . ,   2021 ) . Thus , the number of weights after block-   pruning is decreased considerably which , in turn ,   decreases the COeq emissions . Very likely , this   method would show the same effect on the pro-   posed ClimateBert model .   C Timeline of Emissions in NLP   Figure 3 shows the computational power that was   put into the development of the major NLP mod-   els ( Sevilla et al . , 2022 ) . With few exceptions , the   training compute for NLP models has steadily in-   creased over the past decade . Although progresshas also been made in terms of more energy efﬁ-   cient hardware ( e.g. , 19.5 GFLOPS / watt in a 2013   GTX Titan to 168.3 GFLOPs / watt in a 2021 RTX   A6000 ) , the increase in terms of required FLOPs is   substantially larger . For example , going from GPT   ( in 2018 ) to GPT-3 175B ( in 2020 ) , the training   compute increase from 1.1E19 to 3.14E23 FLOPs —   an increase by a factor larger than 25,000 .   D GHG Protocol Information   Requirements for Companies   Whilst the GHG Protocol does not provide an ICT   sector tool , it provides emission factors by fuel   source to calculate GHG emissions based on the en-   ergy consumption . The emission factors reﬂect the   scientiﬁc climate consensus , based on the report of   the Intergovernmental Panel on Climate Changes ’   latest Assessment Report — IPCC ’s AR5 .   In terms of speciﬁc information to be disclosed ,   the GHG protocol guidance states several items   relevant to NLP and ML research , which serve to   build our model card approach . The items that can   be used for our approach are presented in Figure 4 .   Furthermore , the GHG Protocols ’ Appendix A   provides a guidance on accounting for indirect   emissions from purchased electricity . This would   be an important source of information for AI-   related GHG accounting.24932494