  Eshaan Tanwar   DTU , India   eshaantanwar2000@gmail.comSubhabrata Dutta   IIT Delhi , India   subha0009@gmail.com   Manish Borthakur   IIT Delhi , India   mt6190493@iitd.ac.inTanmoy Chakraborty   IIT Delhi , India   tanchak@iitd.ac.in   Abstract   In - context learning ( ICL ) unfolds as large lan-   guage models become capable of inferring test   labels conditioned on a few labeled samples   without any gradient update . ICL - enabled   large language models provide a promising   step forward toward bypassing recurrent an-   notation costs in a low - resource setting . Yet ,   only a handful of past studies have explored   ICL in a cross - lingual setting , in which the   need for transferring label - knowledge from a   high - resource language to a low - resource one   is immensely crucial . To bridge the gap , we   provide the first in - depth analysis of ICL for   cross - lingual text classification . We find that   the prevalent mode of selecting random input-   label pairs to construct the prompt - context is   severely limited in the case of cross - lingual   ICL , primarily due to the lack of alignment   in the input as well as the output spaces . To   mitigate this , we propose a novel prompt con-   struction strategy – Cross - lingual In - context   Source- Target Alignment ( X - InSTA ) . With an   injected coherence in the semantics of the input   examples and a task - based alignment across the   source and target languages , X - InSTA is able   to outperform random prompt selection by a   large margin across three different tasks using   44 different cross - lingual pairs .   1 Introduction   The emergence of large - scale , pretrained ,   Transformer - based language models ( LLMs ) has   marked the commencement of an avant - garde era   in NLP . Departing from the traditional methods   of neural language learning with temporally   separated training - testing phases for downstream   tasks , pretrained LLMs have shown the ability to   infer labels from test inputs conditioned on the   training data within a single pass . This is known   asIn - context learning – an LLM is promptedwith a few input - output pairs from the training   data ( commonly referred to as demonstrations )   followed by the test input ; for generative tasks   ( summarization , text - to - code , chain - of - thought   reasoning , etc . ) the LLM is then required to   produce an output ; for classification tasks , the   probabilities of the next tokens predicted by the   LLM are mapped to the label space . All of this is   done without updating the parameters of the LLM .   In - context learning is particularly promising for   two different aspects . Firstly , it reduces the need   for task - specific training data , and thus , the cost   of human annotation . Secondly , while the LLM   was trained in a compute - intensive environment ,   the removal of the need for task - specific gradient-   based weight updates can significantly reduce   the carbon footprint of automated NLP / NLU   since the inference - time compute - necessity is   orders of magnitude smaller than that of the   training / finetuning phases . Multiple recent   advancements have been proposed to optimize   the ICL ability of the LLMs ( Lin et al . , 2021 ;   Chowdhery et al . , 2022 ; Liu et al . , 2022 ; Zhang   et al . , 2021 ) .   Challenges in cross - lingual ICL : Given that   there is an order - of - magnitude discrepancy in the   availability of annotated data in a high - resource lan-   guage vs. a low - resource one , the ability to learn   from the high - resource source context to solve   tasks in low - resource targets sounds enticing . Yet ,   the application of ICL in a cross - lingual setting   remains largely unexplored . Previous attempts at   multilingual ICL ( Zhang et al . , 2021 ; Winata et al . ,   2021 ) use randomly selected input - label pairs to   construct the prompt - context . This limits the abil-   ity of an LLM to infer from the context . As Xie   et al . ( 2022 ) suggested , ICL emerges as the ability   to infer target labels from the pretraining distribu-   tion conditioned upon the context ; each input - label   pair in the prompt - context are , in turn , sampled   from the prompt token distribution . Theoretically,6292   the expected prediction error decreases as the num-   ber of examples in the prompt increases . However ,   such infinitely long prompts are practically infea-   sible to attain . Xie et al . ( 2022 ) imposed that a   distinguishability of the prompt - concept , shared   across the prompt - examples , from all other possi-   ble concepts is essential for an optimal predictor . A   random sampling of prompt examples is unlikely   to construct a prompt with distinguishable con-   cepts . Furthermore , given ( x , y)and(x , y )   as two consecutive input - label pairs in the prompt-   context , the transition probability from ytox   is a low - probability one under the pretraining dis-   tribution ( Xie et al . , 2022 ) . The transition becomes   even more improbable if we are to simply append   a test example to the prompt - context of a different   language . Consider the following example of ICL   prompting for cross - lingual sentiment classifica-   tion :   The text segments are concatenated from left - to-   right and top - to - bottom ; therefore , two English   input - label pairs are followed by a Spanish test   input . There are irremovable , token - level low-   probability transitions from the labels to the next   input sentences . On top of this , we have three   completely unrelated sentences juxtaposed together   with an abrupt change in language . Intuitively , it is   less likely for an LLM to be able to map the third   input to its correct label , positiva ( positive in Span-   ish ) following the very much convoluted patternspresented in English .   Proposed approach : We seek to develop   prompt - design strategies for ICL in a cross - lingual   setting that can overcome the foregoing challenges .   A two - way alignment of the source and target ex-   amples is proposed . We start with injecting seman-   tic coherence into the prompt - context by selecting   similar examples ; this aligns the labeled demon-   strations as well as the test inputs to share a set of   common concepts . Next , we seek to enforce an   alignment of task - level signals across languages .   We introduce manually - designed task - specific map-   pings from the source language to the target lan-   guage , thereby providing the LLM with a ‘ natu-   ral ’ transition from the former to the latter . To-   gether , these two approaches constitute our pro-   posed prompts - selection strategy , X - InSTA ( Cross-   lingual In - context Source- Target Alignment , see   Figure 1 for working examples ) . X - InSTA shows a   staggering 18%relative improvement over random   prompt selection averaged across three different   text classification tasks in multiple different lan-   guages with English being the source language .   Careful perturbations to these alignment methods   disclose the importance of label space structure   induced by LLMs for cross - lingual ICL .   Our contributions are summarized below :   1.We propose X - InSTA , a novel method of align-   ing prompt examples in a cross - lingual scenario .   To the best of our knowledge , this is the first at-6293tempt to push prompt design techniques for ICL in   cross - lingual settings beyond the trivial strategy of   random example selection .   2.We present the first , in - depth analysis of the role   of semantic similarity between prompt examples   for cross - lingual ICL .   3.A novel concept of task - based prompt alignment   is presented . We show its efficacy with 44 different   source - target language pairs and empirically relate   this to the underlying structures of multilingual   representations of the LLM .   2 Prompting Techniques   In this section , we lay out a step - by - step ap-   proach to aligning semantic coherence and task-   based signals across source - target examples for   ICL prompts .   2.1 Prelimineries   LetD={(x , y)}be a monolingual labeled   dataset in language s , realized as a collection of   input examples and their labels , x∈Xand   y∈Y , respectively . Here Yis the natural lan-   guage label space in language s. We have another   collection of input examples , D={x } , with   examples in language t. One can define a cross-   lingual text classification task with source and tar-   get languages being sandtin the following man-   ner . First , we select kinput - label pairs from Dto   construct the prompt - context , C :   C = x⊕y⊕[sep]⊕ · · · x⊕y ( 1 )   where [ sep]denotes a separator token ( e.g. , new-   lines ) , and ⊕denotes the concatenation operator .   The problem of in - context prediction then trans-   lates to inferring the label y∈Y , where Yis the   natural language label space in language tcorre-   sponding to the test input x∈Dconditioned on   the prompt - context C , as follows :   y= argmaxp(y|C⊕x )   i.e. , we select the maximum probability label in   the target label space generated by the model as   the token next to the test input xappended to the   context C. The source and target label spaces , Y   andY , share a one - to - one mapping among each   other in terms of translation from stot .   One of the most widely - used methods of con-   structing the context C , which we will henceforth   callrandom prompting , is to randomly select(x , y)from Dand concatenate together . We   explore this method in our analysis , and it serves   as a baseline for our experiments .   2.2 Semantic Alignment   Chang et al . ( 2022 ) showed that multilingual mod-   els encode these languages in a shared embed-   ding space , while still preserving several language-   sensitive semantic information . Despite the lan-   guage difference between source and target inputs ,   xandx , it is then likely that their semantic simi-   larities will be reflected in their hidden representa-   tions constructed by LLM . Therefore , we hypothe-   size that choosing semantically similar examples to   construct the prompt - context would help the model   do in - context inference . That is , if eis the em-   bedding of the target and ethat of the source , the   higher the similarity score between them , the better   sentence xwill serve as a demonstration for the   target sentence x.   Inspired by Liu et al . ( 2022 ) , we extract prompt   examples directly dependent on the test input dis-   tribution . Here we utilize multilingual sentence-   transformers ( Reimers and Gurevych , 2020 ) to   extract the sentence embedding of the test input   x∈Dand the source inputs X. Based on the   cosine similarity between the target input xand   source inputs x∈X , we then extract the top k   demonstrations ( see Algorithm 1 ) . While the tar-   get input and the demonstration differ in language ,   we hypothesize that by pairing semantically simi-   lar context demonstration and input sentence , the   LLM would be able to improve its reasoning abil-   ity and subsequently , the final task performance   ( see Table 11 in Appendix D for examples of such   aligned demonstrations ) .   Algorithm 1 : Semantic Alignment   2.3 Task - based Alignment   Despite the semantic coherence enforced within   the prompt - context via the previously mentioned6294method , the source and target label spaces ,   YandY , remain superficially disconnected .   For fine - tuning , techniques like meta - learning   ( Nooralahzadeh et al . , 2020 ) , and adapters ( Parovi ´ c   et al . , 2022 ) have been used to bridge this gap . For   in - context prompting in which context matters the   most , we propose to do so by adding a manually de-   signed statement that gives the LLM task - specific   information like target language and target label   space .   Task - based alignment is done by appending a   manually - designed statement , called task aligner   to context . This aligner is supposed to inform   the LLM about the mapping from the source label   space Yto the target label space Y. We do task   alignment by first manually creating D={L }   for a given task and source - target language pairs   sandtas a collection of statements in the source   language that emphasizes what the target label and   language are . For example , when the source is En-   glish and the target is Spanish , “ In Española bad   means malo and good means bueno ” will be the   said task aligner that gives the information that the   target language is Española ( Spanish ) and the target   labels are malo andbueno ( badandgood , respec-   tively ) . Next , we construct the prompt - context by   randomly selecting ksource language examples ,   followed by the task aligner from this source - target   pair from D(see Algorithm 2 ) . For more exam-   ples of task - aligned prompt design , please refer to   Tables 11 and 12 in Appendix D.   Algorithm 2 : Task Alignment   2.4 X - InSTA   We finally move on to our proposed method   X - InSTA that combines semantic alignment with   the task - based one . It first selects source exam-   ples from Dwith top- ksimilarity scores as men-   tioned in Section 2.2 . Additionally , we select task-   aligners from Ddepending on the source and tar-   get languages and the task . Finally , we construct   the prompt context by concatenating the selected   examples followed by the task - aligner . The final   label inference can be described as   y= argmaxp(y|x⊕y···x⊕y⊕L⊕x )   where sim(x , x)≥sim(x , x ) , andL∈D   is the task aligner for source and target languages   sandt , respectively for the given task .   3 Results and Analysis   We experiment on three datasets – Multilingual   Amazon Reviews Corpus ( MARC ) ( Keung et al . ,   2020 ) , Cross - language sentiment classification   ( CLS ) ( Prettenhofer and Stein , 2010 ) , and Hat-   Eval ( Basile et al . , 2019 ) , spanning over twelve   language - task pairs and totalling 44cross - lingual   setups ( refer to Appendix A for further description   of the datasets ) . The results on MARC , CLS and   HatEval are shown in Tables 1 , 2 , and 3 , respec-   tively . For our main experiments , we make use of6295   XGLM ( Lin et al . , 2021 ) 7.5 billion variant . We ex-   periment with various models with random prompt-   ing and select XGLM 7.5B for its performance   superiority on various tasks ( refer to Table 8 in Ap-   pendix B ) . For further details on the experimental   setup , please refer to Appendix C and Table 10 for   the language abbreviations used .   3.1 Comparing Alignment Techniques   Semantic Alignment : The improvement intro-   duced by semantic alignment of the prompt - context   over randomly - selected source examples is eminent   in Tables 1 , 2 , and 3 . On the MARC dataset , we   observe a 14 % improvement in macro F1 scores   averaged across different languages . This observa-   tion is consistent across all target - source pairs on   other datasets as well — a gain of 10 % on Hateval ,   and 6 % on CLS . This improvement over random   example selection is consistent across all language   pairs ( except English - to - German in CLS ) consid-   ered in this experiment . This is particularly note-   worthy and one might lead to the conclusion that   dynamically selecting prompt examples based on   semantic similarity aligns the LLM to become a   better in - context learner irrespective of the task and   the languages .   Task - based Alignment : Just by adding a task   aligner , we not only outperform random prompts   but also bring substantial improvements for simi-   larity prompting , even though it is not dynamically   varying with input sentences . The improvement is   18 % in CLS , 8 % in HatEval , and 15 % in MARC ,   in terms of macro F1 scores averaged over different   language pairs .   However , some languages like German in   MARC and English in HatEval produce near-   random predictions in all the set - ups we experi-   mented with . This might be due to the model ’s   inability to perform ICL on these tasks in a cross-   lingual manner for these languages . Previous stud-   ies observed such phenomena in monolingual ICL   ( Webson and Pavlick , 2022 ; Lin et al . , 2021 ) ; cross-   lingual ICL has its added nuances that make it even   more difficult .   We also see a performance drop in the case of   Mandarin in MARC ( Table 1 ) while adding a task   aligner . We investigate the performance drop and   near - random results of German further .   X - InSTA : This prompting mechanism inher-   its both the benefits of semantic and task - based   prompting , hence giving the best results in most   language pairs . But similar to task - based align-   ment , X - InSTA also performs badly on some target   languages . The improvement is 23 % on MARC ,   22 % on CLS , and 14 % on HatEval . We also note   that no specific language can be used as the best   source language .   3.2 Why does Task Alignment Work ?   Next , we seek to validate the performance boost   achieved via task - based aligners along with an at-   tempt to explain the drop in performance with Man-   darin and German . We vary the task aligner and6296   note its effect on the output . We do so in five differ-   ent variations along with the original method ( see   Table 12 in Appendix D for detailed examples of   each scenario ):   1.No aligner prompt added : Same as random   prompting .   2.Making the label space uniform : Across all   source - target setups , we set the source - label   distribution as output for the target too , reduc-   ing the need for task alignment .   3.Only language information : Only giving   the language information to LLM , without   providing any further label information . An   example of such an aligner would be ‘ The   following post is in French language ’ , in a   case when the source is English , and the target   is French .   4.Providing aligner but of a third unrelated   language : We set the aligner of a third lan-   guage . For example ‘ In Spanish bad means   malo and good means bueno . ’ , in a case when   the source is English and the target is French .   5.Incorrect aligner : Making the aligner in-   correct corresponding to the label space . For   example ‘ In French bad means bien and good   means mal . ’ , in a case when the source is En-   glish and the target is French .   It ’s all about the label information : In Table   4 , we note the importance of label space informa-   tion . Providing the model with language infor-   mation does improve the performance ; however ,   the improvement is minuscule compared to the im-   provement achieved via task aligners . This labelinformation , even when of an unrelated third lan-   guage , still helps the model predict better . This   might be due to the fact that the model looks more   rigorously at label space for inference . Therefore ,   this showcases the importance of labelling informa-   tion while going cross - lingual .   Why drop in some languages ? It is noteworthy   that in Table 4 , the task aligner works best for all   target languages except for German and Mandarin .   Both of these languages give the best results in   uniform label space , i.e. , when yis made the same   asy . This points to the inability of the LLM to   align the label space of different source languages   to these target languages . In making the label space   uniform , we lose certain language - specific signals ,   but this may also be seen as a way of reducing task   alignment . Only for German and Mandarin do we   see this trade - off as beneficial ; in all other cases ,   the loss of language - specific features of yleads to   a drop in performance .   3.3 Role of semantic alignment   To understand the role of semantic alignment , we   ran an experiment in which instead of choosing k   nearest neighbor of x , we chose the most dissimi-   lar sentences . Table 5 shows that there is a sharp   decrease in performance as compared to random   prompting for all languages , with German as an   exception . The average fall is 8 % whereas using se-   mantic alignment gives a gain of 10 % w.r.t . random   prompting .   3.4 Automated aligner generation   We also expand our analyses to automatically gen-   erate the aligner using mT5 ( Xue et al . , 2021 ) . It   is trained using a span generation task using sen-   tences like ‘ Paris < MASK > France ’ . The mT5   model is trained to fill the mask token by generat-   ing spans like ‘ is capital of ’ . In our usage , mT5   will fill the < MASK > between the input target test   x , and prompt context Cin the source language   to align the semantics of both . We summarize our6297   procedure for automatic alignment generation in   Algorithm 3 .   Algorithm 3 : Task Alignment   Due to the computational cost of generating the   intermediate prompt for each source - target input   pair , we experiment with English as the only source   language in all three datasets . Table 6 summarizes   the results of using an automated aligner . We note   that the automated aligner leads to better results   than random prompting , and delivers results com-   petitive to semantic prompting in some languages .   However , it fails to incorporate any task - specific   signals , therefore failing to beat task - based align-   ment . One can note the limitations of this approach   in terms of the different pretraining distributions   of the in - context learner and the aligner generator   ( XGLM and mT5 , respectively , in this scenario ) .   The hypothesized role of the aligner was to con-   struct a ‘ natural ’ transition from the source context   to the target input for a particular task . Since mT5   generates these aligners independently without any   access to the pretraining distribution of XGLM , the   disparity manifests with sub - optimal results .   3.5 Error Analysis   We present four examples in Table 7 , highlight-   ing the four major errors we notice while using   X - InSTA , stemming from the following factors :   1.Static task - aligner : In example # 1 , slurs are   used by all the posts . In the context examples ,   they are being used as hate speech ; whereas in   the target , it is not directed at any individual and   thereby , should not be identified as hate speech .   However , the model labels it otherwise . Here , theapparent semantic similarity is misdirecting the   model , and the static nature of the task aligners is   not able to guide it to understand the nuances of   the task .   2.Cultural differences : None of the alignment   methods introduces common knowledge or cultural   knowledge in the prompt . To classify the tweet in   example # 2 , one must have a grasp of hate focused   on migration .   3 . Input length : Both the context prompt and the   input sentence are just too long in example # 3 .   In this case , no matter how better we design the   aligner , we can not fit it within the maximum input   length of 1024 tokens . One can not keep on increas-   ing the max - length to accommodate this pitfall , as   that might lead to higher computation costs . A   possible solution can be found in the direction of   Transformer architectures suitable for longer input   sequences .   4.Lack of human - like commonsense : In exam-   ple # 4 , alignment of the semantics and the task con-   structed a good prompt , but the model predicted   it wrongly by getting confused by the sarcasm in   the first demonstration . To bridge this pitfall , we   need to bring more knowledge of humor or com-   monsense to make the model understand what is   obvious to us .   It should be noted that the majority of these er-   rors are stemming from the incapability of the LLM   itself . Advancements in language model designs   may lead to betterment in future models .   4 Related Works   In - context learning ( ICL ): Brown et al . ( 2020 )   introduced a new approach , called in - context few-   shot learning using the GPT-3 model . Subsequent   efforts have been made to enhance the effective-   ness of ICL . Hendrycks et al . ( 2020 ) evaluated the   breadth and depth of model understanding to de-   termine its weaknesses and strengths . Techniques   such as selecting semantically - similar examples ,   using differentiable soft prompts for backpropaga-   tion , and adjusting prompts to eliminate bias in6298   predictions have been implemented to optimize the   input prompt ( Liu et al . , 2022 ; Zhang et al . , 2021 ;   Zhao et al . , 2021 ) . These efforts have primarily   been directed toward improving the performance   of ICL in a monolingual setting .   Multiple recent studies have sought to explain   the emergence of ICL by assigning different roles   to the LLM . Xie et al . ( 2022 ) provided the notion of   LLMs doing Bayesian inference conditioned upon   the prompt context to predict the test label . Our   work is much in line with this hypothetical model   since alignment over the semantics and the task-   based signals across languages are motivated by   the quest for better alignment between the prompt   and the pretraining distribution and warranting a   shared , distinguishable concept as Xie et al . ( 2022 )   argued . Additionally , von Oswald et al . ( 2022 )   sought to identify LLMs doing gradient - descent as   meta - optimizers while learning in context . Li et al .   ( 2023 ) described ICL as implicit model selection .   Multilingual models : Recent studies on mul-   tilingual tasks have focused on creating multilin-   gual versions of popular pre - trained language mod-   els . These include mBERT ( Devlin et al . , 2018 ) ,   mBART ( Liu et al . , 2020 ) , XLM - R ( Conneau et al . ,   2020 ) , and mT5 ( Xue et al . , 2020 ) , which are de-   rived from models like BERT ( Devlin et al . , 2018 ) ,   BART ( Lewis et al . , 2020 ) , RoBERTa ( Liu et al . ,   2019 ) , and T5 ( Raffel et al . , 2019 ) , respectively . However , fine - tuning these large models for each   task is infeasible due to computational limitations .   While ICL has been attempted for cross - lingual   downstream tasks , these methods only involve ran-   dom sampling of demonstrations for prompt con-   struction ( Zhang et al . , 2021 ; Winata et al . , 2021 ) .   Shi et al . ( 2022 ) addressed the problem of cross-   lingual text - to - sql conversion using ICL . However ,   their method relies on translating the input text in   the source language to the target language before   generating the corresponding SQL code . Agrawal   et al . ( 2022 ) demonstrated the effects of similar   example selection in a few - shot machine transla-   tion setting which is much similar to our proposed   semantic alignment . To the best of our knowledge ,   there is no study on optimizing prompts for cross-   lingual NLP tasks using ICL .   5 Conclusion   In this work , we described the first - ever attempt   in the direction of cross - lingual prompt design for   in - context learning . We found that a random se-   lection of labeled training examples to construct   the prompt - context limits the capability of a multi-   lingual LLM to infer target labels . Instead , align-   ing the semantics as well as the task - specific tex-   tual signals across the source and the target lan-   guage inputs in the prompt demonstrates supe-   rior performance in cross - lingual text classification.6299Based on these findings , we introduced X - InSTA ,   a novel method of in - context prompt design for   cross - lingual text classification . X - InSTA improves   upon random prompt selection substantially across   multiple different cross - lingual tasks .   We found that the dynamicity of similarity - based   example selection is able to guide the LLM to learn   better in - context predictors irrespective of the lan-   guage pair under consideration . On the other hand ,   language pairs with proper alignment in the label   space get more out of the task - based alignment .   These findings may serve as paving stones toward   better cross - lingual ICL methods that incorporate   an automated , dynamic transition from the source   to target distributions .   Limitations   Since this work relies on the in - context learning   ability of large language models , the challenges   associated with computational resources to load an   LLM ensue . Due to resource constraints , we could   not use larger or commercially available LLMs to   validate if the advantages of X - InSTA translate to   those models as well .   As we observed in Section 3.5 , the static na-   ture of the aligners poses a limitation on X - InSTA .   Moreover , these aligners are manually designed .   Therefore , task - specific , trial - and - error style man-   ual intervention is needed . We believe a better   understanding of the pretraining distribution of the   multilingual LLMs can pave the way toward better   automated alignment methods .   There are multiple shortcomings of monolingual   ICL that entail its cross - lingual counterpart and   X - InSTA does not address them ; issues like knowl-   edge hallucination , limited common - sense reason-   ing , inconsistency in retrieving factual associations ,   etc .   Ethics statement   Our proposed method , X - InSTA , delivers improve-   ments in cross - lingual in - context learning . Since   in - context learning ability is emergent in language   models over billion parameters in size , this can   cause potential discrimination in the usage of these   methods based on the availability of access to com-   putational resources . Research groups with limited   access to computational resources will be handi-   capped while resourceful groups will be able to   investigate and advance the future directions of this   research . We did not use any private or sensitive infor-   mation throughout this research . However , if any   private information was leaked to an LLM during   the pretraining stage , X - InSTA does not provide   any privacy filtration . Therefore , privacy concerns   of the underlying model can potentially manifest   with the outputs provided by X - InSTA .   As we dissected the erroneous predictions in   Section 3.5 , the lack of knowledge of cultural dif-   ferences among different languages is a serious   challenge within the LLM and this limits the per-   formance of X - InSTA . Therefore , any potential de-   ployment of our proposed method should be done   under the lens of such considerations . This is even   more delicate in case tasks like hate - speech clas-   sification which was one of the tasks that we ex-   plored in this work . Wrongfully identifying a hate   speech as non - hate or vice versa in a low - resource   target language based on culturally different lan-   guage usage cues present in the prompt - context in   a high - resource languages is a possibility ; this may   lead to unwarranted cultural appropriation and/or   undemocratic gatekeeping .   References63006301   A Dataset Details   Multilingual Amazon Reviews Corpus : MARC   ( Keung et al . , 2020 ) is a large - scale multilingual   corpus of Amazon reviews of customers . The cor-   pus consists of six distinct languages – German ,   English , Spanish , French , Japanese , and Mandarin .   Each language has a training set of size 200Kthat   we use for selecting our demonstrations and a test   set of 40,000reviews classified as positive or neg-   ative .   Cross - language sentiment classification :   CLS ( Prettenhofer and Stein , 2010 ) is a multilin-   gual corpus of four languages – German , English ,   French , and Japanese . It consists of reviews on   DVD , music , and books , with a training set and   a test set of 2,000sentences for each language   classified into negative and positive .   Hateval : HatEval ( Basile et al . , 2019 ) consists   of two languages – English and Spanish , classi-   fied into hate or non - hate . The test set contains   3,000posts for English and 1,600for Spanish ,   with the training set size being 5,000for Spanish   and10,000for English .   B Model Variants   We experiment with multiple different LMs in their   base versions ( i.e. , random prompting ) to gauge   their ability , namely XGLM 7.5B , XGLM 1.7B ,   and Bloom 7.1B. Table 8 contains the performanceof these models on a subset of the test data used   ( namely , CLS and HatEval with English as the   source language ) . As we can see , XGLM 7.5B   appears to outperform other models by a significant   margin on multiple different tasks , and therefore ,   is used for the rest of the experiments .   C Hyperparameters   All codes were written using PyTorch . We used   the Huggingface repository for loading the LLM   and sentence transformer for extracting semantic   similarity . Sklearn was used for calculating the   F1 score . Table 9 describes values of different   hyperparameters and compute resources used .   D Miscellaneous   D.1 Language Code   Refer to Table 10 for this information .   D.2 Prompt Examples   We show a few example prompts ( demonstrations   and test input ) in Table 11 . Additionally , in Ta-   ble 12 , we demonstrate a few examples of different   task - aligners used for the analysis in Section 3.2.6302Hyperparameter Value   Model XGLM-7.5B   GPU NVIDIA A100   Batch Size 4   Max length 1024   Seeds 32,5,232,100,42   k 46303Prompting   MethodPrompt Input Output   Random   Prompting</s > Review : can not operate this   without using 2 hands . does nt   that defeat the point of using it in   the car ? I did nt realize how diffi-   cult it would be to mount it with   a pop socket on the back , too Rat-   ing : bad < /s > Review : Was skep-   tical because these headphones   are cheap and all the reviews are   five stars , well , here goes another   5 stars one ! For the price , you   wo n’t find anything better right   now . Rating : good</s > Review :   they were nice but too big . Rat-   ing : good</s > Revisar : no me llego el articulo   me lo mando por correos normal   sin seguimiento y nunca me llego   tota un desastre Clasificación : malo / bueno   Semantic   Alignment</s > Review : It never came in   the mail I never got it and they   charge me Rating : bad</s > Re-   view : I never recieved this prod-   uct and it never came in the mail .   It was never delivered to my ad-   dress Rating : bad</s > Revisar : no me llego el articulo   me lo mando por correos normal   sin seguimiento y nunca me llego   tota un desastre Clasificación : malo / bueno   Task Align-   ment</s > Review : can not operate this   without using 2 hands . does nt   that defeat the point of using it in   the car ? I did nt realize how diffi-   cult it would be to mount it with   a pop socket on the back , too Rat-   ing : bad < /s > Review : Was skep-   tical because these headphones   are cheap and all the reviews are   five stars , well , here goes an-   other 5 stars one ! For the price ,   you wo n’t find anything better   right now . Rating : good</s > Re-   view : they were nice but too big .   Rating : good < /s > In Española   bad means malo and good means   bueno.</s > Revisar : no me llego el articulo   me lo mando por correos normal   sin seguimiento y nunca me llego   tota un desastre Clasificación : malo / bueno   X - InSTA</s > Review : It never came in   the mail I never got it and they   charge me Rating : bad</s > Re-   view : I never received this prod-   uct and it never came in the mail .   It was never delivered to my ad-   dress Rating : bad</s > In Es-   pañola bad means malo and good   means bueno.</s > Revisar : no me llego el articulo   me lo mando por correos normal   sin seguimiento y nunca me llego   tota un desastre Clasificación : malo / bueno63046305ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Section 6 .   /squareA2 . Did you discuss any potential risks of your work ?   Section 7 .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Left blank .   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   Not applicable . Left blank .   /squareB1 . Did you cite the creators of artifacts you used ?   No response .   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   No response .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   No response .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   No response .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   No response .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   No response .   C / squareDid you run computational experiments ?   Section 3 .   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   Appendix A6306 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   Appendix A   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   Left blank .   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   Left blank .   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   No response .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   No response .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   No response .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   No response .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   No response.6307