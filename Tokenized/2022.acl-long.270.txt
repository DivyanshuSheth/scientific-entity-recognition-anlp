  Tingchen Fu , Xueliang Zhao , Chongyang Tao , Ji - Rong Wen , Rui YanGaoling School of Artificial Intelligence , Renmin University of ChinaWangxuan Institute of Computer Technology , Peking UniversityMicrosoft Corporation   { lucas.futingchen,zhaoxlpku,chongyangtao}@gmail.com   { jrwen,ruiyan}@ruc.edu.cn   Abstract   Knowledge - grounded conversation ( KGC )   shows great potential in building an engaging   and knowledgeable chatbot , and knowledge se-   lection is a key ingredient in it . However , pre-   vious methods for knowledge selection only   concentrate on the relevance between knowl-   edge and dialogue context , ignoring the fact   that age , hobby , education and life experience   of an interlocutor have a major effect on his   or her personal preference over external knowl-   edge . Without taking the personalization issue   into account , it is difficult to select the proper   knowledge and generate persona - consistent re-   sponses . In this work , we introduce personal   memory into knowledge selection in KGC to   address the personalization issue . We propose   a variational method to model the underlying   relationship between one ’s personal memory   and his or her selection of knowledge , and de-   vise a learning scheme in which the forward   mapping from personal memory to knowledge   and its inverse mapping is included in a closed   loop so that they could teach each other . Experi-   ment results show that our method outperforms   existing KGC methods significantly on both   automatic evaluation and human evaluation .   1 Introduction   Open - domain dialogue system often suffers from   safe response ( Li et al . , 2015 ; Zhang et al . , 2019 )   problem as they could only refer to the context   when generating a response . To alleviate this ,   knowledge - grounded conversation ( KGC ) is pro-   posed to introduce external fact and real - world   commonsense as prior knowledge ( Zhou et al . ,   2018a ; Dinan et al . , 2019 ; Zhao et al . , 2020a ) , such   that a dialogue system is able to ground the conver-   sation with the provided knowledge and thereforegenerate informative and engaging responses . As   external knowledge supplements the background   to the inputs and decides what to say , knowledge   selection is a key ingredient in KGC .   Numerous methods have been developed to   tackle the knowledge selection problem by sequen-   tial latent variables ( Kim et al . , 2020 ; Meng et al . ,   2020 ) , reinforcement learning ( Zhao et al . , 2020b ) ,   or expectation maximization algorithm ( Li et al . ,   2020 ) . In spite of the progress in this task , knowl-   edge selection remains an unsolved problem as   the precision is still far from satisfactory in Wiz-   ard of Wikipedia ( Dinan et al . , 2019 ) and other   benchmarks in KGC ( Gopalakrishnan et al . , 2019 ) ,   which also hinders the optimization of subsequent   response generation models . A crucial point is ,   they often make assumption that the golden knowl-   edge is distinguishable as long as the dialogue con-   text is known , yet this is not always held true be-   cause there exists a one - to - many relationship in   conversation and the past utterance history in a   dialogue session is insufficient to decide the knowl-   edge selection or the future trend of a dialogue .   As is shown in Figure 1 , personalization is a   key to success in the task because knowledge se-   lection is a personal or subjective process in na-   ture . When people communicate with each other ,   their perception of dialogue context will evoke their   past memory about relevant life experience , taste   and values , which we refer to as personal memory .   The aroused fragment of personal memory further   guides their interest and preference for different   knowledge . Motivated by this , we postulate a new   task named personalized KGC , introducing per-   sonalization into knowledge - grounded dialogue to   encourage more human - like knowledge selection .   Importing persona memory into knowledge se-   lection is a non - trivial task . One of the challenge is   concretization of personal memory . Personal mem-   ory is an abstract concept related to user - specific   experience , which is difficult to depict or model.3901   Though it has been discussed in open - domain di-   alogue ( Li et al . , 2016 ; Zhang et al . , 2018 ) , no   previous research sheds light on the personaliza-   tion issue in KGC and there exists no dialogue   dataset featured with external facts and personal   memory at the same time . Besides , there is no   annotated label to indicate which knowledge candi-   date a person will choose based on his or her per-   sonal memory . Namely , the mapping between per-   sonal memory and knowledge selection is highly   unconstrained without golden label . Intuitive reso-   lution like treating personal memory as additional   knowledge is sub - optimal because of dependency   between knowledge and personal memory , as is   shown in our experiments .   To address the above issue , we construct a KGC   dataset featured with personalized memory reposi-   tory , collecting user - specific utterance history un-   der multiple types of context , which is a reflec-   tion of one ’s personal memory . And to discover   the underlying relationship between the dialogue   context , personal memory and knowledge , we pro-   pose a variational method and introduce two latent   variables ZandZto indicate the fragment of   personal memory to evoke and the knowledge can-   didate to select respectively . And to model the   mapping from ZtoZ , we introduce an inverse   mapping as a dual task and employ dual learning   to allow the two mappings to teach each other . The   motivation behind this is intuitive : The reconstruc-   tion of personal memory from selected knowledge   candidate is natural and easy if the mapping frompersonal memory to knowledge is accurate . Exten-   sive experiment shows that our methods outperform   competitive baselines in both automatic evaluation   and human evaluation , justifying the importance of   introducing personal memory and the effect of the   dual learning mechanism empirically .   The contributions of this work are three - fold :   ( 1 ) We explore the personalization issue of the   knowledge selection task in KGC and construct a   dataset featured with user - specific personal mem-   ory to benefit relevant research in the future . We   are the first to explore the possibility of introducing   personal memory into KGC .   ( 2 ) We propose a novel variational method and   introduce two latent variables to model the inter-   dependency between the persona and knowledge .   Besides , we employ dual learning to optimize the   relationship between the dialogue context , personal   memory and knowledge in a unified framework .   ( 3 ) We conduct extensive experiments and verify   the proposed methods empirically . Both the auto-   matic and human evaluation evidence the efficacy   of our proposed method .   2 Related Work   There is a substantial literature in the field of   knowledge - grounded conversation . With the   grounding of external knowledge in format of   knowledge graph ( Zhou et al . , 2018a ; Wu et al . ,   2019 ) , document ( Ghazvininejad et al . , 2018 ; Zhou   et al . , 2018b ; Zhao et al . , 2019 ) or visual back-   ground ( Das et al . , 2017 ) , it is regarded as a crit-   ical method towards intelligent dialogue system .   Nowadays , existing methods in KGC often share   a paradigm that decomposes the task into two re-   lated sub - problems , namely knowledge selection   and utterance generation ( Kim et al . , 2020 ) . In this   work , we mainly focus on the knowledge selection   task . To this end , a great deal of methods have been   proposed to retrieve the most relevant knowledge   by memory network ( Ghazvininejad et al . , 2018 ) ,   sequential latent variables ( Kim et al . , 2020 ; Meng   et al . , 2020 ) , reinforcement learning ( Zhao et al . ,   2020b ) and so on . A recent work gives attention   to the expression style of knowledge ( Zhao et al . ,   2021 ) . However , they only focus on the decoding   phase and no methods shed light on the personal-   ization issue of knowledge selection , to our best   knowledge .   Our work is related to dual learning as well . First   proposed in neural machine translation by He et al.3902(2016 ) , dual learning is a semi - supervision learning   scheme aiming at utilizing large - scale unlabeled   data . Together with its newly appeared variants in   recent years ( Xia et al . , 2017 , 2018 ; Wang et al . ,   2019 ) , dual learning has been successfully applied   in neural machine translation ( Xia et al . , 2017 ; He   et al . , 2017 ) , image - image - translation ( Yi et al . ,   2017 ; Lin et al . , 2018 ) , sentiment analysis ( Xia   et al . , 2017 ) , automatic speech recognition ( Ren   et al . , 2019 ) , question answering ( Tang et al . , 2017 ) ,   and knowledge - grounded dialogue ( Meng et al . ,   2020 ) . Our work is related to dual learning as well .   First proposed in neural machine translation by He   et al . ( 2016 ) , dual learning is a semi - supervision   learning scheme aiming at utilizing the large scale   unlabeled data . In this work , we apply dual learn-   ing to model the inter - dependency relationship be-   tween one ’s personal memory and his or her choice   of knowledge .   3 Methodology   3.1 Problem Formulation   Suppose we have a KGC dataset Dwith N   case , and every case is in format of ( C , K , R ) ,   where C= [ u , u , · · · , u]is the context   of the dialogue with ltokens in total , K=   { K , K , · · · , K}is a set of |K|knowledge   candidates . And R= [ r , r , · · · , r]is a re-   sponse in this conversation corresponding to a   specific user with unique user i d. Different from   the original KGC task , we have a memory repos-   itoryM. For every interlocutor corresponding to   the response , a set of his or her personal mem-   oryP={P , P , · · · , P}composed of |P|cus-   tomized utterance history could be retrieved from   the memory repository . Our goal is to learn a prob-   abilistic model p(R|C , K , P)that could generate   a personalized and informative response based on   personal memory and knowledge .   3.2 Model Overview   Figure 2 gives a graphical model of our methods .   As is shown , the core of our proposed method is   five probabilistic models to calculate the prior and   posterior distribution of Z , Zand an auxiliary   distribution of Z. During training , we devise an   unsupervised learning scheme , in which we opti-   mize the distribution of two latent variables Z   andZby dual learning . To be more specific , we   first sample a ˜Zfrom the posterior distribution   q(Z|C , R ) , and then calculate the forward map-   ping from memory to knowledge q(Z|C , R , ˜Z ) ,   from which we sample a˜Z. The reward is de-   signed as the probability of reconstructing the se-   lected memory fragment by the auxiliary distribu-   tionπ(Z=˜Z|C , R,˜Z ) . By maximizing the   reward , the primal task and the auxiliary task could   benefit each other . The gains of the auxiliary distri-   bution is distilled to q(Z|C , R ) , such that the two   posterior distribution and the auxiliary distribution   form a closed loop . Besides , the prior distribution   is forced to get close to the posterior distribution   via KL - divergence .   In the inference phase , the prior distribution of   Zis calculated at first , from which we sample and   activate a personal memory fragment . After that ,   the woken memory fragment is used to decide the   prior knowledge distribution p(Z|C ) . Finally ,   the knowledge sampled from Ztogether with the   memory fragment is sent into a generator to syn-   thesize a response . Note that the golden response   is only involved in the training phase . π,ϕandψ   are all learnable parameters .   3.3 Neural parameterization   To make the latent variables interpretable , we set   the latent space of ZandZas the number of   memory fragments or knowledge candidates to   choose from , and each sampling corresponds to   a single piece of memory fragment or a knowl-   edge candidate . Furthermore , motivated by human   cognitive process , the aroused personal memory   fragment implies one ’s preference for different ex-   ternal knowledge , which influences the likelihood   of choosing different knowledge . In light of this,3903the prior distribution of ( Z , Z)is factorized as :   p(Z , Z ) = p(Z|Z)p(Z ) ( 1 )   And to calculate their probability distribution , we   adopt BERT ( Devlin et al . , 2018 ) as the backbone   of our method to obtain a dense representation of   dialogue context , response , candidate knowledge   sentence or personal memory fragment . Take the   calculation of the prior distribution p(Z|C , Z )   as an example . We first concatenate the context   C , the memory fragment Pindicated by the sam-   pledZ , and the i - th candidate knowledge Kto-   gether as a long sequence . A special [ CLS ] token   is prepended at the beginning of the sequence and   [ SEP ] is inserted to separate different utterances:(2 )   where l , landlare the number of tokens in   the context , memory facet and knowledge candi-   date respectively . Then the embedding layer will   convert Iinto input representations , which is the   sum of the corresponding token embedding and   position embedding . Thereafter , the BERT encoder   performs multi - head attention on the input repre-   sentation to obtain a dense representation . There   arenidentical layers in the BERT encoder , and   for each layer , the multi - head attention could be   formulated as   where FFN(·)is a feed - forward network and we   useQ , K , andVto denote the query   matrix , key matrix and value matrix after the l−1-   th layer respectively . For self - attention , we have   Q = K = V = H , ( 4 )   where Hmeans the hidden state at the l - th layer .   Specially , His the input embedding and His   the final output of the BERT .   We use the vector corresponding to the position   of the special [ CLS ] token in Has the represen-   tation of the i - th knowledge candidate , which is   referred to as h. Then the distribution of Zis   calculated as   p(Z = i|C , Z ) = exp(f(h))Pexp(f(h ) ) ,   ( 5 )   where f(·)is a multi - layer perceptron . The prior   and posterior distribution of ZandZare calcu-   lated in a similar way . The only difference liesin the constitution of input sequence I : For the   prior distribution of Z , Iis the concatenation of   dialogue context and a candidate personal memory   facet :   I = u , u,···u , p , p , · · · , p ( 6 )   And to calculate the posterior distribution , we insert   the response tokens behind the dialogue context to-   kens as the response usually contains clue indicat-   ing the selected knowledge and memory . Namely ,   to compute q(Z|C , R ) , the posterior of Z , the   input is :   I = u , u,···u , r , r , · · · , r , p , p , · · · , p   ( 7 )   And for q(Z|C , R , Z ):   I = u , u,···u , r , r , · · · , r ,   p , p , · · · , p , k , k , · · · , k(8 )   Normally , the generator gof our method could   be specified as any large - scale pre - trained language   model . Here we define the generator as GPT-   2 ( Radford et al . , 2019 ) . Previous methods often   synthesize a response merely based on the dialogue   context and the selected knowledge , taking no con-   sideration of the persona of the interlocutor , which   may lead to an inconsistency in persona . Different   from that , we input the sampled personal memory   fragment and the sampled knowledge candidate   into GPT-2 all together with the dialogue context .   Intuitively , personal memory fragment implies why   the knowledge is paid attention to and underlying   relevance between the persona of the interlocutor   and the knowledge , which endows the generator   to generate persona - consistent and knowledgeable   responses :   g(R ) = g(R|C , Z , Z )   = Yg(r|C , Z , Z , r)(9 )   3.4 Learning Details   Directly maximizing the marginal log - likelihood   of generating the correct response g(R|C , Z , Z )   requires integrating over all possibilities of Z   andZ , which is more than time - consuming . In-   spired by variational inference , we introduce a   variational posterior as the true posterior is in-   tractable . Thereby , instead of directly optimizing3904Algorithm 1 The proposed learning algorithm .   the marginal log - likelihood , we derive an evidence   lower bound objective to maximize :   where q(Z|Z),q(Z),p(Z),p(Z|Z )   are shorthand for q(Z|C , R , Z),q(Z|C , R ) ,   p(Z)andp(Z|C , Z)respectively . A step-   wise derivation could be found in the supplemen-   tary materials .   The forward mapping from personal memory   to knowledge candidates is relatively implicit and   obscure , partially because the customized utterance   history contains unwanted noise . As a result , there   is a tendency that Zis ignored and p(Z|Z , C )   is degenerated into p(Z|C ) , which we refer to as   thevanishing memory .   To address this issue , inspired by the idea of   dual learning ( He et al . , 2016 ) , we introduce an   inverse mapping from knowledge candidate to per-   sonal memory as a dual task , which is depicted by   the auxiliary distribution π(Z|C , R , Z ) . Intu-   itively , there is a natural duality between the map-   ping from personal memory to knowledge and the   inverse mapping . Therefore , if the forward map-   ping makes a good inference about the knowledgeto choose , the inverse mapping is able to map it   back to personal memory , which means that the   memory is not vanishing .   And before the dual learning procedure , the pri-   mal task and the dual task are warmed up to speed   up convergence and alleviate error accumulation in   the dual learning process , following the idea of He   et al . ( 2016 ) and Meng et al . ( 2020 ) . Namely , we   construct pseudo knowledge label ¯Pand persona   label ¯Kbased on their similarity to the response .   ¯K= maxSim(K , R )   ¯P= maxSim(P , R ) ( 11 )   Then , both the primal task and the dual task are   warmed up with a traditional maximum likelihood   estimation objective .   After the warm - up procedure , for each itera-   tion , we first sample a ˜Zaccording to its pos-   terior distribution q(Z|C , R ) . Then the for-   ward mapping calculates the probability distribu-   tionq(Z|C , R , ˜Z ) , from which we sample a˜Z.   The reward for the forward mapping is defined as   the probability that the auxiliary distribution recov-   ers the ˜Z. Mathematically , we have   Re = π(Z=˜Z|C , R,˜Z ) ( 12 )   Symmetrically , the reward for the auxiliary distri-   bution is the prediction probability of the golden   knowledge by the forward mapping :   Re = q(Z=¯Z|C , R , Z ) , ( 13 )   where¯Zis corresponding to the pseudo knowl-   edge label .   And the objective of the dual learning is to max-   imize the reward :   L = E[Re+Re ] ( 14 )   For reward maximization , we optimize the pa-   rameter through policy gradient method ( Sutton   et al . , 2000 ):   Finally , the gains of the dual task is distilled into   the posterior distribution of Zvia a cross - entropy   loss:3905where αis a hyper - parameters to balance the   weights of two parts and the superscript Tmeans   that the distribution is normalized at temperature T.   Thus , the three probabilistic models form a closed   loop in which each component is trained alterna-   tively . The full procedure of our proposed learning   algorithm is concluded in Algorithm 1 .   4 Experiment   4.1 Dataset   Since existing dataset like CMU_DoG ( Zhou et al . ,   2018b ) or Holl - E ( Moghe et al . , 2018 ) do not con-   tain information about personal memory , we estab-   lish a new KGC dataset equipped with a memory   repository . The dataset is constructed based on   Reddit ( Baumgartner et al . , 2020 ) .   In detail , we download the conversational data   on the PushShift dump of Reddit ranging from 2011   to the first half of 2015 and divide them into a train-   ing set , a validation set and a test set according to   the date . To construct a memory repository , we   maintain a dictionary where the key is a long string   hashed from the user account name and the value   is a set of utterances of the user . Since it is a repos-   itory for user - specific utterances , it may inevitably   contain false beliefs or subjective opinions . We   shall leave this issue for future work . Elaborated   data filtering is conducted to ensure : ( 1 ) We only   keep utterances from users that have at least 5ut-   terances in the memory repository ; ( 2 ) Utterances   that are too long or too short are filtered ; ( 3 ) Para-   phrase tool ( Damodaran , 2021 ) is applied on every   utterances to avoid tracing the utterances back to   real reddit users .   The statistics of our dataset is shown in Table 1 .   And the code is available at https://github .   com / Lucasftc / PersonaKGC . A few exam-   ples is shown in Appendix A.3 . To benefit future   research and meanwhile avoid possible malicious   abuse , the dataset is available upon request from   the authors .   4.2 Compared Methods   To verify the effectiveness of the proposed meth-   ods , we compare our methods with baselines in   KGC . Meanwhile , since our proposed method   makes use of personal memory to generate persona-   consistency response , we also compare our meth-   ods with baselines in personalized dialogue .   •Generative Profile Memory Network ( GPMN )   ( Zhang et al . , 2018 ) is a method in personal-   ized dialogue which employs Memory Net-   work along with persona information .   •Transformer Memory Network ( TMN ) ( Dinan   et al . , 2019 ) adopts the traditional Memory   Network with transformer architecture and   introduces the knowledge selection loss .   •Transfertransfo ( Wolf et al . , 2019 ) is a com-   bination of a transfer learning based train-   ing scheme and a high - capacity transformer   model and achieves the best results in the Con-   versational Intelligence Challenge 2 .   •Sequential Knowledge Transformer ( SKT )   ( Kim et al . , 2020 ) utilizes sequential latent   variables for knowledge selection . We use   the pseudo knowledge labels for the golden   knowledge label in implementation .   •KnowledGPT ( Zhao et al . , 2020b ) puts the   knowledge selector and the response genera-   tor in a framework and employ reinforcement   learning and curriculum learning to accom-   plish the state - of - the - art performance in KGC .   •KnowledGPT+M , a variant of KnowledGPT   where we treat personal memory as knowl-   edge candidates as well and input them to the   knowledge selector .   •PBOT ( Liu et al . , 2020 ) is a transmitter-   receiver based framework explicitly modeling   the perception between the interlocutors and   achieves the state - of - the - art in personalized   dialogue .   •BoB ( Song et al . , 2021 ) is a newly published   method that disentangles personalized dia-   logue into persona understanding and person-   alized generation .   For more implementation details about the base-   lines and our method , please refer to appendix A.2.3906   4.3 Evaluation Metrics   We choose distinctness , BLEU(Papineni   et al . , 2002 ) , ROUGE(Lin , 2004)and ME-   TEOR(Denkowski and Lavie , 2014)to be our   automatic metrics . Focusing on the exact n - gram   co - occurrence in hypothesis and reference , BLEU   and ROUGE evaluate the appropriateness of the   proposed model . Distinctness is calculated as the   ratio of unique unigrams and bigrams , paying   more attention to the diversity of generated text .   METEOR measures the alignment , or the exact ,   stem , synonym , and paraphrase matches between   the hypothesis and reference .   Apart from automatic evaluation , we conduct hu-   man evaluation . Specifically , 200examples are ran-   domly sampled from the test set and well - educated   native speakers are recruited to assess the quality   of the generation from different models with their   source hidden . Each annotators are required to give   a score in { 0 : bad , 1 : fair , 2 : good } for three   independent aspects : ( 1 ) fluency : whether the reply   is fluent ; ( 2 ) coherence : whether the reply is coher-   ent with the context ; and ( 3 ) faithfulness : whether   the reply is well - grounded and faithful to the se-   lected knowledge sentence and memory fragment .   The agreement of annotators is measured via Fleiss ’   kappa ( Fleiss , 1971).4.4 Experiment Results   We first report the experimental result in automatic   evaluation . As is shown in Table 2 , our method   outperforms the state - of - the - art baselines in KGC   and personalized dialogue in most metrics , veri-   fying the effectiveness of our model empirically .   Among non - pretrained methods , TMN and GPMN   are low in diversity , since their generator is not   pre - trained on large corpus before . SKT improves   distinctness but shows low appropriateness , pos-   sibly because that it highly relies on the golden   knowledge label , which is costly and not always   available . In pre - trained based methods , Transfer-   transfo attains impressive results on distinctness . It   also achieves competitive appropriateness results ,   but not as good as ours . We gauge the performance   of the model to the large document - level training   corpus , a critical choice for pre - trained language   model , which may boost the diversity of gener-   ated text . Besides , the performance of the BoB ,   a recently published baseline , is less satisfactory   compared with others . The premise of BoB is the   disentanglement between contextual coherence and   persona consistency , which is not always achiev-   able especially when we use user - specific dialogue   history for personal memory information . And   it is notable from the table that there is a signif-   icant gap between the baseline methods in KGC   or personalized dialogue and ours , validating that   neither simply projecting personal information into   dialogue nor purely grounding on knowledge is an   acceptable solution to the KGC task . It is necessary   to combine personal memory and external knowl-   edge together . The comprehensive improvement   of KnowledGPT+M in contrast with the original   KnowledGPT also reveals this viewpoint . Addition-   ally , the considerable advantage of our proposed   method over KnowledGPT+M illustrates the fact3907   that treating personal memory as knowledge is not   enough . The dependency between personal mem-   ory and the knowledge should not be ignored .   We also present the result of human evaluation   since no automatic metric is perfect in this task ( Di-   nan et al . , 2019 ) . Since human evaluation is time-   consuming and expensive , only competitive base-   lines are involved . As shown in Table 3 , our pro-   posed model outperforms the baseline methods and   there is an evident improvement .   4.5 Analysis   Apart from the main results , we are especially in-   terested in some research questions :   •(RQ1 ) How does each component contributes   to the performance of our model ?   •(RQ2 ) How many knowledge sentences andmemory fragments to select ?   To answer the first question , we conduct ablation   study and compare the full model with several vari-   ants:(1 ) w/o . know . the external knowledge base to   grounding the dialogue is removed ; ( 2 ) w/o . mem .   personal memory is removed and this variant is a   standard KGC model essentially ; ( 3 ) w/o . dual . the   dual task is removed , so there is no dual learning   and distillation in this variant ; ( 4 ) w/o . dep . the   dependency of the two latent variables is removed   soZandZare calculated independently . The   ablation result is shown in Table 4 , from which   we could have the following observations : ( 1 ) w/o .   know and w/o . mem exhibit a degeneration at a   great extent , further justifying the necessity of in-   troducing knowledge and personal memory into a   dialogue system , respectively . ( 2 ) w/o . depalso   shows an obvious deterioration . This is in line with   our expectation since w/o . depmodel ZandZ   as two independent latent variables , ignoring the   underlying dependence between them . Compara-   tively speaking , w/o . dual achieves a better result ,   but not as good as the full model due to the destroy   of the closed dual loop .   And to have a intuitive perception about the   effect of the closed dual loop , we examine   the promotion brought to the q(Z|C , R , Z ) ,   π(Z|C , R , Z)andq(Z|C , R)in terms of Re-   call@1 of knowledge or personal memory . The   result is shown in Figure 3 . From the figure we   could see that there is an obvious improvement   after trained with our proposed learning algorithm .   For the ( RQ2 ) , we first explore it by varying   the amount of selected personal memory fragments   and observe how the knowledge selection proce-   dure is influenced . In detail , we vary the num-   ber of personal memory fragments msampled   byp(Z|C)from 1to4and evaluate the per-   formance of p(Z|C , Z)in terms of Recall@n   ( n∈{1,2,5,10 } ) .   As is shown in Table 5 , we could find that the   best performance is reached when m= 2 . There is3908   a fluctuation or slight drop when mcontinues to in-   crease possibly owing to the distraction mixed with   the redundant personal memory . Besides , we are   also curious about the final generation performance   under different numbers of knowledge and personal   memory fragment . It could be seen from Figure 4   that there appears a decline when we increase the   number of knowledge and personal memory frag-   ment , which we attribute to the unwanted noise   mixed with personal memory and knowledge .   5 Conclusion   In this work , we explore personalized KGC by   introducing personal memory into knowledge se-   lection task . Two latent variables are introduced   to select knowledge and personal memory respec-   tively . Besides , dual learning scheme is employed   to allow the two selection task to teach each other .   For future work , we would like to extend the per-   sonalized knowledge - grounded dialogue to person-   alized conversational recommendation system for   application in online shopping .   Ethical Considerations   Intended Use The chief purpose of our dataset is   to examine a dialogue model ’s capacity in selecting   proper knowledge with the help of personal mem-   ory . The dataset is mainly for research propose   and it is not supposed to be directly used to train   a production system . And researchers should be   aware of the possible ethic issues before exploiting   our dataset .   Data Collection All the examples in our dataset   are in English and no human annotators are in-   volved in the data collection process . As men-   tioned in Sec.4.1 , our dataset is built on the basis   of the Reddit dumps from Pushshift ( Baumgartner   et al . , 2020 ) , which is a publicly available resource   widely used in more than a hundred peer - reviewed   publications . Our data collection is in consistent   with the term of use and the research is granted   ethical approval by an external institutional review   board . To avoid potential abuse , the dataset is avail - able upon request to the authors . Contact the au-   thors ( by email ) and clearly state your intended use   if you believe the dataset might be helpful in your   research .   User Privacy Although our dataset includes user-   specific utterance history as personal memory , no   user account names will be revealed or inferred   from the dataset . Besides , the utterance histo-   ries are paraphrased during our procession of the   dataset such that they can not be traced back to the   real users in Reddit . In conclusion , There is no   personally identifiable information in our dataset   or underlying leakage of personal information .   Acknowledgement   Thanks for the reviewers for their valuable sugges-   tions . This work was supported by National Natu-   ral Science Foundation of China ( NSFC Grant No .   62122089 & No . 61876196 & No . 61832017 ) ,   Beijing Outstanding Young Scientist Program   NO . BJJWZYJH012019100020098 , and Intelli-   gent Social Governance Platform , Major Innova-   tion & Planning Interdisciplinary Platform for the   " Double - First Class " Initiative , Renmin University   of China . We also wish to acknowledge the sup-   ports provided and contributions made by Public   Policy and Decision - making Research Lab of RUC ,   and the Public Computing Cloud , Renmin Univer-   sity of China . Rui Yan is also supported by Beijing   Academy of Artificial Intelligence ( BAAI ) .   References390939103911A Appendix   A.1 The derivation of ELBO   For the first term , it could be decomposed as :   Elogg(R|Z , Z )   = EXlogg(R|Z , Z , r )   ( 19 )   For the second term and the third term , they   could be further simplified :   E[logp(Z)−logq(Z ) ]   = −KL(q(Z)||p(Z))(20 )   E[logp(Z|Z)−logq(Z|Z ) ]   = −EKL(q(Z|Z)||p(Z|Z ) )   ( 21 )   A.2 Implementation Details   We choose BERT(Devlin et al . , 2018)and   GPT-2 ( Radford et al . , 2019)as the pre - trained   language model , and implement our methods with   the code in Hugging Face . To tag the pseudo knowl-   edge label and personal memory label , the similar-   ity score function used in Eq . 11 is implemented   as unigram F1 ( Dinan et al . , 2019 ) with the codeshared at ParlAI . In the warm up phase , we pre-   train the primal task and dual task for 5000 steps   and set the batch size and learning rate to be 16   and1e−5respectively . The posterior distribution   ofZis optimized for 1000 steps with a learn-   ing rate of 1e−5and a batch size of 16 . In the   dual learning phase , the algorithm 1 runs for 1000   steps with a batch size of 16and a learning rate   of1e−6 . All modules are learned with Adam   on a GTX 1080 , and we set the hyperparameter   of Adam to be β= 0.9,β= 0.999respectively .   Cosine learning schedule is applied to adjust the   learning rate during training . We set the minimum   learning rate to be 0 in cosine learning schedule .   Gradient clip is set to 2.0to avoid the explosion of   gradient . When decoding , beam search is applied   with a beam width of 5and the minimum generated   length is 10 . The repetition penalty and the length   penalty is set to be 1.0and0.0respectively .   A.3 Data Examples   In Table 6 , We present several examples of our   constructed dataset .   A.4 Case Study   To further analyse the model ’s features , a case in   test set is provided in Table 7 . As is shown , baseline   methods in personalized dialogue has no access to   external knowledge and facts , thus their generation   result tend to be a little generic . And it seems that   the ordinary KGC methods usually give a plain   response like KnowledGPT . Our proposed method   generates a more human - like response , which is in   line with our expectation.39123913