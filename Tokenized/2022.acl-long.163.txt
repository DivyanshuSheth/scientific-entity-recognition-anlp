  Zhe Hu , Hou Pong Chan , Jiachen Liu , Xinyan Xiao , Hua Wu , and Lifu HuangBaidu IncFaculty of Science and Technology , University of MacauVirginia Tech{huzhe01,liujiachen,xiaoxinyan,wu_hua}@baidu.comhpchan@um.edu.mo , lifuh@vt.edu   Abstract   Despite recent progress of pre - trained language   models on generating fluent text , existing meth-   ods still suffer from incoherence problems in   long - form text generation tasks that require   proper content control and planning to form   a coherent high - level logical flow . In this work ,   we propose PLANET , a novel generation frame-   work leveraging autoregressive self - attention   mechanism to conduct content planning and   surface realization dynamically . To guide the   generation of output sentences , our framework   enriches the Transformer decoder with latent   representations to maintain sentence - level se-   mantic plans grounded by bag - of - words . More-   over , we introduce a new coherence - based con-   trastive learning objective to further improve   the coherence of output . Extensive experi-   ments are conducted on two challenging long-   form text generation tasks including counter-   argument generation and opinion article gener-   ation . Both automatic and human evaluations   show that our method significantly outperforms   strong baselines and generates more coherent   texts with richer contents .   1 Introduction   Neural sequence - to - sequence ( seq2seq ) models are   dominant methods for text generation nowadays ,   which are trained to maximize the log - likelihood   over targets in an end - to - end fashion ( Cho et al . ,   2014 ) . Recently , pre - trained methods such as GPT-   2 ( Radford et al . , 2019 ) and BART ( Lewis et al . ,   2020 ) have achieved promising results by lever-   aging large - scale data . While these models can   generate fluent results , they still fall short of pro-   ducing coherent long - form texts with multiple sen-   tences ( Dou et al . , 2021 ) .   Long text generation , especially opinion gener-   ation , usually requires the model to ( 1 ) conduct   proper content selection and ordering ( i.e. , “ what   to say and when to say it ” ) to form a coherent high-   level logical flow , and ( 2 ) appropriately reflect the   text plans into final outputs ( i.e. , “ how to say it ” ) .   We present an example of counter - argument gener-   ation in Figure 1 : given a statement on a controver-   sial topic and a set of keyphrases as guidance talk-   ing points , the task aims to produce an argument   with a different stance to refute the statement ( Hua   et al . , 2019 ) . Human writer assigns keyphrases   for each sentence to form a coherent logical flow   ( e.g. , “ corporations easily tap into public funding ”   →"they also have large influence on government "   →"the current government is still corrupt " ) and   produces the final counter - argument that " public   funding wo n’t solve the election problems " . In con-   trast , although BART learns to include keyphrases   and generate an argument relevant to the statement ,   it suffers from incoherence issues such as incorrect   usage of keyphrases ( not “ corporations ” but ‘ elec-   tion ” that “ be manipulated and controlled ” ) and   wrong stance ( “ public funding would make govern-   ment less corrupt ” ) , and fails to maintain smooth   transitions between sentences ( e.g. , sentence 2 and22883 are unrelated ) and form a coherent text .   To solve the above defects , various text plan-   ning methods were proposed to improve the co-   herence of the generated text . The first type of   methods ( Kang and Hovy , 2020 ; Fu et al . , 2020 ;   Kong et al . , 2021 ) leverage a latent variable as a   global plan to guide the generation process , as il-   lustrated in Figure 2 ( a ) . However , these methods   do not consider fine - grained sentence - level plan-   ning . The second line of methods ( Hua and Wang ,   2020 ; Goldfarb - Tarrant et al . , 2020 ) first produce   sentence - level content plans , and then pass content   plans to a surface realization module to generate   the output words , as shown in Figure 2 ( b ) . Never-   theless , the planning and surface realization com-   ponents are disjointed and may lead to cascading   errors ( Hua et al . , 2021 ) .   In this work , we propose PLANET , a novel   text generation framework that dynamically per-   forms content planning and surf ace realizatio nin   autoregressiv eTransformers . As shown in Fig-   ure 2 ( c ) , for each target sentence , an autoregressive   decoder first performs dynamic content planning by   producing a latent representation ( SN ) as a seman-   tic guidance , and then generates the sentence words .   Both the content planning and surface realization   are achieved dynamically by the autoregressive self-   attention in a unified way : to generate a sentence   ( e.g. , sentence 3 ) , the latent representation ( SN )   attends the previous latent representations ( SN ,   solid blue arrows ) and previous context ( sentence   1and2 , dashed blue arrows ) to plan its overall se-   mantic content ; Then , each output position in the   sentence attends the corresponding latent represen-   tation ( SN , solid green arrow ) and the previous   words ( dashed green arrows ) , and optionally se-   lect keyphrases ( gray arrow ) to decide the exact   wording . To supervise the latent representations ,   we further introduce a sentence - level bag - of - words   prediction auxiliary task to provide supervision sig-   nals of the lexical semantics of the corresponding   sentence . In this way , our framework can be trained   end - to - end and easily applied to pre - trained autore-   gressive Transformers .   Furthermore , to empower our model to distin-   guish coherent and incoherent targets and gener-   ate more coherent outputs , we propose a novel   coherence - based contrastive learning objective   with different strategies to construct negative sam-   ples . We evaluate our model on two long - form   opinion generation tasks : ( 1 ) counter - argument   generation with Reddit / ChangeMyView dataset ,   and ( 2 ) opinion article generation from the New   York Times Opinion corpus . Automatic evalua-   tions show that our proposed method significantly   outperforms strong baselines and generates more   coherent texts with richer contents . Human evalua-   tions further indicate that our model can properly   leverage guidance keyphrases and generate better   results on both datasets .   The overall contributions of our work are :   •A unified framework that dynamically con-   ducts content planning and surface realization by   leveraging the autoregressive self - attention , with a   novel sentence - level bag - of - words auxiliary task to   guide the semantic content of each sentence ;   •A new coherence - based contrastive learning   method with different negative sample construction   strategies to improve the coherence of outputs ;   •Our approach outperforms strong baselines   for both automatic and human evaluations on two   challenging long - form text generation tasks .   2 Related Work   Text Planning for Neural Generation . Tradi-   tional text generation pipeline leverages text plan-   ning component to decide on the high - level struc-   tures ( McKeown , 1985 ; Reiter and Dale , 1997 ;   Hovy , 1990 ; Carenini and Moore , 2006 ) . Ear-   lier work incorporates text planning into neural   seq2seq structures by introducing hierarchical de-   coders ( Yao et al . , 2019 ; Moryossef et al . , 2019;2289Shen et al . , 2019 ) . However , these methods are   hard to be applied to pre - trained models because   of the modifications of model architecture . Several   studies design separate modules for text planning   and surface realization ( Hua and Wang , 2020 ; Tan   et al . , 2021 ; Goldfarb - Tarrant et al . , 2020 ) , which   lead to a disconnection of the two components   and often produce undesired outputs ( Castro Fer-   reira et al . , 2019 ) . Recently , Rashkin et al . ( 2020 )   present a memory - based model to keep track of   the content usage and generate paragraphs recur-   rently . Nevertheless , they do not consider sentence-   level text planning which is critical to maintain   high - level logical flow for opinion text generation .   Hua et al . ( 2021 ) propose a mixed language model   to perform content selection and ordering . How-   ever , they encode multiple content items separately   and do not fully consider the interactions among   content items . In contrast to these prior studies ,   our model conducts sentence - level text planning   and surface realization dynamically by introduc-   ing high - level latent representations for target sen-   tences , and can be incorporated into pre - trained   autoregressive Transformers .   Coherent Long - form Text Generation . Recent   work tackles this problem on the tasks including   story generation ( Fan et al . , 2019 ; Xu et al . , 2020 ) ,   paragraph completion ( Kang and Hovy , 2020 ) , text   infilling ( Huang et al . , 2020 ) , long - form conver-   sation ( Xu et al . , 2021 ) and news article genera-   tion ( Rashkin et al . , 2020 ; Tan et al . , 2021 ) . To   solve the incoherence issue , one type of work   adopts the plan - then - generate strategy as discussed   above . Some work also incorporates discourse and   structured information into generation process to   improve output coherence ( Jiang et al . , 2021 ; Ji   and Huang , 2021 ; Bosselut et al . , 2018 ) . Recently ,   Guan et al . ( 2021 ) propose two auxiliary objec-   tives of similarity prediction and order discrimi-   nation to improve coherence . In this work , we   focus on long - form opinion text generation which   requires an appropriate combination of credible   talking points with rigorous reasoning ( Hua et al . ,   2019 ) , and apply dynamic content planning with a   coherence - based contrastive objective to improve   output coherence .   Controllable Text Generation . Our work is   closely related to controllable generation ( Prabhu-   moye et al . , 2020 ) . In this regard , typical studies   manipulate sentiments ( Hu et al . , 2017 ) , style ( Gao   et al . , 2019 ; Du and Ji , 2021 ; Hu et al . , 2021 ) , syn - tax ( Chen et al . , 2019 ) , and keywords ( Keskar et al . ,   2019 ; He et al . , 2020 ; Wu et al . , 2020 ) to steer the   generation process . We use topical keyphrases as   guidance talking points and require the model to   properly organize and reflect keyphrases for long-   form opinion text generation .   3 Our PLANET Framework   3.1 Framework Overview   Task Description . We follow the previous   work ( Hua and Wang , 2020 ) and model the long-   form opinion generation task by considering the in-   put of ( 1 ) a statement xwhich can be a proposition   for argument generation or a title for opinion - article   generation , and ( 2 ) a set of unordered keyphrases   m={m}related to the statement , serving as   topical guidance signal . The output yis an opinion   text consisting of multiple sentences and properly   reflects the keyphrases in a coherent way .   Our framework is based on the seq2seq structure ,   and we adopt BART ( Lewis et al . , 2020 ) as the   base model . The overall framework is shown in   Figure 3 . The bi - directional encoder first encodes   the statement and keyphrases , and the decoder then   generates the output in an autoregressive manner :   where nis the number of target words . The state-   ment and keyphrases are concatenated , with a seg-   menter inserted between adjacent keyphrases to   indicate the keyphrase boundary .   We conduct content planning and surface realiza-   tion dynamically by leveraging the autoregressive   self - attention mechanism . For each target sentence ,   we introduce a latent representation SNto represent   its global semantic information and guide surface   realization ( § 3.2 ) , then the sentence words attend   the latent representation and dynamically select   keyphrases ( § 3.3 ) . After that , a sentence - level   bag - of - words planning is introduced to enhance   the latent representations ( § 3.4 ) . Finally , we de-   vise a contrastive learning ( CL ) objective to further   improve the coherence of the output text ( § 3.5 ) .   3.2 Latent Representation Learning   We introduce a latent representation for each target   sentence to represent the overall semantic informa-   tion and guide the generation of the sentence words.2290   In particular , we insert a special token [ SN ] before   every target sentence , and regard the hidden states   of the decoder at the positions corresponding to   [ SN ] as the latent representations of the target sen-   tences . This has been shown effective by previous   work ( Guan et al . , 2021 ; Li et al . , 2021 ) .   The workflow of our dynamic planning and re-   alization is shown in Figure 4 . For the vanilla au-   toregressive decoder , the generation of each token   only depends on the previously generated tokens .   In our framework , when producing the j - th output   sentence y , the latent representation SNis first   obtained by attending the previous latent represen-   tations SNand words in previous sentences   y. Then for sentence - level surface realiza-   tion , each token in the current sentence yattends   the previously generated words and latent represen-   tations SN , as well as the current latent rep-   resentation SNas the guidance . A unique advan-   tage of such modeling is that the content planning   and surface realization can be performed simul - taneously and incorporated into any pre - trained   autoregressive language models , further optimized   in an end - to - end fashion .   3.3 Content Selection   Based on the guidance of latent representations ,   each sentence word conducts content selection   by incorporating keyphrases into decoder hidden   states to decide which keyphrases to be reflected   during generation . We first feed the keyphrases   to the encoder to obtain hidden representations .   We then construct a keyphrase memory bank B   by gathering the top layer representations of the   segment tokens ( each keyphrase is represented by   the segment token before it ) . After that , a con-   tent selection layer retrieves keyphrase information   from the keyphrase bank and integrates the selected   information into the decoding process .   Content Selection Layer . At each decoding step   t , the top layer representation of the Transformer   decoder hattends the keyphrase memory bank via   multi - head attention :   where cis a context vector that embeds the se-   lected keyphrase information , his the query , and   Bacts as the key and value for multi - head attention .   Then we incorporate the keyphrase context cinto   the decoder hidden state via a feed - forward layer   followed by a residual connection ( RC):2291Finally , the enhanced hidden state hwill be   passed to another feed - forward layer with softmax   to estimate the probability of each output word :   where Wandbare trainable parameters .   3.4 Sentence - level Bag - of - words Planning   We propose an auxiliary task of sentence - level bag-   of - words ( BOW ) planning to supervise the latent   representations . The goal is to ground the mean-   ing of the latent representations with the bag - of-   words ( Fu et al . , 2020 ) of target sentences to reflect   the global semantic plans . Formally , we define the   BOW of the j - th target sentence zas a categorical   distribution over the entire vocabulary :   where MLP(∗)is parameterized as a multi - layer   feed - forward network . We expect this distribution   to capture the overall semantic plan of the corre-   sponding sentence , and enhance SNto guide the   surface realization of sentence words by condition-   ing the probability of each word on the latent rep-   resentations : p(y|y , SN ) , where sde-   notes the sentence index of the token y. This con-   ditional probability can be naturally satisfied by the   autoregressive decoding process .   The loss of the task is to maximize the likelihood   of predicting the BOW of each target sentence :   where Jis the number of target sentence , and   p(z|SN)denotes the estimated probability of the   l - th element in the bag of words for the j - th target   sentence .   3.5 Coherence - based Contrastive Learning   We further design a contrastive learning ( CL)-based   training objective to enhance the content planning   and drive our model to learn a preference of coher-   ent outputs over incoherent ones .   Negative Sample Construction . One challenge   for contrastive learning is how to construct nega-   tive samples to effectively train the model towards   the desired goals . We consider the original target   as a positive sample representing a logically co-   herent output with gold planning , and construct   negative samples as incoherent ones . In particular , for a positive target , we create 4 negative samples   based on the following strategies : ( 1 ) SHUFFLE ,   where we randomly shuffle the target sentences to   encourage the model to learn the correct sentence   order ; ( 2 ) REPLACE , where we randomly replace   50 % of the original target sentences with random   sentences from the corpus to facilitate the model   to learn better content organization ; ( 3 ) DIFFER-   ENT , where we completely replace the original   target sentences with a new set that are annotated   as the target of a different input from the corpus ; ( 4 )   MASK , where we randomly mask 20 % of the non-   stop target words that are related to any keyphrases   from the keyphrase set , and adopt BART to fill the   masked tokens since BART is naturally a denoising   model . We enforce the filled negative target to be   different from the original one .   Coherence - based Contrastive Loss . Since we   aim to encourage the model to distinguish be-   tween coherent and incoherent targets and generate   outputs with coherent logical flows , we design a   novel coherence - based contrastive learning objec-   tive . Given a source - target pair , the model projects   the output feature from the content selection layer   to a coherence score between 0 and 1 . Formally ,   for the i - th source - target pair , we enforce the score   of the original target ( r ) to be larger than all cor-   responding negatives ( { r } ) by a fixed margin ϕ :   where F(∗)is a nonlinear transformation with sig-   moid , HandHare output features from the   content selection layer for the positive and the k - th   negative sample , and AvgPool ( ∗)is the average   pooling to compute a fixed - size vector . In this way ,   we expect the model to assign higher probability to   the coherent target than incoherent ones .   3.6 Training Objective   We jointly optimize our model for content planning   and surface realization by combining the objectives   for the sentence - level BOW planning ( L ) , the   word - level generation by cross - entropy loss over   the target tokens ( L ) , and the contrastive learn-   ing loss ( L):L = L+αL+βL ,   where αandβare tuned as hyper - parameters.2292   4 Experimental Setups   4.1 Tasks and Datasets   We conduct experiments on two long - form opin-   ion generation datasets of distinct domains : ( 1 )   Argument Generation ( ArgGen ) ( Hua et al . , 2019 ) ,   where the model is required to generate a counter-   argument to refute a given proposition ; ( 2 ) Opinion   Article Generation ( OpinionGen ) ( Hua and Wang ,   2020 ) , to produce an opinion article given a title .   The data statistics are shown in Table 1 .   Argument Generation . We first apply data from   Reddit r / ChangeMyView ( CMV ) for argument gen-   eration . We consider the original poster ( OP ) ti-   tle as the statement , and the high - quality argu-   ment replies ( with community endorsement ) as   the targets . Note that we consider the full argu-   ment replies as targets . The noun phrases and verb   phrases that contain at least one topic signature   word ( Lin and Hovy , 2000 ) are extracted to form   the guidance keyphrases .   Opinion Article Generation . For generating   opinion articles , we consider samples from the   New York Times ( NYT ) corpus ( Sandhaus , 2008 ) ,   with articles whose taxonomy labels include   Top / Opinion . The articles with less than three sen-   tences or more than 10 sentences are discarded .   We further exclude articles containing more than   250 tokens considering the limited computing re-   sources . 57,600 articles are randomly selected as   the final dataset . We apply the same method as   in argument generation to extract topical guidance   keyphrases . The article title is regarded as the input   statement .   4.2 Baselines and Comparisons   We compare our model against the following base-   lines : ( 1 ) R ( Stab et al . , 2018 ) which   retrieves targets based on TF - IDF weights of words   from the training set . We keep the top - ranked re-   sults as outputs ; ( 2 ) HP ( Hua et al . , 2019 )   which is an end - to - end trained generation model   with a hierarchical decoder to perform sentence - level content planning and surface generation ; ( 3 )   FS2 ( Schiller et al . , 2021 ) where we   fine - tune BART with keyphrases concatenated to   the input statements ; ( 4 ) SSP ( Kang and   Hovy , 2020 ) is a global planning method which   first conducts content prediction and then guides   the surface generation with the predicted contents ;   ( 5)SP is a two - stage planning model simi-   lar to Hua and Wang ( 2020 ) , where we first fine-   tune a BART as the planner to generate the or-   dered keyphrase plans for each target sentence , and   then fine - tune another BART as the generator to   produce final outputs based on the statement and   keyphrase plans . The details of SP are in   the Appendix A.2 .   4.3 Training and Decoding Details   We use the BART - base version in all experiments   for both our method and baselines . We truncate   both input statement and output target to at most   256 tokens during training . For the BOW planning   loss ( L ) , we consider the salient content words   as the ground - truth bag of words for each target sen-   tence . For the training objective , we set αas 0.2 for   ArgGen and 0.3 for OpinionGen , and βas 0.2 based   on the validation performance . The margin for con-   trastive loss is set as 0.5 for ArgGen and Opinion-   Gen according to the validation performance . We   optimize our model with AdamW ( Loshchilov and   Hutter , 2017 ) . During the decoding time , we apply   nucleus sampling ( Holtzman et al . , 2019 ) with a   cumulative probability threshold of 0.9 , and the   maximum of generation steps are 150 for ArgGen   and 200 OpinionGen . More training and decoding   details are in the Appendix A.2 .   5 Results and Analysis   5.1 Automatic Results   We first evaluate our model with BLEU ( Pap-   ineni et al . , 2002 ) , ROUGE ( Lin , 2004 ) , and ME-   TEOR ( Denkowski and Lavie , 2014 ) . The results   are shown in Table 2 .   OurPLANET model ( without contrastive   loss ) consistently outperforms all baseline meth-   ods . In particular , compared with FS2   andSSP which are also fine - tuned based   on BART with the same inputs , the substantial   improvements underscore the effectiveness of our   dynamic content planning to generate better out-   puts . Meanwhile , the significant lead over H-   P indicates the importance of incorporating2293   content planning into pre - trained language mod-   els . Furthermore , PLANET significantly out-   performs SP , which confirms that the end-   to - end training in our approach can mitigate the   disconnection issue of the two - stage generation   pipeline and produce superior results .   Among our model variants , removing content se-   lection ( w/o SEL . ) and BOW planning ( w/o BOW )   both lead to performance decrease . This demon-   strates the importance of the components that help   the model conduct effective content planning . In   addition , we observe that incorporating the con-   trastive loss ( PLANET ) brings performance gains   on automatic results , especially with significant im-   provements on BLEU scores . This suggests that   our contrastive loss can guide the model to more   precisely use keyphrases and reflect the keyphrase   information in the outputs . We provide further anal-   ysis on the keyphrase usage in Section 5.2 .   Content Richness . To evaluate content richness ,   we employ Distinct n - gram ( Li et al . , 2016 ) that   calculates the number of distinct n - grams per out-   put in Figure 5 . R achieves the highest   distinct results on both datasets since it returns top-   ranked human - written texts with the most distinct   words . Among generative methods , our dynamic   planning model PLANET outperforms all   baselines on both datasets . In addition , after apply-   ing contrastive loss , our PLANET model gener-   ates even more unique n - grams . The results imply   our dynamic content planning and contrastive loss   can enable the model to generate richer contents .   Automatic Evaluation on Coherence . We fine-   tune BERT ( Devlin et al . , 2019 ) on each dataset to   automatically evaluate the output coherence , which   predicts a score between 0 and 1 for each output .   The higher score indicates a more coherent output .   The coherence model details are in Appendix A.3 .   The results are shown in Figure 6 . Among all   methods , PLANET achieves the highest coherence   scores on both datasets , suggesting that our dy-   namic planning and contrastive loss are effective   to improve the coherence of outputs . In contrast ,   SP has the lowest scores , indicating that de-   coupling planning and decoding stages may lead   to cascading errors . Compared to FS2   andSSP , our PLANET model with-   out contrastive loss also maintains better coherence ,   which confirms that incorporating dynamic content   planning essentially promotes coherence for long   text generation . Moreover , we observe that the re-   sults on OpinionGen are consistently better than2294   those on the ArgGen dataset . A possible reason is   that arguments in ArgGen are collected from social   networks and contain more colloquial and informal   expressions , making it harder to learn the implicit   logical coherence . We leave this for future work .   Ablation on Contrastive Sample Construction .   We study the contribution of each negative sample   construction strategy for improving the coherence   of the outputs . As in Table 3 , removing each strat-   egy leads to a performance degradation , indicating   the effectiveness of all types of negative samples to   enhance the contrastive learning . Among all nega-   tives , removing REPLACE shows the most effects   on both datasets . We hypothesize that replacing tar-   get sentences breaks the original logical flow and   thus is more likely to encourage the model to focus   on the global coherence . In contrast , DIFFERENT   shows the least effects . One possible explanation   is that this strategy focuses more on topical relat-   edness between the input and output , instead of   the logical flow within the output as the negative   sample itself is inherently coherent .   5.2 Human Evaluation   We hire three proficient English speakers as human   judges to evaluate model outputs on a scale of 1   ( worst ) to 5 ( best ) for : ( 1 ) topic relatedness which   measures whether the output is relevant and con-   sistent to the input ; ( 2 ) coherence which measures   the high - level logical flow and transition among   sentences ; and ( 3 ) content richness , measuring the   amount of informative talking points and specific   details . We also ask judges to select top - ranked   results based on the overall quality , and ties are al-   lowed . 50 random samples are selected from each   task . The detailed guidelines of human evaluations   are provided in the Appendix B.   The results are shown in Table 4 . Both our model   variants achieve better results than FS2   on all aspects , underscoring the effectiveness of   our dynamic planning to promote output coherence .   Moreover , introducing contrastive objective further   improves output quality on the above aspects , and   the outputs are more likely to be top - ranked . Over-   all , the human results verify the capability of our   dynamic planning and contrastive objective to gen-   erate high - quality long - form texts .   Appropriateness of Keyphrase Usage . We further   study how keyphrases are utilized in outputs . We   first compute the percentage of keyphrases men-   tioned in outputs , as in the left of Figure 7 . Among   all models , SP uses the least keyphrases   in final outputs . However , its intermediate plan-   ning results cover more than 95 % of keyphrases .   This confirms that the two - stage method results   in a disconnection problem between the planning   module and the surface realization module , and   the outputs are not guaranteed to reflect the plans .   Compared to FS2andSSP , our   methods cover more keyphrases , suggesting that   our dynamic planning and keyphrase selection are   useful to help the model better incorporate the guid-   ance signal into outputs .   We further select 50 random samples for both   tasks and ask the same human judges to score   the outputs from 1 ( worst ) to 5 ( best ) on the cor-   rectness of keyphrase usage : whether the model   uses keyphrases adequately as main talking points   when generating outputs . Results in Figure 7   ( right ) indicate that our models tend to use more   keyphrases and properly organize them in the out-2295   puts compared to all baseline methods . Although   on OpinionGen our contrastive model mentions   fewer keyphrases , human judges rate it with higher   scores for keyphrase usage . We speculate that this   can be attribute to the MASK strategy for negative   sample construction in contrastive learning , which   helps to improve the model ability on the appropri-   ate usage of keyphrases . The above results confirm   thatPLANET can properly utilize the keyphrases   and reflect the contents in the outputs .   5.3 Sample Outputs and Discussions   We show two sample outputs on both tasks and   highlight the phrases relevant to the guidancekeyphrases in Figure 8 . We can see that on both   tasks , our model effectively leverages guidance   keyphrases as main talking points , and properly   organizes and reuses the keyphrases to form a co-   herent output . In contrast , FS2 suffers   from incoherence issues such as repetition ( e.g. , the   first and second argument sentences ) and inconsis-   tent stance ( e.g. , “ choose not to work ” in generated   opinion article ) . This indicates that our dynamic   planning is effective to guide the model to better   leverage keyphrases in the outputs .   We also present the predicted BOW of our model   for each generated sentence . As can be seen , our   model predicts most of the salient content words of   the target sentences and effectively reflects the se-   mantic plans in the generated sentences , suggesting   that our latent representations are useful to capture   the global semantic information of each sentence   and conduct content planning during the generation   process . However , there is still a large gap com-   pared with human written texts , inspiring the future   work on long - form text generation . More sample   outputs are provided in Appendix D.   6 Conclusion   We present a novel generation framework to dy-   namically conduct content planning and surface   realization in large autoregressive Transformers by   leveraging self - attention and high - level latent repre-   sentations . The latent representations are grounded   by bag - of - words that measures the overall semantic   plan of each target sentence . We further introduce   a novel coherence - based contrastive objective with   different negative sample construction strategies to   improve output coherence . Experiment results on   two opinion text generation tasks demonstrate that   our model can generate high - quality outputs with   better coherence and content richness .   Acknowledgements   We thank the anonymous reviewers , area chair , and   senior area chairs for their constructive suggestions   on our work . We also thank Xinyu Hua for the   helpful discussions . Hou Pong Chan was supported   by the Science and Technology Development Fund ,   Macau SAR ( Grant No . 0101/2019 / A2 ) , and the   Multi - year Research Grant from the University of   Macau ( Grant No . MYRG2020 - 00054 - FST ) . Lifu   Huang also thanks the support from the Amazon   Research Awards.2296Ethics Statement   We recognize that our method may generate fabri-   cated and potentially harmful contents due to the   systematic biases of pre - training using heteroge-   neous web corpora and the open - ended genera-   tion characteristics of the opinion generation tasks .   Therefore , we urge the users to carefully examine   the ethical influence of the generated outputs and   cautiously apply the system in real - world applica-   tions .   References229722982299   A Experiment Details   A.1 Additional Experimental Results   In table 2 we report automatic results on both tasks .   Here we present additional automatic results of   BLEU-3 and ROUGLE - L ( recall ) in Table 5 and   Table 6 .   A.2 Training and Decoding Details   Model Training . Our model is built based on   BART , and we use BART -base version for all ex-   periments . Our model contains 185 M parameters   in total . The batch size is set to be 8 , and the maxi-   mum training epoch is set as 15 for non - contrastive   training and 18 for contrastive training . We trun-   cate both the input statement and output target to be   at most 256 tokens during training . We resize the   BART embedding matrix with a new token [ SN ]   and insert a [ SN ] token before each target sentence .   This is also done for baselines for a fair compar-   ison . For computing resources , we use NVIDIA   Tesla V100 GPUs with 32 GB memory for all ex-   periments , and utilize the mixed - precision ( FP16 )   to improve the computational efficiency . For con-   trastive learning , for each positive target , we con-   struct 4 negatives using the strategies described in   Section 3.5 respectively . The best model check-   point is chosen based on the validation loss . Our   model takes around 4 - 5 hours for training , and 30   minutes for decoding on V100 GPUs .   Decoding . During decoding time , we apply the   nucleus sampling ( Holtzman et al . , 2019 ) , and set   k= 10 andp= 0.9 . Considering the computa-   tional cost , we limit the maximum of generation   steps to 150 for argument generation on ArgGen   and 200 for opinion article generation on Opinion-   Gen. To reduce variance introduced by sampling-   based decoding method , we decode three times and   average the results for automatic evaluations . For   our model , we enforce each target sentence to start   with a [ SN ] token during inference : we pre - define   a list of sentence end markers , and when the model   finishes generating a sentence , we enforce the next   generated token to be [ SN ] , although we find in   most cases the model can automatically generate   [ SN ] . The generation process stops when the model   generates the < EOS > token . In this way , the model   can automatically decide on how many sentences   to be generated , and conduct content planning and   surface realization in a dynamic way .   Evaluation Scripts . We use NLTKto implement   BLEU and METEOR , and the ROUGE_SCORE   packageto implement ROUGE .   Details for SP.We design a two - stage gen-   eration method , SP , as a baseline model by   fine - tuning two independent BART models for con-   tent planning and surface realization respectively ,   similar to Hua and Wang ( 2020 ) . In particular ,   the planner BART takes a statement and unordered   keyphrase as inputs , and autoregressively generates   content plans as a sequence of tokens for every   target sentence , where each content plan is repre-   sented by the ordered keyphrases with the same   order as they appear in the corresponding sentence .   Segmenter is added between sentence plans to in-   dicate the sentence boundary . Then the generator2300BART consumes the concatenation of the state-   ment and content plans to produce the final results .   During training , the ground - truth content plans are   used to train the generator , and during inference the   predicted plans are used . For decoding , we apply   beam search for the planner and nucleus sampling   for the generator . Note that Hua and Wang ( 2020 )   applies BERT as planner in their original paper ,   and we replace BERT with BART as BART gives   better performance in our experiments .   A.3 Training Details for Coherence Model   We propose a neural coherence model to evalu-   ate output coherence . Concretely , we fine - tune   BERT ( Devlin et al . , 2019 ) on each dataset to   compute the coherence scores . Instead of com-   puting the overall coherence scores by measuring   and aggregating the coherence of its adjacent sen-   tence pairs ( Xu et al . , 2019 ) , we fine - tune BERT   on the whole text to better learn the global coher-   ence ( Xing and Carenini , 2021 ) .   For training , we follow Sharma et al . ( 2019 ) and   adopt hinge loss to teach the model to assign higher   scores to coherent targets than incoherent ones . The   score is normalized into [ 0 , 1 ] with sigmoid func-   tion , and the margin is set to be 0.8 . Since each   target usually contains multiple sentences , we in-   sert a separator token [ SEP ] between each adjacent   sentence pair . For data construction , we consider   the original text as a positive sample , and randomly   shuffle sentences to construct negative ones . The   test accuracy is 94.3 % on OpinionGen and 73.0 %   on ArgGen , respectively . This implies that our co-   herence model can be used as a reliable metric to   evaluate the output coherence .   B Details for Human Evaluation   We present 55 random samples on each task for   human evaluation , and the first 5 samples are used   only for calibration . We anonymize the models   and shuffle the outputs to the annotators . We eval-   uate model outputs on the following aspects , and   the detailed guidelines are in Table 8 :   •Relatedness : whether the output is relevant   and consistent to the input ;   •Coherence : whether the overall logical flow   is appropriate and the transitions among sentences   are natural and smooth ;   •Content Richness : whether outputs contain   substantial talking points and convey specific de-   tails ;   •Overall Ranking : this is a general assessment   that whether you think the output ranks top among   all candidates . Ties are allowed , which means you   can choose multiple outputs as top - ranking for a   sample .   To measure agreement among human judges , we   compute Krippendorff ’s αfor each aspects . The   values for all aspects on both datasets are presented   in Table 7 . As can be seen , all values are equal   or larger than 0.34 , indicating a general consensus   among the judges .   C Discussions on Limitations and Future   Directions   Here we discuss the limitations of our work and the   potential directions for future studies . Long - form   text generation is a challenging task which requires   the model to properly select and organize contents ,   and faithfully reflect the plans in surface realiza-   tion , in order to form a coherent output . The results   suggest that our dynamic content planning can ef-   fectively leverage keyphrases and generate more   coherent and richer texts than strong baseline meth-   ods . Nevertheless , there is still a gap compared   with human written outputs . Also , in this paper   we follow previous work to study the keyphrases   guided generation ( Hua and Wang , 2020 ; Rashkin   et al . , 2020 ) , where we assume the availability of   keyphrases as guidance signals . For the scenar-   ios where guided keyphrases are not available in   test time , one can use either retrieval - based meth-   ods ( Hua et al . , 2019 ; Wu et al . , 2020 ) or a separate   knowledge - enhanced generative module to obtain   guided keyphrases . However , this is out of the   scope of this work .   We believe there are several promising direc-   tions to explore in the future . First direction can   be applying our dynamic planning method into pre-   trainning or post - pretrainning stage . One advantage   of our model is that it does not require additional   annotated data ( the keyphrases and BOW labels   can be automatically constructed with off - the - shelf   tools as described in data processing ) . Leveraging2301massive pretraining data would be very helpful to   further improve the model performance on long-   text generation in various domains .   Second , one can study different supervision sig-   nals to train the latent representations . In this work   we apply bag - of - words to ground the latent repre-   sentations , which aims to capture the overall seman-   tic information . Other supervision signals such as   discourse structures and entity usage are also very   important for modeling coherence . Considering   these aspects into planning can further improve the   output coherence . Meanwhile , coherence is a broad   definition including topical relatedness , causal re-   lationship , temporal ordering and discourse struc-   tures ( Li and Jurafsky , 2017 ) . Designing different   supervision signals to tackle specific aspects for   coherence would also be a promising direction .   Third , in this work we consider keyphrases as   guidance signals to control the generation . Fu-   ture work can incorporate different guidance sig-   nals from heterogeneous sources such as structured   knowledge and commonsense information to fur-   ther improve the output quality .   D Additional Sample Outputs   We present additional examples on argument gen-   eration in ArgGen and opinion article generation   in OpinionGen from Figure 9 to Figure 12.2302230323042305