  Yi Cheng , Wenge Liu , Wenjie Li , Jiashuo Wang ,   Ruihui Zhao , Bang Liu , Xiaodan Liang , Yefeng ZhengHong Kong Polytechnic UniversityBaidu Inc. , Beijing , ChinaTencent Jarvis LabRALI & Mila , Université de MontréalSun Yat - sen University   { csycheng,cswjli,csjwang}@comp.polyu.edu.hk ,   { kzllwg,xdliang328}@gmail.com , bang.liu@umontreal.ca ,   { zacharyzhao,yefengzheng}@tencent.com   Abstract   Providing Emotional Support ( ES ) to soothe   people in emotional distress is an essential ca-   pability in social interactions . Most existing   research on building ES conversation systems   only considers single - turn interactions with   users , which is over - simplified . In compari-   son , multi - turn ES conversation systems can   provide ES more effectively , but face several   new technical challenges , including : i ) how to   conduct support strategy planning that could   lead to the best supporting effects ; ii ) how to dy-   namically model the user ’s state . In this paper ,   we propose a novel system named MultiESC   to address these issues . For strategy planning ,   drawing inspiration from the A * search algo-   rithm , we propose lookahead heuristics to esti-   mate the future user feedback after using par-   ticular strategies , which helps to select strate-   gies that can lead to the best long - term effects .   For user state modeling , MultiESC focuses on   capturing users ’ subtle emotional expressions   and understanding their emotion causes . Ex-   tensive experiments show that MultiESC sig-   nificantly outperforms competitive baselines   in both strategy planning and dialogue gen-   eration . Our codes are available at https :   //github.com / lwgkzl / MultiESC .   1 Introduction   Almost every human has experienced emotional   distress , even if not suffering from any mental dis-   orders . Frequently , people deal with the distress   by seeking Emotional Support ( ES ) from social   interactions ( Langford et al . , 1997 ; Greene , 2003 ) .   Nevertheless , ES from family and friends is not al-   ways available ( Webber and Mascari , 2018 ) . With   the potential of providing more people with in - time   support , developing Emotional Support Conversa-   tion ( ESC ) systems has attracted much attention .   However , since early ES datasets are constructedFigure 1 : An example of an emotional support conversa-   tion between the support - seeker ( left ) and the supporter   ( right ) . The support strategies adopted by the supporter   are presented in red italics before the utterances .   by crawling post - response pairs from online fo-   rums , they only contain single - turn conversations   ( Medeiros and Bosse , 2018 ; Sharma et al . , 2020 ) .   Thus , most of the existing research on ESC also   only considers single - turn interactions with the user   ( Medeiros and Bosse , 2018 ; Sharma et al . , 2020 ,   2021 ) , which is over - simplified and has limited   support effects . It was not until recently that Liu   et al . ( 2021 ) released the first large - scale multi - turn   ES dataset , ESC . They also designed an ESC   framework , suggesting the conversation procedures   and support strategies for multi - turn ESC .   Compared to the single - turn scenario , develop-   ing multi - turn ESC systems faces several new chal-   lenges . One significant challenge is support strat-   egy planning . As pointed out in the psychologi-   cal literature , particular procedures and strategies   are indispensable for effective emotional support   ( Greene , 2003 ; Hill , 2009 ) . As in Fig . 1 , the sup-   porter strategically soothes the support - seeker by   first caringly inquiring about the situation , then   resonating with the seeker ’s feelings , and finally   providing suggestions to evoke positive emotions.3014Notably , strategy planning in ESC should be   conducted on a long planning horizon . That is ,   instead of merely considering the dialogue history   or foreseeing the immediate effect after using the   strategy , the system should further look ahead , to   consider how much the adopted strategy would   contribute to reducing the user ’s emotional distress   at a long run . Though some strategies may not   directly provide comfort , they are still essential   for reaching the long - term dialogue goal , such as   greetings at the beginning of the conversation and   inquiring about the user ’s experiences .   Another challenge for multi - turn ESC is how   todynamically model the user ’s state during the   conversation . Prior works on emotion - related dia-   logue tasks mainly detect the user ’s coarse - grained   emotion type to enhance dialogue generation ( Lin   et al . , 2019 ; Majumder et al . , 2020 ; Li et al . , 2020a ) .   However , such practice is not completely appropri-   ate for ESC . The reason is that the user ’s emotion   in ESC almost stays the same type , such as being   sad , throughout the conversation . Instead , it often   changes subtly in terms of emotion intensity . Be-   sides , effective ES requires more than only identify-   ing the user ’s emotion . A thorough understanding   of the user ’s situation is also essential .   In this paper , we propose a multi - turn ESC sys-   tem MultiESC to address the above issues . For   strategy planning , we draw inspiration from the A   search algorithm ( Hart et al . , 1968 ; Pearl , 1985 ) and   its recent application in constrained text generation   ( Lu et al . , 2021 ) , which addressed the challenge   of planning ahead by incorporating heuristic esti-   mation of future cost . In MultiESC , we develop   lookahead heuristics to estimate the expectation of   the future user feedback to help select the strategy   that can lead to the best long - term effect . Con-   cretely , we implement a strategy sequence genera-   tor to produce the probability of the future strategy   sequences , and a user feedback predictor to pre-   dict the feedback after applying the sequence of   strategies . For user state modeling , MultiESC cap-   tures the user ’s subtle emotion expressed in the   context by incorporating external knowledge from   the NRC V AD lexicon ( Mohammad , 2018 ) . More-   over , it identifies the user ’s emotion causes ( i.e. ,   the experiences that caused the depressed emotion )   to more thoroughly understand the user ’s situation .   In summary , our contributions are as follows :   •We propose a multi - turn ESC system , MultiESC ,   which conducts support strategy planning withforesight of the user feedback and dynamically   tracks the user ’s state by capturing the subtle   emotional expressions and the emotion causes .   •It is a pioneer work that adopts A - like looka-   head heuristics to achieve dialogue strategy se-   lection on a long planning horizon .   •Experiments show that MultiESC significantly   outperforms a set of state - of - the - art models   in generation quality and strategy planning ,   demonstrating the effectiveness of our proposed   method .   2 Related Work   Emotional Support Conversation Systems .   Since early ES datasets were mainly composed   of single - turn conversations ( Medeiros and Bosse ,   2018 ; Sharma et al . , 2020 ) , most research on de-   veloping ESC systems only considered the simpli-   fied scenario of single - turn interactions with the   user ( Sharma et al . , 2021 ; Hosseini and Caragea ,   2021 ) . The few works that developed multi - turn   ES chatbots rely on predefined templates and hand-   crafted rules ( Zwaan et al . , 2012 ) , which suffer   from limited generality . It was not until last year   that Liu et al . ( 2021 ) released the first multi - turn   ESC dataset ESC . Following Liu et al . ( 2021 ) ,   Peng et al . ( 2022 ) and Tu et al . ( 2022 ) recently ex-   plored data - driven multi - turn ESC systems . Peng   et al . ( 2022 ) proposed a hierarchical graph network   to capture both the global context and the local user   intention . They did not consider strategy planning ,   which is critical in multi - turn ESC . Tu et al . ( 2022 )   proposed to enhance context encoding with com-   monsense knowledge and use the predicted strategy   distribution to guide response generation . Never-   theless , their method of strategy prediction , directly   implemented with a vanilla Transformer encoder ,   was relatively preliminary and did not consider any   user - feedback - oriented planning as we do .   Empathetic Response Generation . Empathetic   Response Generation ( ERG ) ( Rashkin et al . , 2019 )   is a research area closely related to ESC , as being   empathetic is a crucial ability for providing emo-   tional support ( Greene , 2003 ; Pérez - Rosas et al . ,   2017 ) . However , ERG does not has the explicit   goal of proactively soothing the user ’s negative   emotion . Instead , it only reactively generates re-   sponses that are consistent with the user ’s emotion   ( Lin et al . , 2019 ; Majumder et al . , 2020 ; Li et al . ,   2020a ; Zheng et al . , 2021 ; Wang et al . , 2021).3015   3 Preliminaries   ESConv . Our research is conducted on ESC .   It is a long conversation dataset , with an average of   29.8 utterances in each dialogue . It also includes   rich annotations , such as the strategies adopted by   the supporter and the user feedback scores . There   are overall eight types of strategies ( e.g. , question ,   reflection of feelings andself - disclosure ) . The user   feedback score indicates how much the user ’s emo-   tional distress is reduced during the conversation .   They are marked by the support - seekers on a Likert   scale with five levels after every two turns . More   data statistics are provided in the appendix .   NRC V AD Lexicon . The NRC V AD lexicon in-   cludes the Valence - Arousal - Dominance ( V AD )   scores of 20,000 English words . The V AD score   of a word measures its underlying emotion in   three dimensions : valence ( pleased - displeased ) ,   arousal ( excited - calm ) , and dominance ( dominant-   submissive ) . For example , the V AD scores of “ lone-   liness ” and “ abandon ” are ( 0.15 , 0.18 , 0.22 ) and   ( 0.05 , 0.52 , 0.25 ) , respectively . The V AD model   captures a wide range of emotions and allows dif-   ferent emotions to be comparable .   Problem Formulation of ESC . Denote the utter-   ances from the system and the user at the i - th round   of the conversation are respectively ( x , y),while   the user ’s state is u(i=1 , 2 , ... , n ) . Suppose the   set of all support strategies is S. At the t - th turn ,   given the dialogue history H={(x , y ) } , the   system tracks the user states U={u , u , ... , u }   fromHand generates the next utterance x , using   an appropriate support strategy ˆs∈ S.   4 Methodology   As shown in Fig . 2 , our proposed system Multi-   ESC consists of four modules . The dialogue en-   coder first converts the dialogue history Hinto   the embeddings H. At the same time , the user   state modeling module extracts the user state in-   formation , producing the embeddings U. Then ,   givenHandU , the strategy planning module se-   lects the strategy s. Finally , the utterance decoder   generates the utterance x , adopting the strategy s.   4.1 Dialogue Encoder   The dialogue encoder module is implemented with   a Transformer encoder ( Vaswani et al . , 2017 ) . We   concatenate the utterances in Hand keep the last   Ntokens of the concatenation as its input sequence .   Given the input , it produces the dialogue history   embeddings H∈R.   4.2 User State Modeling   Fig . 3 illustrates the workflow of user state mod-   eling . To identify the user ’s state at the i - th round   of the conversation , we first extract the emotion   cause mentioned at this round , denoted as c , with   an off - the - shelf detectortrained on a large - scale   emotion cause detection dataset ( Poria et al . , 2021 ) .   For example , in Fig . 3 , c=“I have not seen my   friends for a long time ” . Then , we concatenate the   dialogue content x , yand the emotion cause c   with special separator tokens to form the input of a   Transformer encoder . Here , the system ’s utterance   xis also considered because it often provides nec-   essary context for understanding the user ’s state .   The input sequence is represented as the positional   sum of emotion embeddings , word embeddings ,   and positional embeddings .   The emotion embeddings are used to fuse   the emotion information . They are obtained   as follows . We train multiple emotion vectors   { e , e , ... , e}to represent the underlying emo-   tions of different words . Concretely , we split the   V AD space into multiple subspaces by dividing the   valence and the arousal dimensions , respectively ,   intonandnintervals of equal length . Each3016   emotional subspace is represented as one emotion   vector e. To construct the emotion embeddings ,   we retrieve the V AD score of each input token from   the NRC V AD lexicon to identify which emotional   subspace it belongs , and then we represent it as the   corresponding emotion vector . For those tokens   without V AD annotation , we use a special emotion   vector to represent them .   Finally , the encoded hidden vector ucorre-   sponding to the [ CLS ] token is used to represent   the user state at the i - th round . The user state em-   beddings Uis the concatenation of all the user   state embeddings before the t - th round , that is ,   U=[u;u; ... ;u ] .   4.3 Strategy Planning with Lookahead   Heuristics   We develop a strategy score function to evaluate   whether to adopt a particular strategy ( e.g. question   orself - disclosure ) by comprehensively considering   the dialogue history and the potential user feedback .   Formally , at the t - th round , MultiESC adopts the   strategy ˆsthat maximizes the score function :   ˆs= arg maxF(s ) , ( 1 )   where F(·)is the strategy score function .   In the following , we will first introduce the strat-   egy score function and then explain how MultiESC   calculates the strategy scores with two components :   a strategy sequence generator and a user feedback   predictor , as presented in Fig . 4 . Finally , we will   describe the architectures of the two components . Strategy Score Function . Our method draws in-   spiration from the classical search algorithm , A   search ( Hart et al . , 1968 ) , which conducts looka-   head planning in a heuristic way . At each step ,   it searches the highest - scoring path by selecting   an action that maximizes the sum of the score so   far and a heuristic estimation of the future score .   Similarly , we define our strategy score function as :   F(s ) = g(s ) + λ·h(s ) , ( 2 )   where g(s)is ahistory - based score ; h(s)is a   lookahead score that heuristically estimates the   future user feedback ; λis a hyper - parameter that   balances the weights of the two terms .   The history - based score g(s)computes the con-   ditional probability distribution of the next strategy   purely based on the dialogue history and the previ-   ous user states . Formally , it is defined as :   g(s ) = −logPr(s|H , U ) . ( 3 )   Previous research on dialogue strategy predic-   tion generally followed this history - based scheme   ( Zhou et al . , 2019 ; Joshi et al . , 2021 ; Dutt et al . ,   2021 ) , though they may vary in their methods of ob-   taining the representations of HandU. However ,   such practice overlooks the strategy ’s future effects   and how much it could help in achieving the long-   term dialogue goal . In our work , we incorporate   the lookahead score to alleviate this issue .   The lookahead score h(s)heuristically esti-   mates the mathematical expectation of the future   user feedback scoreafter adopting the strategy   sat the t - th round . Ideally , to select the strategy   that could lead to the best final result , we want to3017estimate the user feedback score at the end of the   conversation , that is :   ( 4 )   E ( · ) represents the mathematical expectation ; sis   the future strategy sequence to be used after the t - th   round till the end of the conversation ; Sis the set   of all possible strategy sequences ; f(s , s , U )   denotes the user feedback score after successively   applying sandsto comfort a user whose previ-   ous states are U.   However , Eq . 4 is hard to calculate , because the   space of Sis too large and it is difficult to esti-   mate the user feedback f(·)after too many turns   ( i.e. if the strategy sequence sis too long ) . Thus ,   we approximate Eq . 4 as follows . First , we only   look ahead for the limited Lturns . We estimate the   expectation of the user feedback score after Lturns   instead of at the end of the conversation . Then ,   to further narrow the space of S , we only con-   sider the kmost possible future strategy sequences .   Formally , Eq . 4 is approximated as :   ( 5 )   whereSis the set of the strategy sequences whose   lengths are less than L.   Strategy Score Calculation in MultiESC . Multi-   ESC calculates the strategy scores with a Strategy   Sequence Generator ( SSG ) and a User Feedback   Predictor ( UFP ) . The function of SSG is to sequen-   tially predict sbased on HandU , where sis   the strategy sequence that will be used in the follow-   ingLrounds ( s=[s;s ] ) . At the l - th timestep ,   it outputs the predicted strategy distribution :   Pr(s|s , H , U ) , ( 6 )   where l=1,2 , ... , L andsdenotes the already-   generated strategy sequence before the l - th   timestep . The function of UFP is to estimate the   user feedback score f(s , U ) .   As shown in Fig . 4 , to calculate the strategy   score of a particular strategy s , we first use SSG   to derive the history - based score g(s)from its   predicted strategy distribution at the first timestep . Next , we use SSG to find the set of the kmost pos-   sible future strategy sequences ˆSthrough beam   search . For each strategy sequence sinˆS , we   obtain its probability by :   We then leverage UFP to estimate the user feedback   score after successively applying sands . Com-   bining the predicted probabilities of the strategy   sequences and the estimated user feedback scores ,   we obtain the lookahead score h(s)as in Eq . 5 .   Finally , given g(s)andh(s ) , the overall strategy   score is obtained as in Eq . 2 .   Strategy Sequence Generator . SSG is developed   upon the architecture of the Transformer decoder .   Its only difference from the original Transformer   decoder is that it adopts the multi - source attention   mechanism to selectively attend to the dialogue his-   toryHand the user state information U. Specif-   ically , the strategy sequence sis first fed to a   masked multi - head attention layer , producing the   contextualized strategy sequence representations   P. Then , Pinteracts with HandUrespectively   through cross attention layers as :   ˆH = MH - ATT ( L(P ) , L(H ) , L(H ) ) ,   ˆU = MH - ATT ( L(P ) , L(U ) , L(U ) ) ,   where MH - ATT ( · ) represents the multi - head self-   attention mechanism . An information fusion layer   is utilized to combine them :   µ=ReLU ( W[ˆH;ˆU ] + b ) ,   ˆP=µ·ˆH+ ( 1−µ)·ˆU ,   where Wandbare trainable parameters . Next ,   ˆPis fed to a connected feed - forward network with   residual connections around the sub - layers . We   denote the hidden states produced here as /tildewideP. Fi-   nally , the strategy distribution at the l - th timestep   is predicted as :   Pr(s|s , H , U ) = softmax ( W / tildewideP+b ) ,   where Wandbare trainable parameters . To train   the SSG , we use the negative log - likelihood of the   ground - truth strategy sas its loss function .   User Feedback Predictor . UFP predicts the user   feedback score f(s , U)by first encoding s   with a Transformer encoder , denoted as TRS .   Specifically , we leverage a trainable strategy ma-   trixE∈Rto represent different types3018   of strategies . Given the strategies in s , we con-   catenate their corresponding strategy vectors as the   input of TRS , so we have   B = TRS[Emb([CLS ] ; s ) ] ,   where Emb ( · ) represents the operation of the em-   bedding layer that maps the strategies in sto   their corresponding vectors in E. Suppose the   encoded hidden state corresponding to the [ CLS ]   token is q. Next , we pass the user state embed-   dings through a Long - Short Term Memory ( LSTM )   network ( Cheng et al . , 2016 ):   ˆU = LSTM ( u , u , ... , u ) ,   We then use qto attend to the hidden states   ˆU=[ˆu,ˆu , ... , ˆu ] through an attention layer :   /tildewideu=/summationdisplayaˆu ,   a = exp(ˆuWq)/summationtextexp(ˆuWq ) ,   where Wis a trainable matrix . Finally , we obtain   the predicted user feedback score by passing /tildewideu   through a single feedforward layer .   We leverage the ground - truth user feedback   scores annotated in the ESC dataset as super-   vision to train the UFP , and use the Mean Squared   Error ( MSE ) as its loss function L.   4.4 Utterance Decoder   Given the user state embeddings U , the dialogue   history embeddings H , and the selected strategy   ˆ s , the utterance decoder aims to produce the next   utterance x. Its architecture is the same as that   of the strategy sequence generator ( § 4.3 ) , except   for the input sequence . To guide dialogue genera-   tion with the selected strategy ˆ s , we prepend thestrategy embedding of ˆ sbefore the embeddings of   the utterance sequence as the input of the utterance   decoder . The negative likelihood of the ground-   truth token in the target utterance is used as the   generation loss L. More details on the training   procedure are provided in the appendix .   5 Experiments   5.1 Experimental Setup   Baselines . Our baselines include three empathetic   response generators : MoEL ( Lin et al . , 2019 ) ,   MIME ( Majumder et al . , 2020 ) , and EmpDG   ( Li et al . , 2020a ) ; and four state - of - the - art meth-   ods on the ESC dataset : DialoGPT - Joint ,   BlenderBot - Joint ( Liu et al . , 2021 ) , MISC ( Tu   et al . , 2022 ) , and GLHG ( Peng et al . , 2022 ) . More   details about them are described in the appendix .   Implementation Details . We follow the original   division of ESC for training , validation , and   testing . We initialize the parameters of the dialogue   encoder and the utterance decoder of MultiESC   with the BART - small ( Lewis et al . , 2020 ) model   from the HuggingFace library ( Wolf et al . , 2019 ) .   There are n=65types of emotion vectors , with   n = n=8 . In the strategy planning module , we   setλ=0.7 and L=2 . The beam size kis set to be 6   when searching the set of the most possible strat-   egy sequences ˆS. Since the codes of MISC and   GLHG were not released , we directly refer to the re-   sults reported in their original papers . For the other   baselines , we use their released codes to conduct   our experiments . Our model has 145.6 M param-   eters , which is in the same order as the baselines .   For reference , BlenderBot - Joint , DialoGPT - Joint ,   and GLHG have 90 M , 117 M , and 92 M parame-   ters , respectively . More implementation details are   provided in the appendix.3019   5.2 Automatic Evaluation of Generation   Quality   To evaluate the generation quality , we adopt the fol-   lowing metrics : perplexity ( PPL ) , BLEU-1/2/3/4   ( B-1/2/3/4 ) ( Papineni et al . , 2002 ) , ROUGE - L ( R-   L ) ( Lin , 2004 ) , METEOR ( MET ) ( Lavie and Agar-   wal , 2007 ) , and CIDEr ( Vedantam et al . , 2015 ) .   Comparison with Baselines . As shown in the up-   per part of Table 1 , MultiESC performs signifi-   cantly better than the baseline models in all the met-   rics . It performs exceptionally well in the CIDEr   metric , which measures the similarity between TF-   IDF weighted n - grams ( i.e. , the words that fre-   quently appear in many utterances contribute less to   the score ) . This result demonstrates that MultiESC   is more capable of including critical information   in the responses , catering to particular situations   of users . Another finding is that the three empa-   thetic generators ( i.e. , MoEL , MIME , and EmpDG )   achieve significantly worse perplexity and CIDEr   scores than the other models . Through analysis ,   we find that they tend to include content that com-   monly appears in many samples ( e.g. , “ I ’m sorry   to hear that ” , “ I can understand that ” ) . This is prob-   ably because they only focus on how to generate   responses that can display an understanding of the   user ’s emotion , which is insufficient for ESC .   Ablation Study . To analyze the effects of differ-   ent components on the downstream generation , we   compare MultiESC with its following variants : ( 1 )   w / oemotion does not incorporate the emotion em-   bedding layer in the user state modeling module ;   ( 2)w / ocause does not incorporate emotion cause   extraction for user state modeling ; ( 3 ) w / ostrategy   directly generates utterances without first predict-   ing the used strategy ; ( 4 ) w / olookahead conducts   strategy planning without the lookahead heuristics   to estimate the future user feedback scores .   As shown in the lower part of Table 1 , the ab-   lation of any component can cause a drop in the   automatic evaluation results , demonstrating the in-   dispensability of each part . In comparison , the ab-   lation of the emotion embedding layer ( “ w / oemo-   tion ” ) leads to the most significant performance   drop , as understanding the user ’s emotional states   plays the most central role in ESC . The difference   between the automatic evaluation results of the full   model and “ w / olookahead ” is relatively small . It   is because they would generate exactly the same re-   sponses if they select the same strategy . The effects   of lookahead planning heuristics are more evident   in the human interactive test , since the adoption of   different strategies at one turn would trigger differ-   ent responses from the user and lead to different   dialogue directions in the future rounds .   5.3 Human Interactive Evaluation   We recruit four graduate students with linguistic   or psychological background as annotators to chat   with the models for human interactive evaluation .   We randomly sample 128 dialogues from the test   set of ESC . The annotators are asked to act   as the support seekers in these dialogue samples3020   by learning their situations and simulating their   process of seeking emotional support by chatting   with the models . Given MultiESC and a compared   model , the annotators are asked to choose which   one performs better ( or select tie ) in terms of the   following metrics , following Liu et al . ( 2021 ): ( 1 )   Fluency : which model generates more fluent and   understandable responses ; ( 2 ) Empathy : which   model has more appropriate emotion reactions ,   such as warmth , compassion and concern ; ( 3 ) Iden-   tification : which model explores the user ’s situa-   tion more effectively to identify the problem ; ( 4 )   Suggestion : which model offers more helpful sug-   gestions ; ( 5 ) Overall : which model provides more   effective emotional support overall .   As shown in Table 2 , we can see that the ad-   vantage of MultiESC over MoEL is substantial in   all the metrics . It also outperforms BlenderBot-   Joint in the overall supporting effects , though rela-   tively inferior in terms of fluency , probably because   the backbone of BlenderBot - Joint is extensively   pre - trained on large - scale dialogue corpora ( Roller   et al . , 2021 ) . Compared with “ w / ostrategy ” , Multi-   ESC is able to show more empathy , more clearly   inquire about the user ’s situation , and provide more   specific suggestions , demonstrating the importance   of explicit strategy planning in ESC . Comparing   MultiESC with “ w / olookahead ” , we can see that   the incorporation of lookahead heuristics brings   significant improvement in the dimensions of iden-   tification andsuggestion .   5.4 Analysis of Strategy Planning   We evaluate the strategy planning module individ-   ually , using the following metrics : Accuracy , the   proportion of prediction results that are the same as   the ground - truth labels ; Weighted F1 , the weighted   average of F1 scores in different classes while con-   sidering the class imbalance ; Feedback , the next   user feedback score that would be given after the   predicted strategy is adopted , simulated with an   user feedback predictor as illustrated in § 4.3 .   Comparison with Baselines . We compare Multi-   ESC with the three baselinses capable of strategy   planning ( i.e. , DialoGPT - Joint , BlenderBot - Joint ,   and MISC ) . The results are shown in Table 3 . We   can see that MultiESC performs the best in all the   metrics with an absolute improvement of 10.4 %   and 4.45 % in accuracy and weighted F1 , respec-   tively . As shown in Fig . 5 , MultiESC also sur-   passes the baselines in all the top- naccuracy .   Analysis of MultiESC Variants . We analyze the   following variants of our strategy planning method :   ( 1)MultiESC : the model with different beam   sizes when searching the set of kmost possible   strategy sequences ˆS ; ( 2 ) w / olookahead : the   model without the lookahead heuristics . As shown   in Table 4 , the strategy planning performance   steadily improves with the increase of the beam   search size when k≤6 , as the larger beam size   can result in a more precise estimation of the future   user feedback . Nevertheless , further increasing kto   consider more strategy sequences of low probabili-   ties does not continue improving the performance   apparently when k>6 . Our full model also sig-   nificantly outperforms “ w / olookahead ” in all the   metrics , especially regarding the feedback score .   It demonstrates that our lookahead heuristics can   help the model better plan the conversation and   provide more effective emotional support .   5.5 Case Study   Table 5 presents a case study of the responses gen-   erated by different models . We can see that the   utterances from MultiESC and its two variants are3021more consistent with the context and more empa-   thetic than those of the two baseline models . Fur-   ther comparing MultiESC and its two variants , the   utterance from the “ w / ostrategy ” seems general   and less engaging . The responses generated by   MutiESC and “ w / olookahead ” are both of high   quality . Nevertheless , with the incorporation of the   lookahead heuristic , MultiESC tends to proactively   explore the user ’s situation at the beginning stage   of the conversation instead of directly comforting   the user , which aligns with the suggested procedure   for providing emotional support ( Hill , 2009 ) .   6 Conclusion   In this paper , we explored the task of developing   multi - turn Emotional Support Conversation ( ESC )   systems , with focus on how to strategically plan the   conversation procedure . To this end , we proposed   a novel ESC system , MultiESC , that conducts strat-   egy planning with lookahead heuristics to estimate   the long - term effect of the adopted strategy on the   user . Moreover , we also proposed some effective   mechanisms to dynamically model the user ’s state   in multi - turn ESCs . The empirical results showed   that MultiESC achieves significant improvement   compared with a set of strong baselines in both   generation quality and strategy planning .   Limitations   Though our proposed method exhibits large im-   provement compared with the existing baselines ,   we believe that the research on emotional support   chatbots still has a long way to go . Compared   with the human supporters , the utterances gener-   ated by the chatbots are usually general and repeti-   tive , unable to show a personalized , in - depth under-   standing of the user ’s experiences or provide very   specific and constructive suggestions on how to   change the situation . This issue might be alleviated   through the incorporation of commonsense knowl-   edge , which will be included in our future research   direction . Other issues , such as how to construct   more trustworthy and safe emotional support chat-   bots , also require much further exploration .   Ethical Considerations   It needs to be clarified that the term “ emotional   support ” in our paper mainly refers to peer support ,   like the one we can seek from family and friends   in daily conversation . We do not claim to constructchatbots that can provide professional psycho-   counseling or psychological treatment . Still , it   needs particular caution when using such systems ,   and considerable further efforts are required to   construct safer ESC systems . For example , crisis-   warning mechanisms to detect users who have ten-   dencies of self - harming or suicide are desirable .   Our experimental dataset , ESConv , is a well-   established , publicly - available benchmark . It has   filtered the sensitive and private information during   the dataset construction . The participants in our hu-   man evaluation were transparently informed of our   research intent and were paid reasonable wages .   Acknowledgments   This work was supported by the Research   Grants Council of Hong Kong ( PolyU/5204018 ,   PolyU/15207920 , PolyU/15207122 ) and National   Natural Science Foundation of China ( 62076212 ) .   It was also supported in part by in part by Na-   tional Key R&D Program of China under Grant   No . 2020AAA0109700 , the Canada CIFAR AI   Chair Program , and the NSERC Discovery Grant   RGPIN-2021 - 03115 . We also thank Jian Wang and   Yueyuan Li for their helpful comments .   References302230233024Appendix   A. Training Procedure   For training of the strategy sequence generator , we   use the negative log - likelihood of the ground - truth   strategy sas its loss function L. For the utter-   ance decoder , the negative likelihood of the ground-   truth token in the target utterance is used as the gen-   eration loss L. The strategy sequence generator   and the utterance decoder are trained jointly , with   the total loss as L = L+L. For training of the   user feedback predictor , we use the Mean Squared   Error ( MSE ) as its loss function L. Since the   user feedback scores in the ESC dataset are   mainly between 2 - 5 , we augment the training data   by randomly generating 5,000 strategy sequences   and regarding them as samples with the score 1 . It   is trained independently from the strategy predictor   and the utterance decoder .   B. Baselines   MoEL ( Lin et al . , 2019 ) adopts several decoders   focusing on different types of emotional utterances ,   whose outputs are combined to generate the final   utterances .   MIME ( Majumder et al . , 2020 ) follows the archi-   tecture of MoEL and adds extra mechanisms to   combine the results from different decoders .   EmpDG ( Li et al . , 2020a ) learns how to generate   responses consistent with the user ’s emotion via an   adversarial learning framework .   DialoGPT - Joint andBlenderBot - Joint ( Liu et al . ,   2021 ) are developed on the backbones of DialoGPT   ( Zhang et al . , 2020 ) and BlenderBot ( Roller et al . ,   2021 ) , respectively . They prepend a special token ,   denoting the predicted support strategy , before the   generated utterance to generate content conditioned   on a predicted strategy .   MISC ( Tu et al . , 2022 ) enhances context encoding   with commonsense knowledge and uses the pre-   dicted strategy distribution to guide the emotional   support dialogue generation . It predicts the strategy   distribution using a vanilla Transformer encoder .   GLHG ( Peng et al . , 2022 ) adopts a graph neural   network to model the relationships between the   user ’s emotion causes , intentions and the dialogue   history for emotional support dialogue generation .   C. Implementation Details   We initialize the parameters of the dialogue en-   coder and the utterance decoder of MultiESC with   the BART - small ( Lewis et al . , 2020 ) model fromthe HuggingFace library ( Wolf et al . , 2019 ) . The   maximum length of the input sequence for the di-   alogue encoder is N=512 . The dimensions of all   the hidden embeddings are d=768 . There are   n=65types of emotion vectors , with n = n=8 .   In the strategy planning module , we set λ=0.7 ,   which results in the best performance on the val-   idation set among λ∈{0.1 , 0.2 , ... , 1.0 } . For the   number of lookahead rounds L , we experiment   withL∈{1 , 2 , .. , 5 } . We find that the performance   on the validation set is the best when L=2 and   L=3 . The performances when L=2 and L=3   are very close , but considering the computation ef-   ficiency , we set L=2 in the following experiments .   For the searching beam size k , we experiment with   k∈{1 , 2 , .. , 10 } , and finally set it to be 6 , because   it strikes the best balance between performance and   efficiency . We choose the above hyperparameters   by manual tuning , and the selection criterion is the   strategy prediction accuracy on the validation set .   AdamW ( Loshchilov and Hutter , 2018 ) is used   as optimizer ; its initial learning rate is set to be   5×10and adaptively decays during training .   The batch size is set to be 32 . Since the codes   of MISC and GLHG were not released , we directly   refer to the results reported in their original papers .   For the other baselines , we use their released codes   to conduct our experiments . Each model is trained   up to 10 epochs , and the checkpoints that achieve   the best perplexity on the validation set are used   for evaluation .   Our model has 145.6 M parameters . The hard-   ware we used was one GPU of NVIDIA Tesla V100 .   The overall training time is about two hours .   D. Dataset   Our experiments are conducted on the ESC   dataset ( Liu et al . , 2021 ) . It is an English dataset .   To construct the dataset , they recruited crowd-   workers , who had learned the common procedures   and strategies for providing emotional support ,   to converse with volunteers that needed emotion   support through an online platform . The crowd-   workers were required to annotate the strategy   adopted at each turn , and the support - seekers were   asked to give feedback every two rounds on a Lik-   ert scale with five levels , indicating how much their   emotional distress is reduced . The dataset contains   1,300 long dialogues with 38,350 utterances . There3025   is an average of 29.5 utterances per dialogue and   an average 16.7 tokens per utterance . We follow   the original division of the ESC dataset for   training , validation , and testing , with the ration of   8:1:1 . There are overall 8 types of support strate-   gies . Referring to Liu et al . ( 2021 ) , their original   definitions are as follows :   •Question : ask for information related to the prob-   lem to help the help - seeker articulate the issues   that they face .   •Restatement or Paraphrasing : a simple , more   concise rephrasing of the support - seeker ’s state-   ments that could help them see their situation   more clearly .   •Reflection of Feelings : describe the help - seeker ’s   feelings to show the understanding and empathy .   •Self - disclosure : share similar experiences or   emotions that the supporter has also experienced   to express your empathy .   •Affirmation and Reassurance : affirm the support-   seeker ’s ideas , capabilities , and strengths to give   reassurance and encouragement .   •Providing Suggestions : provide suggestions   about how to change the current situation .   •Information : provide useful information to the   help - seeker , for example with data , facts , opin-   ions , resources , or by answering questions .   •Others : other support strategies that do not fall   into the above categories .   In our experiments , we make some adaptions to   the strategy annotation . On one hand , we find that   the definition of Providing Suggestions andInfor-   mation are often hard to differentiate . As shown   in Table 7 , some responses annotated as Provid-   ing Suggestions can also be regarded as providing   useful information , and those labelled as Informa-   tionalso offer suggestions . Thus , we merge these   two categories into one type of strategy , named as   “ Providing Suggestions or Information ” .   On the other hand , we find that the existence of   the “ Others ” category largely impedes the model   performance . As illustrated in the above definition ,   some responses in this category are exchange of   pleasantries , which is the case for approximately   50 % of the responses annotated as Others . We   argue that the exchange of pleasantries is also   an essential strategy , as it can help to establish   a friendly connection with the user ( Miller and   Rollnick , 2012 ) . Thus , we define a new strategy   category , named as “ Greetings ” for such kind of re-   sponses . We obtain the annotation of them by first   using a set of regular expression matches and then   manually double - checking the results . For the rest   of responses labelled as Others , we directly regard   them as unlabelled data and do not include them   in the training of the strategy planning module , be-   cause we find that many of them can actually be   classified as the other types of strategies but were   mislabelled , and this strategy are not helpful in   enhancing the response generation . The strategy   distribution after the above adaptions is presented   in Table 6.3026