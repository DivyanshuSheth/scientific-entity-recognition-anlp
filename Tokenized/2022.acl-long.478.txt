  Bhushan Kotnis , Kiril Gashteovski , Daniel Oñoro - Rubio ,   Ammar Shaker , Vanesa Rodriguez - Tembras , Makoto Takamoto ,   Mathias Niepert , Carolin LawrenceNEC Laboratories Europe , Heidelberg , Germany .   firstname.lastname@neclab.euHeidelberg University , Center for Iberoamerican Studies , Germany . University of Stuttgart , Germany   Abstract   Open Information Extraction ( OpenIE ) is the   task of extracting ( subject , predicate , object )   triples from natural language sentences . Cur-   rent OpenIE systems extract all triple slots in-   dependently . In contrast , we explore the hy-   pothesis that it may be beneﬁcial to extract   triple slots iteratively : ﬁrst extract easy slots ,   followed by the difﬁcult ones by conditioning   on the easy slots , and therefore achieve a better   overall extraction .   Based on this hypothesis , we propose a neural   OpenIE system , IE , that operates in an it-   erative fashion . Due to the iterative nature , the   system is also modular — it is possible to seam-   lessly integrate rule based extraction systems   with a neural end - to - end system , thereby al-   lowing rule based systems to supply extraction   slots whichIE can leverage for extracting   the remaining slots . We conﬁrm our hypothe-   sis empirically : IE outperforms SOTA sys-   tems on multiple languages ranging from Chi-   nese to Arabic . Additionally , we are the ﬁrst to   provide an OpenIE test dataset for Arabic and   Galician .   1 Introduction   Open Information Extraction ( OpenIE ) aims to ex-   tract structured facts in the form of ( subject , re-   lation , object ) -triples from natural language sen-   tences ( Etzioni et al . , 2008 ) . For example , given   a sentence , " Barrack Obama became the US Pres-   ident in the year 2008 " , an OpenIE system is   expected to extract the following triples : ( Bar-   rack Obama ; became ; US President ) and ( Barrack   Obama ; became US President in ; 2008 ) . We refer   to subject , predicate and the object of the triple as   slots of a triple . OpenIE extractions are schema-   free , human understandable intermediate represen-   tations of facts in source texts ( Mausam , 2016 ) .   They are useful in a variety of information extrac-   tion end tasks such as summarization ( Xu and Lap-   ata , 2021 ) , question answering ( Khot et al . , 2017;Yan et al . , 2018 ) and automated schema extraction   ( Nimishakavi et al . , 2016 ) .   The various slots of a triple are dependent on   each other and hence an error in one slot renders   the entire extraction unusable . We hypothesize that   triple extraction errors largely stem from the difﬁ-   culty of extracting certain slots of a triple and said   difﬁculty may depend on the sentence construction   and the language . For example , " Barrack Obama   became the US President in the year 2008 " con-   tains two triples ( Barrack Obama ; became ; US   President ) and(Barrack Obama ; became US Presi-   dent in ; 2008 ) . Extracting the predicate , " became   US President in " , for the second triple is tricky ,   because the object of the ﬁrst triple ( US President )   overlaps with the predicate of the second triple .   But if the extraction system was provided with the   object , ( 2008 ) , and then asked to extract a triple   conditioned on this object , the predicate extraction   would be easier .   This is precisely the hypothesis we wish to in-   vestigate — is it easier to extract certain slots of a   triple , say subjects , compared to other slots , such as   objects , and is it possible to improve performance   by leveraging speciﬁc slot extraction orders ?   Given the hypothesis , we proposeIE , aodular & terative multiingual open Information   Extraction system , which iteratively extracts the   different slots of a triple . The iterative nature al-   lows for ( 1 ) studying the effects of a slot extractions   on the remaining extractions , ( 2 ) extracting easier   triple slots followed by harder ones , ( 3 ) aggregat-   ing different slot extraction orders as a mixture of   experts , and ( 4 ) integrating slots supplied by an   external rule - based system , resulting in a hybrid   system . The latter offers a system that combines   the best of neural and rule based systems , e.g. by   using a rule - based system to extract high precision   slots on which the neural system is conditioned .   We empirically conﬁrm our hypothesis : the iter-   ative nature ofIEoutperforms several SOTA6939systems . It proves especially useful for zero - shot   multilingual extraction , which we evaluated on ﬁve   different low resource languages . Additionally we   show howIEcan leverage rule - based slot ex-   traction by conditioning on them to predict the   remaining parts of the triple . ThereforeIEis a   boon for existing applications wishing to transition   from a rule based information extraction system   to a neural one , becauseIEwould allow using   the rule - based system to compensate for the lack   of exhaustive training data . Finally , we perform   linguistic analyses that uncovers useful insights   on how different languages either make it easy or   difﬁcult for OpenIE systems to extract individual   elements of the triple .   Our contributions are summarized as follows :   1.We proposeIE , a multilingual OpenIE   system that iteratively extracts the different   slots of a triple .   2.We carry out extensive experiments on a vari-   ety of languages ( English , Chinese , German ,   Arabic , Galician , Spanish and Portuguese )   and demonstrate thatIEoutperforms re-   cent SOTA systems by a wide margin , espe-   cially on languages other than English .   3.We perform an extensive analysis based on ab-   lation studies and uncover interesting insights   about the nature of OpenIE task in different   languages .   2IE   The backbone of our system is the iterative proce-   dure ( Section 2.1 ) , which allows us to investigate   our hypothesis . The iterative procedure allows us   to extract triple slots in various pathway orders ,   which results in a series of possible aggregation   schemes ( Section 2.2 ) . To create a strong iterative   system , the training paradigm ( Section 2.3 needs   to consider two aspects : ( 1 ) it needs to prepare   incomplete triple extractions which represent in-   complete triple extractions the system is expected   to predict ; ( 2 ) it creates negative samples that allow   for teaching the system when to not continue with   an extraction due to a prior error . With the iterative   nature we also integrate rule - based systems ( Sec-   tion 2.4 ) as well as elegantly handle the speciﬁc   case of n - ary extractions , where more than 3 slots   need to be extracted ( Section 2.5 ) .   2.1 Iterative Prediction   To implement the iterative nature of our system ,   we use a BERT - based transformer ( Devlin et al . ,   2019 ) as the base building block . On top of this   block , we add a total of four neural networks blocks   in parallel , which we refer to as heads and which   are each in charge of extracting a particular triple   slot . Concretely , we have the heads f ; f ; f ; f ,   which are in charge of predicting subject , object ,   predicate and argument , respectively . The argu-   ment head is an extra feature , which is needed for   n - ary extractions that occur in some datasets , where   in addition to the triple there might be an argument   that modiﬁes the triple , e.g. , a temporal phrase .   Given an input sequence of words of length N ,   S = w;;w , the task for each extraction head   is framed as a BIO tagging problem . For this , each   output head outputs a label lfor tokenw , where   l2fB;I;Og ; i= 1N ( see Figure 1 for   the architecture ) . The output heads use the ﬁnal   transformer hidden state and predict labels denoted   byL;L;L;LwhereL = l;l;l .   By having different extraction heads , we iden-   tify extraction slots iteratively . During prediction6940   time , along with the input sentence , the model also   expects extractions predicted by the previous itera-   tions . To provide this information we add special   symbols to the sentence that explicitly mark the   previous extractions in the sentence . For exam-   ple , we surround the predicate with the symbol   < P > , subject with < S > and object with < O > . For   example , for predicting the object given the predi-   cate extracted from previous iteration , the extracted   predicate is marked in the sentence using the < P >   symbol and the sentence is consequently passed   through the transformer for predicting the object   using the object head . We always extract the ar-   guments at the last iteration , therefore we do not   mark the arguments in the sentence .   Finally , we add the option to attach a dependency   tagtto each word win the sequence . This addi-   tional information may allow the system to more   effectively learn how to extract triples . We use a   language speciﬁc dependency tagger for obtaining   the tags . We target languages , which are low re-   source for OpenIE , but could be high resource for   other tasks , such as PoS tagging or dependency   parsing . For a graphical overview of theIE   architecture , see Figure 1.2.2 Aggregating Decoding Pathways   The order in which the different triple parts are   extracted can be varied . This allows us to investi-   gate the challenge of extracting triple elements in   speciﬁc order on different languages . Additionally   different pathways aid different kinds of extrac-   tions and combining them results in a richer set of   extractions . Choosing a particular order deﬁnes a   decoding pathway P as a sequence of output   heads where u;v;x;y2fs;p;o;ag . For example ,   the decoding pathway Pdenotes a sequence of   output functions ( f;f;f;f ) .   Fixing the n - ary argument extraction in the ﬁ-   nal iteration we obtain the following six decoding   pathways - P;P;P;P;P;P.   Let ’s assume the decoding pathway P : pred-   icates are extracted ﬁrst , then for each predicate ,   subjects are extracted , then for each ( predicate , sub-   ject ) pair objects are extracted and ﬁnally for ev-   ery extracted ( predicate , subject , object ) tuple all   the n - ary arguments are extracted . This extraction   procedure preserves the relationships between the   extracted elements resulting in correctly extracting   multiple triples . Figure 2 illustrates this procedure .   We hypothesize that some triples are easier to   predict if , e.g. , the predicate is extracted ﬁrst while   for others subject ﬁrst would work well . This could   differ from triple to triple , but also with different   languages . Consequently , some decoding pathways   might be more error prone than others . This leads   to two questions : ( 1 ) Which pathways are best ? ( 2 )   Can we improve recall by aggregating triples using   different decoding pathways ?   We propose a simple algorithm we term as Wa-   ter Filling ( WF ) for aggregating the extractions .   This is inspired by the power allocation problem   in the communication engineering literature ( Ku-   mar et al . , 2008 ) . Imagine a thirsty person with   access to different pots of water with varying levels   of purity and with the caveat that the amount of   water is inversely proportional to the purity . The   natural solution is to ﬁrst drink the high purity wa-   ter and move on to the pots in decreasing level of   purity until the thirst is quenched . We use the same   idea . Treating each decoding pathways as an ex-   pert , we assume that the triples extracted by all 6   pathways are more accurate compared to those ex-   tracted by only 5 pathways , 4 pathways and so on .   This can be thought of as triples obtaining votes   from experts . Starting with an empty set , for each   sentence we start adding triples to the set in the6941order of decreasing number of received votes . The   normalized votes a triple receives is used as the   conﬁdence value of the triple . Although the proce-   dure is explained in a sequential manner it can be   parallelized by running all 6 pathways in parallel .   2.3 Training   Triple preparation . For effectively extracting   different triple slots conditioned on other slots , the   model needs to see such combinations during train-   ing . However , enumerating all possible combina-   tions exhaustively is prohibitively expensive . We   propose a sampling technique that ensures that the   model sees varied combinations of different targets   and prior extractions . This is done by creating a   training set that simulates a prior extraction and   forces the model to predict the next extraction . To   ensure that the training dataset size does not ex-   plode , we randomly sample one pathway order for   each training instance .   Based on the sampled pathway , we randomly   sample at which step in the decoding process we   are at and then mark the slots prior to this step in   the sentence and use the remaining steps as target   labels . We allow for multiple instances of the target   labels , however there is only one instance of the   marked element . For example , given one subject   the target could be multiple predicates . This proce-   dure trains the model to predict an appropriate label   conditioned on a variety of previous predictions . At   each time step we update the parameters of the cur-   rently used head and the underlying model .   Given that triples are at different steps in their   decoding process , we minimize different log-   likelihood functions . We describe the log likeli-   hood functions along with a few example of the   training instances in Table 1 . We list additional   details in Appendix A.   Negative Sampling . Iterative prediction is prone   to error ampliﬁcation , i.e. if an error is made dur-   ing the ﬁrst iteration then the error propagates and   affects subsequent extractions . Anticipating this ,   we trainIEto recognize extraction errors made   in the previous iteration . We purposely augment   the training data with corrupted data points con-   taining incorrectly marked extractions . For each   of the incorrect extractions the model is trained to   predict a blank extraction , i.e. , predicting the out-   side label for all tokens . We use a similar sampling   procedure as described previously . For every train-   ing data point from a ﬁxed number of training datapoints , we create one negative sample using one   of the three techniques and then choose knegative   samples , where kis a hyperparameter .   We corrupt triples using three techniques : ( 1 )   corrupting the predicates by replacing them with   randomly chosen tokens from the sentence , ( 2 ) cor-   rupting the subject and object by exchanging them ,   and ( 3 ) by mismatching the subject object pairs   from different triples . We detail the entire proce-   dure in Appendix A.   2.4 Integrating Linguistic Rule based systems   Crucially , each output head is conditioned on the in-   put and the output labels extracted by the previous   function . This feature allowsIEto seamlessly   integrate rule based systems with neural systems   since the conditioning can be also done on extrac-   tions obtained from rule based systems . This is   advantageous in situations where a linguistic rule   based system works well , for say , extracting ob-   jects . ThenIEcan complete the missing parts   of the triple conditioned on the objects .   We treat the output of the rule based system as   potential objects paired with subjects and extract   the predicate connecting them . If the rule based ex-   traction is incorrect , thenIEcan detect the error   and extract nothing . This results in more accurate   extractions compared to simply post - processing the   extracted tokens using linguistic rules .   2.5 Binarizing n - ary Extractions   We evaluateIEon both n - ary as well as binary   triple extraction datasets . One simple way to con-   vert the n - ary extractions to binary extraction is to   ignore the n - ary arguments . However , this will lead   to a decrease in recall because the n - ary arguments   may not be part of other extracted triples due to   the initial n - ary extraction . Another method is to   treat the extracted n - ary arguments as objects to   the same subject , predicate pair . This would ensure   that the extracted arguments are not dropped , how-   ever this may result in drop of precision since the   n - ary argument may not attach to the same predi-   cate . For example , consider the extraction ( Barrack   Obama ; became ; US President ; in the year 2008 ) .   Treating n - ary arguments as objects results in ( Bar-   rack Obama ; became ; US President ) and ( Barrack   Obama ; became ; in the year 2008 ) resulting in an   incorrect extraction .   In contrast to the above subpar solutions , the iter-   ative nature ofIEallows us to elegantly address   the problem of converting n - ary extractions into a6942   binary format : we treat the extracted n - ary argu-   ments as hypothesized objects . We then provide the   extracted subject , hypothesized object pair to the   model , which then extracts a new predicate condi-   tioned on the previously extracted subject and the   hypothesized object , i.e. , p(Ljf();S;L=   " Barrack Obama " ; L="year 2008 " ): This cre-   ates a possibility of extracting the correct predicate ,   something that is not possible with existing n - ary   OpenIE systems .   3 Experiments   3.1 Setup   Baselines & Training . We compareIE   with both unsupervised and supervised baselines .   Speciﬁcally we compareIEwith ClausIE ,   MinIE , Stanford - OIE , RNN - OIE , OIE6 ( Del Corro   and Gemulla , 2013 ; Gashteovski et al . , 2017 ;   Stanovsky et al . , 2018 ; Angeli et al . , 2015 ; Kol-   luru et al . , 2020a ) and Multi2OIE ( Ro et al . , 2020 )   on English . Multi2OIE is the only neural system ca-   pable of extracting triples from multiple languages   and therefore it is the only available baseline for   the non - English evaluations .   We use the English RE - OIE2016 ( Zhan and   Zhao , 2020 ) training dataset used in ( Ro et al . ,   2020 ) . This training dataset contains n - ary extrac-   tions allowingIEto be evaluated on both n - ary   as well as binary extraction benchmarks . Evalu - ation on languages other than English is always   zero - shot , i.e. , the model is trained using only the   English Re - OIE2016 dataset and tested on test set   of the other languages .   CaRB benchmark . We use the CRBbench-   mark introduced in ( Bhardwaj et al . , 2019 ) for eval-   uating English OpenIE n - ary extraction . However ,   theCRBbenchmark also suffers from serious   shortcomings due to its evaluation method based   on token overlaps . For example , ( Gashteovski et al . ,   2021 ) discovered that a simple OpenIE system that   breaks the sentence into a triple at the verb bound-   ary achieves 0:70recall and 0:19precision . This   is problematic since it indicates that simply adding   extraneous words to the extraction results in im-   proved recall .   BenchIE benchmark . Due to the issues identi-   ﬁed for CaRB , we also evaluate using BenchIE ,   which is an exhaustive fact based multilingual   OpenIE benchmark proposed by ( Gashteovski   et al . , 2021 ) . BenchIE evaluates explicit bi-   nary extractions in English , Chinese , and German .   BenchIE is accompanied by an annotation tool ,   AnnIE ( Friedrich et al . , 2021 ) , for extending the   benchmark to additional languages . For Arabic , we   translated 100 sentences from BenchIE - English to   Arabic with the help of a native Arabic speaker and   then extracted triples using AnnIE . Similarly for   Galician we translated all 300 sentences to Galician6943   with the help of a native Galician speaker who also   annotated the dataset using AnnIE .   Multilingual CaRB . Additionally we also eval-   uateIEon the Spanish and Portuguese mul-   tilingual CaRB datasets introduced in Ro et al .   ( 2020 ) . The lexical match evaluation used in   this dataset has numerous shortcomings ( Bhard-   waj et al . , 2019 ) , however we include it for a fair   comparison to Ro et al . ( 2020 ) ’s Multi2OIE sys-   tem . The CRBtest set was translated to Spanish   and Portuguese using the Google Translate API . To   investigate the quality of these automatic transla-   tions , we randomly sampled 100 sentences from   the test sets and had them evaluated by native Span-   ish and Portuguese speakers . To our surprise we   discovered that around 70 percent of the sentence   or extraction translations were inaccurate . Table   2 shows a few examples of the incorrect transla-   tions . For an accurate and clean comparison with   Multi2OIE we also cleaned up part of the Spanish   test set by re - translating 149 sentences and their ex-   tractions in Spanish . These translations were done   by native Spanish speakers .   On the CRBEnglish benchmark we use re-   sults for baselines reported in ( Ro et al . , 2020 ) and   ( Kolluru et al . , 2020a ) . For evaluating on BenchIE ,   we run all the baselines on the BenchIE English   evaluation benchmark . For multilingual BenchIEwe train Multi2OIE using the code and hyperpa-   rameters supplied in the paper . For hyperparameter   tuning we use the CRBEnglish validation set and   use the F1 scores obtained using the CRBevalua-   tion procedure for comparing models with different   hyperparameters . TheIEmodel is trained us-   ing negative sampling and includes the dependency   tag information and binarization . We use the spaCy   dependency parser for obtaining dependency tags .   We were unable to ﬁnd a dependency parsing tool   with universal dependencies for Arabic and there-   fore we did not use dependency tags for Arabic .   For BenchIE , IEuses the binarization function   described in Section 2.5 , but not for CRBand lex-   ical match because they evaluate n - ary extractions .   3.2 Results   3.2.1 English   In Table 5 , we compareIEwith several unsu-   pervised and supervised baselines in English on   CRBand BenchIE.IEperforms much better   compared to other neural baselines on BenchIE .   This is not the case for the CRBdataset since   CRBpenalizes compact extractions and rewards   longer extractions ( Gashteovski et al . , 2021 ) . Al-   though rule based systems like ClausIE and MinIE   outperform neural systems , they can not be used for   languages other than English.6944   3.2.2 Multilingual   In Table 3 , we compareIEwith Multi2OIE   ( M2OIE ) on the multilingual BenchIE benchmark . IEperforms signiﬁcantly better compared to   Multi2OIE for all the languages . For German and   Arabic both Multi2OIE andIEperform sig-   niﬁcantly worse compared to the other languages .   The presence of separable preﬁxes in German verbs   which can not be extracted using BIO tags results   in low performance . The BIO tagging scheme as-   sumes continuity of phrases which is absent for   most German verbs present in predicates , resulting   in extremely low recall . For Arabic , the low scores   are due to the Verb - Subject - Object nature of the   Arabic language along with the fact that subjects or   objects can be expressed as part of the verb . This   calls for additional research on framing OpenIE   tasks for languages such as German and Arabic . IEsigniﬁcantly outperforms Multi2OIE for   Galician language which is closely related to Por-   tuguese . Ablation results in Table 3 also indicate   the usefulness of adding the dependency tags , neg-   ative sampling , and the binarization mechanism .   In Table 4 , we compare MLIE with Multi2OIE   on the CRBlexical match benchmark . MLIE ,   without negative sampling works best for Spanish   clean data . This is not due to the language , but   due to the lexical match evaluation which rewards   overly long extractions even if incorrect . Not us-   ing negative sampling sometimes improves recall   which may improve F1 score . This is observed for   the German benchmark .   3.2.3 Hybrid OpenIEIEcan easily integrate any rule based system   that extracts even a part of the triple . To evaluate   this , we ﬁrst simulate a system that only extracts   the object and useIEto extract other parts of   the triple . We do this by employing ClausIE for   extracting triples for the BenchIE English data and   only use the object , discarding the rest of the triple .   The reason behind the choice of selecting object   extraction from ClausIE is the fact that neural sys-   tems are not good at extracting objects ( Kolluru   et al . , 2020a ) . This is also seen from additional   experiments detailed in Section 4 . Table 6 indeed   conﬁrms that combining rule based object extrac-   tion withIEimproves performance by over 6 %   in F1 score . This showcases thatIE ’s ability to   integrate other systems can be a great advantage .   4 Analysis   We would like to analyze that the ability ofIE   to extract triples using different extraction patterns   results in improved performance on multilingual   data . For this , we compareIEwith the wa-   ter ﬁlling aggregation againstIEwith different   extraction pathways . We also compared with a dy-   namic decoding scheme whereIEchooses a   decoding pathways based on the sentence . To do   this we split a part of the English training set and   for each sentence in the split we record the extrac-   tion pathway that provides the best F1 scoreIE6945   as per CRBevaluation . We then use this as train-   ing data for training another mBERT model which   classiﬁes each sentence in one of the six classes   where each class represents an extraction pathway .   Table 7 details the performance for different ex-   traction schemes . All the extraction schemes ex-   cept WF , use only one pathway . DYN provides   mixed results across the different languages - for   German it is the best approach , whereas for Ara-   bic it is the worst . In contrast , the combination   of multiple pathways allows to performing much   better than the other approaches on all languages ,   except German . This demonstrates that combining   triple extraction from multiple pathways is better   than any single pathway , which in turn conﬁrms   that extracting triples repeatedly from the same sen-   tence using multiple extraction pathways is more   proﬁtable than using a single extraction pathway .   Additionally , Table 7 provides an interesting in-   sight : predicate ﬁrst seems to be the best , followed   by subject ﬁrst and then object ﬁrst for languages   other than Arabic . This also shows how the difﬁ-   culty of extracting triple slots using transfer learn-   ing from English varies with the target language .   Table 7 suggests that predicates are easier to ex-   tract leading to lesser number of errors propagated   in the prediction chain . We suspect that this could   result from differences in linguistic variability . To   test our hypothesis we measured the entropy of   the distribution of dependency and part - of - speech   tags in the predicate , subject and object slots in   the BenchIE English and the multilingual test sets .   Results shown in Table 8 suggest that linguistic   complexity of objects is higher than those of predi-   cates and subjects .   This is also conﬁrmed in Figure 3 , where we plot   the extraction errors in either subject , predicate or   objects among incorrectly extracted triples . Most   errors result from extracting incorrect objects com-   pared to predicates and subjects . The percentage   sum does not add to hundred because an incorrect   triple can contain errors in more than one slot .   5 Related Work   OpenIE systems largely come in two ﬂavors , ( 1 )   unsupervised OpenIE systems that use ﬁne grained   rules based on dependency parse trees ( Del Corro   and Gemulla , 2013 ; Gashteovski et al . , 2017 ;   Lauscher et al . , 2019 ) , and ( 2 ) supervised neu-   ral OpenIE systems , trained end - to - end with large   training datasets ( Stanovsky et al . , 2018 ; Ro et al . ,   2020 ; Kolluru et al . , 2020a ) . Neural OpenIE sys-   tems characterize OpenIE as either a sequence tag-   ging task ( Stanovsky and Dagan , 2016 ; Ro et al . ,   2020 ) , span prediction task or a sequence genera-   tion task ( Kolluru et al . , 2020b ) . However all these   prior approaches extract a triple in a single step ,   which does not allow us to study the effect of ex-   tracting a speciﬁc slot and its effect on extracting   the rest of the triple .   Neural generative approaches to OpenIE use   sequence - to - sequence models with a copy mecha-   nism for generating triples ( Sun et al . , 2018 ; Kol-   luru et al . , 2020b ) . The copy mechanism needs   to be learned and is often a source of errors . A   series of alternative approaches cast OpenIE as a   sequence tagging task where each token is tagged   as subject , predicate or object using a BIO like   tagging scheme ( Stanovsky et al . , 2018 ; Ro et al . ,   2020 ; Kolluru et al . , 2020a ) . In these systems , all   triple slots are extracted simultaneously and it is   therefore not possible to condition on easier slots .   More closely related to our work is SpanOIE   ( Zhan and Zhao , 2020 ) and Multi2OIE ( Ro et al . ,   2020 ) , which ﬁrst extracts the predicate and then6946all additional arguments . Like us , Multi2OIE ( Ro   et al . , 2020 ) addresses multilinguality by leverag-   ing a pretrained BERT model ( Devlin et al . , 2019 )   for transfer learning . In contrast , through our itera-   tive nature , it is possible to enrich the extractions   in other languages if rule based models or other   models ( e.g. NER recognizers ) exist to provide in-   put for a triple slot . IMOJIE ( Kolluru et al . , 2020b )   iteratively extracts entire triples from a sentence :   ﬁrst a triple is extracted , which is added to the in-   put to extract the next triple . In contrast , our work   iteratively extracts the slots of a single triple , which   allows us to condition on the easier slots and there-   fore obtain higher quality triples . ( Kolluru et al . ,   2020a ) propose OpenIE6 , a BERT based system ,   with iterative grid labelling and linguistic constraint   based training . Such lingusitic constraints with   soft penalties can not be readily ported to other lan-   guages since such constraints use head verb based   heuristics . Consequently OIE 6 is evaluated only   on English .   6 Conclusion   We introducedIE , a modular & iterative mul-   tilingual OpenIE system . We conﬁrmed our hy-   pothesis that it is beneﬁcial to extract triple slots   iteratively which allows us to extract easier slots   ﬁrst . Our experiments on English as well as ﬁve   low resource languages uncovered that , with the   exception of Arabic , triples are easier to extract   if the predicate is extracted ﬁrst followed by the   subject and object . More importantly we discov-   ered that extracting triples using multiple extraction   pathways is superior than the standard single ex-   tractions especially in the multilingual setting . We   also demonstrated howIEcan be combined   seamlessly with rule based systems for improv-   ing performance . Although our experiments were   focused on the OpenIE task , we believe that the in-   sights gained can be translated to other information   extraction tasks with coupled extractions . We plan   to explore such connections in the future .   References6947   A Appendix   A.1 Training DetailsIEis expected to predict slots iteratively con-   ditioned on prior extracted slots of a triple , there-   fore it needs to be trained with similar examples .   Exhaustively listing all possible combinations of   prior extracted slots and slots to be extracted is pro-   hibitively expensive . Therefore we use a sampling   procedure that ensures the model sees a variety of   combinations during training .   For every example in the Re-2016 training   dataset we do the following   1.Sample an slot as target ( for extraction ) with   the following probabilities ( subject : 1/3 , pred-   icate : 5/12 , object : 5/12 )   2.Sample two slots , one that is assumed to be   extracted and other the target that needs to be   extracted conditioned on the ﬁrst .   3.Sample three slots , ﬁrst two assumed to be ex-   tracted and the third is the target conditioned   on ﬁrst two .   4.If the example contains n - ary arguments , the   subject , predicate and object are assumed   to be extracted and the n - ary arguments are   treated as targets .   When a slot is sampled for target extraction , all   instances of the slot are expected to be extracted .   For example , if the target is the subject and if   the example consists of multiple subjects then   the targets are multiple subjects . However the   sampled slots assumed to be extracted must be   single instances , and if there are multiple instances ,   then each instance is considered for conditioning   one after the other . Table 9 details the sampling   probabilities for two and three slots . The sampling   probabilities were not tuned , but rather chosen   based on heuristics . Post sampling , we obtain   training dataset with about 5 and a half million   examples .   Negative Sampling6948Extracted Slots Target Slot Probability   subject object 3/12   subject predicate 1/12   object subject 2/12   object predicate 1/12   predicate subject 2/12   predicate object 3/12   ( subject , object ) predicate 2/12   ( subject , predicate ) object 6/12   ( object , predicate ) subject 4/12   We provideIEwith negative samples during   training for reducing error ampliﬁcation arising   out of iterative prediction . In this case the target   is always blank , i.e. , all the tokens are marked   as ’ outside ’ . Thus the sampling revolves around   creating incorrectly extracted slots . We sample   negatives for every example in the training data   and then select knegative samples uniformly at   random.kis treated as a hyperparameter .   Table 10 provides the sampling probabilities for   different slot arrangements . We use three corrup-   tion procedure for generating incorrectly marked   slots , namely , invert , randomize and switch . The in-   vert method consist of swapping the extracted slot   with the target slot . For example , if the extracted   slot is subject and target slot is object , then the ob-   ject is marked as subject . The randomize method   consists of choosing a random span of tokens near   the actual slot . Finally the switch method involves   switching one of the extracted slot with a slot from   another triple associated with the sentence . For   example , in the case of ( subject , object ) , the object   of this triple is switched with an object of another   triple associated with the same sentence . It is pos-   sible that the same subject maybe associated with   the new object as well . We check if this is true , and   if true we ﬁlter out such positives . Num . NS ( k ) Learning Rate F1   0 11039.88   0 31044.70   0 91040.76   10 K 11043.45   10 K 31047.03   10 K 91047.19   100 K 11048.03   100 K 31047.30   100 K 91045.87   1 M 11046.01   1 M 31046.16   1 M 91045.26   A.2 Hyperparameter Tuning   We train and evaluateIEon an NVIDIA Titan   RTX with 24 GB GPU RAM . The training is done   for a maximum of two epochs and each epoch takes   about 9 - 10 hours . The maximum sentence length   using the English train and validation dataset is   found to be about 100 . Due to the addition of   extracted triple element markers we allow a slack   of 20 tokens , thus ﬁxing the maximum sentence   length to 120 . We use a maximum possible batch   size that ﬁts inside the GPU , which results in batch   size of 192 . We use A ( Kingma and Ba , 2015 )   as the optimizer with linear warmup and tune the   learning rate . The linear warmup fraction is ﬁxed at   0:1 . We also treat the number of negative samples ,   k , as a hyperparameter and tune it . We choose the   best hyperparameters based on the F1 score . Table   11 provides details on the recall scores for every   hyperparameter arrangement.69496950