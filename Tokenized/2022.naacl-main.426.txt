  Hanxun Zhong , Zhicheng Dou , Yutao Zhu , Hongjin Qian , Ji - Rong WenSchool of Information , Renmin University of China , Beijing , ChinaGaoling School of Artificial Intelligence , Renmin University of China , Beijing , ChinaUniversity of Montreal , Quebec , Canada   { hanxun_zhong,dou,ian}@ruc.edu.cn   { yutaozhu94,jirong.wen}@gmail.com   Abstract   Personalized dialogue systems explore the   problem of generating responses that are con-   sistent with the user ’s personality , which has   raised much attention in recent years . Exist-   ing personalized dialogue systems have tried   to extract user profiles from dialogue history to   guide personalized response generation . Since   the dialogue history is usually long and noisy ,   most existing methods truncate the dialogue   history to model the user ’s personality . Such   methods can generate some personalized re-   sponses , but a large part of dialogue history is   wasted , leading to sub - optimal performance of   personalized response generation . In this work ,   we propose to refine the user dialogue history   on a large scale , based on which we can handle   more dialogue history and obtain more abun-   dant and accurate persona information . Specifi-   cally , we design an MSP model which consists   of three personal information refiners and a   personalized response generator . With these   multi - level refiners , we can sparsely extract the   most valuable information ( tokens ) from the di-   alogue history and leverage other similar users ’   data to enhance personalization . Experimental   results on two real - world datasets demonstrate   the superiority of our model in generating more   informative and personalized responses .   1 Introduction   Recent years have witnessed great progress in build-   ing personalized dialogue systems . In general , pre-   vious work explores building a personalized dia-   logue system via two pathways : ( 1 ) directly mod-   eling user personality from predefined persona de-   scriptions or user attribute ( Qian et al . , 2018 ; Zhang   et al . , 2018 ; Song et al . , 2019 ) ; and ( 2 ) implicitly   modeling the user personality from the user ’s di-   alogue history ( Li et al . , 2016c ; Ma et al . , 2021 ) .   The latter is considered superior as the dialogue   history is easy to obtain and comprises rich per-   sonalized information . In this paper , we follow thesecond pathway that automatically learns implicit   user profiles from the user ’s dialogue history to   assist in personalized response generation .   It is challenging to model user personality di-   rectly from the dialogue history . The main reason   is that a user ’s dialogue history may contain mas-   sive historical dialogues , which are too heavy to   load in the model and likely to be noisy . A straight-   forward solution is to truncate the dialogue history ,   as done by existing work ( Ma et al . , 2021 ; Qian   et al . , 2021a ) . However , as tremendous information   has been wasted , the model ’s performance is also   influenced . On the other hand , we observe that the   dialogue history from other users may also be help-   ful in generating a personalized response for the   current user . For example , users with the same in-   terest in “ soccer ” may talk about similar things on   such a topic . This has been overlooked by existing   methods . Intuitively , the problem of “ data explo-   sion ” is even more severe in the latter case ( when   other similar users ’ dialogue history is also con-   sidered ) . To alleviate these problems , we propose   using a hierarchical refiner structure to sparsely   extract the most valuable query - aware persona in-   formation from both the current and other simi-   lar users ’ dialogue history . By this means , more   dialogue history can be utilized for learning user   personality and improving response generation .   Our model is called MSP , which stands for   Modeling and Selecting user Personality from the   dialogue history for generating personalized re-   sponses . Instead of attending to all dialogue history ,   MSP refines the most valuable historical informa-   tion that can well portray the user ’s personality   and guide the response generation . Specifically ,   MSP consists of three personal information refin-   ers working at different levels and a personalized   response generator . At first , a user refiner is de-   signed to select a group of users who have similar   interests to the current user . By refining dialogue   history at the user level , we can obtain similar data5808to share information with similar users and avoid   mutual interference with other users . Then , a topic   refiner filters out the current and similar users ’ dia-   logue history that has different topics with the cur-   rent query at the sentence level . Next , we design   a token refiner to extract the most valuable query-   aware user profiles from the remaining dialogue   history at the token level . Finally , a personalized   response generator combines user profiles and the   current query to generate responses . Given that   there is no explicit supervisory signal guiding the   refiner to extract an exemplary user profile , we de-   sign a supplementary sentence matching task and a   joint training method . The generator will construct   a pseudo - label to guide the refiner ’s extraction .   Our contributions are three - fold :   ( 1 ) We design an MSP model to tackle the data   noise problem . It can efficiently refine user profiles   through dialogue history and generate personalized   responses . By this means , our method can capture   abundant user profiles while keeping away from   noisy data .   ( 2 ) We design a refiner structure to extract the   query - aware profile at three levels . Similar users ’   information is taken into account , which can help   improve the personality of the response .   ( 3 ) We design a joint training method for the   refiner and generator . The refiner provides the gen-   erator with user profiles to assist in generating re-   sponses , while the generator constructs a pseudo-   label for the refiner to assist in selecting user pro-   files .   2 Related Work   Personalized Dialogue Generation Open-   domain dialogue generation has been extensively   studied ( Koehn et al . , 2003 ; Vinyals and Le , 2015 ;   Serban et al . , 2016 ; Zhang et al . , 2019a , b ; Liu et al . ,   2020 ; Xiao et al . , 2020 ; Zhu et al . , 2020 ) . Recently ,   personalized dialogue systems have attached more   and more attention . Typical methods include : ( 1 )   explicitly using predefined persona descriptions or   attributes as users ’ profile to generate personalized   responses ( Qian et al . , 2018 ; Zhang et al . , 2018 ;   Olabiyi et al . , 2019 ; Song et al . , 2019 ) ; ( 2 ) using   user ID embeddings to enhance personalized   dialogue generation ( Li et al . , 2016c ; Chan et al . ,   2019 ) ; and ( 3 ) extracting implicit user profile from   users ’ dialogue history to generate personalized   responses ( Al - Rfou et al . , 2016 ; Bak and Oh , 2019 ;   Ma et al . , 2021 ) . Since manually collecting userprofiles is impractical for large - scale datasets and   the user ID embeddings perform badly , in this   study , we focus on the last group of methods for   personalized response generation .   DHAP ( Ma et al . , 2021 ) is the state - of - the - art   method in personalized dialogue generation . It uses   a transformer - based structure to model the user ’s di-   alogue history and extract personal information for   response generation . Unfortunately , this model can   only handle a limited number of user dialogue his-   tories , wasting a lot of valuable information . Our   method has two main differences from DHAP : ( 1 )   We propose a refiner structure in our model so that   more dialogue history can be handled and the most   valuable information can be extracted for improv-   ing response generation ; ( 2 ) With our proposed   refiner , we can further incorporate more dialogue   history from other users ( having similar interests )   to facilitate personalized dialogue generation .   Retrieval - guided Natural Language Generation   Retrieval - based methods can collect relevant infor-   mation for language generation ( Yang et al . , 2019 ) .   It has been widely applied in many tasks such as   text style transfer ( Li et al . , 2018 ) and dialogue gen-   eration ( Wu et al . , 2019 ; Cai et al . , 2019 ) . The idea   of using a retrieval system to get useful information   inspires our study . We use a refiner to automati-   cally extract personal information from dialogue   history and guide the personalized generation .   3 Methodology   In this section , we first formalize our problem and   provide an overview of our proposed MSP model .   Then , we describe the details of each component   and the model optimization .   3.1 Problem Statement and Overview   Considering a set of users U={u , · · · , u } , for   any user u , we have their dialogue history with   others U={(q , r),···,(q , r ) } , where qis   aquery issued by others , while ris the corre-   sponding response given by u. Our target is to   generate a personalized response rfor the user u   to reply a new query q. As we introduced earlier ,   the personalized information can be obtained from   the dialogue history Uof the user uand other   dialogue history Ufrom similar users u(j̸=i).5809   The overview of our MSP model is shown in   Figure 1 . MSP consists of three personal infor-   mation refiners working on different levels and a   personalized response generator . Specifically , the   first refiner is working at the user level . By com-   paring the dialogue history of the current user u   with others , MSP can select a group of users having   similar interests with u. After obtaining a group   of similar users , we further refine their dialogue   history according to the relevance to the current   query ’s topic . Moreover , we add the last refiner to   extract several tokens so that the most fine - grained   personal information can be extracted from the rele-   vant utterances . Finally , the query and the extracted   tokens are fed into the generator and construct a   personalized response .   3.2 User Refiner   The dialogue history of users with similar interests   may share much personal information . Therefore ,   our first target is to select a group of users with   similar interests to the current user . We design a   user refiner to achieve this . Since the users ’ interest   is usually contained in their dialogues with others ,   we consider both the queries and responses in the   dialogue history to select similar users . Specif-   ically , for the user u ’s dialogue history U , we   apply a pre - trained BERT ( Devlin et al . , 2019 ) andrepresent them by the embedding of [ CLS ] token :   U=/summationdisplayBERT ( q),U=/summationdisplayBERT ( r ) .   Then , we can select kusers that have similar in-   terest with the current user uas :   u= TopK ( U·U , k ) , ( 1 )   U= [ U;U ] , ( 2 )   where TopK ( · , · ) is the top- kselection operation .   After the user refiner , we can obtain the dialogue   history of the similar users { u } . It is worth not-   ing that , since the number of users is large in the   datasets , we choose to use the dot - product to com-   pute the similarity of the users so that the whole   process can be implemented by dense retrieval li-   braries , such as Faiss ( Johnson et al . , 2021 ) , which   is very efficient .   3.3 Topic Refiner   The users ’ dialogue history often contains many di-   alogues with others . These dialogues have various   topics , which may be irrelevant to the current query .   Therefore , we propose a topic refiner to select rel-   evant dialogue history for personalized response   generation . Specifically , we use a topic classifier to   compute the topic distribution of the current query5810qand the queries qin the history dialogues :   t = MLP ( mean(BERT ( q ) ) , ( 3 )   t = MLP ( mean(BERT ( q ) ) , ( 4 )   where t , t∈R , and dis the number of topic .   Then , we filter out the dialogue history < q , r >   that has different topics with the current query , i.e. ,   max ( t)̸= max ( t ) .   In the topic refining process , we compare the   queries in the history dialogues with the current   query to filter out topic - irrelevant dialogues . This   process can further reduce the noise and make our   model more lightweight . Both the dialogue history   of the current user and that of the similar users   ( obtained in the former step ) are refined . In the next   step , we will use the responses in these selected   history dialogues and extract the most valuable   tokens for personalized response generation .   3.4 Token Refiner   After the previous two refiners , we obtain a col-   lection of historical responses . Though we can   directly add them into the generation process , our   preliminary experiments indicate that they perform   poorly . A major reason is the noisy quality of the   responses . Indeed , existing studies ( Xing et al . ,   2017 ; Zhu et al . , 2020 ) have demonstrated the ef-   fectiveness of using informative tokens to improve   the response generation . Inspired by these stud-   ies , we further devise a token refiner to extract the   most fine - grained information ( tokens ) from the   historical responses . Specifically , we compute an   attention map Abetween the query qand the his-   torical responses randr(they are from the   similar users and the current user respectively ) as :   A= softmax / parenleftbiggQK   √   d / parenrightbigg   , ( 5 )   Q = TRM(q)·W , ( 6 )   K = TRM(r)·W , ( 7 )   where TRM(·)is a transformer encoder . rrefers   tororr , and correspondingly , Arefers to   the similar user matching map Aand current   user matching map A.W , W∈Rare   parameters , and dis the dimension of the hidden   state . After obtaining the attention matching map   A , we select tokens to form the similar users ’ pro-   file and current user ’s profile according to eachtoken ’s attention weight :   c= TopK(Max ( A ) , k ) , ( 8)   c= TopK(Max ( A ) , k ) , ( 9 )   where kis a hyper - parameter to control the num-   ber of profile tokens . Its influence will be investi-   gated in our experiments .   3.5 Generator   We use a transformer decoder as to generate a per-   sonalized response by using the similar users ’ pro-   filec , current user ’s profile c , and query in-   formation qas input . The decoding process can be   defined as :   ˆy = TRM(x ) , ( 10 )   x= [ c;c;q ] , ( 11 )   where [ ; ] is the concatenation operation and ˆyis   the word generation probability .   3.6 Training and Optimization   The generator is optimized by maximizing the gen-   eration probability of the ground - truth y :   L=−ylog ˆy . ( 12 )   In practice , we find that the token refiner is hard   to train . We speculate the reason is a missing of   direct supervision signals . In this case , it is diffi-   cult to tell whether the training errors stem from   the generation process or the refining process . To   tackle this problem , we propose a supplementary   sentence matching task to assist the token selection .   Supplementary Sentence Matching Task The   core idea of this task is to train the token refiner   directly by introducing supervision signals so that   it can automatically mine valuable tokens . Specifi-   cally , we design a sentence matching task to match   the query with the dialogue history . The task ’s   target is to find the history sentences that help gen-   erate personalized responses . We consider using   the query - history cross attention weight Ato gen-   erate a matching representation and then use this   representation to finish the task . In this way , once   the matching task has been well - finished , we can   use attention map Ato identify the most informa-   tive and valuable parts of a history sentence that   are helpful to generate a personalized response .   To achieve our idea , we design a matching pro-   cess . First , we calculate the matching represen-   tations Hby the cross - attention map Aand then5811apply a CNN with a max - pooling operation to ag-   gregate token information :   S= Maxpool ( CNN ( H ) ) ( 13 )   H = A·V , ( 14 )   V = TRM(r)·W. ( 15 )   Next , we flatten Sand applies a LSTM to aggregate   the sentence information :   h = LSTM ( Flatten ( S ) ) . ( 16 )   Finally , we use the sentence matching vector hto   compute the matching score :   ˆg= Sigmoid ( MLP ( h ) ) . ( 17 )   For guiding the sentence matching task , we design   a pseudo - label gto measure the matching goodness   of each history sentence . We expect the history   with more persona profile information can achieve   a higher score . Therefore , we use the difference   between the personalized ground - truth yand a non-   personalized generated response ˆyto measure the   persona profile and create the pseudo - label :   g=/braceleftigg   1 , g≥α   0 , g < α,(18 )   g= Sum(Max ( ( y−ˆy)·r))/d , ( 19 )   where dis the length of y , and αis a threshold .   Finally , we minimize the binary cross entropy loss   between gandˆg :   L = glog ˆg+ ( 1−g ) log(1 −ˆg ) . ( 20 )   Joint Training To facilitate the learning with the   above gradient approximation approach , we de-   sign a joint training process to train the refiner   and generator in turn . Specifically , in each train-   ing iteration , we first sample a batch of query q ,   response y , similar and current users ’ dialogue his-   toryrandrfrom dataset D. Then , we gener-   ate a non - personalized response ˆyand create the   pseudo - label g(Eq . 18 ) through a non - personalized   generator . This pseudo - label is used to train the   token refiner by optimizing the loss L(Eq . 20 ) .   Further , we sample another batch Dfrom D. Af-   ter extracting similar user profile cand current   user profile c(Eq . 8 , Eq . 9 ) , we generate the per-   sonalized response ˆyand update the generator by   optimizing the loss L(Eq . 12 ) . To avoid mislead-   ing the generation ( by poor profile ) at the beginning   of the training process , we pre - train the refiner for   Nsteps before extracting the profile for the gener-   ator . The detailed training process is summarized   in Algorithm 1.Algorithm 1 Joint Training Process   4 Experiments   4.1 Datasets   To evaluate our model ’s performance , we conduct   experiments on a Chinese Weibo dataset ( Qian   et al . , 2021b ) and an English Reddit dataset . Both   are collected from open - domain social media plat-   forms . On these platforms , users can post vari-   ous topics , and other users can respond to them .   We compare user - id and timestamps to associate   the query with its corresponding response and the   current user ’s dialogue history . As a result , each   training sample contains a query , a response , and a   sequence of dialogue history . Finally , the dataset   is divided into training , validation , and test sets in   chronological order . The statistics of the datasets   are provided in Table 1 .   4.2 Baseline Methods   We compare our proposed model with eight highly   correlated and strong baselines . They can be cate-   gorized into four groups :   Non - personalized Methods ( 1 ) Seq2Seq-   Attention ( Sutskever et al . , 2014 ) is a vanilla   sequence - to - sequence model with attention mech-   anism ( Luong et al . , 2015 ) . ( 2 ) MMI ( Li et al . ,5812   2016a ) is based on Seq2seq and use maximum   mutual information as an extra loss to improve   diversity . ( 3 ) DialoGPT ( Zhang et al . , 2019b ) is a   variant of GPT-2 ( Radford et al . , 2019 ) designed   for dialogue generation .   Predefined Profile - based Methods Since there   is no persona description in the datasets , we test   these methods by using the user ’s dialogue history   as a simulation of predefined persona profiles . ( 4 )   GPMN ( Zhang et al . , 2018 ) enhances the Seq2seq   model with a memory module , which encodes and   stores the persona profile as memory representa-   tions . ( 5 ) PerCV AE ( Zhao et al . , 2017 ) encodes   predefined personalized sentences as a conditional   representation and uses CV AE to generate a per-   sonalized response .   User ID - based Methods ( 6 ) Speaker ( Li et al . ,   2016c ) is based on seq2seq while using user - ID   embedding as user representation to facilitate the   response generation . ( 7 ) Persona WAE ( Chan et al . ,   2019 ) uses WAE ( Wasserstein autoencoder ) for   response generation . It maps user - ID embeddings   to a personalized Gaussian mixture distribution and   then samples the personalized vector to guide the   response generation .   User Dialogue History - based Methods ( 8)   DHAP ( Ma et al . , 2021 ) uses history memory to   store and construct the dynamic query - aware user   profile from dialogue history and then uses a per-   sonalized decoder to generate a response . Since   this model also learns the user profile directly from   the dialogue history , it is the most relevant baseline   of our method .   4.3 Implementation Details   We experiment with multiple sets of hyperparam-   eters to select the best model , and the final hyper-   parameters are listed as follows : The dimensionsof the embeddings and Transformer hidden units   are 768 . The number of heads in the Transformer   is 12 . The number of layers in the Transformer   is set as 2 and 12 respectively in the query en-   coder and decoder . The topic number is 15 , and   the similar user number is set as 10 . The selected   profile token number is 200 for the Weibo dataset   and 30 for the Reddit dataset . The batch size is   128 . Following ( Holtzman et al . , 2020 ) , we adopt   nucleus sampling as our decoding strategy . We   use the Adam ( Kingma and Ba , 2015 ) optimizer   for training the refiners and AdamW ( Loshchilov   and Hutter , 2019 ) with a warm - up method for the   generator . Our code is publicly available .   4.4 Evaluation   Metric - based Evaluation We first evaluate all   methods by several metrics with respect to different   aspects . ( 1 ) BLEU-1/2 ( Papineni et al . , 2002 ) and   ROUGE - L ( Lin and Och , 2004 ) are typical word   overlap - based metrics for measuring the similarity   between the generated response and the ground-   truth.(2 ) Distinct-1/2 ( Li et al . , 2016b ) consider   the number of uni- or bi - grams in the generated re-   sponse , which is commonly used for evaluating the   diversity . ( 3 ) The embedding - based metrics ( i.e. ,   average , extrema , and greedy ) ( Chan et al . , 2019 )   are introduced to measure the semantic similarity   between the generated response and the ground-   truth one . ( 4 ) As a personalized dialogue model ,   following previous studies ( Ma et al . , 2021 ) , two   tailored metrics are adopted to measure how much   information is included in the dialogue history that   can be reflected in the response . Persona - F1 ( P-   F1 ) ( Lian et al . , 2019 ) calculates the F1 value to   measure the uni - grams co - occurring in both the   generated response and the dialogue history . Per-   sona Coverage ( P - Cover ) ( Song et al . , 2019 ) cal-   culates the IDF - weighted word overlap between   the generated response and the golden one so that   the importance of different words can be taken into   account .   Human Annotation Due to the variability of   human language , a response that differs from the   ground - truth may also be appropriate . Following   previous studies ( Chan et al . , 2019 ) , we conduct a   human evaluation of all methods . Concretely , we5813   sample 100 ( query , response , user dialogue history )   triplets and hire three well - educated annotators to   score the responses generated by different mod-   els . Three aspects , i.e. , readability , informative-   ness , and personalization , are considered . The first   two factors are scored on a scale of [ 1 , 3 ] for their   quality , while the third is assessed on a scale of [ 0 ,   1 ] , indicating whether the response can accurately   reflect the user ’s personality . The detailed scoring   criteria are shown in Table 2 .   4.5 Experimental Results   Metric - based Evaluation Table 3 shows all   models ’ performance under different metrics . On   both datasets , it is clear to see that our MSP model   outperforms baselines on all metrics . The improve-   ment is statistically significant ( t - test with p - value   < 0.05 ) . These findings indicate that our model   is capable of generating more fluent , diverse , and   personalized responses than all baselines . In par-   ticular , we can observe : ( 1 ) MSP achieves better   performance on overlap - based metrics . This sug-   gests that our model can provide responses that are   more similar to the ground - truth with the help of   the selected tokens . ( 2 ) For diversity metrics , the   higher distinct values show that our generated re-   sponses are more diverse . Additionally , predefined   profile - based methods and user dialogue history-   based methods outperform others . This shows that   incorporating external information can aid in thegeneration of more informative responses . ( 3 ) In   addition to generating more overlapped words with   the ground - truth response , the improvements in em-   bedding metrics reflect that our model generates   more semantically relevant responses . ( 4 ) Finally ,   the increase in personalized metrics implies that   our approach can incorporate more user - specific   information into the generation . Furthermore , the   significant improvement over DHAP demonstrates   that our model can extract more meaningful person-   alized information from the user dialogue history .   Human Annotation The result of human anno-   tation on the Weibo dataset is shown in Table 4 .   The Fleiss Kappa is around 0.62 , indicating a sub-   stantial agreement achieved by three annotators . In   general , the results of human annotation are con-   sistent with those of the metric - based evaluation .   Both of them demonstrate our model ’s superiority   in generating more fluent , informative , and person-   alized responses . Compared to non - personalized   methods , user id - based methods can enhance per-   sonalization at the expense of readability . User   dialogue history - based methods ( i.e. , DHAP and   MSP ) can largely improve the personalization of   the response while retaining a high level of read-   ability and informativeness . We attribute this to   the abundant personal information contained in the   user dialogue history.5814   5 Further Analysis   We further conduct a series of analyses to elaborate   our model . All analyses here are based on the result   of the Weibo dataset , while similar results can be   observed on the Reddit dataset .   Ablation Study To investigate the impact of dif-   ferent modules in MSP , we conduct an ablation   study by removing or using different strategies in   each module .   We first study the influence of the refiners at   three levels : ( 1 ) We remove the user refiner and   train our model using randomly sampled users . We   can see the performance of all metrics drops . This   illustrates that our MSP model can select users   that share the same interests as the current user and   thereby improving response quality . ( 2 ) We remove   the topic refiner and supply the token refiner with   full dialogue history . The performance degradation   demonstrates that various topics in dialogue his-   tory introduce lots of noise , misleading the token   refiner on extracting valuable tokens , thus impair-   ing the personalized response generation . ( 3 ) We   eliminate the token refiner and feed all dialogue   history sentences directly into the generator . The   decline in performance implies the effectiveness   and necessity of token selection . It is worth noting   that , as compared to using the complete history ,   our selection strategy can reduce training time by   41.6 % , considerably increasing efficiency . All of   the aforementioned experimental results suggest   that MSP ’s advantage stems from high - quality per-   sonalized information extraction rather than simply   introducing additional information .   We then explore the impact of personalized infor-   mation from two sources , i.e. , the current user ’s pro-   file and the similar users ’ profile . Removing either   of them results in decreased performance . This ex-   emplifies their usefulness . Specifically , compared   with similar users ’ profiles , eliminating the current   user ’s profile will hurt the personalization effect   heavily . This result shows that , for personalization ,   the current user ’s profile is more essential than that   of similar users , which is quite intuitive . However ,   the similar users ’ profile has a significant effect on   BLEU-1/2 , implying that such a profile can pro-   vide abundant information for response generation .   Consequently , integrating both types of profiles   significantly improves response generation .   Finally , we conduct an experiment to validate   our proposed joint training for the token refiner .   The declining performance indicates that the token   refiner is unable to extract useful information in the   absence of additional supervision signals . Indeed ,   when the sentence matching task is removed , the   token refiner extracts tokens that are relevant to the   current query , which is less useful for generating a   personalized response .   Influence of Selection Mechanism To validate   the effectiveness of our proposed selection mech-   anism , we replace the refiner with a traditional re-   trieval method ( i.e. , BM25 ( Robertson and Walker ,   1994 ) ) . Specifically , we use the query to retrieve5815   15 relevant responses and feed them into our model   for training . The experimental results are shown   in Figure 2 . We can observe that the retrieval   strategy achieves comparable performance with   our model on word - overlap and embedding - based   metrics . This suggests that the relevant dialogue   history for the query can provide valuable informa-   tion for response generation . However , the retrieval   strategy performs poorly on diversity and person-   alization metrics . This demonstrates that , without   careful selection , the retrieved information is too   generic and thus less helpful for personalized re-   sponse generation .   Influence of Personalized Tokens Amount In   MSP , three refiners are designed to extract person-   alized tokens for response generation . Intuitively ,   the amount of the tokens will influence the refiner ’s   performance . We report this influence in Figure 3 .   As we can see in the left part , the quality of re-   sponse generation improves with more tokens used .   This is because fewer tokens are incapable of cover-   ing sufficient personalized information for response   generation . Our MSP model performs optimally   when about 200 personalized tokens are selected .   When more tokens are introduced , the performance   degrades . The potential reason is that more tokens   would bring the noise to the generation . This is   consistent with our speculation that the dialogue   history is noisy and the information selection is   both effective and necessary .   To provide a more qualitative view of our   method , we conduct a case study in Appendix B.   6 Conclusion   In this work , we propose an MSP model for person-   alized response generation . Unlike previous related   work , we utilize a refiner structure to extract query - aware persona information from large - scale dia-   logue history . The multi - level refiners can sparsely   extract valuable information from dialogue history   and leverage similar users ’ information to enhance   the current user ’s personalization . Experimental   results confirm the effectiveness of our model in   generating informative and personalized responses .   Acknowledgement   Zhicheng Dou is the corresponding author . This   work was supported by National Natural Science   Foundation of China No . 61872370 and No .   61832017 , Beijing Outstanding Young Scientist   Program NO . BJJWZYJH012019100020098 , and   Intelligent Social Governance Platform , Major In-   novation & Planning Interdisciplinary Platform for   the “ Double - First Class ” Initiative , Renmin Uni-   versity of China . We also acknowledge the support   provided and contribution made by Public Policy   and Decision - making Research Lab of RUC .   References581658175818   A Additional Experimental Results   As n - gram word overlap metrics can reflect user   speaking style more accurately , we evaluate the   BLEU-3/4 ( Papineni et al . , 2002 ) , and the result is   shown in Table 6 . It is consistent with other evalu-   ations that our model outperforms every indicator .   This demonstrates that user profiles also contain   speaking style information , and our model can use   the information to achieve a personalized response .   B Case Study   To show the effect of our model more concretely ,   we adopt a case study , and the results are shown   in Table 7 . It shows that our model can extract   profiles from both current and similar users and   generate informative and personalized responses .   Specifically , in his dialogue history , he mentioned   sports H1 , H2 and music H3 , H4 topics . Firstly ,   we can select similar users who also talk about   sports and music , using the user refiner . Then ,   as the query is related to the music topic , we ex-   tract the current and sim users ’ dialogue history re-   sponses about the music topic R1 , R2 by the topic   refiner . Furthermore , the token refiner selects some   meaningful and personalized words from long sen-   tences of reference . In this case , we can find that   the token refiner extracts some compliment words   ( like , beautiful , enjoying ) from the current user ’s   history sentence since the current user likes listen - ing to music . And the token refiner captures more   concrete tokens from sim users ’ history sentences ,   such as “ Angela Leung ” and “ Ember ” . By comb-   ing two profiles , our personalized generator gets   an informative and personalized response close to   ground - truth . In contrast , DialoGPT generates a   fluent but meaningless response to the query.58195820