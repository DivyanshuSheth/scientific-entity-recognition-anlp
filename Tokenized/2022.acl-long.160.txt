  Ran ZhouXin LiRuidan HeLidong BingErik CambriaLuo SiChunyan MiaoDAMO Academy , Alibaba GroupNanyang Technological University , Singapore   Abstract   Data augmentation is an effective solution to   data scarcity in low - resource scenarios . How-   ever , when applied to token - level tasks such   as NER , data augmentation methods often suf-   fer from token - label misalignment , which leads   to unsatsifactory performance . In this work ,   we propose Masked Entity Language Modeling   ( MELM ) as a novel data augmentation frame-   work for low - resource NER . To alleviate the   token - label misalignment issue , we explicitly   inject NER labels into sentence context , and   thus the fine - tuned MELM is able to predict   masked entity tokens by explicitly condition-   ing on their labels . Thereby , MELM gener-   ates high - quality augmented data with novel   entities , which provides rich entity regular-   ity knowledge and boosts NER performance .   When training data from multiple languages are   available , we also integrate MELM with code-   mixing for further improvement . We demon-   strate the effectiveness of MELM on mono-   lingual , cross - lingual and multilingual NER   across various low - resource levels . Experimen-   tal results show that our MELM presents sub-   stantial improvement over the baseline meth-   ods .   1 Introduction   Named entity recognition ( NER ) is a fundamen-   tal NLP task which aims to locate named entity   mentions and classify them into predefined cat-   egories . As a subtask of information extraction ,   it serves as a key building block for information   retrieval ( Banerjee et al . , 2019 ) , question answer-   ing ( Fabbri et al . , 2020 ) and text summarization sys-   tems ( Nallapati et al . , 2016 ) etc . However , except   a few high - resource languages / domains , the ma-   jority of languages / domains have limited amountof labeled data .   Since manually annotating sufficient labeled data   for each language / domain is expensive , low-   resource NER ( Cotterell and Duh , 2017 ; Feng et al . ,   2018 ; Zhou et al . , 2019 ; Rijhwani et al . , 2020 ) has   received increasing attention in the research com-   munity over the past years . As an effective solu-   tion to data scarcity in low - resource scenarios , data   augmentation enlarges the training set by apply-   ing label - preserving transformations . Typical data   augmentation methods for NLP include ( 1 ) word-   level modification ( Wei and Zou , 2019 ; Kobayashi ,   2018 ; Wu et al . , 2019 ; Kumar et al . , 2020 ) and   ( 2 ) back - translation ( Sennrich et al . , 2016 ; Fadaee   et al . , 2017 ; Dong et al . , 2017 ; Yu et al . , 2018 ) .   Despite the effectiveness on sentence - level tasks ,   they suffer from the token - label misalignment issue   when applied to token - level tasks like NER . More   specifically , word - level modification might replace   an entity with alternatives that mismatch the origi-   nal label . Back - translation creates augmented texts   that largely preserve the original content . How-   ever , it hinges on external word alignment tools for   propagating the labels from the original input to   the augmented text , which has proved to be error-   prone .   To apply data augmentation on token - level   tasks , Dai and Adel ( 2020 ) proposed to randomly   substitute entity mentions with existing entities of   the same class . They avoided the token - label mis-   alignment issue but the entity diversity does not in-   crease . Besides , the substituted entity might not fit   into the original context . Li et al . ( 2020a ) avoided   the token - label misalignment issue by only diver-   sifying the context , where they replaced context   ( having ‘ O ’ label ) tokens using MASS ( Song et al . ,   2019 ) and left the entities ( i.e. aspect terms in their   task ) completely unchanged . However , according   to the NER evaluations in Lin et al . ( 2020 ) , aug-   mentation on context gave marginal improvement   on pretrained - LM - based NER models.2251   Our preliminary results on low - resource NER   ( see Figure 1 ) also demonstrate that diversifying en-   tities in the training data is more effective than intro-   ducing more context patterns . Inspired by the afore-   mentioned observations , we propose Masked Entity   Language Modeling ( MELM ) as a data augmenta-   tion framework for low - resource NER , which gen-   erates augmented data with diverse entities while   alleviating the challenge of token - label misalign-   ment . MELM is built upon pretrained Masked   Language Models ( MLM ) , and it is further fine-   tuned on corrupted training sentences with only   entity tokens being randomly masked to facilitate   entity - oriented token replacement . Simply mask-   ing and replacing entity tokens using the finetuned   MLM is still insufficient because the predicted en-   tity might not align with the original label . Taking   the sentence shown in Figure 2b as an example ,   after masking the named entity “ European Union ”   ( Organization ) , the finetuned MLM could predict   it as “ Washington has ” . Such prediction fits the   context but it is not aligned with the original labels .   To alleviate the misalignment , our MELM addi-   tionally introduces a labeled sequence linearization   strategy , which respectively inserts one label token   before and after each entity token and regards the   inserted label tokens as the normal context tokens   during masked language modeling . Therefore , the   prediction of the masked token is conditioned onnot only the context but the entity ’s label as well .   After injecting label information and finetun-   ing on the label - enhanced NER data , our MELM   can exploit rich knowledge from pre - training to   increase entity diversity while greatly reducing   token - label misalignment . Code - mixing ( Singh   et al . , 2019 ; Qin et al . , 2020 ; Zhang et al . , 2021 )   achieved promising results by creating additional   code - mixed samples using the available multilin-   gual training sets , which is particularly beneficial   when the training data of each language is scarce .   Fortunately , in the scenarios of multilingual low-   resource NER , our MELM can also be applied on   the code - mixed examples for further performance   gains . We first apply code - mixing by replacing en-   tities in a source language sentence with the same   type entities of a foreign language . However , even   though token - label alignment is guaranteed by re-   placing with entities of the same type , the candidate   entity might not best fit into the original context   ( for example , replacing a government department   with a football club ) . To solve this problem , we   propose an entity similarity search algorithm based   on bilingual embedding to retrieve the most seman-   tically similar entity from the training entities in   other languages . Finally , after adding language   markers to the code - mixed data , we use them to   fine - tune MELM for generating more code - mixed   augmented data .   To summarize , the main contributions of this   paper are as follows : ( 1 ) we present a novel frame-   work which jointly exploits sentence context and   entity labels for entity - based data augmentation .   It consistently achieves substantial improvement   when evaluated on monolingual , cross - lingual , and   multilingual low - resource NER ; ( 2 ) the proposed   labeled sequence linearization strategy effectively   alleviates the problem of token - label misalignment   during augmentation ; ( 3 ) an entity similarity search   algorithm is developed to better bridge entity - based   data augmentation and code - mixing in multilingual   scenarios .   2 Method   Fig . 2c presents the work flow of our proposed   data augmentation framework . We first perform   labeled sequence linearization to insert the entity   label tokens into the NER training sentences ( Sec-   tion 2.1 ) . Then , we fine - tune the proposed MELM   on linearized sequences ( Section 2.2 ) and create   augmented data by generating diverse entities via2252   masked entity prediction ( Section 2.3 ) .   The augmented data undergoes post - processing   ( Section 2.4 ) and is combined with the original   training set for training the NER model . Algo-   rithm 1 gives the pseudo - code for the overall frame-   work . Under multilingual scenarios , we propose   an entity similarity search algorithm as a refined   code - mixing strategy ( Section 2.5 ) and apply our   MELM on the union set of gold training data and   code - mixed data for further performance improve-   ment .   2.1 Labeled Sequence Linearization   To minimize the amount of generated tokens in-   compatible with the original labels , we design a   labeled sequence linearization strategy to explicitly   take label information into consideration during   masked language modeling . Specifically , as shown   in Figure 2c , we add the label token before and after   each entity token and treat them as normal context   tokens . The yielded linearized sequence is utilized   to further finetune our MELM so that its prediction   is additionally conditioned on the inserted label   tokens . Note that , we initialize the embeddings   of label tokens with those of tokens semantically   related to the label names ( e.g. , “ organization ” for   ⟨B - ORG ⟩ ) . By doing so , the linearized sequence   is semantically closer to a natural sentence and   the difficulty of finetuning on linearized sequence   could be reduced ( Kumar et al . , 2020 ) .   2.2 Fine - tuning MELM   Unlike MLM , only entity tokens are masked during   MELM fine - tuning . At the beginning of each fine-   tuning epoch , we randomly mask entity tokens inthe linearized sentence Xwith masking ratio η .   Then , given the corrupted sentence ˜Xas input ,   our MELM is trained to maximize the probabilities   of the masked entity tokens and reconstruct the   linearized sequence X :   maxlogp(X|˜X)≈Xmlogp(x|˜X)(1 )   where θrepresents the parameters of MELM , n   is the number of tokens in ˜X , xis the original   token in X , m= 1 ifxis masked and other-   wisem= 0 . Through the above fine - tuning pro-   cess , the proposed MELM learns to make use of   both contexts and label information to predict the   masked entity tokens . As we will demonstrate in   Section 4.1 , the predictions generated by the fine-   tuned MELM are significantly more coherent with   the original entity label , compared to those from   other methods .   2.3 Data Generation   To generate augmented training data for NER , we   apply the fine - tuned MELM to replace entities in   the original training samples . Specifically , given   a corrupted sequence , MELM outputs the proba-   bility of each token in the vocabulary being the   masked entity token . However , as the MELM is   fine - tuned on the same training set , directly pick-   ing the most probable token as the replacement is   likely to return the masked entity token in the orig-   inal training sample , and might fail to produce a   novel augmented sentence . Therefore , we propose   torandomly sample the replacement from the top k   most probable components of the probability distri-   bution . Formally , given the probability distribution2253Algorithm 1 Masked Entity Language Modeling ( MELM )   P(x|˜X)for a masked token , we first select a set   V⊆Vof the kmost likely candidates . Then ,   we fetch the replacement ˆxvia random sampling   from V. After obtaining the generated sequence ,   we remove the label tokens and use the remain-   ing parts as the augmented training data . For each   sentence in the original training set , we repeat the   above generation procedure Rrounds to produce   Raugmented examples .   To increase the diversity of augmented data , we   adopt a different masking strategy from train time .   For each entity mention comprising of ntokens ,   we randomly sample a dynamic masking rate ϵ   from Gaussian distribution N(µ , σ ) , where the   Gaussian variance σis set as 1 / n. Thus , the   same sentence will have different masking results   in each of the Raugmentation rounds , resulting in   more varied augmented data .   2.4 Post - Processing   To remove noisy and less informative samples from   the augmented data , the generated augmented data   undergoes post - processing . Specifically , we train a   NER model with the available gold training sam-   ples and use it to automatically assign NER tags   to each augmented sentence . Only augmented   sentences whose predicted labels are consistent   with the their original labels are kept . The post-   processed augmented training set Dis combined   with the gold training set Dto train the final   NER tagger .   2.5 Extending to Multilingual Scenarios   When extending low - resource NER to multilingual   scenarios , it is straightforward to separately applythe proposed MELM on language - specific data for   performance improvement . Nevertheless , it offers   higher potential to enable MELM on top of code-   mixing techniques , which proved to be effective   in enhancing multilingual learning ( Singh et al . ,   2019 ; Qin et al . , 2020 ; Zhang et al . , 2021 ) . In this   paper , with the aim of bridging MELM augmenta-   tion and code - mixing , we propose an entity simi-   larity search algorithm to perform MELM - friendly   code - mixing .   Specifically , given the gold training sets   { D|ℓ∈L}over a set Lof languages , we first   collect label - wise entity sets E , which consists   of the entities appearing in Dand belonging to   classy . To apply code - mixing on a source language   sentence X , we aim to substitute a mentioned   entity eof label ywith a target language entity   e∈E , where the target language is sam-   pled as ℓ∼ U(L\ { ℓ } ) . Instead of randomly   selecting efromE , we choose to retrieve   the entity with the highest semantic similarity to e   ase . Practically , we introduce MUSE bilingual   embeddings ( Conneau et al . , 2017 ) and calculate   the entity ’s embedding Emb(e)by averaging the   embeddings of the entity tokens :   Emb(e ) = 1   |e|XMUSE(e ) ( 2 )   where MUSEdenotes the ℓ−ℓaligned   embeddings and eis the i - th token of e. Next , we   obtain the target - language entity esemantically   closest to eas follows :   e= argmaxf(Emb(e),Emb(˜e ) ) ( 3)2254f(·,·)here is the cosine similarity function . The   output entity eis then used to replace eto create   a code - mixed sentence more suitable for MELM   augmentation . To generate more augmented data   with diverse entities , we further apply MELM on   the gold and code - mixed data . Since the training   data now contains entities from multiple languages ,   we also prepend a language marker to the entity   token to help MELM differentiate different lan-   guages , as shown in Figure 3 .   3 Experiments   To comprehensively evaluate the effectiveness of   the proposed MELM on low - resource NER , we   consider three evaluation scenarios : monolingual ,   zero - shot cross - lingual andmultilingual low-   resource NER .   3.1 Dataset   We conduct experiments on CoNLL NER   dataset ( Tjong Kim Sang , 2002 ; Tjong Kim Sang   and De Meulder , 2003 ) of four languages where   L= { English ( En ) , German ( De ) , Spanish ( Es ) ,   Dutch ( Nl ) } . For each language ℓ∈L , we first   sample Nsentences from the full training set as   D , where N∈ { 100,200,400,800}to simu-   late different low - resource levels . For a realistic   data split ratio , we also downscale the full develop-   ment set to Nsamples as D. The full test set for   each language is adopted as Dfor evaluation .   Formonolingual experiments on language ℓ   with low - resource level N∈ { 100,200,400,800 } ,   we use Das the gold training data , Das the   development set and Das the test set . For zero-   shot cross - lingual experiments with low - resource   level N∈ { 100,200,400,800 } , we use Das   the source language gold training data , Das   the development set and D , DandDas tar-   get language test sets . Under multilingual settings   where Ntraining data from each language is avail-   able(N∈ { 100,200,400 } ) , we useSDas   the gold training data , SDas the develop - ment set and evaluate on D , D , DandD ,   respectively .   3.2 Experimental Setting   MELM Fine - tuning We use XLM - RoBERTa-   base ( Conneau et al . , 2020 ) with a language-   modeling head to initialize MELM parameters .   MELM is fine - tuned for 20 epochs using Adam   optimizer ( Kingma and Ba , 2015 ) with batch size   set to 30 and learning rate set to 1e−5 .   NER Model We use XLM - RoBERTa-   Large ( Conneau et al . , 2020 ) with CRF   head ( Lample et al . , 2016 ) as the NER model   for our experiments . We adopt Adamw opti-   mizer ( Loshchilov and Hutter , 2019 ) with learning   rate set to 2e−5and set batch size to 16 . The   NER model is trained for 10 epochs and the best   model is selected according to dev set performance .   The trained model is evaluated on test sets and we   report the averaged Micro - F1 scores over 3 runs .   Hyperparameter Tuning The masking rate η   in MELM fine - tuning , the Gaussian mean µfor   MELM generation and the number of MELM aug-   mentation rounds Rare set as 0.7 , 0.5 and 3 , re-   spectively . All of these hyperparameters are tuned   on the dev set with grid search . Details of the hy-   perparameter tuning can be found in Appendix A.1   3.3 Baseline Methods   To elaborate the effectiveness of the proposed   MELM , we compare it with the following methods :   Gold - Only The NER model is trained on only the   original gold training set .   Label - wise Substitution Dai and Adel ( 2020 ) ran-   domly substituted named entities with existing en-   tities of the same entity type from the original train-   ing set .   MLM - Entity We randomly mask entity tokens and   directly utilize a pretrained MLM for data augmen-   tation without fine - tuning and labeled sequence   linearization as used in MELM . The prediction of   a masked entity token does not consider label in-   formation but solely relies on the context words .   DAGA Ding et al . ( 2020 ) firstly linearized NER   labels into the input sentences and then use them   to train an autoregressive language model . The   language model was used to synthesize augmented2255data from scratch , where both context and entities   are generated simultaneously .   MulDA Liu et al . ( 2021 ) fine - tuned mBART(Liu   et al . , 2020 ) on linearized multilingual NER data   to generate augmented data with new context and   entities .   3.4 Experimental Results   3.4.1 Monolingual and Cross - lingual NER   As illustrated on the left side of Table 1 , the pro-   posed MELM consistently achieves the best av-   eraged results across different low - resource lev-   els , demonstrating its effectiveness on monolingual   NER . Compared to the best - performing baselines ,   our MELM obtains 6.3 , 1.6 , 1.3 , 0.38 absolute   gains on 100 , 200 , 400 and 800 levels , respectively .   Cross - lingual NER results are shown on the right   side of Table 2 . Again , on each of the designed low-   resource levels , our MELM is superior to baseline   methods in terms of the averaged F1 scores . We   also notice that , given 100 Nl training samples , the   Gold - Only method without data augmentation al-   most fails to converge while the monolingual F1 of   our MELM reaches 66.6 , suggesting that data aug-   mentation is crucial for NER when the annotated   training data is extremely scarce .   To assess the efficacy of the proposed labeled   sequence linearization ( Section 2.1 ) , we directly   fine - tune MELM on masked sentences without lin-   earization ( as shown in Figure 2b ) , denoted as   MELM w/o linearize in Table 1 . We observe a con-   siderable performance drop compared with MELM ,   which proves the label information injected via lin-   earization indeed helps MELM differentiate differ-   ent entity types , and generate entities compatible   with the original label .   Taking a closer look at the baseline methods , we   notice that the monolingual performance of Label-   wise is still unsatisfactory in most cases . One prob-   able reason is that only existing entities within the   training data are used for replacement and the entity   diversity after augmentation is not increased . More-   over , randomly sampling an entity of the same type   for replacement is likely to cause incompatibility   between the context and the entity , yielding a noisy   augmented sample for NER training . Although   MLM - Entity tries to mitigate these two issues by   employing a pretrained MLM to generate novel   tokens that fit into the context , the generated tokens   might not be consistent with the original labels .   Our MELM also promotes the entity diversity ofaugmented data by exploiting pretrained model for   data augmentation .   In the meantime , equipped with the labeled se-   quence linearization strategy , MELM augmentation   is explicitly guided by the label information and the   token - label misalignment is largely alleviated , lead-   ing to superior results in comparison to Lable - wise   and MLM - Entity .   We also compare with DAGA ( Ding et al . , 2020 ) ,   which generates augmented data from scratch us-   ing an autoregressive language model trained on   gold NER data . Although DAGA is competitive on   low - resource levels of 400 and 800 , it still under-   performs the proposed MELM by a large margin   when the training size reduces to 100 or 200 . We at-   tribute this to the disfluent and ungrammatical sen-   tences generated from the undertrained language   model . Instead of generating augmented data from   scratch , MELM focuses on modifying entity tokens   and leave the context unchanged , which guarantees   the quality of augmented sentences even under ex-   tremely low - resource settings .   3.4.2 Multilingual NER   For multilingual low - resource NER , we firstly di-   rectly apply MELM on the concatenation of train-   ing sets from multiple languages . As shown in   Table 2 , MELM- gold achieves substantial improve-   ment over the Gold - only baseline , which is consis-   tent with monolingual and cross - lingual results . We   compare with MulDA ( Liu et al . , 2021 ) as a base-   line data augmentation method . MulDA generates   augmented data autoregressively with an mBART   model , which is fine - tuned on NER data with in-   serted label tokens . At the low - resource levels in   our experimental settings , MulDA is less effective   and even leads to deteriorated performance . The   unsatisfactory performance mainly results from the   discrepancy between pretraining and fine - tuning   due to the inserted label tokens . Given very few   training samples , it is difficult to adapt mBART to   capture the distribution of the inserted label tokens ,   and thus MulDA struggles to generate fluent and   grammatical sentences from scratch . In compari-   son , our proposed method preserves the original   context and introduce less syntactic noise in the   augmented data . To further leverage the benefits   of code - mixing in multilingual NER , we experi-   ment with two code - mixing methods : ( 1 ) Code-   Mix- random , which randomly substitutes entities   with existing entities of the same type from other   languages , and ( 2 ) Code - Mix- ess , which adopts2256   the proposed entity similarity search algorithm in   Section 2.5 as the code - mixing strategy .   Experimental results in Table 2 show that both   methods are able to achieve improved perfor-   mance over Gold - Only . This observation suggests   that code - mixing techniques , either random code-   mixing or code - mixing via our entity similarity   search , are indeed helpful for multilingual NER .   Comparing these two methods , the performancegains brought by Code - Mix- essare more signifi-   ca nt and consistent across different low - resource   levels , which demonstrates the effectiveness of our   proposed entity similarity search algorithm . Apply-   ing MELM on both gold data and code - mixed data   from Code - Mix- ess , the multilingual NER results   are further improved . In summary , our proposed   MELM is well - suited for multilingual NER , which   can be integrated with our code - mixing technique   to achieve further improvement .   4 Further Analysis   4.1 Case Study   Apart from the quantitative results , we further an-   alyze the augmented data to demonstrate the ef-   fectiveness of our MELM in maintaining the con-   sistency between the original label and the aug-   mented token . Table 3 presents examples of the   top-5 predictions from pretrained MLM , MELM   w/o linearize and MELM . As we can see , the pre-   trained MLM , which does not introduce any design   or contraint on data augmentation , tends to gener-   ate high - frequency words such as “ the ” , “ he ” and   “ she ” , and the majority of generated words do not   belong to the original entity class . Being finetuned   on NER data with entity - oriented masking , MELM2257   w/o linearize is able to generate more entity - related   tokens .   However , without the explicit guidance from en-   tity labels , it is still too difficult for MELM w/o   linearize to make valid predictions solely based on   the ambiguous context ( e.g. , both “ Pompeo ” ( PER )   and “ Reuters ” ( ORG ) are compatible with the con-   text of Example # 2 ) , which leads to token - label   misalignment . Compared to the above methods ,   our MELM take both label information and con-   text into consideration , and thus generates more   entities that fit into the context and align with the   original label as well . Moreover , it is notewor-   thy that MELM can leverage the knowledge from   pretrained model to generate real - world entities   that do not exist in the original NER dataset ( e.g. ,   “ Greenpeace ” and “ Amnesty ” ) , which essentially   increases the entity diversity in training data .   4.2 Number of Unique Entities   As demonstrated in Lin et al . ( 2020 ) and our pre-   liminary experiments in Figure 1 , introducing un-   seen entities can effectively provide more entity   regularity knowledge , and helps to improve NER   performance . Therefore , we examine the amount   of unique entities introduced by different methods .   As there might be token - label misalignment in the   augmented data , we firstly train an ‘ oracle ’ NER   model on the full CoNLL dataset and then use it   to tag training data of MELM and different base-   line methods . For each method , we count the total   number of unique entities whose labels match the   labels assigned by the ‘ oracle ’ model . As shown   in Figure 4 , while many augmented entities from   MLM - Entity , DAGA and MELM w/o linearize are   filtered out due to token - label misalignment , we   note that MELM introduces a significantly larger   number of unseen entities in the augmented data .   Therefore MELM is able to provide richer entity   regularity knowledge , which explains its superior-   ity over the baseline methods .   5 Related Work   On sentence level tasks , one line of data augmen-   tation methods are built upon word - level mod-   ifications , which can be based on synonym re-   placement ( Wei and Zou , 2019 ) , LSTM language   model ( Kobayashi , 2018 ) , MLM ( Wu et al . , 2019 ;   Kumar et al . , 2020 ) , auto - regressive pretrained   LM ( Kumar et al . , 2020 ) , or constituent - based   tagging schemes ( Zhong et al . , 2020 ) . However ,   these methods suffer from token - label misalign-   ment when applied to token - level tasks such as   NER , which requires sophisticated post - processing   to remove noisy samples in augmented data ( Bari   et al . , 2021 ; Zhong and Cambria , 2021 ) .   Existing works avoid token - label misalignment   by replacing entities with existing entities of the   same class ( Dai and Adel , 2020 ) , or only modifying   context works and leaving entities / aspect terms   unchanged ( Li et al . , 2020a ) . Others attempt to   produce augmented data by training / fine - tuning2258a generative language model on linearized labeled   sequences ( Ding et al . , 2020 ; Liu et al . , 2020 ) .   Backtranslation ( Sennrich et al . , 2016 ; Fadaee   et al . , 2017 ; Dong et al . , 2017 ; Yu et al . , 2018 )   translates source language sentences into a target   language , and subsequently back to the source lan-   guage , which preserve the overall semantics of the   original sentences . On token - level tasks , however ,   they hinge on external word alignment tools for la-   bel propagation , which are often error - prone ( Tsai   et al . , 2016 ; Li et al . , 2020b ) .   6 Conclusion   We have proposed MELM as a data augmentation   framework for low - resource NER . Through labeled   sequence linearization , we enable MELM to explic-   itly condition on label information when predicting   masked entity tokens . Thus , our MELM effectively   alleviates the token - label misalignment issue and   generates augmented data with novel entities by ex-   ploiting pretrained knowledge . Under multilingual   settings , we integrate MELM with code - mixing for   further performance gains . Extensive experiments   show that the proposed framework demonstrates   encouraging performance gains on monolingual ,   cross - lingual and multilingual NER across various   low - resource levels .   Acknowledgements   This research is partly supported by the Alibaba-   NTU Singapore Joint Research Institute , Nanyang   Technological University . Erik Cambria would   like to thank the support by the Agency for Sci-   ence , Technology and Research ( A*STAR ) under   its AME Programmatic Funding Scheme ( Project   # A18A2b0046 ) .   References225922602261A Appendix   A.1 Hyperparameter Tuning   Masking hyperparameters . To determine the opti-   mal setting for fine - tune mask rate ηand generation   masking parameter µ , we conduct a grid search on   both hyperparameters in range [ 0.3,0.5,0.7 ] . We   finetune MELM and generate English augmented   data on CoNLL following our method in Section 2 .   The augmented data is used to train a NER tagger   and its performance on English dev set is recorded .   As shown in Table 4 , we achieve the best dev set   F1 when η= 0.7andµ= 0.5 , which is adopted   for the rest of this work .   η   0.3 0.5 0.7   0.3 76.90 75.64 78.08   µ0.5 76.16 78.06 78.56   0.7 75.94 78.09 78.37   Number of augmentation rounds . Merging aug-   mented data from multiple rounds increase entity   diversity until it saturates at certain point . Con-   tinuing adding in more augmented data begins to   amplify the noise in augmented data and leads to   decreasing performance . To determine the opti-   mum number of augmentation rounds R , we merge   different amount of augmented data with English   gold data to train a NER tagger , with Rranging   from 1 to 6 . As shown in Table 5 , dev set F1 in-   creases with increasing amount of augmented data   untilR=3 , and starts to drop further beyond . There-   fore , we choose R= 3for all of our experiments .   A.2 Statistics for Reproducibility   In this section , we present the validation F1 av-   eraged among 3 runs of MELM under different   languages and low - resource levels . We also sum-   marize the estimated time for fine - tuning MELM   and the number of parameters used . We separately   show the statistics of monolingual ( Table 6 ) , cross-   lingual ( Table 7 ) and multilingual ( Table 8) NER .   A.3 Computing Infrastructure   Our experiments are conducted on NVIDIA V100   GPU.2262