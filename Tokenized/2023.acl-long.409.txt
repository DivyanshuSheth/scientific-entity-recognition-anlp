  Xiudi ChenHui WuXiaodong ShiDepartment of Artificial Intelligence , School of Informatics , Xiamen University , ChinaNational Institute for Data Science in Health and Medicine , Xiamen University , ChinaKey Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural   Heritage of Fujian and Taiwan ( Xiamen University ) , Ministry of Culture and Tourism , China   { chenxiudi,huistudent}@stu.xmu.edu.cn , mandel@xmu.edu.cn   Abstract   Few - shot continual relation extraction aims to   continually train a model on incrementally few-   shot data to learn new relations while avoid-   ing forgetting old ones . However , current   memory - based methods are prone to overfit-   ting memory samples , resulting in insufficient   activation of old relations and limited ability   to handle the confusion of similar classes . In   this paper , we design a new N - way- K - shot   Continual Relation Extraction ( NK - CRE ) task   and propose a novel few - shot continual relation   extraction method with Consistent Prototype   Learning ( ConPL ) to address the aforemen-   tioned issues . Our proposed ConPL is mainly   composed of three modules : 1 ) a prototype-   based classification module that provides pri-   mary relation predictions under few - shot con-   tinual learning ; 2 ) a memory - enhanced mod-   uledesigned to select vital samples and re-   fined prototypical representations as a novel   multi - information episodic memory ; 3 ) a con-   sistent learning module to reduce catastrophic   forgetting by enforcing distribution consistency .   To effectively mitigate catastrophic forgetting ,   ConPL ensures that the samples and prototypes   in the episodic memory remain consistent in   terms of classification and distribution . Ad-   ditionally , ConPL uses prompt learning to ex-   tract better representations and adopts a focal   loss to alleviate the confusion of similar classes .   Experimental results on two commonly - used   datasets show that our model consistently out-   performs other competitive baselines .   1 Introduction   Continual relation extraction ( CRE ) aims to con-   tinually train a model on new data to learn new   relations while avoiding forgetting old relations .   Due to its wide applicability to real - world applica-   tions , CRE has attracted increasing attention ( Oba-   muyide and Vlachos , 2019 ; Han et al . , 2020 ; ZhaoFigure 1 : The scatter plot that reflects the relation-   ship between distortion and forgetting in four methods ,   namely EMAR ( Han et al . , 2020 ) , RP - CRE ( Cui et al . ,   2021 ) , ERDA ( Qin and Joty , 2022 ) and our proposed   ConPL . The abscissa “ distortion ” indicates the degree   of change in feature embedding , and the ordinate “ for-   getting ” indicates the degree of forgetting . Each point   on the plot represents a prototype of a relation class .   The detailed calculations are shown in Appendix A.1 .   et al . , 2022 ) . Most existing studies adopt memory-   based approaches as the principal architecture and   achieve great success in CRE . For example , Cui   et al . ( 2021 ) employ relation prototype to extract   useful information of each relation . Wang et al .   ( 2022 ) adopt a simple yet effective adversarial class   augmentation mechanism to learn more precise   and robust representations . However , obtaining   large labeled data can be time - consuming and ex-   pensive . Qin and Joty ( 2022 ) introduce continual   few - shot relation learning ( CFRL ) and propose a   novel method of embedding space regularization   and data augmentation . But , the first task in the   CFRL setting still involves a substantial amount of   training data , and the evaluation results obtained in   this setting may not completely reflect the perfor-   mance of the model under true continual few - shot7409learning conditions . This is because a portion of   the test set is drawn from the first task , which can   lead to a big gap between the results obtained in   the CFRL setting and those obtained under true   continual few - shot relation learning conditions .   To this end , we propose the N - way- K - shot   Continual Relation Extraction ( NK - CRE ) , which   strictly adheres to the N - way K - shot few - shot set-   ting and all classes contain only a small amount   of labeled instances . In the NK - CRE setting , we   employ existing CRE methods to conduct a series   of experimental analyses for few - shot continual   relation learning , as illustrated in Figure 1 . We   observe that existing CRE methods , particularly   ERDA , exhibit significant distortion and forgetting .   Additionally , we find that the prototype distortion   is highly relevant to forgetting in NK - CRE . Based   on these findings , we hypothesize that reducing   the prototype distortion can greatly mitigate catas-   trophic forgetting in NK - CRE . However , existing   CRE methods in the NK - CRE setting face the chal-   lenge of overfitting the memory samples due to   the limited memory available , leading to insuffi-   cient activation of the old relations and resulting in   significant distortion and forgetting .   Besides , the confusion of similar classes is   also a major cause of catastrophic forgetting in   CRE ( Wang et al . , 2022 ) , which is particularly   acute in NK - CRE . For instance , the prototype   embeddings of similar classes , like “ father ” and   “ mother ” , tend to be highly similar due to their sim-   ilar context and entity pairs . When “ father ” has al-   ready been learned in a previous task and “ mother ”   is shown in a new task , the model prioritizes learn-   ing the representation of the current class “ mother ” ,   but may disregard the subtle differences between   “ mother ” and “ father ” , leading to catastrophic for-   getting .   To deal with the above issues , we propose   a novel Consistent Prototype Learning ( ConPL )   method for few - shot continual relation extraction   in order to effectively activate old relations and   mitigate catastrophic forgetting . ConPL consists of   three primary modules : 1 ) a prototype - based classi-   fication module , which leverages prompt learning   to extract better relation representations and utilizes   temporary prototypes constructed from new task   data and several distance metric - based losses forbasic classification ; 2 ) a memory - enhanced mod-   ule that comprises sample memory for storing vital   labeled samples and prototype memory for stor-   ing optimal prototype representations ; 3 ) a consis-   tent learning module that addresses the problem of   unbalanced distribution of new and old relations   through consistency learning between sample dis-   tribution . In addition , we introduce a focal loss   to mitigate the impact of the confusion of similar   classes on catastrophic forgetting . This loss func-   tion allows the model to focus on the training of   similar classes , enabling it to pay more attention to   the distinctions between similar classes and reduc-   ing the impact of confusion .   In this study , experimental results of FewRel and   TACRED datasets in the NK - CRE setting demon-   strate that ConPL outperforms existing models   by a significant margin . Further , ablation exper-   iments show that each component of our method   contributes to its effectiveness . Our analysis also   reveals that ConPL not only significantly reduces   the distortion of class prototypes , but also effec-   tively minimizes catastrophic forgetting . Overall ,   our ConPL offers a robust and effective approach   to few - shot continual relation extraction .   2 Related Work   Continual Learning , also known as lifelong learn-   ing and incremental learning , is the process of train-   ing models to perform well on task streams with   different data distributions . Its main methods can   be divided into three categories : ( i ) regularization-   based methods ( Kirkpatrick et al . , 2017 ; Zenke   et al . , 2017 ) ; ( ii ) architecture - based methods ( Fer-   nando et al . , 2017 ; Wortsman et al . , 2020 ) ; and   ( iii ) memory - based methods ( Rolnick et al . , 2019 ;   Cha et al . , 2021 ) . Memory - based methods , also   called rehearsal - based methods , have been shown   to be particularly suitable for natural language pro-   cessing ( NLP ) , especially for CRE ( Wang et al . ,   2019 ; Han et al . , 2020 ; Cui et al . , 2021 ; Zhao et al . ,   2022 ) . These methods selectively store old sam-   ples in limited memory , training them with new   samples to prevent catastrophic forgetting . For ex-   ample , EMAR ( Han et al . , 2020 ) utilizes relation   prototypes for memory reconsolidation exercises .   RP - CRE ( Cui et al . , 2021 ) uses prototypes of all   observed relations to refine subsequent sample em-   beddings . CRECL ( Hu et al . , 2022 ) builds a clas-   sification network and a prototypical contrastive   network . However , these methods only compute7410temporary prototypes before training a new task   and store memory samples , which can lead to sig-   nificant distortion and forgetting as the number of   tasks increases . In contrast , our approach stores   prototypes in memory without modification .   Few - shot Learning aims to address the overfitting   issue that may arise when there is a limited amount   of labeled training data for model training . Exist-   ing methods can be divided into two categories : ( i )   data - based ( Tsai and Salakhutdinov , 2017 ; Benaim   and Wolf , 2018 ) ; and ( ii ) meta learning - based , in-   cluding optimization - based algorithm ( Finn et al . ,   2017 ) and metric - based algorithm . Among them ,   prototypical network ( Snell et al . , 2017 ) is a simple   yet efficient metric - based approach and has become   the most mainstream method in few - shot relation   extraction ( Yang et al . , 2020 ; Qu et al . , 2020 ; Han   et al . , 2021a ) . In this paper , our method is built on   the prototypical network and proposes storing class   prototypes in memory .   Prompt Learning is a simple yet effective   method for fine - tuning pre - trained language mod-   els ( PLMs ) , which uses prompt information to en-   rich the input and enable better mining of prior   knowledge in PLMs . According to the pre - training   objectives , the structure of prompts is mainly di-   vided into two types : ( i ) adding the task descrip-   tion before the input , e.g. , the generative model   GPT-3 ( Brown et al . , 2020 ) ; and ( ii ) formalizing   downstream tasks into cloze - style tasks , e.g. , the   discriminative model BERT ( Devlin et al . , 2018 ) .   According to different forms of expression , prompt   can be divided into continuous ( Lester et al . , 2021 ;   Vu et al . , 2022 ) and discrete ( Schick et al . , 2020 ;   Han et al . , 2021a ) . Continuous prompts are com-   posed of vectors and the optimal prompt embed-   ding can be learned automatically by the model ,   while discrete prompts are manually constructed   by people based on their experience . For relation   extraction , several works ( Han et al . , 2021b ; Chen   et al . , 2022 ) have investigated the utilization of the   prior knowledge of PLMs through prompt learning ,   which has been shown to be effective in few - shot   learning . In this paper , we use discrete prompts   with cloze - style to extract better representations in   few - shot CRE .   3 Problem Formulation   N - way- K - shot Continual Relation Extraction ( NK-   CRE ) is a continual relation learning task in the N-   way K - shot setting scenario , which aims to continu - ally train the model on new tasks to learn new rela-   tions while avoiding forgetting previously learned   ones under the few - shot scenario . Compared to   CFRL ( Qin and Joty , 2022 ) , NK - CRE strictly ad-   heres to the N - way K - shot setting , which is more   challenging yet more representative of real - world   applications .   In NK - CRE , the model is trained on a se-   quence of tasks / braceleftbig   T , T , . . . , T / bracerightbig   , where each   taskT(k∈[1 , . . . , n ] ) has its own training set   D , test set Dand corresponding relation   setR. Each dataset D={(x , y)}contains   Nclasses and Ksamples of each class , where each   sample ( x , y)consists of a sentence xwith a pair   of entities ( e , e)and a relation label y∈R   of the entity pair , and Nis the number of cur-   rent relations in R. After being trained on T   at the k - th task to learn the new relations R , the   model will be evaluated on the test sets of previous   ktasks ˆD=∪Dto verify the discrimi-   nant ability of the model for all known relations   ˆR=∪R.   Different from the memory used in previous   works ( Han et al . , 2020 ; Cui et al . , 2021 ; Qin and   Joty , 2022 ) , we propose a novel multi - information   episodic memory M=/braceleftbig   M , M , . . ./bracerightbig   to alle-   viate catastrophic forgetting in continual learning ,   where Mconsists of the most informative sam-   plesSand prototype representations Pcorre-   sponding to relations RinT. Although each   relation in the memory can store multiple samples ,   we store a sample per relation under a limited ca-   pacity . After the k - th task is trained , the memory   Mcontains sample set ˆS=∪Sand proto-   type set ˆP=∪Pof the previous ktasks .   4 Methodology   In this section , we elaborate on our proposed   method ConPL , which is composed of three mod-   ules : a prototype - based classification module ( Sec-   tion 4.1 ) , a memory - enhanced module ( Section   4.2 ) , and a consistent learning module ( Section 4.3 ) .   Prototype - based classification module is the ba-   sic component of ConPL . Memory - enhanced mod-   ule introduces a novel multi - information episodic   memory equipped with some samples and corre-   sponding prototypical representations . Consistency   learning module adds an extended training process   to balance the predictions of all known relations .   Finally , we give a detailed description of the overall   training procedure ( Section 4.4).74114.1 Prototype - Based Classification Module   Encoder . Given a sentence xwith a head en-   tityeand a tail entity e , we choose BERT ( De-   vlin et al . , 2018 ) as the encoder with parameters   θto obtain the relational representation of entity   pairs in x. Specifically , we firstly enrich the sen-   tence xinto a specific input sequence x =   { [ CLS ] , e,[MASK ] , e,[SEP ] , x,[SEP]}based   on the prompt learning ( Han et al . , 2021b ; Chen   et al . , 2022 ) , and then encode the input sequence   by the encoder to obtain the contextualized repre-   sentation . Here we use the vector representation of   the special token [ MASK ] as the relational repre-   sentation .   h = f(x ) ( 1 )   For simplicity , we will use xto refer to the spe-   cific input sequence x.   Initializing temporary prototypes of new classes .   When firstly training on the k - th new task to learn   new relations , we use all samples of each new re-   lation in the current task to construct prototypi-   cal representations for the corresponding classes .   Specifically , we encode all samples in D , and   then use an aggregation operator ( such as averag-   ing ) to aggregate the embeddings of samples from   the same class to calculate the prototypical repre-   sentation pof each class .   p=1   |D|/summationdisplayf(x ) ( 2 )   where D=/braceleftbig   ( x , y)|(x , y)∈D , y = r / bracerightbig   ,   |D|is the number of samples and prepresents   the prototypical representation of r(r∈R )   in the new task . So the temporary prototypes of   current new task is ˜P=/uniontextp . Based on   previous relation prototypes ˆPof the memory ,   we can get all current prototypes ¯P=ˆP∪˜Prelated to all classes we have seen .   Prototype classifier with experience replay . To   learn new relations while retaining existing rela-   tion knowledge , we use the experience replay totrain the model on the new train dataset ¯D =   D∪ˆS , which combine the training samples   of the k - th task with the samples of the previous   k−1tasks in the memory . The relation distribution   for each sample xis computed as :   p(r|x ) = exp ( d(f(x),p ) )   /summationtextexp ( d(f(x),p))(3 )   where d ( . , .)represents the distance measurement   formula by the cosine similarity , pis the prototyp-   ical representation of r(r∈ˆR)in¯P , and|ˆR|   is the number of all known relations in previous k   tasks .   Thecross entropy loss Lfor classification is   calculated in a distance measurement way .   L=−/summationdisplaylogp(r|x)(4 )   In order to wake up the old relational knowledge ,   we propose the classification consistency loss L   to focus on the consistent correlation between the   feature of each sample in ˆSand the correspond-   ing prototypical representation in ˆPbased on   current memory .   L=/summationdisplay∥f(x)−p∥ ( 5 )   Considering the different correlation between   the new relations and previous relations ( e.g. ,   the relation “ mother ” in the new task and pre-   vious relations “ father ” / “ spouse ” belongs to   greatly similar relations . ) , we select similar classes   to highlight their distinction . Specifically , we   start by obtaining the most similar negative   prototype p= argmax ( d(f(x),p))for   each sample x , which is the prototype of the   most likely relation of miscalculation . Next ,   we set a threshold αand automatically screen   some confusing negative prototypes ˆp=   { p|d(f(x),p)−d(f(x),p ) < α}that   include prototypes that are the most similar to the   prototype pwith the target relation . Here p   andprefer to any prototype other than p , so   p̸=pandp̸=p . The distribution of xis   computed for distinguishing similar classes .   p(r|x ) = exp ( d(f(x),p ) )   /summationtextexp ( d(f(x),p))(6 )   where P= [ p;p;ˆp]represents the set of   prototypes similar to the output feature of xand   |P|is the number.7412Therefore , we adopt the focal loss to alleviate   the difficulty in predicting similar classes .   L=−/summationdisplaylogp(r|x)(7 )   4.2 Memory - Enhanced Module   Compared to previous memory - based methods   ( Han et al . , 2020 ; Cui et al . , 2021 ; Qin and Joty ,   2022 ) , we add prototypical representations into the   episodic memory for enriching the old relations .   So the memory of our model is separated into two   parts : the Sample Memory ˆS , which is used to   store samples with class labels , and the Prototype   Memory ˆP , which is used to store feature embed-   dings of class prototypes .   For the sample memory , we calculate the proto-   typical representation of each relation in the current   taskTbased on Eq ( 2 ) , and then select some clos-   est samples as the typical samples to store them   inS , where each relation of Tonly stores one   typical sample . During training , prototypical repre-   sentations computed by all relation samples can be   unstable . Therefore , once the typical samples are   determined , we use the feature representations of   the selected typical samples to update prototypical   representations of the current task and store their   feature representations in prototype memory P   afterTis trained .   4.3 Consistent Learning Module   Considering the unbalanced distribution of new re-   lations and old ones in the training dataset ¯D ,   we add an extended training step that solely fo-   cuses on the memory Mthat helps to balance the   learning of all known relations and distinguish new   and old relations . Therefore , we propose the dis-   tribution consistency loss Lvia computing the   consistent constraint between the sample distribu-   tion and the prototype distribution .   L=/summationdisplay / vextenddouble / vextenddouble / vextenddoubled / parenleftig   f(x),ˆP / parenrightig   −d / parenleftig   p,ˆP / parenrightig / vextenddouble / vextenddouble / vextenddouble   ( 8)   4.4 Learning Procedure   Joint training objective . We adopt a three - stage   training strategy to train our model . The overall   training objective of the first two stages is com-   puted as follows .   L = λL+λL+λL ( 9)Algorithm 1 Training Process for the k - th task .   And the overall training objective of the third stage   is defined as follows .   L = λL+λL+λL+λL(10 )   where λ , λ , λandλare the relative weights   of the component losses , respectively . It is note-   worthy that the training set of the different stages is   different . The first stage adopts the sample memory   ˆS. After storing the sample memory Sof the   k - th task , the second and third stages use ˆSfor   training .   Training procedure . The overall training proce-   dure is summarized in Algorithm 1 . In the first   stage , we use all samples of each class in D   to obtain the prototype representation ˜Pof all   classes in R. And then based on all prototype   ¯P=ˆP∪˜P , the sample memory ˆS , and   the current training set ¯D = D∪ˆS ,   we let the model learn the knowledge of the new   classes ( line 1 - 8) . In the second stage , we firstly   select key samples Sclosest to the center of7413each class and store them in the sample memory   ˆS=ˆS∪S , and use Sto construct new   prototype Pof the new classes for subsequently   training with ¯P=ˆP∪P(line 9 - 17 ) . In the   third stage , we only useˆSto predict all known   relations and further ensure that the output of the   samples in memory is consistent with their stored   features ( line 18 - 22 ) .   5 Experiments   5.1 Datasets   In line with previous work ( Qin and Joty , 2022 ) ,   our experiments will be conducted on two com-   monly used datasets , FewRel ( Han et al . , 2018 )   andTACRED ( Zhang et al . , 2017 ) . For NK - CRE ,   we evaluate our method under three different few-   shot settings of FewRel , namely 10 - way- 2 - shot , 10-   way-5 - shot , and 10 - way- 10 - shot , and two different   few - shot settings of TACRED , namely 5 - way- 5-   shot and 5 - way- 10 - shot . The detailed introduction   of two datasets is shown in Appendix A.2 .   5.2 Evaluation Methods   After training the model on the k - th task , we use   thewhole accuracy metric to evaluate the model ’s   performance on the union of the test sets of previ-   ousktasks ˆD=∪D. This metric is used   to evaluate the model ’s ability to alleviate catas-   trophic forgetting while acquiring new knowledge   with a few - shot new task .   In addition , we also measure the degree of catas-   trophic forgetting using the forgetting metric pro-   posed by Chaudhry et al . ( 2018 ) . The forgetting   metric measures the degree to which the model has   forgotten previously learned knowledge after train-   ing on new tasks . Specifically , after training on all   the tasks , the authors measure the model ’s perfor-   mance on the test sets of all the previous tasks . The   specific formula for forgetting is as follows :   F=1   n−k / summationdisplayg(11 )   g= maxa−a ( 12 )   where F(k∈[1 , . . . , n −1])represents the for-   getting of the k - th task after all tasks have been   trained , a(j > k ) is the accuracy of the model   on the k - th task after the j - th task training is com-   pleted , and gis the forgetting of the k - th task after   thej - th task training is completed . Considering that the order of task sequences will   affect the final performance of the model , we ran-   domly generate 6task sequences for experiments   and calculate their average accuracy as the final re-   sult . To ensure a fair comparison between the base-   lines and the proposed method , we set the same   random seed for the baselines and our proposed   method to ensure that they are evaluated on the   same set of task sequences .   5.3 Baselines   We compare our proposed method with the follow-   ing baselines :   EMAR ( Han et al . , 2020 ): A classical method   for continual relation learning , which uses relation   prototypes for memory reconsolidation exercise to   keep a stable understanding of the old relations .   RP - CRE ( Cui et al . , 2021 ): A method for contin-   ual relation learning , where prototype embeddings   are computed based on memorized samples and are   used to re - initialize a memory network to refine   subsequent sample embeddings .   ERDA ( Qin and Joty , 2022 ): A SOTA method   for continual few - shot relation learning ( CFRL )   that employs embedding space regularization and   data augmentation to improve model performance .   Considering that PLMs ( e.g. , BERT ) have been   shown to outperform Bi - LSTM on many NLP tasks ,   we replace the Bi - LSTM with BERT to reproduce   the baselines we mentioned . Furthermore , recent   advances in Prompt Learning have shown great per-   formance on many NLP tasks , by enabling models   to learn from prompt - based examples and generate   coherent outputs . Therefore , we construct prompt   templates at the input to generate their variants   EMAR(PT ) , RP - CRE(PT ) , and ERDA(PT ) for   better comparison .   5.4 Training Details   During training , we use BERT ( Devlin et al . ,   2018 ) as the encoder and Adam optimizer with a   learning rate of 2efor gradient updates . To pre-   vent gradient overflow , we set the gradient clipping   value to 10 . The loss weights λ , λ , λandλ   are all set to 1.0 , and αis set to 0.1 . In Algorithm   1,epochandepochare set to 1 , and epochis   set to 3 .   5.5 Main Results   Table 1 presents the whole accuracy of the FewRel   benchmark in the 10 - way-5 - shot setting and the   TACRED benchmark in the 5 - way-5 - shot setting.7414   Based on the main results of NK - CRE , we can   observe that :   ( 1)Prompt learning can obtain better seman-   tic representations and improve model perfor-   mance in few - shot scenarios . Baselines with PT   can achieve the desired effect directly on each task   in NK - CRE , particularly for the first task , with-   out the need for training on a large amount of la-   beled data like CFRL ( Qin and Joty , 2022 ) . On the   FewRel ’s 10 - way-5 - shot , EMAR(PT ) is 12.78 %   higher than EMAR after learning the first task using   the 5 - shot setting and 3.25 % higher than EMAR   after learning the first task with a large amount of   labeled data . Notably , our method ConPL achieves   the highest performances in most of the tasks . In   the first task , our method ConPL achieves the accu-   racy of 95.72 % , which was slightly lower than the   accuracy achieved by ERDA(PT ) at 96.55 % . How-   ever , it is worth noting that ERDA(PT ) leverages   external Wikipedia sentences for data augmenta-   tion , which may account for its slightly superior   performance . On the TACRED ’s 5 - way-5 - shot ,   ConPL achieves the highest performance on all   tasks.(2)Consistent prototype learning with multi-   information memory can significantly improve   model performance in NK - CRE . When faced   with multiple tasks ( T2 ∼T8 ) , Our method ConPL   significantly outperforms all existing methods on   FewRel ’s 10 - way-5 - shot and TACRED ’s 5 - way-   5 - shot . Compared with all baselines , ConPL ob-   tains the highest improvement reaching 26.48 %   of FewRel ’s 10 - way-5 - shot and 41.19 % of TA-   CRED ’s 5 - way-5 - shot after learning all tasks .   More specifically , the performance obtained by our   ConPL at T8 is better than that of EMAR(PT ) at   T6 , RP - CRE(PT ) and ERDA(PT ) at T4 . It proves   that our consistent prototype learning strategy is   highly effective .   Moreover , we present more detailed results in   Table 1 in Appendix A.3 , including the means and   variances of all sequential results . In T1 ∼T8 of   FewRel ’s 10 - way-5 - shot , the mean deviations of   MEAR(PT ) , RP - CRE(PT ) , ERDA(PT ) , and our   ConPL are 2.76%,1.92%,5.27 % , and 1.50 % re-   spectively , which indicate that our method ConPL   is more stable than other baselines . In addition ,   Figure 2 presents the results of FewRel ’s 10 - way-7415   2 - shot , FewRel ’s 10 - way-10 - shot , and TACRED ’s   5 - way-10 - shot . These results also show the effec-   tiveness of our ConPL .   5.6 Ablation Study   We conduct ablation experiments on the FewRel ’s   10 - way-5 - shot from two aspects of the utilization   of memory and auxiliary tasks to verify the con-   tribution of each component in our method and   study the impact on model performance by remov-   ing one module at a time . Utilization of Memory   includes ( a ) without the Prototype Memory ( PM ) ,   ( b ) without the Consistent Learning Module ( CL ) ,   andAuxiliary Tasks includes ( c ) only removing   the classification consistency loss L , ( d ) only re-   moving the distribution consistency loss L , and   ( e ) only removing the focal loss L. The results   of our ablation experiments are shown in Table 2 .   We observe that each component in our method   contributes to the overall performance .   In Utilization of Memory , Prototype Memory   ( PM ) brings a 3.56 % boost after training on all   tasks , demonstrating the strong effectiveness of   our novel multi - information episodic memory . The   Consistent Learning Module ( CL ) gains a 1.52 %   improvement . Also , we find that training without   CL requires fewer epochs than EMAR , ERDA , and   RP - CRE , but outperforms these with PT by 2.91 % ,   7.23 % , and 3.38 % . The performance of T1 with-   out CL is 0.71 % higher than ConPL , as there is no   catastrophic forgetting in the first task , causing the   model to overfit on memory . Memory augmenta-   tion in T1 could reduce the diversity of the training   samples , which leads to lower performance .   In Auxiliary Tasks , The classification consis-   tency loss Land the distribution consistency loss   Lhave a relatively small impact , with only 0.08 %   and0.37 % improvement , respectively . However ,   whenLandLuse sample memory to calculate   probabilities , they can bring significant improve-   ment . We will elaborate on this phenomenon in   5.7 . In addition , we observe that the focal loss L   brings the most significant 10.66 % improvement   to the model ’s performance , demonstrating the im-   portance of effectively dealing with the confusion   of similar classes . Moreover , Figure 3 displays the   t - SNE visualization results of the high similarity re-   lations “ father ” and “ mother ” , which show that our   focal loss significantly improves the ability of the   model to distinguish similar classes in NK - CRE .   5.7 Importance of Consistency Loss   To demonstrate the importance of the classifica-   tion consistency loss and the distribution consis-   tency loss , we conduct an analysis experiment on   FewRel ’s 10 - way-5 - shot . Specifically , we replace   the use of prototype memory with sample memory7416   to calculate probabilities in LandL , which is a   common prototype calculation method . In this case ,   we re - selected better hyperparameters and adjusted   the relative weights λandλto 2 and 5 , respec-   tively . The ablation experiment is re - performed   on ( d ) and ( e ) in 5.6 , and the results are shown in   Figure 4 . The classification consistency loss and   the distribution consistency loss improve by 0.73 %   and2.0%respectively after T8 . We think that due   to the probabilities of LandLbeing computed   by prototype memory , the model can learn correct   classifications and inter - class discrepancy , leading   to a relatively small improvement from the two   consistency losses . However , when using sample   memory to calculate probabilities , these two con-   sistency losses can result in significant gains .   5.8 Forgetting   To provide a more intuitive comparison when test-   ing forgetting , we added two baselines as lower   and upper bounds .   SeqRun serves as a lower bound , where the   model is directly fine - tuned on the new task data   without using past data , leading to severe catas-   trophic forgetting .   JointTrain serves as an upper bound , where   all training data for each new task , including previ-   ously seen data , is stored in the memory .   The forgetting of each task and their average for-   getting on FewRel benchmark ’s 10 - way-5 - shot are   presented in Table 3 , along with the average for-   getting on Fewrel ’s 10 - way-2 - shot , and TACRED ’s   5 - way-5 - shot in Figure 5 . These results show that :   ( 1 ) The use of Prompt learning can significantly   mitigate the issue of catastrophic forgetting .   ( 2 ) Compared with existing methods , our   method greatly mitigates catastrophic forgetting   in continual learning , which is crucial .   ( 3 ) Observing JointTrain , we find that forget-   ting still exists even when all the training data is   available , and our continual learning method is the   closest to it among all methods .   6 Conclusion   We introduce N - way- K - shot Continual Relation   Extraction ( NK - CRE ) , a novel problem in the   realm of continual relation extraction , where all   tasks are conducted in the N - way K - shot setting   scenario . This problem presents a significant chal-   lenge , yet is highly applicable in real - world sce-   narios . To address this problem , we propose   Consistent Prototype Learning ( ConPL ) , a novel   method that effectively alleviates catastrophic for-   getting caused by insufficient activation of old re-   lations and the confusion among similar classes .   Through a series of experimental and analytical   results , we demonstrate that ConPL outperforms   existing methods in NK - CRE . In future research ,   we plan to study how to improve the domain adapt-   ability of the model in few - shot continual relation   extraction.7417Limitations   There are two limitations in this paper : ( 1 ) Com-   pared with existing memory - based methods , the   proposed prototype memory may bring additional   storage space overhead . But since we only require   very little additional memory ( only one vector per   class ) , we did not discuss it ; ( 2 ) Although we noted   that the distortion and forgetting of the prototype   are highly correlated , we did not conduct a detailed   analysis of the reasons for special prototypes that   do not follow this pattern .   Acknowledgements   We would like to express our gratitude to the anony-   mous reviewers for their valuable feedback and   suggestions , which have significantly improved the   quality of our work . This research is supported by   the Key Support Project of NSFC - Liaoning Joint   Foundation ( No . U1908216 ) and the Major Scien-   tific Research Project of the State Language Com-   mission in the 13th Five - Year Plan ( No . WT135-   38 ) .   References7418   A Appendix   A.1 Prototype Distortion and Forgetting   To evaluate the relationship between the change of   feature embeddings and the degree of forgetting ,   we introduce distortion and forgetting metrics for   each class prototype . Distortion is calculated using   the following formula :   D=1   n−i / summationdisplayd ( 13 )   d= 1−s(e , e ) ( 14 )   where iofemeans that the relation rfirstly ap-   pears in task iandedenotes the embedding of   the relation rafter task iis trained . srepresents the   calculation formula of cosine similarity . Drefers   to the mean value of the distortion for relation r   from task ito task n.7419   The formula for the forgetting of the prototype   is as follows :   F=1   n−i / summationdisplayg ( 15 )   g= maxa−a ( 16 )   where arepresents the whole accuracy of the   test set for relation rafter the task lis trained , f   represents the degree of forgetting of relation r   after task jis trained , and irepresents the relation   rfirstly appears in task i.   Based on the above formulas , we calculate the   distortion and forgetting of each prototype in differ-   ent methods . Considering that the order of task se-   quences has a relatively large impact on the change   of embedding and forgetting of each class , we ran-   domly generate 50 task sequences and show their   average results . Figure 1 illustrates the correlation   between the embedding distortion and the degree   of forgetting in different methods .   A.2 Datasets   The following is the detailed introduction of the   FewRel ( Han et al . , 2018 ) and TACRED ( Zhang   et al . , 2017 ) datasets .   FewRel is a few - shot relation classification   dataset that was proposed by Han et al . ( 2018 ) . It   consists of 100relation classes , each of which has   700instances . The dataset is split into a training   set , a validation set , and a test set , with a split of   64/16/20fraction corresponding to each set . Fol-   lowing CFRL ( Qin and Joty , 2022 ) , we randomly   divide the publicly accessible 80relations from the   training and validation sets into 8tasks , each con-   taining 10relations ( 10 - way ) . In this paper , we set2 - shot , 5 - shot , and 10 - shot as different few - shot   settings in the NK - CRE benchmark .   TACRED is a relation extraction dataset that   was proposed by Zhang et al . ( 2017 ) . It contains 42   relations and over 100,000instances . The dataset   is preprocessed by filtering out the special relation   “ n / a ” , resulting in the remaining 41relation classes   and68,438instances to construct the NK - CRE   benchmark . Similar to FewRel , we divide the 41   relations into 8 tasks , with one task containing 6   relations and the others containing 5 relations ( 5-   way ) . We set 5 - shot and 10 - shot as different few-   shot settings in this paper .   A.3 Main Results with Means and Variances   Table 4 shows the whole accuracy ( % ) and variance   of different methods after training for each task on   FewRel ’s 10 - way-5 - shot . We observe that due to   the strict implementation of the few - shot contin-   ual learning task , NK - CRE has a larger variance   compared to CFRL . Nonetheless , the average vari-   ance of our method ConPL is still lower than that   of existing methods in CFRL , indicating that our   method is robust.7420ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   Limitations   /squareA2 . Did you discuss any potential risks of your work ?   Limitations   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   Abstract ; 1 Introduction   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   Left blank .   /squareB1 . Did you cite the creators of artifacts you used ?   No response .   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   No response .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   No response .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   No response .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   No response .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   No response .   C / squareDid you run computational experiments ?   5 Experiments   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   5.4 Training Details7421 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   5.4 Training Details   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   5.5 Main Results ; 5.6 Ablation Study ; 5.7 Importance of Consistency Loss ; 5.8 Forgetting   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   5.4 Training Details   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   No response .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   No response .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   No response .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   No response .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   No response.7422