  Yuanyuan LeiRuihong HuangLu WangNick BeauchampComputer Science and Engineering , Texas A&M University , College Station , TXComputer Science and Engineering , University of MichiganPolitical Science , Northeastern University{yuanyuan , huangrh}@tamu.eduwangluxy@umich.edu , n.beauchamp@northeastern.edu   Abstract   As polarization continues to rise among both   the public and the news media , increasing at-   tention has been devoted to detecting media   bias . Most recent work in the NLP community ,   however , identify bias at the level of individual   articles . However , each article itself comprises   multiple sentences , which vary in their ideolog-   ical bias . In this paper , we aim to identify sen-   tences within an article that can illuminate and   explain the overall bias of the entire article . We   show that understanding the discourse role of a   sentence in telling a news story , as well as its   relation with nearby sentences , can reveal the   ideological leanings of an author even when the   sentence itself appears merely neutral . In par-   ticular , we consider using a functional news dis-   course structure and PDTB discourse relations   to inform bias sentence identification , and dis-   till the auxiliary knowledge from the two types   of discourse structure into our bias sentence   identification system . Experimental results on   benchmark datasets show that incorporating   both the global functional discourse structure   and local rhetorical discourse relations can ef-   fectively increase the recall of bias sentence   identification by 8.27 % - 8.62 % , as well as in-   crease the precision by 2.82 % - 3.48 % .   1 Introduction   News media play a vast role not only by providing   information , but also by selecting , packaging , and   organizing the information to shape public opinions   ( Mccombs and Reynolds , 2002 , 2009 ) . Multiple   studies showed that the media outlets are becoming   more partisan and polarized , with great potential to   influence public ’s political stance ( Gentzkow and   Shapiro , 2010b , a ) , which presents the necessity to   develop novel models to detect the media bias .   Most recent research work focus on detecting   the media bias either at the level of media outlet(Baly et al . , 2018 ) , or at the level of individual ar-   ticles ( Kiesel et al . , 2019 ; Baly et al . , 2020a ; Roy   and Goldwasser , 2020 ) . However , each article it-   self comprises multiple sentences , which vary in   their ideological bias ( Entman , 2006 , 2007a ) . In   this paper , we focus on sentence - level media bias   analysis to identify bias sentences that , as inter-   preted by ( Gentzkow and Shapiro , 2006 ; Entman ,   2007b ; Mullainathan and Shleifer , 2002 ) , provide   the supportive or background information to shift   opinion in an ideological direction , though that may   be done via selective inclusion or omission as well   as overt ideological language . The identified bias   sentences can illuminate and explain the overall   bias of the entire article . This is a difficult task ,   however , considering that ideological bias tends to   be implicit and subtle , and a bias sentence itself   can appear merely neutral .   While sophisticated semantic reasoning may be   needed to determine if a sentence induces bias , we   observe that understanding the discourse role of   a sentence in news story telling can inform bias   sentence identification . Specifically , we observe   that sentences describing the main news event are   less likely to carry bias , in contrast , certain types   of supportive contents are more likely to induce   bias , such as sentences describing reactions of vari-   ous parties toward the main event or main entities .   This is related to the selective reporting problem   in news production ( Broockman and Kalla , 2022 ;   Enke , 2020 ) , where journalists select what to in-   clude from among many materials that are all rel-   evant to the main event to some extent , and the   selected content can reveal the organization or jour-   nalist ’s leaning and stance on the main event or   main entities .   Table 1 shows an example document , where the   main event is the democratic Rep. Braley " mocks "   Grassley as farmer . The author first introduced   the main event in sentence one ( S1 ) and continued   to describe a followup event in S2 and S3 , Braley10040   made an apology , which was immediately triggered   by the main event . Arguably , the first three sen-   tences form a relatively complete news , and there   is no clear opinion projected to either entity yet .   But , the author continued to describe the reaction   ofa spokesperson for Grassley and included two   quotations from this person , an indirect quotation   ( S4 ) and a direct quotation ( S5 ) , that commented   on the two main entities . The long direct quotation   ( S5 ) proclaims the importance of Grassley ’s back-   ground and does cast a positive impression on the   entity Grassley , especially when understood with   respect to the main event of Grassley being mocked   as farmer . Presumably , there were reactions from   other parties or individuals toward this main event   that are relevant to report as well , the fact that the   author selected to include this particular individ-   ual ’s quotations reveal his ideology leaning .   In particular , we choose to incorporate discourse   roles predicted by our recent system for news dis-   course profiling(Choubey and Huang , 2021 ) . The   news discourse profiling task distinguishes three   types of contents in a news article , main contents ,   context - informing contents and additional support-   i ve contents , and labels each sentence with one ofeight subtypes reflecting common discourse roles   of a sentence in telling a news story . Specifically ,   1 ) . main contents have two subtypes , Main event   ( M1 ) and Consequence ( M2 ) , and cover sentences   that describe the main event and their immediate   consequences which are often found inseparable   from main events . 2 ) . context - informing contents   have two subtypes , Previous Event ( C1 ) and Cur-   rent Context ( C2 ) , and cover sentences that explain   the context or cause of the main event , including   recent events and general circumstances , and 3 ) .   additional supportive contents have four subtypes ,   describing past events that precede the main event   in months and years ( Historical Event ( D1 ) ) or un-   verifiable situations that are often fictional or per-   sonal accounts of incidents of an unknown person   ( Anecdotal Event ( D2 ) ) , or opinionated contents   including reactions from immediate participants ,   experts , known personalities as well as journalists   or news sources ( Evaluation ( D3 ) ) , except spec-   ulations and projected consequences that are la-   beled as Expectation ( D4 ) . Numerical analysis on   two datasets ( Table 2 ) show that depending on the   dataset , a bias sentence is more commonly tagged   as context - informing content or Anecdotal Event   ( D2 ) and Evaluation ( D3 ) subtypes of additional   supportive content.10041   In addition to global discourse roles in news   story telling , we observe that local discourse rela-   tions with nearby sentences , the causal relation and   the comparison relation in particular , can inform   bias sentence identification as well . Causal rela-   tion implication is commonly used in journalism to   attribute responsibility ( Temmann et al . , 2021 ) . In-   terestingly , we found that the strong contrast seman-   tics indicated by a comparison discourse relation   can influence readers ’ perceptions of the related   events or entities . In the example of table 3 , the   fourth sentence S4 itself has a neutral sentiment   connotation , but when interpreted with respect to   its previous sentence S3 and the comparison rela-   tion between them , this sentence has a purpose to   challenge the authenticity of its previous sentence   and has the effect to sway readers ’ opinions to-   ward the event and involved entities . Therefore , we   also train contingency and comparison discourse   relation predictors using the PDTB corpus ( Prasad   et al . , 2008 ) and incorporate their predictions to   inform bias sentence identification .   We design a knowledge distillation model ( Hin-   ton et al . , 2015 ) to distill the auxiliary knowledge   from the global functional discourse role predic-   tor and local rhetorical discourse relation predic-   tors into our bias sentence detection system . An   extra distillation loss is designed for guiding the   detection model to learn from both global and lo-   cal discourse structure predictors , so that the sys-   tem can learn to take both discourse structures   into account for building sentence representations .   Specifically , a framework for response - based multi-   teacher knowledge distillation is implemented , in   which the student model takes predicted probability   from the teacher model as learning material and   aims to mimic teacher ’s behavior , as well as digests   and integrates knowledge from multiple teachers .   Experiments on two benchmark datasets ( Fan et al . ,   2019 ; Lim et al . , 2020 ) show that the knowledge   distilled from both the global functional structureteacher and the local rhetorical structure teacher   can increase the bias sentence identification recall   by 8.27 % - 8.62 % „ as well as the precision by   2.82 % - 3.48 % , on top of a strong baseline system .   2 Related Work   Article - level media bias detection has attracted   lots of attention in the nlp community ( Hamborg   et al . , 2018 ) . ( Sapiro - Gheiler , 2019 ) utilized a text-   based method for measuring news ideology . ( Iyyer   et al . , 2014 ) used recurrent neural network for po-   litical ideology detection . ( Baly et al . , 2019 ) de-   signed a multi - task original regression framework   for jointly predicting the trustworthiness and the   ideology of news media . ( Liu et al . , 2022 ) pre-   trained a language model for the political domain   to better understand news political stance . ( Baly   et al . , 2020b ) proposed to prevent the model from   learning media source as a shortcut for predict-   ing ideology through an adversarial model . We ,   however , focus on detecting the media bias at the   sentence - level .   Sentence - level media bias has a relatively short   history in research . ( Fan et al . , 2019 ) is the first   work to annotate bias sentences in a news doc-   ument , and they also built a baseline model for   sentence - level bias detection . ( Lim et al . , 2020 ) is   another work annotating bias sentences with docu-   ment contexts considered . ( Spinde et al . , 2021b , a )   collected thousands of sentences from news arti-   cles and annotated them independent from the doc-   ument they are taken from . Considering that bias   sentences in a news article can be merely neutral   or factual , sentence - level bias detection remains a   challenging task .   News discourse is a news genre - specific discourse   structure proposed by ( Choubey et al . , 2020 ) , in   which they categorized each sentence in a news   article into eight types of discourse roles revolv-   ing around the main event . ( Choubey and Huang ,   2021 ) improved news discourse structure profiling10042through an actor - critic framework , in which the   explicit subtopic structure is used as critics and a   combination model of the REINFORCE algorithm   ( Williams , 1992 ) and imitation learning ( Hussein   et al . , 2017 ) is designed for training actor , and the   interaction between sentences and the document   is modeled in a hierarchy structure . In this paper ,   we used this state - of - art news discourse structure   model as our teacher model .   PDTB discourse relation is provided by ( Prasad   et al . , 2006 ) , annotating explicit and implicit dis-   course relations between adjacent sentences or   clauses in news articles . The newer version PDTB   2.0 ( Prasad et al . , 2008 ) added annotations of im-   plicit relations across the entire corpus , and an-   notated sense of relations into four main classes :   comparison , contingency , temporal , and expansion .   PDTB 3.0 ( Prasad et al . , 2019 ) annotated addi-   tional implicit intra - sentential relations . As shown   in ( Liang et al . , 2020 ) , the sense - distribution of   intra - sentential relations differs from that of inter-   sentential relations . Considering that sentence-   level media bias detection takes sentence as dis-   course unit , we used PDTB 2.0 data to train the   teachers that predict local rhetorical discourse rela-   tions .   Knowledge distillation ( Hinton et al . , 2015 ) is a   technique used for compressing large deep models   as well as retaining its performance . Response-   based knowledge distillation ( Kim et al . , 2018 ; Ba   and Caruana , 2014 ; Mirzadeh et al . , 2020 ) uses   the soft logits of a large deep model as the teacher   knowledge , and trains with a distillation loss to   make student logits match teacher logits . Multi-   teacher knowledge distillation ( You et al . , 2017 ;   Lan et al . , 2018 ; Song and Chai , 2018 ) utilized   knowledge from different types of teachers and   guide the student to build the ability of knowledge   integration . In this paper , a response - based multi-   teacher knowledge distillation framework is de-   signed to distill two types of discourse structures .   3 The Distillation Model   In this section , we will elaborate on the bias sen-   tence detection model distilling two types of dis-   course in detail . The model takes a whole news arti-   cle consisting of Nsentences ( S , S , . . . , S)as   input , and outputs the predicted probability of each   sentence containing bias ( P , P , . . . , P ) .   A framework of response - based multi - teacher   knowledge distillation is designed , shown in Figure1 . Response , which is the soft probability predicted   from the teacher model , is used as the learning   materials for the bias detection model . An extra   distillation loss is designed to guide the model to   mimic the discourse teachers ’ response , so that the   sentence embedding can be updated with two types   of discourse informed as auxiliary knowledge .   3.1 Bias detection layers   RoBERTa ( Liu et al . , 2019 ) is utilized as the fun-   damental language model . The initial sentence em-   bedding is the hidden state at the sentence start to-   ken < s > . Then a Bi - LSTM ( Hochreiter and Schmid-   huber , 1997 ) layer with the hidden dimension 384   is applied to capture the context information and   derive the sentence embedding ( E , E , . . . , E ) ,   in which E∈R , i= 1,2 , . . . , N andd= 768 .   Two fully connected layers activated by the   ReLU function are built on the top of sentence   embeddings , as the bias detection layers to predict   the probability of each sentence containing bias :   P= ( p,1−p )   = σ(W(ReLU ( WE+b ) ) + b)(1 )   where i= 1,2 , . . . , N , σis the softmax function ,   W∈R , W∈R   The loss for learning whether each sentence con-   tains bias or not is the classical cross entropy loss :   L=−/parenleftig / summationdisplayylog(p )   + ( 1−y ) log(1 −p)/parenrightig(2 )   where ( y , y , . . . , y)demonstrate the true label   for each sentence , y∈ { 0,1 } , i= 1,2 , . . . , N ,   value 1means biased and 0means unbiased .   3.2 Global discourse role prediction layers   The teacher model for the global functional dis-   course T is the current state - of - art news   discourse structure model ( Choubey and Huang ,   2021 ) . The teacher T classified eight dis-   course roles with an actor - critic framework , in   which the explicit subtopic structure is used as   critics , and a combination model of REINFORCE   algorithm ( Williams , 1992 ) and imitation learning   is designed for training the actor .   The global discourse teacher T predicts the   probability of eight discourse roles for each sen-   tence S , i= 1,2 , . . . , N in the input article as   Q = ( q , q , . . . , q ) 10043   Soft probability Q predicted by the teacher   model is used as the learning material for global   discourse structure .   Another two fully connected layers activated by   the ReLU function are built on the top of sentence   embeddings E , i= 1,2 , . . . , N , as the student   global discourse role layers for predicting the prob-   ability of eight discourse roles :   P = ( p , p , . . . , p )   = σ(W(ReLU ( WE+b ) ) + b)(3 )   where i= 1,2 , . . . , N , σis the softmax function ,   W∈R , W∈R. Soft probability P   predicted by the student global discourse role lay-   ersrepresents its learning outcome .   The mean squared error loss between the pre-   dicted probability from the teacher Qand stu-   dent layers Pis designed to guide the student   global discourse role layers to mimic the teacher ’s   response , so as to learn the global discourse roles   distilled from the teacher model T :   L = /summationdisplay / summationdisplay(p−q ) ( 4 )   3.3 Local discourse relation prediction layers   The teacher models for the local Comparison and   Contingency relations are both binary classification   models and share the same model structure . Take   theComparison teacher as an example for illustra-   tion , the training data in PDTB dataset takes the   sentence pair ( Arg1 , Arg2 ) as the input , and the   label is 0 or 1 standing for whether the sentence   pair has the comparison relation between them or   not . RoBERTa ( Liu et al . , 2019 ) is the fundamen-   tal language model , and the concatenation of the   hidden state at the sentence start token < s > of Arg1and Arg2 is used as the feature vector . A fully con-   nected layer is added on this feature vector to out-   put the probability of whether comparison relation   exist in ( Arg1 , Arg2 ) or not . Local Comparison   andContingency relation teacher are denoted as   T andTrespectively .   T , Tpredicts the probability of compari-   son / contingency for every adjacent sentence pairs   ( S , S ) , i= 2 , . . . , N in the input article as   Q = ( q,1−q )   Q= ( q,1−q)(5 )   Soft probability Q , Q predicted by the   teacher model is used as the learning material for   local discourse relations .   Fully connected layers activated by the ReLU   function are added on the concatenation of the sen-   tence embedding ( E , E ) , as the student local   discourse relation layers for predicting the proba-   bility of comparison / contingency :   P = ( p,1−p )   = σ(W(ReLU ( W[E;E ] + b ) ) + b )   P= ( p,1−p )   = σ(W(ReLU ( W[E;E ] + b ) ) + b )   ( 6 )   where i= 2 , . . . , N , σis the softmax function ,   W , W∈R , W , W∈R. Soft proba-   bility P , P outputted by the student local   discourse relation layers represents its understand-   ing of the two relations .   The cross entropy loss between the response   Q , Qfrom the teacher , and the predicted   probability P , P generated by the student   layers , is additionally penalized to minimize the   performance gap between the teacher model and   student layers . In this way , local discourse relations10044are distilled from the teacher T , Tinto the   student local discourse relation layers :   3.4 The Learning Objective   The learning objective is the sum of bias detection   layers loss , global discourse role layers loss , and   the local discourse relation layers loss :   L = λL+λL + λL   ( 8)   Learning the three types loss together can update   the sentence embedding with two types of dis-   course incorporated . In this way , the global and   local discourse structures are distilled as auxiliary   knowledge into the bias sentence detection model .   4 Experiments   4.1 Datasets   The sentence - level bias detection task has a rela-   tively short research history and few referable re-   sources . BASIL and BiasedSents datasets are the   only two available datasets till now that annotate   bias sentences with context considered within a   news article . Table 4 shows statistics of the two   datasets .   BASIL dataset is the first work to annotate the   sentence - level bias ( Fan et al . , 2019 ) . It con-   tains 100 triples of articles , each triple consists   of three articles from three different media outlets   discussing the same event , a total number of 300   articles . Fox News , New York Times , and Huff-   ington Post are selected as the media outlets , and   10 sets are collected from each year between 2010   and 2019 . The Cohen ’s kappa agreement between   each annotator and the gold standard is from 0.34   to 0.70 . The researcher demonstrates that bias sen-   tences can be embedded uniformly across the entire   article , and encoding contextual knowledge from   the full articles is important .   BiasedSents dataset is another work of annotating   news bias on sentence - level ( Lim et al . , 2020 ) . It   contains 46 articles from Sep 2017 to May 2018 .   They collected crowd - sourcing annotations in four   scales : not biased , slightly biased , biased , and very   biased . Following the same scenario of binary   judgements ( Lim et al . , 2020 ) , we also considered   the first two scales as unbiased and the latter two as   biased . The dataset provided the annotation from   five different annotators , and we used the majority   votes to derive the final gold labels . The Cohen ’s   kappa agreement between each annotator and our   gold label ranges from 0.17 to 0.58 .   4.2 Teacher Models   We use the state - of - art model for news discourse   profiling ( Choubey and Huang , 2021 ) as out teacher   model . We re - trained the model once using the   same parameters described in the paper , and Table 5   shows its performance on the eight news discourse   roles .   We trained our own teacher models for predict-   ing contingency and comparison relations between   sentences . The teacher models are both binary clas-   sification models and share the same simple archi-   tecture consisting of a fully connected layer applied   on the concatenation of two sentence embeddings   corresponding to two adjacent sentences . Followed   the official suggestion in PDTB 2.0 dataset(Prasad   et al . , 2008 ) , sections 2 - 21 , sections 22 & 24 and   section 23 are used for training , development and   testing respectively . Both explicit and implicit rela-   tion data are utilized for training , because bias sen-   tence may be in a discourse relation with neighbor   sentences with or without a connectives explicitly   shown . Table 6 shows the performance of Compar-   ison andContingency discourse relation teachers   respectively .   4.3 Baseline Models   The previous work by ( Fan et al . , 2019 ) built a   BERT ( Devlin et al . , 2019 ) baseline model for the   bias sentence detection task . However , their model   takes a single sentence as input and ignore the doc-   ument context . In contrast , our distillation model   takes the entire news article as the input , and make   a prediction for each sentence in the input article .   Therefore , for fair comparison , in addition to a   baseline model imitating the model in ( Fan et al . ,   2019 ) , we also built another baseline model that   takes the entire news article consisting of Nsen-10045M1 M2 C1 C2 D1 D2 D3 D4 Macro   Precision 56.30 33.33 28.69 57.63 66.76 52.98 65.45 57.61 57.10   Recall 49.57 24.68 25.35 58.83 60.34 51.15 68.77 65.19 55.34   F1 - score 52.72 28.36 26.92 58.22 63.39 52.05 67.07 61.17 56.21   Comparison Relation Contingency Relation   90.50 / 73.80 / 81.30 69.60 / 74.00 / 71.74   tences ( S , S , . . . , S)as the input . To be de-   tailed , the two baseline models are :   •RoBERTa : The hidden state at the sentence   start token < s > of each sentence Sis used   as its sentence embedding . Then two fully   connected layers activated by the ReLU func-   tion and a softmax layer are added on the top   of sentence embedding as the bias detection   layers to output the predicted probability .   •RoBERTa + context : Before the bias detec-   tion layers , a Bi - LSTM layer with the hidden   dimension 384 is added on the hidden state at   the < s > token , in order to encode context infor-   mation when deriving sentence embeddings .   This baseline model equals to our distillation   model without discourse structure distilled .   4.4 Feature Concatenation Models   In addition to the two baseline models above , we   present a feature concatenation model to incorpo-   rate the discourse structures as additional feature   on top of RoBERTa + context model . For each sen-   tence , we create a global discourse feature vector   with eight probabilities for eight discourse roles   predicted by the news discourse teacher model .   Similarly , a local discourse feature vector consists   of the probabilities for comparison and contingency   relation with its adjacent sentences predicted by   the PDTB teacher model . The global and local   discourse structures feature vectors are concate-   nated with the sentence embedding in the RoBERTa   + context model before the bias detection layers .   Therefore , the feature concatenation model also in-   corporates the global and local discourse structuresas additional information , but in a more naive way   compared to the distillation model .   4.5 Experimental Setting   Ten - fold cross validation is performed , in each time ,   a fold is used as the test set , eight folds are used as   the training set while a remaining fold is used as the   validation set to determine when to stop training .   Instead of spitting data into ten folders based on in-   dividual sentences as in ( Fan et al . , 2019 ) , we split   data based on articles . In our setting , sentences   from the same article can never appear in both a   training fold and a test fold , preventing the leaking   of knowledge . After collecting the prediction re-   sults for the ten test folds , Precision , Recall , and   F1 - score of the bias class are reported .   The value of three λhyper - parameters are ob-   tained via grid search , in the range of [ 0,3 ] with   a step size of 0.5.The value of λis set to be 1 ,   andλ equals to 1.5 , λ equals to 0.5 . The   training epochs is 5 for each testing task . We used   AdamW ( Loshchilov and Hutter , 2019 ) as the opti-   mizer . The learning rate is adaptively adjusted by a   linear schedular . The weight decay is set to be 1e-2 .   The dimension of sentence embedding , as well as   the dimension of intermediate fully connected lay-   ers are set to be d= 768 . We used Nvidia GeForce   RTX 3090 for training the model . The running time   of ten - folder cross validation is around two hours   for our full model , and one hour for the baseline   models .   4.6 Experimental Results   The results of 10 - folder cross validation on the two   datasets BASIL and BiasedSents are shown in Ta-   ble 7 . The first section of the table shows results of   two baselines . Compared to RoBERTa , RoBERTa   + context yields a little better performance across   all the metrics , this shows that bias sentence iden-   tification benefits from having access to the wider   context , however , the small improvements suggest   that simply incorporating raw contexts with no fo-   cus or further analysis has limited effects.10046BASIL BiasedSents   Precision Recall F1 - score Precision Recall F1 - score   Baseline Model   RoBERTa 40.10 40.43 40.26 37.17 76.90 50.11   RoBERTa + context 40.71 41.57 41.13 38.10 77.24 51.03   Feature Concatenation Models   + Global News Discourse Structure 42.65 42.96 42.80 39.43 75.86 51.89   + Local Discourse Relations 40.12 44.52 42.20 37.89 80.34 51.49   + Both Global and Local 42.06 43.54 42.78 38.84 78.62 52.00   Distillation Models   + Global News Discourse Structure 43.41 46.64 44.97 41.42 76.55 53.75   + Local Discourse Relations 43.06 46.48 44.71 37.50 85.86 52.20   + Both ( The Full Model ) 43.53 49.84 46.47 41.58 85.17 55.88   The second section of Table 7 shows results of   adding one type or both types of discourse struc-   tures as additional features on top of the stronger   baseline model RoBERTa + context . We can see   that adding the additional features of global and   local discourse structures yields consistent im-   provements on both precision and recall , which   demonstrates the usefulness of the global and lo-   cal discourse structures information . However , the   amount of performance gain was not so impressive ,   up to 1.35 % on precision and up to 1.97 % on re-   call , which presents the necessity for having more   sophisticated models in order to better incorporate   the discourse structures .   The third section of Table 7 shows results of   incorporating one type or both types of discourse   structure information to the model RoBERTa + con-   textby knowledge distillation . We can see that   distilling the global discourse roles of sentences   ( the row + Global News Discourse Structure ) im-   proves the precision by 2.70 % to 3.32 % , as well   as the recall by up to 5.07 % . The improvements   on both precision and recall metrics indicate that   incorporating news discourse structures resolves   both false - positive and false - negative predictions   on bias sentences . Meanwhile , distilling the local   comparison and contingency discourse relations   ( the row + Local Discourse Relations ) can effec-   tively seek out additional bias sentence that are oth-   erwise overlooked by the contextualized RoBERTa   baseline system ( RoBERTa + context ) , and be able   to improve the recall noticeably by 4.91 % - 8.62 % .   By comparing the distillation model results in   the third section with the feature concatenationmodel results in the second section , we can see   that the distillation models can better incorporate   the global and local discourse structures , yielding   extra gains of 1.47 % - 2.74 % in precision and 6.3 %   - 6.55 % in recall .   Finally , the last row of Table 7 shows that the full   system , when incorporating both global discourse   role and local discourse relation information with   the distillation model , can accumulate the perfor-   mance gains and yields the best performance on   both datasets . Compared to the baseline RoBERTa   + context , the full model improves the recall of bias   sentence identification by 8.27 % and 8.62 % on on   BASIL and BiasedSents respectively , as well as   improve the precision by 2.82 % and 3.48 % on the   two datasets . The F1 - score is improved by 4.85 % -   5.34 % . The significance test ( the student t - test with   95 % confidence level ) shows that the full model   significantly outperforms the baseline models with   the p - value less than 2e-6 .   4.7 Analysis   4.7.1 Global Functional Discourse   Here , we present the performance change across   the eight discourse roles in Table 8 . Incorporat-   ing the global functional discourse can bring pre-   cision and recall improvement across almost all   the eight discourse roles , and help alleviate both   false - negative and false - positive problems . The   most improvement on Recall exist in the discourse   roleEvaluation ( D4 ) , Previous Context ( C1 ) , and   Current Context ( C2 ) , which is consistent with the   analysis in Table 2 showing that these discourse   roles contain more bias than other types . The most10047M1 M2 C1 C2 D1 D2 D3 D4 Overall   Precision + 9.01 nan + 5.23 + 9.63 + 5.14 - 1.68 + 0.47 + 1.52 + 2.83   Recall + 10.71 nan + 2.56 + 3.87 + 1.92 + 4.17 + 10.64 - 1.20 + 8.27   Precision + 1.30 nan + 1.27 + 4.86 - 0.72 + 0 + 5.69 + 4.89 + 3.49   Recall + 0 nan + 2.22 + 2.04 + 1.33 + 0 + 10.71 + 25.00 + 7.93   Comparison Contingency   Precision + 3.37 + 4.62   Recall + 0.68 + 4.00   Precision + 3.74 + 8.88   Recall + 5.26 + 5.88   improvement on Precision exist in the discourse   roleMain Event ( M1 ) , Current Context ( C2 ) , and   Expectation ( D4 ) , which is also consistent with the   analysis in Table 2 that Main Event andExpectation   contains less bias .   4.7.2 Local Rhetorical Discourse   Here , we study the effect of local discourse rela-   tions , and present the precision and recall change   within the instances having comparison / contin-   gency relation with nearby sentences in Table 9 .   We can see that all the evaluation metrics have the   gain . Distilling the Comparison relation can im-   prove the Recall for the instances with comparison   relation by up to 5.26 % . Distilling the Contingency   relation can improve the Recall for the instances   with contingency relation by up to 5.88 % .   5 Conclusions   We study bias sentence identification within a news   article , a challenging and important task that can   illuminate and explain the overall bias of the entire   article . We advocate for a discourse structure in-   formed approach and have identified a global func-   tional discourse structure and local rhetorical dis-   course relations as useful information for address-   ing this task . We also designed a knowledge distil-   lation method that incorporates discourse structures   and effectively informs bias sentence identification .   For future work , we are keen to understand and   categorize major mechanisms or strategies used by   different news agencies to inject ideological bias.6 Limitations   One major limitation is that we only experimented   on English datasets . While both the global news   discourse structure and local discourse relations   we identified useful for bias detection in English   news articles may also be useful for analyzing news   articles written in other languages ( more future   work is needed to verify this ) , we acknowledge that   it will not be easy to obtain the discourse structure   teacher models our approach requires because there   may not be relevant annotated corpora existing for   other languages . To the best of our knowledge ,   the news discourse corpus does not have any non-   English version yet , researchers have started to   create PDTB - style discourse annotations for other   languages , but the languages considered are still   limited to several resource rich languages such as   Arabic , Hindi and Chinese .   7 Ethical Considerations   As our evaluation shows , the presented bias sen-   tence detection system has not achieved a satisfac-   tory level of performance and may make false bias   predictions when deployed .   Acknowledgements   We would like to thank the anonymous reviewers   for their valuable feedback and input . We grate-   fully acknowledge support from National Science   Foundation ( NSF ) via the awards IIS-2127746 and   IIS-1942918 . Lu Wang is supported through NSF   grant IIS-2127747 .   References100481004910050