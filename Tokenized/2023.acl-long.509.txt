  Junhao Zheng , Qianli Ma * , Shengjie Qiu , Yue Wu , Peitian Ma ,   Junlong Liu , Huawen Feng , Xichen Shang and Haibin Chen   School of Computer Science and Engineering ,   South China University of Technology , Guangzhou , China   junhaozheng47@outlook.com , qianlima@scut.edu.cn   Abstract   Fine - tuning has been proven to be a simple   and effective technique to transfer the learned   knowledge of Pre - trained Language Models   ( PLMs ) to downstream tasks . However , vanilla   fine - tuning easily overfits the target data and   degrades the generalization ability . Most exist-   ing studies attribute it to catastrophic forgetting ,   and they retain the pre - trained knowledge in-   discriminately without identifying what knowl-   edge is transferable . Motivated by this , we   frame fine - tuning into a causal graph and dis-   cover that the crux of catastrophic forgetting   lies in the missing causal effects from the pre-   trained data . Based on the causal view , we   propose a unified objective for fine - tuning to   retrieve the causality back . Intriguingly , the   unified objective can be seen as the sum of the   vanilla fine - tuning objective , which learns new   knowledge from target data , and the causal ob-   jective , which preserves old knowledge from   PLMs . Therefore , our method is flexible and   can mitigate negative transfer while preserving   knowledge . Since endowing models with com-   monsense is a long - standing challenge , we im-   plement our method on commonsense QA with   a proposed heuristic estimation to verify its ef-   fectiveness . In the experiments , our method   outperforms state - of - the - art fine - tuning meth-   ods on all six commonsense QA datasets and   can be implemented as a plug - in module to in-   flate the performance of existing QA models .   1 Introduction   Deep Pre - trained Language Models ( PLMs ) such   as RoBERTa ( Liu et al . , 2019b ) and T5 ( Raffel   et al . , 2020 ) ) are inherently knowledge bases since   they are exposed to a tremendous amount of data   ( e.g. , the C4 dataset ( Raffel et al . , 2020 ) ) in thepre - training stage ( Petroni et al . , 2019 ; AlKhamissi   et al . , 2022 ) . Unfortunately , transferring the intrin-   sic knowledge in PLMs to downstream tasks is non-   trivial . In practice , fine - tuning is adopted widely   due to its flexibility ( Chen et al . , 2020 ) and numer-   ous improved methods ( Lee et al . , 2019 ; Chen et al . ,   2020 , 2019 ; Mosbach et al . , 2020 ; Zhang et al . ,   2020b ; Xu et al . , 2021a ; Aghajanyan et al . , 2020 ;   Wu et al . , 2022 ) are proposed in recent years . How-   ever , fine - tuning faces two challenges when adapt-   ing models to new domains ( Chen et al . , 2019 ) ,   including catastrophic forgetting ( Kirkpatrick et al . ,   2017 ) and negative transfer ( Torrey and Shavlik ,   2010 ) . More specifically , catastrophic forgetting   refers to models losing previously learned knowl-   edge and overfitting the target domain data . Neg-   ative transfer occurs because not all pre - trained   knowledge is transferable across domains . Obvi-   ously , catastrophic forgetting and negative transfer   constitute a dilemma where the crux lies in identi-   fying and utilizing transferable knowledge .   A large body of previous work has been con-   ducted to solve this problem . Existing fine - tuning   methods for mitigating catastrophic forgetting can   be summarized as preventing the fine - tuned models   from deviating too far from the pre - trained weights .   For example , RecAdam ( Chen et al . , 2020 ) and   Child - Tuning ( Xu et al . , 2021a ) utilize the Fisher   Information Matrix estimated by the pre - trained   model to constraint the update in the fine - tuned   model . Mixout ( Lee et al . , 2019 ) randomly re-   places the model parameters with their pre - trained   weights . These methods constrain the update of   models ’ parameters indiscriminately without iden-   tifying what knowledge is transferable and thus   susceptible to negative transfer . Chen et al . ( 2019 )   proposed BSS , which focuses on mitigating nega-   tive transfer by penalizing the small singular values   of the feature matrix . However , when only negative   transfer is concerned , BSSmay not fully utilize the   pre - trained knowledge.9155In this paper , we propose a novel method called   Causal EffectTuning ( CET ) for mining the pre-   trained knowledge in PLMs . Unlike the previous   fine - tuning method , our method is rooted in the   theory of causal inference . It delves into the causal-   ities between data , models , and features instead   of merely statistical association . First , we frame   vanilla fine - tuning into a causal graph ( Glymour   et al . , 2016 ) and find out that the cause of catas-   trophic forgetting is the vanishing causal effects of   pre - trained data . Therefore , preventing forgetting   is to maximize the causal effect . Then , we ap-   proximate the causal effect with the likelihood of   the joint prediction of K - Nearest - Neighbor ( KNN )   samples . Since equipping models with common-   sense knowledge is still challenging , we implement   the proposed causal graph with a heuristic approx-   imation on commonsense QA . We measure the   distance with the similarity between gold answers   ( i.e. , ground - truth answers ) instead of questions for   retrieving KNNs . The rationale is that the ques-   tions with the same gold answer share the same   commonsense knowledge in PLMs . Finally , we   apply our method to RoBERTa ( Liu et al . , 2019b )   and T5 ( Raffel et al . , 2020 ) and conduct extensive   experiments on six commonsense datasets . The   experimental results show that our method outper-   forms state - of - the - art fine - tuning methods and can   be plugged into the state - of - the - art QA models to   improve performance .   More importantly , our method is lightweight and   flexible since it requires no learnable parameter   except PLMs and has fewer hyper - parameters to   tune . It is worth noting that our method readily   controls the strength of knowledge preservation by   a single hyper - parameter , enabling a good balance   between preserving pre - trained knowledge and ab-   sorbing new knowledge from downstream tasks . In   summary , our contributions are three - fold :   •We present a causal graph for fine - tuning with   less forgetting by identifying the root cause of   catastrophic forgetting as the missing causal   effects of pre - trained data .   •Based on the proposed causal graph , we de-   sign a lightweight and flexible fine - tuning   method called CausalEffectTuning for pre-   serving knowledge in PLMs .   •For commonsense QA , we estimate the causal   effect with a heuristic approximation . And we   verify the effectiveness and versatility of ourmethod through extensive experiments on six   commonsense QA datasets .   2 Related Work   2.1 Fine - tuning Methods   Apart from the methods mentioned above , some ap-   proaches improve downstream performances from   the perspective of robustness . Aghajanyan et al .   ( 2020 ) proposed R3F , which regularizes the sym-   metric KL divergence between the classifications   of the original samples and the perturbed ones . Wu   et al . ( 2022 ) proposed Noisytune , which adds uni-   form distribution noise to pre - trained parameters   before fine - tuning to reduce the risk of overfitting   the pre - training tasks and data . Besides , Mosbach   et al . ( 2020 ) ; Zhang et al . ( 2020b ) increased the   stability of fine - tuning BERT ( Devlin et al . , 2019 )   in the low - data regime . Mosbach et al . ( 2020 ) ad-   vocated fine - tuning for a long time and choosing   good optimizers and hyper - parameters . Zhang et al .   ( 2020b ) verified that re - initialized the top layers   of BERT helps pre - trained knowledge transfer to   downstream tasks .   2.2 Causal Inference   Causal inference ( Glymour et al . , 2016 ; Schölkopf ,   2022 ) has been recently introduced to various com-   puter vision tasks such as image classification ( Hu   et al . , 2021 ) , semantic segmentation ( Zhang et al . ,   2020a ) and long - tailed classification ( Tang et al . ,   2020 ; Nan et al . , 2021 ) , and NLP tasks such as dis-   tantly supervised NER ( Zhang et al . , 2021 ) , neural   dialogue generation ( Zhu et al . , 2020 ) and contin-   ual named entity recognition ( Zheng et al . , 2022 ) .   To our best knowledge , we are the first to apply   causal inference to fine - tuning .   2.3 Continual Learning   Although catastrophic forgetting happens in both   continual learning ( Rebuffi et al . , 2017 ; Hu et al . ,   2021 ) and fine - tuning , the targets of these two tasks   are fundamentally different . Continual learning   aims to learn a growing number of tasks sequen-   tially and maximize the performance on all recog-   nized tasks . In contrast , fine - tuning maximize only   the performance of target tasks . The recent advance   in continual learning ( Hu et al . , 2021 ; Zheng et al . ,   2022 ) partially inspires this work.9156   3 Methodology   In this section , we first use causal graphs ( Pearl ,   2009 ) to analyze how pre - trained knowledge is for-   gotten in fine - tuning . Then , we present a causal   graph for anti - forgetting based on previous anal-   ysis . Next , we estimate the causal effect through   derivations and propose a unified learning objec-   tive for fine - tuning with less forgetting . At last , we   provide a heuristic approximation for estimating   the causal effect on a challenging downstream task ,   commonsense QA . Note that the proposed causal   graph and the fine - tuning method are generic to all   downstream tasks .   3.1 Vanilla Fine - Tuning   In a causal graph , nodes represent variables , and di-   rected edges are causalities between nodes . Fig.(1a )   delineates the process of vanilla fine - tuning . We   denote the pre - trained data ( i.e. , pre - trained knowl-   edge ) as P ; the data in target tasks as X ; the fea-   ture of Xextracted by the pre - trained model and   fine - tuned model as HandH , respectively ; the   prediction of the fine - tuned model on target tasks   asˆY(i.e . , the probability over categories ) . The   causality between nodes ( i.e. , directed edges ) is as   follows : ( 1 ) X→H→ˆY : X→Hrepresents   that the feature His extracted by the backbone   model such as RoBERTa , and H→ˆYrepresents   a classifier compute the prediction ˆYaccording to   the extracted feature H ; ( 2)X→H←P : H   is determined by both PandXbecause His ex-   tracted by the pre - trained model , which is trained   onP.Then , the effect of pre - trained data Pon predic-   tions ˆYcan be calculated as :   Effect = P(ˆY= ˆy|do(P = p ) )   −P(ˆY= ˆy|do(P= 0 ) ) ( 1 )   = P(ˆY= ˆy|P = p)−P(ˆY= ˆy|P= 0 )   ( 2 )   = P(ˆY= ˆy)−P(ˆY= ˆy ) ( 3 )   = 0 , ( 4 )   In Eq.(1 ) , do(P= 0 ) represents that no pre - trained   data is used for pre - training , and do(P = p )   represents a standard pre - training is performed .   Then , P(ˆY= ˆy|do(P = p))is the prediction   given by a pre - trained - then - fine - tuned model   andP(ˆY= ˆy|do(P= 0 ) ) is the prediction given   by a randomly - initialized - then - fine - tuned model .   Eq.(1 ) defines Effectas the difference between   the two predictions . Eq.(2 ) holds because Phas   no parent nodes . Eq.(3 ) holds because collider H   blocks all causal paths from PtoY.   Eq.(1)-(4 ) shows that a vanilla fine - tuned model   will eventually forget all pre - trained knowledge   when no constraints are imposed . In practice , fine-   tuned models will not forget all learned knowl-   edge because the learning rate and training time   are considerably lower and shorter than those in   pre - training . However , fine - tuned models likely   forget partial pre - trained knowledge , overfit the tar-   get data , and fall into sub - optimal states since the   amount of target data is usually considerably less   than that of pre - trained data .   3.2 Fine - Tuning with Less Forgetting   The causal graph in Fig.(1a ) necessitates the re-   trieval of the causality between PandˆYback . A   straightforward solution is utilizing the pre - trained9157data to constrain model behaviors in new tasks .   However , it is often obstructed by time , space , and   financial constraints .   Thanks to causal inference , we can build a causal   path between PandXwithout storing P. In the   causal graph Fig.(1a ) , His the joint outcome of   the independent causes PandX. Intriguingly ,   once the common effect His observed , the causes   PandXbecome dependent . The causal effect is   called colliding effect in Hu et al . ( 2021 ) ; Zheng   et al . ( 2022 ) . We ’d like to provide a vivid exam-   ple ( Pearl , 2009 ) for understanding this pattern in   causal inference : If the admission criteria to a cer-   tain school require either high grades or special mu-   sical talents , then these two attributes will be found   to be correlated ( negatively ) in that school ’s student   population , even if these attributes are uncorrelated   in the population at large . By conditioning on H ,   the causal effect of pre - trained data is preserved   during fine - tuning ( i.e. , Effect>0 ) , and thus the   pre - trained knowledge is preserved .   Except for preserving old knowledge , assimilat-   ing new knowledge from target data is critical . In   addition , negative transfer may occur if we pre-   serve pre - trained knowledge overly . Motivated by   this , we split the target data into two nodes X   andX.Xrepresents the samples where we   calculate colliding effects , and their knowledge   should be transferred from PLMs . Xis the   samples where we do not calculate colliding ef-   fects , and their knowledge is domain - specific and   should be absorbed into fine - tuned models . Con-   sequently , the causal graph for our method is in   Fig.(1b ) , and the rationale is as follows : The fine-   tuned model preserves pre - trained knowledge by   utilizing colliding effects ( P↔X ) while learn-   ing domain - specific knowledge ( X ) . The final   prediction depends on both pre - trained knowl-   edge anddomain - specific knowledge from causal   paths P↔X→H→ˆYandX→H→ˆY ,   respectively .   3.3 Estimating Colliding Effects   Next , we need to estimate the colliding effect be-   tween PandX. When conditioning on H , Effectcan be calculated as :   Effect=/summationdisplayEffect(5 )   ≈/summationdisplay / summationdisplayP(ˆY|X = x)W(x , x ) ,   ( 6 )   where / summationtextW(x , x ) = 1 .Nis the num-   ber of samples in the target data and xis the i - th   sample . Effectis the colliding effect of Pon   the prediction ˆY.W(·,·)is a function deter-   mined by the pre - trained model and measures the   similarity between two samples in the hidden space   of the pre - trained model . In this case , we denote   W(x , x)asWfor brevity . xis the   k - th nearest neighbor of xin the hidden space .   Since xalways has the largest similarity with   itself , we let x = xand call xthe anchor   sample . Besides , we assume that the KNearest   Neighbours ( KNNs ) are sorted in descending order   according to the similarity . Therefore , we have   W≥W≥W≥ · · · ≥ W.Kis a hyper-   parameter representing the number of neighbors for   estimating ˆY. We provide a detailed derivation   and further explanation in Appendix A.   Eq.(5 ) re - writes the total causal effect as the sum   of the causal effect on the prediction of each tar-   get sample ( i.e. , Effect ) . In Eq.(6 ) , P(ˆY|X=   x)represents the likelihood of ˆYwhen x   is the model input . Eq.(6 ) shows that Effectcan   be approximated by the weighted sum of the like-   lihood when the model input is the anchor sample   xand its KNNs . Since we expect to maximize   P(ˆY = y|X = x ) , maximizing Effect   equals to maximizing the likelihood of the joint   prediction on the ground - truth label y.   3.4 Overall Objective   In Eq . 6 , the total causal effect Effectis bro-   ken down into the causal effect of each sample   Effect . In this case , maximizing Effectis to   preserve the related knowledge of all samples . As   we mentioned before , indiscriminately preserving   knowledge may lead to negative transfer . To ad-   dress this problem , we introduce a similarity thresh-   oldθto select the number of nearest neighbors for   each sample automatically . Specifically , for the   i - th sample , we truncate the k(K≥k≥0 ) near-   est neighbors whose similarity is greater or equal9158   thanθ . In this way , we differentiate the strength of   knowledge preservation on each sample by select-   ing the neighbors with small distances to their an-   chor sample . More interestingly , when k= 0,i.e . ,   a sample has no neighbors , the Effectamounts   toP(ˆY = y|X = x ) , which is exactly the   objective of each sample in vanilla fine - tuning . Fig .   2 provides an illustration for our method , where the   samples with no neighbors can be seen as a special   case of our method . Formally , we define the overall   objective as follows :   max Effect=/summationdisplayEffect(7 )   = /summationdisplayEffect   /bracehtipupleft / bracehtipdownright / bracehtipdownleft / bracehtipupright+/summationdisplayEffect   /bracehtipupleft / bracehtipdownright / bracehtipdownleft / bracehtipupright , ( 8)   = /summationdisplay / summationdisplayP(ˆY|X = x)W   /bracehtipupleft /bracehtipdownright / bracehtipdownleft /bracehtipupright(9 )   + /summationdisplayP(ˆY|X = x )   /bracehtipupleft /bracehtipdownright / bracehtipdownleft /bracehtipupright ,   where / summationtextW= 1,S={i|k>0},S=   { i|k= 0 } . Considering the distances between   KNNs and their anchor sample are approximated   and thus inaccurate , we set W = WandW = W=···=W = when k>0for   implementation . Wis a hyper - parameter for con-   trolling the strength of colliding effects . When   W= 0 , the overall target degenerates to the   vanilla fine - tuning target . When W= 1 , the over-   all target retains knowledge indiscriminately on all   samples . In Eq.(9 ) , the second term amounts to the   vanilla fine - tuning objective since only the anchor   sample ’s prediction is computed . In other words ,   we preserve knowledge for the samples with KNNs   and learn new knowledge for the samples without   KNNs . The rationale is that the knowledge should   be preserved when more samples require it to an-   swer the question . In the proposed causal graph   in Fig.(1b ) , the first and the second term of Eq.(9 )   correspond to the two causal paths through Xand   Xrespectively . We summarized the proposed   method in Fig . 2 and Alg . 1 in Appendix A.   3.5 An Implementation on Commonsense QA   In this subsection , we provide an implementation   for the causal graph in Fig.(1b ) on commonsense   QA . We note that the overall objective in Eq . 9 is   agnostic to specific downstream tasks and model   architectures . The implementation can be different   in various tasks or model architectures , and the key   is to find proper KNNs . This paper provides an   implementation on commonsense QA since PLMs   may be endowed with commonsense knowledge   in pre - training ( Petroni et al . , 2019 ; AlKhamissi   et al . , 2022 ) , and it is still challenging for models to9159capitalize on commonsense ( Talmor et al . , 2018 ) .   We first formulate the commonsense QA as   follows : Given a dataset with Nsamples   { ( q , a,{o } ) } , we train the best model for   choosing the gold answer aamong options { o }   given a question q. More specifically , the input of   thei - th sample can be x = q||o||···|| oor   { x}={q||o}where||is the string - level   concatenation .   Then , we define a metric to search KNNs . A sim-   ple solution is to compute the euclidean distance or   cosine similarity between the average last hidden   states of PLMs . However , this method struggles   to capture accurate semantic meanings , and mea-   suring sentence similarity remains challenging . In   this regard , we provide a simple heuristic approxi-   mation . In most cases , the questions with the same   gold answers share the same knowledge . For exam-   ple , “ airplane ” is the gold answer to the following   questions , and we can use the knowledge about “ air-   plane ” to answer them : “ What is a fast but expen-   sive way to send small cargo ? ” ; “ Where could you   find a seat that sometimes vibrates ? ” ; “ What has   metal wings ? ” . Therefore , we estimate the similar-   ity between gold answers to cope with the difficulty   of evaluating sentence similarity . Since options are   usually much shorter than questions , lightweight   tools such as spaCy ( Honnibal et al . , 2020 ) can be   used to retrieve gold answers with close semantic   meanings ( e.g. , “ airplane ” and “ aeroplane ” ) .   At last , we define the input of the i - th sam-   ple ’s KNNs as x = q||o||···|| oor   { x}={q||o } . It alleviates the over-   fitting problem since the model needs to select the   correct answer among the options of anchor sample   when the question is from its KNNs .   4 Experiments   4.1 Settings   Datasets . We conduct experiments on 6 datasets :   CommonsenseQA(CSQA ) ( Talmor et al . , 2018 ) ,   OpenBookQA(OBQA ) ( Mihaylov et al . , 2018 ) ,   ARC ( Clark et al . , 2018 , 2016 ) , QASC ( Khot et al . ,   2020 ) , SocialIQA ( SIQA ) ( Sap et al . , 2019 ) , PIQA   ( Bisk et al . , 2020 ) . Since the official test sets of   CSQA , QASC , SIQA , and PIQA are not available ,   we follow ( Yasunaga et al . , 2021 ) and use the offi - cial dev sets as test sets and split in - house dev set   from the original training sets . The dataset statistics   are summarized in Table 6 in Appendix B.   Training . Given its popularity , we use RoBERTa-   large ( Liu et al . , 2019b ) as the backbone model in   default . We also explore T5 - large ( Raffel et al . ,   2020 ) since Khashabi et al . ( 2020 ) showed that it   excels at answering questions in different formats .   Other training details are specified in Appendix B.   Competitive Methods . We make comparisons   with nine state - of - the - art fine - tuning methods :   vanilla fine - tuning , BSS ( Chen et al . , 2019 ) ,   ChildTune - F&ChildTune - D ( Xu et al . , 2021a ) ,   Mixout ( Lee et al . , 2019 ) , NoisyTune ( Wu et al . ,   2022 ) , R3F ( Aghajanyan et al . , 2020 ) , RecAdam   ( Chen et al . , 2020 ) and ReInit ( Zhang et al . , 2020b ) .   For each method , we use the recommended hyper-   parameters in the paper and source code for a fair   comparison . We discuss the implementation details   of the fine - tuning methods in Appendix C.   Hyper - Parameters . As for the hyperparameters   of our methods , we fix K= 5and search the best   Win { 0.5 , 0.7 , 0.9 , 0.95 , 0.97 } for each dataset .   We use spaCy to estimate the similarity between   gold answers . We set θ= 0.99for PIQA and   θ= 1.00for other datasets ( i.e. , the gold answers   should be matched precisely ) .   4.2 Results and Analyses   Comparisons with State - Of - The - Art . To   demonstrate the effectiveness of our method ,   we re - implement several strong baselines on   commonsense QA datasets using their officially   released codes and hyper - parameters . The results   are summarized in Table 1 . Results show that   our method outperforms all fine - tuning methods   consistently . On QASC and OBQA , our method   achieves 57.57 % and 70.76 % accuracy , obtaining   3.53 % and 2.64 % improvements on vanilla   fine - tuning .   Why our method better preserves commonsense   knowledge from PLMs ? The reasons are two - fold .   The first reason is that our method utilizes the col-   liding effect for transferring the “ colliding ” com-   monsense knowledge , while other methods do not .   For instance , in Fig.2 , our method encourages mod-   els to update xand its KNNs x , x , x   simultaneously . In this way , the commonsense   knowledge about “ airplane ” that “ airplanes deliver   small and precious cargo ” , “ airplanes have metal   wings ” and “ airplanes have seats ” can be trans-9160   ferred jointly , which reduces the risk of over - fitting .   We provide more examples from each dataset in   Table 3 and Table 10,11 , in Appendix F. The sec-   ond reason is that our method does not directly   constrain ( e.g. , ChildTune - D , Mixout , RecAdam )   or modify ( e.g. , NoisyTune , ReInit ) the parame-   ters of fine - tuned models . Empirical results show   that these methods encounter negative transfers on   some of the datasets . Instead , our method buildsupon the causal inference theory and utilizes the   joint prediction as a soft constraint to transfer re-   lated knowledge while mitigating negative transfer .   Compared with Knowledge - Graph - Based Meth-   ods . Utilizing knowledge graphs such as Con-   ceptNet ( Speer et al . , 2017 ) is a common prac-   tice for building commonsense QA systems .   We compared our method with six knowledge-   graph - based methods : Relation Network ( San-   toro et al . , 2017 ) , KagNet ( Lin et al . , 2019 ) ,   RGCN(Schlichtkrull et al . , 2018 ) , MHGRN(Feng   et al . , 2020 ) , QAGNN(Yasunaga et al . , 2021 ) ,   SAFE(Jiang et al . , 2022 ) . Detailed descriptions and   other related works are given in Appendix D. Note   that these methods utilize knowledge graphs ( KGs )   as external knowledge resources , and most of them   train graph neural networks ( GNNs ) for extracting   features from KGs . In contrast , our method does   not introduce any additional learnable parameters   except PLMs and the final fully - connected layer .   The result in Table 2 shows that our method out-9161performs RGCN , KagNet , and Relation Network   by only mining the internal knowledge of PLMs .   Furthermore , our method significantly outperforms   all the knowledge - graph - based methods under low   resource conditions ( ≤20 % training data is used ) ,   which shows that our method helps PLMs adapt to   downstream tasks with less data .   In addition , our method can be easily imple-   mented as a plug - in module by simply substitut-   ing the vanilla fine - tuning objective for the causal   effect in Eq.(9 ) . We combine our method with   QAGNN and SAFE , respectively . Table 2 shows   that our approach consistently improves QAGNN   and SAFE and achieves superior performances .   Therefore , the pre - trained commonsense knowl-   edge benefits downstream tasks even when KGs   are introduced .   Fine - tuning on a Cyclic Chain of Tasks . To   understand how our method preserves knowledge   during fine - tuning , we follow Aghajanyan et al .   ( 2020 ) and design a cyclic chain of tasks :   A→B→C / bracehtipupleft / bracehtipdownright / bracehtipdownleft / bracehtipupright→A→B→C / bracehtipupleft / bracehtipdownright / bracehtipdownleft / bracehtipupright→ · · ·   In our experiment , we set A = CSQA , B = OBQA ,   and C = QASC for a demonstration . Specifically ,   we start from a PLM and fine - tune it on CSQA .   Then , we use the model fine - tuned on CSQA to ini-   tialize the backbone model ’s parameters and con-   tinue fine - tuning it on OBQA . Table 4 shows that   our method retains knowledge significantly bet-   ter than vanilla fine - tuning . The performances on   OBQA and QASC improve at every cycle , suggest-   ing that our method effectively retains knowledge   from the previous datasets . Unfortunately , both per-   formances of vanilla fine - tuning and our method   on CSQA degrade slightly , showing that negative   transfer happens . In this case , vanilla fine - tuning   will lead to more serious performance degradation .   The experiment is for demonstration , and a better   combination of tasks that promote each other may   be found .   Ablation Study . To verify the effectiveness of   our method , we consider the following ablated   version of our method : ( 1 ) replacing the KNNs   ( Large , Ours ) with randomly selected samples   ( Rand ) or samples with the smallest similarity   ( Small ) ; ( 2 ) searching the KNNs according to the   similarity of average last hidden states ( Avg ) in-   stead of gold answers ( Gold , Ours ) . The result in   Table 5 shows that the model learns commonsense   knowledge better when the KNNs share the gold   answer with close meaning .   Additional Experiments . Due to space con-   straints , we present the experiments on T5 , the   hyper - parameter analysis , the experiments on   Named Entity Recognition , and further discussions   in Appendix E.   5 Conclusion   We propose a novel fine - tuning technique rooted in   causal inference for preserving pre - trained knowl-   edge from PLMs . Although many fine - tuning meth-   ods have been proposed in recent years , most of   them overlooked one or both hidden issues of fine-   tuning , catastrophic forgetting and negative trans-   fer , which result in a dilemma . In this paper , we   provide an answer to the dilemma from the casual   lens . Impressively , we empirically find that the   proposed method achieves the best performance   on six commonsense QA datasets and is flexible   to be applied to various QA systems and model   architectures.9162Limitations   There are three limitations on our method . First ,   we did not verify our method on more generic tasks ,   such as text classification , yet it is not limited to   commonsense QA . Extending our method to other   downstream tasks is our future work . Second , our   method requires a longer training time and a larger   GPU memory since the KNNs require forward and   backward propagation additionally . Third , we do   not consider the ambiguity of gold answers , which   may affect the quality of KNNs . For example , “ ap-   ple ” may refer to a kind of fruit or a technology   company .   Acknowledgements   The work described in this paper was partially   funded by the National Natural Science Founda-   tion of China ( Grant Nos . 62272173 , 61872148 ) ,   the Natural Science Foundation of Guang-   dong Province ( Grant Nos . 2022A1515010179 ,   2019A1515010768 ) .   References916391649165   AA Detailed Derivation for the Colliding   Effect   Algorithm 1 : Causal Effect Tuning   Input : D={(x , y ) } : a training set   withNsamples ; F : a pre - trained   model   Output : F : a fine - tuned modelInitialize F ← F;Compute the KNNs for each sample x :   x , · · · , x;while not converge do Compute Effectaccording to Eq.(9);F ← arg maxEffect;endreturn F ;   Without loss of generality , we first define the   fine - tuning process formally as follows : Given a   pre - trained model Fand a dataset with Nsamples   { ( x , y } , we aim to learn a model Fwhich   has the best performance on predicting the label   y. Recall that in Eq.(5 ) , we re - write Effectas   the sum of the causal effect on each prediction ˆY.   Now , the outcome node ˆYin the causal graph be-   comes ˆY. Then , we need to condition on H   to utilize colliding effects . Considering when pre-   dicting ˆY , xshould play an important role .   Furthermore , when X = x , its hidden feature is   simply calculated as h = F(x ) . Therefore , it   is natural to choose has the hidden feature we   condition on .   After controlling H = h , the meaning of the   input node Xin the causal graph becomes all sam-   ples whose hidden feature is h. Unfortunately ,   due to the sparsity in high dimensional spaces , onlyxsatisfies this constraint . Intuitively , if   we loosen this constraint a bit , the colliding effect   will not disappear instantly . Instead , the colliding   effect will vanish gradually when the hidden fea-   ture becomes farther and farther away from h.   Put differently , colliding effects still exist when   samples bear a resemblance to each other in the   hidden space of the pre - trained model .   Now , we provide a derivation as follows :   Eq.(10 ) is deduced from Eq.(2 ) and the condition   ofH = h. Eq.(11 ) expands Eq.(10 ) as the sum   of all Nsamples . In Eq.(12 ) , P(ˆY|X , H ) =   P(ˆY|X)because Xis the only mediator ( Pearl ,   2009 ) from PtoˆY. In Eq.(13 ) , we approxi-   mateP(X = x|H = h , P= 0 ) as zero be-   cause the likelihood of X = xis small when the   model is randomly initialized . Eq.(14 ) is obtained   by applying Bayes formula to Eq.(13 ) . In Eq.(14 ) ,   P(H = h|P = p)andP(X = x|P = p )   are intractable and can be seen as constants . We   note that the likelihood term P(H = h|X=   x , P = p)represents how likely the hidden fea-   ture is hwhen the input sample is x. Obvi-   ously , the likelihood is the largest when k = i   and becomes smaller when the hidden feature of9166xbecome farther away from h. Therefore , the   fractional term of Eq . 14 can be regarded as a scal-   ing factor of the likelihood P(ˆY|X = x ) . In   Eq.(15 ) , we re - write the fractional term of Eq.(14 )   as a function of xandxsince h = F(x ) .   In Eq.(15 ) , we truncate the top K samples , which   are closest to x , in the hidden space of the pre-   trained model . Besides , we let x = xsince   xhas the largest similarity with itself . Addition-   ally , we let / summationtextW(x , x ) = 1 to ensure   that the joint prediction is a probability distribution   over categories .   B Training Details   The dataset statistics is in Table 6 . All models   are implemented based on Pytorch ( Paszke et al . ,   2019 ) and Huggingface ( Wolf et al . , 2019 ) . We   use the default hyper - parameters of RoBERTa and   T5 according to the Huggingface implementation .   Following Yasunaga et al . ( 2021 ) ; Khashabi et al .   ( 2020 ) , we concatenate all options as input when   the backbone is T5 and concatenate each option re-   spectively when the backbone is RoBERTa . We   tuned the batch size in { 64 , 128 } , the learning   rate of the backbone model in { 5e-5 , 2e-5 , 1e-5 } .   Before fine - tuning RoBERTa , a randomly initial-   ized fully connected ( FC ) layer is added on top of   RoBERTa , and the learning rate of the FC layer   is 1e-2 . We use RAdam ( Liu et al . , 2019a ) as the   optimizer and use a constant learning rate sched-   uler . The weight decay is 1e-2 , and the maximum   gradient norm is 1.0 . For each dataset , the training   hyper - parameters are the same for all methods for   a fair comparison . We select the best model accord-   ing to the performance on the dev set and report   the test accuracy of the chosen model . The experi-   ments are run on GeForce RTX 3090 GPU . Each   experiment is repeated five times . Since we do not   introduce any learnable parameters except PLMs ,   the total number of parameters of our method is the   same as PLMs ( RoBERTa - large and T5 - large have   355 M and 770 M parameters , respectively ) .   C Details of the Competitive Fine - tuning   Methods   The details of the competitive fine - tuning methods   are as follows . Note that we use recommended   hyper - parameters in the paper or the source code   for a fair comparison .   •vanilla fine - tuning : fine - tuning has beenproven to be a simple and effective method of   adapting large PLMs to downstream tasks .   •BSS ( Chen et al . , 2019 ): BSS focuses on   mitigating negative transfer by penalizing the   small singular values of the feature matrix .   We penalize the smallest singular value , and   the weight of the regularization term is set as   1e-3 as recommended .   •ChildTune - F&ChildTune - D ( Xu et al . , 2021a ): ChildTune - F&ChildTune - D update a subset   of parameters ( called child network ) of large   PLMs in the backward process . ChildTune-   D utilizes the Fisher Information Matrix es-   timated by the pre - trained model to deter-   mine the child network . ChildTune - F uses   Bernoulli distribution to determine the child   network .   •Mixout(Lee et al . , 2019 ): Mixout randomly   mixes the parameters of the pre - trained and   the fine - tuned model to regularize the fine-   tuning process . In the experiments , the mixing   probability pis set as 0.9 .   •NoisyTune ( Wu et al . , 2022 ): NoisyTune adds   uniform noises to the parameter of the pre-   trained model based on their standard devia-   tions . The scaling factor λ , which controls the   relative noise intensity , is set as 0.15 .   •R3F(Aghajanyan et al . , 2020 ): R3F allevi-   ates representational collapse by introducing   parametric noise . R3F generates noise from   either a normal or uniform distribution .   •RecAdam(Chen et al . , 2020 ): RecAdam   optimizes a multi - task objective and utilize an   annealing coefficient to gradually shift the ob-   jective from pre - training to downstream tasks .   •ReInit ( Zhang et al . , 2020b ): Zhang et al .   ( 2020b ) verified that transferring the top pre-   trained layers slows down learning and hurts   performance . ReInit re - initializes the top lay-   ers of PLMs when adapting to new tasks . In   our experiments , we re - initialize the top 3   transformer block.9167   D Related Works of Commonsense QA   Commonsense reasoning is a key pillar of human   cognition and intelligence , but it is still a long-   standing challenge for deep learning systems ( Xu   et al . , 2021b ; Wang et al . , 2020b ; Talmor et al . ,   2018 ) . Current question and answering ( QA ) sys-   tems rely on external sources such as knowledge   graphs ( e.g. , ConceptNet ) ( Yasunaga et al . , 2021 ;   Feng et al . , 2020 ; Wang et al . , 2020a ; Lin et al . ,   2019 ) , knowledge bases ( e.g. , Wiktionary ) ( Xu   et al . , 2021b ) and generative pre - trained language   models ( e.g. , GPT3 ( Brown et al . , 2020 ) ) ( Liu   et al . , 2022b ; Yang et al . , 2020 ; Rajani et al . , 2019 ;   Liu et al . , 2022a ) , and achieve remarkable success .   Despite the remarkable success , collecting high-   quality external knowledge is usually expensive ,   and noisy knowledge is easily introduced ( Liu et al . ,   2022b ) . In this paper , we present a novel fine-   tuning method that retains commonsense knowl-   edge from PLMs since they are exposed to a colos-   sal amount of data in pre - training and inherently   knowledge bases ( Petroni et al . , 2019 ; AlKhamissi   et al . , 2022 ) . Different from the existing common-   sense QA models , our method does not rely on KGs   or GNNs . Moreover , our method can be a plug - in   module to enhance the performance of common-   sense QA models . We compared six commonsense   QA methods in the experiments :   •Relation Network ( Santoro et al . , 2017 ) uti-   lizes a relational reasoning structure over the   knowledge graph ;   •KagNet ( Lin et al . , 2019 ) aggregates informa-   tion with graph convolutional networks and   LSTMs , and a hierarchical path - based atten-   tion mechanism ;   •RGCN ( Schlichtkrull et al . , 2018 ) extends   the graph convolutional network with relation-   specific weights ;   •MHGRN ( Feng et al . , 2020 ) utilizes both   GNNs and path - based models for common-   sense QA ;   •QAGNN ( Yasunaga et al . , 2021 ) models the   QA context and the knowledge graph in a   joint graph and extracts their representations   through a GNN .   •SAFE ( Jiang et al . , 2022 ) designs a simple   MLP - based knowledge encoder that utilizes   statistical relation paths as features .   E Additional Experimental Results   Experiments on T5 . Our method is model-   agnostic since it only requires computing the joint   prediction . Different from discriminant models   such as RoBERTa , T5 is a generative model whose9168   output is in text format . Following Khashabi et al .   ( 2020 ) , we concatenate a question and its all op-   tions with prefixes ( a),(b),(c ) , ... as the input , and   expect the model to output the ground - truth op-   tion in text format . To adapt our model to T5 , we   substitute the prediction from the probability distri-   bution over options to the probability distribution   over vocabulary . In this way , we encourage T5 to   generate the same gold answer when the input is   the question of the anchor sample and its KNNs .   The experimental result is in Table 7 . From   the result , we find that our method still improves   vanilla fine - tuning consistently , which demon-   strates that our approach can be applied to various   architectures . Besides , we also apply ReInit on T5   as in RoBERTa . Unfortunately , T5 fails to adapt   to downstream tasks when only a few parameters   are re - initiated ( e.g. , the self - attention layer or the   cross - attention layer in the topmost transformer   block ) . We conjecture that the final language mod-   eling head ( LM head ) , which maps the last hidden   states to the vocabulary space , hinders the knowl-   edge of the bottom layers to transfer to new tasks .   Different from ReInit , our method is also applica-   ble to T5 because it has no assumptions about the   model architecture .   Hyper - parameter Analysis . We consider two   hyper - parameters that may influence the effective-   ness of our method : the number of neighbors K   and the weight for controlling the strength of col-   liding effects W. Fig . 3a and 3b show that   our method is robust when various Ware cho-   sen . When the backbone is RoBERTa - large , ourmethod achieves the best performance when W=   0.7on OBQA , ARC - Easy , and ARC - Challenge ;   when W= 0.9on QASC and SIQA ; and when   W= 0.97on CSQA . When the backbone is T5-   large , our method achieves the best performance   when W= 0.9on QASC ; when W= 0.95on   CSQA , OBQA , ARC - Easy , and PIQA ; and when   W= 0.97on ARC - Challenge and SIQA . In addi-   tion , we find that some datasets , such as CSQA , re-   quire more domain - specific knowledge while some   datasets , such as OBQA , require more pre - trained   knowledge . The result of Kin Table 8 shows that   a larger Kis beneficial . Our method is also robust   toKbecause the similarity threshold θtruncates   the number of nearest neighbors for each sample .   Differences between Our Method and Data Aug-   mentation . Our method recombines the KNN   questions with the options of the anchor sample .   A reasonable conjecture is that our method “ adds ”   KNN samples to enhance generalization ability .   We do the following experiment to test the hypoth-   esis : We add the same KNN samples generated by   our method into the original training set for fine-   tuning . The result shows that its improvement is   not statistically significant . The reason may be as   follows : Recall that we set θ= 1.0on five out of   six datasets where the gold answer of the anchor   sample and its KNNs should be matched precisely .   Therefore , on most datasets , the KNN samples re-   combine with the options containing their original   gold answer , suggesting that they provide no ad-   ditional information . Besides , the newly added   samples change the data distribution of the original9169   training set .   Experiments on Named Entity Recognition . To   demonstrate that CET has the potential to improve   more generic tasks , we apply CET to another task ,   Named Entity Recognition ( NER ) , which is a fun-   damental task in NLP . First , NER can be formu-   lated as a word - level classification task . Therefore ,   both " anchor " and KNNs refer to a specific word .   Then , we use the Euclidean distance as a metric to   find the KNNs in the space of the last hidden states   of PLMs . Considering NER focuses on recogniz-   ing entities , we only compute the causal effects on   entity words . During training , both the sentences   containing anchor and KNN words are fed into the   model . And then , we compute the joint prediction   as in Eq.6 by combining the score prediction of the   anchor word and the corresponding KNN words .   Finally , we jointly optimize the causal effects of   entity words and the vanilla fine - tuning objective   of non - entity words as in Eq.9 .   We choose three widely used datasets for ex-   periments : CoNLL2003 ( Sang and De Meulder ,   2003 ) , Ontonotes5 ( Hovy et al . , 2006 ) , I2B2 ( Mur-   phy et al . , 2010 ) . Following previous experiments ,   we use RoBERTa - large as the backbone . The result   in Table 9 indicates that CET outperforms vanilla   fine - tuning consistently .   To better understand CET , here is an example   from CoNLL2003 : The anchor is a Location en-   tity " California " in the sentence " . . . Marine Lab-   oratories in California say . . . " . Its three nearest   neighbours are 1 . " California " in the sentence " At   California , Tim . . . " ; 2 . " Oakland " in the sentence   " OAKLAND AT NEW YORK " ; 3 . " Florida " in the   sentence " At Florida , . . . " . As shown , the anchor   and KNN words share the related prior knowledge   of PLMs , which can also be illustrated in Figure 2 .   F More examples of Colliding Effects91709171ACL 2023 Responsible NLP Checklist   A For every submission :   /squareA1 . Did you describe the limitations of your work ?   In the Limitations section   /squareA2 . Did you discuss any potential risks of your work ?   Our work does not involve any sensitive data or sensitive tasks .   /squareA3 . Do the abstract and introduction summarize the paper ’s main claims ?   In abstract and section 1 .   /squareA4 . Have you used AI writing assistants when working on this paper ?   Left blank .   B / squareDid you use or create scientiﬁc artifacts ?   In section 5 and appendix B.   /squareB1 . Did you cite the creators of artifacts you used ?   In section 5 and appendix B. We cite all the datasets and codes .   /squareB2 . Did you discuss the license or terms for use and / or distribution of any artifacts ?   All the datasets and codes can be used for research purposes .   /squareB3 . Did you discuss if your use of existing artifact(s ) was consistent with their intended use , provided   that it was speciﬁed ? For the artifacts you create , do you specify intended use and whether that is   compatible with the original access conditions ( in particular , derivatives of data accessed for research   purposes should not be used outside of research contexts ) ?   The use of existing artifacts was consistent with their intended use .   /squareB4 . Did you discuss the steps taken to check whether the data that was collected / used contains any   information that names or uniquely identiﬁes individual people or offensive content , and the steps   taken to protect / anonymize it ?   All the datasets and codes can be used for research purposes and do not contains any information   that names or uniquely identiﬁes individual people or offensive content .   /squareB5 . Did you provide documentation of the artifacts , e.g. , coverage of domains , languages , and   linguistic phenomena , demographic groups represented , etc . ?   All the datasets and codes are available for research purposes . Therefore , we do n’t need to provide   documentation for them .   /squareB6 . Did you report relevant statistics like the number of examples , details of train / test / dev splits ,   etc . for the data that you used / created ? Even for commonly - used benchmark datasets , include the   number of examples in train / validation / test splits , as these provide necessary context for a reader   to understand experimental results . For example , small differences in accuracy on large test sets may   be signiﬁcant , while on small test sets they may not be .   In section 5 and appendix B.   C / squareDid you run computational experiments ?   In section 5 and appendix B.   /squareC1 . Did you report the number of parameters in the models used , the total computational budget   ( e.g. , GPU hours ) , and computing infrastructure used ?   In section 5 and appendix B.9172 / squareC2 . Did you discuss the experimental setup , including hyperparameter search and best - found   hyperparameter values ?   In section 5 and appendix B.   /squareC3 . Did you report descriptive statistics about your results ( e.g. , error bars around results , summary   statistics from sets of experiments ) , and is it transparent whether you are reporting the max , mean ,   etc . or just a single run ?   In section 5 and appendix B.   /squareC4 . If you used existing packages ( e.g. , for preprocessing , for normalization , or for evaluation ) , did   you report the implementation , model , and parameter settings used ( e.g. , NLTK , Spacy , ROUGE ,   etc . ) ?   In section 5 and appendix B.   D / squareDid you use human annotators ( e.g. , crowdworkers ) or research with human participants ?   Left blank .   /squareD1 . Did you report the full text of instructions given to participants , including e.g. , screenshots ,   disclaimers of any risks to participants or annotators , etc . ?   Not applicable . Left blank .   /squareD2 . Did you report information about how you recruited ( e.g. , crowdsourcing platform , students )   and paid participants , and discuss if such payment is adequate given the participants ’ demographic   ( e.g. , country of residence ) ?   Not applicable . Left blank .   /squareD3 . Did you discuss whether and how consent was obtained from people whose data you ’re   using / curating ? For example , if you collected data via crowdsourcing , did your instructions to   crowdworkers explain how the data would be used ?   Not applicable . Left blank .   /squareD4 . Was the data collection protocol approved ( or determined exempt ) by an ethics review board ?   Not applicable . Left blank .   /squareD5 . Did you report the basic demographic and geographic characteristics of the annotator population   that is the source of the data ?   Not applicable . Left blank.9173