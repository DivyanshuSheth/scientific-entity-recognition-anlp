  Yu Jin Kim , Beong - woo Kwak , Youngwook Kim , Reinald Kim Amplayo   Seung - won HwangandJinyoung YeoYonsei University , Seoul , KoreaGoogle Research , London , UKSeoul National University , Seoul , Korea   { yujin000731 , beongwoo.kwak , youngwook , jinyeo}@yonsei.ac.kr   reinald@google.com , seungwonh@snu.ac.kr   Abstract   Commonsense reasoning systems should be   able to generalize to diverse reasoning cases .   However , most state - of - the - art approaches de-   pend on expensive data annotations and over-   ﬁt to a speciﬁc benchmark without learning   how to perform general semantic reasoning .   To overcome these drawbacks , zero - shot QA   systems have shown promise as a robust learn-   ing scheme by transforming a commonsense   knowledge graph ( KG ) into synthetic QA-   form samples for model training . Considering   the increasing type of different commonsense   KGs , this paper aims to extend the zero - shot   transfer learning scenario into multiple - source   settings , where different KGs can be utilized   synergetically . Towards this goal , we propose   to mitigate the loss of knowledge from the   interference among the different knowledge   sources , by developing a modular variant of   the knowledge aggregation as a new zero - shot   commonsense reasoning framework . Results   on ﬁve commonsense reasoning benchmarks   demonstrate the efﬁcacy of our framework , im-   proving the performance with multiple KGs .   1 Introduction   The ability to understand natural language through   commonsense reasoning is one of the core focuses   in the ﬁeld of natural language processing . To   measure and study the different aspects of com-   monsense reasoning , several datasets are devel-   oped , such as SocialIQA ( Sap et al . , 2019b ) , Com-   monsenseQA ( Talmor et al . , 2018 ) , and Physi-   calIQA ( Bisk et al . , 2020 ) , each requiring different   type of commonsense knowledge ( e.g. , social , taxo-   nomic , causal , declarative , etc ) to select the correct   answer . While large - scale neural systems ( Devlin   et al . , 2018 ; Yang et al . , 2019 ; Liu et al . , 2019b )   have shown human - level accuracy on these bench-   marks , recent studies ( Mitra et al . , 2019 ) also crit-   icize that these models solve individual datasets , rather than learning how to perform general seman-   tic reasoning . To this end , Ma et al . ( 2021 ) sug-   gested zero - shot evaluation as a genuine measure   for the reasoning capability of the machine .   Inspired by this new metric , in this work , we   focus on building unsupervised zero - shot multiple-   choice QA systems . That is , we target an arbitrary   commonsense reasoning task where conventional   approaches ( that rely heavily on task - speciﬁc super-   vision ) are not applicable to such zero - shot learning   scenarios . To learn QA models without expensive   annotation efforts , recent works ( Ma et al . , 2021 ;   Banerjee and Baral , 2020 ; Malaviya et al . , 2020 )   propose to generate a synthetic QA dataset using a   commonsense KG such as ATOMIC ( Sap et al . ,   2019a ) and ConceptNet ( Speer et al . , 2017 ) .   Such an approach mostly focuses only on one spe-   ciﬁc type of reasoning relations ( e.g. , if - then re-   lation , or declarative relation ) , neglecting the fact   that real - world QA systems require simultaneously   considering different types of reasoning abilities   ( e.g. , declarative and social , or causal and physical   reasoning ; Ilievski et al . , 2021 ; Chang et al . , 2021 ) .   To consider different types of reasoning , this   paper extends ideas from the aforementioned zero-   shot learning to the multi - source case such that   it beneﬁts from different types of commonsense   knowledge on individual KGs . For example ,   ATOMIC ( Sap et al . , 2019a ) focuses on social com-   monsense while ConceptNet ( Speer et al . , 2017 )   contains conceptual knowledge . A practical ap-   proach is multi - task learning ( MTL ; Caruana , 1997 ;   Liu et al . , 2019a ) , which learns a shared encoder   for different synthetic QA datasets from multiple   KGs . Despite its effectiveness , MTL scheme suf-   fers from interference among different KGs , which   results in forgetting previously learned knowledge   when trained on new KG which has different kinds   of knowledge ( Pilault et al . , 2021 ; Pfeiffer et al . ,   2021 ; Wang et al . , 2021a ; Wu et al . , 2020 ) .   To address these limitations , we propose a novel,2244modularized framework that aims to learn multiple   expert models for KGs , then conduct zero - shot fu-   sion to allow collaboration among KGs . For this   purpose , we leverage AdapterFusion ( Pfeiffer et al . ,   2021 ) where multiple tiny modules between Trans-   former blocks called adapters ( Houlsby et al . , 2019 )   can be combined after independent training , thus   allowing a continual integration of the adapters   without retraining the entire framework . Speciﬁ-   cally , we treat the adapters as different KG - speciﬁc   experts , and combine them using an attention - like   fusion module . To improve the fusion of adapters ,   we suggest a KG - alignment adapter that guides   to the apt expert adapters . Here , we use KGs in   three different synthetic supervision training : ( 1 )   KG - speciﬁc QA datasets to train the KG - speciﬁc   expert adapters , ( 2 ) a KG classiﬁcation datasets to   train the KG - alignment adapter , and ( 3 ) a balanced   mixture of KG - speciﬁc QA datasets to train the   fusion module . Our modularized method alleviates   the interference between different KGs , which is   the pitfall of MTL from our empirical observation ,   and thus combines multiple KGs into a synergetic   zero - shot framework .   Our contributions are : ( 1 ) We suggest a simple ,   yet effective KG modularization strategy for the use   of multiple KGs in commonsense reasoning . ( 2 )   We then explore the use of AdapterFusion ( Pfeif-   fer et al . , 2021 ) for better knowledge aggregation   based on the KG modularization in zero - shot set-   ting . We believe that such modularized transfer   learning is critical to using different knowledge   sources synergetically against interference between   them . ( 3 ) In extensive experiments on various com-   monsense reasoning benchmarks , our framework   achieves signiﬁcant improvements over baselines   using a single KG , even using multiple KGs , which   implies the robustness in commonsense reasoning .   2 Related Work & Preliminaries   2.1 Zero - shot Commonsense Reasoning   Many researchers have recently focused on build-   ing unsupervised models without any benchmark   supervisions ( i.e. , zero - shot learning ) . In such zero-   shot setting , KGs are often used as an external re-   source for improving model prior ( e.g. , continually   learned from pre - trained language models ) ( Baner-   jee and Baral , 2020 ; Bosselut and Choi , 2019 ; Ma   et al . , 2021 ) , especially for commonsense reason-   ing , as much existing work couples language mod-   els with neural / symbolic commonsense KGs . However , most of existing work are either as-   suming the existence of the alignment information   between tasks and KGs ( Banerjee and Baral , 2020 )   or an integrated KG ( Ma et al . , 2021 ) . For example ,   ATOMIC(Hwang et al . , 2021 ) , a commonsense   KG which incorporates tuples from ConceptNet   andATOMIC with new relations and further crowd-   sourcing , combines multiple KGs into a new in-   tegrated KG , but as widely known ( Ilievski et al . ,   2020 ; Hwang et al . , 2021 ) , heterogeneous schema   between different KGs may limit triplets that can be   integrated . Rather than such symbolic KG integra-   tion with the inevitable loss of knowledge , in this   work , we explore the neural KG integration leverag-   ing the multiple KGs without additional processing   and alignment information between KG and task .   2.2 Transfer Learning with Modular   Approaches   The idea of having specialized parameters , or so-   called experts , has been widely studied to integrate   multiple sources of knowledge via transfer learn-   ing . The adapter module ( Rebufﬁ et al . , 2017 ;   Houlsby et al . , 2019 ) has been explored as one   of such approaches , introducing a small number   of task - speciﬁc parameters at every layer of pre-   trained language model ( PLM ) while sharing the   parameters of underlying PLM which is ﬁxed . To   address the limitations of transfer learning due to   high re - training cost , many works utilize the multi-   ple adapter modules for individual tasks with differ-   ent domains ( Puigcerver et al . , 2020 ; Bapna et al . ,   2019 ; Rücklé et al . , 2020 ; Madotto et al . , 2021 )   considering each adapter to be an expert of each do-   main . Similar to our work , K - Adapter ( Wang et al . ,   2021a ) encodes factual and linguistic knowledge to   each adapter , but in this paper , we further explore   how to mitigate catastrophic forgetting or interfer-   ence among multiple adapters for better knowledge   transfer in zero - shot setting .   2.3 Multi - Task Learning   MTL ( Liu et al . , 2019a ; Zhang and Yang , 2017 ;   Caruana , 1997 ) learns a shared representation while   aggregating knowledge across multiple learning   tasks , often leading to better generalization ability   of a model . However , parametric aggregation of   knowledge with MTL has following limitations :   ( 1 ) retraining the full model when adding new2245tasks ( Houlsby et al . , 2019 ; Pfeiffer et al . , 2021 ,   2020b ) ( 2 ) catastrophic forgetting and interference   between tasks leading to difﬁculties of solving   each task equally well ( Pilault et al . , 2021 ; Wu   et al . , 2020 ; Yu et al . , 2020 ) and ( 3 ) inconsistent   effect ( Lourie et al . , 2021 ) . To deal with these   challenges , Mixture - of - Experts ( MoE ) is a param-   eterized generalization of ensembling techniques ,   which has been adapted for MTL with gating net-   work trained to optimize each task ( Ma et al . , 2018 ) .   However , simple linear gating networks are too   shallow and thus may destruct task knowledge for   commonsense reasoning .   To address this problem , AdapterFusion ( Pfeiffer   et al . , 2021 ) has been proposed to fuse task speciﬁc   parameters called adapters for the given target task   leveraging attention - like mechanism . AdapterFu-   sion aggregates adapters , which is trained indepen-   dently for each task , in a non - destructive manner   mitigating aforementioned MTL problems such   as forgetting and interference between tasks . Re-   cently , it has been used for zero - shot cross - lingual   transfer framework ( Pfeiffer et al . , 2020c ; Wang   et al . , 2021b ) , which motivates our work to transfer   multi - source knowledge with less interference for   zero - shot commonsense reasoning .   3 Modularized Zero - shot Framework   In our setup , we repurpose synthetic QA genera-   tion ( Ma et al . , 2021 ) for the task of knowledge-   driven zero - shot learning for commonsense reason-   ing , i.e. , we transform a KG into multiple ( Q , A )   pairs where Qis a natural language question and   A={A, ... ,A}is the set of options with   manswer candidates . Speciﬁcally , given a triple   ( e , r , e)in a KG , where e , eandr   denote head / tail entity and relation respectively , we   transformeandrinto a natural language ques-   tionQusing templates . For the option set A , we   use the combination of the correct answer eand   m−1distractors which are tail entities from other   triples sampled randomly ( Ma et al . , 2021 ) . Details   are described in Appendix B.   Formally , we denote ( Q , A)as one QA sam-   ple . The goal is to learn a QA model from the   synthetic QA sample . In a downstream task ( e.g. ,   reasoning benchmarks such as SocialIQA and Com-   monsenseQA ) , we need to predict answers given   non - synthetic test samples ( Q , A ) . In the   training stage , we are given KKG - driven datasets   { D}fromKdifferent KGs , where Dis   a dataset with Nsamples for KG kas follows :   D={(Q , A , label ) } ( 1 )   wherelabel is the index of the correct answer   for each sample . In this work , as shown in Ta-   ble 1 , we generate four synthetic QA datasets   from ATOMIC , ConceptNet , WikiData , and   WordNet ( More details are in Appendix C ) .   For effective use of multiple KGs at once with   less interference , we present a modularized frame-   work , which is a novel approach to knowledge   transfer for the zero - shot setting as shown in Fig-   ure 1 . As a modular approach , we train the mul-   tiple KG - speciﬁc adapters ( expert adapters ) with   each dataset from KG . Based on these pre - trained   adapters , we use a zero - shot fusion method to   aggregate knowledge of each adapter leveraging   AdapterFusion ( Pfeiffer et al . , 2021 ) as a base   architecture with the balanced mixture of each   KG dataset . Further , for better knowledge fusion ,   we suggest a KG - alignment aware adapter ( KG-   Classiﬁer adapter ) as a guide for detecting align-   ment with given sample in zero - shot reasoning .   Here , we utilize KG classiﬁcation dataset by veri-   fying the synthetic QAs . Algorithm 1 in Appendix   outlines the overall process of our proposed frame-   work . We summarize the notations in Appendix A.   3.1 KG Modularization   First , we modularize the KGs to preserve their in-   trinsic knowledge . Considering the importance of   using a suitable and well - aligned KG ( Ma et al . ,   2019 , 2021 ) on a downstream task , the subtle   difference between each KG should be learned   by the model without any interference from each   other . Accordingly , we adopt the adapter mod-   ule ( Houlsby et al . , 2019 ) which repurposes a pre-   trained language model ( PLM ) to incorporate each2246   KG as tiny modules in between Transformer blocks .   Speciﬁcally , as illustrated in Figure 2 ( except for   green area ) , the adapter training strategy involves   injecting new layers ( parameterized by Φ ) into the   original PLM ( parameterized by θ ) . The weights   of the original PLM are untouched , while the new   adapter layers are initialized at random . Formally ,   we call each adapter trained with Das an expert   adapter for KGk , parameterized by Φ.   When a QA sample ( Q , A)is given for dataset   D , we ﬁrst concatenate question Qand each   answer option A={A, ... ,A}to generate   input sequences T={T, ... ,T } . Then , we   compute a score S(Ma et al . , 2021 ) for the an-   swer candidate Ais computed as follows :   S=−1   |T|/summationdisplaylogP ( w| ... w , w ... ;θ , Φ )   ( 2 )   wherewis a word token in the sequence Tand   Pis the conditional probability from Transformer   blocks parameterized by θandΦ. To train the   adapter Φ , we use the marginal ranking loss ( Ma   et al . , 2021 ) as follows :   L=1   m / summationdisplay / summationdisplaymax(0,η−S + S )   ( 3 )   whereηrepresents the margin .   Φ←argminL(D;θ , Φ ) ( 4 )   where KG - invariant parameters θare ﬁxed and only   KG - dependent parameters Φare learned , whichenables to store the corresponding knowledge sep-   arately without any interference . Further , we can   parallelize the training of adapter for all KGs . The   efﬁciency of adapter training allows our modular-   ization to be more scalable .   3.2 Zero - shot Fusion   Once the expert adapters are learned , we combine   the knowledge from each expert adapter using an   attention - like mechanism . We present a novel fu-   sion strategy as shown in Figure 2 , which is referred   to as the zero - shot fusion . In contrast to Adapter-   Fusion ( Pfeiffer et al . , 2021 ) where the focus is   learning to transfer knowledge to a speciﬁc target   task , our zero - shot fusion aims to generalize this   transfer to any arbitrary target task . Speciﬁcally ,   the zero - shot fusion parameters Ψlearn to combine   ﬁxed expert adapters which are parameterized by   Φ, ... ,Φ. In each Transformer layer lof PLM   with the injected fusion layer , the zero - shot fusion   parameters Ψconsist of query , key , and value   matrices , denoted by W , W , and Wrespec-   tively . These parameters are used to learn the bal-   ancing between the representation of each expert   adapters through attention - like mechanism . While   ﬁxing both the parameters θand all expert adapters   Φ, ... ,Φ , the only trainable weights Ψon   the fusion layer learns to combine the knowledge   from different Kexpert adapters by using the sub-   set of{D}by random sampling . Here , we   balance the ratio between the Kknowledge - driven   datasets asNsamples ( details are in Appendix D ) .   Formally ,   Ψ←argmin / summationdisplayL(D;θ,{Φ},Ψ )   ( 5 )   where Ψrefers to the initialized zero - shot fusion   parameters .   More speciﬁcally , in the l - th Transformer layer ,   leth andhbe the representations of un-   derlying PLM parameterized by θand an expert   adapter parameterized by Φ , respectively . Then ,   using the hidden representation h of PLM as   a query , the fusion layer performs the attention - like   function as follows :   K , V= [ h, ... ,h ] ( 6 )   Q = h ( 7 )   z = Attention ( QW , KW , VW)(8)2247   where zis passed to the next Transformer layer .   Given a sample , the zero - shot fusion learns the   suitable balancing parameters between the expert   adapters for zero - shot reasoning . Eventually , it   learns to identify generalizability across common-   sense reasoning tasks .   3.3 KG - Classiﬁer Adapter   AdapterFusion uses the PLM hidden representation   h as a query which is learned when training   on a speciﬁc downstream task . In our zero - shot   setting , however , we use a mixture of synthetic QA   for fusion training , which is not exactly a training   dataset for a downstream task . To compensate for   this issue , we present KG - Classiﬁer adapter , which   is a KG alignment - aware adapter , which is moti-   vated from the fact that the ability to ﬁnd which   KG has an alignment with the given sample can be   helpful as a role of providing a guidance for better   performance ( Ma et al . , 2019 , 2021 ) .   Speciﬁcally , we propose a novel training task for   KG - Classiﬁer adapter , which requires predicting   the KG for the given sample of the task . For that ,   given{D } , we ﬁrst transform a QA sam-   ple(Q , A)into a new KG classiﬁcation sample   [ Q;A ] where [ ; ] is the concatenation . Then ,   we obtain a new label y∈ { 0,1}indicating   the corresponding KG source . The samples are in   Appendix E. Formally , KG classiﬁcation dataset   D is deﬁned as :   D = { ( [ Q;A ] , y ) } ( 9 )   whereMis the total size of{D}.Based onD , we learn the KG - Classiﬁer   adapter parameterized by θandΦ . First , a   classiﬁcation sample iis encoded into h∈   Rthen scored as ˆy∈Rwith a linear layer   W∈R , i.e. ,ˆy = Wh . Once ˆy   is normalized by a softmax layer , the network is   trained to minimize the cross - entropy loss L   between the prediction ˆyand its ground truth y :   Φ←argmin / summationdisplayL(y,ˆy;θ , Φ ) ( 10 )   We propose to use the representation of KG-   Classiﬁer adapter as a query in attention - like mech-   anism , referred to as the zero - shot fusion with KG-   Classiﬁer adapter . That is , using the hidden repre-   sentationh of aKG - Classiﬁer adapter param-   eterized by Φ as a query , we substitute Qin   Eq . ( 11 ) as follows :   Q = h ( 11 )   The overall zero - shot fusion architecture including   KG - Classiﬁer is illustrated in Figure 2 .   4 Experiments   In this section we evaluate the efﬁcacy of our frame-   work on ﬁve commonsense reasoning tasks . We   denote KG - Classiﬁer adapter byKG - C adapter .   4.1 Experimental Settings   All our experiments are conducted in a zero - shot   setting , in which the models do not have access to   the ofﬁcial training data or labels of the benchmark .   For the evaluation , we use the validation set of   each benchmark , however , the validation set of   each benchmark can be role as an test set since   it is not used for hyperparameter tuning or model   selection . We use accuracy as a metric .   4.1.1 Benchmarks   We evaluate our proposed framework on ﬁve   question - answering benchmarks for commonsense   reasoning : SocialIQA ( SIQA ) ( Sap et al . , 2019b ) ,   CommonsenseQA ( CSQA ) ( Talmor et al . , 2018 ) ,   Abductive NLI ( a - NLI ) ( Bhagavatula et al . , 2020 ) ,   PhysicalIQA ( PIQA ) ( Bisk et al . , 2020 ) , and Wino-   Grande ( WG ) ( Sakaguchi et al . , 2020 ) . Each com-   monsense benchmark evaluates a speciﬁc kind   of knowledge : social commonsense for SIQA ,   concept - level commonsense for CSQA , abductive2248   reasoning for a - NLI , physical commonsense for   PIQA , and pronoun resolution ability for WG .   The details are presented in Appendix G.   4.1.2 Baselines   We compare our framework with the following   baselines . First , to show the characteristics of   each benchmark , we use the random or the most   frequent label as Random and Majority base-   line , respectively . RoBERTa - L and GPT2 - L is   the performance of each PLM without any ﬁne-   tuning . Also , as the baseline for the unsuper-   vised learning model using KGs , we report the   performance of Self - talk ( Shwartz et al . , 2020 ) ,   COMET - DynaGen ( Bosselut and Choi , 2019 ) ,   SMLM ( Banerjee and Baral , 2020 ) as presented   in original papers .   For further analysis in § 4.4 and§4.5 , we set the   following models that are pre - trained on the syn-   thetic QA datasets from KGs as baselines :   •Single - Task Learning ( STL ) : The model is   pre - trained on a synthetic QA dataset gener-   ated from a single KG . Speciﬁcally , we exper-   iment two architectural choices : PLM ( STL-   PLM ) and PLM with adapters ( STL - Adapter ) .   For each architecture , there are four STL mod-   els for each of synthetic QA datasets derived   from ATOMIC , ConceptNet , WikiData ,   andWordNet . We note that the trained STL-   Adapter is an expert adapter from a speciﬁc   KG in our framework . The performance ofeach STL baseline is shown in Appendix I   Table 9 and Table 10 .   •Multi - Task Learning ( MTL ) : The model is   pre - trained on multiple synthetic QA datasets ,   each of which is generated from a KG . We   experiment with a PLM trained on all four   aforementioned synthetic QA datasets . We   note that the difference between STL - PLM   and MTL is whether to use one synthetic QA   dataset or multiple synthetic QA datasets for   its training .   4.1.3 Implementations   We employ RoBERTa - L ( Liu et al . , 2019b ) from   Hugging Face ’s transformers toolkit for all experi-   ments . We follow the default settings from Ma et al .   ( 2021 ) . Our implementation uses Adapter ( Houlsby   et al . , 2019 ) and AdapterFusion ( Pfeiffer et al . ,   2021 ) as a base model architecture from Adpa-   terHub ( Pfeiffer et al . , 2020a ) . We run our experi-   ments with three different random seeds . The im-   plementation details are described in Appendix H.   4.2 Main Results   Table 2 shows the zero - shot evaluation results on   ﬁve benchmark datasets . Generally , zero - shot fu-   sion scores higher than the baselines across all   benchmarks , and further , zero - shot fusion shows   the best performance in all benchmarks except WG .   We note that although Ma et al . ( 2021 ) uses the syn-   thetic QA dataset after sample ﬁltering , our method   achieves comparable performance with the best per-   formance in WG , even with the raw dataset . Also ,   the average score of all evaluation benchmarks ( the2249last column of Table 2 ) shows that zero - shot fusion   has generalisability in commonsense reasoning .   In addition , zero - shot fusion achieves consis-   tent improvements over MTL . These results indi-   cate that our proposed zero - shot fusion method   attributes to fusing the knowledge of multiple KGs   more synergetically regardless of the task .   Moreover , as an ablation , we compare the zero-   shot fusion with and without KG - C adapter to ex-   plore the efﬁcacy of the KG - C adapter . We can   observe that zero - shot fusion with KG - C adapter   improves the average accuracy by 0.4 % , which im-   plies that the use of KG - C adapter improves the   overall performance and makes our method gener-   alize better on most of the evaluation benchmarks .   4.3 Impact of the KG - Classiﬁer Adapter   To assess the effects of the KG - C adapter itself , we   visualize and compare the ﬁnal layer [ CLS ] token   representation between PLM and KG - C adapter .   Figure 3 shows t - SNE ( Van der Maaten and Hinton ,   2008 ) plots of all representation of ﬁve benchmark   datasets . In this ﬁgure , every sample is mapped   into a 1024 - dimensional feature space through   RoBERTa - L model and projected back into a two-   dimensional plane by t - SNE . We can observe that   KG - C adapter can separate the samples of differ-   ent benchmarks well despite being unseen data . It   veriﬁes that KG - awareness acquired with the KG   classiﬁcation task is beneﬁcial to categorize the   given sample . The KG - C adapter can thus gener-   ate a relevant KG - aware query for a given sample   and help to fuse representations from suitable ex-   pert adapters in our proposed framework .   Further , we explore how the KG - C adapter   affects zero - shot fusion which is based on an   attention - like mechanism ( Pfeiffer et al . , 2021 )   compared to zero - shot fusion without KG - C   adapter . Here , while zero - shot fusion without KG-   C adapter simply uses the representation of PLM   as a query , zero - shot fusion with KG - C adapter   leverages the representation of KG - C adapter . To   illustrate this strength , we visualize the attention   probability of [ CLS ] token from each fusion layer   as a representative in Figure 4 . The column of the   darker cell indicates the adapter that has the big-   ger inﬂuence on the fused representation . We can   observe that zero - shot fusion with KG - C adapter   fuses the knowledge from different experts with a   subtle difference rather than focusing on a single   expert severely . This implies that KG - C adapter   enables the delicate balancing between multiple   knowledge sources based on the KG - alignment   awareness , which leads to performance improve-   ments in commonsense reasoning tasks . Interest-   ingly , both cases have the ability not to focus on   theexpert adapter based on WikiData , which   can be seen as a redundant expert . This obser-   vation would beneﬁt from the further study that   explores the optimal combination of KGs by expert   selection or rejection .   4.4 Mitigating Interference   In this experiment , we compare the amount of in-   terference in the MTL and zero - shot fusion with   KG - C adapter . We propose a novel evaluation met-   ric , the interference ratio , which is the percentage   of the incorrectly predicted samples by the multi-   KG models among the correctly predicted samples   from the STL models in common .   Using the interference ratio , we can precisely   compare the negative effects of multi - KG models2250   on knowledge aggregation since the only reason   to get the correct samples wrong is the interfer-   ence caused by learning with additional KGs . We   present the interference ratio of the models on ﬁve   benchmark datasets in Figure 5 . This ﬁgure shows   that MTL has the higher interference ratio than   the competing models across all benchmarks . Our   method achieves a substantially better ratio , espe-   cially when KG - C adapter is used . This demon-   strates the efﬁcacy of our framework in mitigating   interference between knowledge , which is one of   the major problems of MTL .   4.5 Visualization of Knowledge Aggregation   To verify the ability of our model to aggregate dif-   ferent types of KGs , we compare the relative per-   formance gains of MTL and zero - shot fusion with   KG - C adapter when increasing the number of KGs .   The performance of all KG - combinations for each   framework is presented in Table 9 and Table 10 . We   visualize the improvement of performance for ﬁve   benchmark development sets , leveraging heatmaps   in Figure 6 . Here , for the sake of brevity , we denote   our framework with KG - C adapter as our method .   For MTL in Figure 6 ( a ) , the color of the cell   denotes the relative improvement of MTL with the   combination of KGs over the best performance   among the STL - PLM of KGs . Also , for our method   in Figure 6 ( b ) , the relative improvement is mea-   sured based on the best performance among the   STL - Adapter of KGs , considering the difference of   the base architecture for MTL ( i.e. PLM ) and zero-   shot fusion ( i.e. PLM with adapter ) . The green and   red colors denote the increase and decrease of per-   formance , respectively , when using multiple KGs   together . The greener color on the cells indicates   that the approach beneﬁts from an increasing num-   ber of KGs , which implies aggregating knowledge   successfully .   In Figure 6 , while the MTL tends to show the   decrease of the performance when more KGs are   utilized for training , our method obtains relative   performance improvement across most of bench-   marks . In both framework , the slightly degraded   performance of the combination of KGs without   ATOMIC could be due to the strong alignment be-   tween ATOMIC and SIQA . Except for the above   case , we can observe that as more KGs are lever-   aged , the color of the cell gets greener , which im-   plies that our method gains more advantages for   better performance . This demonstrates that our   method enables knowledge aggregation for multi-   ple KGs synergetically .   5 Conclusion   Despite the existence of various types of common-   sense KGs , utilizing multiple KGs has not been   explored enough in the commonsense reasoning   ﬁeld . Motivated by this , this paper proposes a   modularized transfer learning framework to fuse   the knowledge from multiple KGs efﬁciently for   zero - shot commonsense reasoning . Our framework   consists of KG modularization for expert adapter ,   zero - shot fusion and KG - Classiﬁer adapter . Exten-   sive experiments show that our framework obtains   strong improvements over MTL on ﬁve common-   sense reasoning benchmarks .   In the future , our work can be extended to adapt   our methods to further various multiple KGs with   studies of appropriate scale for KG modularization .   In addition , based on our hypothesis that the exis-   tence of an optimal combination , we can explore   the study for the optional use of modularized KG   experts for the best transfer learning.2251Acknowledgements   This work was partly supported by Institute of In-   formation & communications Technology Plan-   ning & Evaluation ( IITP ) grant funded by the   Korea government ( MSIT ) ( No . 2020 - 0 - 01361 ,   Artiﬁcial Intelligence Graduate School Program   ( Yonsei University ) ) and ( No . 2022 - 0 - 00077 , AI   Technology Development for Commonsense Ex-   traction , Reasoning , and Inference from Heteroge-   neous Data ) and the National Research Foundation   of Korea ( NRF ) grant funded by the Korea govern-   ment ( MSIT ) ( No . 2021 - 11 - 1055 ) . Jinyoung Yeo   is a corresponding author .   References22522253A List of Notations   We summarize the notations used in this paper in   Table 7 .   B Synthetic QA   We generate QA for four KGs ( ATOMIC ,   ConceptNet , WikiData andWordNet ) based   on synthetic QA generation ( Ma et al . , 2021 ) with-   out sample ﬁltering . We use the preﬁxes for relation   of triplet as shown in Table 3 for generating syn-   thetic QA ( refer to Ma et al . ( 2021 ) ) . Table 4 shows   the statistics of the synthetic QA dataset from KGs .   The samples of synthetic QA with source triplet   are shown in Table 5 .   C Commonsense Knowledge Graphs   A variety of KGs have been proposed to provide   large - scale high quality collection of different com-   monsense knowledge types : ATOMIC ( Sap et al . ,   2019a ) focuses on inferential knowledge organized   as typed if - then relations with variables ( e.g. , “ if X   pays Y a compliment , then Y will likely return the   compliment ” ) .ConceptNet ( Speer et al . , 2017 )   mainly consists of taxonomic and lexical knowl-   edge ( e.g. , RelatedTo , Synonym , and IsA ) and   physical commonsense knowledge ( e.g. , MadeOf   and PartOf ) . WikiData ( Vrande ˇci´c and Krötzsch ,   2014 ) is a general - domain KG which has a close   relation with Wikipedia . WordNet ( Miller , 1995 )   is a large lexical source of words and taxonomical   system .   D Dataset for Zero - shot Fusion   For zero - shot fusion training , we use balanced mix-   ture of synthetic QA from different KGs by random   sampling . The statistics of dataset for zero - shot fu-   sion is shown in Table 6 . For validation dataset , we   balance between the ATOMIC , ConceptNet and   WordNet due to the lack of synthetic QA valida-   tion dataset from WikiData .2254   E KG - Classiﬁcation Dataset   We suggest KG - Classiﬁcation dataset D for   KG - Classiﬁer adapter training . The example of   transformation from synthetic QA dataset Dis   shown in Table 8 . The dataset size is equal to the   whole dataset of synthetic QA ( refer to Table 4).F Zero - shot architecture with   parameters   We describe the illustration of the zero - shot fusion   architecture with parameters in Figure 7 .   G Commonsense Reasoning Benchmarks   SocialIQA ( SIQA ) ( Sap et al . , 2019b ) requires   reasoning for emotional and social intelligence in   everyday situations . Each QA consists of a con-   text that comes from ATOMIC , a question which   is based on the relations in ATOMIC , and 3 an-   swer candidates . It contains 38,000 multiple - choice2255questions , which is generated by crowdsourcing .   CommonsenseQA ( CSQA ) ( Talmor et al . , 2018 )   evaluates a broad range of concept - level common-   sense reasoning . Each multiple - choice question ,   answer and distractors are designed by crowdsourc-   ing based on the ConceptNet .   Abductive NLI ( a - NLI ) ( Bhagavatula et al . , 2020 )   asks to infer the most plausible explanation based   on the given causal situation to test abductive rea-   soning in narratives . Each sample consists of the   beginning and the end of the story with two pos-   sible options to be an explanation for the given   situation .   PhysicalIQA ( PIQA ) ( Bisk et al . , 2020 ) requires   physical commonsense reasoning to select the most   sensible solution for the given goal among the two   choices . Its dataset is comprised of over 16,000   training samples , 2 K validation samples , and 3 K   test samples .   HellaSWAG ( HSWAG ) ( Zellers et al . , 2019 ) is an   evolved version of SWAG ( Zellers et al . , 2018 ) ,   which asks to infer the most proper story based on   the given situation . The dataset consists of 70 K   questions with four answer options .   H Implementation Details   In all our experiments , we use max sequence length   128 , batch size 32 , weight decay 0.01 , adam β   0.9 , adamβ0.99 , adam epsilion 1e , warm - up   proportion 0.05 , and margin 1.0 . The experiments   are conducted split across NVIDIA GeForce 3090   and NVIDIA RTX A5000 .   H.1 Baselines   The baseline models for STL - PLM and MTL are   trained with learning rate 1efor single epoch .   H.2 Adapter   Forexpert adapters , we use learning rate 8eafter   tuning in{5e,8e,1e,5e,8e,1e } .   ForKG - Classiﬁer adapter , we use learning rate   1e , batch size 64 for ﬁve epochs .   H.3 Zero - shot fusion   After experiment with learning rates { 1e,8e } ,   we empirically ﬁnd that a learning rate of 1e   works well on zero - shot fusion without / with KG-   Classiﬁer adapter , respectively . Here , we set the at-   tention drop probability 0.1 . As we used extremely   smaller subset of the synthetic QA dataset , zero-   shot fusions are trained for ﬁve epochs . I Knowledge aggregation of zero - shot   fusion   In order to validate the efﬁcacy on knowledge ag-   gregation of zero - shot fusion over the STL , we   present the results of each framework with various   combination of KGs in Table 9 and Table 10.2256   Algorithm 1 : Proposed framework for zero - shot commonsense reasoning2257