  Shu Liu , Kaiwen Li , Zuhe LiSchool of Computer Science and Engineering , Central South UniversityHunan Engineering Research Center of Machine Vision and Intelligent MedicineSchool of Computer and Communication Engineering , Zhengzhou University of Light IndustryHenan Key Laboratory of Data Intelligence on Food Safety   { sliu35 , itkaven}@csu.edu.cn zuheli@126.com   Abstract   Aspect sentiment triplet extraction ( ASTE ) is   a challenging subtask in aspect - based senti-   ment analysis . It aims to explore the triplets   of aspects , opinions and sentiments with com-   plex correspondence from the context . The   bidirectional machine reading comprehension   ( BMRC ) can effectively deal with ASTE task ,   but several problems remains , such as query   conﬂict and probability unilateral decrease .   Therefore , this paper presents a robustly op-   timized BMRC method by incorporating four   improvements . The word segmentation is ap-   plied to facilitate the semantic learning . Ex-   clusive classiﬁers are designed to avoid the in-   terference between different queries . A span   matching rule is proposed to select the aspects   and opinions that better represent the expec-   tations of the model . The probability gen-   eration strategy is also introduced to obtain   the predicted probability for aspects , opinions   and aspect - opinion pairs . We have conducted   extensive experiments on multiple benchmark   datasets , where our model achieves the state-   of - the - art performance .   1 Introduction   Aspect - based sentiment analysis ( ABSA ) is an im-   portant research area of natural language process-   ing ( NLP ) , which aims to mine ﬁne - grained opin-   ions and sentiments based on a speciﬁc aspect . In   recent years , it has attracted extensive attention of   researchers ( Hu and Liu , 2004 ) . ABSA includes   three basic subtasks : aspect term extraction ( Yin   et al . , 2016 ; Li et al . , 2018 ; Ma et al . , 2019 ) , opin-   ion term extraction ( Liu et al . , 2015 ; Wu et al . ,   2021 ) , and aspect level sentiment classiﬁcation   ( Wang et al . , 2016 ; Chen et al . , 2017 ; Jiang et al . ,   2019 ; Zhang and Qian , 2020 ) .   Substantial progress has been achieved in re-   cent studies , integrating multiple subtasks into amore complex task ( Chen and Qian , 2020 ; He et al . ,   2019 ; Luo et al . , 2019 ; Zhao et al . , 2020 ) . Among   them , aspect sentiment triplet extraction ( ASTE )   ( Peng et al . , 2020 ) becomes a subject of great in-   terest , which is also the goal of our work . Many   research efforts have been made ( Xu et al . , 2021 ;   Mao et al . , 2021 ; Chen et al . , 2021 ) , for example ,   using bidirectional machine reading comprehen-   sion ( BMRC ) for ASTE . It handles the task effec-   tively , but problems still remain . In the structure   of BMRC , the shared classiﬁers may lead to query   conﬂicts based on speciﬁc context , thus affecting   the model performance . Some important strategies   are also ignored , such as word segmentation , span   matching and probability generation .   In this paper , we present a robustly optimized   BMRC method for ASTE . The task is transformed   into a machine reading comprehension problem .   The complex correspondence between the aspect   and opinion is processed through bidirectional   query based on speciﬁc context . Such relationship   can be effectively used to make their extraction   mutually beneﬁcial , thus facilitating better predic-   tion of various sentiments . In order to deal with   the ASTE task more efﬁciently , we incorporate the   word segmentation and exclusive classiﬁers , and   improve the span matching where the priority rule   of the combination of probability and position re-   lationship has been added . We also optimize the   generation of probability to avoid its unilateral de-   crease . Our contributions can be summarized as   follows :   •Exclusive classiﬁers are designed in BMRC ,   so as to avoid the interference between dif-   ferent question answering steps and the query   conﬂict .   •We further advance the prediction perfor-   mance by adding word segmentation , improv-   ing span matching and probability generation .   •Extensive experiments are conducted on272   benchmark datasets , where our model   achieves the state - of - the - art performance .   2 Methodology   In this section , we brieﬂy review the ASTE task   and BMRC model , and then introduce our four   improvements in detail .   2.1 Problem Formulation   Given a sentence W={w , w , ... , w}withM   tokens , ASTE task is to identify the collection of   triplets T={(a , o , s ) } , where a , o , sand   |T|denote the aspect , the opinion expression , the   sentiment , and the number of triplets , respectively .   For the sentence shown in Figure 1 , the collection   Tis{(portions , small , negative ) , ( food , good ,   positive ) } .   2.2 BMRC   BMRC can put forward the corresponding query ac-   cording to the context , and the model then outputs   the desired answer .   Forward Query BMRC will query all the aspects   based on context ; Then , according to the aspect   of each prediction , all opinions describing it are   queried from the context .   Backward Query BMRC will query all the opin-   ions based on context ; Then , according to the opin-   ion of each prediction , all aspects describing it are   queried from the context .   Sentiment Prediction Once the aspect - opinion   pairs are obtained , the sentiment queries can be   constructed to predict the sentiments of the corre-   sponding pairs according to the context .   After that , the sentiments and aspect - opinion   pairs are combined into triplets . The whole process   is illustrated in Figure 2 .   2.3 Word Segmentation   We use the tokenizer based on wordpiece in BERT   ( Devlin et al . , 2019 ) to segment words into sub-   words . Wordpiece is a common technique for word   segmentation in NLP tasks . The role of word segmentation has been inves-   tigated . Suppose the word " walking " is fed into   the model , unless it appears many times in the   training corpus , the model may fail to handle the   word well . When similar words like " walked " ,   " walker " or"walks " show up , without word seg-   mentation , they will be treated as completely dif-   ferent words . However , if they are subdivided into   " walk # # ing " , " walk # # ed " , " walk # # er " , and " walk   # # s " , their sub - word " walk " contains the same se-   mantics which is quite common during training . In   this sense , the model is able to learn more informa-   tion through word segmentation .   2.4 Exclusive Classiﬁers   Bidirectional queries are performed in BMRC , and   the model needs to perform multiple different types   of queries based on context . For example , the   aspect query in forward query is different from   the opinion query in backward query . The former   queries all the aspects in the context , while the lat-   ter queries all the opinions in the context , requiring   different entities . Another example is the aspect   query in the forward query and the aspect query in   the backward query . Although the entities of the   two queries are the same , the latter conveys opin-   ion information and searches for all the aspects   described by it , while the former does not carry any   context information , namely , all the aspects in the   context .   In the original BMRC , all queries share one clas-   siﬁer . However , if different types of queries use the   same classiﬁer , it can not serve any part very well .   These different types of queries will interfere with   each other and cause the query conﬂict . By adding   exclusive classiﬁers , each different type of query   can use a unique classiﬁer , as shown in Figure 3 ,   which can effectively avoid the problem of query   conﬂict and greatly improve the performance of the   model .   2.5 Span Matching   Recently , there is a lot of work to deal with ABSA   tasks based on span extraction ( Hu et al . , 2019 ;   Xu et al . , 2021 ) , so does BMRC . After obtaining   the predicted value of each position as the start or   end position of span through binary classiﬁers , the   predicted value is converted into probability using   softmax function ( Chen et al . , 2021 ) .   When predicting the span , many start and end   positions may be predicted . The rule to match them   is very important , which will seriously affect the273   performance of the model . The matching should   consider the probability of start and end positions ,   as well as the relationship between the positions .   The former represents the optimistic degree of the   model for the position , and the latter is the judg-   ment that the start and end positions of span are   as close as possible ; the priority of probability is   higher . So , the overview of our span matching rule   is : make each end position match the start position   with the highest probability after the previous end   position . If there is a start position with the same   probability , select the one whose position is closest   to the end position.2.6 Probability Generation   Once the bidirectional queries and span matching   are completed , the aspects , opinions and pairs with   corresponding relationship are obtained . In BMRC ,   the probability product of the start and end posi-   tions is taken as the probability of the span , and the   probability of pair is the probability product of as-   pect and opinion . In this way , the probability of pair   decreases unilaterally and can not well represent   the prediction of the pair by the model . For exam-   ple , the probability of the four positions of pair is   0.9 , while the probability of pair is 0.9= 0.6561 ,   which seems not so reasonable .   By probability generation , we can effectively   solve the problem of unilateral decrease in the prob-   ability of span and pair , so that their probability can   better reﬂect the expectation of the model . The op-   erations are shown in Equation 1 and 2 , where we   balance the probability of span and pair so that their   probability is within the interval of the two related   probabilities . It enables us to avoid the unilateral   decrease of probability , but keep more appropriate   to the expectation of the model .   P(span ) =   P(span ) ∗P(span)(1 )   P(pair ) =   P(pair)∗P(pair ) ( 2)274   In the above equations , P(⋆)represents the pre-   diction probability of ⋆. The span represents an   aspect or opinion , span andspanrepresent   its start and end positions . The pair represents an   aspect - opinion pair , pairandpairrepresent   the aspect and opinion in the pair . For the conve-   nience of comparison , the calculation method of   P(span ) andP(span)is consistent with   BMRC ( Chen et al . , 2021 ) .   The effects of span matching and probability   generation are shown in Figure 4 .   3 Experiment   In this section , we introduce information about the   experiments , including datasets , evaluation metrics ,   baselines , experimental results , and ablation study .   3.1 Datasets   We evaluate the model performance on ASTE - Data-   v1 ( Peng et al . , 2020 ) and ASTE - Data - v2 ( Xu   et al . , 2020 ) , which are popular benchmark datasets   for ASTE task . They are derived from Laptop14 ,   Rest14 , Rest15 , and Rest16 of SemEval shared   challenges ( Pontiki et al . , 2014 , 2015 , 2016 ) . The   ASTE - Data - v2 datasets are the reﬁned data of the   previous ASTE - Data - V1 datasets.3.2 Evaluation Metrics   We use precision ( P ) , recall ( R ) and F1 scores as   evaluation metrics to gauge the performance . A   triplet prediction is correct only if the aspect , opin-   ion and sentiment are predicted correctly .   3.3 Results   We focus on the ASTE task . The experimen-   tal results on ASTE - Data - v1 and ASTE - Data - v2   datasets are shown in Tables 1 and 2 , respectively .   In order to make a fair comparison with baselines ,   our F1 scores appear at least three times in the   experiments .   It is worth noting that we have achieved state - of-   the - art performances on both ASTE - Data datasets ,   indicating that our improvements further advance   the performance of BMRC in dealing with ASTE   task . On the Laptop14 , Rest14 , Rest15 , and Rest16   datasets of ASTE - Data - v1 , the F1 scores of our   model are increased by 2.97 , 4.20 , 5.61 and 5.52 re-   spectively , compared with the original BMRC . As   for ASTE - Data - v2 , we also increase the F1 scores   of the Strong baseline Span - ASTE ( Xu et al . , 2021 )   by 2.74 , 0.77 , 2.36 and 2.90 , respectively . This   indicates that our improvement is very signiﬁcant.275   3.4 Ablation Experiments   Firstly , we experiment the model without improve-   ment on the ASTE - Data - v2 . The model is a re-   production based on BMRC , and then gradually   superimposes the four improvements of word seg-   mentation , exclusive classiﬁers , span matching and   probability generation to conduct ablation exper-   iment . This arrangement corresponds to the se-   quence before and after they contact the data , that   is , the data will ﬁrst pass through word segmenta-   tion and enter the model , the prediction value is   obtained from the exclusive classiﬁers , and then   span matching is carried out according to it . Fi-   nally , the probability generation is used to generate   probabilistic representations of aspects , opinions   and pairs . The datasets and various parameters of   the ﬁve experiments are the same . In order to make   a fair comparison with baselines , our F1 scores ap-   pear at least three times in the experiments . The   ablation experimental results are shown in Table   3 . Each improvement advances the performance   of the model , demonstrating their advantages and   effectiveness.4 Conclusion   In this paper , we propose several improvements   on the basis of BMRC for ASTE task , which can   effectively deal with the complex correspondence   among aspect , opinion and sentiment . In order   to deal with the problems of the original BMRC ,   we add exclusive classiﬁers and three strategies ,   including word segmentation , span matching and   probability generation . The proposed method is   expected to handle complex ASTE task more ef-   ﬁciently . Extensive experiments are conducted to   demonstrate the advantages of our improvements .   Acknowledgements   This work was supported by the National Natural   Science Foundation of China ( No . 61902435 and   61702462 ) , the Fundamental Research Funds for   the Central Universities of Central South Univer-   sity , and the Scientiﬁc and Technological Project   of Henan Province ( No . 222102210010 ) . We are   grateful for resources from the High Performance   Computing Center of Central South University.276References277278