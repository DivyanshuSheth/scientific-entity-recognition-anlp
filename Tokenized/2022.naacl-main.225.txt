  Hassan SajjadNadir DurraniFahim DalviFiroj AlamAbdul Rafae KhanJia Xu   { hsajjad , ndurrani , faimaduddin , fialam}@hbku.edu.qaQatar Computing Research Institute , HBKU Research Complex , Qatar   { akhan4,jxu70}@stevens.eduSchool of Engineering and Science , Steven Institute of Technology , USA   Abstract   We propose a novel framework ConceptX ,   to analyze how latent concepts are encoded in   representations learned within pre - trained lan-   guage models . It uses clustering to discover the   encoded concepts and explains them by align-   ing with a large set of human - defined concepts .   Our analysis on seven transformer language   models reveal interesting insights : i ) the la-   tent space within the learned representations   overlap with different linguistic concepts to a   varying degree , ii ) the lower layers in the model   are dominated by lexical concepts ( e.g. , affixa-   tion ) , whereas the core - linguistic concepts ( e.g. ,   morphological or syntactic relations ) are bet-   ter represented in the middle and higher layers ,   iii ) some encoded concepts are multi - faceted   and can not be adequately explained using the   existing human - defined concepts .   1 Introduction   Contextualized word representations learned in   deep neural network models ( DDNs ) capture rich   concepts making them ubiquitous for transfer learn-   ing towards downstream NLP . Despite their revolu-   tion , the blackbox nature of the deep NLP models   is a major bottle - neck for their large scale adapt-   ability . Understanding the inner dynamics of these   models is important to ensure fairness , robustness ,   reliability and control .   A plethora of research has been carried out to   probe DNNs for the linguistic knowledge ( e.g. mor-   phology , syntactic and semantic roles ) captured   within the learned representations . A commonly   used framework to gauge how well linguistic infor-   mation can be extracted from these models is the   Probing Framework ( Hupkes et al . , 2018 ) , where   they train an auxiliary classifier using representa-   tions as features to predict the property of inter-   est . The performance of the classifier reflects theamount of knowledge learned within representa-   tions . To this end , the researchers have analyzed   what knowledge is learned within the representa-   tions through relevant extrinsic phenomenon vary-   ing from word morphology ( Vylomova et al . , 2016 ;   Belinkov et al . , 2017a ) to high level concepts such   as syntactic structure ( Blevins et al . , 2018 ; Marvin   and Linzen , 2018 ) and semantics ( Qian et al . , 2016 ;   Reif et al . , 2019 ; Belinkov et al . , 2017b ) or more   generic properties ( Adi et al . , 2016 ; Rogers et al . ,   2020 ) .   In this work , we approach the representation   analysis from a different angle and present a novel   framework ConceptX . In contrast to relying on   the prediction capacity of the representations , we   analyze the latent concepts learned within these rep-   resentations and how knowledge is structured , us-   ing an unsupervised method . More specifically , we   question : i ) do the representations encode knowl-   edge inline with linguistic properties such as word   morphology and semantics ? ii ) which properties   dominate the overall structure in these representa-   tions ? iii ) does the model learn any novel concepts   beyond linguistic properties ? Answers to these   questions reveal how deep neural network models   structure language information to learn a task .   Our inspiration to use the term concept comes   from “ concept based explanation ” in computer   vision ( Kim et al . , 2018 ; Ghorbani et al . , 2019 ;   Chen et al . , 2020 ) . Stock ( 2010 ) defined a concept   as “ a class containing certain objects as elements ,   where the objects have certain properties ” . We   define an encoded concept as a cluster of context-   aware latent representations of words , where the   representations are encoder layer outputs .   Our framework clusters contextualized repre-   sentations using agglomerative hierarchical clus-   tering ( Gowda and Krishna , 1978 ) . The result-   ing clusters represent encoded concepts , captured   within the learned representations ( Please see Fig-   ure 1 for illustration ) . We then use a novel align-3082   ment function that measures the amount of over-   lap between encoded concepts and a range of pre-   defined categories ( that we call as human - defined   concepts in this paper ) . We experimented with   affixes , casing , morphological , syntactic , seman-   tic , WordNet ( Miller , 1995 ) , and psycholinguistic   concepts ( LIWC Pennebaker et al . ( 2001 ) ) . The   use of such a diverse set of human - defined con-   cepts enables us to cover various abstractions of   language . In Figure 3 we present a few examples   of human - defined concepts that were aligned with   the encoded concepts .   We carry out our study on seven pre - trained   transformer models such as BERT ( Devlin et al . ,   2019 ) and XLM - RoBERTa ( Conneau et al . , 2020 ) ,   with varying optimization functions , architectural   details and training data . Some notable findings   emerging from our analysis are as follows :   •Shallow concepts such as lexical ngrams or   suffixes are predominantly captured in the   lower layers of the network .   •WordNet and psycholinguistic - based concepts   ( LIWC ) are also learned in the lower layers .   •Middle and higher layers encode concepts that   capture core linguistic properties such as mor-   phology , semantics and syntax .   •Roughly 50 % of the encoded concepts adhere   to our suite of human - defined linguistic con-   cepts .   •The models learn novel concepts that are   multi - faceted and can not be adequately ex-   plained using the existing human - defined con-   cepts . Our contributions in this paper are as follow : i ) We   present ConceptX , a framework that interprets   encoded concepts in the learned representation by   measuring their alignment to the human - defined   concepts . ii ) We provide a qualitative and quan-   titative evidence of how knowledge is structured   within deep NLP models with respect to a large   suite of human - defined concepts .   2 Related Work   Most of the work done on interpretability in deep   NLP addresses two questions in particular : ( i )   what linguistic ( and non - linguistic ) knowledge is   learned within contextualized representations , Con-   cept Analysis and(ii)how this information is uti-   lized in the decision making process , Attribution   Analysis ( Sajjad et al . , 2021 ) . The former thrives on   post - hoc decomposability , where we analyze repre-   sentations to uncover linguistic phenomenon that   are captured as the network is trained towards any   NLP task ( Adi et al . , 2016 ; Conneau et al . , 2018 ;   Liu et al . , 2019a ; Tenney et al . , 2019 ; Belinkov   et al . , 2020 ) and the latter characterize the role of   model components and input features towards a   specific prediction ( Linzen et al . , 2016 ; Gulordava   et al . , 2018 ; Marvin and Linzen , 2018 ) . Our work   falls into the former category .   Previous studies have explored visualization   methods to analyze the learned representations   ( Karpathy et al . , 2015 ; Kádár et al . , 2017 ) , atten-   tion heads ( Clark et al . , 2019 ; Vig , 2019 ) , language   compositionality ( Li et al . , 2016 ) etc . A more com-   monly used framework analyzes representations by   correlating parts of the neural network with linguis-   tic properties , by training a classifier to predict a3083feature of interest ( Adi et al . , 2016 ; Belinkov et al . ,   2017a ; Conneau et al . , 2018 ) . Several researchers   used probing classifiers for investigating the con-   textualized representations learned from a variety   of neural language models on a variety of character-   ( Durrani et al . , 2019 ) , word- ( Liu et al . , 2019a ) or   sub - sentence level ( Tenney et al . , 2019 ) linguistic   tasks . Rather than analyzing the representations as   a whole , several researchers also explored identify-   ing salient neurons within the model that capture   different properties ( Dalvi et al . , 2019a ; Durrani   et al . , 2020 ; Suau et al . , 2020 ; Mu and Andreas ,   2020 ) or are salient for the model irrespective of   the property ( Bau et al . , 2019 ; Wu et al . , 2020 ) .   Our work is inline with ( Michael et al . , 2020 ;   Dalvi et al . , 2022 ) , who analyzed latent concepts   learned in pre - trained models . Michael et al . ( 2020 )   used a binary classification task to induce latent   concepts relevant to a task and showed the presence   of linguistically motivated and novel concepts in   the representation . However , different from them ,   we analyze representations in an unsupervised fash-   ion . Dalvi et al . ( 2022 ) used human - in - the - loop to   analyze latent spaces in BERT . Our framework uses   human - defined concepts to automatically generate   explanations for the latent concepts . This enabled   us to scale our study to many transformer models .   In a similar work , Mamou et al . ( 2020 ) ap-   plied manifold analysis technique to understand   the amount of information stored about object cate-   gories per unit . Our approach does away from the   methodological limitations of probing framework   such as complexity of the probes , effect of random-   ness etc ( Belinkov , 2021 ) . However , it is important   to mention that the two frameworks are orthogonal   and complement each other .   3 Methodology   A vector representation in the neural network   model is composed of feature attributes of the in-   put words . We group the encoded vector repre-   sentations using a clustering approach discussed   below . The underlying clusters , that we term as   theencoded concepts , are then matched with the   human - defined concepts using an alignment func-   tion . Formally , consider a Neural Network ( NN )   modelMwithLencoder layers { l , l , ... l , ... , l } ,   withHhidden nodes per layer . An input sentence   consisting of Mwords w , w , ... w , ... , wis fed   into a NN . For each input word i , we compute   the node output ( after applying the activation func - tions ) y(w)of every hidden node h∈ { 1 , ... , H }   in each layer l , where− →y(w)is the vector rep-   resentation composing the outputs of all hidden   nodes in layer lforw . Our goal is to cluster repre-   sentations− →y , from a large training data to obtain   encoded concepts . We then align these with various   human - defined concepts to obtain an explanation   of them to build an understanding of how these   concepts are represented across the network .   3.1 Clustering   We use agglomerative hierarchical cluster-   ing ( Gowda and Krishna , 1978 ) , which we found   to be effective for this task . It assigns each word   to a separate cluster and then iteratively combines   them based on Ward ’s minimum variance criterion   that minimizes intra - cluster variance . Distance   between two representations is calculated with   the squared Euclidean distance . The algorithm   terminates when the required Kclusters ( aka   encoded concepts ) are formed , where Kis a   hyperparameter . Each encoded concept represents   a latent relationship between the words present in   the cluster . Appendix C presents the algorithm .   3.2 Alignment   Now we define the alignment function between the   encoded and human - defined concepts . Consider   a human - defined concept as z , where a function   z(w ) = zdenotes that zis the human - defined   concept of word w. For example , parts - of - speech   is a human - defined concept and each tag such as   noun , verb etc . represents a class / label within the   concept , e.g. z(sea ) = noun . Similarly , suffix   is a human - defined concept with various suffixes   representing a class , e.g. z(bigger ) = er . A re-   verse function of z is a one - to - many function that   outputs a set of unique words with the given human-   defined concept , i.e. , z(z ) = { w , w , . . . , w } ,   likez(noun ) = { sea , tree , . . . } , where Jis   the total number of words with the human - defined   concept of z. Following this notation , an encoded   concept is indicated as c , where c(w ) = cis a   function of applying encoded concept on w , and   its reverse function outputs a set of unique words   with the encoded concept of c , i.e. , c(c ) =   { w , w , . . . , w } , where Iis the set size .   To align the encoded concepts with the human-   defined concepts , we auto - annotate the input data   that we used to get the clusters , with the human-   defined concepts . We call our encoded concept ( c)3084to be θ - aligned ( Λ ) with a human - defined concept   ( z ) as follows :   Λ(z , c ) = /braceleftigg   1,if≥θ   0,otherwise ,   where Kronecker function δ(w , w)is defined as   δ(w , w ) = /braceleftbigg1,ifw = w   0,otherwise   We compute candΛ(z , c)for the encoder output   from each layer lof a neural network . To compute   a network - wise alignment , we simply average θ-   agreement over layers .   4 Experimental Setup   4.1 Dataset   We used a subset of WMT News 2018(359 M   tokens ) dataset . We randomly selected 250k sen-   tences from the dataset ( ≈5 M tokens ) to train our   clustering model . We discarded words with a fre-   quency of less than 10 and selected maximum 10   occurrences of a word type . The final dataset con-   sists of 25k word types with 10 contexts per word .   4.2 Pre - trained Models   We carried out our analysis on various 12 - layered   transformer models such as BERT - cased ( BERT-   c , Devlin et al . , 2019 ) , BERT - uncased ( BERT - uc ) ,   RoBERTa ( Liu et al . , 2019b ) , XLNet ( Yang et al . ,   2019 ) and ALBERT ( Lan et al . , 2019 ) . We also   analyzed multilingual models such as multilingual-   bert - cased ( mBERT ) and XLM - RoBERTa ( XLM-   R , Conneau et al . , 2020 ) where the embedding   space is shared across many languages . This choice   of models is motivated from interesting differences   in their architectural designs , training data settings   ( cased vs. un - cased ) and multilinguality .   4.3 Clustering and Alignment   We extract contextualized representation of words   by performing a forward pass over the network us-   ing the NeuroX toolkit ( Dalvi et al . , 2019b ) . Wecluster representations in every layer into Kgroups .   To find an optimum value of K , we experimented   with the ELbow ( Thorndike , 1953 ) and Silhou-   ette ( Rousseeuw , 1987 ) methods . However , we   did not observe reliable results ( see Appendix C ) .   Therefore , we empirically selected K= 1000   based on finding a decent balance between many   small clusters ( over - clustering ) and a few large clus-   ters ( under - clustering ) . We found that our results   are not sensitive to this parameter and generalize   for different cluster settings ( See Section 5.4 ) . For   the alignment between encoded and human - defined   concepts , we use θ= 90 % i.e. , we consider an en-   coded concept and a human - defined concept to be   aligned , if they have at least 90 % match .   4.4 Human - defined concepts   We experiment with the various Human - defined   concepts , which we categorize into four groups :   •Lexical Concepts : Ngrams , Affixes , Casing ,   First and the Last Word ( in a sentence )   •Morphology and Semantics : POS tags ( Mar-   cus et al . , 1993 ) and SEM tags ( Abzianidze   et al . , 2017 )   •Syntactic : Chunking tags ( Tjong Kim Sang   and Buchholz , 2000 ) and CCG super - tags   ( Hockenmaier , 2006 )   •Linguistic Ontologies : WordNet ( Miller ,   1995 ) and LIWC ( Pennebaker et al . , 2001 )   At various places in this paper , we also refer to   Morphology , Semantics and Syntactic concepts as   core - linguistic concepts . We trained BERT - based   classifiers using gold - annotated training data and   standard splits for each core - linguistic concepts   and auto - labelled the selected news dataset using   these .   5 Analysis   In this section , we analyze the encoded concepts   by aligning them with the human - defined concepts .   5.1 Overall Alignment   First we present to what extent the encoded con-   cepts in the entire network align with the human-   defined concepts . We compute the overall score   as the percentage of the aligned encoded concepts   to the human - defined concepts across layers us-   ing the function described in Section 3.2 . We3085   found an overall match of at least 43.6 % in XL-   Net and at most 72.4 % in XLM - R ( See Table 1 ) .   Interestingly , the multilingual models ( mBERT and   XLM - R ) found substantially higher match than the   monolingual models . The inclusion of multiple   languages during training causes the model to learn   more linguistic properties . Note that the extent of   alignment with the human - defined concept may not   necessarily correlate with its overall performance .   For example XLNet performs outperforms BERT   on the GLUE tasks , but aligns less with the human-   defined concepts compared to BERT in our results .   A similar observation was made by Belinkov et al .   ( 2020 ) who also found that the translation quality of   an NMT model may not correlate with the amount   of linguistic knowledge learned in the representa-   tion . Various factors such as : architectural design ,   training data , objective function , initialization , etc ,   play a role in training a pre - trained model . More   controlled experiments are needed to understand   the relationship of each factor on the performance   of the model and on the linguistic learning of the   model .   We further investigated per conceptalignmentto understand which human - defined concepts are   better represented within the encoded concepts .   Figure 2 presents the results .   Lexical Concepts Pre - trained models encode   varying amount of lexical concepts such as casing ,   ngrams and suffixes . We found between 7 - 11 % en-   coded concepts that align with the casing concept   ( title case or upper case ) . We observed that most of   these encoded concepts consist of named entities ,   which were grouped together based on semantics .   Comparing suffixes and ngrams While affixes   often have linguistic connotation ( e.g. , the prefix   antinegates the meaning of the stem and the suffix   iesis used for pluralization ) , the ngram units that   become part of the vocabulary as an artifact of   statistical segmentation ( e.g. , using BPE ( Sennrich   et al . , 2016 ) or Word - piece ( Schuster and Nakajima ,   2012 ) ) often lack any linguistic meaning . However ,   models learn to encode such information . We found   a match ranging from 1 % ( BERT - cased ) up to 25 %   ( XLM - R ) when comparing encoded concepts with   the suffix concept . A similar pattern is observed   in the case of the ngram concept ( which is a super-   set of the suffix concept ) where a staggering 48 %   matches were found . Figure 6a shows an ngram   cluster found in layer 2 of BERT - c.   Morphology and Semantics We found that the   encoded concepts based on word morphology   ( POS ) consistently showed a higher match across   all models in comparison to the other abstract con-   cepts , aligning a quarter of the encoded concepts   in the case of mBERT . The alignment with seman-   tic concepts is relatively lower , with at most 16 %   match across models . This reflects that while the   models learn both linguistic properties , morpholog-   ical ontology is relatively preferred compared to   the semantic hierarchy .   Syntactic These concepts capture grammatical   orientation of a word , for example Chunking : B - NP   is a syntactic concept describing words in the be-   ginning of a noun phrase . CCG : PP / NP is a concept3086   in CCG super tagging , describing words that takes   a noun phrase on the right and outputs a preposi-   tion phrase for example “ [ in[the US ] ] ” . We found   relatively fewer matches , a maximum of 7 % and   14 % matching encoded concepts for Chunking and   CCG concepts respectively . The low matches for   syntactic concepts suggest that the models do not   encode the same syntactic hierarchy suggested by   these human - defined syntactic tasks .   Linguistic Ontologies Comparing the encoded   concepts with static linguistic ontologies , we found   WordNet concepts to be the second most aligned   concept ( 11 - 21 % ) with the human - defined con-   cepts . LIWC also shows a relatively higher align-   ment compared to the other human - defined con-   cepts in a few models ( e.g. , BERT - c ) . However ,   this observation is not consistent across models and   we found a range between 5 - 16 % matches . These   results present an interesting case where several   models prefer the distinction of lexical ontology   over abstract linguistic concepts such as morphol-   ogy . Figure 3 shows examples of encoded concepts   aligned with WordNet and LIWC . We see that these   concepts are built based on a semantic relationship   e.g. , the clusters in Figure 3b , 3c and 3d group   words based on religious , facial anatomy , and spe-   cific motion - related vocabulary respectively .   Comparing Models The results of multilingual   models ( mBERT , XLM - R ) are intriguing given that   their encoded concepts are dominated by ngram-   based concepts and POS concepts , and their rela-   tively lesser alignment with the linguistic ontolo-   gies . On the contrary , several monolingual models   ( BERT - c , ALBERT ) showed a better match with   linguistic ontologies specially WordNet .   The higher number of matches to the ngram ( and   suffix ) concepts in the multilingual models is due to   the difference in subword segmentation . The sub-   word models in XLM - R and mBERT are optimized   for multiple languages , resulting in a vocabularyconsisting of a large number of small ngram units .   This causes the multilingual models to aggressively   segment the input sequence , compared to the mono-   lingual modelsand resulted in highly dominated   ngram - based encoded concepts , especially in the   lower layers . This may also explain the relatively   lower match that multilingual models exhibit to the   linguistic ontologies . We discuss this further in the   context of layer - wise analysis in Section 5.2 .   Comparing BERT cased vs. uncased , interest-   ingly BERT - uc consistently showed higher matches   for the core - linguistic concepts ( See Figure 2 ) . We   speculate that in the absence of casing informa-   tion , BERT - uc is forced to learn more linguistic   concepts , whereas BERT - c leverages the explicit   casing information to capture more semantically   motivated concepts based on linguistic ontologies .   The higher matches in multilingual models in   comparison to the monolingual models , and BERT-   uncased in comparison to BERT - cased suggest that   the training complexity is one factor that plays a   role in a model ’s ability to learn linguistic nuances .   For example , multilingual models need to optimize   many languages , which is a harder task compared   to learning one language . Similarly , the absence   of capitalization in training data makes the learn-   ing task relatively harder for BERT - uc compared to   BERT - c models , thus resulting in higher matches   for BERT - uc . We speculate that the harder the train-   ing task , the more language nuances are learned   by a model . Belinkov et al . ( 2020 ) made a similar   observation , where they showed that the linguistic   knowledge learned within the encoder - decoder rep-   resentations in NMT models correlates with com-   plexity of a language - pair involved in the task .   5.2 Layer - wise Alignment   Now we study the alignment of human - defined   concepts across layers to understand how concepts3087   evolve in the network . Figure 4 shows results for   selected models . The y - axis is the normalized   number of aligned concepts across layers .   Overall Trend We observed mostly consistent   patterns across models except for ALBERT , which   we will discuss later in this section . We found that   the shallow concepts ( such as ngram and suffixes )   and the linguistic ontologies ( LIWC and WORD-   NET ) are better represented in the initial layers and   exhibit a downward trend in the higher layers of   the network . On the contrary the core linguistic   concepts ( POS , Chunking , etc . ) are better repre - sented in the higher layers ( layer 8 - 10 ) . The last   layers do not show any consistently dominating   human - defined concepts considered in this work .   We can generalize on these trends and hypothesize   on how encoded concepts evolve in the network :   the initial layers of the pretrained models , group   words based on their lexical and semantic similar-   ities where the former is an artifact of subword   segmentation . With the inclusion of context and ab-   straction in the higher layers , these groups evolve   into linguistic manifolds . The encoded concepts   in the last layers are influenced by the objective   function and learn concepts relevant to the task .   Durrani et al . ( 2021 ) also made similar observation3088when analyzing linguistic concepts in pre - trained   models that are fine - tuned towards different GLUE   tasks .   Concept - wise Trend In the following , we dis-   cuss different concepts in detail . As we mentioned   earlier , the high presence of ngram and suffix con-   cepts in the lower layers is due to subword seg-   mentation . At the higher layers , the models start   encoding abstract concepts , therefore get better   alignment with the core linguistic concepts . Cas-   ing shows an exception to other lexical concepts   and has similar trend to POS and SEM . Upon in-   vestigating we observed that the words appearing   in these clusters have a hybrid connotation . For   example , more than 98 % of the encoded concepts   that match with Casing are named entities , which   explains the trend . The syntactic concepts observe   peak in the higher - middle layers and a downward   trend towards the end . These findings resonate   with the earlier work on interpreting neural net-   work representations for BERT . For example Liu   et al . ( 2019a ) also showed that probes trained with   layers 7 - 8 give the highest accuracy when trained   towards predicting the tasks of Chunking and CCG   tagging . Although here , we are targeting a slightly   different question i.e. how the latent concepts are   encoded within the representations and how they   evolve from input to output layers of the network .   We observed a downward trend in linguistic on-   tologies ( WordNet , LIWC ) as we go from lower   layers to higher layers as opposed to the core lin-   guistic concepts ( POS , CCG , etc . ) . This is because   of the context independent nature of these concepts   as opposed to the core - linguistic concepts which   are annotated based on the context . The embed-   ding layer is non - contextualized , thus shows a high   match with linguistic ontologies . With the availabil-   ity of context in contextualized layers , the encoded   concepts evolve into context - aware groups , result-   ing in higher matches with core - linguistic concepts .   Comparing Models While the overall trend is   consistent among BERT - uc , mBERT and XLNet   ( and other studied models – Figure 10 in Appendix ) ,   the models somewhat differ in the last layers : see   the large drop in core - linguistic concepts such as   POS and Chunking for XLNet and mBERT in com-   parison to BERT . This suggests that BERT retains   much of the core - linguistic information at the last   layers . Durrani et al . ( 2020 ) observed a similar   pattern in their study , where they showed BERT toretain linguistic information deeper in the model as   opposed to XLNet where it was more localized and   predominantly preserved earlier in the network .   While the overall layer - wise trends of multilin-   gual models look similar to some monolingual mod-   els ( mBERT vs. XLNet in Fig 4b , c ) , the former ’s   absolute layer - wise matches ( numbers inside the   brackets in Figure 4 e.g. Casing ( 166 ) ) are gener-   ally substantially higher than the monolingual coun-   terparts . For example , the POS and SEM matches   of mBERT are 38.9 % and 30 % respectively which   are 18 % and 15 % higher than BERT - uc . On the   contrary , the number of matches with linguistic   ontologies is often lower for multilingual models   ( mBERT LIWC alignment of 65 vs. BERT - uc align-   ment of 186 ) . We hypothesize that the variety of   training languages in terms of their morphological   and syntactic structure has caused the multilingual   models to learn more core - linguistic concepts in   order to optimize the training task . Although , the   knowledge captured within linguistic ontologies is   essential , it may not be as critical to the training of   the model as the linguistic concepts .   ALBERT showed a very different trend from   the other models . Note that ALBERT shares param-   eters across layers while the other models have sep-   arate parameters for every layer . This explains the   ALBERT results where we see relatively less varia-   tion across layers . More interestingly , the encoded   concepts in the last layers of ALBERT showed   presence of all human - defined concepts considered   here ( see the relatively smaller drop of ALBERT   alignment curves in Figure 4 ) .   5.3 Unaligned Concepts   In Table 1 we observed that at least 27.6 % ( in   XLM - R ) and up to 56.4 % ( in XLNet ) encoded   concepts did not align with the human - defined con-   cepts . What concepts do these unaligned clusters   contain ? In an effort to answer this question , we   analyzed these clusters and observed that many of   them were compositional concepts that involves   more than one fine - grained categories of the human   defined concepts . Figure 5a shows an example of   the unaligned concept which partly aligns with a   semantic category ( SEM : geopolitical entity ) and a   morphological category ( POS : adjective ) . Similarly ,   Figure 5b is a verbs related to cognitive processes   and Figure 5c shows an unaligned cluster that is   composed of different verb forms ( past , present   and gerunds ) . The alignment with multiple human-3089   defined concepts can be used to generate explana-   tions for these unaligned concepts . For example ,   Figure 5a can be aligned as a mix of geopolitical en-   tities and adjectives . We also quantitatively verified   the number of unaligned encoded concepts that can   be explained using composition of different con-   cepts ( See Appendix E : Table 9 ) and found that a   majority of the clusters can be explained using a   combination of three pre - defined concepts ..   Moreover , note that encoded concepts are often   multifacet i.e. , they represent more than one re-   lationship . For example , the encoded concept in   Figure 5c consists of different forms of verbs but at   the same time , these verbs are semantically similar .   The semantic relationship present here is not ade-   quately captured using the human - defined concepts   used in this work . These are the novel concepts that   require richer annotations or human - in - the - loop   setup to generate adequate explanations .   5.4 Generalization of Results   Do the results generalize over different dataset se-   lection and using different number of clusters ? We   ran experiments using different split of the news   dataset for several models , and also performed   alignment using different values of K , the num-   ber of clusters . The results are consistent across   the board . Please see Appendix F for details .   6 Conclusion   We presented ConceptX , a novel framework for   analyzing the encoded concepts within deep NLP   models . Our method uses unsupervised clustering   to discover latent concepts within the contextual-   ized representations and then aligned these con-   cepts with a suite of human - defined concepts to   generate explanations for them . Our results illumi-   nate how DNNs structure language information . A   few notable findings are : i ) lower layers captureshallow linguistic concepts , ii ) whereas the abstract   linguistic concepts such as morphology and seman-   tics are preserved higher in the network , iii ) the   extent of alignment varies across different models   and different human - defined concepts , iv ) we found   that novel explanations and an improved coverage   of concepts can be achieved via compositionality .   References3090309130923093Appendix   A Human - defined concept labels   A.1 Lexical Concepts :   Ngrams , Affixes , Casing , First and the Last Word .   A.2 Morphology and Semantics :   POS tags : We used the Penn Treebank POS tags   discussed in ( Marcus et al . , 1993 ) , which consists   of 36 POS tags and 12 other tags ( i.e. , punctuation   and currency symbols ) . In Table 2 , we provide   POS tags and their description .   SEM tags : ( Abzianidze et al . , 2017 ) consists of   73 sem - tags grouped into 13 meta - tags . In Table   3 , we provide a detailed information of the tagset ,   and in Table 5 , we provide fine and coarse tags   mapping .   A.3 Syntactic :   Chunking tags : For Chunking we used the tagset   discussed in ( Tjong Kim Sang and Buchholz ,   2000 ) , which consists of 11 tags as follows : NP   ( Noun phrase ) , VP ( Verb phrase ) , PP ( Prepositional   phrase ) , ADVP ( Adverb phrase ) , SBAR ( Subor-   dinate phrase ) , ADJP ( Adjective phrase ) , PRT   ( Particles ) , CONJP ( Conjunction ) , INTJ ( Interjec-   tion ) , LST ( List marker ) , UCP ( Unlike coordinate   phrase ) . For the annotation , chunks are represented   using IOB format , which results in 22 tags in the   dataset as reported in Table 4 .   CCG super - tags Hockenmaier ( 2006 ) devel-   oped , CCGbank , a dataset with Combinatory Cat-   egorial Grammar ( CCG ) derivations and depen-   dency structures from the Penn Treebank . CCG is   a lexicalized grammar formalism , which is expres-   sive and efficiently parseable . It consists of 1272   tags .   A.4 Linguistic Ontologies :   WordNet : ( Miller , 1995 ) consists of 26 lexico-   graphic senses for nouns , 2 for adjectives , and 1   for adverbs . Each of them represent a supersense   and a hierarchy can be formed from hypernym to   hyponym .   LIWC : Over the past few decades , Pennebaker   et al . ( Pennebaker et al . , 2001 ) have designed psy-   cholinguistic concepts using high frequency words .   These word categories are mostly used to study   gender , age , personality , and health to estimate the   correlation between these attributes and word us-   age . It is a knowledge - based system where words   are mapped different high level concepts .   B BERT - based Sequence Tagger   We trained a BERT - based sequence tagger to auto-   annotate our training data . We used standard splits   for training , development and test data for the 4   linguistic tasks ( POS , SEM , Chunking and CCG   super tagging ) that we used to carry out our analy-   sis on . The splits to preprocess the data are avail-3094   able through git repositoryreleased with Liu et al .   ( 2019a ) . See Table 4 for statistics and classifier   accuracy.3095C Clustering details   Algorithm 1 assigns each word to a separate clus-   ter and then iteratively combines them based on   Ward ’s minimum variance criterion that minimizes   intra - cluster variance . Distance between two vec-   tor representations is calculated with the squared   Euclidean distance .   Algorithm 1 Clustering Procedure   Input : − →y : word representation of words   Parameter : K : the total number of clus-   tersforeach word wdo assign wto cluster cend forwhile number of clusters ̸=Kdo foreach cluster pair c , cdo d= inner - cluster difference of com-   bined cluster candc end forc , c= cluster pair with minimum value of   d merge clusters candcend while   C.1 Selection of the number of Clusters   The Elbow curve did not show any optimum clus-   tering point , with the increase in number of clus-   ters the distortion score kept decreasing , resulting   in over - clustering ( a large number of clusters con-   sisted of less than 5 words ) . The over - clustering   resulted in high but wrong alignment scores e.g.   consider a two word cluster having words “ good ”   and “ great ” . The cluster will have a successful   match with “ adjective ” since more than 90 % of the   words in the cluster are adjectives . In this way , a lot   of small clusters will have a successful match with   many human - defined concepts and the resulting   alignment scores will be high . On the other hand ,   Silhouette resulted in under - clustering , giving the   best score at number of clusters = 10 . We handled   this empirically by trying several values for the   number of clusters i.e. , 200 to 1600 with step size   200 . We selected 1000 to find a good balance with   over and under clustering . We understand that this   may not be the best optimal point . We presented   the results of 600 and 1000 clusters to show that our   findings are not sensitive to the number of clusters   parameter . D Coarse vs. Fine - grained Categories   D.1 Coarse vs. Fine - grained Categories   Our analysis of compositional concepts showed   that several fine - grained concepts could be com-   bined to explain an unaligned concept . For exam-   ple , by combining verb categories of POS to one   coarse verb category , we can align the encoded   concept present in Figure 5c . To probe this more   formally , we collapsed POS and SEM fine - grained   concepts into coarser categories ( 27 POS tags and   15 SEM tags ) . We then recomputed the alignment   with the encoded concepts . For most of the models ,   the alignment doubled compared to the fine - grained   categorizes with at least 39 % and at most 53 % per-   cent match for POS . This reflects that in several   cases , models learn the coarse language hierarchy .   We further questioned how many encoded concepts   can be explained using coarse human - defined con-   cepts . Compared to Table 1 , the matches increased   by at most 17 points in the case of BERT - uc . The   XLM - R showed the highest matching percentage   of 81 % . The higher alignment suggests that most of   the encoded concepts learned by pre - trained mod-   els can be explained using human - defined concepts .   ( See Appendix D for detailed results ) .   D.2 Corase POS and SEM labels   Tables 5 and 6 present results for our mapping   of fine - grained SEM and POS tags into coarser   categories .   D.3 Results   Table 7 presents the alignment results of using   coarse POS and SEM concepts . We observed that3096   the alignment doubles in most of the cases which re-   flects that in several cases , models learn the coarse   language hierarchy . However , they do not strictly   adhere to fine - grained categories existed in human-   defined concepts . We further extend the alignment   of coarse POS and SEM categories to the overall   alignment with the human - defined concepts . Table   8 presents the results . We see a match of up to   81 % in the case of XLM - R. The high alignment   suggests that many of the encoded concepts can be   explained using coarse human - defined concepts .   E Compositional Coverage   Table 9 shows the amount of coverage we obtain   when aligning with the morphological concepts   when allowing 90 % of the words in the cluster to   be from Nconcepts . F Robustness of Methodology across   Datasets and Settings   Figure 8 shows the layer - wise patterns using 600   clusters instead of 1000 as used in the main paper .   We observe that the overall trends largely remain   the same .   To further demonstrate the robustness of our   method with respect to dataset , we sub - sampled   another dataset from the News corpus with a dif-   ferent vocabulary by selecting words that appear   between 2 to 10 times in the corpus . Note that   the selection of vocabulary is due to the memory   and computation limitations . Figure 9 shows the   results using this selection of data . Compared to   Figure 4 , we can see that the overall patterns are   largely similar and confirms the robustness of our   findings . The slight difference in the patterns of   WordNet and LIWC are due to the large selection   of proper nouns in the second set of the data .   G Layer - wise results   Figure 10 present layer - wise results for all the un-   derstudied models.30973098309931003101