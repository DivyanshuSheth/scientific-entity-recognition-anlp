  Huiyuan Lai , Antonio Toral , Malvina Nissim   CLCG , University of Groningen / The Netherlands   { h.lai , a.toral.ruiz , m.nissim}@rug.nl   Abstract   We exploit the pre - trained seq2seq model   mBART for multilingual text style transfer .   Using machine translated data as well as gold   aligned English sentences yields state - of - the-   art results in the three target languages we   consider . Besides , in view of the general   scarcity of parallel data , we propose a modu-   lar approach for multilingual formality trans-   fer , which consists of two training strategies   that target adaptation to both language and   task . Our approach achieves competitive per-   formance without monolingual task - speciÔ¨Åc   parallel data and can be applied to other style   transfer tasks as well as to other languages .   1 Introduction   Text style transfer ( TST ) is a text generation task   where a given sentence must get rewritten chang-   ing its style while preserving its meaning . Tradi-   tionally , tasks such as swapping the polarity of a   sentence ( e.g. ‚Äú This restaurant is getting worse and   worse . ‚Äù$‚ÄúThis restaurant is getting better and bet-   ter . ‚Äù ) as well as changing the formality of a text   ( e.g. ‚Äú it all depends on when ur ready . ‚Äù $ ‚Äú It all   depends on when you are ready . ‚Äù ) are considered   as instances of TST . We focus here on the latter   case only , i.e. formality transfer , because ( i ) re-   cent work has shown that polarity swap is less of a   style transfer task , since meaning is altered in the   transformation ( Lai et al . , 2021a ) , and ( ii ) data in   multiple languages has recently become available   for formality transfer ( Briakou et al . , 2021b ) .   Indeed , mostly due to the availability of parallel   training and evaluation data , almost all prior TST   work focuses on monolingual ( English ) text ( Rao   and Tetreault , 2018 ; Li et al . , 2018 ; Prabhumoye   et al . , 2018 ; Cao et al . , 2020).As a Ô¨Årst step   towards multilingual style transfer , Briakou et al .   ( 2021b ) have released XFORMAL , a benchmarkof multiple formal reformulations of informal text   in Brazilian Portuguese ( BR - PT ) , French ( FR ) , and   Italian ( IT ) . For these languages the authors have   manually created evaluation datasets . On these ,   they test several monolingual TST baseline models   developed using language - speciÔ¨Åc pairs obtained   by machine translating GYAFC , a English corpus   for formality transfer ( Rao and Tetreault , 2018 ) .   Briakou et al . ( 2021b ) Ô¨Ånd that the models trained   on translated parallel data do not outperform a sim-   ple rule - based system based on handcrafted trans-   formations , especially on content preservation , and   conclude that formality transfer on languages other   than English is particularly challenging .   One reason for the poor performance could be   the low quality ( observed upon our own manual   inspection ) of the pseudo - parallel data , especially   the informal side . Since machine translation sys-   tems are usually trained with formal texts like   news ( Zhang et al . , 2020 ) , informal texts are harder   to translate , or might end up more formal when   translated . But most importantly , the neural models   developed by Briakou et al . ( 2021b ) do not take ad-   vantage of two recent Ô¨Åndings : ( i ) pre - trained mod-   els , especially the sequence - to - sequence model   BART ( Lewis et al . , 2020 ) , have proved to help sub-   stantially with content preservation in style trans-   fer ( Lai et al . , 2021b ) ; ( ii ) Multilingual Neural Ma-   chine Translation ( Johnson et al . , 2017 ; Aharoni   et al . , 2019 ; Liu et al . , 2020 ) and Multilingual Text   Summarization ( Hasan et al . , 2021 ) have achieved   impressive results leveraging multilingual models   which allow for cross - lingual knowledge transfer .   In this work we use the multilingual large model   mBART ( Liu et al . , 2020 ) to model style transfer in   a multilingual fashion exploiting available parallel   data of one language ( English ) to transfer the task   and domain knowledge to other target languages .   To address real - occurring situations , in our exper-   iments we also simulate complete lack of parallel   data for a target language ( even machine translated),262and lack of style - related data at all ( though avail-   ability of out - of - domain data ) . Language speci-   Ô¨Åcities are addressed through adapter - based strate-   gies ( Pfeiffer et al . , 2020 ; √úst√ºn et al . , 2020 , 2021 ) .   We obtain state - of - the - art results in all three target   languages , and propose a modular methodology   that can be applied to other style transfer tasks as   well as to other languages . We release our code   and hopefully foster the research progress .   2 Approach and Data   As a base experiment aimed at exploring the con-   tribution of mBART ( Liu et al . , 2020 ; Tang et al . ,   2020 ) for multilingual style transfer , we Ô¨Åne - tune   this model with parallel data speciÔ¨Åcally developed   for style transfer in English ( original ) and three   other languages ( machine translated ) .   Next , in view of the common situation where   parallel data for a target language is not avail-   able , we propose a two - step adaptation training   approach on mBART that enables modular mul-   tilingual TST . We avoid iterative back - translation   ( IBT ) ( Hoang et al . , 2018 ) , often used in previous   TST work ( Prabhumoye et al . , 2018 ; Lample et al . ,   2019 ; Yi et al . , 2020 ; Lai et al . , 2021a ) , since it has   been shown to be computationally costly ( √úst√ºn   et al . , 2021 ; Stickland et al . , 2021a ) . We still run   comparison models that use it .   In the Ô¨Årst adaptation step , we address the prob-   lem of some languages being not well represented   in mBART , which preliminary experiments have   shown to hurt our downstream task . We conduct   a language adaptation denoising training using un-   labelled data for the target language . In the sec-   ond step , we address the task at hand through Ô¨Åne-   tuning cross - attention with auxiliary gold parallel   English data adapting the model to the TST task .   For TST Ô¨Åne - tuning , we use parallel training   data , namely formal / informal aligned sentences   ( both manually produced for English and machine   translated for three other languages ) . For the adap-   tation strategies , we also collect formality and   generic non - parallel data . Details follow .   English formality data GYAFC ( Rao and   Tetreault , 2018 ) is an English dataset of aligned   formal and informal sentences . Gold parallel pairsare provided for training , validation , and test .   Multilingual formality data XFORMAL ( Bri-   akou et al . , 2021b ) is a benchmark for multilingual   formality transfer , which provides an evaluation set   that consists of four formal rewrites of informal sen-   tences in BR - PT , FR , and IT . This dataset contains   pseudo - parallel corpora in each language , obtained   via machine translating the English GYAFC pairs .   Language - speciÔ¨Åc formality non - parallel data   Following Rao and Tetreault ( 2018 ) and Briakou   et al . ( 2021b ) , we crawl the domain data in tar-   get language from Yahoo Answers . We then use   the style regressor from Briakou et al . ( 2021a ) to   predict formality score of the sentence to auto-   matically select sentences in each style direction .   Language - speciÔ¨Åc generic non - parallel data   5 M sentences containing 5 to 30 words for each   language randomly selected from News Crawl .   3 Adaptation Training   To adapt mBART to multilingual TST , we employ   two adaptation training strategies that target lan-   guage and task respectively .   3.1 Language Adaptation   As shown in Figure 1(a ) , we introduce a mod-   ule for language adaptation . Inspired by previous   work ( Houlsby et al . , 2019 ; Bapna and Firat , 2019 ) ,   we use an adapter ( ADAPT ; ~50 M parameters ) ,   which is inserted into each layer of the Transformer   encoder and decoder , after the feed - forward block .   Following Bapna and Firat ( 2019 ) , the ADAPT   moduleAat layericonsists of a layer-   normalization LN of the input x2Rfollowed by   a down - projection W2R , a non - linearity   and an up - projection W2Rcombined with   a residual connection with the input x :   A(x ) = WRELU ( WLN(x ) ) + x(1 )   Language adaptation training Following   mBART ‚Äôs pretraining , we conduct the language   adaptation training on a denoising task , which   aims to reconstruct text from a corrupted version :   L= X   log(Tjg(T ) ;  ) ( 2)263   where  are the parameters of adaptation module   A , Tis a sentence in target language and gis the   noise function that masks 30 % of the words in   the sentence . Each language has its own separate   adaptation module . During language adaptation   training , the parameters of the adaptation module   are updated while the other parameters stay frozen .   3.2 Task Adaptation   As shown in Figure 1(b ) , after training the language   adaptation module we Ô¨Åne - tune the model on the   auxiliary English parallel data with the aim of mak-   ing the model adapt to the speciÔ¨Åc task of formality   transfer . Following Stickland et al . ( 2021b ) , we   only update the parameters of the decoder ‚Äôs cross-   attention ( i.e. task adaptation module ) while the   other parameters are Ô¨Åxed , thus limiting computa-   tional cost and catastrophic forgetting .   Multilingual TST process For the language   adaptation modules we have two settings : ( i ) adap-   tation modules Aon the encoder come from the   model trained with source style texts , and modules   Aon the decoder come from the model trained   with target style texts ( M2.X , Table 1 ) ; ( ii ) both A   andAare from a model trained with generic texts   ( M3.X ) , so there are no source and target styles for   the adaptation modules . For the task adaptation   modules , we also have two settings : ( i ) the module   is from the English model ( X + EN cross - attn ) ; ( ii )   Ô¨Åne - tuning the model of the target language with   English parallel data ( X + EN data ) .   4 Experiments   All experiments are implemented atop Trans-   formers ( Wolf et al . , 2020 ) using mBART - large-50 ( Tang et al . , 2020 ) . We train the model using   the Adam optimiser ( Kingma and Ba , 2015 ) with   learning rate 1e-5 for all experiments . We train   the language adaptation modules with generic texts   separately for each language for 200k training steps   with batch size 32 , accumulating gradients over 8   update steps , and set it to 1 for other training .   Evaluation Following previous work ( Luo et al . ,   2019 ; Sancheti et al . , 2020 ) , we assess style   strength and content preservation . We Ô¨Åne - tune   mBERT ( Devlin et al . , 2019 ) with Briakou et al .   ( 2021b ) ‚Äôs pseudo - parallel corpora to evaluate the   style accuracy of the outputs . We also use a style re-   gressor from Briakou et al . ( 2021a ) , which is based   on XLM - R ( Conneau et al . , 2020 ) and is shown to   correlate well with human judgments . We calcu-   late BLEU and COMET ( Rei et al . , 2020 ) to assess   content preservation . As overall score , following   previous work , we compute the harmonic mean   ( HM ) of style accuracy and BLEU .   Systems Based on our data ( Section 2 ) , we have   four settings for our systems . D1 : pseudo - parallel   data in the target language via machine translating   the English resource ; D2 : non - parallel style data in   the target language ; D3 : no style data in the target   language ; D4 : no parallel data at all . The Ô¨Årst three   settings all contain gold English parallel data .   Results Table 1 shows the results for both I ! F   ( informal - to - formal ) and F ! I ( formal - to - informal )   transformations . We include the models from Bri-   akou et al . ( 2021b ) for comparison ( they only   model the I!F direction).264   Results in D1show that Ô¨Åne - tuning mBART   with pseudo - parallel data yields the best overall per-   formance in the I!F direction . The F ! I results ,   instead , are rather poor and on Italian even worse   than IBT - based models ( M2.1 ) . This could be due   to this direction being harder in general , since there   is more variation in informal texts , but it could also   be made worse by the bad quality of the informal   counterpart in the translated pairs . Indeed , work   in machine translation has shown that low - quality   data is more problematic in the target side than in   the source side ( Bogoychev and Sennrich , 2019 ) .   InD2 , we see that our proposed adaptation ap-   proaches outperform IBT - based models on both   transfer directions . The results of Ô¨Åne - tuning the   target language ‚Äôs model with English parallel data   are generally better than inserting the EN model ‚Äôs   cross - attention module into the target language ‚Äôs   model . This suggests that the former can better   transfer task and domain knowledge .   InD3 , the large amounts of generic texts yield   more improvement in I ! F direction rather than   F!I. This could be due to generic texts being more   formal than informal . The performance improve-   ment on Portuguese is particularly noticeable ( com-   pare M3.1 trained with EN data only with other   M3.X models ) , and mostly due to this language   being less represented than the others in mBART .   Interestingly , the performance of task adaptation   strategies is reversed compared to D2 : it is here   better to adapt cross attention in the English model   rather than Ô¨Åne - tune the target language model di-   rectly . Future work will need to investigate how   using different data sources for language adapta-   tion ( D2 , style - speciÔ¨Åc vs D3 , generic ) interacts   with task adaptation strategies .   Results for D4show that language adaptationtraining helps with content preservation , especially   for Portuguese , conÔ¨Årming this curbs the problem   of language underrepresentation in pre - training .   However , low performance on style accuracy shows   that task - speciÔ¨Åc data is necessary , even if it comes   from a different language .   5 Analysis and Discussion   Case Study Table 2 shows a group of example   outputs in Italian . In the I ! F direction , most sys-   tems tend to copy a lot from the source and change   formality words slightly . DLSM and Rule - based   systems fail to transfer the formality style while oth-   ers are successful to some extent : our M1.1 yields   the best performance on the style strength . When   looking at content , most outputs contain more or   less part of the source sentence ; Multi - Task system   achieves the highest BLEU score but our systems   ( except for M3.3 ) have higher COMET scores , with   M3.1 achieving the highest score . For the F ! I di-   rection , we can see that M1.1 has the worst perfor-   mance on style strength ( its output is almost iden-   tical to the source ) , while M2.1 , M3.1 and M3.2   generate the same output with the lowest regression   score . Overall , M3.3 achieves the best performance   on style and content .   Direction Analysis For English , Rao and   Tetreault ( 2018 ) Ô¨Ånd that the I ! F direction is quite   different from the opposite one since there are far   more ways to express informality . As our work is   the Ô¨Årst attempt at the F ! I direction in a multilin-   gual setting , we run some additional analysis using   two test sets for each direction : ( a ) the original   test set ; ( b ) the test set of the opposite direction ,   swapping sources and references . We Ô¨Åne - tune   BART ( Lewis et al . , 2020 ) and mBART-50 ( Tang   et al . , 2020 ) with English parallel data ( GYAFC)265   and evaluate them on ( a ) and ( b ) . Figure 2 shows   the results of content preservation . For INPUT   ( source copy ) , BLEU scores are almost the same   swapping sources and references but COMET ones   are not , probably due to COMET being trained to   prefer a formal / better ‚Äú generated sentence ‚Äù ; com-   pared to INPUT , the performance gain of BART   and mBART in I!F is larger than the opposite   direction on both metrics . Results are similar for   other languages ( Table 3 ) . We pick M1.1 and M1.2   from Table 1 since they are both Ô¨Åne - tuned using   parallel data in the target language . BLEU scores   of F!I are always lower than the opposite ; the   COMET score of INPUT in F ! I is higher than   I!F , but scores of both systems for F ! I drop af-   ter transforming the source sentence into the target   style . All these observations suggest that there is   more variation in informal texts for the languages   we consider , and the F ! I direction is harder .   6 Conclusions   Fine - tuning a pre - trained multilingual model with   machine translated training data yields state - of - the-   art results for transferring informal to formal text .   The results for the formal - to - informal direction are   considerably worse ‚Äî the task is more difÔ¨Åcult , and   the quality of translated informal text is lower . We   have also proposed two adaptation training strate-   gies that can be applied in a cross - lingual transfer   strategy . These strategies target language and task   adaptation , and can be combined to adapt mBART   for multilingual formality transfer . The adaptation   strategies with auxiliary parallel data from a differ-   ent language are effective , yielding competitive re-   sults and outperforming more classic IBT - based ap-   proaches without task - speciÔ¨Åc parallel data . Lastly ,   we have shown that formal - to - informal transforma-   tion is harder than the opposite direction.266Acknowledgments   This work was partly funded by the China Schol-   arship Council ( CSC ) . The anonymous reviewers   of ACL Rolling Review provided us with useful   comments which contributed to improving this pa-   per and its presentation , so we ‚Äôre grateful to them .   We would also like to thank the Center for Infor-   mation Technology of the University of Groningen   for their support and for providing access to the   Peregrine high performance computing cluster .   Ethics Statement   All work that automatically generates and/or al-   ters natural text could unfortunately be used mali-   ciously . While we can not fully prevent such uses   once our models are made public , we do hope that   writing about risks explicitly and also raising aware-   ness of this possibility in the general public are   ways to contain the effects of potential harmful   uses . We are open to any discussion and sugges-   tions to minimise such risks .   References267268269A   This appendices include : ( i ) Results for BART and mBART on English data ( A.1 ) ; ( ii ) Results for style   classiÔ¨Åers / regressor ( A.2 ) ; ( iii ) Detailed results for multilingual formality transfer ( A.3 ) .   A.1 Results for BART and mBART on English data   We Ô¨Åne - tune BART ( Lewis et al . , 2020 ) and mBART-50 ( Tang et al . , 2020 ) with English parallel data   speciÔ¨Åcally developed for formality transfer in English ( GYAFC ) . The performance of BART and English   data can be seen as a sort of upperbound , as these are best conditions ( monolingual model , and gold   parallel data ) . The drop we see using mBART is rather small , suggesting mBART is a viable option . We   also see that formal to informal is much harder than viceversa , probably due to high variability in informal   formulations ( Rao and Tetreault , 2018 ) . Table A.1 shows the results for both models .   A.2 Results for style classiÔ¨Åers / regressor   We compare four different style classiÔ¨Åers and one regressor : ( i ) TextCNN ( Kim , 2014 ) trained with   pseudo - parallel data in the target language ; ( ii ) mBERT ( Devlin et al . , 2019 ) Ô¨Åne - tuned with pseudo-   parallel data , English data , or a combination of all data ; and ( iii ) a XLM - R ( Conneau et al . , 2020 ) based   style regressor from Briakou et al . ( 2021a ) , which is trained with formality rating data in English.270A.3 Detailed results for multilingual formality transfer271