  Juan Diego RodriguezTodd HayDavid Gros   Zain ShamsiRavi SrinivasanApplied Research Laboratories , The University of Texas at AustinEn SoluciónUniversity of California , Davis   { juand - r , zain.shamsi , ravi.srinivasan}@utexas.edu   todd.hay@ensolucion.com   dgros@ucdavis.edu   Abstract   Machine - generated text presents a potential   threat not only to the public sphere , but also to   the scientiﬁc enterprise , whereby genuine re-   search is undermined by convincing , synthetic   text . In this paper we examine the problem of   detecting GPT-2 - generated technical research   text . We ﬁrst consider the realistic scenario   where the defender does not have full infor-   mation about the adversary ’s text generation   pipeline , but is able to label small amounts   of in - domain genuine and synthetic text in or-   der to adapt to the target distribution . Even   in the extreme scenario of adapting a physics-   domain detector to a biomedical detector , we   ﬁnd that only a few hundred labels are sufﬁ-   cient for good performance . Finally , we show   that paragraph - level detectors can be used to   detect the tampering of full - length documents   under a variety of threat models .   1 Introduction   Recent advances in techniques for generating real-   istic synthetic content ( i.e. , deepfakes ) pose a di-   verse set of problems with signiﬁcant societal con-   sequences ( Kreps et al . , 2020 ; Bommasani et al . ,   2021 ; McGufﬁe and Newhouse , 2020 ) . The advent   of large language models for text generation ( Rad-   ford et al . , 2019 ; Brown et al . , 2020 ) have made   it easier than ever to create convincing synthetic   text ( Solaiman et al . , 2019 ) . While much attention   has been focused on the role of synthetic audio and   video , it can be argued that synthetic text may give   rise to some of the most serious threats to infor-   mation integrity and the long - term preservation of   archival knowledge ( Aliman and Kester , 2021).Figure 1 : Machine - generated text enables the corrup-   tion of technical knowledge ( e.g. , biomedical research ) .   One of the above abstracts was generated by GPT-2 .   More examples of generated text can be found in § A.7 .   While there are currently no documented cases   of published papers containing text from neural lan-   guage models , non - neural machine - generated pa-   pers have already been published in peer - reviewed   journals ( Cabanac and Labbé , 2021 ) . With more   convincing text generation techniques and a grow-   ing number of publications , this is a problem that   could get much worse , particularly for non - peer-   reviewed technical text ( Ranade et al . , 2021 ) . In ad-   dition to hindering the scientiﬁc process , synthetic   technical texts could be used to manipulate public   opinion and sow discord around speciﬁc scientiﬁc   topics ( Aliman and Kester , 2021 ) . Other conse-   quences of machine - generated technical text in-   clude the contamination of NLP pipelines ( Ranade   et al . , 2021 ) and poisoning of language models   ( Schuster et al . , 2021 ) .   The rise of realistic machine - generated text – and1213its possible misuse – has spurred the development   of automated tools to distinguish between genuine   and synthetic English text . However , most work   to date has focused on web text or news , rather than   on domain - speciﬁc technical text ( Solaiman et al . ,   2019 ; Zellers et al . , 2019 ) . While synthetic techni-   cal text is likely to be distinguished by subject mat-   ter experts ( SMEs ) , it is difﬁcult for non - domain   evaluators to do so . Therefore , given the ease at   which large amounts of synthetic text can be gener-   ated , automated countermeasures are necessary in   order to alleviate the burden on SMEs .   We focus on developing capabilities for detect-   ing generated technical English text and delineating   the contexts in which these detection approaches   can be applied . We assume an adversary gener-   ating technical text using GPT-2 ( Radford et al . ,   2019 ) , but do not know apriori in exactly which   technical area . Realistically , some domain shift   will be inevitable , which leads us to investigate   whether detectors can be applied across domains ,   e.g. , can a detector of generated physics papers be   adapted to also detect biomedical text ? In addition ,   most work to date has focused on detecting short   pieces of text . We show that automated detection   of tampered full - length research papers is possible   under various threat models . Our work makes two   main contributions :   •We show that accurate cross - domain detection   of generated technical text is possible using a   small number of in - domain samples and quan-   tify the amount of SME effort required .   •We study the detectability of tampered full-   text technical papers ( where a subset of para-   graphs have been replaced with generated text )   under various scenarios .   2 Related Work   Automated detection of synthetic text Auto-   mated approaches to detecting machine - generated   text have included energy - based models ( Bakhtin   et al . , 2019 ) , repurposing the generator as a dis-   criminator ( Zellers et al . , 2019 ) , and various neural   and non - neural classiﬁers ( Solaiman et al . , 2019 ;   Ippolito et al . , 2020 ; Uchendu et al . , 2020 ; Zhong   et al . , 2020 ; Fröhling and Zubiaga , 2021 ; Fagniet al . , 2021 ) . Most work on automated detection   targeted GPT-2 - generated text , although Bakhtin   et al . ( 2019 ) , Uchendu et al . ( 2020 ) , Fagni et al .   ( 2021 ) and Stiff and Johansson ( 2021 ) also exper-   imented with other generators . Finally , there is a   growing body of work on the adversarial robust-   ness of automated detectors of synthetic text ( Wolff ,   2020 ; Bhat and Parthasarathy , 2020 ; Stiff and Jo-   hansson , 2021 ; Crothers et al . , 2022 ) . A survey   on the automatic detection of synthetic text can be   found in ( Jawahar et al . , 2020 ) .   Prior work closest to our study are ( Solaiman   et al . , 2019 ) , ( Ippolito et al . , 2020 ) , ( Munir et al . ,   2021 ) , ( Bakhtin et al . , 2019 ) and ( Stiff and Johans-   son , 2021 ) , which look at cross - domain settings   where the distribution of synthetic text used to train   a detector differs from the target distribution . The   shift could be due to different model architectures   ( Bakhtin et al . , 2019 ; Stiff and Johansson , 2021 ) ,   different model sizes ( Solaiman et al . , 2019 ) , differ-   ent decoding strategies ( Solaiman et al . , 2019 ; Ip-   polito et al . , 2020 ) , or different ﬁne - tuning datasets   ( Bakhtin et al . , 2019 ; Munir et al . , 2021 ; Stiff and   Johansson , 2021 ) . Bakhtin et al . ( 2019 ) show that   energy - based models generalize poorly across cor-   pora ( Wikipedia , news and books ) , but that training   on the union of the source and target domains is   effective . Munir et al . ( 2021 ) show that XLNet   can accurately attribute synthetic text even when   the GPT-2 - generated portions of the training and   test sets come from GPT-2 ﬁne - tuned on different   subreddits .   Unlike the previous papers , we evaluate our de-   tectors on technical ( biomedical ) text , and vary the   number of labeled samples available for training   in the target domain , under the assumption that   source labels are plentiful but target examples are   more expensive to obtain ( i.e. , source samples can   be generated at will , but target examples need to   be discovered and veriﬁed by a human since the   adversary ’s target text generator is generally un-   available ) . In addition , we evaluate the detection   of full - length tampered documents consisting of a   mix of real and machine - generated content .   Attribution for synthetic text In addition to dis-   tinguishing between real and generated text , one   may also wish to determine which system gener-   ated a given text ( e.g. , model type , size , decoding   strategy ) . Variations of this “ authorship attribu-   tion ” problem have been explored by Uchendu et al .   ( 2020 ) , Tay et al . ( 2020 ) and Munir et al . ( 2021).1214These works have found that , in general , while   the attribution problem is harder than the detection   problem , details of the text generator can often be   learned from the generated text .   Human detection of synthetic text Human eval-   uations on the detection of generated text have been   conducted for news ( Zellers et al . , 2019 ; Brown   et al . , 2020 ; Kreps et al . , 2020 ; Clark et al . , 2021 ) ,   product reviews ( Hovy , 2016 ; Yao et al . , 2017 ; Ade-   lani et al . , 2020 ) , web text ( Gehrmann et al . , 2019 ;   Ippolito et al . , 2020 ) , stories ( Clark et al . , 2021 ;   Donahue et al . , 2020 ; Clark et al . , 2021 ; Gunser   et al . , 2021 ) , peer reviews ( Bartoli and Medvet ,   2020 ) , cybersecurity text ( Ranade et al . , 2021 ) and   submissions to federal public comment websites   ( Weiss , 2019 ) . These studies have shown that it   is difﬁcult for people to distinguish between real   and neural - generated text . Gehrmann et al . ( 2019 )   developed a tool , GLTR , to help users visualize   statistical artifacts in generated text .   3 Threat model and defender capabilities   3.1 Threat Model   Given that people have trouble distinguishing   real ( human - written ) from GPT-2 - generated text   ( Zellers et al . , 2019 ; Kreps et al . , 2020 ; Clark et al . ,   2021 ) , we study the detection of generated text   under the threat model where an adversary gener-   ates text from GPT-2 domain - tunedon domain-   speciﬁc text . We do not necessarily assume that   text from this domain is publicly available in sig-   niﬁcant quantities . Throughout , we shall refer to   those developing the generated text as the adver-   sary , and those building automated detectors of   synthetic text as the defender . As there does not   ( yet ) exist a " real - world " dataset of GPT-2 gener-   ated technical text , we simulate both the adversary   and the defender .   We study two scenarios : where the adversary   generates single technical abstracts ( § 4.1 ) , and   where the adversary replaces randomly selected   paragraphs in full - length documents with GPT-2-   generated paragraphs ( § 4.2 ) . Other threat models   are possible , such as replacing single words , sen-   tences or phrases ( Schuster et al . , 2020 ; Donahue   et al . , 2020 ; Bhat and Parthasarathy , 2020 ) , and   should be studied in future work .   3.2 Defender Capabilities   In general , the defender has little or no informa-   tion about the adversary ’s text generation pipeline ,   including the data used for training , the model ar-   chitecture used , or the decoding strategy employed .   We assume the defender has access to a small num-   ber of examples from the adversary , which can   be labeled by a subject matter expert ( SME ) as   real ( human ) or synthetic ( generated).In addition ,   since the defender does not have access to the ad-   versary ’s target generator , they can build a proxy   generator , trained on proxy text , in order to obtain1215more samples of real and synthetic text which are   ( hopefully ) statistically similar to the ones obtained   from the adversary , as shown in Figure 2 . The de-   fender can then train a model to detect generated   text using both the in - domain SME - labeled text   and the ( possibly ) out - of - domain proxy text , as de-   scribed in more detail in § 4 . The level of access the   defender is assumed to have to various parts of the   adversary generation pipeline is shown in Table 1 .   Since the effect of differing model sizes has al-   ready been explored ( Zellers et al . , 2019 ; Solaiman   et al . , 2019 ; Fröhling and Zubiaga , 2021 ) , we as-   sume the adversary and defender use the same sized   model ( GPT-2 Medium , with 355 M parameters ) ,   but domain - tuned on different datasets . Since the   defender can not guess the temperature value used   by the target generator , we shall decode using a tem-   perature value of 1.0 for the target generator , but 0.8   for the proxy generator . We also assume both ad-   versary and defender use nucleus sampling ( Holtz-   man et al . , 2020 ) . The defender would not know   whether the generator is using nucleus sampling .   However , it was shown in ( Ippolito et al . , 2020 ;   Solaiman et al . , 2019 ) that a discriminator trained   with nucleus sampling is able perform nearly as   well at detecting text generated with top - k ( Fan   et al . , 2018 ) sampling as with nucleus sampling ,   while a discriminator trained using top - k sampling   fails to detect generations from nucleus sampling .   Hence this is a reasonable assumption to make .   Our experiments will investigate the effects of   domain shift between the proxy and target data , as   well as the number of SME - labeled examples avail-   able to the defender . While the assumption thatboth adversary and defender share the same model   architecture may seem like a strong one , we ﬁx the   architecture so as to focus on the effect of domain   shift , and note that previous works have already   studied the effect of using different architectures   ( Bakhtin et al . , 2019 ; Stiff and Johansson , 2021 ) ,   model sizes ( Solaiman et al . , 2019 ) , and decoding   strategies ( Ippolito et al . , 2020 ; Solaiman et al . ,   2019 ) .   4 Automated Detection   4.1 Detecting Generated Abstracts   While the defender could train a detector on the   union of SME - labeled ( target ) and proxy data as   done in ( Zellers et al . , 2019 ) , we instead follow   a pipelined approach by ﬁrst task - tuning on the   proxy real and synthetic text to produce a proxy   detector , before task - tuning a second time on the   SME - labeled text . One advantage of this approach   is that one would still have a detector even when   SME labels are not available . In addition , previous   studies have shown that task - tuning twice can yield   good performance on a variety of tasks and can   help mitigate the effects of domain shift ( Phang   et al . , 2018 ; Sellam et al . , 2020 ) .   Preliminary experiments on in - domain detection   showed that ﬁne - tuning RoBERTa consistently out-   performed other classiﬁers ( LSTMs , HAN , BERT   and XLNet ) , as shown in Appendix § A.2 , and   so we exclusively use RoBERTa in all of our ex-   periments . This is in line with results in ( So-   laiman et al . , 2019 ; Uchendu et al . , 2020 ; Fagni   et al . , 2021 ) , which showed the effectiveness of   RoBERTa for detecting GPT-2 - generated text . In   order to investigate the beneﬁt of further pretrain-   ing ( Gururangan et al . , 2020 ) , we also domain-   tune RoBERTa on technical text from various sci-   ence , technology , engineering , and mathematics   ( STEM ) ﬁelds , as described in § 5.1.2 ; we call the   resulting model RoBERTa - large - STEM . Our exper-   iments will vary both the number of proxy and   SME - labeled abstracts , as well as the subject do-   main of proxy text , as detailed in § 5.1 .   4.2 Detecting Tampered Documents   We also investigate how well our detection meth-   ods work when applied at the document level , as-   suming the following attacker model : a fraction of   randomly - selected paragraphs in a document are   replaced by generated paragraphs ( see § 5.2.1 for   details ) . Each generated paragraph is conditioned1216on the previous paragraph ( i.e. , the previous para-   graph is used as a prompt ) . Conditioning helps   the text stay on - topic , and would likely help evade   coherence - based detectors(Singla et al . , 2021 ) .   We refer to the modiﬁed documents as tampered   rather than generated , since only a subset of the   document might be generated .   On the detection side , we train paragraph - level   detectors , and then aggregate paragraph scores into   document scores to classify documents . We need to   specify both the question we would like to answer ,   as well as how to aggregate the detectors ’ para-   graph scores{s}to answer it . Here we interpret   sas the probability that a paragraph has been gen-   erated . The general question “ has this document   been tampered with ? ” leads to two more speciﬁc   questions and associated scoring strategies :   •(S1 ) Is at least one paragraph in the document   generated ? The probability that a document   with paragraph scores { s}has at least one   synthetic paragraph is then given by :   P= 1−/productdisplay   ( 1−s )   •(S2 ) What fraction of a document is gener-   ated ? For a document with Nparagraphs , this   is :   F=1   N / summationdisplay   1   As we will see , one drawback of scoring with ( S1 )   is that it is extremely sensitive to false positives . En-   tirely human - written documents have a high chance   of having one or two false positives ( especially   among short paragraphs ) , even if the other para-   graphs are correctly classiﬁed . In these cases the   human documents will be classiﬁed as tampered .   Since the false positive rate is highest for short para-   graphs , we can ﬁlter out very short paragraphs   from each document before scoring . We thus also   experiment with the following score :   •(S1 - T ) Is at least one paragraph plonger than   a given threshold Tsynthetic ? The probability   that this is the case is :   P= 1−/productdisplay   ( 1−s · 1)For each document we can use thresholds for P   orFto decide how to classify the document ; in   addition , we shall use ( S2 ) to rank documents by   how much generated content they contain .   5 Datasets   Here we describe the datasets used and other ex-   perimental details when simulating the adversary   and defender ’s pipelines ( Figure 2 ) . The experi-   ments on synthetic abstract detection are described   in § 5.1 ; experiments on tampered document detec-   tion are described in § 5.2 .   5.1 Real and Synthetic Abstracts   Table 2 summarizes the datasets used . The ad-   versary has access to the Semantic Scholar Open   Research Corpus(Ammar et al . , 2018 ) , while the   defender has access so several subsets of CORE   ( Knoth and Zdrahal , 2012 ) , as well as small amount   of text labeled by a SME . We chose abstracts from   CORE related to biomedicine and physics , since   these subjects had the largest number of abstracts   for ﬁne - tuning models ( shown in § A.6 , Table 10 ) .   5.1.1 Test Data   We ﬁrst discuss the construction of datasets used   to evaluate the detection of GPT-2 - generated ab-   stracts . The test set consists of 1000 real and 1000   synthetic abstracts , generated using GPT-2 domain-   tuned on abstracts from the January 2019 version   of the Semantic Scholar Open Research Corpus   ( Ammar et al . , 2018 ) , hereafter referred to as1217Semantic Scholar . Text was generated using nu-   cleus sampling , with psampled uniformly between   0.9 and 1.0 , since ( Zellers et al . , 2019 ) showed   detection was hardest with pin that range .   5.1.2 Training Data   Here we describe the SME - labeled abstracts ( in-   domain ) and proxy ( possibly out - of - domain ) data   used to train detectors of GPT-2 generated ab-   stracts .   SME - labeled data Nested subsets of another   10k abstracts ( of sizes { 100 , 500 , 1000 , 1k , 10k } ) ,   obtained in the same way as the test set , were used   as “ SME - labeled ” ( in - domain ) data for training .   Proxy data Out - of - domain abstracts were sam-   pled from the CORE dataset of open access re-   search papers ( Knoth and Zdrahal , 2012 ) , version   2018 - 03 - 01 . CORE covers a wide variety of   subjects , some of which can be identiﬁed from   each paper ’s data provider . We used a subset of   CORE related to STEM ﬁelds , and ﬁltered out   non - English abstracts using the Python package   langdetect . This subset of CORE was also used to   domain - tune RoBERTa - large on STEM abstracts ,   resulting in RoBERTa - large - STEM .   We trained proxy generators using the biomed-   ical and physics portions of CORE ( 237,620 ab-   stracts for each ) , and on the union of the biomedical   and physics portions ( “ biomedical - physics ” , with   475,240 abstracts ) . For each of these three gen-   erators , we created nested subsets ( of sizes { 100 ,   500 , 1000 , 1k , 10k , 100k } ) of proxy training data .   As with the SME - labeled data , half of the samples   were real and half were generated . In the case of   biomedical - physics , we used equal numbers of real   biomedical and real physics text . We estimate that   roughly half of the biomedical - physics generations   were biomedical . Examples of generated physics   and biomedical abstracts can be found in Appendix   § A.7.5.2 Real and Tampered Documents   While the CORE corpus includes full - length doc-   uments , they have not been pre - processed and are   rather noisy . Fortunately , the S2ORC corpus ( Lo   et al . , 2020)includes millions of pre - processed   scientiﬁc documents . The full - length papers in   S2ORC have been preprocessed with paragraph   splitting ; in addition , captions , tables , headers , foot-   ers , footnotes , abstracts and bibliography have been   removed from the main text .   We sampled from the 6.8 million papers in   S2ORC which are biomedicalto create disjoint   datasets for domain - tuning proxy and target GPT-2   generators , for task - tuning RoBERTa - based detec-   tors , and for test sets . Since our attacker model con-   sists of random paragraph replacement , we domain-   tuned GPT-2 on 890,000 biomedical paragraphs in   order to generate new paragraphs conditioned on   previous paragraphs . This is done twice , on non-   overlapping data , to obtain two separate generators :   the target generator is used to create the test doc-   ument collections and SME - labeled training para-   graph collections , while the proxy generator is used   to create proxy training data . The details of each   of these datasets are given below .   5.2.1 Test Data   In order to evaluate our detectors against vari-   ous document tampering scenarios , we use sev-   eral document - level datasets , which differ by the   number of generated ( replaced ) paragraphs in each   document . Each of these test sets consists of   500 human documents and 500 tampered ( gener-   ated / modiﬁed ) documents . The ﬁve test sets con-   taining tampered documents are given as follows :   test-1 - fake contains only tampered documents with   exactly one synthetic paragraph , text - x replaces   every paragraph with a generated paragraph with   probability x , forxin { 0.1 , 0.5 , 0.9 } , and test-   all - fake has all paragraphs generated , with each   subsequent paragraph generated conditional on the   previously generated paragraph . Two examples can   be found in Appendix § A.7 , Table 13.12185.2.2 Training Data   Here we describe the datasets used to build   paragraph - level detectors .   SME - labeled data Nested subsets of 10,000   paragraphs ( of sizes { 0 , 100 , 500 , 1k , 10k } ) were   used as SME - labeled ( in - domain ) training data ,   with equal numbers of real and generated para-   graphs . The generated paragraphs are obtained   using the same domain - tuned generator as for the   test sets . For each paper , we sample one paragraph   to use as real , and one paragraph to condition on .   Proxy data The proxy GPT-2 generator is used   to obtain nested subsets of 10,000 paragraphs ( of   sizes { 0 , 100 , 500 , 1k , 10k } ) in much the same way   as for the in - domain data , except for one difference .   Unlike for the in - domain data , the defender has   access to every human paragraph that is being re-   placed by a ( proxy ) generated paragraph . So for   each paper , we sample a real paragraph at position   i , and use the previous paragraph at position i−1   as a prompt for the generated paragraph .   What if the defender uses a proxy generator   designed for unconditional paragraph generation ?   Preliminary experiments on using proxy data gener-   ated without prompting showed only a small drop   in accuracy under most dataset sizes , so this is not   a strong assumption to make .   6 Results   6.1 Detection of Generated Abstracts   Detection performance on Semantic Scholar ab-   stracts depends on the model used for task - tuning   ( RoBERTa - base , RoBERTa - large , or RoBERTa-   large - STEM ) , the proxy domain ( biomedical ,   physics , or biomedical - physics ) , and the number of   proxy and SME samples used for task - tuning , with   full results shown in Appendix § A.3 . We consider   the effects of these four dimensions below .   Interplay of SME and proxy labels Some SME   labels are always needed for good performance ,   even when the training proxy text is in a similar   domain as the target domain ( Table 3 ) . Without   any SME labels , the highest accuracy that could be   achieved with RoBERTa - large using only biomed-   ical proxy text was .67 ( with 10k proxy samples ) .   0 100 500 1k 10k 100k   0 .59 .58 .54 .67 .65   100 .68 .67 .89 .89 .81 .82   500 .69 .68 .82 .75 .88 .84   1k .80 .90 .84 .89 .90 .8410k .92 .95 .94 .94 .95 .92   n   100 .67 .87 .78   500 .89 .82 .83   1k .89 .85 .84   10k .81 .69 .62   100k .82 .70 .66   Task - tuning the 10k - proxy model checkpoint a sec-   ond time with only 100 SME - labeled samples re-   sulted in a large improvement ( accuracy of .81 ,   recall of .95 ) .   Given a ﬁxed number of SME samples , increas-   ing the number of proxy samples improves perfor-   mance , but only up to a point , after which the proxy   data starts being detrimental . For example , given   100 SME examples ( row 2 in Table 3 ) , the highest   performance for the biomedical proxy experiments   was achieved when using between 500 and 1000   proxy samples ( resulting in accuracy of .76-.77 for   RoBERTa - base , .89 for RoBERTa - large and .91-.92   for RoBERTa - large - STEM ) . The same observation   holds when using physics and biomedical - physics   proxy text . Unsurprisingly , the effects are worse   with increasing domain shift . The decrease in accu-   racy when jumping from 1k to 10k proxy samples   is .08 for biomedical proxy data , .16 for biomedical-   physics proxy data , and .22 for physics proxy data .   Effect of domain shift When 1k or 10k SME la-   bels were available , performance across task - tuning   domains was similar . On the other hand , with 500   SME labels or less the impact of the proxy data   domain was greater , as shown in Table 4 for the   case of 100 SME labels . For most proxy dataset   sizes , there is a decrease in performance as one   moves from biomedical to physics .   Finally , we note that when using RoBERTa-1219large - STEM , 100 SME samples are sufﬁcient to   achieve .91 accuracy when using biomedical proxy   samples . However , if the proxy samples come from   a different domain ( physics , or a mix of physics and   biomedicine ) , then 500 SME samples are required   to achieve the same accuracy .   Effect of model size RoBERTa - large had higher   accuracy than RoBERTa - base under most scenar-   ios , with an absolute increase in accuracy ranging   between 1 and 22 points . RoBERTa - large always   had higher precision than RoBERTa - base .   Effect of domain - tuning Pre - training RoBERTa   on a diverse corpus of STEM technical text im-   proved performance in most cases , sometimes by   a large margin . RoBERTa - large - STEM outper-   formed RoBERTa - large even when the target and   proxy domains were close ( i.e. , using biomedical   proxy data ) , with 1 to 5 point gains in accuracy   under most conditions .   Domain - tuning RoBERTa was more beneﬁcial   with increasing amounts of domain shift , and when   task - tuning on a large number of proxy samples   and a small number of SME - labeled samples , as   shown in Figure 3 . A domain - speciﬁc RoBERTa is   better at recovering from being trained on a large   volume of data from the wrong domain , when given   a small amount of in - domain text .   6.2 Detection of Tampered Documents   The performance of the RoBERTa - large detectors   at the paragraph level is shown in Table 5 . It is not   unrealistic to assume a SME can label 100 para-   graphs ( 50 real , 50 synthetic ) to create a detector   with .94 accuracy . Thus , in the rest of the section   we shall only evaluate the classiﬁer trained on 10k   conditioned proxy samples and 100 SME samples .   Identifying documents with at least one syn-   thetic paragraph Here we apply the scoring   0 100 500 1k 10k   0 .60 .78 .84 .93   100 .77 .82 .87 .89 .94   500 .85 .89 .90 .90 .95   1k .91 .91 .90 .92 .9410k .96 .95 .96 .96 .96   Test set T= 500 T= 1000   test - all - fake .87 [ .79 , 1.0 ] .98 [ .96 , 1.0 ]   test-0.9 .87 [ .79 , 1.0 ] .97 [ .96 , .99 ]   test-0.5 .86 [ .79 , .99 ] .96 [ .96 , .96 ]   test-0.1 .81 [ .77 , .89 ] .80 [ .94 , .63 ]   test-1 - fake .76 [ .74 , .78 ] .67 [ .91 , .37 ]   strategies ( S1 ) and(S1 - T ) described in § 4.2 to pre-   dict whether a given document has at least one   generated paragraph . We found that on all our test   sets , scoring documents using ( S1 ) resulted in re-   call of .99 - 1 but precision at nearly chance level   ( .55-.56 ) . This is due to the high false positive rate   for short paragraphs . To remedy this , we score us-   ing(S1 - T ) , ignoring all paragraphs shorter than a   given threshold of Tcharacters . The results for   T= 500 andT= 1000 are shown in Table 6 .   When T= 1000 , performance is high for test-   all - fake , test-0.9 and test-0.5 ; however , recall drops   substantially for test-0.1 and test-1 - fake . This is   due to the fact that these test sets contain very   few generated paragraphs , which are then more   likely to be ﬁltered out : all synthetic paragraphs   were removed from 64 % of tampered test-1 - fake   documents , and 39 % of tampered test-0.1 docu-   ments . Unfortunately , ﬁltering less aggressively   withT= 500 improves recall at the cost of lower   precision across all test sets .   Ranking documents by fraction of generated   content We rank documents using ( S2 ) , i.e. , ac-   cording to the estimated fraction of paragraphs clas-1220Test set P@100 P@250 P@500   test - all - fake 1.0 1.0 .99   test-0.9 1.0 1.0 .99   test-0.5 .98 .97 .95   test-0.1 .70 .74 .69   test-1 - fake .57 .60 .59   siﬁed as generated . Table 7 shows the fraction of   documents in the top - k ranked documents that were   tampered with ( P@k ) . It is possible to retrieve   nearly all tampered documents , except for test sets   test-0.1 and test-1 - fake .   Effect of paragraph splitting errors It is unre-   alistic to assume that the adversary and the defender   use the same paragraph splits . For example , text   from a PDF ﬁle must ﬁrst be extracted and split   into paragraphs before detection can be done . Even   when using a good paragraph splitter , it is unlikely   that the paragraph splits would exactly match those   used by the generator . To investigate the robustness   of detection against paragraph splitting errors we   process each test set as follows : each paragraph   is sentence - segmented with scispaCy v.0.2.2 ( Neu-   mann et al . , 2019 ) , and every ﬁve consecutive sen-   tences is taken to be a paragraph , disregarding the   original paragraph splits . This is a stress - test for   our detectors , since one can probably achieve far   fewer paragraph - splitting errors when using a para-   graph splitter such as GROBID ( Lopez , 2009 ) .   When applying the detector on the incorrectly-   split documents and scoring with ( S1 ) , we ﬁnd   that precision increases from .55 to between .61   and .67 . This is due the fact that paragraphs in   the human 5 - sentence splits are generally longer   than the original paragraphs . On the other hand ,   recall drops signiﬁcantly for test-0.1 and test-1-   fake ( from .99 to .87 , and .99 to .79 , respectively ) .   This is due to the fact that it is harder to detect   paragraphs containing a mix of real and synthetic   content : recall was .95 , .66 and .33 for the the   subsets of paragraphs with 5 , 4 , and 3 synthetic   sentences , respectively.7 Conclusion   In this paper , we studied the problem of automatic   detection of GPT-2 - generated technical text . We   found that RoBERTa - based detectors can be suc-   cessfully adapted from one scientiﬁc discipline   ( physics ) to another ( biomedicine ) , requiring rel-   atively small amounts of in - domain labeled data .   These could be provided by a subject matter ex-   pert ( SME ) in a reasonable amount of time . We   also evaluated these paragraph - level detectors on   a document tampering task , assuming that the ad-   versary replaces randomly - selected paragraphs in a   document with generated ones .   Future work should evaluate the extent to which   this methodology would work on detecting text   from newer generators such as GPT-3 . Other chal-   lenging scenarios include adding noisy labels ( e.g. ,   if a SME makes a certain fraction of mistakes ) , and   class imbalance . Our results on document tamper-   ing ( i.e. , that it is signiﬁcantly harder to detect small   amounts of generated text intermingled amongst   real text ) also point to the need to develop detec-   tion pipelines for other threat models such as single   word or phrase substitutions ( Schuster et al . , 2020 ) .   As text generation techniques continue to improve ,   it may be that more interpretable , fact - checking   approaches are required to detect both human and   machine - generated misinformation .   Acknowledgements   We would like to thank Greg Durrett , Katrin Erk ,   Jessy Li , and the anonymous reviewers for their   helpful comments and suggestions .   Ethical Considerations   Improvements in the detection of synthetic text   could be used by an adversary to improve the qual-   ity of generated text or to help them avoid detec-   tion ( Darmetko , 2021 ) . False positives are another   source of potential negative consequences of auto-   mated detectors . For example , incorrectly ﬂagged   human - written content could be a source of misin-   formation , and could additionally lead to a loss of   trust in the detection system . Care should be taken   that false positives do not affect certain demograph-   ics disproportionately ( Bommasani et al . , 2021 ,   § 5.2 ) . Finally , widespread awareness of the mere   possibility of synthetic scientiﬁc text can further   undermine public trust in genuine science ( Makri ,   2017).1221References122212231224   A Appendix   A.1 Fine - tuning hyperparameters   Here we list the main hyperparameters used in our   experiments .   Domain - tuning GPT-2 to generate abstracts   The GPT-2 generators ( both proxy and target gen-   erators ) were domain - tuned with a block size of   512 BPE tokens , and a batch size of 6 on two Titan   RTX GPUs , with the Adam optimizer .   Domain - tuning GPT-2 to generate paragraphs   in context Proxy and target GPT-2 generators   were obtained by domain - tuning GPT-2 with a   block size of 768 and a batch size of 3 for   four epochs on two disjoint , random subsets of   S2ORC biomedical papers , each consisting in   about 890,000 paragraphs .   We formatted the ﬁne - tuning data in order to gen-   erate complete paragraphs conditioned on previous   paragraphs ; i.e. , each training instance consisted of   text from consecutive paragraph pairs : the last 256   tokens of a paragraph , a special newline token , and   the next paragraph . For each paragraph pair ( A , B ) ,   truncating Aat 256 tokens allowed us to encode at   least 512 tokens for each paragraph B , and about   95 % of paragraphs in the domain - tuning dataset   are shorter than 512 tokens . Thus , the model could   learn how to end paragraphs naturally .   Task - tuning RoBERTa We task - tuned all   RoBERTa models with a block size of 512 on   two Titan RTX GPUs . For RoBERTa - base , we   used a batch size of 40 , while for RoBERTa - large   and RoBERTa - large - STEM we used a batch size   of 7 . Preliminary experiments suggested that for   the smaller task - tuning datasets training for more   epochs improved performance . The 100 - sample   task - tuning dataset was trained for 80 epochs , the   500 - sample dataset was trained for 16 epochs ,   and the other datasets were trained for 8 epochs .   Task - tuning on the SME - labeled ( target ) text was   done using the same hyperparameters as were used   for the proxy task - tuning . A.2 Comparison of classiﬁers on in - domain   detection   Table 8 compares several classiﬁers on the in-   domain detection task ( i.e. , the real portions of the   train and test sets are from the Semantic Scholar   corpus , and the synthetic portions were produced   by the same GPT-2 - Medium generator ) .   RoBERTa - large ( Liu et al . , 2019 ) and XLNet-   large ( Yang et al . , 2019 ) outperform the other clas-   siﬁers . We chose RoBERTa over XLNet because   XLNet is known to be unstable when task - tuned on   small datasets ( Ma et al . , 2019 ) .   Discriminator Accuracy   LR ( BOW ) .64   LSTM .67   HAN .72   BERT - base .86   BERT - large .90   XLNet - base .89   XLNet - large .95   RoBERTa - base .93   RoBERTa - large .95   LR ( BOW ) indicates logistic regression with un-   igram count features , and HAN ( Hierarchical At-   tention Network ) is a hierarchical LSTM with two   attention layers , one for words and another for sen-   tences ( Yang et al . , 2016 ) .   Both the LSTM and the HAN used pre - trained   GloVe embeddings(Pennington et al . , 2014 ) .   They were trained for 60 epochs with early stop-   ping ( patience 10 ) , with 128 hidden layer units ,   dropout of 0.5 , a batch size of 64 , learning rate   of 0.001 and the Adam optimizer . For the HAN ,   abstracts were truncated at the ﬁrst 20 sentences   and only the ﬁrst 50 tokens in each sentence were   used . For the LSTM , abstracts were truncated at   200 tokens .   A.3 Full cross - domain results   Figures 4 , 5 and 6 contain the full results ( accu-   racy , precision and recall ) for all the cross - domain   experiments discussed in § 6.1.1225   A.4 Effect of paragraph length on detection   performance   There is a higher percentage of short paragraphs in   the body of scientiﬁc papers than there is among   abstracts . We noticed this can lead to difﬁculties   in detection , since detector performance deterio-   rates with shorter text lengths ( Ippolito et al . , 2020 ;   Munir et al . , 2021 ) .   To investigate the effect of paragraph length on   performance , we ranked the human paragraphs by   their length in characters and binned them ( 200   per bin ) , in order to calculate the false positive   rate within each bin . The false negative rates were   calculated similarly using the generated paragraphs .   These are shown in Figures 7 and 8 . The false   positive and false negative rates can be seen to   increase substantially for paragraphs with less than   500 characters .   A.5 Effect of training on paragraphs   generated without conditioning   Since it might be unrealistic to assume that both the   adversary ’s ( target ) generator and the defender ’s   ( proxy ) generator both generate text in the same   way – by conditioning on the last 256 tokens of the   previous paragraph – we veriﬁed that our results are   not heavily dependent on this assumption by also   testing detection performance using unconditional   ( i.e. , unprompted ) synthetic paragraphs as proxy   training data .   Tables 5 and 9 show paragraph - level accuracy   when training on conditioned and unconditioned   proxy data , respectively . As expected ( Tay et al . ,   2020 ) , performance is higher when training with   conditioned proxy generations than with uncondi-   tioned proxy generations if no SME samples are   used ( e.g. , an increase in .10 in accuracy when us-   ing 10k proxy samples ) . This is mostly due to a   large increase in recall ( up to .21 for 10k proxy sam-   ples ) . However , a second round of task - tuning with1226   0 100 500 1k 10k   0 .51 .73 .78 .83   100 .77 .75 .83 .88 .93   500 .85 .83 .89 .89 .94   1k .91 .92 .88 .92 .9310k .96 .95 .96 .96 .96   SME samples helps close the gap between task-   tuning with conditioned and unconditioned proxy   samples . Indeed , 100 SME samples are enough to   nearly close the gap ( a difference of .02 in accu-   racy).1227A.6 STEM subset of the CORE dataset1228A.7 Examples of generated technical text   Tables 11 and 12 show examples of GPT-2 - generated biomedical and physics abstracts . Table 13 shows   two examples of tampered documents , where some of the paragraphs were replaced by GPT-2 - generated   paragraphs . Some of the ( human - detectable ) errors in the generated abstracts are given in Appendix § A.8.122912301231A.8 Human - detected errors in generated   biomedical abstracts   The following are a list of errors we found in a sub-   set of 75 synthetic biomedical abstracts generated   by GPT-2 . A similar , larger list of annotations of   error types found in GPT-2 and GPT-3 generated   text was recently provided by ( Dou et al . , 2021 ) .   Not a real word The following words caused   the annotator to mark the abstract as computer-   generated :   • ‘ ProBNER ’   • ‘ Chaos - Tector Chargor ’   • ‘ ﬁbre preveller ’   • ‘ gravidum ’   • ‘ di - nitro - L - arginine ’   • ‘ Cd - FPOs ’   • ‘ halliopeusing ’   Incorrect acronym The following were   acronym - related errors :   • ‘ left middle cerebral artery ( LMCMA ) ’   • ‘ occlusion ( MOOC ) ’   • ‘ In Situ Analysis ( SIA ) ’   • ‘ semantic energy transport ( STM ) ’   • ‘ cross - questionnaires ( CCQs ) ’   •‘Noisy Distributed Execution ( NDE ) ’   [ acronym introduced but never used again ]   Coherence problem   •‘First , a proper description of Big Memory is   required ; In previous studies , it was stated that   Stochastic Roughness is a Fundamentality for   Big Memory . ’   •‘The scheme is based on the framework called   as a density functional , proportional basis ’   [ has nothing to do with rest of abstract ]   • ‘ nanofacial ’ [ unrelated to rest of abstract ]   •‘CONCLUSIONS From a therapeutic point   of view , this multispectral imaging method   allowed to measure all ultrasound values si-   multaneously and easily . Further studies with   practical applications in pediatric emergency   medicine could reveal speciﬁc features of var-   ious brain injury in this way . ’ [ unrelated to   rest of abstract]•‘Parents and doctors share more in common   than many researchers expect . What is avail-   able for use ? ’   Knowledge error : entity does not exist   • ‘ Nevographic Origin of Caustic Cygnosis ’   • ‘ R402D nuclear phytoarray ’   • ‘ the Sargento regime ’   • ‘ SEPA insertion rule ’   •‘4 - OHDA ’ [ does not exist ; but 6 - OHDA does ]   • ‘ The Europir position ’   Knowledge error : other   •‘nonlinear RC receiver in a hydraulic grade ’   [ strange combination of electrical and ﬂuid   mechanics terms ]   •‘inﬂammation - related molecules staphylococ-   cus aureus ’ [ Not a molecule ]   • ‘ the city of san real ’ [ not a city ]   • ‘ The State of Barack Obama ’ [ not a state ]   •‘premature diagnosis of asthma is signiﬁ-   cantly associated with overweight ’   •‘Vaccine coverage is at such high levels in the   United States that without additional initia-   tives , an epidemic likely will emerge within   four years . ’   •‘Trespassing into a host ’s natural area can con-   fer adverse impacts such as diseases , extra   costs , unexpected complications , disadvan-   tages and adverse property rights ’ [ unrealistic   list ]   Contradictory or illogical   •‘Sixty - six occlusions were identiﬁed in the   60 eyes for occlusions , 31 of these ( 90 % ) oc-   curred in abscesses while the rest were non-   occidental . ’   •‘Six groups of 75 children were examined   by means of retrospective analysis . The ﬁrst   group consisted of 66 children , who received   care in the neonatal intensive care unit from   29 January 1971 to 24 June 1972 . The second   group , consisting of 166 children , ’   •‘in patients aged over 65 y of gender between   52.7 years and 70.2 years ’   •‘three inference rules : ’ [ only two rules listed ]   • ‘ can be partially fully ﬁlled’1232Odd grammar   • ‘ Participants ’ means of outcome ’   •‘To compare different gastrointestinal tumors   patients undergo for the intrauterine difﬁcult   caesarean section ’   •‘High temperature polymer is potential dis-   play material , especially in ﬁlm industry ’   [ missing determiners ]   •‘Therefore , new color model for high tem-   perature polymer is proposed . This paper in-   troduces carbon disulﬁde systems and their   design . Simple model is found . We used the   uncertainty principle to overcome this uncer-   tainty . The scheme is based on the framework   called as a density functional , proportional ba-   sis . ’ [ " as a " should be " a " ; also missing some   determiners ]   •‘associated with overweight . ’ [ adjective needs   a noun ]   Strange adjective   • ‘ V oo - like Gene ’   • ‘ non - dominant rodent ’   • ‘ cat - like crystals ’   • ‘ air - exposed mice ’   • ‘ semantic energy transport ’   • ‘ intervertebral sedimentation ’   • ‘ double plasma - associated disease ’   Repetition   •‘our algorithm usually yields evidence of a   weak algorithm ’   • ‘ Negotiation and negotiation ’   • ‘ specialty medical specialty ’   • ‘ discriminant discriminative ’   • ‘ STM based STM system ’   • ‘ processions , and subsequent processesions . ’   •‘The two leading theories suggest that the in-   cidence is an early event after acute expan-   sion of spleen parenchyma , involving the clot-   ting / permeability clique . In this article , we   propose a new hypothesis : the incidence of   double plasma - associated disease is an early   event . ’   • ‘ Interfaces and interfaces’• ‘ where each property represents a property ’   •‘all the vector representations ( or all of them ) ’   •‘in making decision - decisions . Results from   data from data ’   •‘during the growth phase and during the   growth phase , ’   Semantically odd / sounds weird   • ‘ the aortic roots of rats ’   • ‘ ﬁrst - trimester of illness ’   •‘Keeping the word has become an argument   against any pretense of better strategy ’   •‘Metabolic health refers to the state of health   associated with the metabolism of a given sub-   stance or disease , not necessarily a testicular   aspect of normal physical functioning ’   •‘mothers share more than once with a physi-   cian , parent or relative ’   •‘have not clariﬁed the communication of the   ultrasound wave motion to the patient ’   •‘there are several non - invasive and sometimes   invasive systems which would beneﬁt from   the use of these systems to an unlimited ex-   tent ’   •‘reduce productivity and results of the US Na-   tional Health Interview Survey ’   •‘We used the uncertainty principle to over-   come this uncertainty ’   •‘The rate of change in hourly body tempera-   ture was recorded in the eyes of dogs ’   • ‘ Monotreme rhythms in internal and external   body temperature’1233