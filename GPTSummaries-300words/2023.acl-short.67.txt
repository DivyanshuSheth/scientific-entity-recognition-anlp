Summary:

This research paper presents a novel unsupervised approach to subtitle segmentation using pretrained masked language models. The approach predicts line endings and subtitle breaks based on the likelihood of punctuation at candidate segmentation points. The proposed method achieved competitive segmentation accuracy across multiple metrics while preserving the original text and adhering to length constraints. Although supervised models trained on in-domain data and with audio information performed better, the unsupervised approach is highly portable across languages and domains, making it a robust off-the-shelf solution for subtitle segmentation. The proposed method was evaluated on the MuST-Cinema corpus and compared against supervised models. Evaluation metrics included Sigma (a measure of readability), break coverage, and length conformity. The results showed that the unsupervised approach outperformed a simple character counting baseline and generated valid subtitles. The paper also discusses the limitations of the approach, potential risks, and ethical considerations related to energy consumption and model training.