Summary:

The paper proposes a clustering-based loss correction framework called Feature Cluster Loss Correction (FCLC) for fine-grained entity typing (FET) tasks. FCLC addresses the challenge of label noise in FET and mitigates confirmation bias. The framework consists of two phases: in the first phase, a coarse backbone model is trained as a feature extractor and noise estimator; in the second phase, loss correction is applied to each feature cluster. Experimental results on three public datasets show that FCLC achieves the best performance compared to competitive systems. The model is stable to hyperparameters and shows robustness even in the absence of clean data. The evaluation metrics used are strict accuracy, Macro F1, and Micro F1. The paper includes an ablation study and analyzes the sensitivity of the introduced hyperparameters. The proposed framework outperforms previous state-of-the-art models and proves effective in mitigating confirmation bias. The FET datasets used include BBN, OntoNotes, and Wiki/FIGER. The paper concludes by highlighting the benefits of FCLC and suggesting future research directions.