The research paper investigates the understanding of predicate-noun dependencies in vision-and-language models, focusing on their ability to track syntactic dependencies between words. The authors create a new multimodal task to evaluate this understanding and evaluate a range of state-of-the-art models. They find that models' performance on the task varies considerably, with some performing well and others at chance level. They analyze the reasons for this variability and find that the quality of pretraining data is essential for better performance. Moreover, models that leverage fine-grained multimodal pretraining objectives in addition to image-text matching perform better. The study highlights the importance of targeted and controlled evaluations for a precise and rigorous test of the models' multimodal knowledge. The models are evaluated on their ability to track predicate-noun dependencies in a zero-shot setting using an evaluation dataset constructed from Open Images. The evaluation metric used is accuracy, and the results show varying performance across different models. The task is relevant to understanding the multimodal knowledge of vision-and-language models. The dataset used for evaluation is constructed from Open Images and contains carefully selected images and paired sentences with minimal differences. The evaluation set contains 2584 triplets, and for each triplet, a target and a distractor sentence are provided, and the models need to find the correct sentence corresponding to the image. The evaluation set is designed to control for linguistic biases and ensures that the models must take into account the dependencies between words and concepts in the image. The paper provides insights into the performance and capabilities of different models in understanding predicate-noun dependencies and highlights the factors that contribute to their performance variability. The research work can help in improving the design and evaluation of vision-and-language models for better multimodal comprehension of syntax and dependencies.