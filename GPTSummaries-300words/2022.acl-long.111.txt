Summary:

The research paper proposes a framework called Few-Shot Transformer based Enrichment (FeSTE) for enriching tabular datasets using unstructured data. FeSTE uses a two-step fine-tuning process with a BERT-based architecture to generate high-quality features. The entity linking phase links entities in the tabular dataset to their corresponding entries in an external data source (DBpedia). The fine-tuning phase includes a preliminary stage, where the model is trained on multiple datasets using a reformulation process, and a target dataset fine-tuning stage. The features generation phase generates new features by tasking the model with predicting the likelihood of the text belonging to each target class value. FeSTE outperforms existing fine-tuning solutions, achieving an average improvement of 9.2% when combined with the original features. It performs well even when applied separately, achieving an average AUC of 0.664. FeSTE is evaluated on 17 diverse tabular datasets and proves to be a generic and efficient approach for feature generation.