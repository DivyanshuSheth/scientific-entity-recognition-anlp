This research paper presents a study on leveraging multilingual pre-trained generative language models for zero-shot cross-lingual event argument extraction (EAE). The proposed model, X-G (Cross-lingual Generative Event Argument extractor), formulates EAE as a language generation task. It uses language-agnostic templates and finetunes multilingual pre-trained generative models to generate sentences that fill in the templates with arguments extracted from the input passage. X-G outperforms the current state-of-the-art models on zero-shot cross-lingual EAE, achieving better performance in terms of argument classification F1 scores on ACE-2005 and ERE datasets. The model does not require additional named entity recognition modules or dependency parsing annotations. The results demonstrate the potential of using a generation-based framework for zero-shot cross-lingual structured prediction tasks. The proposed method is evaluated on the ACE-2005 and ERE datasets, and the performance is compared with OneIE, CL-GCN, GATE, and TANL models. The evaluation metric used is the argument classification F1 score. The current work is evaluated on the task of zero-shot cross-lingual event argument extraction, using the ACE-2005 and ERE datasets. The code for the proposed model is available on GitHub.